{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 486,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0411522633744856,
      "grad_norm": 2.260618209838867,
      "learning_rate": 4.931412894375857e-05,
      "loss": 1.0107,
      "step": 10
    },
    {
      "epoch": 0.0823045267489712,
      "grad_norm": 3.214149236679077,
      "learning_rate": 4.862825788751715e-05,
      "loss": 1.0167,
      "step": 20
    },
    {
      "epoch": 0.12345679012345678,
      "grad_norm": 4.277707576751709,
      "learning_rate": 4.794238683127572e-05,
      "loss": 1.0059,
      "step": 30
    },
    {
      "epoch": 0.1646090534979424,
      "grad_norm": 2.5272467136383057,
      "learning_rate": 4.725651577503429e-05,
      "loss": 0.9704,
      "step": 40
    },
    {
      "epoch": 0.205761316872428,
      "grad_norm": 3.8862414360046387,
      "learning_rate": 4.657064471879287e-05,
      "loss": 0.9443,
      "step": 50
    },
    {
      "epoch": 0.24691358024691357,
      "grad_norm": 1.6692676544189453,
      "learning_rate": 4.5884773662551446e-05,
      "loss": 0.9847,
      "step": 60
    },
    {
      "epoch": 0.2880658436213992,
      "grad_norm": 3.336012601852417,
      "learning_rate": 4.5198902606310016e-05,
      "loss": 0.9521,
      "step": 70
    },
    {
      "epoch": 0.3292181069958848,
      "grad_norm": 5.309791088104248,
      "learning_rate": 4.451303155006859e-05,
      "loss": 1.0021,
      "step": 80
    },
    {
      "epoch": 0.37037037037037035,
      "grad_norm": 2.483232259750366,
      "learning_rate": 4.3827160493827164e-05,
      "loss": 0.9494,
      "step": 90
    },
    {
      "epoch": 0.411522633744856,
      "grad_norm": 2.5128893852233887,
      "learning_rate": 4.3141289437585735e-05,
      "loss": 0.8615,
      "step": 100
    },
    {
      "epoch": 0.45267489711934156,
      "grad_norm": 1.8458083868026733,
      "learning_rate": 4.2455418381344305e-05,
      "loss": 0.9208,
      "step": 110
    },
    {
      "epoch": 0.49382716049382713,
      "grad_norm": 1.5228114128112793,
      "learning_rate": 4.176954732510288e-05,
      "loss": 0.9755,
      "step": 120
    },
    {
      "epoch": 0.5349794238683128,
      "grad_norm": 4.4465861320495605,
      "learning_rate": 4.108367626886145e-05,
      "loss": 0.8778,
      "step": 130
    },
    {
      "epoch": 0.5761316872427984,
      "grad_norm": 3.2350895404815674,
      "learning_rate": 4.039780521262003e-05,
      "loss": 0.8642,
      "step": 140
    },
    {
      "epoch": 0.6172839506172839,
      "grad_norm": 1.6391477584838867,
      "learning_rate": 3.971193415637861e-05,
      "loss": 0.8848,
      "step": 150
    },
    {
      "epoch": 0.6584362139917695,
      "grad_norm": 2.147470235824585,
      "learning_rate": 3.902606310013718e-05,
      "loss": 0.8493,
      "step": 160
    },
    {
      "epoch": 0.6995884773662552,
      "grad_norm": 3.6368894577026367,
      "learning_rate": 3.834019204389575e-05,
      "loss": 0.8006,
      "step": 170
    },
    {
      "epoch": 0.7407407407407407,
      "grad_norm": 4.538646697998047,
      "learning_rate": 3.7654320987654326e-05,
      "loss": 0.8138,
      "step": 180
    },
    {
      "epoch": 0.7818930041152263,
      "grad_norm": 2.589768171310425,
      "learning_rate": 3.6968449931412896e-05,
      "loss": 0.7583,
      "step": 190
    },
    {
      "epoch": 0.823045267489712,
      "grad_norm": 3.8337368965148926,
      "learning_rate": 3.628257887517147e-05,
      "loss": 0.7889,
      "step": 200
    },
    {
      "epoch": 0.8641975308641975,
      "grad_norm": 3.8384883403778076,
      "learning_rate": 3.5596707818930044e-05,
      "loss": 0.7788,
      "step": 210
    },
    {
      "epoch": 0.9053497942386831,
      "grad_norm": 4.43965482711792,
      "learning_rate": 3.4910836762688615e-05,
      "loss": 0.7229,
      "step": 220
    },
    {
      "epoch": 0.9465020576131687,
      "grad_norm": 4.989063739776611,
      "learning_rate": 3.4224965706447185e-05,
      "loss": 0.8169,
      "step": 230
    },
    {
      "epoch": 0.9876543209876543,
      "grad_norm": 2.5915749073028564,
      "learning_rate": 3.353909465020576e-05,
      "loss": 0.7434,
      "step": 240
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.744236171245575,
      "eval_runtime": 14.0273,
      "eval_samples_per_second": 69.151,
      "eval_steps_per_second": 4.349,
      "step": 243
    },
    {
      "epoch": 1.02880658436214,
      "grad_norm": 5.361692428588867,
      "learning_rate": 3.285322359396434e-05,
      "loss": 0.7757,
      "step": 250
    },
    {
      "epoch": 1.0699588477366255,
      "grad_norm": 2.824070930480957,
      "learning_rate": 3.216735253772291e-05,
      "loss": 0.74,
      "step": 260
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 2.5536513328552246,
      "learning_rate": 3.148148148148148e-05,
      "loss": 0.7594,
      "step": 270
    },
    {
      "epoch": 1.1522633744855968,
      "grad_norm": 3.278482437133789,
      "learning_rate": 3.079561042524006e-05,
      "loss": 0.6651,
      "step": 280
    },
    {
      "epoch": 1.1934156378600824,
      "grad_norm": 3.943725347518921,
      "learning_rate": 3.010973936899863e-05,
      "loss": 0.8494,
      "step": 290
    },
    {
      "epoch": 1.2345679012345678,
      "grad_norm": 4.546464920043945,
      "learning_rate": 2.9423868312757202e-05,
      "loss": 0.7421,
      "step": 300
    },
    {
      "epoch": 1.2757201646090535,
      "grad_norm": 2.6447038650512695,
      "learning_rate": 2.8737997256515776e-05,
      "loss": 0.7207,
      "step": 310
    },
    {
      "epoch": 1.316872427983539,
      "grad_norm": 3.4157228469848633,
      "learning_rate": 2.8052126200274347e-05,
      "loss": 0.7892,
      "step": 320
    },
    {
      "epoch": 1.3580246913580247,
      "grad_norm": 3.329698085784912,
      "learning_rate": 2.736625514403292e-05,
      "loss": 0.7362,
      "step": 330
    },
    {
      "epoch": 1.3991769547325104,
      "grad_norm": 3.4335529804229736,
      "learning_rate": 2.6680384087791498e-05,
      "loss": 0.7724,
      "step": 340
    },
    {
      "epoch": 1.4403292181069958,
      "grad_norm": 4.0990681648254395,
      "learning_rate": 2.5994513031550072e-05,
      "loss": 0.7081,
      "step": 350
    },
    {
      "epoch": 1.4814814814814814,
      "grad_norm": 3.818448066711426,
      "learning_rate": 2.5308641975308646e-05,
      "loss": 0.6679,
      "step": 360
    },
    {
      "epoch": 1.522633744855967,
      "grad_norm": 3.3457744121551514,
      "learning_rate": 2.4622770919067216e-05,
      "loss": 0.6681,
      "step": 370
    },
    {
      "epoch": 1.5637860082304527,
      "grad_norm": 4.82092809677124,
      "learning_rate": 2.393689986282579e-05,
      "loss": 0.7166,
      "step": 380
    },
    {
      "epoch": 1.6049382716049383,
      "grad_norm": 6.341253757476807,
      "learning_rate": 2.3251028806584364e-05,
      "loss": 0.6622,
      "step": 390
    },
    {
      "epoch": 1.646090534979424,
      "grad_norm": 3.9521188735961914,
      "learning_rate": 2.2565157750342935e-05,
      "loss": 0.6407,
      "step": 400
    },
    {
      "epoch": 1.6872427983539096,
      "grad_norm": 3.4412872791290283,
      "learning_rate": 2.1879286694101512e-05,
      "loss": 0.7026,
      "step": 410
    },
    {
      "epoch": 1.7283950617283952,
      "grad_norm": 4.257637023925781,
      "learning_rate": 2.1193415637860082e-05,
      "loss": 0.7355,
      "step": 420
    },
    {
      "epoch": 1.7695473251028808,
      "grad_norm": 5.289259910583496,
      "learning_rate": 2.0507544581618656e-05,
      "loss": 0.6343,
      "step": 430
    },
    {
      "epoch": 1.8106995884773662,
      "grad_norm": 5.635893821716309,
      "learning_rate": 1.982167352537723e-05,
      "loss": 0.7549,
      "step": 440
    },
    {
      "epoch": 1.8518518518518519,
      "grad_norm": 16.445077896118164,
      "learning_rate": 1.91358024691358e-05,
      "loss": 0.809,
      "step": 450
    },
    {
      "epoch": 1.8930041152263375,
      "grad_norm": 4.121251583099365,
      "learning_rate": 1.8449931412894378e-05,
      "loss": 0.8253,
      "step": 460
    },
    {
      "epoch": 1.934156378600823,
      "grad_norm": 5.396562576293945,
      "learning_rate": 1.7764060356652952e-05,
      "loss": 0.7259,
      "step": 470
    },
    {
      "epoch": 1.9753086419753085,
      "grad_norm": 5.027585506439209,
      "learning_rate": 1.7078189300411522e-05,
      "loss": 0.7102,
      "step": 480
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.6934587955474854,
      "eval_runtime": 13.8965,
      "eval_samples_per_second": 69.802,
      "eval_steps_per_second": 4.39,
      "step": 486
    }
  ],
  "logging_steps": 10,
  "max_steps": 729,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 511683307573248.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
