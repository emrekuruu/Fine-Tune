{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 729,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0411522633744856,
      "grad_norm": 2.260618209838867,
      "learning_rate": 4.931412894375857e-05,
      "loss": 1.0107,
      "step": 10
    },
    {
      "epoch": 0.0823045267489712,
      "grad_norm": 3.214149236679077,
      "learning_rate": 4.862825788751715e-05,
      "loss": 1.0167,
      "step": 20
    },
    {
      "epoch": 0.12345679012345678,
      "grad_norm": 4.277707576751709,
      "learning_rate": 4.794238683127572e-05,
      "loss": 1.0059,
      "step": 30
    },
    {
      "epoch": 0.1646090534979424,
      "grad_norm": 2.5272467136383057,
      "learning_rate": 4.725651577503429e-05,
      "loss": 0.9704,
      "step": 40
    },
    {
      "epoch": 0.205761316872428,
      "grad_norm": 3.8862414360046387,
      "learning_rate": 4.657064471879287e-05,
      "loss": 0.9443,
      "step": 50
    },
    {
      "epoch": 0.24691358024691357,
      "grad_norm": 1.6692676544189453,
      "learning_rate": 4.5884773662551446e-05,
      "loss": 0.9847,
      "step": 60
    },
    {
      "epoch": 0.2880658436213992,
      "grad_norm": 3.336012601852417,
      "learning_rate": 4.5198902606310016e-05,
      "loss": 0.9521,
      "step": 70
    },
    {
      "epoch": 0.3292181069958848,
      "grad_norm": 5.309791088104248,
      "learning_rate": 4.451303155006859e-05,
      "loss": 1.0021,
      "step": 80
    },
    {
      "epoch": 0.37037037037037035,
      "grad_norm": 2.483232259750366,
      "learning_rate": 4.3827160493827164e-05,
      "loss": 0.9494,
      "step": 90
    },
    {
      "epoch": 0.411522633744856,
      "grad_norm": 2.5128893852233887,
      "learning_rate": 4.3141289437585735e-05,
      "loss": 0.8615,
      "step": 100
    },
    {
      "epoch": 0.45267489711934156,
      "grad_norm": 1.8458083868026733,
      "learning_rate": 4.2455418381344305e-05,
      "loss": 0.9208,
      "step": 110
    },
    {
      "epoch": 0.49382716049382713,
      "grad_norm": 1.5228114128112793,
      "learning_rate": 4.176954732510288e-05,
      "loss": 0.9755,
      "step": 120
    },
    {
      "epoch": 0.5349794238683128,
      "grad_norm": 4.4465861320495605,
      "learning_rate": 4.108367626886145e-05,
      "loss": 0.8778,
      "step": 130
    },
    {
      "epoch": 0.5761316872427984,
      "grad_norm": 3.2350895404815674,
      "learning_rate": 4.039780521262003e-05,
      "loss": 0.8642,
      "step": 140
    },
    {
      "epoch": 0.6172839506172839,
      "grad_norm": 1.6391477584838867,
      "learning_rate": 3.971193415637861e-05,
      "loss": 0.8848,
      "step": 150
    },
    {
      "epoch": 0.6584362139917695,
      "grad_norm": 2.147470235824585,
      "learning_rate": 3.902606310013718e-05,
      "loss": 0.8493,
      "step": 160
    },
    {
      "epoch": 0.6995884773662552,
      "grad_norm": 3.6368894577026367,
      "learning_rate": 3.834019204389575e-05,
      "loss": 0.8006,
      "step": 170
    },
    {
      "epoch": 0.7407407407407407,
      "grad_norm": 4.538646697998047,
      "learning_rate": 3.7654320987654326e-05,
      "loss": 0.8138,
      "step": 180
    },
    {
      "epoch": 0.7818930041152263,
      "grad_norm": 2.589768171310425,
      "learning_rate": 3.6968449931412896e-05,
      "loss": 0.7583,
      "step": 190
    },
    {
      "epoch": 0.823045267489712,
      "grad_norm": 3.8337368965148926,
      "learning_rate": 3.628257887517147e-05,
      "loss": 0.7889,
      "step": 200
    },
    {
      "epoch": 0.8641975308641975,
      "grad_norm": 3.8384883403778076,
      "learning_rate": 3.5596707818930044e-05,
      "loss": 0.7788,
      "step": 210
    },
    {
      "epoch": 0.9053497942386831,
      "grad_norm": 4.43965482711792,
      "learning_rate": 3.4910836762688615e-05,
      "loss": 0.7229,
      "step": 220
    },
    {
      "epoch": 0.9465020576131687,
      "grad_norm": 4.989063739776611,
      "learning_rate": 3.4224965706447185e-05,
      "loss": 0.8169,
      "step": 230
    },
    {
      "epoch": 0.9876543209876543,
      "grad_norm": 2.5915749073028564,
      "learning_rate": 3.353909465020576e-05,
      "loss": 0.7434,
      "step": 240
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.744236171245575,
      "eval_runtime": 14.0273,
      "eval_samples_per_second": 69.151,
      "eval_steps_per_second": 4.349,
      "step": 243
    },
    {
      "epoch": 1.02880658436214,
      "grad_norm": 5.361692428588867,
      "learning_rate": 3.285322359396434e-05,
      "loss": 0.7757,
      "step": 250
    },
    {
      "epoch": 1.0699588477366255,
      "grad_norm": 2.824070930480957,
      "learning_rate": 3.216735253772291e-05,
      "loss": 0.74,
      "step": 260
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 2.5536513328552246,
      "learning_rate": 3.148148148148148e-05,
      "loss": 0.7594,
      "step": 270
    },
    {
      "epoch": 1.1522633744855968,
      "grad_norm": 3.278482437133789,
      "learning_rate": 3.079561042524006e-05,
      "loss": 0.6651,
      "step": 280
    },
    {
      "epoch": 1.1934156378600824,
      "grad_norm": 3.943725347518921,
      "learning_rate": 3.010973936899863e-05,
      "loss": 0.8494,
      "step": 290
    },
    {
      "epoch": 1.2345679012345678,
      "grad_norm": 4.546464920043945,
      "learning_rate": 2.9423868312757202e-05,
      "loss": 0.7421,
      "step": 300
    },
    {
      "epoch": 1.2757201646090535,
      "grad_norm": 2.6447038650512695,
      "learning_rate": 2.8737997256515776e-05,
      "loss": 0.7207,
      "step": 310
    },
    {
      "epoch": 1.316872427983539,
      "grad_norm": 3.4157228469848633,
      "learning_rate": 2.8052126200274347e-05,
      "loss": 0.7892,
      "step": 320
    },
    {
      "epoch": 1.3580246913580247,
      "grad_norm": 3.329698085784912,
      "learning_rate": 2.736625514403292e-05,
      "loss": 0.7362,
      "step": 330
    },
    {
      "epoch": 1.3991769547325104,
      "grad_norm": 3.4335529804229736,
      "learning_rate": 2.6680384087791498e-05,
      "loss": 0.7724,
      "step": 340
    },
    {
      "epoch": 1.4403292181069958,
      "grad_norm": 4.0990681648254395,
      "learning_rate": 2.5994513031550072e-05,
      "loss": 0.7081,
      "step": 350
    },
    {
      "epoch": 1.4814814814814814,
      "grad_norm": 3.818448066711426,
      "learning_rate": 2.5308641975308646e-05,
      "loss": 0.6679,
      "step": 360
    },
    {
      "epoch": 1.522633744855967,
      "grad_norm": 3.3457744121551514,
      "learning_rate": 2.4622770919067216e-05,
      "loss": 0.6681,
      "step": 370
    },
    {
      "epoch": 1.5637860082304527,
      "grad_norm": 4.82092809677124,
      "learning_rate": 2.393689986282579e-05,
      "loss": 0.7166,
      "step": 380
    },
    {
      "epoch": 1.6049382716049383,
      "grad_norm": 6.341253757476807,
      "learning_rate": 2.3251028806584364e-05,
      "loss": 0.6622,
      "step": 390
    },
    {
      "epoch": 1.646090534979424,
      "grad_norm": 3.9521188735961914,
      "learning_rate": 2.2565157750342935e-05,
      "loss": 0.6407,
      "step": 400
    },
    {
      "epoch": 1.6872427983539096,
      "grad_norm": 3.4412872791290283,
      "learning_rate": 2.1879286694101512e-05,
      "loss": 0.7026,
      "step": 410
    },
    {
      "epoch": 1.7283950617283952,
      "grad_norm": 4.257637023925781,
      "learning_rate": 2.1193415637860082e-05,
      "loss": 0.7355,
      "step": 420
    },
    {
      "epoch": 1.7695473251028808,
      "grad_norm": 5.289259910583496,
      "learning_rate": 2.0507544581618656e-05,
      "loss": 0.6343,
      "step": 430
    },
    {
      "epoch": 1.8106995884773662,
      "grad_norm": 5.635893821716309,
      "learning_rate": 1.982167352537723e-05,
      "loss": 0.7549,
      "step": 440
    },
    {
      "epoch": 1.8518518518518519,
      "grad_norm": 16.445077896118164,
      "learning_rate": 1.91358024691358e-05,
      "loss": 0.809,
      "step": 450
    },
    {
      "epoch": 1.8930041152263375,
      "grad_norm": 4.121251583099365,
      "learning_rate": 1.8449931412894378e-05,
      "loss": 0.8253,
      "step": 460
    },
    {
      "epoch": 1.934156378600823,
      "grad_norm": 5.396562576293945,
      "learning_rate": 1.7764060356652952e-05,
      "loss": 0.7259,
      "step": 470
    },
    {
      "epoch": 1.9753086419753085,
      "grad_norm": 5.027585506439209,
      "learning_rate": 1.7078189300411522e-05,
      "loss": 0.7102,
      "step": 480
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.6934587955474854,
      "eval_runtime": 13.8965,
      "eval_samples_per_second": 69.802,
      "eval_steps_per_second": 4.39,
      "step": 486
    },
    {
      "epoch": 2.016460905349794,
      "grad_norm": 2.9742591381073,
      "learning_rate": 1.6392318244170096e-05,
      "loss": 0.6951,
      "step": 490
    },
    {
      "epoch": 2.05761316872428,
      "grad_norm": 4.4836297035217285,
      "learning_rate": 1.570644718792867e-05,
      "loss": 0.7915,
      "step": 500
    },
    {
      "epoch": 2.0987654320987654,
      "grad_norm": 3.379560708999634,
      "learning_rate": 1.5020576131687244e-05,
      "loss": 0.7096,
      "step": 510
    },
    {
      "epoch": 2.139917695473251,
      "grad_norm": 5.022838115692139,
      "learning_rate": 1.4334705075445818e-05,
      "loss": 0.7221,
      "step": 520
    },
    {
      "epoch": 2.1810699588477367,
      "grad_norm": 4.654024124145508,
      "learning_rate": 1.364883401920439e-05,
      "loss": 0.649,
      "step": 530
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 2.874767303466797,
      "learning_rate": 1.2962962962962962e-05,
      "loss": 0.7576,
      "step": 540
    },
    {
      "epoch": 2.263374485596708,
      "grad_norm": 3.672074317932129,
      "learning_rate": 1.2277091906721536e-05,
      "loss": 0.692,
      "step": 550
    },
    {
      "epoch": 2.3045267489711936,
      "grad_norm": 4.426287651062012,
      "learning_rate": 1.159122085048011e-05,
      "loss": 0.5807,
      "step": 560
    },
    {
      "epoch": 2.3456790123456788,
      "grad_norm": 4.4778523445129395,
      "learning_rate": 1.0905349794238684e-05,
      "loss": 0.6325,
      "step": 570
    },
    {
      "epoch": 2.386831275720165,
      "grad_norm": 5.393679141998291,
      "learning_rate": 1.0219478737997256e-05,
      "loss": 0.7386,
      "step": 580
    },
    {
      "epoch": 2.42798353909465,
      "grad_norm": 3.463270664215088,
      "learning_rate": 9.53360768175583e-06,
      "loss": 0.6796,
      "step": 590
    },
    {
      "epoch": 2.4691358024691357,
      "grad_norm": 4.174952030181885,
      "learning_rate": 8.847736625514404e-06,
      "loss": 0.6857,
      "step": 600
    },
    {
      "epoch": 2.5102880658436213,
      "grad_norm": 4.041520118713379,
      "learning_rate": 8.161865569272976e-06,
      "loss": 0.5945,
      "step": 610
    },
    {
      "epoch": 2.551440329218107,
      "grad_norm": 3.4893925189971924,
      "learning_rate": 7.47599451303155e-06,
      "loss": 0.6641,
      "step": 620
    },
    {
      "epoch": 2.5925925925925926,
      "grad_norm": 3.385369300842285,
      "learning_rate": 6.790123456790123e-06,
      "loss": 0.7159,
      "step": 630
    },
    {
      "epoch": 2.633744855967078,
      "grad_norm": 2.497631072998047,
      "learning_rate": 6.104252400548697e-06,
      "loss": 0.7459,
      "step": 640
    },
    {
      "epoch": 2.674897119341564,
      "grad_norm": 4.172474384307861,
      "learning_rate": 5.41838134430727e-06,
      "loss": 0.7599,
      "step": 650
    },
    {
      "epoch": 2.7160493827160495,
      "grad_norm": 3.161388397216797,
      "learning_rate": 4.732510288065844e-06,
      "loss": 0.6896,
      "step": 660
    },
    {
      "epoch": 2.757201646090535,
      "grad_norm": 3.508918523788452,
      "learning_rate": 4.046639231824417e-06,
      "loss": 0.6877,
      "step": 670
    },
    {
      "epoch": 2.7983539094650207,
      "grad_norm": 5.486672401428223,
      "learning_rate": 3.3607681755829907e-06,
      "loss": 0.6058,
      "step": 680
    },
    {
      "epoch": 2.8395061728395063,
      "grad_norm": 5.259687423706055,
      "learning_rate": 2.6748971193415637e-06,
      "loss": 0.7169,
      "step": 690
    },
    {
      "epoch": 2.8806584362139915,
      "grad_norm": 4.217446804046631,
      "learning_rate": 1.9890260631001372e-06,
      "loss": 0.747,
      "step": 700
    },
    {
      "epoch": 2.9218106995884776,
      "grad_norm": 6.430498123168945,
      "learning_rate": 1.3031550068587107e-06,
      "loss": 0.6427,
      "step": 710
    },
    {
      "epoch": 2.962962962962963,
      "grad_norm": 3.764673948287964,
      "learning_rate": 6.17283950617284e-07,
      "loss": 0.69,
      "step": 720
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.6831112504005432,
      "eval_runtime": 13.9078,
      "eval_samples_per_second": 69.745,
      "eval_steps_per_second": 4.386,
      "step": 729
    }
  ],
  "logging_steps": 10,
  "max_steps": 729,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 767524961359872.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
