{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emrekuruu/Fine-Tune/blob/main/knowledge_distil_roberta_vs_distilbert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUox-IuVRGDD",
        "outputId": "69943e3e-d17f-4b89-a794-ed5a0e15330f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets peft"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TYL77usRinq",
        "outputId": "5ac946d4-4e2e-4809-f8f0-2e9b2998bbd9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.5.1+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (1.2.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8TcVpvVRoGI",
        "outputId": "d8038587-ac9f-4e48-db24-bf5b9b457491"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CRQ27Dl_NxLv"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mMvfUb5wNxLw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datasets import load_dataset, Dataset\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3upgzzwdNxLx"
      },
      "outputs": [],
      "source": [
        "def prepare_datasets(tokenizer, dataset_name=\"financial_phrasebank\", subset_name=\"sentences_50agree\", max_length=128, random_state=42):\n",
        "    dataset = load_dataset(dataset_name, subset_name, trust_remote_code=True)\n",
        "\n",
        "    df = pd.DataFrame(dataset['train'])\n",
        "\n",
        "    # Stratify split into train, validation, and test\n",
        "    train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "        df['sentence'], df['label'], test_size=0.2, stratify=df['label'], random_state=random_state\n",
        "    )\n",
        "    train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "        train_texts, train_labels, test_size=0.1, stratify=train_labels, random_state=random_state\n",
        "    )\n",
        "\n",
        "    # Create DataFrames for each split\n",
        "    train_df = pd.DataFrame({'sentence': train_texts, 'label': train_labels})\n",
        "    val_df = pd.DataFrame({'sentence': val_texts, 'label': val_labels})\n",
        "    test_df = pd.DataFrame({'sentence': test_texts, 'label': test_labels})\n",
        "\n",
        "    # Convert DataFrames to Hugging Face Dataset format\n",
        "    train_dataset = Dataset.from_pandas(train_df)\n",
        "    val_dataset = Dataset.from_pandas(val_df)\n",
        "    test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "    # Define tokenization function\n",
        "    def tokenize_function(example):\n",
        "        return tokenizer(\n",
        "            example[\"sentence\"],\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=max_length\n",
        "        )\n",
        "     # Tokenize datasets\n",
        "    train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "    val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
        "    test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "    # Remove raw text and prepare for Hugging Face Trainer\n",
        "    train_dataset = train_dataset.remove_columns([\"sentence\"])\n",
        "    val_dataset = val_dataset.remove_columns([\"sentence\"])\n",
        "    test_dataset = test_dataset.remove_columns([\"sentence\"])\n",
        "\n",
        "    train_dataset = train_dataset.rename_column(\"label\", \"labels\")\n",
        "    val_dataset = val_dataset.rename_column(\"label\", \"labels\")\n",
        "    test_dataset = test_dataset.rename_column(\"label\", \"labels\")\n",
        "\n",
        "    train_dataset.set_format(\"torch\")\n",
        "    val_dataset.set_format(\"torch\")\n",
        "    test_dataset.set_format(\"torch\")\n",
        "\n",
        "    return train_dataset, val_dataset, test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXBAho7oNxLx",
        "outputId": "db123b0f-64ee-497e-82b4-aa77956a9b24"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "# Load the tokenizer for BERT\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Load the Teacher model (BERT)\n",
        "teacher_model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
        "\n",
        "# Load the Student model (DistilBERT)\n",
        "student_model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgnlSDGNNxLy",
        "outputId": "76ece52a-e63b-4f5c-818b-180dbfdcea57"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 3488/3488 [00:00<00:00, 24431.47 examples/s]\n",
            "Map: 100%|██████████| 388/388 [00:00<00:00, 22940.69 examples/s]\n",
            "Map: 100%|██████████| 970/970 [00:00<00:00, 22919.05 examples/s]\n"
          ]
        }
      ],
      "source": [
        "train_dataset, val_dataset, test_dataset = prepare_datasets(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFgT4lzuNxLy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def distillation_loss(student_logits, teacher_logits, true_labels, temperature=2.0, alpha=0.7):\n",
        "    # Soft labels from teacher model\n",
        "    soft_labels = F.softmax(teacher_logits / temperature, dim=-1)\n",
        "\n",
        "    # Hard loss using true labels\n",
        "    hard_loss = F.cross_entropy(student_logits, true_labels)\n",
        "\n",
        "    # Soft loss between teacher and student logits\n",
        "    soft_loss = F.kl_div(\n",
        "        F.log_softmax(student_logits / temperature, dim=-1),\n",
        "        soft_labels,\n",
        "        reduction='batchmean'\n",
        "    )\n",
        "\n",
        "    # Weighted combination of soft and hard loss\n",
        "    return alpha * soft_loss + (1.0 - alpha) * hard_loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naCuJuErNxLy"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def get_teacher_logits(model, dataset, batch_size=16, device='cpu'):\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
        "    logits = []\n",
        "\n",
        "    model.eval()  # Set teacher model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs = {k: v.to(device) for k, v in batch.items() if k in ['input_ids', 'attention_mask']}\n",
        "            outputs = model(**inputs)\n",
        "            logits.append(outputs.logits.cpu())\n",
        "\n",
        "    return torch.cat(logits, dim=0)  # Concatenate all logits into one tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEtIwdjcNxLy"
      },
      "outputs": [],
      "source": [
        "def distillation_train_loop(student_model, teacher_model, train_dataset, val_dataset, tokenizer, epochs=3, batch_size=16, learning_rate=5e-5, device='cpu'):\n",
        "    student_model = student_model.to(device)\n",
        "    teacher_model = teacher_model.to(device)\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(student_model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Teacher logits for the entire training dataset\n",
        "    teacher_logits = get_teacher_logits(teacher_model, train_dataset, batch_size=batch_size, device=device)\n",
        "    print(f\"Teacher logits: {teacher_logits}\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        student_model.train()\n",
        "        total_loss = 0.0\n",
        "\n",
        "        for i, batch in enumerate(train_dataloader):\n",
        "            inputs = {k: v.to(device) for k, v in batch.items() if k in ['input_ids', 'attention_mask']}\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            # Select corresponding teacher logits for this batch\n",
        "            batch_teacher_logits = teacher_logits[i * batch_size:(i + 1) * batch_size].to(device)\n",
        "\n",
        "            # Forward pass of student model\n",
        "            student_outputs = student_model(**inputs)\n",
        "            print(f\"Student outputs: {student_outputs}\")\n",
        "            student_logits = student_outputs.logits\n",
        "            print(f\"Student logits: {student_logits}\")\n",
        "\n",
        "            # Compute loss\n",
        "            loss = distillation_loss(student_logits, batch_teacher_logits, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_dataloader):.4f}\")\n",
        "\n",
        "    return student_model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6qtLLXINxLz",
        "outputId": "4fdf3fc4-ba3a-45a6-dc26-21e22fb8f9b8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/beyzakaya/miniforge3/envs/DLprojectenv/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/var/folders/kv/563b5k8n4xg24_t9kd2d72c40000gn/T/ipykernel_56174/2655727639.py:14: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_teacher = Trainer(\n",
            "  2%|▏         | 10/654 [00:22<15:48,  1.47s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8957, 'grad_norm': 4.335817337036133, 'learning_rate': 4.923547400611621e-05, 'epoch': 0.05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 20/654 [00:35<11:03,  1.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7797, 'grad_norm': 3.726905584335327, 'learning_rate': 4.847094801223242e-05, 'epoch': 0.09}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▍         | 30/654 [00:55<19:18,  1.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7911, 'grad_norm': 3.6768481731414795, 'learning_rate': 4.7706422018348626e-05, 'epoch': 0.14}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 40/654 [01:14<20:44,  2.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7659, 'grad_norm': 6.559085845947266, 'learning_rate': 4.694189602446483e-05, 'epoch': 0.18}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 50/654 [01:34<14:28,  1.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.6494, 'grad_norm': 5.637365341186523, 'learning_rate': 4.617737003058104e-05, 'epoch': 0.23}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▉         | 60/654 [02:01<34:59,  3.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.5958, 'grad_norm': 7.2245049476623535, 'learning_rate': 4.541284403669725e-05, 'epoch': 0.28}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 70/654 [02:44<33:00,  3.39s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.5212, 'grad_norm': 9.817317008972168, 'learning_rate': 4.4648318042813456e-05, 'epoch': 0.32}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 80/654 [03:20<37:59,  3.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.5809, 'grad_norm': 14.302302360534668, 'learning_rate': 4.3883792048929664e-05, 'epoch': 0.37}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 90/654 [03:51<25:06,  2.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4667, 'grad_norm': 4.403275012969971, 'learning_rate': 4.311926605504588e-05, 'epoch': 0.41}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 100/654 [04:09<13:33,  1.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4744, 'grad_norm': 2.98917293548584, 'learning_rate': 4.235474006116208e-05, 'epoch': 0.46}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 110/654 [04:27<14:55,  1.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4692, 'grad_norm': 13.180750846862793, 'learning_rate': 4.159021406727829e-05, 'epoch': 0.5}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 120/654 [04:39<08:44,  1.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.451, 'grad_norm': 4.209173679351807, 'learning_rate': 4.0825688073394495e-05, 'epoch': 0.55}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|█▉        | 130/654 [04:47<07:08,  1.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.3658, 'grad_norm': 13.522235870361328, 'learning_rate': 4.00611620795107e-05, 'epoch': 0.6}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██▏       | 140/654 [04:56<08:09,  1.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4707, 'grad_norm': 6.981060981750488, 'learning_rate': 3.929663608562692e-05, 'epoch': 0.64}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 150/654 [05:05<07:03,  1.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.394, 'grad_norm': 3.078388214111328, 'learning_rate': 3.8532110091743125e-05, 'epoch': 0.69}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▍       | 160/654 [05:15<08:03,  1.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4116, 'grad_norm': 11.815357208251953, 'learning_rate': 3.7767584097859326e-05, 'epoch': 0.73}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 170/654 [05:26<07:30,  1.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4293, 'grad_norm': 8.353646278381348, 'learning_rate': 3.7003058103975534e-05, 'epoch': 0.78}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 180/654 [05:34<06:24,  1.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4091, 'grad_norm': 3.852647542953491, 'learning_rate': 3.623853211009174e-05, 'epoch': 0.83}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 29%|██▉       | 190/654 [05:47<11:29,  1.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.3439, 'grad_norm': 8.242115020751953, 'learning_rate': 3.5474006116207956e-05, 'epoch': 0.87}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 31%|███       | 200/654 [05:57<07:18,  1.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4478, 'grad_norm': 11.006133079528809, 'learning_rate': 3.4709480122324164e-05, 'epoch': 0.92}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 210/654 [06:07<07:36,  1.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4146, 'grad_norm': 3.8564493656158447, 'learning_rate': 3.394495412844037e-05, 'epoch': 0.96}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                 \n",
            " 33%|███▎      | 218/654 [06:22<06:04,  1.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.39951249957084656, 'eval_runtime': 7.9863, 'eval_samples_per_second': 48.583, 'eval_steps_per_second': 3.13, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▎      | 220/654 [06:25<20:41,  2.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4293, 'grad_norm': 5.919196605682373, 'learning_rate': 3.318042813455658e-05, 'epoch': 1.01}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 230/654 [06:35<06:36,  1.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2745, 'grad_norm': 12.205646514892578, 'learning_rate': 3.241590214067278e-05, 'epoch': 1.06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 240/654 [06:44<05:46,  1.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2492, 'grad_norm': 19.635948181152344, 'learning_rate': 3.1651376146788995e-05, 'epoch': 1.1}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 250/654 [06:52<05:59,  1.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2927, 'grad_norm': 13.9088716506958, 'learning_rate': 3.08868501529052e-05, 'epoch': 1.15}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|███▉      | 260/654 [07:01<05:22,  1.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2574, 'grad_norm': 12.238587379455566, 'learning_rate': 3.012232415902141e-05, 'epoch': 1.19}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 41%|████▏     | 270/654 [07:09<05:22,  1.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2473, 'grad_norm': 4.494692802429199, 'learning_rate': 2.9357798165137618e-05, 'epoch': 1.24}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 280/654 [07:18<05:12,  1.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2933, 'grad_norm': 5.556410789489746, 'learning_rate': 2.8593272171253826e-05, 'epoch': 1.28}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 290/654 [07:26<05:01,  1.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2478, 'grad_norm': 15.016253471374512, 'learning_rate': 2.782874617737003e-05, 'epoch': 1.33}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 46%|████▌     | 300/654 [07:35<04:48,  1.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2413, 'grad_norm': 10.48573112487793, 'learning_rate': 2.7064220183486238e-05, 'epoch': 1.38}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 47%|████▋     | 310/654 [07:43<04:30,  1.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2933, 'grad_norm': 8.468277931213379, 'learning_rate': 2.629969418960245e-05, 'epoch': 1.42}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 49%|████▉     | 320/654 [07:51<04:33,  1.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2082, 'grad_norm': 11.91784954071045, 'learning_rate': 2.5535168195718656e-05, 'epoch': 1.47}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 330/654 [08:00<04:21,  1.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1717, 'grad_norm': 6.597239017486572, 'learning_rate': 2.4770642201834864e-05, 'epoch': 1.51}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 340/654 [08:08<04:10,  1.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2109, 'grad_norm': 6.263698577880859, 'learning_rate': 2.4006116207951072e-05, 'epoch': 1.56}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|█████▎    | 350/654 [08:16<04:01,  1.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2668, 'grad_norm': 3.51605486869812, 'learning_rate': 2.324159021406728e-05, 'epoch': 1.61}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 55%|█████▌    | 360/654 [08:25<03:58,  1.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2358, 'grad_norm': 6.929905891418457, 'learning_rate': 2.2477064220183487e-05, 'epoch': 1.65}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 370/654 [08:32<03:38,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1737, 'grad_norm': 13.150646209716797, 'learning_rate': 2.1712538226299695e-05, 'epoch': 1.7}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 58%|█████▊    | 380/654 [08:59<08:46,  1.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1887, 'grad_norm': 2.7542884349823, 'learning_rate': 2.0948012232415903e-05, 'epoch': 1.74}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|█████▉    | 390/654 [09:17<08:21,  1.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2438, 'grad_norm': 7.993503093719482, 'learning_rate': 2.018348623853211e-05, 'epoch': 1.79}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 61%|██████    | 400/654 [09:43<07:55,  1.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2273, 'grad_norm': 1.731151819229126, 'learning_rate': 1.9418960244648318e-05, 'epoch': 1.83}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 63%|██████▎   | 410/654 [09:51<03:25,  1.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.189, 'grad_norm': 10.786277770996094, 'learning_rate': 1.8654434250764526e-05, 'epoch': 1.88}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 420/654 [10:00<03:27,  1.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2369, 'grad_norm': 24.436796188354492, 'learning_rate': 1.7889908256880737e-05, 'epoch': 1.93}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 66%|██████▌   | 430/654 [10:09<03:13,  1.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2379, 'grad_norm': 10.953409194946289, 'learning_rate': 1.712538226299694e-05, 'epoch': 1.97}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                 \n",
            " 67%|██████▋   | 436/654 [10:20<03:09,  1.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.42221856117248535, 'eval_runtime': 5.1733, 'eval_samples_per_second': 75.001, 'eval_steps_per_second': 4.833, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 440/654 [10:25<05:57,  1.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1247, 'grad_norm': 0.48542287945747375, 'learning_rate': 1.636085626911315e-05, 'epoch': 2.02}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 69%|██████▉   | 450/654 [10:35<03:32,  1.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1219, 'grad_norm': 4.878985404968262, 'learning_rate': 1.559633027522936e-05, 'epoch': 2.06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 460/654 [10:44<02:38,  1.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0529, 'grad_norm': 0.5471055507659912, 'learning_rate': 1.4831804281345565e-05, 'epoch': 2.11}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 72%|███████▏  | 470/654 [10:56<04:36,  1.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.094, 'grad_norm': 2.234342336654663, 'learning_rate': 1.4067278287461774e-05, 'epoch': 2.16}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 73%|███████▎  | 480/654 [11:10<03:11,  1.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0941, 'grad_norm': 2.1173996925354004, 'learning_rate': 1.3302752293577984e-05, 'epoch': 2.2}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▍  | 490/654 [11:23<03:31,  1.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1095, 'grad_norm': 8.039071083068848, 'learning_rate': 1.253822629969419e-05, 'epoch': 2.25}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▋  | 500/654 [11:50<09:03,  3.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0603, 'grad_norm': 0.2917783856391907, 'learning_rate': 1.1773700305810397e-05, 'epoch': 2.29}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 510/654 [12:28<06:34,  2.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.058, 'grad_norm': 3.5893125534057617, 'learning_rate': 1.1009174311926607e-05, 'epoch': 2.34}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|███████▉  | 520/654 [12:48<04:15,  1.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0454, 'grad_norm': 0.35865363478660583, 'learning_rate': 1.0244648318042814e-05, 'epoch': 2.39}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 81%|████████  | 530/654 [12:58<01:46,  1.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0929, 'grad_norm': 1.6767597198486328, 'learning_rate': 9.480122324159022e-06, 'epoch': 2.43}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 83%|████████▎ | 540/654 [13:06<01:33,  1.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.065, 'grad_norm': 0.4124130606651306, 'learning_rate': 8.71559633027523e-06, 'epoch': 2.48}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 84%|████████▍ | 550/654 [13:59<06:46,  3.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1427, 'grad_norm': 7.561567783355713, 'learning_rate': 7.951070336391438e-06, 'epoch': 2.52}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 560/654 [14:19<03:21,  2.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1231, 'grad_norm': 0.09226620942354202, 'learning_rate': 7.186544342507645e-06, 'epoch': 2.57}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 87%|████████▋ | 570/654 [14:48<03:34,  2.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0902, 'grad_norm': 2.3611152172088623, 'learning_rate': 6.422018348623854e-06, 'epoch': 2.61}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 89%|████████▊ | 580/654 [15:07<02:04,  1.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1019, 'grad_norm': 0.11030992120504379, 'learning_rate': 5.657492354740062e-06, 'epoch': 2.66}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 590/654 [15:25<01:34,  1.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0148, 'grad_norm': 0.17759627103805542, 'learning_rate': 4.892966360856269e-06, 'epoch': 2.71}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 92%|█████████▏| 600/654 [15:37<00:56,  1.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.127, 'grad_norm': 0.4788254201412201, 'learning_rate': 4.128440366972477e-06, 'epoch': 2.75}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 610/654 [16:06<01:00,  1.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1061, 'grad_norm': 13.228991508483887, 'learning_rate': 3.363914373088685e-06, 'epoch': 2.8}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 95%|█████████▍| 620/654 [16:22<00:40,  1.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1632, 'grad_norm': 16.87421417236328, 'learning_rate': 2.599388379204893e-06, 'epoch': 2.84}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96%|█████████▋| 630/654 [16:33<00:28,  1.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1102, 'grad_norm': 2.434553861618042, 'learning_rate': 1.8348623853211011e-06, 'epoch': 2.89}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 640/654 [16:47<00:24,  1.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0989, 'grad_norm': 0.21832436323165894, 'learning_rate': 1.0703363914373088e-06, 'epoch': 2.94}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 99%|█████████▉| 650/654 [16:58<00:04,  1.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1114, 'grad_norm': 0.08660129457712173, 'learning_rate': 3.0581039755351683e-07, 'epoch': 2.98}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                 \n",
            "100%|██████████| 654/654 [17:20<00:00,  1.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.6311530470848083, 'eval_runtime': 7.7797, 'eval_samples_per_second': 49.873, 'eval_steps_per_second': 3.213, 'epoch': 3.0}\n",
            "{'train_runtime': 1040.5886, 'train_samples_per_second': 10.056, 'train_steps_per_second': 0.628, 'train_loss': 0.2857098263611487, 'epoch': 3.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=654, training_loss=0.2857098263611487, metrics={'train_runtime': 1040.5886, 'train_samples_per_second': 10.056, 'train_steps_per_second': 0.628, 'total_flos': 688304700776448.0, 'train_loss': 0.2857098263611487, 'epoch': 3.0})"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set up the training arguments for the teacher model\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results_knowledge_distill/teacher_model\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    logging_dir=\"./logs_knowledge_distill/teacher_model\",\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "# Trainer for the teacher model\n",
        "trainer_teacher = Trainer(\n",
        "    model=teacher_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "# Fine-tune the teacher model\n",
        "trainer_teacher.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjVi3ZhONxLz"
      },
      "source": [
        "#### This function ensures the student model is trained using the logits from the teacher model in addition to the ground truth labels, combining hard and soft losses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwFCHcBfNxLz",
        "outputId": "2aa59a57-39f5-4fdc-c9a3-8c6f5a4ae343"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teacher logits: tensor([[-2.6213,  4.1635, -2.3194],\n",
            "        [-1.5190, -1.7753,  4.8557],\n",
            "        [-2.5256,  4.1303, -2.2848],\n",
            "        ...,\n",
            "        [-1.7173,  3.6361, -2.9695],\n",
            "        [-1.8634, -1.4155,  4.7208],\n",
            "        [-2.6480,  4.1266, -2.2814]])\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4568,  1.6938, -0.6216],\n",
            "        [-1.4918,  1.5309, -0.0303],\n",
            "        [-1.6417,  1.1014,  0.4621],\n",
            "        [-1.2778,  1.1750, -0.1223],\n",
            "        [-1.7693,  0.3149,  1.4295],\n",
            "        [-1.8186,  1.1852,  0.1105],\n",
            "        [ 0.1959,  0.1122, -0.8044],\n",
            "        [-2.2644,  0.2283,  1.6057],\n",
            "        [-1.8654,  0.4816,  0.9782],\n",
            "        [-0.0396,  0.2007, -0.8431],\n",
            "        [-1.1631,  1.3751, -0.3029],\n",
            "        [-1.7715,  1.5458,  0.2369],\n",
            "        [-1.1664,  1.3201, -0.6355],\n",
            "        [-1.6168, -0.0067,  1.1921],\n",
            "        [-1.7620,  0.3772,  1.1147],\n",
            "        [-1.8191,  1.2931,  0.3181]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4568,  1.6938, -0.6216],\n",
            "        [-1.4918,  1.5309, -0.0303],\n",
            "        [-1.6417,  1.1014,  0.4621],\n",
            "        [-1.2778,  1.1750, -0.1223],\n",
            "        [-1.7693,  0.3149,  1.4295],\n",
            "        [-1.8186,  1.1852,  0.1105],\n",
            "        [ 0.1959,  0.1122, -0.8044],\n",
            "        [-2.2644,  0.2283,  1.6057],\n",
            "        [-1.8654,  0.4816,  0.9782],\n",
            "        [-0.0396,  0.2007, -0.8431],\n",
            "        [-1.1631,  1.3751, -0.3029],\n",
            "        [-1.7715,  1.5458,  0.2369],\n",
            "        [-1.1664,  1.3201, -0.6355],\n",
            "        [-1.6168, -0.0067,  1.1921],\n",
            "        [-1.7620,  0.3772,  1.1147],\n",
            "        [-1.8191,  1.2931,  0.3181]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5808,  1.6886, -0.0567],\n",
            "        [-1.5757,  1.7930, -0.4598],\n",
            "        [-1.2112,  1.0803, -0.2517],\n",
            "        [-1.9942,  1.0192,  0.6077],\n",
            "        [-1.4595,  1.4458, -0.1002],\n",
            "        [-1.7656,  0.1432,  1.3050],\n",
            "        [-1.6312,  1.5670, -0.0466],\n",
            "        [-1.6714,  1.6358, -0.0982],\n",
            "        [-1.9927,  0.2996,  1.4402],\n",
            "        [-1.3640,  1.4469, -0.2880],\n",
            "        [-1.6073,  1.7372, -0.1742],\n",
            "        [-1.8234,  1.4073,  0.0721],\n",
            "        [-1.8748,  1.2589,  0.2262],\n",
            "        [-1.5140,  1.9485, -0.1832],\n",
            "        [-1.8572,  1.1929,  0.5277],\n",
            "        [-1.9547,  1.0560,  0.4281]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5808,  1.6886, -0.0567],\n",
            "        [-1.5757,  1.7930, -0.4598],\n",
            "        [-1.2112,  1.0803, -0.2517],\n",
            "        [-1.9942,  1.0192,  0.6077],\n",
            "        [-1.4595,  1.4458, -0.1002],\n",
            "        [-1.7656,  0.1432,  1.3050],\n",
            "        [-1.6312,  1.5670, -0.0466],\n",
            "        [-1.6714,  1.6358, -0.0982],\n",
            "        [-1.9927,  0.2996,  1.4402],\n",
            "        [-1.3640,  1.4469, -0.2880],\n",
            "        [-1.6073,  1.7372, -0.1742],\n",
            "        [-1.8234,  1.4073,  0.0721],\n",
            "        [-1.8748,  1.2589,  0.2262],\n",
            "        [-1.5140,  1.9485, -0.1832],\n",
            "        [-1.8572,  1.1929,  0.5277],\n",
            "        [-1.9547,  1.0560,  0.4281]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8969,  0.2397,  1.0902],\n",
            "        [-0.1880,  0.9118, -0.9832],\n",
            "        [-2.0599,  0.2623,  1.3519],\n",
            "        [-1.4655,  1.8053, -0.4308],\n",
            "        [-2.0229,  0.8996,  0.8102],\n",
            "        [-1.5829,  1.8561, -0.2814],\n",
            "        [-1.2304,  1.8818, -0.4453],\n",
            "        [-1.7999,  1.6950, -0.2052],\n",
            "        [ 0.2999,  0.1976, -0.7324],\n",
            "        [-1.2648,  1.6260, -0.4516],\n",
            "        [-1.7086,  0.7986,  0.5704],\n",
            "        [-1.4620,  1.8107, -0.3460],\n",
            "        [-1.9785,  0.1820,  1.0779],\n",
            "        [-1.7401,  0.5852,  0.8561],\n",
            "        [-1.3896,  1.4953, -0.5455],\n",
            "        [-1.9561,  1.2152,  0.2842]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8969,  0.2397,  1.0902],\n",
            "        [-0.1880,  0.9118, -0.9832],\n",
            "        [-2.0599,  0.2623,  1.3519],\n",
            "        [-1.4655,  1.8053, -0.4308],\n",
            "        [-2.0229,  0.8996,  0.8102],\n",
            "        [-1.5829,  1.8561, -0.2814],\n",
            "        [-1.2304,  1.8818, -0.4453],\n",
            "        [-1.7999,  1.6950, -0.2052],\n",
            "        [ 0.2999,  0.1976, -0.7324],\n",
            "        [-1.2648,  1.6260, -0.4516],\n",
            "        [-1.7086,  0.7986,  0.5704],\n",
            "        [-1.4620,  1.8107, -0.3460],\n",
            "        [-1.9785,  0.1820,  1.0779],\n",
            "        [-1.7401,  0.5852,  0.8561],\n",
            "        [-1.3896,  1.4953, -0.5455],\n",
            "        [-1.9561,  1.2152,  0.2842]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7141,  1.8761, -0.5925],\n",
            "        [-1.5706,  1.1415,  0.3156],\n",
            "        [-1.4402,  1.4088, -0.3472],\n",
            "        [-1.4057,  1.0404,  0.1290],\n",
            "        [-1.6380,  1.5460, -0.1893],\n",
            "        [-1.9334,  1.8076, -0.1668],\n",
            "        [-1.9521,  0.3418,  1.0511],\n",
            "        [-1.4147,  1.7655, -0.3826],\n",
            "        [-1.5983,  1.2245,  0.1235],\n",
            "        [-1.2994,  1.5697, -0.5744],\n",
            "        [-1.6341,  1.9706, -0.4236],\n",
            "        [-1.3460,  1.7099, -0.7192],\n",
            "        [-1.8432, -0.0081,  1.1590],\n",
            "        [-1.0330, -0.1063,  0.4977],\n",
            "        [-1.2093,  1.5753, -0.7494],\n",
            "        [-1.7473,  0.0451,  1.3275]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7141,  1.8761, -0.5925],\n",
            "        [-1.5706,  1.1415,  0.3156],\n",
            "        [-1.4402,  1.4088, -0.3472],\n",
            "        [-1.4057,  1.0404,  0.1290],\n",
            "        [-1.6380,  1.5460, -0.1893],\n",
            "        [-1.9334,  1.8076, -0.1668],\n",
            "        [-1.9521,  0.3418,  1.0511],\n",
            "        [-1.4147,  1.7655, -0.3826],\n",
            "        [-1.5983,  1.2245,  0.1235],\n",
            "        [-1.2994,  1.5697, -0.5744],\n",
            "        [-1.6341,  1.9706, -0.4236],\n",
            "        [-1.3460,  1.7099, -0.7192],\n",
            "        [-1.8432, -0.0081,  1.1590],\n",
            "        [-1.0330, -0.1063,  0.4977],\n",
            "        [-1.2093,  1.5753, -0.7494],\n",
            "        [-1.7473,  0.0451,  1.3275]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8880,  0.5797,  1.0462],\n",
            "        [-1.1565,  1.7072, -0.6239],\n",
            "        [-0.4670,  0.3878, -0.2553],\n",
            "        [-1.1267,  0.0882,  0.5977],\n",
            "        [-1.4539,  1.6303, -0.2260],\n",
            "        [-1.4307,  1.8323, -0.6772],\n",
            "        [-1.6197,  1.7431, -0.5176],\n",
            "        [ 0.3151,  0.0745, -0.8056],\n",
            "        [-1.7548,  1.7354, -0.3265],\n",
            "        [-1.6265,  1.9403, -0.5851],\n",
            "        [-1.3482,  1.4719, -0.4669],\n",
            "        [-1.6000,  1.8708, -0.3454],\n",
            "        [-1.2566,  1.5660, -0.6674],\n",
            "        [-1.5996,  1.3574,  0.0147],\n",
            "        [-1.4978,  0.5757,  0.3773],\n",
            "        [-1.7697,  0.0973,  1.1830]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8880,  0.5797,  1.0462],\n",
            "        [-1.1565,  1.7072, -0.6239],\n",
            "        [-0.4670,  0.3878, -0.2553],\n",
            "        [-1.1267,  0.0882,  0.5977],\n",
            "        [-1.4539,  1.6303, -0.2260],\n",
            "        [-1.4307,  1.8323, -0.6772],\n",
            "        [-1.6197,  1.7431, -0.5176],\n",
            "        [ 0.3151,  0.0745, -0.8056],\n",
            "        [-1.7548,  1.7354, -0.3265],\n",
            "        [-1.6265,  1.9403, -0.5851],\n",
            "        [-1.3482,  1.4719, -0.4669],\n",
            "        [-1.6000,  1.8708, -0.3454],\n",
            "        [-1.2566,  1.5660, -0.6674],\n",
            "        [-1.5996,  1.3574,  0.0147],\n",
            "        [-1.4978,  0.5757,  0.3773],\n",
            "        [-1.7697,  0.0973,  1.1830]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2173,  1.6854, -0.7218],\n",
            "        [-1.4920,  1.7671, -0.6350],\n",
            "        [ 0.3513,  0.0959, -1.0022],\n",
            "        [-1.3255,  1.8228, -0.3550],\n",
            "        [ 0.2836,  0.1714, -0.8218],\n",
            "        [-0.1668,  0.5345, -0.8727],\n",
            "        [-1.8353,  2.0175, -0.5865],\n",
            "        [ 0.2520,  0.0674, -0.7655],\n",
            "        [-1.4565,  1.9292, -0.4260],\n",
            "        [-1.6304,  0.4388,  1.0338],\n",
            "        [-1.3879,  0.9916, -0.0966],\n",
            "        [-0.1588,  0.6567, -0.7677],\n",
            "        [-1.2565,  1.5755, -0.5490],\n",
            "        [-1.2649,  1.6284, -0.5473],\n",
            "        [-1.4908,  1.8048, -0.7164],\n",
            "        [-1.7832,  2.1890, -0.4949]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2173,  1.6854, -0.7218],\n",
            "        [-1.4920,  1.7671, -0.6350],\n",
            "        [ 0.3513,  0.0959, -1.0022],\n",
            "        [-1.3255,  1.8228, -0.3550],\n",
            "        [ 0.2836,  0.1714, -0.8218],\n",
            "        [-0.1668,  0.5345, -0.8727],\n",
            "        [-1.8353,  2.0175, -0.5865],\n",
            "        [ 0.2520,  0.0674, -0.7655],\n",
            "        [-1.4565,  1.9292, -0.4260],\n",
            "        [-1.6304,  0.4388,  1.0338],\n",
            "        [-1.3879,  0.9916, -0.0966],\n",
            "        [-0.1588,  0.6567, -0.7677],\n",
            "        [-1.2565,  1.5755, -0.5490],\n",
            "        [-1.2649,  1.6284, -0.5473],\n",
            "        [-1.4908,  1.8048, -0.7164],\n",
            "        [-1.7832,  2.1890, -0.4949]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4473, -0.0038,  0.9192],\n",
            "        [-0.5547,  0.6509, -0.4672],\n",
            "        [-0.9378,  1.2056, -0.4954],\n",
            "        [-1.2899,  0.1189,  0.8748],\n",
            "        [-1.6029,  2.0654, -0.5146],\n",
            "        [-1.5999,  1.8809, -0.5239],\n",
            "        [-1.4438,  1.9209, -0.3122],\n",
            "        [-1.0144,  1.3347, -0.6797],\n",
            "        [-1.8773,  2.1005, -0.4372],\n",
            "        [-1.6271,  0.4022,  0.7778],\n",
            "        [-2.0181,  1.4072,  0.1399],\n",
            "        [-1.7730,  1.0972, -0.0378],\n",
            "        [ 0.0349,  0.2952, -0.8624],\n",
            "        [-1.3738,  1.7125, -0.5301],\n",
            "        [-1.4603,  1.9760, -0.3511],\n",
            "        [-0.9744,  1.4929, -0.7590]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4473, -0.0038,  0.9192],\n",
            "        [-0.5547,  0.6509, -0.4672],\n",
            "        [-0.9378,  1.2056, -0.4954],\n",
            "        [-1.2899,  0.1189,  0.8748],\n",
            "        [-1.6029,  2.0654, -0.5146],\n",
            "        [-1.5999,  1.8809, -0.5239],\n",
            "        [-1.4438,  1.9209, -0.3122],\n",
            "        [-1.0144,  1.3347, -0.6797],\n",
            "        [-1.8773,  2.1005, -0.4372],\n",
            "        [-1.6271,  0.4022,  0.7778],\n",
            "        [-2.0181,  1.4072,  0.1399],\n",
            "        [-1.7730,  1.0972, -0.0378],\n",
            "        [ 0.0349,  0.2952, -0.8624],\n",
            "        [-1.3738,  1.7125, -0.5301],\n",
            "        [-1.4603,  1.9760, -0.3511],\n",
            "        [-0.9744,  1.4929, -0.7590]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.5201,  0.3785, -0.4718],\n",
            "        [-1.2962,  1.5986, -0.4343],\n",
            "        [ 0.1818,  0.0055, -0.8860],\n",
            "        [-1.7050,  1.6695, -0.2703],\n",
            "        [-1.4208, -0.1215,  0.9247],\n",
            "        [ 0.4385, -0.0335, -0.8810],\n",
            "        [-1.5586,  1.7617, -0.3256],\n",
            "        [-1.7066,  1.6914, -0.5316],\n",
            "        [-2.0845,  1.0420,  0.6715],\n",
            "        [-1.4831,  1.0806,  0.2099],\n",
            "        [-1.4429,  1.7936, -0.5431],\n",
            "        [-1.8366,  0.5299,  0.7811],\n",
            "        [-1.4471,  1.6804, -0.4279],\n",
            "        [-1.3845,  0.1014,  0.7955],\n",
            "        [ 0.0970,  0.3794, -0.7938],\n",
            "        [-1.9072,  0.6539,  0.8181]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-0.5201,  0.3785, -0.4718],\n",
            "        [-1.2962,  1.5986, -0.4343],\n",
            "        [ 0.1818,  0.0055, -0.8860],\n",
            "        [-1.7050,  1.6695, -0.2703],\n",
            "        [-1.4208, -0.1215,  0.9247],\n",
            "        [ 0.4385, -0.0335, -0.8810],\n",
            "        [-1.5586,  1.7617, -0.3256],\n",
            "        [-1.7066,  1.6914, -0.5316],\n",
            "        [-2.0845,  1.0420,  0.6715],\n",
            "        [-1.4831,  1.0806,  0.2099],\n",
            "        [-1.4429,  1.7936, -0.5431],\n",
            "        [-1.8366,  0.5299,  0.7811],\n",
            "        [-1.4471,  1.6804, -0.4279],\n",
            "        [-1.3845,  0.1014,  0.7955],\n",
            "        [ 0.0970,  0.3794, -0.7938],\n",
            "        [-1.9072,  0.6539,  0.8181]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5584,  1.7904, -0.3210],\n",
            "        [-1.4272,  1.7838, -0.5500],\n",
            "        [-1.5076,  1.7006, -0.5693],\n",
            "        [-1.3787,  0.1077,  0.8029],\n",
            "        [-1.9888,  0.7693,  1.0535],\n",
            "        [-1.3906,  1.8703, -0.3374],\n",
            "        [-1.3968, -0.0687,  0.7893],\n",
            "        [-1.1569,  1.5628, -0.7887],\n",
            "        [-1.4318,  0.1253,  0.9321],\n",
            "        [-1.2737,  1.6697, -0.6392],\n",
            "        [-1.7873,  0.2935,  0.9819],\n",
            "        [-1.4592,  0.1470,  0.8396],\n",
            "        [-1.4940,  1.8155, -0.5937],\n",
            "        [-1.0518,  0.8756, -0.1353],\n",
            "        [-1.8676,  0.1120,  1.1754],\n",
            "        [-1.4071,  0.0181,  0.8922]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5584,  1.7904, -0.3210],\n",
            "        [-1.4272,  1.7838, -0.5500],\n",
            "        [-1.5076,  1.7006, -0.5693],\n",
            "        [-1.3787,  0.1077,  0.8029],\n",
            "        [-1.9888,  0.7693,  1.0535],\n",
            "        [-1.3906,  1.8703, -0.3374],\n",
            "        [-1.3968, -0.0687,  0.7893],\n",
            "        [-1.1569,  1.5628, -0.7887],\n",
            "        [-1.4318,  0.1253,  0.9321],\n",
            "        [-1.2737,  1.6697, -0.6392],\n",
            "        [-1.7873,  0.2935,  0.9819],\n",
            "        [-1.4592,  0.1470,  0.8396],\n",
            "        [-1.4940,  1.8155, -0.5937],\n",
            "        [-1.0518,  0.8756, -0.1353],\n",
            "        [-1.8676,  0.1120,  1.1754],\n",
            "        [-1.4071,  0.0181,  0.8922]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4765,  1.8344, -0.4541],\n",
            "        [ 0.3183, -0.0887, -0.8284],\n",
            "        [-1.8266,  1.2304,  0.1374],\n",
            "        [-1.7662,  1.7618, -0.3422],\n",
            "        [-1.7449,  1.4021, -0.0907],\n",
            "        [-1.5072,  1.8590, -0.5322],\n",
            "        [-1.1289,  1.5206, -0.5161],\n",
            "        [-1.6403,  1.6249, -0.2184],\n",
            "        [-1.9604,  1.4893,  0.2569],\n",
            "        [-1.4178,  1.5459, -0.4688],\n",
            "        [-1.8111,  0.9545,  0.6346],\n",
            "        [-1.7611,  1.3625, -0.0725],\n",
            "        [-2.0322,  0.4491,  0.9949],\n",
            "        [-2.1114,  1.0166,  0.5607],\n",
            "        [-1.8647,  0.4941,  0.8324],\n",
            "        [-1.8858,  1.6332, -0.0103]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4765,  1.8344, -0.4541],\n",
            "        [ 0.3183, -0.0887, -0.8284],\n",
            "        [-1.8266,  1.2304,  0.1374],\n",
            "        [-1.7662,  1.7618, -0.3422],\n",
            "        [-1.7449,  1.4021, -0.0907],\n",
            "        [-1.5072,  1.8590, -0.5322],\n",
            "        [-1.1289,  1.5206, -0.5161],\n",
            "        [-1.6403,  1.6249, -0.2184],\n",
            "        [-1.9604,  1.4893,  0.2569],\n",
            "        [-1.4178,  1.5459, -0.4688],\n",
            "        [-1.8111,  0.9545,  0.6346],\n",
            "        [-1.7611,  1.3625, -0.0725],\n",
            "        [-2.0322,  0.4491,  0.9949],\n",
            "        [-2.1114,  1.0166,  0.5607],\n",
            "        [-1.8647,  0.4941,  0.8324],\n",
            "        [-1.8858,  1.6332, -0.0103]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1501,  0.8308,  0.9894],\n",
            "        [ 0.0816,  0.1146, -0.6804],\n",
            "        [-1.6468,  1.6523, -0.3956],\n",
            "        [-0.4358,  0.7952, -0.9513],\n",
            "        [-2.0343,  1.9148, -0.0294],\n",
            "        [ 0.3067,  0.1947, -0.8112],\n",
            "        [-1.4048,  0.1876,  1.1138],\n",
            "        [ 0.1607,  0.0883, -0.8433],\n",
            "        [-1.3767,  1.6757, -0.4643],\n",
            "        [-0.8140,  0.0965,  0.2266],\n",
            "        [-1.9513,  1.8642, -0.2587],\n",
            "        [-1.9456,  2.1230, -0.2895],\n",
            "        [-0.9125,  0.7586, -0.1862],\n",
            "        [ 0.4059, -0.1091, -0.9392],\n",
            "        [-1.7820,  1.4136, -0.0967],\n",
            "        [-1.4014,  1.6458, -0.4302]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1501,  0.8308,  0.9894],\n",
            "        [ 0.0816,  0.1146, -0.6804],\n",
            "        [-1.6468,  1.6523, -0.3956],\n",
            "        [-0.4358,  0.7952, -0.9513],\n",
            "        [-2.0343,  1.9148, -0.0294],\n",
            "        [ 0.3067,  0.1947, -0.8112],\n",
            "        [-1.4048,  0.1876,  1.1138],\n",
            "        [ 0.1607,  0.0883, -0.8433],\n",
            "        [-1.3767,  1.6757, -0.4643],\n",
            "        [-0.8140,  0.0965,  0.2266],\n",
            "        [-1.9513,  1.8642, -0.2587],\n",
            "        [-1.9456,  2.1230, -0.2895],\n",
            "        [-0.9125,  0.7586, -0.1862],\n",
            "        [ 0.4059, -0.1091, -0.9392],\n",
            "        [-1.7820,  1.4136, -0.0967],\n",
            "        [-1.4014,  1.6458, -0.4302]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1397e+00,  1.5334e+00,  3.6656e-01],\n",
            "        [-1.5806e+00,  9.4443e-02,  9.5022e-01],\n",
            "        [-1.7965e+00,  8.3183e-02,  1.2819e+00],\n",
            "        [-2.0434e+00,  7.9573e-01,  5.5927e-01],\n",
            "        [-1.5749e+00,  3.6432e-01,  8.8442e-01],\n",
            "        [ 1.9667e-01,  7.3335e-02, -9.4493e-01],\n",
            "        [-1.5946e+00,  1.5603e+00, -2.0114e-01],\n",
            "        [-1.0464e+00,  1.0204e+00, -4.5841e-01],\n",
            "        [-1.4966e+00,  1.7984e+00, -5.4026e-01],\n",
            "        [-1.3123e+00,  1.1718e+00, -3.4633e-01],\n",
            "        [-1.2636e+00,  2.3403e-01,  7.2084e-01],\n",
            "        [-1.6755e+00,  1.4961e+00, -1.3193e-01],\n",
            "        [-1.7290e+00,  1.1583e+00,  2.9804e-01],\n",
            "        [-2.0875e+00,  1.6509e+00, -1.1191e-03],\n",
            "        [-1.8971e+00,  1.7920e+00, -1.5188e-01],\n",
            "        [-1.7845e+00,  1.8361e+00, -1.5329e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1397e+00,  1.5334e+00,  3.6656e-01],\n",
            "        [-1.5806e+00,  9.4443e-02,  9.5022e-01],\n",
            "        [-1.7965e+00,  8.3183e-02,  1.2819e+00],\n",
            "        [-2.0434e+00,  7.9573e-01,  5.5927e-01],\n",
            "        [-1.5749e+00,  3.6432e-01,  8.8442e-01],\n",
            "        [ 1.9667e-01,  7.3335e-02, -9.4493e-01],\n",
            "        [-1.5946e+00,  1.5603e+00, -2.0114e-01],\n",
            "        [-1.0464e+00,  1.0204e+00, -4.5841e-01],\n",
            "        [-1.4966e+00,  1.7984e+00, -5.4026e-01],\n",
            "        [-1.3123e+00,  1.1718e+00, -3.4633e-01],\n",
            "        [-1.2636e+00,  2.3403e-01,  7.2084e-01],\n",
            "        [-1.6755e+00,  1.4961e+00, -1.3193e-01],\n",
            "        [-1.7290e+00,  1.1583e+00,  2.9804e-01],\n",
            "        [-2.0875e+00,  1.6509e+00, -1.1191e-03],\n",
            "        [-1.8971e+00,  1.7920e+00, -1.5188e-01],\n",
            "        [-1.7845e+00,  1.8361e+00, -1.5329e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2680,  1.2873, -0.0575],\n",
            "        [-1.6775,  0.3889,  1.0493],\n",
            "        [-1.8963,  0.4460,  0.9678],\n",
            "        [-1.9677,  1.5980,  0.0842],\n",
            "        [-2.0162,  0.4283,  1.1752],\n",
            "        [-1.4565,  0.0893,  0.9317],\n",
            "        [ 0.3339,  0.0505, -0.7772],\n",
            "        [-1.6001,  1.7563, -0.3555],\n",
            "        [-1.7633,  0.2872,  1.1554],\n",
            "        [-1.5450,  1.7104, -0.0072],\n",
            "        [-0.0197,  0.4424, -0.9216],\n",
            "        [-2.0893,  1.3294,  0.4043],\n",
            "        [-2.1290,  1.9618, -0.2788],\n",
            "        [-1.8640,  1.6078, -0.0457],\n",
            "        [-2.0188,  0.9139,  0.6380],\n",
            "        [-1.7744,  0.3510,  0.9486]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2680,  1.2873, -0.0575],\n",
            "        [-1.6775,  0.3889,  1.0493],\n",
            "        [-1.8963,  0.4460,  0.9678],\n",
            "        [-1.9677,  1.5980,  0.0842],\n",
            "        [-2.0162,  0.4283,  1.1752],\n",
            "        [-1.4565,  0.0893,  0.9317],\n",
            "        [ 0.3339,  0.0505, -0.7772],\n",
            "        [-1.6001,  1.7563, -0.3555],\n",
            "        [-1.7633,  0.2872,  1.1554],\n",
            "        [-1.5450,  1.7104, -0.0072],\n",
            "        [-0.0197,  0.4424, -0.9216],\n",
            "        [-2.0893,  1.3294,  0.4043],\n",
            "        [-2.1290,  1.9618, -0.2788],\n",
            "        [-1.8640,  1.6078, -0.0457],\n",
            "        [-2.0188,  0.9139,  0.6380],\n",
            "        [-1.7744,  0.3510,  0.9486]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.0282,  1.3471, -0.5169],\n",
            "        [-1.8294,  1.8399, -0.2557],\n",
            "        [-1.5882,  0.1801,  0.9642],\n",
            "        [-1.8569,  1.8524, -0.2316],\n",
            "        [-1.9657,  1.8344, -0.2300],\n",
            "        [-2.4348,  0.9898,  1.0129],\n",
            "        [-1.9226,  1.7134,  0.1648],\n",
            "        [-1.9125,  2.0559, -0.4284],\n",
            "        [-0.2810,  0.6755, -0.7247],\n",
            "        [-1.8789,  0.3384,  1.1373],\n",
            "        [-1.7875,  0.3358,  1.2439],\n",
            "        [-1.9016,  1.8626,  0.0937],\n",
            "        [-1.0248,  1.2165, -0.5676],\n",
            "        [-1.7765,  1.6915, -0.3748],\n",
            "        [-1.7048,  1.9291, -0.3737],\n",
            "        [-1.5646,  1.2691, -0.1334]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.0282,  1.3471, -0.5169],\n",
            "        [-1.8294,  1.8399, -0.2557],\n",
            "        [-1.5882,  0.1801,  0.9642],\n",
            "        [-1.8569,  1.8524, -0.2316],\n",
            "        [-1.9657,  1.8344, -0.2300],\n",
            "        [-2.4348,  0.9898,  1.0129],\n",
            "        [-1.9226,  1.7134,  0.1648],\n",
            "        [-1.9125,  2.0559, -0.4284],\n",
            "        [-0.2810,  0.6755, -0.7247],\n",
            "        [-1.8789,  0.3384,  1.1373],\n",
            "        [-1.7875,  0.3358,  1.2439],\n",
            "        [-1.9016,  1.8626,  0.0937],\n",
            "        [-1.0248,  1.2165, -0.5676],\n",
            "        [-1.7765,  1.6915, -0.3748],\n",
            "        [-1.7048,  1.9291, -0.3737],\n",
            "        [-1.5646,  1.2691, -0.1334]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0195,  0.6617,  0.9426],\n",
            "        [-1.7519,  1.6056, -0.0421],\n",
            "        [-1.6624,  1.0689,  0.0477],\n",
            "        [-1.9956,  1.4005,  0.0821],\n",
            "        [-1.9263,  0.2883,  1.0516],\n",
            "        [ 0.2455,  0.0966, -0.9458],\n",
            "        [-1.8336,  1.8750, -0.0494],\n",
            "        [-1.9564,  0.5724,  1.0470],\n",
            "        [-2.1272,  1.2094,  0.3707],\n",
            "        [-2.1567,  1.7640, -0.0174],\n",
            "        [-1.3445,  1.4774, -0.5061],\n",
            "        [-1.7895,  1.7644, -0.0460],\n",
            "        [-1.3003,  1.2155, -0.3857],\n",
            "        [ 0.0726,  0.4491, -1.0450],\n",
            "        [-1.5117,  1.4972, -0.1928],\n",
            "        [ 0.0702,  0.4610, -0.8497]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0195,  0.6617,  0.9426],\n",
            "        [-1.7519,  1.6056, -0.0421],\n",
            "        [-1.6624,  1.0689,  0.0477],\n",
            "        [-1.9956,  1.4005,  0.0821],\n",
            "        [-1.9263,  0.2883,  1.0516],\n",
            "        [ 0.2455,  0.0966, -0.9458],\n",
            "        [-1.8336,  1.8750, -0.0494],\n",
            "        [-1.9564,  0.5724,  1.0470],\n",
            "        [-2.1272,  1.2094,  0.3707],\n",
            "        [-2.1567,  1.7640, -0.0174],\n",
            "        [-1.3445,  1.4774, -0.5061],\n",
            "        [-1.7895,  1.7644, -0.0460],\n",
            "        [-1.3003,  1.2155, -0.3857],\n",
            "        [ 0.0726,  0.4491, -1.0450],\n",
            "        [-1.5117,  1.4972, -0.1928],\n",
            "        [ 0.0702,  0.4610, -0.8497]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9680,  1.0076,  0.7110],\n",
            "        [-2.0108,  1.7003,  0.1266],\n",
            "        [-2.1008,  0.5764,  1.2419],\n",
            "        [-0.1937,  0.4258, -0.6580],\n",
            "        [-1.4765,  1.4540, -0.2391],\n",
            "        [-1.6448,  1.4945, -0.0344],\n",
            "        [-2.0368,  0.3880,  0.9560],\n",
            "        [-1.8123,  1.7368,  0.0339],\n",
            "        [-2.0459,  1.7589, -0.0740],\n",
            "        [-1.8791,  1.6231, -0.0909],\n",
            "        [-1.6988,  1.9049, -0.2524],\n",
            "        [-1.7572,  1.3740,  0.0399],\n",
            "        [-1.8872,  1.6421, -0.0355],\n",
            "        [-2.2634,  1.2957,  0.3201],\n",
            "        [-1.9051,  1.9290,  0.0443],\n",
            "        [-1.9209,  0.5007,  1.1036]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9680,  1.0076,  0.7110],\n",
            "        [-2.0108,  1.7003,  0.1266],\n",
            "        [-2.1008,  0.5764,  1.2419],\n",
            "        [-0.1937,  0.4258, -0.6580],\n",
            "        [-1.4765,  1.4540, -0.2391],\n",
            "        [-1.6448,  1.4945, -0.0344],\n",
            "        [-2.0368,  0.3880,  0.9560],\n",
            "        [-1.8123,  1.7368,  0.0339],\n",
            "        [-2.0459,  1.7589, -0.0740],\n",
            "        [-1.8791,  1.6231, -0.0909],\n",
            "        [-1.6988,  1.9049, -0.2524],\n",
            "        [-1.7572,  1.3740,  0.0399],\n",
            "        [-1.8872,  1.6421, -0.0355],\n",
            "        [-2.2634,  1.2957,  0.3201],\n",
            "        [-1.9051,  1.9290,  0.0443],\n",
            "        [-1.9209,  0.5007,  1.1036]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6825,  1.5395, -0.0678],\n",
            "        [-2.2996,  1.4369,  0.2242],\n",
            "        [-1.8487,  1.2347,  0.5672],\n",
            "        [ 0.3789, -0.0330, -0.9931],\n",
            "        [-1.6918,  1.8080, -0.1860],\n",
            "        [-1.8046,  1.5112, -0.2935],\n",
            "        [-1.6130,  1.0512,  0.3293],\n",
            "        [-2.1008,  1.3963,  0.3071],\n",
            "        [ 0.2869,  0.1972, -0.8933],\n",
            "        [-2.0431,  1.1523,  0.5678],\n",
            "        [-2.1712,  1.0084,  0.9933],\n",
            "        [-1.9742,  0.5090,  0.9714],\n",
            "        [-2.0596,  1.2941,  0.5765],\n",
            "        [-1.5263,  1.0797,  0.0525],\n",
            "        [-1.8429,  1.3291,  0.0243],\n",
            "        [-0.8968,  1.0144, -0.6456]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6825,  1.5395, -0.0678],\n",
            "        [-2.2996,  1.4369,  0.2242],\n",
            "        [-1.8487,  1.2347,  0.5672],\n",
            "        [ 0.3789, -0.0330, -0.9931],\n",
            "        [-1.6918,  1.8080, -0.1860],\n",
            "        [-1.8046,  1.5112, -0.2935],\n",
            "        [-1.6130,  1.0512,  0.3293],\n",
            "        [-2.1008,  1.3963,  0.3071],\n",
            "        [ 0.2869,  0.1972, -0.8933],\n",
            "        [-2.0431,  1.1523,  0.5678],\n",
            "        [-2.1712,  1.0084,  0.9933],\n",
            "        [-1.9742,  0.5090,  0.9714],\n",
            "        [-2.0596,  1.2941,  0.5765],\n",
            "        [-1.5263,  1.0797,  0.0525],\n",
            "        [-1.8429,  1.3291,  0.0243],\n",
            "        [-0.8968,  1.0144, -0.6456]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2506,  1.3120,  0.4991],\n",
            "        [-1.9895,  1.1160,  0.2085],\n",
            "        [-1.6726,  0.4690,  0.8600],\n",
            "        [-2.0388,  1.2898,  0.5152],\n",
            "        [-1.9939,  1.3771,  0.2646],\n",
            "        [-1.5869,  1.5342, -0.3130],\n",
            "        [-1.8967,  0.1897,  1.1269],\n",
            "        [-1.7729,  0.2877,  1.0380],\n",
            "        [-1.7016,  0.3462,  1.0169],\n",
            "        [-1.7091,  1.6189,  0.0821],\n",
            "        [ 0.4552,  0.2810, -1.1331],\n",
            "        [-2.1216,  1.3714,  0.1336],\n",
            "        [-1.4630,  1.4112, -0.1254],\n",
            "        [ 0.4686, -0.0261, -0.8961],\n",
            "        [-1.8095,  1.6762, -0.0553],\n",
            "        [-2.0339,  0.8945,  0.9589]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.2506,  1.3120,  0.4991],\n",
            "        [-1.9895,  1.1160,  0.2085],\n",
            "        [-1.6726,  0.4690,  0.8600],\n",
            "        [-2.0388,  1.2898,  0.5152],\n",
            "        [-1.9939,  1.3771,  0.2646],\n",
            "        [-1.5869,  1.5342, -0.3130],\n",
            "        [-1.8967,  0.1897,  1.1269],\n",
            "        [-1.7729,  0.2877,  1.0380],\n",
            "        [-1.7016,  0.3462,  1.0169],\n",
            "        [-1.7091,  1.6189,  0.0821],\n",
            "        [ 0.4552,  0.2810, -1.1331],\n",
            "        [-2.1216,  1.3714,  0.1336],\n",
            "        [-1.4630,  1.4112, -0.1254],\n",
            "        [ 0.4686, -0.0261, -0.8961],\n",
            "        [-1.8095,  1.6762, -0.0553],\n",
            "        [-2.0339,  0.8945,  0.9589]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5531,  1.7348, -0.3591],\n",
            "        [ 0.3054, -0.0077, -0.9494],\n",
            "        [-0.2666,  0.6412, -0.8432],\n",
            "        [-1.7674,  1.4206, -0.1860],\n",
            "        [-2.0025,  1.1007,  0.6408],\n",
            "        [-2.0228,  0.4424,  1.0205],\n",
            "        [-1.7104,  1.7505, -0.1631],\n",
            "        [-1.8808,  1.6186, -0.0944],\n",
            "        [ 0.3867, -0.1134, -0.9485],\n",
            "        [-2.1851,  1.0836,  0.6771],\n",
            "        [-1.9213,  0.5509,  0.9053],\n",
            "        [-0.0534,  0.3766, -0.8946],\n",
            "        [-1.8776,  1.5840, -0.1584],\n",
            "        [ 0.0284,  0.2467, -0.9474],\n",
            "        [ 0.3481,  0.0124, -0.7146],\n",
            "        [-1.8992,  0.9368,  0.4645]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5531,  1.7348, -0.3591],\n",
            "        [ 0.3054, -0.0077, -0.9494],\n",
            "        [-0.2666,  0.6412, -0.8432],\n",
            "        [-1.7674,  1.4206, -0.1860],\n",
            "        [-2.0025,  1.1007,  0.6408],\n",
            "        [-2.0228,  0.4424,  1.0205],\n",
            "        [-1.7104,  1.7505, -0.1631],\n",
            "        [-1.8808,  1.6186, -0.0944],\n",
            "        [ 0.3867, -0.1134, -0.9485],\n",
            "        [-2.1851,  1.0836,  0.6771],\n",
            "        [-1.9213,  0.5509,  0.9053],\n",
            "        [-0.0534,  0.3766, -0.8946],\n",
            "        [-1.8776,  1.5840, -0.1584],\n",
            "        [ 0.0284,  0.2467, -0.9474],\n",
            "        [ 0.3481,  0.0124, -0.7146],\n",
            "        [-1.8992,  0.9368,  0.4645]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6481,  1.6352, -0.2957],\n",
            "        [-1.9631,  1.4994,  0.2981],\n",
            "        [-1.5491,  1.1086,  0.2300],\n",
            "        [-1.8973,  1.5566, -0.0588],\n",
            "        [-1.7790,  1.5539,  0.1366],\n",
            "        [-0.9257,  1.0216, -0.4392],\n",
            "        [-1.9018,  1.4440,  0.2721],\n",
            "        [-1.6586,  0.3714,  1.0444],\n",
            "        [-1.6601,  1.7457, -0.2582],\n",
            "        [ 0.4393, -0.0611, -0.9682],\n",
            "        [-1.9924,  1.4067,  0.1905],\n",
            "        [-1.5189,  1.5694, -0.3049],\n",
            "        [-1.8023,  1.5746, -0.2943],\n",
            "        [-1.8835,  1.3636, -0.0769],\n",
            "        [-2.1459,  1.1378,  0.4839],\n",
            "        [-2.1272,  1.4915,  0.2959]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6481,  1.6352, -0.2957],\n",
            "        [-1.9631,  1.4994,  0.2981],\n",
            "        [-1.5491,  1.1086,  0.2300],\n",
            "        [-1.8973,  1.5566, -0.0588],\n",
            "        [-1.7790,  1.5539,  0.1366],\n",
            "        [-0.9257,  1.0216, -0.4392],\n",
            "        [-1.9018,  1.4440,  0.2721],\n",
            "        [-1.6586,  0.3714,  1.0444],\n",
            "        [-1.6601,  1.7457, -0.2582],\n",
            "        [ 0.4393, -0.0611, -0.9682],\n",
            "        [-1.9924,  1.4067,  0.1905],\n",
            "        [-1.5189,  1.5694, -0.3049],\n",
            "        [-1.8023,  1.5746, -0.2943],\n",
            "        [-1.8835,  1.3636, -0.0769],\n",
            "        [-2.1459,  1.1378,  0.4839],\n",
            "        [-2.1272,  1.4915,  0.2959]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7030,  1.5949, -0.2490],\n",
            "        [-1.7295,  1.8265, -0.1417],\n",
            "        [-1.9773,  1.2351,  0.4184],\n",
            "        [-1.5281,  0.5793,  0.5152],\n",
            "        [-2.2141,  0.9186,  0.8656],\n",
            "        [ 0.3650,  0.0457, -1.0428],\n",
            "        [-1.4780,  1.2289, -0.1320],\n",
            "        [-1.4170,  1.7169, -0.2941],\n",
            "        [-1.6790,  1.5279, -0.1742],\n",
            "        [ 0.4215,  0.1363, -0.8381],\n",
            "        [ 0.5759, -0.0372, -1.1097],\n",
            "        [-2.1263,  0.6578,  0.7944],\n",
            "        [-2.3422,  1.6028,  0.2962],\n",
            "        [ 0.3367, -0.0103, -0.8541],\n",
            "        [-0.8324,  0.4251, -0.0777],\n",
            "        [-2.1144,  0.6001,  1.0192]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7030,  1.5949, -0.2490],\n",
            "        [-1.7295,  1.8265, -0.1417],\n",
            "        [-1.9773,  1.2351,  0.4184],\n",
            "        [-1.5281,  0.5793,  0.5152],\n",
            "        [-2.2141,  0.9186,  0.8656],\n",
            "        [ 0.3650,  0.0457, -1.0428],\n",
            "        [-1.4780,  1.2289, -0.1320],\n",
            "        [-1.4170,  1.7169, -0.2941],\n",
            "        [-1.6790,  1.5279, -0.1742],\n",
            "        [ 0.4215,  0.1363, -0.8381],\n",
            "        [ 0.5759, -0.0372, -1.1097],\n",
            "        [-2.1263,  0.6578,  0.7944],\n",
            "        [-2.3422,  1.6028,  0.2962],\n",
            "        [ 0.3367, -0.0103, -0.8541],\n",
            "        [-0.8324,  0.4251, -0.0777],\n",
            "        [-2.1144,  0.6001,  1.0192]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2026e+00,  7.8478e-01,  9.4017e-01],\n",
            "        [-1.9702e+00,  1.3964e+00,  2.3825e-01],\n",
            "        [ 1.3158e-01,  3.5358e-01, -9.5030e-01],\n",
            "        [-1.2767e-01,  4.6840e-01, -9.0016e-01],\n",
            "        [-2.2358e+00,  1.0165e+00,  7.1087e-01],\n",
            "        [ 3.4404e-01,  3.1044e-01, -1.0395e+00],\n",
            "        [-2.1681e+00,  1.6850e+00,  3.1116e-01],\n",
            "        [-1.8588e+00,  1.6093e+00,  2.8002e-02],\n",
            "        [-1.8152e+00,  1.4223e+00,  1.1178e-02],\n",
            "        [-1.8930e+00,  1.4321e+00,  2.2762e-03],\n",
            "        [-2.0251e+00,  1.2643e+00,  2.5583e-01],\n",
            "        [-1.9793e+00,  1.2001e+00,  6.0797e-01],\n",
            "        [-2.0379e+00,  1.4379e+00,  4.1150e-01],\n",
            "        [-1.8087e+00,  1.5697e+00,  8.6610e-02],\n",
            "        [-2.3313e+00,  1.6212e+00,  4.6631e-02],\n",
            "        [-1.8249e+00,  4.5793e-01,  9.8432e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.2026e+00,  7.8478e-01,  9.4017e-01],\n",
            "        [-1.9702e+00,  1.3964e+00,  2.3825e-01],\n",
            "        [ 1.3158e-01,  3.5358e-01, -9.5030e-01],\n",
            "        [-1.2767e-01,  4.6840e-01, -9.0016e-01],\n",
            "        [-2.2358e+00,  1.0165e+00,  7.1087e-01],\n",
            "        [ 3.4404e-01,  3.1044e-01, -1.0395e+00],\n",
            "        [-2.1681e+00,  1.6850e+00,  3.1116e-01],\n",
            "        [-1.8588e+00,  1.6093e+00,  2.8002e-02],\n",
            "        [-1.8152e+00,  1.4223e+00,  1.1178e-02],\n",
            "        [-1.8930e+00,  1.4321e+00,  2.2762e-03],\n",
            "        [-2.0251e+00,  1.2643e+00,  2.5583e-01],\n",
            "        [-1.9793e+00,  1.2001e+00,  6.0797e-01],\n",
            "        [-2.0379e+00,  1.4379e+00,  4.1150e-01],\n",
            "        [-1.8087e+00,  1.5697e+00,  8.6610e-02],\n",
            "        [-2.3313e+00,  1.6212e+00,  4.6631e-02],\n",
            "        [-1.8249e+00,  4.5793e-01,  9.8432e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.4124,  1.2846,  0.6857],\n",
            "        [-1.8028,  1.3500, -0.0758],\n",
            "        [-2.1848,  1.0047,  0.6597],\n",
            "        [-1.6880,  1.4142,  0.2404],\n",
            "        [-2.1074,  1.3313,  0.4990],\n",
            "        [-1.9188,  1.5059,  0.4770],\n",
            "        [-2.0976,  1.6097,  0.4881],\n",
            "        [-1.6169,  1.6240,  0.1039],\n",
            "        [-1.8440,  1.2097,  0.3961],\n",
            "        [-2.2177,  0.7754,  0.8486],\n",
            "        [-2.0818,  1.1875,  0.6408],\n",
            "        [-1.6801,  1.5328, -0.0654],\n",
            "        [-1.2698,  1.4023, -0.4753],\n",
            "        [-1.7524,  1.3702,  0.0542],\n",
            "        [-1.7128,  1.3559, -0.0474],\n",
            "        [-1.4300,  1.2955, -0.0620]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.4124,  1.2846,  0.6857],\n",
            "        [-1.8028,  1.3500, -0.0758],\n",
            "        [-2.1848,  1.0047,  0.6597],\n",
            "        [-1.6880,  1.4142,  0.2404],\n",
            "        [-2.1074,  1.3313,  0.4990],\n",
            "        [-1.9188,  1.5059,  0.4770],\n",
            "        [-2.0976,  1.6097,  0.4881],\n",
            "        [-1.6169,  1.6240,  0.1039],\n",
            "        [-1.8440,  1.2097,  0.3961],\n",
            "        [-2.2177,  0.7754,  0.8486],\n",
            "        [-2.0818,  1.1875,  0.6408],\n",
            "        [-1.6801,  1.5328, -0.0654],\n",
            "        [-1.2698,  1.4023, -0.4753],\n",
            "        [-1.7524,  1.3702,  0.0542],\n",
            "        [-1.7128,  1.3559, -0.0474],\n",
            "        [-1.4300,  1.2955, -0.0620]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7993,  1.4972,  0.0309],\n",
            "        [-2.2965,  1.1838,  0.6829],\n",
            "        [-0.4948,  0.8397, -0.6195],\n",
            "        [-2.0422,  0.7085,  1.0508],\n",
            "        [-0.3262,  0.4632, -0.4354],\n",
            "        [-2.4930,  1.3647,  0.6164],\n",
            "        [ 0.4091, -0.0455, -0.8811],\n",
            "        [-1.9165,  1.5976, -0.2146],\n",
            "        [-1.9766,  1.2294,  0.4164],\n",
            "        [ 0.0040,  0.4809, -0.7295],\n",
            "        [-2.0419,  1.2230,  0.5695],\n",
            "        [-1.8514,  1.3950, -0.1196],\n",
            "        [ 0.5184,  0.0813, -0.9102],\n",
            "        [-1.9056,  0.7753,  0.9141],\n",
            "        [-1.8222,  0.7731,  0.9787],\n",
            "        [-1.6657,  1.5609,  0.0198]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7993,  1.4972,  0.0309],\n",
            "        [-2.2965,  1.1838,  0.6829],\n",
            "        [-0.4948,  0.8397, -0.6195],\n",
            "        [-2.0422,  0.7085,  1.0508],\n",
            "        [-0.3262,  0.4632, -0.4354],\n",
            "        [-2.4930,  1.3647,  0.6164],\n",
            "        [ 0.4091, -0.0455, -0.8811],\n",
            "        [-1.9165,  1.5976, -0.2146],\n",
            "        [-1.9766,  1.2294,  0.4164],\n",
            "        [ 0.0040,  0.4809, -0.7295],\n",
            "        [-2.0419,  1.2230,  0.5695],\n",
            "        [-1.8514,  1.3950, -0.1196],\n",
            "        [ 0.5184,  0.0813, -0.9102],\n",
            "        [-1.9056,  0.7753,  0.9141],\n",
            "        [-1.8222,  0.7731,  0.9787],\n",
            "        [-1.6657,  1.5609,  0.0198]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3968,  1.2937, -0.1311],\n",
            "        [-2.0710,  1.0570,  0.4677],\n",
            "        [-1.4146,  1.3578, -0.1908],\n",
            "        [-1.8834,  0.6231,  0.8630],\n",
            "        [-1.5718,  1.1395, -0.1479],\n",
            "        [-2.0315,  1.6150,  0.2095],\n",
            "        [-1.7276,  0.2971,  0.9305],\n",
            "        [-1.8157,  1.5717,  0.0592],\n",
            "        [-1.2067,  1.6200, -0.2811],\n",
            "        [-1.2935,  0.7521,  0.2244],\n",
            "        [-1.5258,  1.3332, -0.1748],\n",
            "        [-1.6795,  1.2923,  0.2303],\n",
            "        [-2.2193,  0.9275,  1.0426],\n",
            "        [-0.8913,  1.1886, -0.8016],\n",
            "        [-1.7305,  1.3322,  0.1728],\n",
            "        [-1.5796,  0.7858,  0.2914]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3968,  1.2937, -0.1311],\n",
            "        [-2.0710,  1.0570,  0.4677],\n",
            "        [-1.4146,  1.3578, -0.1908],\n",
            "        [-1.8834,  0.6231,  0.8630],\n",
            "        [-1.5718,  1.1395, -0.1479],\n",
            "        [-2.0315,  1.6150,  0.2095],\n",
            "        [-1.7276,  0.2971,  0.9305],\n",
            "        [-1.8157,  1.5717,  0.0592],\n",
            "        [-1.2067,  1.6200, -0.2811],\n",
            "        [-1.2935,  0.7521,  0.2244],\n",
            "        [-1.5258,  1.3332, -0.1748],\n",
            "        [-1.6795,  1.2923,  0.2303],\n",
            "        [-2.2193,  0.9275,  1.0426],\n",
            "        [-0.8913,  1.1886, -0.8016],\n",
            "        [-1.7305,  1.3322,  0.1728],\n",
            "        [-1.5796,  0.7858,  0.2914]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.2949, -0.0353, -0.9060],\n",
            "        [-1.4809,  1.2609,  0.0080],\n",
            "        [-2.1235,  1.5603,  0.3231],\n",
            "        [-1.9352,  1.5274,  0.0348],\n",
            "        [-1.8600,  1.5229,  0.1648],\n",
            "        [-1.9876,  1.3464,  0.2469],\n",
            "        [-1.8078,  0.9841,  0.5350],\n",
            "        [-1.6115,  1.2840, -0.0586],\n",
            "        [-1.8178,  1.3468,  0.3814],\n",
            "        [ 0.2792,  0.1360, -0.9413],\n",
            "        [-1.9685,  0.5677,  1.1617],\n",
            "        [-2.0464,  0.9119,  0.7198],\n",
            "        [ 0.2926,  0.1165, -0.9106],\n",
            "        [-1.5272,  1.2775, -0.1740],\n",
            "        [-1.7108,  1.2761,  0.1806],\n",
            "        [-1.9620,  1.4867,  0.0507]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.2949, -0.0353, -0.9060],\n",
            "        [-1.4809,  1.2609,  0.0080],\n",
            "        [-2.1235,  1.5603,  0.3231],\n",
            "        [-1.9352,  1.5274,  0.0348],\n",
            "        [-1.8600,  1.5229,  0.1648],\n",
            "        [-1.9876,  1.3464,  0.2469],\n",
            "        [-1.8078,  0.9841,  0.5350],\n",
            "        [-1.6115,  1.2840, -0.0586],\n",
            "        [-1.8178,  1.3468,  0.3814],\n",
            "        [ 0.2792,  0.1360, -0.9413],\n",
            "        [-1.9685,  0.5677,  1.1617],\n",
            "        [-2.0464,  0.9119,  0.7198],\n",
            "        [ 0.2926,  0.1165, -0.9106],\n",
            "        [-1.5272,  1.2775, -0.1740],\n",
            "        [-1.7108,  1.2761,  0.1806],\n",
            "        [-1.9620,  1.4867,  0.0507]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.1328,  0.1523, -0.6214],\n",
            "        [-1.7005,  1.3099,  0.2880],\n",
            "        [-1.8501,  0.5710,  0.9457],\n",
            "        [-2.0052,  0.5493,  1.0234],\n",
            "        [-1.8300,  0.7927,  0.8858],\n",
            "        [-1.3701,  0.7549,  0.3592],\n",
            "        [-2.0148,  1.2070,  0.2099],\n",
            "        [-1.2903,  1.2003, -0.0716],\n",
            "        [-2.0446,  0.5562,  0.8467],\n",
            "        [-1.7712,  1.9766, -0.0951],\n",
            "        [ 0.2980,  0.2074, -0.9178],\n",
            "        [-2.0644,  1.5834,  0.1297],\n",
            "        [-2.0355,  1.5966,  0.1695],\n",
            "        [-2.0816,  1.1746,  0.3903],\n",
            "        [-1.7721,  1.3085,  0.0588],\n",
            "        [ 0.3750,  0.0516, -0.8968]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.1328,  0.1523, -0.6214],\n",
            "        [-1.7005,  1.3099,  0.2880],\n",
            "        [-1.8501,  0.5710,  0.9457],\n",
            "        [-2.0052,  0.5493,  1.0234],\n",
            "        [-1.8300,  0.7927,  0.8858],\n",
            "        [-1.3701,  0.7549,  0.3592],\n",
            "        [-2.0148,  1.2070,  0.2099],\n",
            "        [-1.2903,  1.2003, -0.0716],\n",
            "        [-2.0446,  0.5562,  0.8467],\n",
            "        [-1.7712,  1.9766, -0.0951],\n",
            "        [ 0.2980,  0.2074, -0.9178],\n",
            "        [-2.0644,  1.5834,  0.1297],\n",
            "        [-2.0355,  1.5966,  0.1695],\n",
            "        [-2.0816,  1.1746,  0.3903],\n",
            "        [-1.7721,  1.3085,  0.0588],\n",
            "        [ 0.3750,  0.0516, -0.8968]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1491e+00,  1.6023e+00,  1.3924e-01],\n",
            "        [-1.9703e+00,  1.2094e+00,  6.4100e-01],\n",
            "        [-1.4648e+00,  1.4833e+00, -9.2048e-03],\n",
            "        [-1.5037e+00,  1.4628e+00, -1.0687e-01],\n",
            "        [-1.7461e+00,  1.6036e+00,  3.2691e-01],\n",
            "        [-1.4136e+00,  1.4119e+00, -3.1461e-01],\n",
            "        [-1.8982e+00,  4.0869e-01,  9.6476e-01],\n",
            "        [-1.4748e+00,  1.4360e+00,  9.4396e-04],\n",
            "        [-1.8026e+00,  6.3234e-01,  1.1372e+00],\n",
            "        [-2.0506e+00,  9.6225e-01,  5.4069e-01],\n",
            "        [-1.2849e+00,  1.2566e+00, -2.4742e-01],\n",
            "        [-1.5317e+00,  1.7782e+00, -4.2399e-01],\n",
            "        [-1.4349e+00,  1.1619e+00, -6.1875e-02],\n",
            "        [-1.8628e+00,  1.4725e+00,  1.2070e-01],\n",
            "        [-1.9454e+00,  3.2478e-01,  9.1072e-01],\n",
            "        [-2.0558e+00,  1.3191e+00,  3.5409e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1491e+00,  1.6023e+00,  1.3924e-01],\n",
            "        [-1.9703e+00,  1.2094e+00,  6.4100e-01],\n",
            "        [-1.4648e+00,  1.4833e+00, -9.2048e-03],\n",
            "        [-1.5037e+00,  1.4628e+00, -1.0687e-01],\n",
            "        [-1.7461e+00,  1.6036e+00,  3.2691e-01],\n",
            "        [-1.4136e+00,  1.4119e+00, -3.1461e-01],\n",
            "        [-1.8982e+00,  4.0869e-01,  9.6476e-01],\n",
            "        [-1.4748e+00,  1.4360e+00,  9.4396e-04],\n",
            "        [-1.8026e+00,  6.3234e-01,  1.1372e+00],\n",
            "        [-2.0506e+00,  9.6225e-01,  5.4069e-01],\n",
            "        [-1.2849e+00,  1.2566e+00, -2.4742e-01],\n",
            "        [-1.5317e+00,  1.7782e+00, -4.2399e-01],\n",
            "        [-1.4349e+00,  1.1619e+00, -6.1875e-02],\n",
            "        [-1.8628e+00,  1.4725e+00,  1.2070e-01],\n",
            "        [-1.9454e+00,  3.2478e-01,  9.1072e-01],\n",
            "        [-2.0558e+00,  1.3191e+00,  3.5409e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5407,  1.0414,  0.1383],\n",
            "        [-2.0983,  1.4852,  0.2083],\n",
            "        [-1.9726,  1.5567,  0.1756],\n",
            "        [-1.5318,  1.2376, -0.0421],\n",
            "        [-1.7535,  1.3428,  0.2127],\n",
            "        [-1.7863,  1.5544,  0.0601],\n",
            "        [-2.0149,  0.7828,  0.7990],\n",
            "        [-1.8073,  1.5522, -0.0114],\n",
            "        [-1.6612,  1.4085,  0.1592],\n",
            "        [-1.7907,  1.3830,  0.0553],\n",
            "        [-1.4371,  1.2280, -0.1564],\n",
            "        [-1.7240,  0.7384,  0.7239],\n",
            "        [-1.6621,  1.4913, -0.2311],\n",
            "        [-1.4830,  1.2453, -0.2940],\n",
            "        [ 0.4539, -0.1449, -0.7420],\n",
            "        [-1.4559,  1.1877,  0.1413]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5407,  1.0414,  0.1383],\n",
            "        [-2.0983,  1.4852,  0.2083],\n",
            "        [-1.9726,  1.5567,  0.1756],\n",
            "        [-1.5318,  1.2376, -0.0421],\n",
            "        [-1.7535,  1.3428,  0.2127],\n",
            "        [-1.7863,  1.5544,  0.0601],\n",
            "        [-2.0149,  0.7828,  0.7990],\n",
            "        [-1.8073,  1.5522, -0.0114],\n",
            "        [-1.6612,  1.4085,  0.1592],\n",
            "        [-1.7907,  1.3830,  0.0553],\n",
            "        [-1.4371,  1.2280, -0.1564],\n",
            "        [-1.7240,  0.7384,  0.7239],\n",
            "        [-1.6621,  1.4913, -0.2311],\n",
            "        [-1.4830,  1.2453, -0.2940],\n",
            "        [ 0.4539, -0.1449, -0.7420],\n",
            "        [-1.4559,  1.1877,  0.1413]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9768,  0.4685,  1.0646],\n",
            "        [-1.8344,  1.3127,  0.0957],\n",
            "        [-1.7173,  1.3740, -0.0447],\n",
            "        [-1.0946,  1.2646, -0.2473],\n",
            "        [ 0.2397, -0.0587, -0.8147],\n",
            "        [-1.7795,  0.8479,  0.7190],\n",
            "        [-1.9804,  0.6084,  1.2400],\n",
            "        [-1.7694,  1.3991, -0.0653],\n",
            "        [-1.7685,  0.4952,  0.8929],\n",
            "        [-1.8329,  0.4614,  1.1261],\n",
            "        [-1.3426,  1.2483, -0.0406],\n",
            "        [-1.8782,  1.4180,  0.0205],\n",
            "        [-1.7436,  1.4271, -0.0123],\n",
            "        [-1.9834,  0.9168,  0.7730],\n",
            "        [-2.0323,  0.5325,  1.0357],\n",
            "        [-1.6242,  1.7057, -0.0417]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9768,  0.4685,  1.0646],\n",
            "        [-1.8344,  1.3127,  0.0957],\n",
            "        [-1.7173,  1.3740, -0.0447],\n",
            "        [-1.0946,  1.2646, -0.2473],\n",
            "        [ 0.2397, -0.0587, -0.8147],\n",
            "        [-1.7795,  0.8479,  0.7190],\n",
            "        [-1.9804,  0.6084,  1.2400],\n",
            "        [-1.7694,  1.3991, -0.0653],\n",
            "        [-1.7685,  0.4952,  0.8929],\n",
            "        [-1.8329,  0.4614,  1.1261],\n",
            "        [-1.3426,  1.2483, -0.0406],\n",
            "        [-1.8782,  1.4180,  0.0205],\n",
            "        [-1.7436,  1.4271, -0.0123],\n",
            "        [-1.9834,  0.9168,  0.7730],\n",
            "        [-2.0323,  0.5325,  1.0357],\n",
            "        [-1.6242,  1.7057, -0.0417]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1737,  0.5648,  1.1256],\n",
            "        [ 0.1421,  0.4352, -0.7538],\n",
            "        [-0.3496,  0.8832, -0.9682],\n",
            "        [-1.7526,  0.8965,  0.6240],\n",
            "        [-1.5874,  1.0301,  0.0455],\n",
            "        [-1.6969,  0.6895,  0.8503],\n",
            "        [-1.0139,  0.9557,  0.0159],\n",
            "        [-1.4640,  1.6553, -0.2845],\n",
            "        [ 0.3993,  0.0773, -0.7615],\n",
            "        [ 0.4883, -0.0489, -0.8049],\n",
            "        [-1.9863,  1.1868,  0.4008],\n",
            "        [-1.5445,  1.4678, -0.0084],\n",
            "        [-1.7052,  0.5622,  0.9239],\n",
            "        [-2.3387,  0.8512,  1.0229],\n",
            "        [-1.8207,  1.0305,  0.3225],\n",
            "        [-1.6242,  1.1162, -0.0694]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1737,  0.5648,  1.1256],\n",
            "        [ 0.1421,  0.4352, -0.7538],\n",
            "        [-0.3496,  0.8832, -0.9682],\n",
            "        [-1.7526,  0.8965,  0.6240],\n",
            "        [-1.5874,  1.0301,  0.0455],\n",
            "        [-1.6969,  0.6895,  0.8503],\n",
            "        [-1.0139,  0.9557,  0.0159],\n",
            "        [-1.4640,  1.6553, -0.2845],\n",
            "        [ 0.3993,  0.0773, -0.7615],\n",
            "        [ 0.4883, -0.0489, -0.8049],\n",
            "        [-1.9863,  1.1868,  0.4008],\n",
            "        [-1.5445,  1.4678, -0.0084],\n",
            "        [-1.7052,  0.5622,  0.9239],\n",
            "        [-2.3387,  0.8512,  1.0229],\n",
            "        [-1.8207,  1.0305,  0.3225],\n",
            "        [-1.6242,  1.1162, -0.0694]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.0788,  1.3498, -0.4431],\n",
            "        [-1.7284,  1.6353, -0.3045],\n",
            "        [-1.5816,  1.5156, -0.1686],\n",
            "        [-1.6171,  1.1364,  0.3574],\n",
            "        [-1.5271,  1.4904,  0.0419],\n",
            "        [-1.8009,  0.3849,  0.9977],\n",
            "        [-1.5553,  1.4328, -0.1645],\n",
            "        [ 0.6359, -0.0747, -0.8079],\n",
            "        [-1.3873,  1.2456, -0.2708],\n",
            "        [-1.5880,  1.2441, -0.1748],\n",
            "        [-1.5231,  0.3273,  1.1142],\n",
            "        [-1.3785,  1.1645, -0.3824],\n",
            "        [-1.8323,  0.5910,  0.7492],\n",
            "        [-1.5661,  1.4215, -0.0129],\n",
            "        [-1.5611,  0.3172,  0.8050],\n",
            "        [-1.8986,  0.7828,  0.7348]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.0788,  1.3498, -0.4431],\n",
            "        [-1.7284,  1.6353, -0.3045],\n",
            "        [-1.5816,  1.5156, -0.1686],\n",
            "        [-1.6171,  1.1364,  0.3574],\n",
            "        [-1.5271,  1.4904,  0.0419],\n",
            "        [-1.8009,  0.3849,  0.9977],\n",
            "        [-1.5553,  1.4328, -0.1645],\n",
            "        [ 0.6359, -0.0747, -0.8079],\n",
            "        [-1.3873,  1.2456, -0.2708],\n",
            "        [-1.5880,  1.2441, -0.1748],\n",
            "        [-1.5231,  0.3273,  1.1142],\n",
            "        [-1.3785,  1.1645, -0.3824],\n",
            "        [-1.8323,  0.5910,  0.7492],\n",
            "        [-1.5661,  1.4215, -0.0129],\n",
            "        [-1.5611,  0.3172,  0.8050],\n",
            "        [-1.8986,  0.7828,  0.7348]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5079e+00,  1.3078e+00, -2.3452e-01],\n",
            "        [-1.8150e+00,  9.5841e-01,  6.3561e-01],\n",
            "        [-1.7785e+00,  1.5858e+00, -4.6734e-01],\n",
            "        [-1.8000e-03,  4.4577e-01, -1.0783e+00],\n",
            "        [-2.0593e+00,  1.0961e+00,  3.7491e-01],\n",
            "        [-1.7226e+00,  1.4564e+00, -3.3064e-02],\n",
            "        [-1.9063e+00,  3.9351e-01,  1.0155e+00],\n",
            "        [-1.6079e+00,  1.3672e+00, -1.0490e-01],\n",
            "        [-1.1492e+00,  5.7279e-01,  4.8708e-01],\n",
            "        [-1.4987e+00,  1.4578e+00, -2.3348e-01],\n",
            "        [ 3.5714e-01,  3.6234e-02, -7.6356e-01],\n",
            "        [-1.1463e+00,  1.3023e+00, -3.0967e-01],\n",
            "        [-1.7336e+00,  1.5910e+00, -9.6977e-02],\n",
            "        [-1.5392e+00,  1.2648e+00, -2.6235e-01],\n",
            "        [-1.5006e+00,  1.3090e+00, -8.5506e-02],\n",
            "        [-1.6735e+00,  1.5506e+00,  5.2781e-02]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5079e+00,  1.3078e+00, -2.3452e-01],\n",
            "        [-1.8150e+00,  9.5841e-01,  6.3561e-01],\n",
            "        [-1.7785e+00,  1.5858e+00, -4.6734e-01],\n",
            "        [-1.8000e-03,  4.4577e-01, -1.0783e+00],\n",
            "        [-2.0593e+00,  1.0961e+00,  3.7491e-01],\n",
            "        [-1.7226e+00,  1.4564e+00, -3.3064e-02],\n",
            "        [-1.9063e+00,  3.9351e-01,  1.0155e+00],\n",
            "        [-1.6079e+00,  1.3672e+00, -1.0490e-01],\n",
            "        [-1.1492e+00,  5.7279e-01,  4.8708e-01],\n",
            "        [-1.4987e+00,  1.4578e+00, -2.3348e-01],\n",
            "        [ 3.5714e-01,  3.6234e-02, -7.6356e-01],\n",
            "        [-1.1463e+00,  1.3023e+00, -3.0967e-01],\n",
            "        [-1.7336e+00,  1.5910e+00, -9.6977e-02],\n",
            "        [-1.5392e+00,  1.2648e+00, -2.6235e-01],\n",
            "        [-1.5006e+00,  1.3090e+00, -8.5506e-02],\n",
            "        [-1.6735e+00,  1.5506e+00,  5.2781e-02]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9921,  0.6428,  1.0531],\n",
            "        [-1.5763,  0.7289,  0.5339],\n",
            "        [-1.7620,  1.4955, -0.1881],\n",
            "        [-1.0096,  0.5677,  0.4178],\n",
            "        [-1.8416,  1.1750,  0.3888],\n",
            "        [-1.4494,  1.6961, -0.1015],\n",
            "        [ 0.3821,  0.1131, -0.9870],\n",
            "        [-1.7396,  0.9662,  0.7546],\n",
            "        [-1.9888,  0.7874,  1.0579],\n",
            "        [-2.0298,  0.6453,  1.0247],\n",
            "        [-0.1842,  0.3841, -0.5891],\n",
            "        [-0.2711,  0.4382, -0.6806],\n",
            "        [-1.7888,  0.9493,  0.3755],\n",
            "        [-2.0058,  1.3055,  0.4174],\n",
            "        [-1.9908,  1.7281, -0.2262],\n",
            "        [-0.2562,  0.8534, -0.9246]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9921,  0.6428,  1.0531],\n",
            "        [-1.5763,  0.7289,  0.5339],\n",
            "        [-1.7620,  1.4955, -0.1881],\n",
            "        [-1.0096,  0.5677,  0.4178],\n",
            "        [-1.8416,  1.1750,  0.3888],\n",
            "        [-1.4494,  1.6961, -0.1015],\n",
            "        [ 0.3821,  0.1131, -0.9870],\n",
            "        [-1.7396,  0.9662,  0.7546],\n",
            "        [-1.9888,  0.7874,  1.0579],\n",
            "        [-2.0298,  0.6453,  1.0247],\n",
            "        [-0.1842,  0.3841, -0.5891],\n",
            "        [-0.2711,  0.4382, -0.6806],\n",
            "        [-1.7888,  0.9493,  0.3755],\n",
            "        [-2.0058,  1.3055,  0.4174],\n",
            "        [-1.9908,  1.7281, -0.2262],\n",
            "        [-0.2562,  0.8534, -0.9246]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1137,  0.8680,  0.7887],\n",
            "        [-1.2522,  1.7719, -0.5970],\n",
            "        [-0.9590,  1.1587, -0.5103],\n",
            "        [ 0.4810,  0.0121, -0.9518],\n",
            "        [-2.0209,  0.8255,  0.9415],\n",
            "        [-2.2026,  0.8294,  0.7599],\n",
            "        [-1.4433,  1.4290, -0.2851],\n",
            "        [-1.5034,  1.5639, -0.3057],\n",
            "        [-1.7964,  0.5156,  0.7872],\n",
            "        [-1.9176,  1.1608,  0.3990],\n",
            "        [-0.9095,  0.4037,  0.0771],\n",
            "        [-1.3564,  1.6000, -0.5386],\n",
            "        [-1.2227,  1.4191, -0.4720],\n",
            "        [-2.2992,  0.8093,  0.9689],\n",
            "        [-1.5961,  1.5755, -0.0728],\n",
            "        [-1.5428,  1.7438, -0.4588]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1137,  0.8680,  0.7887],\n",
            "        [-1.2522,  1.7719, -0.5970],\n",
            "        [-0.9590,  1.1587, -0.5103],\n",
            "        [ 0.4810,  0.0121, -0.9518],\n",
            "        [-2.0209,  0.8255,  0.9415],\n",
            "        [-2.2026,  0.8294,  0.7599],\n",
            "        [-1.4433,  1.4290, -0.2851],\n",
            "        [-1.5034,  1.5639, -0.3057],\n",
            "        [-1.7964,  0.5156,  0.7872],\n",
            "        [-1.9176,  1.1608,  0.3990],\n",
            "        [-0.9095,  0.4037,  0.0771],\n",
            "        [-1.3564,  1.6000, -0.5386],\n",
            "        [-1.2227,  1.4191, -0.4720],\n",
            "        [-2.2992,  0.8093,  0.9689],\n",
            "        [-1.5961,  1.5755, -0.0728],\n",
            "        [-1.5428,  1.7438, -0.4588]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3182,  1.4718, -0.4840],\n",
            "        [-1.6578,  0.4504,  1.0398],\n",
            "        [-0.3365,  0.9701, -0.9505],\n",
            "        [-1.4502,  1.4528, -0.4804],\n",
            "        [-1.7047,  1.7349, -0.1063],\n",
            "        [-1.8092,  1.5350, -0.0317],\n",
            "        [-1.6429,  1.5502, -0.2956],\n",
            "        [-1.6288,  1.6832, -0.3330],\n",
            "        [-1.5050,  1.4516, -0.4750],\n",
            "        [-1.8896,  1.6108,  0.1082],\n",
            "        [ 0.4013, -0.1751, -0.8057],\n",
            "        [ 0.5431, -0.1449, -0.8332],\n",
            "        [-1.4239,  1.8479, -0.6227],\n",
            "        [-1.9517,  1.3757,  0.4420],\n",
            "        [-2.2041,  1.2647,  0.6167],\n",
            "        [-1.5313,  1.7563, -0.4046]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3182,  1.4718, -0.4840],\n",
            "        [-1.6578,  0.4504,  1.0398],\n",
            "        [-0.3365,  0.9701, -0.9505],\n",
            "        [-1.4502,  1.4528, -0.4804],\n",
            "        [-1.7047,  1.7349, -0.1063],\n",
            "        [-1.8092,  1.5350, -0.0317],\n",
            "        [-1.6429,  1.5502, -0.2956],\n",
            "        [-1.6288,  1.6832, -0.3330],\n",
            "        [-1.5050,  1.4516, -0.4750],\n",
            "        [-1.8896,  1.6108,  0.1082],\n",
            "        [ 0.4013, -0.1751, -0.8057],\n",
            "        [ 0.5431, -0.1449, -0.8332],\n",
            "        [-1.4239,  1.8479, -0.6227],\n",
            "        [-1.9517,  1.3757,  0.4420],\n",
            "        [-2.2041,  1.2647,  0.6167],\n",
            "        [-1.5313,  1.7563, -0.4046]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1388,  0.5726,  0.8874],\n",
            "        [-2.0844,  1.2122,  0.6429],\n",
            "        [-1.7374,  1.8250, -0.3420],\n",
            "        [-1.7339,  1.4185, -0.2247],\n",
            "        [-1.3862,  1.3636, -0.1346],\n",
            "        [-2.0508,  0.9189,  0.9852],\n",
            "        [-1.6760,  1.8324, -0.3263],\n",
            "        [-1.4415,  0.9347,  0.2968],\n",
            "        [-1.3623,  1.7185, -0.3968],\n",
            "        [-1.9083,  0.4426,  0.9361],\n",
            "        [-1.3277,  1.4158, -0.5804],\n",
            "        [ 0.3070,  0.1045, -0.7338],\n",
            "        [-2.1357,  0.8213,  0.7372],\n",
            "        [-2.1458,  0.7162,  1.1041],\n",
            "        [-1.5214,  1.9138, -0.7235],\n",
            "        [-1.9563,  0.7940,  0.7403]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1388,  0.5726,  0.8874],\n",
            "        [-2.0844,  1.2122,  0.6429],\n",
            "        [-1.7374,  1.8250, -0.3420],\n",
            "        [-1.7339,  1.4185, -0.2247],\n",
            "        [-1.3862,  1.3636, -0.1346],\n",
            "        [-2.0508,  0.9189,  0.9852],\n",
            "        [-1.6760,  1.8324, -0.3263],\n",
            "        [-1.4415,  0.9347,  0.2968],\n",
            "        [-1.3623,  1.7185, -0.3968],\n",
            "        [-1.9083,  0.4426,  0.9361],\n",
            "        [-1.3277,  1.4158, -0.5804],\n",
            "        [ 0.3070,  0.1045, -0.7338],\n",
            "        [-2.1357,  0.8213,  0.7372],\n",
            "        [-2.1458,  0.7162,  1.1041],\n",
            "        [-1.5214,  1.9138, -0.7235],\n",
            "        [-1.9563,  0.7940,  0.7403]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-8.6856e-01,  1.1573e+00, -5.6783e-01],\n",
            "        [-1.5464e+00,  2.0306e+00, -6.6507e-01],\n",
            "        [-1.9758e+00,  6.8754e-01,  8.9163e-01],\n",
            "        [-1.6067e+00,  1.7873e+00, -4.2124e-01],\n",
            "        [-1.5996e+00,  1.9108e+00, -4.2811e-01],\n",
            "        [-1.3531e+00,  1.3971e+00, -2.7992e-01],\n",
            "        [-1.4715e+00,  1.6595e+00, -3.8446e-01],\n",
            "        [-1.5467e+00,  1.8954e+00, -5.1558e-01],\n",
            "        [-1.5699e+00,  1.8837e+00, -5.0411e-01],\n",
            "        [-1.8503e+00,  4.2376e-01,  8.7642e-01],\n",
            "        [-1.7031e+00,  1.6881e+00, -4.4424e-01],\n",
            "        [-1.2198e+00,  1.5837e+00, -5.8833e-01],\n",
            "        [ 4.5165e-01, -2.6162e-01, -8.4401e-01],\n",
            "        [-1.8483e+00,  8.3531e-01,  9.1635e-01],\n",
            "        [-2.0430e+00,  1.8047e+00, -7.5335e-04],\n",
            "        [ 3.6482e-01, -1.6390e-02, -8.5745e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-8.6856e-01,  1.1573e+00, -5.6783e-01],\n",
            "        [-1.5464e+00,  2.0306e+00, -6.6507e-01],\n",
            "        [-1.9758e+00,  6.8754e-01,  8.9163e-01],\n",
            "        [-1.6067e+00,  1.7873e+00, -4.2124e-01],\n",
            "        [-1.5996e+00,  1.9108e+00, -4.2811e-01],\n",
            "        [-1.3531e+00,  1.3971e+00, -2.7992e-01],\n",
            "        [-1.4715e+00,  1.6595e+00, -3.8446e-01],\n",
            "        [-1.5467e+00,  1.8954e+00, -5.1558e-01],\n",
            "        [-1.5699e+00,  1.8837e+00, -5.0411e-01],\n",
            "        [-1.8503e+00,  4.2376e-01,  8.7642e-01],\n",
            "        [-1.7031e+00,  1.6881e+00, -4.4424e-01],\n",
            "        [-1.2198e+00,  1.5837e+00, -5.8833e-01],\n",
            "        [ 4.5165e-01, -2.6162e-01, -8.4401e-01],\n",
            "        [-1.8483e+00,  8.3531e-01,  9.1635e-01],\n",
            "        [-2.0430e+00,  1.8047e+00, -7.5335e-04],\n",
            "        [ 3.6482e-01, -1.6390e-02, -8.5745e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6544,  1.8535, -0.4945],\n",
            "        [-1.1878,  1.6785, -0.6321],\n",
            "        [-1.1818,  1.6488, -0.7015],\n",
            "        [-1.4733,  1.6549, -0.5889],\n",
            "        [-2.0264,  0.6995,  1.2920],\n",
            "        [-1.4492,  1.6586, -0.5599],\n",
            "        [-2.0001,  1.9980, -0.1133],\n",
            "        [-1.8767,  1.0885,  0.4290],\n",
            "        [-2.3973,  0.8504,  0.8332],\n",
            "        [ 0.0591,  0.3409, -1.1022],\n",
            "        [-1.6742,  1.4985, -0.3419],\n",
            "        [ 0.4581,  0.0165, -0.8839],\n",
            "        [-1.6270,  1.8441, -0.3937],\n",
            "        [-1.7463,  2.1133, -0.3617],\n",
            "        [-1.6944,  1.9498, -0.5383],\n",
            "        [-1.9741,  0.5385,  1.1724]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6544,  1.8535, -0.4945],\n",
            "        [-1.1878,  1.6785, -0.6321],\n",
            "        [-1.1818,  1.6488, -0.7015],\n",
            "        [-1.4733,  1.6549, -0.5889],\n",
            "        [-2.0264,  0.6995,  1.2920],\n",
            "        [-1.4492,  1.6586, -0.5599],\n",
            "        [-2.0001,  1.9980, -0.1133],\n",
            "        [-1.8767,  1.0885,  0.4290],\n",
            "        [-2.3973,  0.8504,  0.8332],\n",
            "        [ 0.0591,  0.3409, -1.1022],\n",
            "        [-1.6742,  1.4985, -0.3419],\n",
            "        [ 0.4581,  0.0165, -0.8839],\n",
            "        [-1.6270,  1.8441, -0.3937],\n",
            "        [-1.7463,  2.1133, -0.3617],\n",
            "        [-1.6944,  1.9498, -0.5383],\n",
            "        [-1.9741,  0.5385,  1.1724]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5862,  1.8999, -0.6431],\n",
            "        [-1.5350,  1.8016, -0.6835],\n",
            "        [-1.7012,  2.0044, -0.5496],\n",
            "        [-1.6136,  0.6939,  0.7041],\n",
            "        [-1.5693,  1.9624, -0.6860],\n",
            "        [-0.9912,  1.4020, -0.5953],\n",
            "        [-2.0727,  0.8789,  0.8825],\n",
            "        [-0.1632,  0.8487, -0.9523],\n",
            "        [-1.9803,  1.1531,  0.5635],\n",
            "        [-1.9623,  1.5840,  0.2248],\n",
            "        [-1.5543,  1.6778, -0.4196],\n",
            "        [-1.2098,  1.9101, -0.5590],\n",
            "        [-1.6546,  2.0642, -0.5407],\n",
            "        [-1.5954,  1.8011, -0.4328],\n",
            "        [-2.3328,  1.2203,  0.8169],\n",
            "        [-1.6797,  1.7047, -0.4260]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5862,  1.8999, -0.6431],\n",
            "        [-1.5350,  1.8016, -0.6835],\n",
            "        [-1.7012,  2.0044, -0.5496],\n",
            "        [-1.6136,  0.6939,  0.7041],\n",
            "        [-1.5693,  1.9624, -0.6860],\n",
            "        [-0.9912,  1.4020, -0.5953],\n",
            "        [-2.0727,  0.8789,  0.8825],\n",
            "        [-0.1632,  0.8487, -0.9523],\n",
            "        [-1.9803,  1.1531,  0.5635],\n",
            "        [-1.9623,  1.5840,  0.2248],\n",
            "        [-1.5543,  1.6778, -0.4196],\n",
            "        [-1.2098,  1.9101, -0.5590],\n",
            "        [-1.6546,  2.0642, -0.5407],\n",
            "        [-1.5954,  1.8011, -0.4328],\n",
            "        [-2.3328,  1.2203,  0.8169],\n",
            "        [-1.6797,  1.7047, -0.4260]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7755,  2.0310, -0.6466],\n",
            "        [-2.0988,  0.6301,  0.9343],\n",
            "        [-2.0365,  0.7374,  1.0580],\n",
            "        [-2.2198,  1.2184,  0.7729],\n",
            "        [-1.3825,  2.0417, -0.6671],\n",
            "        [-1.5647,  1.9811, -0.6021],\n",
            "        [-1.3604,  1.9081, -0.7679],\n",
            "        [-1.1728,  1.7514, -0.9326],\n",
            "        [-1.8329,  0.5159,  1.0923],\n",
            "        [-1.2808,  2.0404, -0.7449],\n",
            "        [-1.7497,  1.9864, -0.6145],\n",
            "        [-1.9820,  1.2693,  0.3616],\n",
            "        [-1.4953,  1.8943, -0.7714],\n",
            "        [-2.2029,  1.2347,  0.6266],\n",
            "        [-1.8559,  1.9657, -0.0700],\n",
            "        [-1.8506,  1.9975, -0.4090]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7755,  2.0310, -0.6466],\n",
            "        [-2.0988,  0.6301,  0.9343],\n",
            "        [-2.0365,  0.7374,  1.0580],\n",
            "        [-2.2198,  1.2184,  0.7729],\n",
            "        [-1.3825,  2.0417, -0.6671],\n",
            "        [-1.5647,  1.9811, -0.6021],\n",
            "        [-1.3604,  1.9081, -0.7679],\n",
            "        [-1.1728,  1.7514, -0.9326],\n",
            "        [-1.8329,  0.5159,  1.0923],\n",
            "        [-1.2808,  2.0404, -0.7449],\n",
            "        [-1.7497,  1.9864, -0.6145],\n",
            "        [-1.9820,  1.2693,  0.3616],\n",
            "        [-1.4953,  1.8943, -0.7714],\n",
            "        [-2.2029,  1.2347,  0.6266],\n",
            "        [-1.8559,  1.9657, -0.0700],\n",
            "        [-1.8506,  1.9975, -0.4090]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1662,  0.9194,  0.8387],\n",
            "        [-1.7225,  1.8710, -0.5269],\n",
            "        [-1.6236,  1.6734, -0.6691],\n",
            "        [-1.5683,  2.1694, -0.4509],\n",
            "        [ 0.5450, -0.1945, -0.9762],\n",
            "        [-1.9859,  1.8286, -0.4169],\n",
            "        [-2.0226,  0.7053,  1.0684],\n",
            "        [-2.2198,  1.2584,  0.6168],\n",
            "        [-1.7630,  2.1677, -0.6252],\n",
            "        [-1.9490,  0.4648,  0.9805],\n",
            "        [-1.6742,  2.0480, -0.5868],\n",
            "        [-1.5876,  1.9920, -0.5716],\n",
            "        [-1.8987,  0.4519,  1.2004],\n",
            "        [-1.2649,  2.0241, -0.5878],\n",
            "        [-2.2745,  0.9281,  0.9107],\n",
            "        [-1.9323,  1.9410, -0.1991]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1662,  0.9194,  0.8387],\n",
            "        [-1.7225,  1.8710, -0.5269],\n",
            "        [-1.6236,  1.6734, -0.6691],\n",
            "        [-1.5683,  2.1694, -0.4509],\n",
            "        [ 0.5450, -0.1945, -0.9762],\n",
            "        [-1.9859,  1.8286, -0.4169],\n",
            "        [-2.0226,  0.7053,  1.0684],\n",
            "        [-2.2198,  1.2584,  0.6168],\n",
            "        [-1.7630,  2.1677, -0.6252],\n",
            "        [-1.9490,  0.4648,  0.9805],\n",
            "        [-1.6742,  2.0480, -0.5868],\n",
            "        [-1.5876,  1.9920, -0.5716],\n",
            "        [-1.8987,  0.4519,  1.2004],\n",
            "        [-1.2649,  2.0241, -0.5878],\n",
            "        [-2.2745,  0.9281,  0.9107],\n",
            "        [-1.9323,  1.9410, -0.1991]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6660,  1.9245, -0.2870],\n",
            "        [ 0.3027,  0.1950, -0.8994],\n",
            "        [-1.5399,  2.1750, -0.8427],\n",
            "        [-2.0631,  0.5190,  1.2097],\n",
            "        [-1.4907,  2.1244, -0.8799],\n",
            "        [-1.7207,  1.6628, -0.4684],\n",
            "        [-1.6293,  2.1331, -0.6555],\n",
            "        [-2.1247,  2.0411, -0.3763],\n",
            "        [-1.7266,  0.3879,  1.2186],\n",
            "        [-1.7286,  1.8080, -0.2915],\n",
            "        [-2.0474,  0.9127,  0.5560],\n",
            "        [-1.7352,  2.1617, -0.8467],\n",
            "        [-1.5168,  1.9416, -0.6569],\n",
            "        [-1.8183,  1.9425, -0.7058],\n",
            "        [-2.0026,  1.5214,  0.3370],\n",
            "        [-1.8420,  2.0589, -0.7991]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6660,  1.9245, -0.2870],\n",
            "        [ 0.3027,  0.1950, -0.8994],\n",
            "        [-1.5399,  2.1750, -0.8427],\n",
            "        [-2.0631,  0.5190,  1.2097],\n",
            "        [-1.4907,  2.1244, -0.8799],\n",
            "        [-1.7207,  1.6628, -0.4684],\n",
            "        [-1.6293,  2.1331, -0.6555],\n",
            "        [-2.1247,  2.0411, -0.3763],\n",
            "        [-1.7266,  0.3879,  1.2186],\n",
            "        [-1.7286,  1.8080, -0.2915],\n",
            "        [-2.0474,  0.9127,  0.5560],\n",
            "        [-1.7352,  2.1617, -0.8467],\n",
            "        [-1.5168,  1.9416, -0.6569],\n",
            "        [-1.8183,  1.9425, -0.7058],\n",
            "        [-2.0026,  1.5214,  0.3370],\n",
            "        [-1.8420,  2.0589, -0.7991]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9153,  2.3404, -0.7273],\n",
            "        [-1.0373,  1.1848, -0.2490],\n",
            "        [-2.0324,  0.3404,  1.0937],\n",
            "        [-2.1150,  0.6945,  1.2505],\n",
            "        [-2.1214,  1.3041,  0.5106],\n",
            "        [ 0.4268,  0.1983, -0.8264],\n",
            "        [-1.5855,  2.0427, -0.7791],\n",
            "        [-2.2930,  1.0809,  0.6842],\n",
            "        [-1.6662,  2.2741, -0.4012],\n",
            "        [-2.1034,  1.5466,  0.4654],\n",
            "        [-1.5721,  2.1279, -0.5727],\n",
            "        [-1.6134,  2.0054, -0.5914],\n",
            "        [ 0.1168,  0.0760, -0.8486],\n",
            "        [-2.0309,  2.3420, -0.3549],\n",
            "        [-1.7609,  2.1599, -0.5959],\n",
            "        [ 0.6329,  0.0630, -1.0754]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9153,  2.3404, -0.7273],\n",
            "        [-1.0373,  1.1848, -0.2490],\n",
            "        [-2.0324,  0.3404,  1.0937],\n",
            "        [-2.1150,  0.6945,  1.2505],\n",
            "        [-2.1214,  1.3041,  0.5106],\n",
            "        [ 0.4268,  0.1983, -0.8264],\n",
            "        [-1.5855,  2.0427, -0.7791],\n",
            "        [-2.2930,  1.0809,  0.6842],\n",
            "        [-1.6662,  2.2741, -0.4012],\n",
            "        [-2.1034,  1.5466,  0.4654],\n",
            "        [-1.5721,  2.1279, -0.5727],\n",
            "        [-1.6134,  2.0054, -0.5914],\n",
            "        [ 0.1168,  0.0760, -0.8486],\n",
            "        [-2.0309,  2.3420, -0.3549],\n",
            "        [-1.7609,  2.1599, -0.5959],\n",
            "        [ 0.6329,  0.0630, -1.0754]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7369,  2.2006, -0.5638],\n",
            "        [-1.5825,  2.2225, -0.7997],\n",
            "        [-1.8406,  0.2685,  1.3754],\n",
            "        [-2.0716,  0.3122,  1.1927],\n",
            "        [-2.2060,  1.3326,  0.3272],\n",
            "        [-1.8205,  1.9720, -0.6133],\n",
            "        [-2.0689,  0.2799,  1.2989],\n",
            "        [-1.2963,  1.0412,  0.0626],\n",
            "        [-1.8471,  1.8001, -0.0923],\n",
            "        [-1.9830,  0.3317,  1.3978],\n",
            "        [-2.2451,  0.6248,  1.2195],\n",
            "        [-1.7428,  0.3233,  1.0899],\n",
            "        [-2.1035,  0.7839,  0.8624],\n",
            "        [-1.9738,  0.4983,  1.2070],\n",
            "        [-2.0980,  0.6733,  0.9699],\n",
            "        [-1.4409,  2.0261, -0.5690]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7369,  2.2006, -0.5638],\n",
            "        [-1.5825,  2.2225, -0.7997],\n",
            "        [-1.8406,  0.2685,  1.3754],\n",
            "        [-2.0716,  0.3122,  1.1927],\n",
            "        [-2.2060,  1.3326,  0.3272],\n",
            "        [-1.8205,  1.9720, -0.6133],\n",
            "        [-2.0689,  0.2799,  1.2989],\n",
            "        [-1.2963,  1.0412,  0.0626],\n",
            "        [-1.8471,  1.8001, -0.0923],\n",
            "        [-1.9830,  0.3317,  1.3978],\n",
            "        [-2.2451,  0.6248,  1.2195],\n",
            "        [-1.7428,  0.3233,  1.0899],\n",
            "        [-2.1035,  0.7839,  0.8624],\n",
            "        [-1.9738,  0.4983,  1.2070],\n",
            "        [-2.0980,  0.6733,  0.9699],\n",
            "        [-1.4409,  2.0261, -0.5690]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.1223,  0.5683, -1.0191],\n",
            "        [-1.6029,  1.6778, -0.2673],\n",
            "        [-2.0551,  1.0688,  0.3842],\n",
            "        [-1.6303,  1.7900, -0.1914],\n",
            "        [-1.9791,  2.0777, -0.5152],\n",
            "        [-2.3577,  1.3992,  0.4042],\n",
            "        [-1.8974,  2.1705, -0.5407],\n",
            "        [-1.9797,  1.8944, -0.2769],\n",
            "        [-1.1220,  1.4037, -0.6978],\n",
            "        [-1.8001,  0.2987,  1.3190],\n",
            "        [-1.6734,  0.1110,  1.2209],\n",
            "        [-2.1968,  1.7395, -0.1194],\n",
            "        [-1.6319,  2.1620, -0.3784],\n",
            "        [-1.9393,  1.6826, -0.1922],\n",
            "        [-1.8142,  0.1991,  1.0765],\n",
            "        [-1.7608,  1.8276, -0.3861]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.1223,  0.5683, -1.0191],\n",
            "        [-1.6029,  1.6778, -0.2673],\n",
            "        [-2.0551,  1.0688,  0.3842],\n",
            "        [-1.6303,  1.7900, -0.1914],\n",
            "        [-1.9791,  2.0777, -0.5152],\n",
            "        [-2.3577,  1.3992,  0.4042],\n",
            "        [-1.8974,  2.1705, -0.5407],\n",
            "        [-1.9797,  1.8944, -0.2769],\n",
            "        [-1.1220,  1.4037, -0.6978],\n",
            "        [-1.8001,  0.2987,  1.3190],\n",
            "        [-1.6734,  0.1110,  1.2209],\n",
            "        [-2.1968,  1.7395, -0.1194],\n",
            "        [-1.6319,  2.1620, -0.3784],\n",
            "        [-1.9393,  1.6826, -0.1922],\n",
            "        [-1.8142,  0.1991,  1.0765],\n",
            "        [-1.7608,  1.8276, -0.3861]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2525,  1.9500,  0.0824],\n",
            "        [-1.6989,  0.4080,  1.2108],\n",
            "        [ 0.5228, -0.2431, -0.9392],\n",
            "        [-1.8328,  2.0757, -0.5917],\n",
            "        [-2.2976,  1.7440,  0.0702],\n",
            "        [-2.1479,  1.0634,  0.8373],\n",
            "        [-2.0143,  0.3833,  1.1867],\n",
            "        [-1.9085,  2.2390, -0.4592],\n",
            "        [-2.1629,  0.9920,  0.9476],\n",
            "        [ 0.5349,  0.0084, -0.9636],\n",
            "        [-2.3796,  0.8823,  1.1376],\n",
            "        [-1.6900,  1.9783, -0.3745],\n",
            "        [-1.8757,  1.9406, -0.4491],\n",
            "        [-2.3405,  0.5084,  1.3274],\n",
            "        [-2.2817,  1.2406,  0.9789],\n",
            "        [-2.2834,  0.9956,  0.9098]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.2525,  1.9500,  0.0824],\n",
            "        [-1.6989,  0.4080,  1.2108],\n",
            "        [ 0.5228, -0.2431, -0.9392],\n",
            "        [-1.8328,  2.0757, -0.5917],\n",
            "        [-2.2976,  1.7440,  0.0702],\n",
            "        [-2.1479,  1.0634,  0.8373],\n",
            "        [-2.0143,  0.3833,  1.1867],\n",
            "        [-1.9085,  2.2390, -0.4592],\n",
            "        [-2.1629,  0.9920,  0.9476],\n",
            "        [ 0.5349,  0.0084, -0.9636],\n",
            "        [-2.3796,  0.8823,  1.1376],\n",
            "        [-1.6900,  1.9783, -0.3745],\n",
            "        [-1.8757,  1.9406, -0.4491],\n",
            "        [-2.3405,  0.5084,  1.3274],\n",
            "        [-2.2817,  1.2406,  0.9789],\n",
            "        [-2.2834,  0.9956,  0.9098]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5253,  0.5618,  0.7947],\n",
            "        [-2.2295,  0.5518,  1.4206],\n",
            "        [-2.1186,  0.2676,  1.4295],\n",
            "        [-1.3245,  1.6347, -0.7258],\n",
            "        [-2.2525,  1.7112,  0.1575],\n",
            "        [-1.6948,  2.2432, -0.6416],\n",
            "        [-0.7971,  1.1851, -0.9072],\n",
            "        [-2.3721,  0.8525,  1.0021],\n",
            "        [-1.9712,  2.2175, -0.6035],\n",
            "        [-1.7150,  2.0025, -0.7394],\n",
            "        [-2.3260,  0.6015,  1.1574],\n",
            "        [-1.7588,  2.2631, -0.5367],\n",
            "        [-2.0057,  2.3644, -0.4458],\n",
            "        [-1.9616,  1.8111,  0.1105],\n",
            "        [-1.9496,  0.1856,  1.2768],\n",
            "        [-1.9022,  1.9529, -0.0898]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5253,  0.5618,  0.7947],\n",
            "        [-2.2295,  0.5518,  1.4206],\n",
            "        [-2.1186,  0.2676,  1.4295],\n",
            "        [-1.3245,  1.6347, -0.7258],\n",
            "        [-2.2525,  1.7112,  0.1575],\n",
            "        [-1.6948,  2.2432, -0.6416],\n",
            "        [-0.7971,  1.1851, -0.9072],\n",
            "        [-2.3721,  0.8525,  1.0021],\n",
            "        [-1.9712,  2.2175, -0.6035],\n",
            "        [-1.7150,  2.0025, -0.7394],\n",
            "        [-2.3260,  0.6015,  1.1574],\n",
            "        [-1.7588,  2.2631, -0.5367],\n",
            "        [-2.0057,  2.3644, -0.4458],\n",
            "        [-1.9616,  1.8111,  0.1105],\n",
            "        [-1.9496,  0.1856,  1.2768],\n",
            "        [-1.9022,  1.9529, -0.0898]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8676,  1.9529, -0.1475],\n",
            "        [-1.6613,  0.1987,  1.0555],\n",
            "        [-1.8047,  1.6372,  0.1244],\n",
            "        [-1.9042,  0.2724,  1.3831],\n",
            "        [-2.0103,  1.9302, -0.1319],\n",
            "        [-1.6428,  1.4459, -0.0180],\n",
            "        [-1.7079,  0.0141,  1.2755],\n",
            "        [-2.0335,  0.3477,  1.3355],\n",
            "        [-1.9208,  2.1933, -0.5873],\n",
            "        [ 0.5205, -0.1913, -0.9759],\n",
            "        [-1.7763,  2.3422, -0.5123],\n",
            "        [-1.8692,  1.8066,  0.1020],\n",
            "        [-2.0480,  0.5096,  1.0585],\n",
            "        [-1.9275,  0.4160,  1.1797],\n",
            "        [-2.4385,  1.8729,  0.4027],\n",
            "        [-2.2728,  0.5007,  1.4193]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8676,  1.9529, -0.1475],\n",
            "        [-1.6613,  0.1987,  1.0555],\n",
            "        [-1.8047,  1.6372,  0.1244],\n",
            "        [-1.9042,  0.2724,  1.3831],\n",
            "        [-2.0103,  1.9302, -0.1319],\n",
            "        [-1.6428,  1.4459, -0.0180],\n",
            "        [-1.7079,  0.0141,  1.2755],\n",
            "        [-2.0335,  0.3477,  1.3355],\n",
            "        [-1.9208,  2.1933, -0.5873],\n",
            "        [ 0.5205, -0.1913, -0.9759],\n",
            "        [-1.7763,  2.3422, -0.5123],\n",
            "        [-1.8692,  1.8066,  0.1020],\n",
            "        [-2.0480,  0.5096,  1.0585],\n",
            "        [-1.9275,  0.4160,  1.1797],\n",
            "        [-2.4385,  1.8729,  0.4027],\n",
            "        [-2.2728,  0.5007,  1.4193]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8778,  2.2860, -0.4169],\n",
            "        [-2.0548,  2.2815, -0.4640],\n",
            "        [-2.1752,  0.8711,  0.9894],\n",
            "        [-2.1274,  0.3094,  1.3499],\n",
            "        [-2.2890,  0.6823,  1.1910],\n",
            "        [-1.5895,  1.6163, -0.1845],\n",
            "        [-1.7780,  2.3018, -0.7165],\n",
            "        [-2.0898,  0.4224,  1.2891],\n",
            "        [-2.0216,  0.2802,  1.2917],\n",
            "        [-2.2054,  2.5114, -0.2217],\n",
            "        [-1.8244,  2.1878, -0.3488],\n",
            "        [-2.0877,  0.4151,  1.1912],\n",
            "        [-1.7406,  2.1675, -0.6204],\n",
            "        [-1.9907,  0.3064,  1.2703],\n",
            "        [ 0.6071, -0.1726, -0.9964],\n",
            "        [-1.9411,  2.0415, -0.3128]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8778,  2.2860, -0.4169],\n",
            "        [-2.0548,  2.2815, -0.4640],\n",
            "        [-2.1752,  0.8711,  0.9894],\n",
            "        [-2.1274,  0.3094,  1.3499],\n",
            "        [-2.2890,  0.6823,  1.1910],\n",
            "        [-1.5895,  1.6163, -0.1845],\n",
            "        [-1.7780,  2.3018, -0.7165],\n",
            "        [-2.0898,  0.4224,  1.2891],\n",
            "        [-2.0216,  0.2802,  1.2917],\n",
            "        [-2.2054,  2.5114, -0.2217],\n",
            "        [-1.8244,  2.1878, -0.3488],\n",
            "        [-2.0877,  0.4151,  1.1912],\n",
            "        [-1.7406,  2.1675, -0.6204],\n",
            "        [-1.9907,  0.3064,  1.2703],\n",
            "        [ 0.6071, -0.1726, -0.9964],\n",
            "        [-1.9411,  2.0415, -0.3128]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0370,  1.9576, -0.3056],\n",
            "        [-1.8742,  0.3842,  1.2252],\n",
            "        [-1.4038,  0.3187,  0.7774],\n",
            "        [-2.1762,  0.9430,  0.8320],\n",
            "        [-2.2167,  2.2510, -0.1254],\n",
            "        [-2.1491,  1.1951,  0.8714],\n",
            "        [-2.1014,  0.3226,  1.3522],\n",
            "        [-2.0009,  2.2011, -0.5154],\n",
            "        [-1.8728,  1.8697, -0.2672],\n",
            "        [-2.0096,  0.1367,  1.3543],\n",
            "        [-1.8539,  0.1911,  1.2057],\n",
            "        [ 0.7104, -0.2528, -0.9451],\n",
            "        [-2.4961,  1.4386,  0.5706],\n",
            "        [ 0.5873,  0.0473, -1.0303],\n",
            "        [ 0.4056,  0.1446, -0.9520],\n",
            "        [-2.3111,  0.9894,  0.8609]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0370,  1.9576, -0.3056],\n",
            "        [-1.8742,  0.3842,  1.2252],\n",
            "        [-1.4038,  0.3187,  0.7774],\n",
            "        [-2.1762,  0.9430,  0.8320],\n",
            "        [-2.2167,  2.2510, -0.1254],\n",
            "        [-2.1491,  1.1951,  0.8714],\n",
            "        [-2.1014,  0.3226,  1.3522],\n",
            "        [-2.0009,  2.2011, -0.5154],\n",
            "        [-1.8728,  1.8697, -0.2672],\n",
            "        [-2.0096,  0.1367,  1.3543],\n",
            "        [-1.8539,  0.1911,  1.2057],\n",
            "        [ 0.7104, -0.2528, -0.9451],\n",
            "        [-2.4961,  1.4386,  0.5706],\n",
            "        [ 0.5873,  0.0473, -1.0303],\n",
            "        [ 0.4056,  0.1446, -0.9520],\n",
            "        [-2.3111,  0.9894,  0.8609]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1247,  1.7233,  0.0082],\n",
            "        [-2.3489,  1.8177,  0.1136],\n",
            "        [-2.0526,  2.2546, -0.5546],\n",
            "        [-2.2089,  1.9934, -0.2681],\n",
            "        [-1.8615,  2.2031, -0.2762],\n",
            "        [-1.7446,  2.1666, -0.4608],\n",
            "        [-2.2977,  0.4530,  1.1303],\n",
            "        [-1.6877,  2.3248, -0.4361],\n",
            "        [ 0.5963, -0.2995, -1.0348],\n",
            "        [-1.5677,  1.9768, -0.2830],\n",
            "        [-1.3264,  0.2892,  0.6400],\n",
            "        [-2.1485,  2.3368, -0.5983],\n",
            "        [-2.0022,  0.4396,  1.4755],\n",
            "        [-1.6459,  1.8564, -0.3874],\n",
            "        [ 0.5530,  0.0443, -1.0194],\n",
            "        [-2.0031,  1.0935,  0.6980]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1247,  1.7233,  0.0082],\n",
            "        [-2.3489,  1.8177,  0.1136],\n",
            "        [-2.0526,  2.2546, -0.5546],\n",
            "        [-2.2089,  1.9934, -0.2681],\n",
            "        [-1.8615,  2.2031, -0.2762],\n",
            "        [-1.7446,  2.1666, -0.4608],\n",
            "        [-2.2977,  0.4530,  1.1303],\n",
            "        [-1.6877,  2.3248, -0.4361],\n",
            "        [ 0.5963, -0.2995, -1.0348],\n",
            "        [-1.5677,  1.9768, -0.2830],\n",
            "        [-1.3264,  0.2892,  0.6400],\n",
            "        [-2.1485,  2.3368, -0.5983],\n",
            "        [-2.0022,  0.4396,  1.4755],\n",
            "        [-1.6459,  1.8564, -0.3874],\n",
            "        [ 0.5530,  0.0443, -1.0194],\n",
            "        [-2.0031,  1.0935,  0.6980]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3807,  1.7459, -0.5688],\n",
            "        [-1.9588,  1.3197,  0.2659],\n",
            "        [-2.1717,  2.3606, -0.4918],\n",
            "        [-1.4262,  1.1566,  0.0571],\n",
            "        [-2.3322,  0.8721,  1.1606],\n",
            "        [-2.2288,  2.1650, -0.1323],\n",
            "        [-2.1696,  1.0961,  0.6521],\n",
            "        [ 0.4018, -0.1310, -0.9386],\n",
            "        [-2.3438,  0.4825,  1.1914],\n",
            "        [-1.9487,  1.8441, -0.3330],\n",
            "        [ 0.3784, -0.1120, -0.7507],\n",
            "        [-2.0751,  2.1009, -0.3518],\n",
            "        [-2.3126,  1.7006,  0.2943],\n",
            "        [-2.2299,  0.7801,  1.2193],\n",
            "        [-2.3840,  1.5762,  0.4706],\n",
            "        [-1.7307,  2.2997, -0.7216]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3807,  1.7459, -0.5688],\n",
            "        [-1.9588,  1.3197,  0.2659],\n",
            "        [-2.1717,  2.3606, -0.4918],\n",
            "        [-1.4262,  1.1566,  0.0571],\n",
            "        [-2.3322,  0.8721,  1.1606],\n",
            "        [-2.2288,  2.1650, -0.1323],\n",
            "        [-2.1696,  1.0961,  0.6521],\n",
            "        [ 0.4018, -0.1310, -0.9386],\n",
            "        [-2.3438,  0.4825,  1.1914],\n",
            "        [-1.9487,  1.8441, -0.3330],\n",
            "        [ 0.3784, -0.1120, -0.7507],\n",
            "        [-2.0751,  2.1009, -0.3518],\n",
            "        [-2.3126,  1.7006,  0.2943],\n",
            "        [-2.2299,  0.7801,  1.2193],\n",
            "        [-2.3840,  1.5762,  0.4706],\n",
            "        [-1.7307,  2.2997, -0.7216]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2932,  0.4728,  1.2756],\n",
            "        [-1.9379,  2.2648, -0.7773],\n",
            "        [-1.6730,  2.3139, -0.7165],\n",
            "        [-1.9698,  2.0153, -0.2826],\n",
            "        [-2.3570,  1.3640,  0.5176],\n",
            "        [-1.7267,  1.9315, -0.2695],\n",
            "        [-2.0262,  0.7408,  1.1259],\n",
            "        [-2.0531,  1.8564, -0.0873],\n",
            "        [ 0.3132,  0.5197, -1.2896],\n",
            "        [-1.8807,  2.1038, -0.5023],\n",
            "        [ 0.2179, -0.0949, -0.8188],\n",
            "        [-2.1342,  2.2941, -0.4094],\n",
            "        [-0.8234,  1.4096, -0.7687],\n",
            "        [ 0.6757, -0.2132, -1.0098],\n",
            "        [-1.6749,  2.1626, -0.5886],\n",
            "        [-1.1521,  0.5855,  0.2175]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.2932,  0.4728,  1.2756],\n",
            "        [-1.9379,  2.2648, -0.7773],\n",
            "        [-1.6730,  2.3139, -0.7165],\n",
            "        [-1.9698,  2.0153, -0.2826],\n",
            "        [-2.3570,  1.3640,  0.5176],\n",
            "        [-1.7267,  1.9315, -0.2695],\n",
            "        [-2.0262,  0.7408,  1.1259],\n",
            "        [-2.0531,  1.8564, -0.0873],\n",
            "        [ 0.3132,  0.5197, -1.2896],\n",
            "        [-1.8807,  2.1038, -0.5023],\n",
            "        [ 0.2179, -0.0949, -0.8188],\n",
            "        [-2.1342,  2.2941, -0.4094],\n",
            "        [-0.8234,  1.4096, -0.7687],\n",
            "        [ 0.6757, -0.2132, -1.0098],\n",
            "        [-1.6749,  2.1626, -0.5886],\n",
            "        [-1.1521,  0.5855,  0.2175]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0337,  0.7201,  1.1708],\n",
            "        [-2.0802,  1.0186,  0.8903],\n",
            "        [-2.1007,  0.4318,  1.2325],\n",
            "        [ 0.4314,  0.2996, -1.0781],\n",
            "        [ 0.1483,  0.3314, -0.9179],\n",
            "        [ 0.5713,  0.0407, -1.1200],\n",
            "        [-2.0291,  2.4402, -0.6878],\n",
            "        [-1.9600,  2.0901, -0.5506],\n",
            "        [-2.0956,  0.6116,  1.0419],\n",
            "        [-1.5847,  1.7514, -0.2898],\n",
            "        [-1.7794,  2.0660, -0.6036],\n",
            "        [ 0.3921,  0.2698, -1.1496],\n",
            "        [-2.2842,  1.1252,  0.8403],\n",
            "        [-1.6681,  2.0367, -0.3749],\n",
            "        [-1.8352,  1.9309, -0.3806],\n",
            "        [-2.0917,  0.7532,  1.2962]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0337,  0.7201,  1.1708],\n",
            "        [-2.0802,  1.0186,  0.8903],\n",
            "        [-2.1007,  0.4318,  1.2325],\n",
            "        [ 0.4314,  0.2996, -1.0781],\n",
            "        [ 0.1483,  0.3314, -0.9179],\n",
            "        [ 0.5713,  0.0407, -1.1200],\n",
            "        [-2.0291,  2.4402, -0.6878],\n",
            "        [-1.9600,  2.0901, -0.5506],\n",
            "        [-2.0956,  0.6116,  1.0419],\n",
            "        [-1.5847,  1.7514, -0.2898],\n",
            "        [-1.7794,  2.0660, -0.6036],\n",
            "        [ 0.3921,  0.2698, -1.1496],\n",
            "        [-2.2842,  1.1252,  0.8403],\n",
            "        [-1.6681,  2.0367, -0.3749],\n",
            "        [-1.8352,  1.9309, -0.3806],\n",
            "        [-2.0917,  0.7532,  1.2962]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9156,  1.9520, -0.3333],\n",
            "        [-2.1588,  0.5290,  1.2744],\n",
            "        [ 0.4699, -0.0405, -0.9844],\n",
            "        [-0.2081,  0.4921, -0.6961],\n",
            "        [-1.9810,  1.9637, -0.1603],\n",
            "        [-1.7487,  2.0842, -0.6899],\n",
            "        [-1.4195,  1.7164, -0.7770],\n",
            "        [-1.8582,  2.0959, -0.5565],\n",
            "        [-2.0391,  2.2353, -0.6855],\n",
            "        [-1.8471,  0.3376,  1.1192],\n",
            "        [-2.2494,  2.1388, -0.3662],\n",
            "        [-1.5777,  1.8001, -0.2130],\n",
            "        [-1.5277,  1.8290, -0.5189],\n",
            "        [-1.9824,  1.9019, -0.4019],\n",
            "        [ 0.6269,  0.0320, -0.9990],\n",
            "        [ 0.6158, -0.0530, -1.1728]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9156,  1.9520, -0.3333],\n",
            "        [-2.1588,  0.5290,  1.2744],\n",
            "        [ 0.4699, -0.0405, -0.9844],\n",
            "        [-0.2081,  0.4921, -0.6961],\n",
            "        [-1.9810,  1.9637, -0.1603],\n",
            "        [-1.7487,  2.0842, -0.6899],\n",
            "        [-1.4195,  1.7164, -0.7770],\n",
            "        [-1.8582,  2.0959, -0.5565],\n",
            "        [-2.0391,  2.2353, -0.6855],\n",
            "        [-1.8471,  0.3376,  1.1192],\n",
            "        [-2.2494,  2.1388, -0.3662],\n",
            "        [-1.5777,  1.8001, -0.2130],\n",
            "        [-1.5277,  1.8290, -0.5189],\n",
            "        [-1.9824,  1.9019, -0.4019],\n",
            "        [ 0.6269,  0.0320, -0.9990],\n",
            "        [ 0.6158, -0.0530, -1.1728]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.2758,  0.1873, -1.0931],\n",
            "        [-2.2274,  1.4172,  0.5350],\n",
            "        [-1.9576,  2.3064, -0.3033],\n",
            "        [-1.1681,  1.3442, -0.2895],\n",
            "        [-0.9023,  0.2634,  0.2010],\n",
            "        [-1.8993,  1.9725, -0.3066],\n",
            "        [-1.8364,  2.4515, -0.4875],\n",
            "        [-2.2272,  1.5067,  0.4055],\n",
            "        [-2.2454,  1.9462,  0.0153],\n",
            "        [-2.1117,  1.0282,  0.8962],\n",
            "        [-1.8027,  0.3709,  1.0282],\n",
            "        [-2.0286,  2.1685, -0.6134],\n",
            "        [ 0.2517,  0.1120, -0.6491],\n",
            "        [-1.9989,  1.0317,  0.5940],\n",
            "        [-1.6002,  0.9799,  0.4823],\n",
            "        [-1.8973,  0.3233,  1.0471]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.2758,  0.1873, -1.0931],\n",
            "        [-2.2274,  1.4172,  0.5350],\n",
            "        [-1.9576,  2.3064, -0.3033],\n",
            "        [-1.1681,  1.3442, -0.2895],\n",
            "        [-0.9023,  0.2634,  0.2010],\n",
            "        [-1.8993,  1.9725, -0.3066],\n",
            "        [-1.8364,  2.4515, -0.4875],\n",
            "        [-2.2272,  1.5067,  0.4055],\n",
            "        [-2.2454,  1.9462,  0.0153],\n",
            "        [-2.1117,  1.0282,  0.8962],\n",
            "        [-1.8027,  0.3709,  1.0282],\n",
            "        [-2.0286,  2.1685, -0.6134],\n",
            "        [ 0.2517,  0.1120, -0.6491],\n",
            "        [-1.9989,  1.0317,  0.5940],\n",
            "        [-1.6002,  0.9799,  0.4823],\n",
            "        [-1.8973,  0.3233,  1.0471]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.4107,  0.9573, -1.1225],\n",
            "        [-1.1334,  1.3471, -0.2969],\n",
            "        [-1.8782,  2.0754, -0.5374],\n",
            "        [-1.0999,  0.5239,  0.3744],\n",
            "        [-0.4735,  1.2303, -0.9421],\n",
            "        [-2.2140,  0.8608,  0.9840],\n",
            "        [-1.2274,  1.6844, -0.7232],\n",
            "        [-1.7698,  1.7778, -0.4047],\n",
            "        [-1.6949,  2.1172, -0.7067],\n",
            "        [-1.5887,  1.7460, -0.5146],\n",
            "        [-1.9194,  0.2554,  1.1654],\n",
            "        [-1.7477,  1.7814, -0.3133],\n",
            "        [-1.8817,  2.0714, -0.2072],\n",
            "        [-1.4606,  1.9289, -0.5333],\n",
            "        [-1.7999,  1.9390, -0.6958],\n",
            "        [-1.5641,  1.5621, -0.2824]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-0.4107,  0.9573, -1.1225],\n",
            "        [-1.1334,  1.3471, -0.2969],\n",
            "        [-1.8782,  2.0754, -0.5374],\n",
            "        [-1.0999,  0.5239,  0.3744],\n",
            "        [-0.4735,  1.2303, -0.9421],\n",
            "        [-2.2140,  0.8608,  0.9840],\n",
            "        [-1.2274,  1.6844, -0.7232],\n",
            "        [-1.7698,  1.7778, -0.4047],\n",
            "        [-1.6949,  2.1172, -0.7067],\n",
            "        [-1.5887,  1.7460, -0.5146],\n",
            "        [-1.9194,  0.2554,  1.1654],\n",
            "        [-1.7477,  1.7814, -0.3133],\n",
            "        [-1.8817,  2.0714, -0.2072],\n",
            "        [-1.4606,  1.9289, -0.5333],\n",
            "        [-1.7999,  1.9390, -0.6958],\n",
            "        [-1.5641,  1.5621, -0.2824]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.4449,  1.2686,  0.8654],\n",
            "        [-2.1086,  0.4957,  1.2709],\n",
            "        [-1.5289,  1.7675, -0.3240],\n",
            "        [-1.7826, -0.0945,  1.2702],\n",
            "        [-1.7972,  2.1157, -0.7791],\n",
            "        [-1.7709,  1.9054, -0.4767],\n",
            "        [-1.8738,  1.2694,  0.1496],\n",
            "        [-1.5585,  1.6767, -0.3210],\n",
            "        [-1.5536,  1.8334, -0.6134],\n",
            "        [ 0.2301,  0.1491, -1.1126],\n",
            "        [-2.1886,  0.6593,  1.3691],\n",
            "        [-1.9280,  1.9087, -0.1202],\n",
            "        [ 0.2596,  0.4734, -1.1369],\n",
            "        [-2.2897,  0.9404,  0.7341],\n",
            "        [-1.7902,  2.0677, -0.5372],\n",
            "        [-1.1492,  1.3622, -0.5506]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.4449,  1.2686,  0.8654],\n",
            "        [-2.1086,  0.4957,  1.2709],\n",
            "        [-1.5289,  1.7675, -0.3240],\n",
            "        [-1.7826, -0.0945,  1.2702],\n",
            "        [-1.7972,  2.1157, -0.7791],\n",
            "        [-1.7709,  1.9054, -0.4767],\n",
            "        [-1.8738,  1.2694,  0.1496],\n",
            "        [-1.5585,  1.6767, -0.3210],\n",
            "        [-1.5536,  1.8334, -0.6134],\n",
            "        [ 0.2301,  0.1491, -1.1126],\n",
            "        [-2.1886,  0.6593,  1.3691],\n",
            "        [-1.9280,  1.9087, -0.1202],\n",
            "        [ 0.2596,  0.4734, -1.1369],\n",
            "        [-2.2897,  0.9404,  0.7341],\n",
            "        [-1.7902,  2.0677, -0.5372],\n",
            "        [-1.1492,  1.3622, -0.5506]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.4799,  0.2892, -1.1492],\n",
            "        [-2.2237,  2.0589, -0.0459],\n",
            "        [-2.3820,  0.7107,  0.9790],\n",
            "        [-1.8342,  0.1991,  0.9474],\n",
            "        [-1.7373,  2.3869, -0.6624],\n",
            "        [ 0.2356,  0.2195, -1.3631],\n",
            "        [-2.0080,  2.1275, -0.3985],\n",
            "        [-1.7695,  1.7237, -0.3590],\n",
            "        [-2.2180,  1.7415,  0.2435],\n",
            "        [-1.8189,  1.7274, -0.0719],\n",
            "        [-2.2071,  0.6215,  1.0939],\n",
            "        [ 0.1871,  0.3779, -1.1758],\n",
            "        [-2.0775,  2.2289, -0.5950],\n",
            "        [ 0.4362,  0.3700, -1.1112],\n",
            "        [-2.0661,  2.1217, -0.3220],\n",
            "        [-1.7647,  2.0419, -0.6654]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.4799,  0.2892, -1.1492],\n",
            "        [-2.2237,  2.0589, -0.0459],\n",
            "        [-2.3820,  0.7107,  0.9790],\n",
            "        [-1.8342,  0.1991,  0.9474],\n",
            "        [-1.7373,  2.3869, -0.6624],\n",
            "        [ 0.2356,  0.2195, -1.3631],\n",
            "        [-2.0080,  2.1275, -0.3985],\n",
            "        [-1.7695,  1.7237, -0.3590],\n",
            "        [-2.2180,  1.7415,  0.2435],\n",
            "        [-1.8189,  1.7274, -0.0719],\n",
            "        [-2.2071,  0.6215,  1.0939],\n",
            "        [ 0.1871,  0.3779, -1.1758],\n",
            "        [-2.0775,  2.2289, -0.5950],\n",
            "        [ 0.4362,  0.3700, -1.1112],\n",
            "        [-2.0661,  2.1217, -0.3220],\n",
            "        [-1.7647,  2.0419, -0.6654]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.0185,  1.3213, -0.8420],\n",
            "        [-1.6594,  2.0219, -0.7760],\n",
            "        [-2.0092,  0.6553,  0.6891],\n",
            "        [-1.7074,  1.8999, -0.6147],\n",
            "        [-2.2854,  0.6830,  1.1462],\n",
            "        [-1.7906,  2.1817, -0.4442],\n",
            "        [-1.6203,  1.7743, -0.1964],\n",
            "        [ 0.4488,  0.1494, -1.1745],\n",
            "        [-0.9221,  0.6117, -0.2252],\n",
            "        [-2.1568,  2.1644, -0.0616],\n",
            "        [-0.3232,  0.9356, -0.9970],\n",
            "        [-1.8995,  0.5315,  1.0706],\n",
            "        [-1.7702,  1.8158, -0.1892],\n",
            "        [-1.8795,  1.8538, -0.3122],\n",
            "        [-0.5521,  0.6664, -0.5491],\n",
            "        [ 0.4360,  0.3480, -1.0701]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.0185,  1.3213, -0.8420],\n",
            "        [-1.6594,  2.0219, -0.7760],\n",
            "        [-2.0092,  0.6553,  0.6891],\n",
            "        [-1.7074,  1.8999, -0.6147],\n",
            "        [-2.2854,  0.6830,  1.1462],\n",
            "        [-1.7906,  2.1817, -0.4442],\n",
            "        [-1.6203,  1.7743, -0.1964],\n",
            "        [ 0.4488,  0.1494, -1.1745],\n",
            "        [-0.9221,  0.6117, -0.2252],\n",
            "        [-2.1568,  2.1644, -0.0616],\n",
            "        [-0.3232,  0.9356, -0.9970],\n",
            "        [-1.8995,  0.5315,  1.0706],\n",
            "        [-1.7702,  1.8158, -0.1892],\n",
            "        [-1.8795,  1.8538, -0.3122],\n",
            "        [-0.5521,  0.6664, -0.5491],\n",
            "        [ 0.4360,  0.3480, -1.0701]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8118,  1.9310, -0.3915],\n",
            "        [-1.6526,  2.1228, -0.6527],\n",
            "        [-1.7864,  1.9776, -0.3650],\n",
            "        [-1.8963,  2.1380, -0.3395],\n",
            "        [-1.9922,  0.4159,  1.1879],\n",
            "        [-2.1661,  0.5602,  0.9087],\n",
            "        [-1.9191,  1.8751, -0.2693],\n",
            "        [-1.2557,  1.7213, -0.8752],\n",
            "        [-1.7813,  2.0737, -0.5721],\n",
            "        [-2.4254,  1.4626,  0.4691],\n",
            "        [-1.9895,  2.1081, -0.3780],\n",
            "        [-1.8486,  2.1058, -0.6139],\n",
            "        [-2.2854,  1.0663,  1.0544],\n",
            "        [-1.8383,  0.5156,  1.1022],\n",
            "        [-2.0525,  1.5114,  0.2403],\n",
            "        [-1.9164,  1.8949, -0.5644]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8118,  1.9310, -0.3915],\n",
            "        [-1.6526,  2.1228, -0.6527],\n",
            "        [-1.7864,  1.9776, -0.3650],\n",
            "        [-1.8963,  2.1380, -0.3395],\n",
            "        [-1.9922,  0.4159,  1.1879],\n",
            "        [-2.1661,  0.5602,  0.9087],\n",
            "        [-1.9191,  1.8751, -0.2693],\n",
            "        [-1.2557,  1.7213, -0.8752],\n",
            "        [-1.7813,  2.0737, -0.5721],\n",
            "        [-2.4254,  1.4626,  0.4691],\n",
            "        [-1.9895,  2.1081, -0.3780],\n",
            "        [-1.8486,  2.1058, -0.6139],\n",
            "        [-2.2854,  1.0663,  1.0544],\n",
            "        [-1.8383,  0.5156,  1.1022],\n",
            "        [-2.0525,  1.5114,  0.2403],\n",
            "        [-1.9164,  1.8949, -0.5644]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0341,  1.7545, -0.0036],\n",
            "        [-1.8460,  2.0373, -0.2578],\n",
            "        [-2.1833,  2.0158,  0.0074],\n",
            "        [-1.8453,  2.0147, -0.3379],\n",
            "        [-1.9446,  1.8098, -0.4341],\n",
            "        [-0.2186,  0.4432, -0.8169],\n",
            "        [-2.1130,  0.6738,  1.0344],\n",
            "        [-1.9123,  1.9689, -0.3420],\n",
            "        [-2.1751,  1.7441,  0.1518],\n",
            "        [-2.0994,  0.6119,  1.2945],\n",
            "        [-2.2183,  0.6018,  1.2209],\n",
            "        [-1.9531,  1.9839, -0.3356],\n",
            "        [-1.8221,  2.0073, -0.2288],\n",
            "        [-1.8380,  1.9041, -0.7863],\n",
            "        [-0.1279,  0.7262, -1.1870],\n",
            "        [-1.7865,  1.4052,  0.2550]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0341,  1.7545, -0.0036],\n",
            "        [-1.8460,  2.0373, -0.2578],\n",
            "        [-2.1833,  2.0158,  0.0074],\n",
            "        [-1.8453,  2.0147, -0.3379],\n",
            "        [-1.9446,  1.8098, -0.4341],\n",
            "        [-0.2186,  0.4432, -0.8169],\n",
            "        [-2.1130,  0.6738,  1.0344],\n",
            "        [-1.9123,  1.9689, -0.3420],\n",
            "        [-2.1751,  1.7441,  0.1518],\n",
            "        [-2.0994,  0.6119,  1.2945],\n",
            "        [-2.2183,  0.6018,  1.2209],\n",
            "        [-1.9531,  1.9839, -0.3356],\n",
            "        [-1.8221,  2.0073, -0.2288],\n",
            "        [-1.8380,  1.9041, -0.7863],\n",
            "        [-0.1279,  0.7262, -1.1870],\n",
            "        [-1.7865,  1.4052,  0.2550]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4773,  1.5984, -0.3667],\n",
            "        [-1.7148,  2.1453, -0.3721],\n",
            "        [-1.7103,  1.9287, -0.2929],\n",
            "        [-1.5016,  1.7924, -0.2424],\n",
            "        [-1.6929,  2.0682, -0.6684],\n",
            "        [-1.7770,  2.0668, -0.4957],\n",
            "        [-1.5483,  1.7772, -0.3482],\n",
            "        [-1.6409,  1.7548, -0.1950],\n",
            "        [-1.8863,  1.8961, -0.2186],\n",
            "        [-1.8484,  1.8261, -0.3246],\n",
            "        [-2.0500,  1.6497, -0.0153],\n",
            "        [-2.0643,  1.3688,  0.4328],\n",
            "        [-2.2727,  0.6671,  1.2011],\n",
            "        [ 0.2883,  0.3539, -1.1528],\n",
            "        [-1.9716,  1.9444, -0.2384],\n",
            "        [-2.0492,  0.5004,  0.9771]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4773,  1.5984, -0.3667],\n",
            "        [-1.7148,  2.1453, -0.3721],\n",
            "        [-1.7103,  1.9287, -0.2929],\n",
            "        [-1.5016,  1.7924, -0.2424],\n",
            "        [-1.6929,  2.0682, -0.6684],\n",
            "        [-1.7770,  2.0668, -0.4957],\n",
            "        [-1.5483,  1.7772, -0.3482],\n",
            "        [-1.6409,  1.7548, -0.1950],\n",
            "        [-1.8863,  1.8961, -0.2186],\n",
            "        [-1.8484,  1.8261, -0.3246],\n",
            "        [-2.0500,  1.6497, -0.0153],\n",
            "        [-2.0643,  1.3688,  0.4328],\n",
            "        [-2.2727,  0.6671,  1.2011],\n",
            "        [ 0.2883,  0.3539, -1.1528],\n",
            "        [-1.9716,  1.9444, -0.2384],\n",
            "        [-2.0492,  0.5004,  0.9771]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2516,  1.0247,  0.9752],\n",
            "        [ 0.3480,  0.1906, -1.1403],\n",
            "        [-1.1441,  1.3259, -0.3963],\n",
            "        [-2.2542,  0.7582,  1.2746],\n",
            "        [-1.9675,  0.4780,  1.1213],\n",
            "        [-2.1385,  0.4744,  1.0801],\n",
            "        [-0.6777,  0.9381, -0.6290],\n",
            "        [-1.5654,  1.5431, -0.2812],\n",
            "        [-1.5060,  1.7169, -0.0848],\n",
            "        [-1.8592,  1.9548, -0.2038],\n",
            "        [-1.7821,  1.9575, -0.2284],\n",
            "        [-2.0038,  1.8937, -0.2102],\n",
            "        [-0.0097,  0.4448, -0.9904],\n",
            "        [-1.7617,  1.7723, -0.2013],\n",
            "        [-1.8449,  1.9107, -0.1376],\n",
            "        [-2.0926,  1.8033,  0.0371]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.2516,  1.0247,  0.9752],\n",
            "        [ 0.3480,  0.1906, -1.1403],\n",
            "        [-1.1441,  1.3259, -0.3963],\n",
            "        [-2.2542,  0.7582,  1.2746],\n",
            "        [-1.9675,  0.4780,  1.1213],\n",
            "        [-2.1385,  0.4744,  1.0801],\n",
            "        [-0.6777,  0.9381, -0.6290],\n",
            "        [-1.5654,  1.5431, -0.2812],\n",
            "        [-1.5060,  1.7169, -0.0848],\n",
            "        [-1.8592,  1.9548, -0.2038],\n",
            "        [-1.7821,  1.9575, -0.2284],\n",
            "        [-2.0038,  1.8937, -0.2102],\n",
            "        [-0.0097,  0.4448, -0.9904],\n",
            "        [-1.7617,  1.7723, -0.2013],\n",
            "        [-1.8449,  1.9107, -0.1376],\n",
            "        [-2.0926,  1.8033,  0.0371]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8186,  1.6237, -0.0672],\n",
            "        [-1.9771,  0.4328,  0.9904],\n",
            "        [-2.1478,  1.7057,  0.0386],\n",
            "        [-2.0338,  1.8162,  0.0553],\n",
            "        [-2.1958,  1.3132,  0.5219],\n",
            "        [ 0.3291,  0.4065, -1.1321],\n",
            "        [-1.8126,  2.0663, -0.3616],\n",
            "        [-1.8822,  1.9341, -0.0830],\n",
            "        [-0.6533,  1.2255, -0.9161],\n",
            "        [-1.8321,  1.9578, -0.2253],\n",
            "        [-2.0201,  1.3016,  0.8272],\n",
            "        [-0.4860,  0.8289, -0.6967],\n",
            "        [-0.9119,  0.7482, -0.1111],\n",
            "        [-1.9062,  1.8315, -0.1195],\n",
            "        [ 0.4116,  0.3554, -1.2147],\n",
            "        [-2.0032,  1.8279, -0.1572]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8186,  1.6237, -0.0672],\n",
            "        [-1.9771,  0.4328,  0.9904],\n",
            "        [-2.1478,  1.7057,  0.0386],\n",
            "        [-2.0338,  1.8162,  0.0553],\n",
            "        [-2.1958,  1.3132,  0.5219],\n",
            "        [ 0.3291,  0.4065, -1.1321],\n",
            "        [-1.8126,  2.0663, -0.3616],\n",
            "        [-1.8822,  1.9341, -0.0830],\n",
            "        [-0.6533,  1.2255, -0.9161],\n",
            "        [-1.8321,  1.9578, -0.2253],\n",
            "        [-2.0201,  1.3016,  0.8272],\n",
            "        [-0.4860,  0.8289, -0.6967],\n",
            "        [-0.9119,  0.7482, -0.1111],\n",
            "        [-1.9062,  1.8315, -0.1195],\n",
            "        [ 0.4116,  0.3554, -1.2147],\n",
            "        [-2.0032,  1.8279, -0.1572]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3942,  1.4365, -0.2846],\n",
            "        [-2.3024,  0.6559,  0.9639],\n",
            "        [-1.9700,  1.2777,  0.1116],\n",
            "        [-2.1009,  0.3958,  1.0580],\n",
            "        [-1.7732,  1.5358,  0.1508],\n",
            "        [-2.0422,  1.7364,  0.2936],\n",
            "        [ 0.1374,  0.3797, -1.0744],\n",
            "        [-1.8636,  1.5694,  0.1285],\n",
            "        [-1.9690,  1.6755, -0.1196],\n",
            "        [-1.4010,  0.2783,  0.7342],\n",
            "        [-0.0689,  0.5132, -0.8392],\n",
            "        [-2.2057,  0.6440,  1.0791],\n",
            "        [-1.9954,  0.9441,  0.5211],\n",
            "        [-1.9411,  1.3829,  0.2149],\n",
            "        [ 0.0265,  0.3014, -0.9875],\n",
            "        [-1.5187,  1.5104, -0.5095]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3942,  1.4365, -0.2846],\n",
            "        [-2.3024,  0.6559,  0.9639],\n",
            "        [-1.9700,  1.2777,  0.1116],\n",
            "        [-2.1009,  0.3958,  1.0580],\n",
            "        [-1.7732,  1.5358,  0.1508],\n",
            "        [-2.0422,  1.7364,  0.2936],\n",
            "        [ 0.1374,  0.3797, -1.0744],\n",
            "        [-1.8636,  1.5694,  0.1285],\n",
            "        [-1.9690,  1.6755, -0.1196],\n",
            "        [-1.4010,  0.2783,  0.7342],\n",
            "        [-0.0689,  0.5132, -0.8392],\n",
            "        [-2.2057,  0.6440,  1.0791],\n",
            "        [-1.9954,  0.9441,  0.5211],\n",
            "        [-1.9411,  1.3829,  0.2149],\n",
            "        [ 0.0265,  0.3014, -0.9875],\n",
            "        [-1.5187,  1.5104, -0.5095]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1814,  1.1039,  0.5281],\n",
            "        [-2.2716,  0.6650,  1.0321],\n",
            "        [-2.0168,  0.6287,  1.2965],\n",
            "        [-1.7847,  1.6774, -0.1163],\n",
            "        [ 0.4775,  0.1156, -1.3164],\n",
            "        [-1.8640,  1.7390, -0.0232],\n",
            "        [ 0.5127,  0.2613, -1.2639],\n",
            "        [-2.4501,  0.8241,  0.9557],\n",
            "        [-1.6527,  1.7635,  0.0640],\n",
            "        [-1.3692,  1.4170, -0.3853],\n",
            "        [-2.0888,  0.4631,  1.1111],\n",
            "        [ 0.5636,  0.2481, -1.2057],\n",
            "        [-0.1139,  0.6179, -0.8561],\n",
            "        [ 0.3483,  0.2238, -0.9831],\n",
            "        [-1.8322,  1.7391, -0.0961],\n",
            "        [-1.8058,  0.4834,  0.9766]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1814,  1.1039,  0.5281],\n",
            "        [-2.2716,  0.6650,  1.0321],\n",
            "        [-2.0168,  0.6287,  1.2965],\n",
            "        [-1.7847,  1.6774, -0.1163],\n",
            "        [ 0.4775,  0.1156, -1.3164],\n",
            "        [-1.8640,  1.7390, -0.0232],\n",
            "        [ 0.5127,  0.2613, -1.2639],\n",
            "        [-2.4501,  0.8241,  0.9557],\n",
            "        [-1.6527,  1.7635,  0.0640],\n",
            "        [-1.3692,  1.4170, -0.3853],\n",
            "        [-2.0888,  0.4631,  1.1111],\n",
            "        [ 0.5636,  0.2481, -1.2057],\n",
            "        [-0.1139,  0.6179, -0.8561],\n",
            "        [ 0.3483,  0.2238, -0.9831],\n",
            "        [-1.8322,  1.7391, -0.0961],\n",
            "        [-1.8058,  0.4834,  0.9766]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6759,  1.6716, -0.2213],\n",
            "        [-1.0731,  1.4011, -0.4666],\n",
            "        [-1.9086,  1.6802, -0.0567],\n",
            "        [-1.9591,  1.2062,  0.2760],\n",
            "        [ 0.0521,  0.3491, -0.9278],\n",
            "        [-1.7448,  1.5687, -0.1287],\n",
            "        [-1.3753,  1.4690, -0.5342],\n",
            "        [-1.5631,  1.4995, -0.1556],\n",
            "        [-1.8241,  1.1768,  0.4509],\n",
            "        [-1.6172,  1.5463, -0.2080],\n",
            "        [-1.6253,  1.6422, -0.2363],\n",
            "        [-0.2914,  0.3758, -0.4152],\n",
            "        [-2.0907,  1.5181,  0.4858],\n",
            "        [-2.1157,  0.6642,  1.0349],\n",
            "        [-1.3109,  1.4059, -0.2993],\n",
            "        [-1.4545,  1.2947, -0.1371]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6759,  1.6716, -0.2213],\n",
            "        [-1.0731,  1.4011, -0.4666],\n",
            "        [-1.9086,  1.6802, -0.0567],\n",
            "        [-1.9591,  1.2062,  0.2760],\n",
            "        [ 0.0521,  0.3491, -0.9278],\n",
            "        [-1.7448,  1.5687, -0.1287],\n",
            "        [-1.3753,  1.4690, -0.5342],\n",
            "        [-1.5631,  1.4995, -0.1556],\n",
            "        [-1.8241,  1.1768,  0.4509],\n",
            "        [-1.6172,  1.5463, -0.2080],\n",
            "        [-1.6253,  1.6422, -0.2363],\n",
            "        [-0.2914,  0.3758, -0.4152],\n",
            "        [-2.0907,  1.5181,  0.4858],\n",
            "        [-2.1157,  0.6642,  1.0349],\n",
            "        [-1.3109,  1.4059, -0.2993],\n",
            "        [-1.4545,  1.2947, -0.1371]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6140,  1.5033, -0.2607],\n",
            "        [ 0.1503,  0.4033, -1.0496],\n",
            "        [-1.5940,  1.2337,  0.0703],\n",
            "        [-2.0055,  0.4589,  1.2230],\n",
            "        [-1.3236,  1.4461, -0.2700],\n",
            "        [-1.9710,  0.8080,  0.9093],\n",
            "        [-1.4481,  1.6240, -0.3440],\n",
            "        [-1.5684,  1.4916, -0.3932],\n",
            "        [-2.1728,  1.1187,  0.8299],\n",
            "        [-1.7910,  1.5849, -0.2145],\n",
            "        [ 0.2528,  0.1881, -0.7717],\n",
            "        [-0.0252,  0.6912, -0.9828],\n",
            "        [-1.4525,  1.5486, -0.2833],\n",
            "        [-0.4542,  0.1219, -0.1150],\n",
            "        [-1.4667,  1.4827, -0.1354],\n",
            "        [-1.8101,  0.4678,  0.9431]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6140,  1.5033, -0.2607],\n",
            "        [ 0.1503,  0.4033, -1.0496],\n",
            "        [-1.5940,  1.2337,  0.0703],\n",
            "        [-2.0055,  0.4589,  1.2230],\n",
            "        [-1.3236,  1.4461, -0.2700],\n",
            "        [-1.9710,  0.8080,  0.9093],\n",
            "        [-1.4481,  1.6240, -0.3440],\n",
            "        [-1.5684,  1.4916, -0.3932],\n",
            "        [-2.1728,  1.1187,  0.8299],\n",
            "        [-1.7910,  1.5849, -0.2145],\n",
            "        [ 0.2528,  0.1881, -0.7717],\n",
            "        [-0.0252,  0.6912, -0.9828],\n",
            "        [-1.4525,  1.5486, -0.2833],\n",
            "        [-0.4542,  0.1219, -0.1150],\n",
            "        [-1.4667,  1.4827, -0.1354],\n",
            "        [-1.8101,  0.4678,  0.9431]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3753,  1.6768, -0.4969],\n",
            "        [ 0.3957,  0.1830, -1.0354],\n",
            "        [-1.9360,  0.7125,  1.0642],\n",
            "        [-1.5902,  1.6409, -0.2251],\n",
            "        [-2.0004,  0.3990,  1.1998],\n",
            "        [-1.7467,  0.2143,  1.1406],\n",
            "        [-1.6047,  1.5968,  0.0389],\n",
            "        [-1.2888,  0.7063,  0.1743],\n",
            "        [-1.8903,  0.5564,  0.8095],\n",
            "        [-2.0570,  0.7214,  0.8618],\n",
            "        [-1.9412,  0.3163,  1.2128],\n",
            "        [-1.9587,  0.3222,  1.0600],\n",
            "        [-1.6474,  1.8844, -0.0548],\n",
            "        [-1.6329,  1.8560, -0.4924],\n",
            "        [-1.7570,  1.0013,  0.4124],\n",
            "        [-1.9182,  0.5818,  1.1856]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3753,  1.6768, -0.4969],\n",
            "        [ 0.3957,  0.1830, -1.0354],\n",
            "        [-1.9360,  0.7125,  1.0642],\n",
            "        [-1.5902,  1.6409, -0.2251],\n",
            "        [-2.0004,  0.3990,  1.1998],\n",
            "        [-1.7467,  0.2143,  1.1406],\n",
            "        [-1.6047,  1.5968,  0.0389],\n",
            "        [-1.2888,  0.7063,  0.1743],\n",
            "        [-1.8903,  0.5564,  0.8095],\n",
            "        [-2.0570,  0.7214,  0.8618],\n",
            "        [-1.9412,  0.3163,  1.2128],\n",
            "        [-1.9587,  0.3222,  1.0600],\n",
            "        [-1.6474,  1.8844, -0.0548],\n",
            "        [-1.6329,  1.8560, -0.4924],\n",
            "        [-1.7570,  1.0013,  0.4124],\n",
            "        [-1.9182,  0.5818,  1.1856]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5973,  0.2230, -1.1858],\n",
            "        [-0.8074,  0.6609, -0.1021],\n",
            "        [-1.1486,  1.0715, -0.1448],\n",
            "        [-1.8977,  0.1990,  1.0693],\n",
            "        [-1.3293,  1.5357, -0.3347],\n",
            "        [-1.4613,  1.6599, -0.4178],\n",
            "        [ 0.6110,  0.2210, -1.2199],\n",
            "        [-1.6408,  1.4961, -0.0210],\n",
            "        [-2.2004,  0.5120,  1.1313],\n",
            "        [-1.1272,  0.6656,  0.1048],\n",
            "        [-1.4778,  1.5010, -0.1517],\n",
            "        [-0.9022,  1.2354, -0.5189],\n",
            "        [-1.7323,  1.2608,  0.0296],\n",
            "        [-2.1106,  0.4833,  1.3013],\n",
            "        [-1.1755,  1.5724, -0.5026],\n",
            "        [-1.8445,  0.3859,  1.0886]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.5973,  0.2230, -1.1858],\n",
            "        [-0.8074,  0.6609, -0.1021],\n",
            "        [-1.1486,  1.0715, -0.1448],\n",
            "        [-1.8977,  0.1990,  1.0693],\n",
            "        [-1.3293,  1.5357, -0.3347],\n",
            "        [-1.4613,  1.6599, -0.4178],\n",
            "        [ 0.6110,  0.2210, -1.2199],\n",
            "        [-1.6408,  1.4961, -0.0210],\n",
            "        [-2.2004,  0.5120,  1.1313],\n",
            "        [-1.1272,  0.6656,  0.1048],\n",
            "        [-1.4778,  1.5010, -0.1517],\n",
            "        [-0.9022,  1.2354, -0.5189],\n",
            "        [-1.7323,  1.2608,  0.0296],\n",
            "        [-2.1106,  0.4833,  1.3013],\n",
            "        [-1.1755,  1.5724, -0.5026],\n",
            "        [-1.8445,  0.3859,  1.0886]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.8006,  0.1838, -1.1799],\n",
            "        [-1.1851,  1.3206, -0.3892],\n",
            "        [-0.1068,  0.5842, -0.6880],\n",
            "        [-1.2313,  1.5963, -0.4567],\n",
            "        [-1.6982,  0.2484,  0.9321],\n",
            "        [-1.5416,  1.4136, -0.3174],\n",
            "        [-0.1535,  0.5851, -0.6179],\n",
            "        [-1.3486,  1.4698, -0.2745],\n",
            "        [ 0.5987,  0.1131, -1.1652],\n",
            "        [-1.9203,  1.5752,  0.0357],\n",
            "        [ 0.4674,  0.3024, -1.3094],\n",
            "        [ 0.5296,  0.2798, -1.1643],\n",
            "        [-2.2177,  0.4585,  1.2456],\n",
            "        [-1.2355,  1.5529, -0.6887],\n",
            "        [-1.6824,  1.6023, -0.1322],\n",
            "        [ 0.5538,  0.2873, -1.1733]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.8006,  0.1838, -1.1799],\n",
            "        [-1.1851,  1.3206, -0.3892],\n",
            "        [-0.1068,  0.5842, -0.6880],\n",
            "        [-1.2313,  1.5963, -0.4567],\n",
            "        [-1.6982,  0.2484,  0.9321],\n",
            "        [-1.5416,  1.4136, -0.3174],\n",
            "        [-0.1535,  0.5851, -0.6179],\n",
            "        [-1.3486,  1.4698, -0.2745],\n",
            "        [ 0.5987,  0.1131, -1.1652],\n",
            "        [-1.9203,  1.5752,  0.0357],\n",
            "        [ 0.4674,  0.3024, -1.3094],\n",
            "        [ 0.5296,  0.2798, -1.1643],\n",
            "        [-2.2177,  0.4585,  1.2456],\n",
            "        [-1.2355,  1.5529, -0.6887],\n",
            "        [-1.6824,  1.6023, -0.1322],\n",
            "        [ 0.5538,  0.2873, -1.1733]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.3697,  0.9920, -0.7754],\n",
            "        [-1.2106,  1.4391, -0.4400],\n",
            "        [-1.4155,  0.2457,  0.7984],\n",
            "        [-0.9193,  1.1170, -0.5218],\n",
            "        [-1.2319,  1.4657, -0.3222],\n",
            "        [-0.9815,  1.2991, -0.6557],\n",
            "        [-1.1828,  0.9487,  0.2290],\n",
            "        [-1.7366,  1.1216,  0.2688],\n",
            "        [ 0.4994,  0.2167, -1.0871],\n",
            "        [-1.7177,  0.4087,  0.9409],\n",
            "        [-1.1130,  1.4891, -0.8582],\n",
            "        [ 0.4919,  0.3423, -1.1642],\n",
            "        [-2.0515,  0.7341,  1.0213],\n",
            "        [-1.6007,  1.6348, -0.2447],\n",
            "        [-1.1571,  1.4991, -0.5738],\n",
            "        [-1.1562,  0.9049, -0.0372]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-0.3697,  0.9920, -0.7754],\n",
            "        [-1.2106,  1.4391, -0.4400],\n",
            "        [-1.4155,  0.2457,  0.7984],\n",
            "        [-0.9193,  1.1170, -0.5218],\n",
            "        [-1.2319,  1.4657, -0.3222],\n",
            "        [-0.9815,  1.2991, -0.6557],\n",
            "        [-1.1828,  0.9487,  0.2290],\n",
            "        [-1.7366,  1.1216,  0.2688],\n",
            "        [ 0.4994,  0.2167, -1.0871],\n",
            "        [-1.7177,  0.4087,  0.9409],\n",
            "        [-1.1130,  1.4891, -0.8582],\n",
            "        [ 0.4919,  0.3423, -1.1642],\n",
            "        [-2.0515,  0.7341,  1.0213],\n",
            "        [-1.6007,  1.6348, -0.2447],\n",
            "        [-1.1571,  1.4991, -0.5738],\n",
            "        [-1.1562,  0.9049, -0.0372]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.1913,  0.7271,  0.0420],\n",
            "        [-0.4413,  0.1819, -0.3850],\n",
            "        [-0.0075,  0.7480, -0.9310],\n",
            "        [-1.0926,  1.2736, -0.3589],\n",
            "        [-1.3461,  1.6901, -0.3696],\n",
            "        [-0.5823,  1.1109, -0.5999],\n",
            "        [-1.2162,  1.2883, -0.3075],\n",
            "        [-1.3809,  1.4710, -0.5487],\n",
            "        [-1.7000,  0.5077,  0.9162],\n",
            "        [-0.2357,  0.7510, -1.0525],\n",
            "        [-1.5574,  1.0203,  0.2140],\n",
            "        [-1.4350,  1.6889, -0.4240],\n",
            "        [ 0.0673,  0.4106, -0.6758],\n",
            "        [-1.1210,  1.5366, -0.4299],\n",
            "        [-1.1359,  1.2612, -0.3724],\n",
            "        [-1.5389,  1.6430, -0.1619]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.1913,  0.7271,  0.0420],\n",
            "        [-0.4413,  0.1819, -0.3850],\n",
            "        [-0.0075,  0.7480, -0.9310],\n",
            "        [-1.0926,  1.2736, -0.3589],\n",
            "        [-1.3461,  1.6901, -0.3696],\n",
            "        [-0.5823,  1.1109, -0.5999],\n",
            "        [-1.2162,  1.2883, -0.3075],\n",
            "        [-1.3809,  1.4710, -0.5487],\n",
            "        [-1.7000,  0.5077,  0.9162],\n",
            "        [-0.2357,  0.7510, -1.0525],\n",
            "        [-1.5574,  1.0203,  0.2140],\n",
            "        [-1.4350,  1.6889, -0.4240],\n",
            "        [ 0.0673,  0.4106, -0.6758],\n",
            "        [-1.1210,  1.5366, -0.4299],\n",
            "        [-1.1359,  1.2612, -0.3724],\n",
            "        [-1.5389,  1.6430, -0.1619]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7706,  1.5548,  0.0273],\n",
            "        [-1.1204,  1.8101, -0.7279],\n",
            "        [-1.8705,  0.7083,  0.7870],\n",
            "        [-1.5511,  1.5350, -0.3603],\n",
            "        [ 0.7227,  0.1734, -1.1677],\n",
            "        [-1.1657,  1.7444, -0.6626],\n",
            "        [-0.9880,  1.4909, -0.3294],\n",
            "        [-1.3949,  1.4992, -0.5978],\n",
            "        [-0.6275,  1.1607, -0.8052],\n",
            "        [-1.4345,  1.4840, -0.1883],\n",
            "        [-2.0596,  0.4227,  1.0981],\n",
            "        [-1.8638,  1.4927,  0.2669],\n",
            "        [-1.3438,  1.1725, -0.1904],\n",
            "        [ 0.7404,  0.0961, -1.2912],\n",
            "        [ 0.0532,  0.2158, -0.8871],\n",
            "        [-1.6465,  2.0016, -0.3326]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7706,  1.5548,  0.0273],\n",
            "        [-1.1204,  1.8101, -0.7279],\n",
            "        [-1.8705,  0.7083,  0.7870],\n",
            "        [-1.5511,  1.5350, -0.3603],\n",
            "        [ 0.7227,  0.1734, -1.1677],\n",
            "        [-1.1657,  1.7444, -0.6626],\n",
            "        [-0.9880,  1.4909, -0.3294],\n",
            "        [-1.3949,  1.4992, -0.5978],\n",
            "        [-0.6275,  1.1607, -0.8052],\n",
            "        [-1.4345,  1.4840, -0.1883],\n",
            "        [-2.0596,  0.4227,  1.0981],\n",
            "        [-1.8638,  1.4927,  0.2669],\n",
            "        [-1.3438,  1.1725, -0.1904],\n",
            "        [ 0.7404,  0.0961, -1.2912],\n",
            "        [ 0.0532,  0.2158, -0.8871],\n",
            "        [-1.6465,  2.0016, -0.3326]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.8484,  0.6708, -0.1337],\n",
            "        [-1.5146,  1.5082, -0.0853],\n",
            "        [-1.7440,  1.4008,  0.1099],\n",
            "        [-1.6357,  0.2873,  0.9916],\n",
            "        [-0.7330,  1.1726, -0.8706],\n",
            "        [-0.1389,  0.2524, -0.4708],\n",
            "        [ 0.4411,  0.3131, -0.9739],\n",
            "        [-0.6437,  0.7536, -0.5119],\n",
            "        [ 0.1782,  0.4933, -1.2898],\n",
            "        [-1.4993,  1.5275, -0.4923],\n",
            "        [-1.6522,  0.8363,  0.3254],\n",
            "        [-1.2304,  1.2960, -0.4524],\n",
            "        [-0.2675,  0.5801, -0.7008],\n",
            "        [-1.7011,  0.3275,  0.9615],\n",
            "        [-1.5170,  1.7728, -0.4745],\n",
            "        [-1.5750,  1.5930, -0.2669]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-0.8484,  0.6708, -0.1337],\n",
            "        [-1.5146,  1.5082, -0.0853],\n",
            "        [-1.7440,  1.4008,  0.1099],\n",
            "        [-1.6357,  0.2873,  0.9916],\n",
            "        [-0.7330,  1.1726, -0.8706],\n",
            "        [-0.1389,  0.2524, -0.4708],\n",
            "        [ 0.4411,  0.3131, -0.9739],\n",
            "        [-0.6437,  0.7536, -0.5119],\n",
            "        [ 0.1782,  0.4933, -1.2898],\n",
            "        [-1.4993,  1.5275, -0.4923],\n",
            "        [-1.6522,  0.8363,  0.3254],\n",
            "        [-1.2304,  1.2960, -0.4524],\n",
            "        [-0.2675,  0.5801, -0.7008],\n",
            "        [-1.7011,  0.3275,  0.9615],\n",
            "        [-1.5170,  1.7728, -0.4745],\n",
            "        [-1.5750,  1.5930, -0.2669]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7220,  0.7358,  0.7211],\n",
            "        [-1.8245,  0.2591,  1.0525],\n",
            "        [-1.2307,  1.4376, -0.6816],\n",
            "        [-1.6311,  0.8505,  0.4506],\n",
            "        [-2.1516,  0.4717,  1.0135],\n",
            "        [-1.3775,  1.8513, -0.6397],\n",
            "        [ 0.2993,  0.4065, -1.1149],\n",
            "        [-1.8796,  0.9210,  0.7396],\n",
            "        [-2.1009,  0.7707,  0.9550],\n",
            "        [ 0.3884,  0.2012, -1.1451],\n",
            "        [-1.7811,  1.1746,  0.3255],\n",
            "        [-1.3305,  1.7198, -0.5546],\n",
            "        [-1.0005,  1.2715, -0.6175],\n",
            "        [-0.4301,  1.1162, -1.0808],\n",
            "        [-0.9869,  1.4502, -0.6751],\n",
            "        [-1.2403,  1.4495, -0.5661]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7220,  0.7358,  0.7211],\n",
            "        [-1.8245,  0.2591,  1.0525],\n",
            "        [-1.2307,  1.4376, -0.6816],\n",
            "        [-1.6311,  0.8505,  0.4506],\n",
            "        [-2.1516,  0.4717,  1.0135],\n",
            "        [-1.3775,  1.8513, -0.6397],\n",
            "        [ 0.2993,  0.4065, -1.1149],\n",
            "        [-1.8796,  0.9210,  0.7396],\n",
            "        [-2.1009,  0.7707,  0.9550],\n",
            "        [ 0.3884,  0.2012, -1.1451],\n",
            "        [-1.7811,  1.1746,  0.3255],\n",
            "        [-1.3305,  1.7198, -0.5546],\n",
            "        [-1.0005,  1.2715, -0.6175],\n",
            "        [-0.4301,  1.1162, -1.0808],\n",
            "        [-0.9869,  1.4502, -0.6751],\n",
            "        [-1.2403,  1.4495, -0.5661]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2150,  1.7462, -0.5996],\n",
            "        [-1.3728,  1.9337, -0.3615],\n",
            "        [-1.4172,  0.4024,  0.7580],\n",
            "        [-1.2918,  1.7338, -0.6560],\n",
            "        [-1.1495,  1.5671, -0.5117],\n",
            "        [ 0.6474,  0.2765, -1.3047],\n",
            "        [-1.3607,  0.7682,  0.1445],\n",
            "        [-1.4177,  1.5407, -0.4057],\n",
            "        [ 0.5847,  0.0949, -1.2355],\n",
            "        [-1.0655,  0.1655,  0.4295],\n",
            "        [-0.8396,  1.0906, -0.3057],\n",
            "        [-1.7432,  1.5971, -0.0654],\n",
            "        [-0.4045,  1.0868, -0.8353],\n",
            "        [-1.5601,  1.6384, -0.3806],\n",
            "        [-0.0383,  0.8220, -0.9960],\n",
            "        [-1.3809,  1.9747, -0.4554]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2150,  1.7462, -0.5996],\n",
            "        [-1.3728,  1.9337, -0.3615],\n",
            "        [-1.4172,  0.4024,  0.7580],\n",
            "        [-1.2918,  1.7338, -0.6560],\n",
            "        [-1.1495,  1.5671, -0.5117],\n",
            "        [ 0.6474,  0.2765, -1.3047],\n",
            "        [-1.3607,  0.7682,  0.1445],\n",
            "        [-1.4177,  1.5407, -0.4057],\n",
            "        [ 0.5847,  0.0949, -1.2355],\n",
            "        [-1.0655,  0.1655,  0.4295],\n",
            "        [-0.8396,  1.0906, -0.3057],\n",
            "        [-1.7432,  1.5971, -0.0654],\n",
            "        [-0.4045,  1.0868, -0.8353],\n",
            "        [-1.5601,  1.6384, -0.3806],\n",
            "        [-0.0383,  0.8220, -0.9960],\n",
            "        [-1.3809,  1.9747, -0.4554]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5575,  1.8216, -0.5019],\n",
            "        [-1.5537,  1.6238, -0.3129],\n",
            "        [-1.3453,  1.6854, -0.5172],\n",
            "        [-1.9373,  0.7114,  0.9558],\n",
            "        [ 0.8308,  0.1064, -1.1417],\n",
            "        [-1.4649,  1.7960, -0.5593],\n",
            "        [-1.4233,  1.7772, -0.4258],\n",
            "        [-1.2703,  1.7407, -0.5835],\n",
            "        [-1.7634,  1.9395, -0.4068],\n",
            "        [-1.4961,  1.9062, -0.2903],\n",
            "        [-1.9202,  1.1424,  0.1760],\n",
            "        [-1.0870,  1.1381, -0.4247],\n",
            "        [ 0.5013,  0.4652, -1.1734],\n",
            "        [-1.6980,  1.5936, -0.0030],\n",
            "        [-0.3107,  0.3449, -0.4086],\n",
            "        [-0.7531,  1.2893, -0.6184]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5575,  1.8216, -0.5019],\n",
            "        [-1.5537,  1.6238, -0.3129],\n",
            "        [-1.3453,  1.6854, -0.5172],\n",
            "        [-1.9373,  0.7114,  0.9558],\n",
            "        [ 0.8308,  0.1064, -1.1417],\n",
            "        [-1.4649,  1.7960, -0.5593],\n",
            "        [-1.4233,  1.7772, -0.4258],\n",
            "        [-1.2703,  1.7407, -0.5835],\n",
            "        [-1.7634,  1.9395, -0.4068],\n",
            "        [-1.4961,  1.9062, -0.2903],\n",
            "        [-1.9202,  1.1424,  0.1760],\n",
            "        [-1.0870,  1.1381, -0.4247],\n",
            "        [ 0.5013,  0.4652, -1.1734],\n",
            "        [-1.6980,  1.5936, -0.0030],\n",
            "        [-0.3107,  0.3449, -0.4086],\n",
            "        [-0.7531,  1.2893, -0.6184]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.2296,  0.3842, -1.0622],\n",
            "        [-1.5998,  1.6553, -0.4885],\n",
            "        [-1.0807,  1.1339, -0.3214],\n",
            "        [-2.0213,  0.3211,  1.0273],\n",
            "        [-1.6417,  1.8457, -0.3277],\n",
            "        [-1.7832,  1.7823, -0.3341],\n",
            "        [-1.7114,  1.1416,  0.5137],\n",
            "        [-1.2058,  1.6167, -0.5470],\n",
            "        [-1.7519,  1.2756,  0.4459],\n",
            "        [-1.4309,  1.8602, -0.5583],\n",
            "        [-1.5374,  1.7372, -0.4784],\n",
            "        [-1.8441,  0.1623,  1.1801],\n",
            "        [-0.1786,  0.2892, -0.4428],\n",
            "        [-2.0425,  0.9833,  0.6288],\n",
            "        [-1.4564,  1.6962, -0.4482],\n",
            "        [-1.7440,  2.1448, -0.5848]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.2296,  0.3842, -1.0622],\n",
            "        [-1.5998,  1.6553, -0.4885],\n",
            "        [-1.0807,  1.1339, -0.3214],\n",
            "        [-2.0213,  0.3211,  1.0273],\n",
            "        [-1.6417,  1.8457, -0.3277],\n",
            "        [-1.7832,  1.7823, -0.3341],\n",
            "        [-1.7114,  1.1416,  0.5137],\n",
            "        [-1.2058,  1.6167, -0.5470],\n",
            "        [-1.7519,  1.2756,  0.4459],\n",
            "        [-1.4309,  1.8602, -0.5583],\n",
            "        [-1.5374,  1.7372, -0.4784],\n",
            "        [-1.8441,  0.1623,  1.1801],\n",
            "        [-0.1786,  0.2892, -0.4428],\n",
            "        [-2.0425,  0.9833,  0.6288],\n",
            "        [-1.4564,  1.6962, -0.4482],\n",
            "        [-1.7440,  2.1448, -0.5848]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.3660,  0.2152, -0.0902],\n",
            "        [-1.9293,  1.1718,  0.3303],\n",
            "        [-1.7369,  1.8085, -0.3807],\n",
            "        [-1.6699,  1.8534, -0.3675],\n",
            "        [-1.6346,  1.8749, -0.2816],\n",
            "        [ 0.0414,  0.7619, -0.8653],\n",
            "        [ 0.2629,  0.5767, -1.1333],\n",
            "        [-0.3879,  0.2082, -0.1836],\n",
            "        [-1.3112,  1.5863, -0.3532],\n",
            "        [-1.5473,  1.7702, -0.3588],\n",
            "        [-1.0985,  0.3036,  0.4518],\n",
            "        [-1.4766,  1.6774, -0.4064],\n",
            "        [-1.5570,  1.6420, -0.4294],\n",
            "        [-1.7719,  1.1852,  0.2764],\n",
            "        [-1.9386,  1.9506, -0.1950],\n",
            "        [ 0.6963,  0.1875, -1.2469]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-0.3660,  0.2152, -0.0902],\n",
            "        [-1.9293,  1.1718,  0.3303],\n",
            "        [-1.7369,  1.8085, -0.3807],\n",
            "        [-1.6699,  1.8534, -0.3675],\n",
            "        [-1.6346,  1.8749, -0.2816],\n",
            "        [ 0.0414,  0.7619, -0.8653],\n",
            "        [ 0.2629,  0.5767, -1.1333],\n",
            "        [-0.3879,  0.2082, -0.1836],\n",
            "        [-1.3112,  1.5863, -0.3532],\n",
            "        [-1.5473,  1.7702, -0.3588],\n",
            "        [-1.0985,  0.3036,  0.4518],\n",
            "        [-1.4766,  1.6774, -0.4064],\n",
            "        [-1.5570,  1.6420, -0.4294],\n",
            "        [-1.7719,  1.1852,  0.2764],\n",
            "        [-1.9386,  1.9506, -0.1950],\n",
            "        [ 0.6963,  0.1875, -1.2469]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6680,  1.8943, -0.4425],\n",
            "        [-1.6076,  1.5040, -0.2145],\n",
            "        [-1.5170,  1.6459, -0.3154],\n",
            "        [-1.3811,  1.7844, -0.4989],\n",
            "        [-1.2859,  1.8791, -0.6064],\n",
            "        [-1.8538,  1.8863, -0.2506],\n",
            "        [-1.2787,  1.1921, -0.0719],\n",
            "        [ 0.3482,  0.2356, -0.9715],\n",
            "        [-1.8154,  0.5290,  1.1479],\n",
            "        [-2.0830,  0.2697,  1.1770],\n",
            "        [ 0.0257,  0.7619, -0.9509],\n",
            "        [-1.6492,  1.9018, -0.1053],\n",
            "        [-2.0920,  0.6405,  0.9879],\n",
            "        [-1.5188,  1.6063, -0.3840],\n",
            "        [-1.6852,  1.8250, -0.5523],\n",
            "        [-1.3999,  1.7053, -0.4829]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6680,  1.8943, -0.4425],\n",
            "        [-1.6076,  1.5040, -0.2145],\n",
            "        [-1.5170,  1.6459, -0.3154],\n",
            "        [-1.3811,  1.7844, -0.4989],\n",
            "        [-1.2859,  1.8791, -0.6064],\n",
            "        [-1.8538,  1.8863, -0.2506],\n",
            "        [-1.2787,  1.1921, -0.0719],\n",
            "        [ 0.3482,  0.2356, -0.9715],\n",
            "        [-1.8154,  0.5290,  1.1479],\n",
            "        [-2.0830,  0.2697,  1.1770],\n",
            "        [ 0.0257,  0.7619, -0.9509],\n",
            "        [-1.6492,  1.9018, -0.1053],\n",
            "        [-2.0920,  0.6405,  0.9879],\n",
            "        [-1.5188,  1.6063, -0.3840],\n",
            "        [-1.6852,  1.8250, -0.5523],\n",
            "        [-1.3999,  1.7053, -0.4829]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3178,  1.7021, -0.3209],\n",
            "        [-1.7084,  1.6022, -0.0505],\n",
            "        [-1.6900,  1.7193, -0.4076],\n",
            "        [-1.6111,  1.7707, -0.2561],\n",
            "        [-1.8703,  1.7311, -0.1936],\n",
            "        [ 0.5176,  0.3047, -1.1362],\n",
            "        [-1.6507,  1.8585, -0.4621],\n",
            "        [-1.4197,  1.6192, -0.6777],\n",
            "        [ 0.3691,  0.4136, -1.1752],\n",
            "        [-0.9271,  1.6728, -0.7101],\n",
            "        [-1.8957,  1.3729,  0.1883],\n",
            "        [-1.0012,  1.4496, -0.6520],\n",
            "        [-0.8108,  1.2970, -0.4018],\n",
            "        [-1.6078,  1.8273, -0.4876],\n",
            "        [-1.8773,  1.6140, -0.0773],\n",
            "        [-1.9958,  0.9896,  0.5378]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3178,  1.7021, -0.3209],\n",
            "        [-1.7084,  1.6022, -0.0505],\n",
            "        [-1.6900,  1.7193, -0.4076],\n",
            "        [-1.6111,  1.7707, -0.2561],\n",
            "        [-1.8703,  1.7311, -0.1936],\n",
            "        [ 0.5176,  0.3047, -1.1362],\n",
            "        [-1.6507,  1.8585, -0.4621],\n",
            "        [-1.4197,  1.6192, -0.6777],\n",
            "        [ 0.3691,  0.4136, -1.1752],\n",
            "        [-0.9271,  1.6728, -0.7101],\n",
            "        [-1.8957,  1.3729,  0.1883],\n",
            "        [-1.0012,  1.4496, -0.6520],\n",
            "        [-0.8108,  1.2970, -0.4018],\n",
            "        [-1.6078,  1.8273, -0.4876],\n",
            "        [-1.8773,  1.6140, -0.0773],\n",
            "        [-1.9958,  0.9896,  0.5378]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5234,  0.5419, -1.2099],\n",
            "        [-1.6177,  1.9447, -0.3205],\n",
            "        [-0.9918,  0.2494,  0.2910],\n",
            "        [-1.5204,  1.7287, -0.2758],\n",
            "        [-1.4441,  1.6588, -0.0457],\n",
            "        [-1.1474,  1.5402, -0.5231],\n",
            "        [-1.9453,  0.4978,  1.1515],\n",
            "        [-1.8884,  1.7680, -0.3039],\n",
            "        [-1.9785,  1.7036,  0.4697],\n",
            "        [-2.1451,  0.4319,  1.2681],\n",
            "        [-2.0069,  0.3729,  1.1088],\n",
            "        [-1.6763,  1.5877, -0.2881],\n",
            "        [-0.3762,  1.0447, -0.8469],\n",
            "        [ 0.4518,  0.3701, -1.1998],\n",
            "        [-2.4083,  1.2536,  0.3555],\n",
            "        [-1.5824,  0.3606,  1.0748]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.5234,  0.5419, -1.2099],\n",
            "        [-1.6177,  1.9447, -0.3205],\n",
            "        [-0.9918,  0.2494,  0.2910],\n",
            "        [-1.5204,  1.7287, -0.2758],\n",
            "        [-1.4441,  1.6588, -0.0457],\n",
            "        [-1.1474,  1.5402, -0.5231],\n",
            "        [-1.9453,  0.4978,  1.1515],\n",
            "        [-1.8884,  1.7680, -0.3039],\n",
            "        [-1.9785,  1.7036,  0.4697],\n",
            "        [-2.1451,  0.4319,  1.2681],\n",
            "        [-2.0069,  0.3729,  1.1088],\n",
            "        [-1.6763,  1.5877, -0.2881],\n",
            "        [-0.3762,  1.0447, -0.8469],\n",
            "        [ 0.4518,  0.3701, -1.1998],\n",
            "        [-2.4083,  1.2536,  0.3555],\n",
            "        [-1.5824,  0.3606,  1.0748]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5364,  1.7833, -0.3162],\n",
            "        [-1.5357,  1.7130, -0.3813],\n",
            "        [-1.8087,  1.8362, -0.1479],\n",
            "        [ 0.2578,  0.3840, -1.2029],\n",
            "        [-1.7731,  1.6891, -0.2608],\n",
            "        [-2.0343,  0.9308,  0.9065],\n",
            "        [-1.6460,  2.0082, -0.3024],\n",
            "        [-2.1672,  0.5042,  1.3399],\n",
            "        [-1.7187,  1.4884, -0.1290],\n",
            "        [-0.4438,  0.2978, -0.2193],\n",
            "        [-1.5703,  1.9288, -0.4716],\n",
            "        [-1.7384,  0.4309,  0.9795],\n",
            "        [-1.6622,  2.0966, -0.5079],\n",
            "        [-2.0734,  0.5270,  1.0462],\n",
            "        [-1.4884,  1.7898, -0.4800],\n",
            "        [-1.5671,  2.0410, -0.6064]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5364,  1.7833, -0.3162],\n",
            "        [-1.5357,  1.7130, -0.3813],\n",
            "        [-1.8087,  1.8362, -0.1479],\n",
            "        [ 0.2578,  0.3840, -1.2029],\n",
            "        [-1.7731,  1.6891, -0.2608],\n",
            "        [-2.0343,  0.9308,  0.9065],\n",
            "        [-1.6460,  2.0082, -0.3024],\n",
            "        [-2.1672,  0.5042,  1.3399],\n",
            "        [-1.7187,  1.4884, -0.1290],\n",
            "        [-0.4438,  0.2978, -0.2193],\n",
            "        [-1.5703,  1.9288, -0.4716],\n",
            "        [-1.7384,  0.4309,  0.9795],\n",
            "        [-1.6622,  2.0966, -0.5079],\n",
            "        [-2.0734,  0.5270,  1.0462],\n",
            "        [-1.4884,  1.7898, -0.4800],\n",
            "        [-1.5671,  2.0410, -0.6064]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.3870,  0.7302, -0.6633],\n",
            "        [-1.0473,  1.7291, -0.5552],\n",
            "        [-1.5161,  1.6221, -0.2656],\n",
            "        [-1.6716,  1.6950, -0.2783],\n",
            "        [-1.3567,  1.7236, -0.4035],\n",
            "        [-1.8428,  0.4565,  0.9462],\n",
            "        [-1.5781,  1.7617, -0.3984],\n",
            "        [-1.8955,  1.6885, -0.2908],\n",
            "        [-1.5063,  1.5907, -0.2137],\n",
            "        [ 0.3030,  0.6342, -0.9724],\n",
            "        [-1.7094,  1.9018, -0.3598],\n",
            "        [-1.6893,  1.6522, -0.0491],\n",
            "        [-1.6632,  1.7266, -0.4439],\n",
            "        [-1.7538,  1.6987, -0.2620],\n",
            "        [-2.1156,  0.4729,  0.8837],\n",
            "        [-1.4241,  1.9635, -0.5820]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-0.3870,  0.7302, -0.6633],\n",
            "        [-1.0473,  1.7291, -0.5552],\n",
            "        [-1.5161,  1.6221, -0.2656],\n",
            "        [-1.6716,  1.6950, -0.2783],\n",
            "        [-1.3567,  1.7236, -0.4035],\n",
            "        [-1.8428,  0.4565,  0.9462],\n",
            "        [-1.5781,  1.7617, -0.3984],\n",
            "        [-1.8955,  1.6885, -0.2908],\n",
            "        [-1.5063,  1.5907, -0.2137],\n",
            "        [ 0.3030,  0.6342, -0.9724],\n",
            "        [-1.7094,  1.9018, -0.3598],\n",
            "        [-1.6893,  1.6522, -0.0491],\n",
            "        [-1.6632,  1.7266, -0.4439],\n",
            "        [-1.7538,  1.6987, -0.2620],\n",
            "        [-2.1156,  0.4729,  0.8837],\n",
            "        [-1.4241,  1.9635, -0.5820]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.8682,  1.2301, -0.6830],\n",
            "        [-1.7328,  1.8076, -0.3258],\n",
            "        [-1.6954,  1.7991, -0.4088],\n",
            "        [-2.0723,  0.9818,  0.8392],\n",
            "        [-1.7571,  1.6441, -0.1834],\n",
            "        [-2.0621,  0.3723,  1.1957],\n",
            "        [-1.7601,  1.9191, -0.3923],\n",
            "        [-1.3508,  1.7472, -0.4569],\n",
            "        [-1.7694,  1.8965, -0.1290],\n",
            "        [-1.8406,  0.6586,  0.7912],\n",
            "        [-1.6160,  0.3435,  0.9541],\n",
            "        [-1.5791,  1.5556, -0.2814],\n",
            "        [-1.8795,  0.2958,  1.2399],\n",
            "        [-1.8980,  1.7882, -0.0753],\n",
            "        [-1.9138,  0.3857,  1.1330],\n",
            "        [-1.7374,  0.4367,  1.0293]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-0.8682,  1.2301, -0.6830],\n",
            "        [-1.7328,  1.8076, -0.3258],\n",
            "        [-1.6954,  1.7991, -0.4088],\n",
            "        [-2.0723,  0.9818,  0.8392],\n",
            "        [-1.7571,  1.6441, -0.1834],\n",
            "        [-2.0621,  0.3723,  1.1957],\n",
            "        [-1.7601,  1.9191, -0.3923],\n",
            "        [-1.3508,  1.7472, -0.4569],\n",
            "        [-1.7694,  1.8965, -0.1290],\n",
            "        [-1.8406,  0.6586,  0.7912],\n",
            "        [-1.6160,  0.3435,  0.9541],\n",
            "        [-1.5791,  1.5556, -0.2814],\n",
            "        [-1.8795,  0.2958,  1.2399],\n",
            "        [-1.8980,  1.7882, -0.0753],\n",
            "        [-1.9138,  0.3857,  1.1330],\n",
            "        [-1.7374,  0.4367,  1.0293]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4263,  1.3913, -0.1417],\n",
            "        [-0.7640,  0.0834,  0.0807],\n",
            "        [-1.6018,  1.7291, -0.4561],\n",
            "        [-1.5258,  1.8251, -0.3872],\n",
            "        [ 0.1680,  0.2522, -0.7748],\n",
            "        [-1.4780,  1.7410, -0.2770],\n",
            "        [-1.6416,  0.6936,  0.7465],\n",
            "        [-1.3851,  1.4639, -0.2896],\n",
            "        [-1.5832,  1.7730, -0.2794],\n",
            "        [-1.8677,  1.3803,  0.1536],\n",
            "        [-1.2487,  1.9524, -0.6876],\n",
            "        [-1.9615,  0.4573,  0.9468],\n",
            "        [-1.4492,  1.7715, -0.4111],\n",
            "        [-1.2733,  1.5765, -0.4797],\n",
            "        [-1.6122,  1.6866, -0.3304],\n",
            "        [-1.5974,  1.7783, -0.2518]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4263,  1.3913, -0.1417],\n",
            "        [-0.7640,  0.0834,  0.0807],\n",
            "        [-1.6018,  1.7291, -0.4561],\n",
            "        [-1.5258,  1.8251, -0.3872],\n",
            "        [ 0.1680,  0.2522, -0.7748],\n",
            "        [-1.4780,  1.7410, -0.2770],\n",
            "        [-1.6416,  0.6936,  0.7465],\n",
            "        [-1.3851,  1.4639, -0.2896],\n",
            "        [-1.5832,  1.7730, -0.2794],\n",
            "        [-1.8677,  1.3803,  0.1536],\n",
            "        [-1.2487,  1.9524, -0.6876],\n",
            "        [-1.9615,  0.4573,  0.9468],\n",
            "        [-1.4492,  1.7715, -0.4111],\n",
            "        [-1.2733,  1.5765, -0.4797],\n",
            "        [-1.6122,  1.6866, -0.3304],\n",
            "        [-1.5974,  1.7783, -0.2518]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4133,  1.6596, -0.3949],\n",
            "        [-1.7839,  0.2629,  0.8893],\n",
            "        [-1.4300,  1.3274, -0.0810],\n",
            "        [-1.0885,  1.6198, -0.6863],\n",
            "        [-1.6900,  1.7356, -0.1722],\n",
            "        [-1.5387,  1.4476, -0.1241],\n",
            "        [-1.4387,  1.6813, -0.5690],\n",
            "        [-1.7160,  1.8273, -0.2933],\n",
            "        [-1.4425,  1.9205, -0.2908],\n",
            "        [-1.4021,  1.5670, -0.5284],\n",
            "        [-1.6343,  1.6712, -0.1905],\n",
            "        [-2.1158,  0.5497,  0.9505],\n",
            "        [-1.5938,  1.7321, -0.3354],\n",
            "        [-0.1845,  0.8865, -1.0623],\n",
            "        [-1.6176,  0.8472,  0.3905],\n",
            "        [-1.3583,  0.5092,  0.8023]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4133,  1.6596, -0.3949],\n",
            "        [-1.7839,  0.2629,  0.8893],\n",
            "        [-1.4300,  1.3274, -0.0810],\n",
            "        [-1.0885,  1.6198, -0.6863],\n",
            "        [-1.6900,  1.7356, -0.1722],\n",
            "        [-1.5387,  1.4476, -0.1241],\n",
            "        [-1.4387,  1.6813, -0.5690],\n",
            "        [-1.7160,  1.8273, -0.2933],\n",
            "        [-1.4425,  1.9205, -0.2908],\n",
            "        [-1.4021,  1.5670, -0.5284],\n",
            "        [-1.6343,  1.6712, -0.1905],\n",
            "        [-2.1158,  0.5497,  0.9505],\n",
            "        [-1.5938,  1.7321, -0.3354],\n",
            "        [-0.1845,  0.8865, -1.0623],\n",
            "        [-1.6176,  0.8472,  0.3905],\n",
            "        [-1.3583,  0.5092,  0.8023]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7749,  0.6178,  0.9603],\n",
            "        [-1.4125,  1.6145, -0.3236],\n",
            "        [-1.5919,  1.5500, -0.2596],\n",
            "        [-1.6676,  1.7913, -0.2402],\n",
            "        [-1.5689,  2.0776, -0.1194],\n",
            "        [-1.7089,  1.4854, -0.0551],\n",
            "        [ 0.1599,  0.1824, -1.0766],\n",
            "        [-1.6490,  1.6475, -0.2629],\n",
            "        [ 0.4608,  0.2168, -1.1088],\n",
            "        [-1.6369,  1.6123, -0.0284],\n",
            "        [-1.6368,  1.5819, -0.1612],\n",
            "        [-1.8217,  1.8684, -0.3520],\n",
            "        [-1.7617,  1.5577, -0.2171],\n",
            "        [ 0.2156,  0.4056, -0.7950],\n",
            "        [-2.0747,  0.6308,  0.9408],\n",
            "        [-1.4831,  1.5908, -0.1754]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7749,  0.6178,  0.9603],\n",
            "        [-1.4125,  1.6145, -0.3236],\n",
            "        [-1.5919,  1.5500, -0.2596],\n",
            "        [-1.6676,  1.7913, -0.2402],\n",
            "        [-1.5689,  2.0776, -0.1194],\n",
            "        [-1.7089,  1.4854, -0.0551],\n",
            "        [ 0.1599,  0.1824, -1.0766],\n",
            "        [-1.6490,  1.6475, -0.2629],\n",
            "        [ 0.4608,  0.2168, -1.1088],\n",
            "        [-1.6369,  1.6123, -0.0284],\n",
            "        [-1.6368,  1.5819, -0.1612],\n",
            "        [-1.8217,  1.8684, -0.3520],\n",
            "        [-1.7617,  1.5577, -0.2171],\n",
            "        [ 0.2156,  0.4056, -0.7950],\n",
            "        [-2.0747,  0.6308,  0.9408],\n",
            "        [-1.4831,  1.5908, -0.1754]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6584,  1.6088, -0.3080],\n",
            "        [-1.3297,  0.5092,  0.4804],\n",
            "        [-1.7826,  0.4541,  1.0320],\n",
            "        [-1.4458,  0.8597,  0.3731],\n",
            "        [-2.0616,  0.7937,  1.0061],\n",
            "        [-1.5363,  1.4422, -0.2716],\n",
            "        [ 0.1895,  0.2996, -0.9130],\n",
            "        [-1.6231,  1.6624, -0.1033],\n",
            "        [ 0.3128,  0.3744, -1.1827],\n",
            "        [-2.1233,  0.5639,  1.2083],\n",
            "        [-2.1755,  0.6941,  1.2578],\n",
            "        [-1.8867,  0.9439,  0.5380],\n",
            "        [-1.7193,  1.7154, -0.0065],\n",
            "        [-2.1761,  0.6584,  1.1071],\n",
            "        [-1.5858,  1.1711,  0.1404],\n",
            "        [ 0.3667,  0.3173, -1.0987]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6584,  1.6088, -0.3080],\n",
            "        [-1.3297,  0.5092,  0.4804],\n",
            "        [-1.7826,  0.4541,  1.0320],\n",
            "        [-1.4458,  0.8597,  0.3731],\n",
            "        [-2.0616,  0.7937,  1.0061],\n",
            "        [-1.5363,  1.4422, -0.2716],\n",
            "        [ 0.1895,  0.2996, -0.9130],\n",
            "        [-1.6231,  1.6624, -0.1033],\n",
            "        [ 0.3128,  0.3744, -1.1827],\n",
            "        [-2.1233,  0.5639,  1.2083],\n",
            "        [-2.1755,  0.6941,  1.2578],\n",
            "        [-1.8867,  0.9439,  0.5380],\n",
            "        [-1.7193,  1.7154, -0.0065],\n",
            "        [-2.1761,  0.6584,  1.1071],\n",
            "        [-1.5858,  1.1711,  0.1404],\n",
            "        [ 0.3667,  0.3173, -1.0987]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5226,  1.6990, -0.3131],\n",
            "        [-1.7737,  1.2594,  0.0294],\n",
            "        [-1.8912,  0.8030,  0.9040],\n",
            "        [-1.9960,  0.5979,  1.0523],\n",
            "        [-1.5328,  1.6819, -0.2168],\n",
            "        [-1.3318,  1.5911, -0.1872],\n",
            "        [ 0.5139,  0.1784, -1.0318],\n",
            "        [ 0.6523,  0.2571, -1.3126],\n",
            "        [-1.9336,  0.8134,  0.7839],\n",
            "        [-1.6781,  1.4387, -0.1081],\n",
            "        [-1.3243,  1.4392, -0.1401],\n",
            "        [ 0.3812,  0.3659, -1.0786],\n",
            "        [-1.8845,  1.3166,  0.3422],\n",
            "        [-1.8796,  1.7777, -0.0873],\n",
            "        [-0.8028,  0.6444, -0.0352],\n",
            "        [-0.7620,  1.0302, -0.4303]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5226,  1.6990, -0.3131],\n",
            "        [-1.7737,  1.2594,  0.0294],\n",
            "        [-1.8912,  0.8030,  0.9040],\n",
            "        [-1.9960,  0.5979,  1.0523],\n",
            "        [-1.5328,  1.6819, -0.2168],\n",
            "        [-1.3318,  1.5911, -0.1872],\n",
            "        [ 0.5139,  0.1784, -1.0318],\n",
            "        [ 0.6523,  0.2571, -1.3126],\n",
            "        [-1.9336,  0.8134,  0.7839],\n",
            "        [-1.6781,  1.4387, -0.1081],\n",
            "        [-1.3243,  1.4392, -0.1401],\n",
            "        [ 0.3812,  0.3659, -1.0786],\n",
            "        [-1.8845,  1.3166,  0.3422],\n",
            "        [-1.8796,  1.7777, -0.0873],\n",
            "        [-0.8028,  0.6444, -0.0352],\n",
            "        [-0.7620,  1.0302, -0.4303]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6409,  1.0932,  0.2554],\n",
            "        [-2.0153,  1.1669,  0.3659],\n",
            "        [-1.6440,  1.3127,  0.2534],\n",
            "        [-1.4243,  1.5782, -0.2296],\n",
            "        [-1.8886,  1.0381,  0.4651],\n",
            "        [-1.1674,  1.3933, -0.3435],\n",
            "        [-0.9817,  1.2305, -0.3496],\n",
            "        [-2.1864,  1.0754,  0.8946],\n",
            "        [ 0.4759,  0.1817, -1.1806],\n",
            "        [-1.4702,  1.3763, -0.2450],\n",
            "        [-0.5322,  0.7050, -0.3702],\n",
            "        [-1.5595,  1.0329,  0.2866],\n",
            "        [-1.8563,  0.7529,  0.8484],\n",
            "        [-1.3768,  1.4191, -0.1556],\n",
            "        [-1.4915,  1.5852, -0.3943],\n",
            "        [-1.7741,  0.5573,  0.9495]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6409,  1.0932,  0.2554],\n",
            "        [-2.0153,  1.1669,  0.3659],\n",
            "        [-1.6440,  1.3127,  0.2534],\n",
            "        [-1.4243,  1.5782, -0.2296],\n",
            "        [-1.8886,  1.0381,  0.4651],\n",
            "        [-1.1674,  1.3933, -0.3435],\n",
            "        [-0.9817,  1.2305, -0.3496],\n",
            "        [-2.1864,  1.0754,  0.8946],\n",
            "        [ 0.4759,  0.1817, -1.1806],\n",
            "        [-1.4702,  1.3763, -0.2450],\n",
            "        [-0.5322,  0.7050, -0.3702],\n",
            "        [-1.5595,  1.0329,  0.2866],\n",
            "        [-1.8563,  0.7529,  0.8484],\n",
            "        [-1.3768,  1.4191, -0.1556],\n",
            "        [-1.4915,  1.5852, -0.3943],\n",
            "        [-1.7741,  0.5573,  0.9495]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5057,  1.6222, -0.1549],\n",
            "        [-1.5962,  1.6810, -0.2519],\n",
            "        [-1.5641,  1.7952, -0.1669],\n",
            "        [-1.4897,  1.3846, -0.3204],\n",
            "        [-1.9342,  0.5346,  0.9028],\n",
            "        [-1.4156,  1.6692, -0.3037],\n",
            "        [-1.2680,  1.2407, -0.0906],\n",
            "        [-0.3201,  0.8583, -0.8263],\n",
            "        [-1.4351,  1.4439, -0.1499],\n",
            "        [-1.7572,  1.5817, -0.0120],\n",
            "        [-1.9156,  1.5157,  0.2482],\n",
            "        [-1.4668,  1.5758, -0.1564],\n",
            "        [-1.3528,  0.2445,  0.7474],\n",
            "        [-1.6977,  0.3648,  0.8458],\n",
            "        [-1.7918,  0.6333,  0.8127],\n",
            "        [-1.4010,  1.6408, -0.0925]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5057,  1.6222, -0.1549],\n",
            "        [-1.5962,  1.6810, -0.2519],\n",
            "        [-1.5641,  1.7952, -0.1669],\n",
            "        [-1.4897,  1.3846, -0.3204],\n",
            "        [-1.9342,  0.5346,  0.9028],\n",
            "        [-1.4156,  1.6692, -0.3037],\n",
            "        [-1.2680,  1.2407, -0.0906],\n",
            "        [-0.3201,  0.8583, -0.8263],\n",
            "        [-1.4351,  1.4439, -0.1499],\n",
            "        [-1.7572,  1.5817, -0.0120],\n",
            "        [-1.9156,  1.5157,  0.2482],\n",
            "        [-1.4668,  1.5758, -0.1564],\n",
            "        [-1.3528,  0.2445,  0.7474],\n",
            "        [-1.6977,  0.3648,  0.8458],\n",
            "        [-1.7918,  0.6333,  0.8127],\n",
            "        [-1.4010,  1.6408, -0.0925]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6392,  0.4923,  0.6883],\n",
            "        [-1.2847,  1.3454, -0.3098],\n",
            "        [-1.3093,  1.7064, -0.1973],\n",
            "        [-1.6462,  1.2605, -0.3020],\n",
            "        [-1.4103,  1.3081, -0.2198],\n",
            "        [ 0.5344,  0.0832, -1.2216],\n",
            "        [-1.9061,  0.6107,  1.0281],\n",
            "        [-1.3160,  1.4229, -0.2406],\n",
            "        [-1.1587,  1.1506, -0.2376],\n",
            "        [-1.7846,  1.8712, -0.0434],\n",
            "        [-1.9332,  0.4153,  0.8904],\n",
            "        [-1.8246,  1.1633,  0.5156],\n",
            "        [-1.2716,  1.2253, -0.1367],\n",
            "        [-1.5934,  1.1279,  0.3845],\n",
            "        [-1.7594,  0.7434,  0.8337],\n",
            "        [-0.5274,  0.1708, -0.0901]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6392,  0.4923,  0.6883],\n",
            "        [-1.2847,  1.3454, -0.3098],\n",
            "        [-1.3093,  1.7064, -0.1973],\n",
            "        [-1.6462,  1.2605, -0.3020],\n",
            "        [-1.4103,  1.3081, -0.2198],\n",
            "        [ 0.5344,  0.0832, -1.2216],\n",
            "        [-1.9061,  0.6107,  1.0281],\n",
            "        [-1.3160,  1.4229, -0.2406],\n",
            "        [-1.1587,  1.1506, -0.2376],\n",
            "        [-1.7846,  1.8712, -0.0434],\n",
            "        [-1.9332,  0.4153,  0.8904],\n",
            "        [-1.8246,  1.1633,  0.5156],\n",
            "        [-1.2716,  1.2253, -0.1367],\n",
            "        [-1.5934,  1.1279,  0.3845],\n",
            "        [-1.7594,  0.7434,  0.8337],\n",
            "        [-0.5274,  0.1708, -0.0901]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4437,  1.3560, -0.2489],\n",
            "        [-1.8065,  0.6198,  0.5733],\n",
            "        [-1.5098,  1.3405, -0.0547],\n",
            "        [-0.2800,  0.1237, -0.2569],\n",
            "        [-1.8633,  0.5239,  0.8925],\n",
            "        [-1.4925,  1.5025, -0.2089],\n",
            "        [-1.0478,  1.3333, -0.2023],\n",
            "        [-1.8968,  0.5139,  0.8684],\n",
            "        [-1.8727,  0.5127,  0.7088],\n",
            "        [-1.2139,  1.3372, -0.1683],\n",
            "        [-1.8029,  0.8054,  0.7557],\n",
            "        [-1.5923,  1.6061, -0.2191],\n",
            "        [-1.3063,  1.6559, -0.3063],\n",
            "        [-1.1835,  1.4440, -0.4024],\n",
            "        [-1.7999,  0.5407,  0.9703],\n",
            "        [-1.3522,  1.0807, -0.0294]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4437,  1.3560, -0.2489],\n",
            "        [-1.8065,  0.6198,  0.5733],\n",
            "        [-1.5098,  1.3405, -0.0547],\n",
            "        [-0.2800,  0.1237, -0.2569],\n",
            "        [-1.8633,  0.5239,  0.8925],\n",
            "        [-1.4925,  1.5025, -0.2089],\n",
            "        [-1.0478,  1.3333, -0.2023],\n",
            "        [-1.8968,  0.5139,  0.8684],\n",
            "        [-1.8727,  0.5127,  0.7088],\n",
            "        [-1.2139,  1.3372, -0.1683],\n",
            "        [-1.8029,  0.8054,  0.7557],\n",
            "        [-1.5923,  1.6061, -0.2191],\n",
            "        [-1.3063,  1.6559, -0.3063],\n",
            "        [-1.1835,  1.4440, -0.4024],\n",
            "        [-1.7999,  0.5407,  0.9703],\n",
            "        [-1.3522,  1.0807, -0.0294]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3384,  1.4453, -0.2525],\n",
            "        [-1.3669,  1.5851, -0.2582],\n",
            "        [-1.7421,  0.8264,  0.6126],\n",
            "        [-1.0954,  1.4725, -0.5560],\n",
            "        [-1.5078,  1.5734, -0.2983],\n",
            "        [ 0.3398,  0.3861, -1.0986],\n",
            "        [-0.8062,  0.8740, -0.4773],\n",
            "        [-1.2971,  1.4899, -0.2609],\n",
            "        [-1.8674,  0.8729,  0.8869],\n",
            "        [-1.2240,  1.3726, -0.2147],\n",
            "        [-1.7369,  0.4644,  0.7078],\n",
            "        [-1.9703,  0.6510,  0.9024],\n",
            "        [-1.7371,  0.6390,  0.7418],\n",
            "        [-1.2622,  1.4670, -0.2209],\n",
            "        [-0.8750,  1.2593, -0.3883],\n",
            "        [-1.6387,  0.6264,  0.6031]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3384,  1.4453, -0.2525],\n",
            "        [-1.3669,  1.5851, -0.2582],\n",
            "        [-1.7421,  0.8264,  0.6126],\n",
            "        [-1.0954,  1.4725, -0.5560],\n",
            "        [-1.5078,  1.5734, -0.2983],\n",
            "        [ 0.3398,  0.3861, -1.0986],\n",
            "        [-0.8062,  0.8740, -0.4773],\n",
            "        [-1.2971,  1.4899, -0.2609],\n",
            "        [-1.8674,  0.8729,  0.8869],\n",
            "        [-1.2240,  1.3726, -0.2147],\n",
            "        [-1.7369,  0.4644,  0.7078],\n",
            "        [-1.9703,  0.6510,  0.9024],\n",
            "        [-1.7371,  0.6390,  0.7418],\n",
            "        [-1.2622,  1.4670, -0.2209],\n",
            "        [-0.8750,  1.2593, -0.3883],\n",
            "        [-1.6387,  0.6264,  0.6031]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7165,  0.4669,  0.8685],\n",
            "        [-1.2870,  1.5353, -0.3801],\n",
            "        [-1.2202,  1.5077, -0.2578],\n",
            "        [-0.7676,  1.3726, -0.4437],\n",
            "        [-1.4582,  0.3875,  0.7671],\n",
            "        [ 0.5775,  0.1207, -1.0362],\n",
            "        [-1.3550,  1.3933, -0.4495],\n",
            "        [-1.7378,  0.6090,  0.9236],\n",
            "        [-1.6153,  1.6303, -0.1672],\n",
            "        [-2.0641,  0.6592,  0.9689],\n",
            "        [-1.3117,  1.4334, -0.0810],\n",
            "        [-1.7375,  0.6079,  0.7219],\n",
            "        [-1.5524,  1.5711, -0.1761],\n",
            "        [-1.9808,  0.6645,  0.8695],\n",
            "        [-1.6618,  1.1715,  0.1338],\n",
            "        [-1.2592,  1.3824, -0.0662]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7165,  0.4669,  0.8685],\n",
            "        [-1.2870,  1.5353, -0.3801],\n",
            "        [-1.2202,  1.5077, -0.2578],\n",
            "        [-0.7676,  1.3726, -0.4437],\n",
            "        [-1.4582,  0.3875,  0.7671],\n",
            "        [ 0.5775,  0.1207, -1.0362],\n",
            "        [-1.3550,  1.3933, -0.4495],\n",
            "        [-1.7378,  0.6090,  0.9236],\n",
            "        [-1.6153,  1.6303, -0.1672],\n",
            "        [-2.0641,  0.6592,  0.9689],\n",
            "        [-1.3117,  1.4334, -0.0810],\n",
            "        [-1.7375,  0.6079,  0.7219],\n",
            "        [-1.5524,  1.5711, -0.1761],\n",
            "        [-1.9808,  0.6645,  0.8695],\n",
            "        [-1.6618,  1.1715,  0.1338],\n",
            "        [-1.2592,  1.3824, -0.0662]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3252,  1.1344,  0.1296],\n",
            "        [-1.0690,  1.4454, -0.3808],\n",
            "        [-1.2709,  1.4083, -0.3625],\n",
            "        [-1.4194,  1.4355, -0.0227],\n",
            "        [-1.1385,  0.2402,  0.5316],\n",
            "        [-1.3813,  1.6067, -0.2593],\n",
            "        [-1.4763,  1.3743, -0.0709],\n",
            "        [-1.8086,  0.5308,  0.8966],\n",
            "        [-1.3914,  1.3302, -0.0464],\n",
            "        [-1.3756,  0.5768,  0.6808],\n",
            "        [-1.8366,  0.6705,  0.9570],\n",
            "        [ 0.3381,  0.0789, -0.8669],\n",
            "        [-1.6833,  0.9733,  0.4992],\n",
            "        [-1.2784,  1.4184, -0.4255],\n",
            "        [-1.2867,  1.4889, -0.3008],\n",
            "        [-1.2164,  1.1570, -0.2877]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3252,  1.1344,  0.1296],\n",
            "        [-1.0690,  1.4454, -0.3808],\n",
            "        [-1.2709,  1.4083, -0.3625],\n",
            "        [-1.4194,  1.4355, -0.0227],\n",
            "        [-1.1385,  0.2402,  0.5316],\n",
            "        [-1.3813,  1.6067, -0.2593],\n",
            "        [-1.4763,  1.3743, -0.0709],\n",
            "        [-1.8086,  0.5308,  0.8966],\n",
            "        [-1.3914,  1.3302, -0.0464],\n",
            "        [-1.3756,  0.5768,  0.6808],\n",
            "        [-1.8366,  0.6705,  0.9570],\n",
            "        [ 0.3381,  0.0789, -0.8669],\n",
            "        [-1.6833,  0.9733,  0.4992],\n",
            "        [-1.2784,  1.4184, -0.4255],\n",
            "        [-1.2867,  1.4889, -0.3008],\n",
            "        [-1.2164,  1.1570, -0.2877]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6553,  0.5600,  0.9343],\n",
            "        [-1.2129,  1.3475, -0.3237],\n",
            "        [-1.2666,  1.4012, -0.2809],\n",
            "        [-1.6561,  0.4751,  0.8970],\n",
            "        [-1.6707,  0.6403,  0.6158],\n",
            "        [-1.2045,  1.3794,  0.0498],\n",
            "        [ 0.2163,  0.2187, -0.8174],\n",
            "        [-1.6787,  0.4643,  0.9444],\n",
            "        [ 0.3211,  0.1292, -0.7211],\n",
            "        [-1.1591,  1.2641, -0.3136],\n",
            "        [ 0.1868,  0.4068, -0.8974],\n",
            "        [-1.5392,  1.3336, -0.1661],\n",
            "        [-1.6522,  0.3747,  0.8333],\n",
            "        [-1.0099,  1.1073, -0.3873],\n",
            "        [-1.2987,  1.4057, -0.2878],\n",
            "        [-1.5299,  1.0563,  0.0686]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6553,  0.5600,  0.9343],\n",
            "        [-1.2129,  1.3475, -0.3237],\n",
            "        [-1.2666,  1.4012, -0.2809],\n",
            "        [-1.6561,  0.4751,  0.8970],\n",
            "        [-1.6707,  0.6403,  0.6158],\n",
            "        [-1.2045,  1.3794,  0.0498],\n",
            "        [ 0.2163,  0.2187, -0.8174],\n",
            "        [-1.6787,  0.4643,  0.9444],\n",
            "        [ 0.3211,  0.1292, -0.7211],\n",
            "        [-1.1591,  1.2641, -0.3136],\n",
            "        [ 0.1868,  0.4068, -0.8974],\n",
            "        [-1.5392,  1.3336, -0.1661],\n",
            "        [-1.6522,  0.3747,  0.8333],\n",
            "        [-1.0099,  1.1073, -0.3873],\n",
            "        [-1.2987,  1.4057, -0.2878],\n",
            "        [-1.5299,  1.0563,  0.0686]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4162,  0.8245,  0.3071],\n",
            "        [-1.4522,  1.4889, -0.3801],\n",
            "        [-1.2054,  1.1950, -0.2006],\n",
            "        [-1.4070,  1.3100, -0.3265],\n",
            "        [-1.3087,  1.5889, -0.6150],\n",
            "        [-1.6639,  0.4200,  0.8646],\n",
            "        [-1.1911,  1.5679, -0.4181],\n",
            "        [-1.5966,  0.5384,  0.6229],\n",
            "        [-1.2914,  1.3960, -0.2165],\n",
            "        [-1.6777,  1.5752,  0.0263],\n",
            "        [-1.0578,  1.1712, -0.4673],\n",
            "        [-1.0145,  1.4913, -0.4457],\n",
            "        [-1.6682,  0.3592,  0.9296],\n",
            "        [-1.7549,  0.5469,  0.6255],\n",
            "        [-0.6349,  0.9815, -0.6660],\n",
            "        [-1.1604,  1.3152, -0.3413]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4162,  0.8245,  0.3071],\n",
            "        [-1.4522,  1.4889, -0.3801],\n",
            "        [-1.2054,  1.1950, -0.2006],\n",
            "        [-1.4070,  1.3100, -0.3265],\n",
            "        [-1.3087,  1.5889, -0.6150],\n",
            "        [-1.6639,  0.4200,  0.8646],\n",
            "        [-1.1911,  1.5679, -0.4181],\n",
            "        [-1.5966,  0.5384,  0.6229],\n",
            "        [-1.2914,  1.3960, -0.2165],\n",
            "        [-1.6777,  1.5752,  0.0263],\n",
            "        [-1.0578,  1.1712, -0.4673],\n",
            "        [-1.0145,  1.4913, -0.4457],\n",
            "        [-1.6682,  0.3592,  0.9296],\n",
            "        [-1.7549,  0.5469,  0.6255],\n",
            "        [-0.6349,  0.9815, -0.6660],\n",
            "        [-1.1604,  1.3152, -0.3413]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7338,  1.0017,  0.2777],\n",
            "        [-1.2687,  1.4505, -0.3509],\n",
            "        [-1.2222,  1.3598, -0.1214],\n",
            "        [-1.9011,  0.7310,  0.8012],\n",
            "        [-1.9262,  0.4412,  1.0473],\n",
            "        [-1.1267,  1.3283, -0.3704],\n",
            "        [-1.5651,  0.3690,  0.8685],\n",
            "        [-1.4412,  0.9942,  0.3080],\n",
            "        [-1.7684,  1.1913,  0.4152],\n",
            "        [-1.3384,  1.5863, -0.4633],\n",
            "        [-1.2022,  1.5680, -0.4444],\n",
            "        [-1.1150,  1.6209, -0.3880],\n",
            "        [-1.4438,  1.5482, -0.3233],\n",
            "        [-0.9089,  0.4422,  0.2168],\n",
            "        [-1.1470,  1.6085, -0.4459],\n",
            "        [-0.7288,  0.3214, -0.0047]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7338,  1.0017,  0.2777],\n",
            "        [-1.2687,  1.4505, -0.3509],\n",
            "        [-1.2222,  1.3598, -0.1214],\n",
            "        [-1.9011,  0.7310,  0.8012],\n",
            "        [-1.9262,  0.4412,  1.0473],\n",
            "        [-1.1267,  1.3283, -0.3704],\n",
            "        [-1.5651,  0.3690,  0.8685],\n",
            "        [-1.4412,  0.9942,  0.3080],\n",
            "        [-1.7684,  1.1913,  0.4152],\n",
            "        [-1.3384,  1.5863, -0.4633],\n",
            "        [-1.2022,  1.5680, -0.4444],\n",
            "        [-1.1150,  1.6209, -0.3880],\n",
            "        [-1.4438,  1.5482, -0.3233],\n",
            "        [-0.9089,  0.4422,  0.2168],\n",
            "        [-1.1470,  1.6085, -0.4459],\n",
            "        [-0.7288,  0.3214, -0.0047]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2777,  1.5666, -0.5149],\n",
            "        [-1.6756,  0.4372,  0.8902],\n",
            "        [-0.1354,  0.0816, -0.1787],\n",
            "        [-2.0697,  0.8405,  0.9237],\n",
            "        [-1.3809,  1.7105, -0.5614],\n",
            "        [-1.3589,  1.6115, -0.2560],\n",
            "        [ 0.6774,  0.1162, -1.0700],\n",
            "        [-1.6213,  0.5704,  0.8143],\n",
            "        [-1.5441,  1.5724, -0.2635],\n",
            "        [-1.4391,  1.3884, -0.2778],\n",
            "        [-0.9926,  1.3918, -0.4085],\n",
            "        [-0.5224,  0.1735,  0.1598],\n",
            "        [-1.7275,  0.7343,  0.8724],\n",
            "        [-1.2689,  1.2698, -0.5527],\n",
            "        [-1.4468,  0.8530,  0.3440],\n",
            "        [-1.2855,  1.6418, -0.4661]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2777,  1.5666, -0.5149],\n",
            "        [-1.6756,  0.4372,  0.8902],\n",
            "        [-0.1354,  0.0816, -0.1787],\n",
            "        [-2.0697,  0.8405,  0.9237],\n",
            "        [-1.3809,  1.7105, -0.5614],\n",
            "        [-1.3589,  1.6115, -0.2560],\n",
            "        [ 0.6774,  0.1162, -1.0700],\n",
            "        [-1.6213,  0.5704,  0.8143],\n",
            "        [-1.5441,  1.5724, -0.2635],\n",
            "        [-1.4391,  1.3884, -0.2778],\n",
            "        [-0.9926,  1.3918, -0.4085],\n",
            "        [-0.5224,  0.1735,  0.1598],\n",
            "        [-1.7275,  0.7343,  0.8724],\n",
            "        [-1.2689,  1.2698, -0.5527],\n",
            "        [-1.4468,  0.8530,  0.3440],\n",
            "        [-1.2855,  1.6418, -0.4661]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3010,  0.9237,  0.1583],\n",
            "        [-1.6058,  0.4519,  0.9583],\n",
            "        [-1.4956,  1.3421,  0.0587],\n",
            "        [ 0.5144,  0.1394, -1.1256],\n",
            "        [-1.6494,  0.4116,  1.0284],\n",
            "        [ 0.2656,  0.0427, -0.7772],\n",
            "        [ 0.5810,  0.1777, -1.0311],\n",
            "        [-0.6948,  1.5690, -0.5836],\n",
            "        [-1.3742,  1.1404, -0.2193],\n",
            "        [-1.4609,  1.6326, -0.3043],\n",
            "        [-1.5178,  1.8934, -0.2118],\n",
            "        [-1.1849,  1.5467, -0.5277],\n",
            "        [-1.1470,  1.5686, -0.3780],\n",
            "        [-1.8153,  0.5976,  0.8733],\n",
            "        [-1.0243,  0.1612,  0.5777],\n",
            "        [-1.7996,  0.4581,  1.0171]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3010,  0.9237,  0.1583],\n",
            "        [-1.6058,  0.4519,  0.9583],\n",
            "        [-1.4956,  1.3421,  0.0587],\n",
            "        [ 0.5144,  0.1394, -1.1256],\n",
            "        [-1.6494,  0.4116,  1.0284],\n",
            "        [ 0.2656,  0.0427, -0.7772],\n",
            "        [ 0.5810,  0.1777, -1.0311],\n",
            "        [-0.6948,  1.5690, -0.5836],\n",
            "        [-1.3742,  1.1404, -0.2193],\n",
            "        [-1.4609,  1.6326, -0.3043],\n",
            "        [-1.5178,  1.8934, -0.2118],\n",
            "        [-1.1849,  1.5467, -0.5277],\n",
            "        [-1.1470,  1.5686, -0.3780],\n",
            "        [-1.8153,  0.5976,  0.8733],\n",
            "        [-1.0243,  0.1612,  0.5777],\n",
            "        [-1.7996,  0.4581,  1.0171]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5865,  0.0173, -0.9571],\n",
            "        [-1.6557,  0.9550,  0.4989],\n",
            "        [-1.3769,  1.6764, -0.5493],\n",
            "        [-1.4437,  0.1680,  0.7862],\n",
            "        [-0.9985,  1.5833, -0.5735],\n",
            "        [-1.2326,  1.6610, -0.6965],\n",
            "        [-1.6006,  0.3991,  0.8745],\n",
            "        [-1.3611,  1.3848, -0.0407],\n",
            "        [-1.4884,  1.4120, -0.4105],\n",
            "        [ 0.6514,  0.0659, -1.0071],\n",
            "        [-1.7688,  0.4451,  0.8208],\n",
            "        [-0.5247,  0.2670, -0.0879],\n",
            "        [-0.0573,  0.2299, -0.5329],\n",
            "        [-1.2356,  1.5928, -0.4616],\n",
            "        [ 0.4621, -0.0424, -1.0814],\n",
            "        [-1.2508,  1.6145, -0.4643]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.5865,  0.0173, -0.9571],\n",
            "        [-1.6557,  0.9550,  0.4989],\n",
            "        [-1.3769,  1.6764, -0.5493],\n",
            "        [-1.4437,  0.1680,  0.7862],\n",
            "        [-0.9985,  1.5833, -0.5735],\n",
            "        [-1.2326,  1.6610, -0.6965],\n",
            "        [-1.6006,  0.3991,  0.8745],\n",
            "        [-1.3611,  1.3848, -0.0407],\n",
            "        [-1.4884,  1.4120, -0.4105],\n",
            "        [ 0.6514,  0.0659, -1.0071],\n",
            "        [-1.7688,  0.4451,  0.8208],\n",
            "        [-0.5247,  0.2670, -0.0879],\n",
            "        [-0.0573,  0.2299, -0.5329],\n",
            "        [-1.2356,  1.5928, -0.4616],\n",
            "        [ 0.4621, -0.0424, -1.0814],\n",
            "        [-1.2508,  1.6145, -0.4643]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2063,  1.5420, -0.5989],\n",
            "        [ 0.2043,  0.3591, -1.0806],\n",
            "        [-1.1856,  1.5653, -0.4957],\n",
            "        [-1.2126,  1.5946, -0.3564],\n",
            "        [-1.5954,  0.5039,  0.8925],\n",
            "        [-1.3961,  1.5694, -0.5244],\n",
            "        [ 0.4304,  0.3210, -0.9666],\n",
            "        [-1.2945,  1.4977, -0.5712],\n",
            "        [-1.9245,  0.7195,  0.9623],\n",
            "        [-1.2788,  1.6565, -0.6031],\n",
            "        [ 0.6287,  0.1748, -0.9595],\n",
            "        [-1.1988,  1.7105, -0.5364],\n",
            "        [-1.2543,  1.7071, -0.3481],\n",
            "        [-1.2150,  1.6379, -0.3651],\n",
            "        [-1.7811,  0.5559,  0.8047],\n",
            "        [ 0.5585,  0.1636, -1.0655]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2063,  1.5420, -0.5989],\n",
            "        [ 0.2043,  0.3591, -1.0806],\n",
            "        [-1.1856,  1.5653, -0.4957],\n",
            "        [-1.2126,  1.5946, -0.3564],\n",
            "        [-1.5954,  0.5039,  0.8925],\n",
            "        [-1.3961,  1.5694, -0.5244],\n",
            "        [ 0.4304,  0.3210, -0.9666],\n",
            "        [-1.2945,  1.4977, -0.5712],\n",
            "        [-1.9245,  0.7195,  0.9623],\n",
            "        [-1.2788,  1.6565, -0.6031],\n",
            "        [ 0.6287,  0.1748, -0.9595],\n",
            "        [-1.1988,  1.7105, -0.5364],\n",
            "        [-1.2543,  1.7071, -0.3481],\n",
            "        [-1.2150,  1.6379, -0.3651],\n",
            "        [-1.7811,  0.5559,  0.8047],\n",
            "        [ 0.5585,  0.1636, -1.0655]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6682,  0.7060,  0.7074],\n",
            "        [-1.6583,  0.4277,  0.8658],\n",
            "        [-1.2912,  1.9062, -0.6273],\n",
            "        [ 0.1211, -0.0057, -0.5869],\n",
            "        [-1.2931,  1.6365, -0.6784],\n",
            "        [ 0.3018,  0.5056, -1.0874],\n",
            "        [-1.0451,  1.4526, -0.5594],\n",
            "        [-1.1258,  1.6976, -0.6921],\n",
            "        [-1.3876,  0.3697,  0.8752],\n",
            "        [-0.6324,  1.2599, -0.9372],\n",
            "        [-0.6289,  1.2685, -0.9734],\n",
            "        [-1.2832,  1.6339, -0.3284],\n",
            "        [-1.4236,  1.9067, -0.4098],\n",
            "        [-1.5055,  0.4412,  0.9168],\n",
            "        [-1.0687,  1.7557, -0.7018],\n",
            "        [-1.4991,  1.1816, -0.1834]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6682,  0.7060,  0.7074],\n",
            "        [-1.6583,  0.4277,  0.8658],\n",
            "        [-1.2912,  1.9062, -0.6273],\n",
            "        [ 0.1211, -0.0057, -0.5869],\n",
            "        [-1.2931,  1.6365, -0.6784],\n",
            "        [ 0.3018,  0.5056, -1.0874],\n",
            "        [-1.0451,  1.4526, -0.5594],\n",
            "        [-1.1258,  1.6976, -0.6921],\n",
            "        [-1.3876,  0.3697,  0.8752],\n",
            "        [-0.6324,  1.2599, -0.9372],\n",
            "        [-0.6289,  1.2685, -0.9734],\n",
            "        [-1.2832,  1.6339, -0.3284],\n",
            "        [-1.4236,  1.9067, -0.4098],\n",
            "        [-1.5055,  0.4412,  0.9168],\n",
            "        [-1.0687,  1.7557, -0.7018],\n",
            "        [-1.4991,  1.1816, -0.1834]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.1184,  1.4366, -0.5725],\n",
            "        [-1.6252,  0.8228,  0.4149],\n",
            "        [-0.9605,  1.3866, -0.8052],\n",
            "        [-1.0323,  1.5955, -0.7175],\n",
            "        [-1.3169,  1.7162, -0.6618],\n",
            "        [-1.3698,  1.5812, -0.5145],\n",
            "        [-1.0911,  1.6999, -0.6087],\n",
            "        [-1.6903,  1.0873,  0.2165],\n",
            "        [ 0.6557,  0.0639, -1.2224],\n",
            "        [-1.8630,  0.8018,  0.6773],\n",
            "        [-1.1502,  1.6838, -0.4790],\n",
            "        [-1.8053,  1.9412, -0.1781],\n",
            "        [ 0.6628, -0.0054, -1.0280],\n",
            "        [-1.2142,  1.7892, -0.5477],\n",
            "        [-1.2567,  1.8931, -0.7826],\n",
            "        [-1.4032,  0.4738,  0.5284]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.1184,  1.4366, -0.5725],\n",
            "        [-1.6252,  0.8228,  0.4149],\n",
            "        [-0.9605,  1.3866, -0.8052],\n",
            "        [-1.0323,  1.5955, -0.7175],\n",
            "        [-1.3169,  1.7162, -0.6618],\n",
            "        [-1.3698,  1.5812, -0.5145],\n",
            "        [-1.0911,  1.6999, -0.6087],\n",
            "        [-1.6903,  1.0873,  0.2165],\n",
            "        [ 0.6557,  0.0639, -1.2224],\n",
            "        [-1.8630,  0.8018,  0.6773],\n",
            "        [-1.1502,  1.6838, -0.4790],\n",
            "        [-1.8053,  1.9412, -0.1781],\n",
            "        [ 0.6628, -0.0054, -1.0280],\n",
            "        [-1.2142,  1.7892, -0.5477],\n",
            "        [-1.2567,  1.8931, -0.7826],\n",
            "        [-1.4032,  0.4738,  0.5284]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4829e+00,  1.3837e+00,  9.2623e-02],\n",
            "        [-1.1813e+00,  1.7342e+00, -3.6067e-01],\n",
            "        [-1.1541e+00,  1.7156e+00, -6.1222e-01],\n",
            "        [-5.5024e-05,  7.0478e-02, -3.4514e-01],\n",
            "        [-1.4998e+00,  5.3871e-01,  6.9909e-01],\n",
            "        [-1.1841e+00,  1.6214e+00, -7.3670e-01],\n",
            "        [-9.7702e-01,  1.5412e+00, -6.5792e-01],\n",
            "        [-1.8170e+00,  6.7715e-01,  6.6417e-01],\n",
            "        [-1.8467e+00,  9.0383e-01,  3.5099e-01],\n",
            "        [-1.1838e+00,  1.4736e+00, -4.5544e-01],\n",
            "        [-1.4058e+00,  1.7171e+00, -5.0132e-01],\n",
            "        [ 5.8421e-01,  5.8477e-02, -1.1578e+00],\n",
            "        [-1.2953e+00,  1.7878e+00, -6.7615e-01],\n",
            "        [-1.4467e+00,  3.7961e-01,  7.7286e-01],\n",
            "        [-1.1181e+00,  1.5535e+00, -6.7502e-01],\n",
            "        [-1.5508e+00,  2.6167e-01,  9.3949e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4829e+00,  1.3837e+00,  9.2623e-02],\n",
            "        [-1.1813e+00,  1.7342e+00, -3.6067e-01],\n",
            "        [-1.1541e+00,  1.7156e+00, -6.1222e-01],\n",
            "        [-5.5024e-05,  7.0478e-02, -3.4514e-01],\n",
            "        [-1.4998e+00,  5.3871e-01,  6.9909e-01],\n",
            "        [-1.1841e+00,  1.6214e+00, -7.3670e-01],\n",
            "        [-9.7702e-01,  1.5412e+00, -6.5792e-01],\n",
            "        [-1.8170e+00,  6.7715e-01,  6.6417e-01],\n",
            "        [-1.8467e+00,  9.0383e-01,  3.5099e-01],\n",
            "        [-1.1838e+00,  1.4736e+00, -4.5544e-01],\n",
            "        [-1.4058e+00,  1.7171e+00, -5.0132e-01],\n",
            "        [ 5.8421e-01,  5.8477e-02, -1.1578e+00],\n",
            "        [-1.2953e+00,  1.7878e+00, -6.7615e-01],\n",
            "        [-1.4467e+00,  3.7961e-01,  7.7286e-01],\n",
            "        [-1.1181e+00,  1.5535e+00, -6.7502e-01],\n",
            "        [-1.5508e+00,  2.6167e-01,  9.3949e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.1829,  2.0652, -0.7652],\n",
            "        [-1.7004,  0.7567,  0.5977],\n",
            "        [-1.2492,  1.7770, -0.5560],\n",
            "        [-1.0210,  1.6470, -0.7751],\n",
            "        [-0.4064,  0.1964,  0.0066],\n",
            "        [-1.0398,  1.2992, -0.7337],\n",
            "        [ 0.5706,  0.2618, -1.0155],\n",
            "        [-1.1878,  1.6657, -0.5378],\n",
            "        [ 0.4243,  0.2689, -0.9712],\n",
            "        [-1.4050,  0.3534,  0.9169],\n",
            "        [-0.5823,  0.1251,  0.0118],\n",
            "        [-1.1862,  1.8853, -0.8158],\n",
            "        [-1.7349,  0.3718,  0.8943],\n",
            "        [-1.3791,  1.7757, -0.6337],\n",
            "        [-1.2653,  1.7221, -0.6424],\n",
            "        [-1.0777,  1.6373, -0.8314]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.1829,  2.0652, -0.7652],\n",
            "        [-1.7004,  0.7567,  0.5977],\n",
            "        [-1.2492,  1.7770, -0.5560],\n",
            "        [-1.0210,  1.6470, -0.7751],\n",
            "        [-0.4064,  0.1964,  0.0066],\n",
            "        [-1.0398,  1.2992, -0.7337],\n",
            "        [ 0.5706,  0.2618, -1.0155],\n",
            "        [-1.1878,  1.6657, -0.5378],\n",
            "        [ 0.4243,  0.2689, -0.9712],\n",
            "        [-1.4050,  0.3534,  0.9169],\n",
            "        [-0.5823,  0.1251,  0.0118],\n",
            "        [-1.1862,  1.8853, -0.8158],\n",
            "        [-1.7349,  0.3718,  0.8943],\n",
            "        [-1.3791,  1.7757, -0.6337],\n",
            "        [-1.2653,  1.7221, -0.6424],\n",
            "        [-1.0777,  1.6373, -0.8314]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3963,  1.6937, -0.4786],\n",
            "        [-1.2720,  1.6972, -0.8072],\n",
            "        [ 0.5889,  0.1620, -1.1160],\n",
            "        [ 0.7003,  0.0531, -1.0811],\n",
            "        [-1.3386,  1.9066, -0.4617],\n",
            "        [-0.7710,  1.3426, -0.7534],\n",
            "        [-0.9155,  0.1608,  0.6358],\n",
            "        [-1.0939,  1.4675, -0.4261],\n",
            "        [-1.5049,  1.8916, -0.7414],\n",
            "        [-0.1352,  0.6390, -0.8277],\n",
            "        [-1.0792,  1.5769, -0.6328],\n",
            "        [-0.9432,  1.7735, -0.8190],\n",
            "        [-1.0967,  1.8134, -0.7727],\n",
            "        [-1.6324,  0.9693,  0.4655],\n",
            "        [-1.0463,  1.4376, -0.7265],\n",
            "        [-1.1887,  1.6480, -0.6281]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3963,  1.6937, -0.4786],\n",
            "        [-1.2720,  1.6972, -0.8072],\n",
            "        [ 0.5889,  0.1620, -1.1160],\n",
            "        [ 0.7003,  0.0531, -1.0811],\n",
            "        [-1.3386,  1.9066, -0.4617],\n",
            "        [-0.7710,  1.3426, -0.7534],\n",
            "        [-0.9155,  0.1608,  0.6358],\n",
            "        [-1.0939,  1.4675, -0.4261],\n",
            "        [-1.5049,  1.8916, -0.7414],\n",
            "        [-0.1352,  0.6390, -0.8277],\n",
            "        [-1.0792,  1.5769, -0.6328],\n",
            "        [-0.9432,  1.7735, -0.8190],\n",
            "        [-1.0967,  1.8134, -0.7727],\n",
            "        [-1.6324,  0.9693,  0.4655],\n",
            "        [-1.0463,  1.4376, -0.7265],\n",
            "        [-1.1887,  1.6480, -0.6281]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.1040,  1.7815, -0.9178],\n",
            "        [-1.1370,  1.7505, -0.7701],\n",
            "        [-1.4488,  1.8623, -0.6352],\n",
            "        [-1.3521,  1.7729, -0.6374],\n",
            "        [-1.2255,  1.3650, -0.2342],\n",
            "        [-0.3538,  0.8954, -0.8368],\n",
            "        [-1.3406,  1.9200, -0.6610],\n",
            "        [-1.3014,  1.6122, -0.2861],\n",
            "        [-1.1559,  1.7659, -0.7762],\n",
            "        [-1.0683,  1.3086, -0.6208],\n",
            "        [-1.2982,  1.4995, -0.4151],\n",
            "        [-1.6683,  0.5448,  0.7751],\n",
            "        [-0.2771,  0.8158, -1.1241],\n",
            "        [-1.7701,  0.2957,  0.9552],\n",
            "        [-1.3372,  1.7932, -0.6258],\n",
            "        [-0.5225,  1.0750, -0.4636]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.1040,  1.7815, -0.9178],\n",
            "        [-1.1370,  1.7505, -0.7701],\n",
            "        [-1.4488,  1.8623, -0.6352],\n",
            "        [-1.3521,  1.7729, -0.6374],\n",
            "        [-1.2255,  1.3650, -0.2342],\n",
            "        [-0.3538,  0.8954, -0.8368],\n",
            "        [-1.3406,  1.9200, -0.6610],\n",
            "        [-1.3014,  1.6122, -0.2861],\n",
            "        [-1.1559,  1.7659, -0.7762],\n",
            "        [-1.0683,  1.3086, -0.6208],\n",
            "        [-1.2982,  1.4995, -0.4151],\n",
            "        [-1.6683,  0.5448,  0.7751],\n",
            "        [-0.2771,  0.8158, -1.1241],\n",
            "        [-1.7701,  0.2957,  0.9552],\n",
            "        [-1.3372,  1.7932, -0.6258],\n",
            "        [-0.5225,  1.0750, -0.4636]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4197,  1.6995, -0.7205],\n",
            "        [-1.5412,  0.2465,  0.9100],\n",
            "        [-1.4946,  1.8691, -0.6567],\n",
            "        [ 0.7461,  0.0139, -1.1915],\n",
            "        [-0.9846,  1.6620, -0.7297],\n",
            "        [-1.1372,  1.7576, -0.6601],\n",
            "        [-1.3863,  1.9451, -0.6520],\n",
            "        [-1.3680,  0.6978,  0.2598],\n",
            "        [-1.3870,  1.8603, -0.7231],\n",
            "        [-1.2802,  1.6238, -0.4697],\n",
            "        [-1.3185, -0.0108,  1.0924],\n",
            "        [-1.1466,  1.9015, -0.7414],\n",
            "        [-1.6601,  0.6567,  0.6507],\n",
            "        [-1.2854,  1.5554, -0.4853],\n",
            "        [-1.5139,  0.1993,  0.9920],\n",
            "        [-1.6356,  0.4161,  0.9525]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4197,  1.6995, -0.7205],\n",
            "        [-1.5412,  0.2465,  0.9100],\n",
            "        [-1.4946,  1.8691, -0.6567],\n",
            "        [ 0.7461,  0.0139, -1.1915],\n",
            "        [-0.9846,  1.6620, -0.7297],\n",
            "        [-1.1372,  1.7576, -0.6601],\n",
            "        [-1.3863,  1.9451, -0.6520],\n",
            "        [-1.3680,  0.6978,  0.2598],\n",
            "        [-1.3870,  1.8603, -0.7231],\n",
            "        [-1.2802,  1.6238, -0.4697],\n",
            "        [-1.3185, -0.0108,  1.0924],\n",
            "        [-1.1466,  1.9015, -0.7414],\n",
            "        [-1.6601,  0.6567,  0.6507],\n",
            "        [-1.2854,  1.5554, -0.4853],\n",
            "        [-1.5139,  0.1993,  0.9920],\n",
            "        [-1.6356,  0.4161,  0.9525]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.0821,  1.7648, -0.6472],\n",
            "        [-1.7319,  0.2912,  1.1081],\n",
            "        [-1.2371,  1.7870, -0.8052],\n",
            "        [-1.2444,  1.8543, -0.3605],\n",
            "        [-0.8246,  1.7386, -0.5907],\n",
            "        [-1.2375,  1.6149, -0.2249],\n",
            "        [-1.7816,  0.5708,  0.8969],\n",
            "        [ 0.2632,  0.0784, -0.7399],\n",
            "        [-1.6520,  0.2283,  1.1385],\n",
            "        [-1.2593,  2.0137, -0.7254],\n",
            "        [-1.7676,  1.3370,  0.2173],\n",
            "        [-1.3809,  1.9181, -0.4661],\n",
            "        [-1.2931,  1.6250, -0.1639],\n",
            "        [-1.2422,  1.3411, -0.3836],\n",
            "        [-1.5257,  1.8530, -0.6771],\n",
            "        [-1.7091,  0.2674,  0.9723]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.0821,  1.7648, -0.6472],\n",
            "        [-1.7319,  0.2912,  1.1081],\n",
            "        [-1.2371,  1.7870, -0.8052],\n",
            "        [-1.2444,  1.8543, -0.3605],\n",
            "        [-0.8246,  1.7386, -0.5907],\n",
            "        [-1.2375,  1.6149, -0.2249],\n",
            "        [-1.7816,  0.5708,  0.8969],\n",
            "        [ 0.2632,  0.0784, -0.7399],\n",
            "        [-1.6520,  0.2283,  1.1385],\n",
            "        [-1.2593,  2.0137, -0.7254],\n",
            "        [-1.7676,  1.3370,  0.2173],\n",
            "        [-1.3809,  1.9181, -0.4661],\n",
            "        [-1.2931,  1.6250, -0.1639],\n",
            "        [-1.2422,  1.3411, -0.3836],\n",
            "        [-1.5257,  1.8530, -0.6771],\n",
            "        [-1.7091,  0.2674,  0.9723]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5255,  0.1166, -0.8160],\n",
            "        [-1.6735,  1.3551, -0.0516],\n",
            "        [-1.3214,  1.7702, -0.4983],\n",
            "        [-1.0212,  1.4224, -0.6585],\n",
            "        [-1.5200,  1.3293, -0.0516],\n",
            "        [-2.0124,  0.4838,  1.1289],\n",
            "        [-1.3512,  1.8545, -0.7062],\n",
            "        [-0.8659,  1.6707, -0.5836],\n",
            "        [-1.6338,  1.0187,  0.3713],\n",
            "        [-0.9101,  1.5096, -0.2792],\n",
            "        [ 0.2031, -0.0506, -0.5014],\n",
            "        [-1.1694,  1.7197, -0.7184],\n",
            "        [-1.4578,  0.0255,  1.0361],\n",
            "        [-1.3143,  1.6313, -0.5368],\n",
            "        [ 0.7223,  0.1016, -0.9507],\n",
            "        [-1.4729,  1.7734, -0.4096]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.5255,  0.1166, -0.8160],\n",
            "        [-1.6735,  1.3551, -0.0516],\n",
            "        [-1.3214,  1.7702, -0.4983],\n",
            "        [-1.0212,  1.4224, -0.6585],\n",
            "        [-1.5200,  1.3293, -0.0516],\n",
            "        [-2.0124,  0.4838,  1.1289],\n",
            "        [-1.3512,  1.8545, -0.7062],\n",
            "        [-0.8659,  1.6707, -0.5836],\n",
            "        [-1.6338,  1.0187,  0.3713],\n",
            "        [-0.9101,  1.5096, -0.2792],\n",
            "        [ 0.2031, -0.0506, -0.5014],\n",
            "        [-1.1694,  1.7197, -0.7184],\n",
            "        [-1.4578,  0.0255,  1.0361],\n",
            "        [-1.3143,  1.6313, -0.5368],\n",
            "        [ 0.7223,  0.1016, -0.9507],\n",
            "        [-1.4729,  1.7734, -0.4096]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3635,  0.4710,  1.1305],\n",
            "        [ 0.4720, -0.0353, -1.0844],\n",
            "        [-2.0076,  1.1181,  0.4492],\n",
            "        [-1.5661,  1.8401, -0.4462],\n",
            "        [-1.2846,  1.6455, -0.5859],\n",
            "        [-1.3760,  0.1467,  1.0058],\n",
            "        [-1.7391,  0.1021,  1.0195],\n",
            "        [-1.8590,  0.0386,  1.1714],\n",
            "        [-0.6849,  1.1446, -0.7012],\n",
            "        [-1.5077,  0.0825,  0.8979],\n",
            "        [-1.1984,  1.7667, -0.6896],\n",
            "        [-1.0165,  1.5619, -0.5715],\n",
            "        [-1.4516,  1.9457, -0.5288],\n",
            "        [-1.6323,  0.1336,  1.0451],\n",
            "        [ 0.7700,  0.0092, -0.9275],\n",
            "        [-1.3483,  2.0346, -0.6052]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3635,  0.4710,  1.1305],\n",
            "        [ 0.4720, -0.0353, -1.0844],\n",
            "        [-2.0076,  1.1181,  0.4492],\n",
            "        [-1.5661,  1.8401, -0.4462],\n",
            "        [-1.2846,  1.6455, -0.5859],\n",
            "        [-1.3760,  0.1467,  1.0058],\n",
            "        [-1.7391,  0.1021,  1.0195],\n",
            "        [-1.8590,  0.0386,  1.1714],\n",
            "        [-0.6849,  1.1446, -0.7012],\n",
            "        [-1.5077,  0.0825,  0.8979],\n",
            "        [-1.1984,  1.7667, -0.6896],\n",
            "        [-1.0165,  1.5619, -0.5715],\n",
            "        [-1.4516,  1.9457, -0.5288],\n",
            "        [-1.6323,  0.1336,  1.0451],\n",
            "        [ 0.7700,  0.0092, -0.9275],\n",
            "        [-1.3483,  2.0346, -0.6052]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3018,  1.4446, -0.6256],\n",
            "        [-1.3014,  1.7990, -0.6022],\n",
            "        [-1.2999,  1.5785, -0.3557],\n",
            "        [-1.5589,  1.5859, -0.3437],\n",
            "        [-1.3633,  0.0557,  1.1184],\n",
            "        [-1.3029,  1.1748, -0.1112],\n",
            "        [-1.5471,  1.1451,  0.4636],\n",
            "        [ 0.5711, -0.1088, -0.9191],\n",
            "        [-0.6244,  1.3223, -0.8214],\n",
            "        [-1.4766,  0.1802,  1.0309],\n",
            "        [-1.2100,  1.4272, -0.3248],\n",
            "        [-1.1664,  1.7871, -0.7437],\n",
            "        [-1.9227,  0.7889,  0.6356],\n",
            "        [-1.0360,  1.6558, -0.5294],\n",
            "        [-1.0029,  1.5384, -0.7012],\n",
            "        [-1.3498,  1.8228, -0.8205]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3018,  1.4446, -0.6256],\n",
            "        [-1.3014,  1.7990, -0.6022],\n",
            "        [-1.2999,  1.5785, -0.3557],\n",
            "        [-1.5589,  1.5859, -0.3437],\n",
            "        [-1.3633,  0.0557,  1.1184],\n",
            "        [-1.3029,  1.1748, -0.1112],\n",
            "        [-1.5471,  1.1451,  0.4636],\n",
            "        [ 0.5711, -0.1088, -0.9191],\n",
            "        [-0.6244,  1.3223, -0.8214],\n",
            "        [-1.4766,  0.1802,  1.0309],\n",
            "        [-1.2100,  1.4272, -0.3248],\n",
            "        [-1.1664,  1.7871, -0.7437],\n",
            "        [-1.9227,  0.7889,  0.6356],\n",
            "        [-1.0360,  1.6558, -0.5294],\n",
            "        [-1.0029,  1.5384, -0.7012],\n",
            "        [-1.3498,  1.8228, -0.8205]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8578,  0.2468,  1.1745],\n",
            "        [-1.8234,  0.8009,  0.6265],\n",
            "        [-1.4914,  0.6081,  0.4201],\n",
            "        [-0.7676,  1.2485, -0.6864],\n",
            "        [-1.3854,  1.4835, -0.3738],\n",
            "        [-1.0113,  1.5816, -0.7154],\n",
            "        [-0.7645,  0.0758,  0.4424],\n",
            "        [-1.5604,  1.7035, -0.5668],\n",
            "        [-1.1859,  1.7785, -0.4097],\n",
            "        [-1.1144,  1.4853, -0.5058],\n",
            "        [-1.4658,  1.7079, -0.3914],\n",
            "        [-1.5811,  0.2768,  1.0361],\n",
            "        [-1.6894,  0.2627,  1.1414],\n",
            "        [-1.1972,  1.0926, -0.2768],\n",
            "        [-1.1899,  1.7670, -0.4386],\n",
            "        [-1.4482,  0.0717,  1.2160]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8578,  0.2468,  1.1745],\n",
            "        [-1.8234,  0.8009,  0.6265],\n",
            "        [-1.4914,  0.6081,  0.4201],\n",
            "        [-0.7676,  1.2485, -0.6864],\n",
            "        [-1.3854,  1.4835, -0.3738],\n",
            "        [-1.0113,  1.5816, -0.7154],\n",
            "        [-0.7645,  0.0758,  0.4424],\n",
            "        [-1.5604,  1.7035, -0.5668],\n",
            "        [-1.1859,  1.7785, -0.4097],\n",
            "        [-1.1144,  1.4853, -0.5058],\n",
            "        [-1.4658,  1.7079, -0.3914],\n",
            "        [-1.5811,  0.2768,  1.0361],\n",
            "        [-1.6894,  0.2627,  1.1414],\n",
            "        [-1.1972,  1.0926, -0.2768],\n",
            "        [-1.1899,  1.7670, -0.4386],\n",
            "        [-1.4482,  0.0717,  1.2160]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.1094,  1.6734, -0.8167],\n",
            "        [-1.1679,  1.5788, -0.5515],\n",
            "        [-1.7564,  0.2122,  1.2817],\n",
            "        [-1.5900,  1.6504, -0.1970],\n",
            "        [-1.6180,  0.0892,  1.2403],\n",
            "        [-1.8187,  0.1317,  1.0645],\n",
            "        [-1.2788,  1.9798, -0.5618],\n",
            "        [-1.5080,  1.7827, -0.1023],\n",
            "        [ 0.6154, -0.0306, -0.8671],\n",
            "        [-1.3332,  1.7121, -0.5655],\n",
            "        [-1.5034, -0.0323,  1.3414],\n",
            "        [-1.6612,  0.0387,  1.2107],\n",
            "        [-1.8563,  0.2290,  1.2955],\n",
            "        [-1.7917,  1.6266, -0.2292],\n",
            "        [-1.2449,  1.6472, -0.5700],\n",
            "        [-1.7357,  0.2550,  1.1002]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.1094,  1.6734, -0.8167],\n",
            "        [-1.1679,  1.5788, -0.5515],\n",
            "        [-1.7564,  0.2122,  1.2817],\n",
            "        [-1.5900,  1.6504, -0.1970],\n",
            "        [-1.6180,  0.0892,  1.2403],\n",
            "        [-1.8187,  0.1317,  1.0645],\n",
            "        [-1.2788,  1.9798, -0.5618],\n",
            "        [-1.5080,  1.7827, -0.1023],\n",
            "        [ 0.6154, -0.0306, -0.8671],\n",
            "        [-1.3332,  1.7121, -0.5655],\n",
            "        [-1.5034, -0.0323,  1.3414],\n",
            "        [-1.6612,  0.0387,  1.2107],\n",
            "        [-1.8563,  0.2290,  1.2955],\n",
            "        [-1.7917,  1.6266, -0.2292],\n",
            "        [-1.2449,  1.6472, -0.5700],\n",
            "        [-1.7357,  0.2550,  1.1002]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6212,  1.6614, -0.2808],\n",
            "        [-1.6859,  0.8689,  0.4109],\n",
            "        [-1.8145,  0.5396,  1.0842],\n",
            "        [-0.7309,  0.1523,  0.4819],\n",
            "        [-0.9630,  1.4290, -0.5998],\n",
            "        [-1.3093,  1.2586, -0.4148],\n",
            "        [-1.8071, -0.0708,  1.1587],\n",
            "        [ 0.4748, -0.2390, -0.4868],\n",
            "        [-1.0477,  1.8117, -0.5847],\n",
            "        [-1.8493,  0.1982,  1.1631],\n",
            "        [-1.6288,  0.5236,  0.8887],\n",
            "        [-1.4821,  1.5274, -0.1952],\n",
            "        [-1.6915,  0.9759,  0.3277],\n",
            "        [-1.8108,  0.4238,  1.2259],\n",
            "        [-1.9910,  0.4815,  1.2782],\n",
            "        [-1.5941,  0.2453,  1.3673]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6212,  1.6614, -0.2808],\n",
            "        [-1.6859,  0.8689,  0.4109],\n",
            "        [-1.8145,  0.5396,  1.0842],\n",
            "        [-0.7309,  0.1523,  0.4819],\n",
            "        [-0.9630,  1.4290, -0.5998],\n",
            "        [-1.3093,  1.2586, -0.4148],\n",
            "        [-1.8071, -0.0708,  1.1587],\n",
            "        [ 0.4748, -0.2390, -0.4868],\n",
            "        [-1.0477,  1.8117, -0.5847],\n",
            "        [-1.8493,  0.1982,  1.1631],\n",
            "        [-1.6288,  0.5236,  0.8887],\n",
            "        [-1.4821,  1.5274, -0.1952],\n",
            "        [-1.6915,  0.9759,  0.3277],\n",
            "        [-1.8108,  0.4238,  1.2259],\n",
            "        [-1.9910,  0.4815,  1.2782],\n",
            "        [-1.5941,  0.2453,  1.3673]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6917,  0.2718,  1.2528],\n",
            "        [ 0.4957, -0.1571, -0.7796],\n",
            "        [-1.8351,  0.1672,  1.1581],\n",
            "        [ 0.1544,  0.2687, -0.7888],\n",
            "        [-0.9586,  1.1735, -0.1711],\n",
            "        [-1.4105,  1.8016, -0.6443],\n",
            "        [-1.6738,  0.4821,  0.8851],\n",
            "        [-1.8207, -0.0513,  1.1771],\n",
            "        [-1.6213,  1.4818, -0.1658],\n",
            "        [-1.1578,  1.9115, -0.3772],\n",
            "        [-1.7110,  0.4389,  0.9634],\n",
            "        [-0.9527,  1.4069, -0.7129],\n",
            "        [ 0.5711,  0.1315, -1.0651],\n",
            "        [-1.7641, -0.0653,  1.3383],\n",
            "        [-1.6009,  0.2665,  1.0649],\n",
            "        [-1.6459,  0.3963,  0.9604]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6917,  0.2718,  1.2528],\n",
            "        [ 0.4957, -0.1571, -0.7796],\n",
            "        [-1.8351,  0.1672,  1.1581],\n",
            "        [ 0.1544,  0.2687, -0.7888],\n",
            "        [-0.9586,  1.1735, -0.1711],\n",
            "        [-1.4105,  1.8016, -0.6443],\n",
            "        [-1.6738,  0.4821,  0.8851],\n",
            "        [-1.8207, -0.0513,  1.1771],\n",
            "        [-1.6213,  1.4818, -0.1658],\n",
            "        [-1.1578,  1.9115, -0.3772],\n",
            "        [-1.7110,  0.4389,  0.9634],\n",
            "        [-0.9527,  1.4069, -0.7129],\n",
            "        [ 0.5711,  0.1315, -1.0651],\n",
            "        [-1.7641, -0.0653,  1.3383],\n",
            "        [-1.6009,  0.2665,  1.0649],\n",
            "        [-1.6459,  0.3963,  0.9604]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2588,  1.9372, -0.5755],\n",
            "        [-1.7183,  0.5639,  0.6778],\n",
            "        [-1.4689,  1.8356, -0.6351],\n",
            "        [-1.3782, -0.0145,  1.1723],\n",
            "        [-1.7201,  1.0479,  0.4056],\n",
            "        [-0.0163, -0.2495, -0.0903],\n",
            "        [-2.1382,  0.7178,  0.7863],\n",
            "        [-2.0694,  0.7179,  1.0213],\n",
            "        [-1.1396,  1.7056, -0.7907],\n",
            "        [-0.5461, -0.0588,  0.4007],\n",
            "        [-0.4869,  0.7744, -0.5224],\n",
            "        [-1.5221,  1.6947, -0.4759],\n",
            "        [-1.8784,  0.2912,  1.2625],\n",
            "        [-1.7287,  0.2491,  1.2600],\n",
            "        [-1.8173,  0.4504,  1.0564],\n",
            "        [-1.5737,  0.6786,  0.7319]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2588,  1.9372, -0.5755],\n",
            "        [-1.7183,  0.5639,  0.6778],\n",
            "        [-1.4689,  1.8356, -0.6351],\n",
            "        [-1.3782, -0.0145,  1.1723],\n",
            "        [-1.7201,  1.0479,  0.4056],\n",
            "        [-0.0163, -0.2495, -0.0903],\n",
            "        [-2.1382,  0.7178,  0.7863],\n",
            "        [-2.0694,  0.7179,  1.0213],\n",
            "        [-1.1396,  1.7056, -0.7907],\n",
            "        [-0.5461, -0.0588,  0.4007],\n",
            "        [-0.4869,  0.7744, -0.5224],\n",
            "        [-1.5221,  1.6947, -0.4759],\n",
            "        [-1.8784,  0.2912,  1.2625],\n",
            "        [-1.7287,  0.2491,  1.2600],\n",
            "        [-1.8173,  0.4504,  1.0564],\n",
            "        [-1.5737,  0.6786,  0.7319]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.7783, -0.1906, -0.9851],\n",
            "        [ 0.6377, -0.1688, -0.8286],\n",
            "        [-0.8351,  1.2377, -0.8038],\n",
            "        [-0.3281,  0.8385, -0.8592],\n",
            "        [-1.5836, -0.0551,  1.0817],\n",
            "        [-1.1630,  1.9201, -0.5398],\n",
            "        [-1.1082,  1.4569, -0.5302],\n",
            "        [-1.5606,  1.7990, -0.5567],\n",
            "        [-1.6426,  1.8543, -0.2529],\n",
            "        [-0.8846,  1.4810, -0.5161],\n",
            "        [-2.0175,  1.3903,  0.5301],\n",
            "        [-1.3079,  1.4824, -0.6201],\n",
            "        [-1.7043, -0.0528,  1.2179],\n",
            "        [-1.8506,  0.4830,  1.0265],\n",
            "        [ 0.8443, -0.2345, -0.7961],\n",
            "        [-1.3142,  1.6167, -0.5519]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.7783, -0.1906, -0.9851],\n",
            "        [ 0.6377, -0.1688, -0.8286],\n",
            "        [-0.8351,  1.2377, -0.8038],\n",
            "        [-0.3281,  0.8385, -0.8592],\n",
            "        [-1.5836, -0.0551,  1.0817],\n",
            "        [-1.1630,  1.9201, -0.5398],\n",
            "        [-1.1082,  1.4569, -0.5302],\n",
            "        [-1.5606,  1.7990, -0.5567],\n",
            "        [-1.6426,  1.8543, -0.2529],\n",
            "        [-0.8846,  1.4810, -0.5161],\n",
            "        [-2.0175,  1.3903,  0.5301],\n",
            "        [-1.3079,  1.4824, -0.6201],\n",
            "        [-1.7043, -0.0528,  1.2179],\n",
            "        [-1.8506,  0.4830,  1.0265],\n",
            "        [ 0.8443, -0.2345, -0.7961],\n",
            "        [-1.3142,  1.6167, -0.5519]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2356,  1.2679, -0.3040],\n",
            "        [-1.4079,  1.6726, -0.5897],\n",
            "        [-1.2999,  1.4985, -0.3664],\n",
            "        [-1.2685,  1.6145, -0.2531],\n",
            "        [-1.6932, -0.1191,  1.1590],\n",
            "        [-1.3480,  1.7783, -0.4185],\n",
            "        [-1.7924,  1.3821,  0.0769],\n",
            "        [-1.6334,  1.7958, -0.0959],\n",
            "        [-1.7497,  0.1768,  1.3280],\n",
            "        [-1.9811,  0.4824,  1.2098],\n",
            "        [-1.6005,  1.9682, -0.4616],\n",
            "        [-1.2869,  1.6579, -0.4443],\n",
            "        [-0.7979,  1.3335, -0.8443],\n",
            "        [-1.4990,  1.5118, -0.2615],\n",
            "        [-2.1431,  0.2508,  1.4751],\n",
            "        [ 0.5581, -0.0890, -0.6692]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2356,  1.2679, -0.3040],\n",
            "        [-1.4079,  1.6726, -0.5897],\n",
            "        [-1.2999,  1.4985, -0.3664],\n",
            "        [-1.2685,  1.6145, -0.2531],\n",
            "        [-1.6932, -0.1191,  1.1590],\n",
            "        [-1.3480,  1.7783, -0.4185],\n",
            "        [-1.7924,  1.3821,  0.0769],\n",
            "        [-1.6334,  1.7958, -0.0959],\n",
            "        [-1.7497,  0.1768,  1.3280],\n",
            "        [-1.9811,  0.4824,  1.2098],\n",
            "        [-1.6005,  1.9682, -0.4616],\n",
            "        [-1.2869,  1.6579, -0.4443],\n",
            "        [-0.7979,  1.3335, -0.8443],\n",
            "        [-1.4990,  1.5118, -0.2615],\n",
            "        [-2.1431,  0.2508,  1.4751],\n",
            "        [ 0.5581, -0.0890, -0.6692]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9332,  0.9724,  0.8265],\n",
            "        [-1.7380,  0.3141,  1.1101],\n",
            "        [-2.0389,  0.4166,  1.1886],\n",
            "        [ 0.4043, -0.0802, -0.5821],\n",
            "        [-1.6681,  1.8298, -0.3581],\n",
            "        [ 0.3910, -0.0148, -0.7565],\n",
            "        [-2.0732,  0.9514,  0.7468],\n",
            "        [-1.2075,  1.4354, -0.6021],\n",
            "        [-1.4402,  1.8724, -0.5189],\n",
            "        [-1.3283,  1.7744, -0.3173],\n",
            "        [-1.6841,  1.5225,  0.1007],\n",
            "        [-1.6957,  0.1828,  1.3629],\n",
            "        [-0.0313, -0.1326, -0.0596],\n",
            "        [-1.2768,  1.6627, -0.3875],\n",
            "        [-1.1855,  0.4901,  0.4361],\n",
            "        [-1.0896,  0.5261,  0.2966]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9332,  0.9724,  0.8265],\n",
            "        [-1.7380,  0.3141,  1.1101],\n",
            "        [-2.0389,  0.4166,  1.1886],\n",
            "        [ 0.4043, -0.0802, -0.5821],\n",
            "        [-1.6681,  1.8298, -0.3581],\n",
            "        [ 0.3910, -0.0148, -0.7565],\n",
            "        [-2.0732,  0.9514,  0.7468],\n",
            "        [-1.2075,  1.4354, -0.6021],\n",
            "        [-1.4402,  1.8724, -0.5189],\n",
            "        [-1.3283,  1.7744, -0.3173],\n",
            "        [-1.6841,  1.5225,  0.1007],\n",
            "        [-1.6957,  0.1828,  1.3629],\n",
            "        [-0.0313, -0.1326, -0.0596],\n",
            "        [-1.2768,  1.6627, -0.3875],\n",
            "        [-1.1855,  0.4901,  0.4361],\n",
            "        [-1.0896,  0.5261,  0.2966]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.3212,  0.4096,  1.0402],\n",
            "        [-1.6298,  0.0154,  1.1231],\n",
            "        [-1.1405,  1.6105, -0.4139],\n",
            "        [-1.6011,  2.1088, -0.2477],\n",
            "        [-1.3272,  1.6468, -0.8081],\n",
            "        [-1.4086,  1.6582, -0.4054],\n",
            "        [ 0.0420,  0.2749, -0.5436],\n",
            "        [ 0.6561, -0.1801, -0.7742],\n",
            "        [-1.3303,  1.7262, -0.4790],\n",
            "        [ 0.3348,  0.2067, -0.7074],\n",
            "        [-2.0870,  0.3089,  1.3991],\n",
            "        [-1.4085,  1.7786, -0.3494],\n",
            "        [-1.1970,  1.5407, -0.8100],\n",
            "        [ 0.0113,  0.3315, -0.6566],\n",
            "        [-0.7860,  1.6039, -0.8308],\n",
            "        [-1.2695,  1.7395, -0.5918]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.3212,  0.4096,  1.0402],\n",
            "        [-1.6298,  0.0154,  1.1231],\n",
            "        [-1.1405,  1.6105, -0.4139],\n",
            "        [-1.6011,  2.1088, -0.2477],\n",
            "        [-1.3272,  1.6468, -0.8081],\n",
            "        [-1.4086,  1.6582, -0.4054],\n",
            "        [ 0.0420,  0.2749, -0.5436],\n",
            "        [ 0.6561, -0.1801, -0.7742],\n",
            "        [-1.3303,  1.7262, -0.4790],\n",
            "        [ 0.3348,  0.2067, -0.7074],\n",
            "        [-2.0870,  0.3089,  1.3991],\n",
            "        [-1.4085,  1.7786, -0.3494],\n",
            "        [-1.1970,  1.5407, -0.8100],\n",
            "        [ 0.0113,  0.3315, -0.6566],\n",
            "        [-0.7860,  1.6039, -0.8308],\n",
            "        [-1.2695,  1.7395, -0.5918]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9599,  1.2297,  0.5135],\n",
            "        [-1.3094,  1.8398, -0.5243],\n",
            "        [-1.8277,  0.1859,  1.2791],\n",
            "        [-2.0634,  0.5140,  1.1969],\n",
            "        [-1.4175,  1.7700, -0.6032],\n",
            "        [ 0.2998, -0.1923, -0.5294],\n",
            "        [-1.4600,  1.8012, -0.3987],\n",
            "        [-1.1956,  1.7524, -0.6168],\n",
            "        [-1.3223,  1.6675, -0.4367],\n",
            "        [-1.8382,  0.6345,  0.8768],\n",
            "        [-1.4524,  2.0403, -0.5378],\n",
            "        [-1.4735,  1.7702, -0.5796],\n",
            "        [-1.9469,  1.4882,  0.1952],\n",
            "        [-1.2404,  1.6839, -0.4374],\n",
            "        [-0.5655,  1.2038, -0.6384],\n",
            "        [-1.4862,  1.7801, -0.3068]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9599,  1.2297,  0.5135],\n",
            "        [-1.3094,  1.8398, -0.5243],\n",
            "        [-1.8277,  0.1859,  1.2791],\n",
            "        [-2.0634,  0.5140,  1.1969],\n",
            "        [-1.4175,  1.7700, -0.6032],\n",
            "        [ 0.2998, -0.1923, -0.5294],\n",
            "        [-1.4600,  1.8012, -0.3987],\n",
            "        [-1.1956,  1.7524, -0.6168],\n",
            "        [-1.3223,  1.6675, -0.4367],\n",
            "        [-1.8382,  0.6345,  0.8768],\n",
            "        [-1.4524,  2.0403, -0.5378],\n",
            "        [-1.4735,  1.7702, -0.5796],\n",
            "        [-1.9469,  1.4882,  0.1952],\n",
            "        [-1.2404,  1.6839, -0.4374],\n",
            "        [-0.5655,  1.2038, -0.6384],\n",
            "        [-1.4862,  1.7801, -0.3068]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0900,  1.1634,  0.4443],\n",
            "        [ 0.2648, -0.0438, -0.6904],\n",
            "        [ 0.5842, -0.0363, -0.8356],\n",
            "        [-1.3366,  2.1410, -0.6584],\n",
            "        [-1.9008,  0.3999,  1.2661],\n",
            "        [-1.6814,  1.8590, -0.3172],\n",
            "        [-1.7539,  2.0141, -0.1392],\n",
            "        [-1.5506,  1.7691, -0.3913],\n",
            "        [-1.8514,  0.1696,  1.1499],\n",
            "        [-1.3246,  2.0107, -0.7740],\n",
            "        [-1.3521,  1.6101, -0.6620],\n",
            "        [-0.6066,  1.1688, -0.9010],\n",
            "        [-1.4530,  1.8531, -0.5220],\n",
            "        [ 0.3702,  0.3922, -0.9482],\n",
            "        [-1.2950,  1.6457, -0.6270],\n",
            "        [-1.6420,  2.0038, -0.4079]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0900,  1.1634,  0.4443],\n",
            "        [ 0.2648, -0.0438, -0.6904],\n",
            "        [ 0.5842, -0.0363, -0.8356],\n",
            "        [-1.3366,  2.1410, -0.6584],\n",
            "        [-1.9008,  0.3999,  1.2661],\n",
            "        [-1.6814,  1.8590, -0.3172],\n",
            "        [-1.7539,  2.0141, -0.1392],\n",
            "        [-1.5506,  1.7691, -0.3913],\n",
            "        [-1.8514,  0.1696,  1.1499],\n",
            "        [-1.3246,  2.0107, -0.7740],\n",
            "        [-1.3521,  1.6101, -0.6620],\n",
            "        [-0.6066,  1.1688, -0.9010],\n",
            "        [-1.4530,  1.8531, -0.5220],\n",
            "        [ 0.3702,  0.3922, -0.9482],\n",
            "        [-1.2950,  1.6457, -0.6270],\n",
            "        [-1.6420,  2.0038, -0.4079]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1438,  0.3974,  1.2203],\n",
            "        [-1.9557,  0.6797,  0.8921],\n",
            "        [-1.6063,  1.7090, -0.4532],\n",
            "        [-1.0967,  1.5000, -0.4659],\n",
            "        [-1.8148,  0.0701,  1.1597],\n",
            "        [-1.7026,  1.6183, -0.2363],\n",
            "        [-1.6322,  1.9610, -0.5893],\n",
            "        [-2.0304,  0.6579,  0.8714],\n",
            "        [-1.6787,  2.0790, -0.2976],\n",
            "        [-1.2815,  1.8638, -0.5439],\n",
            "        [-1.8931,  0.5110,  1.0329],\n",
            "        [-1.5198,  1.9792, -0.6155],\n",
            "        [-1.8732,  1.8248, -0.2999],\n",
            "        [-1.9092,  1.7148, -0.3256],\n",
            "        [-1.6026,  2.0051, -0.5434],\n",
            "        [-1.3229,  1.8544, -0.4867]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1438,  0.3974,  1.2203],\n",
            "        [-1.9557,  0.6797,  0.8921],\n",
            "        [-1.6063,  1.7090, -0.4532],\n",
            "        [-1.0967,  1.5000, -0.4659],\n",
            "        [-1.8148,  0.0701,  1.1597],\n",
            "        [-1.7026,  1.6183, -0.2363],\n",
            "        [-1.6322,  1.9610, -0.5893],\n",
            "        [-2.0304,  0.6579,  0.8714],\n",
            "        [-1.6787,  2.0790, -0.2976],\n",
            "        [-1.2815,  1.8638, -0.5439],\n",
            "        [-1.8931,  0.5110,  1.0329],\n",
            "        [-1.5198,  1.9792, -0.6155],\n",
            "        [-1.8732,  1.8248, -0.2999],\n",
            "        [-1.9092,  1.7148, -0.3256],\n",
            "        [-1.6026,  2.0051, -0.5434],\n",
            "        [-1.3229,  1.8544, -0.4867]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9677,  1.0890,  0.4164],\n",
            "        [-1.7157,  1.6872,  0.0028],\n",
            "        [-2.1156,  1.0456,  0.8007],\n",
            "        [-2.4226,  0.5915,  1.3972],\n",
            "        [-1.4835,  1.8244, -0.3640],\n",
            "        [-1.5185,  1.9588, -0.5272],\n",
            "        [-1.8555,  1.7001, -0.0028],\n",
            "        [-1.6217,  1.8537, -0.3512],\n",
            "        [-1.7274,  1.7479, -0.0592],\n",
            "        [-1.7050,  1.9091, -0.4366],\n",
            "        [-1.9659,  1.0229,  0.7634],\n",
            "        [-1.7865,  0.2741,  1.1821],\n",
            "        [-1.5947,  1.8875, -0.6645],\n",
            "        [-1.6333,  0.3717,  1.1178],\n",
            "        [-1.8879,  1.6557, -0.4223],\n",
            "        [ 0.4114, -0.0563, -0.7571]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9677,  1.0890,  0.4164],\n",
            "        [-1.7157,  1.6872,  0.0028],\n",
            "        [-2.1156,  1.0456,  0.8007],\n",
            "        [-2.4226,  0.5915,  1.3972],\n",
            "        [-1.4835,  1.8244, -0.3640],\n",
            "        [-1.5185,  1.9588, -0.5272],\n",
            "        [-1.8555,  1.7001, -0.0028],\n",
            "        [-1.6217,  1.8537, -0.3512],\n",
            "        [-1.7274,  1.7479, -0.0592],\n",
            "        [-1.7050,  1.9091, -0.4366],\n",
            "        [-1.9659,  1.0229,  0.7634],\n",
            "        [-1.7865,  0.2741,  1.1821],\n",
            "        [-1.5947,  1.8875, -0.6645],\n",
            "        [-1.6333,  0.3717,  1.1178],\n",
            "        [-1.8879,  1.6557, -0.4223],\n",
            "        [ 0.4114, -0.0563, -0.7571]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6908,  1.7773, -0.3534],\n",
            "        [-1.6351,  2.0891, -0.3636],\n",
            "        [-1.7102,  1.7350, -0.3458],\n",
            "        [-1.5360,  1.9997, -0.7154],\n",
            "        [-1.7110,  2.1971, -0.6079],\n",
            "        [-1.6377,  2.0493, -0.2008],\n",
            "        [-1.5347,  0.8928,  0.5230],\n",
            "        [-0.5538,  1.2011, -0.8268],\n",
            "        [-1.9729,  0.5362,  0.9216],\n",
            "        [-1.7300,  2.1823, -0.4716],\n",
            "        [-1.6235,  2.0031, -0.4073],\n",
            "        [-1.6188,  1.9749, -0.4792],\n",
            "        [-1.3440,  2.1416, -0.7366],\n",
            "        [-1.8814,  0.5300,  1.0462],\n",
            "        [-2.2143,  0.5555,  1.1495],\n",
            "        [-1.7217,  2.2298, -0.4074]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6908,  1.7773, -0.3534],\n",
            "        [-1.6351,  2.0891, -0.3636],\n",
            "        [-1.7102,  1.7350, -0.3458],\n",
            "        [-1.5360,  1.9997, -0.7154],\n",
            "        [-1.7110,  2.1971, -0.6079],\n",
            "        [-1.6377,  2.0493, -0.2008],\n",
            "        [-1.5347,  0.8928,  0.5230],\n",
            "        [-0.5538,  1.2011, -0.8268],\n",
            "        [-1.9729,  0.5362,  0.9216],\n",
            "        [-1.7300,  2.1823, -0.4716],\n",
            "        [-1.6235,  2.0031, -0.4073],\n",
            "        [-1.6188,  1.9749, -0.4792],\n",
            "        [-1.3440,  2.1416, -0.7366],\n",
            "        [-1.8814,  0.5300,  1.0462],\n",
            "        [-2.2143,  0.5555,  1.1495],\n",
            "        [-1.7217,  2.2298, -0.4074]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.4053,  0.3148, -1.0955],\n",
            "        [-1.5915,  1.9636, -0.3565],\n",
            "        [-2.1327,  0.6928,  1.0536],\n",
            "        [-1.5844,  2.0813, -0.5912],\n",
            "        [ 0.3818,  0.1061, -0.9206],\n",
            "        [-1.8180,  1.9127, -0.4315],\n",
            "        [-2.1171,  0.8056,  0.8728],\n",
            "        [-1.6127,  0.6470,  0.4877],\n",
            "        [-1.7156,  2.2044, -0.5525],\n",
            "        [-1.5132,  2.0672, -0.5551],\n",
            "        [-1.4362,  1.9077, -0.3334],\n",
            "        [-1.8126,  0.2863,  1.2882],\n",
            "        [-1.8234,  1.8538, -0.2953],\n",
            "        [-2.1432,  1.0941,  0.6135],\n",
            "        [-2.0549,  0.7609,  1.0317],\n",
            "        [-1.5557,  1.9032, -0.3445]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.4053,  0.3148, -1.0955],\n",
            "        [-1.5915,  1.9636, -0.3565],\n",
            "        [-2.1327,  0.6928,  1.0536],\n",
            "        [-1.5844,  2.0813, -0.5912],\n",
            "        [ 0.3818,  0.1061, -0.9206],\n",
            "        [-1.8180,  1.9127, -0.4315],\n",
            "        [-2.1171,  0.8056,  0.8728],\n",
            "        [-1.6127,  0.6470,  0.4877],\n",
            "        [-1.7156,  2.2044, -0.5525],\n",
            "        [-1.5132,  2.0672, -0.5551],\n",
            "        [-1.4362,  1.9077, -0.3334],\n",
            "        [-1.8126,  0.2863,  1.2882],\n",
            "        [-1.8234,  1.8538, -0.2953],\n",
            "        [-2.1432,  1.0941,  0.6135],\n",
            "        [-2.0549,  0.7609,  1.0317],\n",
            "        [-1.5557,  1.9032, -0.3445]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7917e+00,  2.3284e-01,  1.0344e+00],\n",
            "        [-1.7784e+00,  3.7567e-01,  1.2530e+00],\n",
            "        [ 6.7674e-01, -1.0496e-01, -9.6751e-01],\n",
            "        [-2.0590e+00,  1.8779e+00, -5.3598e-02],\n",
            "        [-1.6626e+00,  1.9756e+00, -4.0503e-01],\n",
            "        [-1.9525e+00,  2.2789e+00, -5.2064e-01],\n",
            "        [-1.8051e+00,  4.2873e-01,  1.0528e+00],\n",
            "        [-1.6370e+00,  2.2463e+00, -5.6880e-01],\n",
            "        [-1.7741e+00,  1.8010e+00, -7.3129e-04],\n",
            "        [-1.6181e+00,  1.9518e+00, -4.2724e-01],\n",
            "        [-2.4483e+00,  1.6618e+00,  3.4239e-01],\n",
            "        [-1.7575e+00,  1.9183e+00, -4.3116e-01],\n",
            "        [-2.0288e+00,  9.1199e-01,  7.9772e-01],\n",
            "        [-2.2631e+00,  1.1736e+00,  7.6387e-01],\n",
            "        [-1.8190e+00,  1.8768e+00, -5.7511e-01],\n",
            "        [-1.4353e+00,  2.0340e+00, -6.2388e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7917e+00,  2.3284e-01,  1.0344e+00],\n",
            "        [-1.7784e+00,  3.7567e-01,  1.2530e+00],\n",
            "        [ 6.7674e-01, -1.0496e-01, -9.6751e-01],\n",
            "        [-2.0590e+00,  1.8779e+00, -5.3598e-02],\n",
            "        [-1.6626e+00,  1.9756e+00, -4.0503e-01],\n",
            "        [-1.9525e+00,  2.2789e+00, -5.2064e-01],\n",
            "        [-1.8051e+00,  4.2873e-01,  1.0528e+00],\n",
            "        [-1.6370e+00,  2.2463e+00, -5.6880e-01],\n",
            "        [-1.7741e+00,  1.8010e+00, -7.3129e-04],\n",
            "        [-1.6181e+00,  1.9518e+00, -4.2724e-01],\n",
            "        [-2.4483e+00,  1.6618e+00,  3.4239e-01],\n",
            "        [-1.7575e+00,  1.9183e+00, -4.3116e-01],\n",
            "        [-2.0288e+00,  9.1199e-01,  7.9772e-01],\n",
            "        [-2.2631e+00,  1.1736e+00,  7.6387e-01],\n",
            "        [-1.8190e+00,  1.8768e+00, -5.7511e-01],\n",
            "        [-1.4353e+00,  2.0340e+00, -6.2388e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7679,  2.1359, -0.3493],\n",
            "        [-1.8135,  2.2142, -0.4329],\n",
            "        [-1.6420,  2.0343, -0.2353],\n",
            "        [-1.7025,  1.8590, -0.4345],\n",
            "        [ 0.4854, -0.0661, -1.0141],\n",
            "        [-1.9911,  2.1332, -0.2885],\n",
            "        [-0.0036,  0.3544, -0.5381],\n",
            "        [-1.7941,  1.4189, -0.2811],\n",
            "        [-2.4170,  1.8154,  0.3219],\n",
            "        [-1.5626,  1.7821, -0.4360],\n",
            "        [-1.2793,  1.5425, -0.5997],\n",
            "        [-1.7527,  2.0271, -0.6312],\n",
            "        [-2.0134,  1.7975,  0.1207],\n",
            "        [-1.3732,  1.6321, -0.4413],\n",
            "        [-2.0889,  1.7723,  0.0794],\n",
            "        [-1.8953,  1.9825, -0.3443]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7679,  2.1359, -0.3493],\n",
            "        [-1.8135,  2.2142, -0.4329],\n",
            "        [-1.6420,  2.0343, -0.2353],\n",
            "        [-1.7025,  1.8590, -0.4345],\n",
            "        [ 0.4854, -0.0661, -1.0141],\n",
            "        [-1.9911,  2.1332, -0.2885],\n",
            "        [-0.0036,  0.3544, -0.5381],\n",
            "        [-1.7941,  1.4189, -0.2811],\n",
            "        [-2.4170,  1.8154,  0.3219],\n",
            "        [-1.5626,  1.7821, -0.4360],\n",
            "        [-1.2793,  1.5425, -0.5997],\n",
            "        [-1.7527,  2.0271, -0.6312],\n",
            "        [-2.0134,  1.7975,  0.1207],\n",
            "        [-1.3732,  1.6321, -0.4413],\n",
            "        [-2.0889,  1.7723,  0.0794],\n",
            "        [-1.8953,  1.9825, -0.3443]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5824,  0.2020, -0.9547],\n",
            "        [-1.6759,  2.1564, -0.1438],\n",
            "        [-2.0570,  0.8636,  0.9925],\n",
            "        [-1.9621,  0.5454,  1.1464],\n",
            "        [-2.4482,  2.0785,  0.0497],\n",
            "        [-1.6559,  2.1020, -0.4884],\n",
            "        [-1.6286,  2.1955, -0.4307],\n",
            "        [-2.0061,  1.8307, -0.4473],\n",
            "        [ 0.7036, -0.0214, -0.9513],\n",
            "        [ 0.6085, -0.0167, -1.0085],\n",
            "        [-1.5254,  1.8474, -0.2458],\n",
            "        [-1.7883,  2.0556, -0.3316],\n",
            "        [-1.8554,  1.8201,  0.1281],\n",
            "        [-1.9870,  1.9580, -0.0904],\n",
            "        [-1.9451,  2.0919, -0.2922],\n",
            "        [-1.9431,  1.9926, -0.1145]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.5824,  0.2020, -0.9547],\n",
            "        [-1.6759,  2.1564, -0.1438],\n",
            "        [-2.0570,  0.8636,  0.9925],\n",
            "        [-1.9621,  0.5454,  1.1464],\n",
            "        [-2.4482,  2.0785,  0.0497],\n",
            "        [-1.6559,  2.1020, -0.4884],\n",
            "        [-1.6286,  2.1955, -0.4307],\n",
            "        [-2.0061,  1.8307, -0.4473],\n",
            "        [ 0.7036, -0.0214, -0.9513],\n",
            "        [ 0.6085, -0.0167, -1.0085],\n",
            "        [-1.5254,  1.8474, -0.2458],\n",
            "        [-1.7883,  2.0556, -0.3316],\n",
            "        [-1.8554,  1.8201,  0.1281],\n",
            "        [-1.9870,  1.9580, -0.0904],\n",
            "        [-1.9451,  2.0919, -0.2922],\n",
            "        [-1.9431,  1.9926, -0.1145]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1020,  1.9496, -0.3218],\n",
            "        [-1.6033,  1.9349, -0.3926],\n",
            "        [-1.7152,  2.1485, -0.5893],\n",
            "        [-1.5543,  1.9917, -0.4640],\n",
            "        [-1.4698,  1.7138, -0.4454],\n",
            "        [-2.0475,  2.0410, -0.1787],\n",
            "        [-2.1791,  0.5950,  0.9211],\n",
            "        [-1.5006,  1.7337, -0.4556],\n",
            "        [-2.0778,  1.4929,  0.4591],\n",
            "        [-2.1144,  0.7224,  0.9434],\n",
            "        [-1.7933,  2.0094, -0.3490],\n",
            "        [-1.8311,  1.7549, -0.2168],\n",
            "        [-1.7860,  2.1134, -0.4194],\n",
            "        [-1.9692,  2.0919, -0.2115],\n",
            "        [-1.6874,  1.9233, -0.3188],\n",
            "        [-1.2386,  1.4028, -0.2955]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1020,  1.9496, -0.3218],\n",
            "        [-1.6033,  1.9349, -0.3926],\n",
            "        [-1.7152,  2.1485, -0.5893],\n",
            "        [-1.5543,  1.9917, -0.4640],\n",
            "        [-1.4698,  1.7138, -0.4454],\n",
            "        [-2.0475,  2.0410, -0.1787],\n",
            "        [-2.1791,  0.5950,  0.9211],\n",
            "        [-1.5006,  1.7337, -0.4556],\n",
            "        [-2.0778,  1.4929,  0.4591],\n",
            "        [-2.1144,  0.7224,  0.9434],\n",
            "        [-1.7933,  2.0094, -0.3490],\n",
            "        [-1.8311,  1.7549, -0.2168],\n",
            "        [-1.7860,  2.1134, -0.4194],\n",
            "        [-1.9692,  2.0919, -0.2115],\n",
            "        [-1.6874,  1.9233, -0.3188],\n",
            "        [-1.2386,  1.4028, -0.2955]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9460,  1.7087, -0.5237],\n",
            "        [-1.9995,  1.0583,  0.5302],\n",
            "        [-1.8472,  2.0217, -0.3616],\n",
            "        [-2.3147,  1.0399,  1.0837],\n",
            "        [-1.7801,  1.7824, -0.0419],\n",
            "        [-1.8404,  0.4681,  1.0259],\n",
            "        [-1.9804,  2.2716, -0.3475],\n",
            "        [-1.5917,  1.7186, -0.3396],\n",
            "        [-1.5554,  1.9726, -0.5792],\n",
            "        [ 0.6586,  0.1921, -1.0866],\n",
            "        [-1.5892,  1.8809, -0.3995],\n",
            "        [-1.6574,  1.8735, -0.4443],\n",
            "        [-1.6362,  2.0157, -0.1405],\n",
            "        [-1.8787,  2.0117, -0.4219],\n",
            "        [ 0.8586, -0.0688, -1.0211],\n",
            "        [-2.0375,  0.5612,  0.6719]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9460,  1.7087, -0.5237],\n",
            "        [-1.9995,  1.0583,  0.5302],\n",
            "        [-1.8472,  2.0217, -0.3616],\n",
            "        [-2.3147,  1.0399,  1.0837],\n",
            "        [-1.7801,  1.7824, -0.0419],\n",
            "        [-1.8404,  0.4681,  1.0259],\n",
            "        [-1.9804,  2.2716, -0.3475],\n",
            "        [-1.5917,  1.7186, -0.3396],\n",
            "        [-1.5554,  1.9726, -0.5792],\n",
            "        [ 0.6586,  0.1921, -1.0866],\n",
            "        [-1.5892,  1.8809, -0.3995],\n",
            "        [-1.6574,  1.8735, -0.4443],\n",
            "        [-1.6362,  2.0157, -0.1405],\n",
            "        [-1.8787,  2.0117, -0.4219],\n",
            "        [ 0.8586, -0.0688, -1.0211],\n",
            "        [-2.0375,  0.5612,  0.6719]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1247e+00,  1.9272e+00,  1.4634e-01],\n",
            "        [-2.0161e+00,  2.0042e+00,  4.4966e-04],\n",
            "        [-2.1776e+00,  1.2359e+00,  5.0065e-01],\n",
            "        [-1.9849e+00,  1.4254e+00,  4.7441e-01],\n",
            "        [-2.3230e+00,  8.3024e-01,  1.1249e+00],\n",
            "        [-1.9446e+00,  5.8587e-01,  8.5805e-01],\n",
            "        [-1.7612e+00,  2.0485e+00, -3.5346e-01],\n",
            "        [-1.7949e+00,  2.0420e+00, -3.2816e-01],\n",
            "        [-2.0154e+00,  7.3728e-01,  7.7266e-01],\n",
            "        [-1.8484e+00,  2.0247e+00, -2.0875e-01],\n",
            "        [-6.9890e-01,  4.9615e-01, -1.9342e-02],\n",
            "        [ 3.9519e-01,  1.5071e-01, -7.7649e-01],\n",
            "        [-2.2969e+00,  1.9680e+00, -4.6888e-02],\n",
            "        [-2.1902e+00,  7.9755e-01,  8.7494e-01],\n",
            "        [-1.8657e+00,  1.9144e+00, -1.8724e-01],\n",
            "        [-1.7464e+00,  1.9700e+00, -2.8957e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1247e+00,  1.9272e+00,  1.4634e-01],\n",
            "        [-2.0161e+00,  2.0042e+00,  4.4966e-04],\n",
            "        [-2.1776e+00,  1.2359e+00,  5.0065e-01],\n",
            "        [-1.9849e+00,  1.4254e+00,  4.7441e-01],\n",
            "        [-2.3230e+00,  8.3024e-01,  1.1249e+00],\n",
            "        [-1.9446e+00,  5.8587e-01,  8.5805e-01],\n",
            "        [-1.7612e+00,  2.0485e+00, -3.5346e-01],\n",
            "        [-1.7949e+00,  2.0420e+00, -3.2816e-01],\n",
            "        [-2.0154e+00,  7.3728e-01,  7.7266e-01],\n",
            "        [-1.8484e+00,  2.0247e+00, -2.0875e-01],\n",
            "        [-6.9890e-01,  4.9615e-01, -1.9342e-02],\n",
            "        [ 3.9519e-01,  1.5071e-01, -7.7649e-01],\n",
            "        [-2.2969e+00,  1.9680e+00, -4.6888e-02],\n",
            "        [-2.1902e+00,  7.9755e-01,  8.7494e-01],\n",
            "        [-1.8657e+00,  1.9144e+00, -1.8724e-01],\n",
            "        [-1.7464e+00,  1.9700e+00, -2.8957e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9736,  1.8908, -0.1743],\n",
            "        [-2.1029,  2.1890, -0.2979],\n",
            "        [ 0.8311, -0.0605, -1.1241],\n",
            "        [-2.3003,  1.3613,  0.7382],\n",
            "        [-1.8130,  0.8381,  0.5511],\n",
            "        [-0.7022,  1.2809, -0.6841],\n",
            "        [-1.7146,  0.1062,  1.3618],\n",
            "        [-1.7536,  1.9360, -0.1955],\n",
            "        [-1.7430,  2.0000, -0.3408],\n",
            "        [-1.6749,  1.6973, -0.3013],\n",
            "        [-1.8399,  2.0022, -0.2094],\n",
            "        [-1.1854,  1.6903, -0.4891],\n",
            "        [-1.7322,  1.9194, -0.3406],\n",
            "        [-1.6586,  0.5810,  1.0126],\n",
            "        [-1.9064,  1.9872, -0.0801],\n",
            "        [-1.7511,  1.7010, -0.3547]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9736,  1.8908, -0.1743],\n",
            "        [-2.1029,  2.1890, -0.2979],\n",
            "        [ 0.8311, -0.0605, -1.1241],\n",
            "        [-2.3003,  1.3613,  0.7382],\n",
            "        [-1.8130,  0.8381,  0.5511],\n",
            "        [-0.7022,  1.2809, -0.6841],\n",
            "        [-1.7146,  0.1062,  1.3618],\n",
            "        [-1.7536,  1.9360, -0.1955],\n",
            "        [-1.7430,  2.0000, -0.3408],\n",
            "        [-1.6749,  1.6973, -0.3013],\n",
            "        [-1.8399,  2.0022, -0.2094],\n",
            "        [-1.1854,  1.6903, -0.4891],\n",
            "        [-1.7322,  1.9194, -0.3406],\n",
            "        [-1.6586,  0.5810,  1.0126],\n",
            "        [-1.9064,  1.9872, -0.0801],\n",
            "        [-1.7511,  1.7010, -0.3547]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8279,  1.9857, -0.2974],\n",
            "        [-2.0801,  1.9076, -0.1380],\n",
            "        [-1.0927,  1.6291, -0.5943],\n",
            "        [-1.8365,  1.9915, -0.1607],\n",
            "        [-1.8487,  1.9624, -0.2091],\n",
            "        [-1.8986,  0.2878,  1.1534],\n",
            "        [-1.7578,  2.0044, -0.1555],\n",
            "        [-1.6784,  0.9127,  0.6119],\n",
            "        [-0.6701,  0.4714,  0.0276],\n",
            "        [ 0.3275,  0.3538, -1.0149],\n",
            "        [ 0.4775, -0.0735, -0.9274],\n",
            "        [-1.8205,  0.4103,  1.1676],\n",
            "        [-1.7463,  1.9320, -0.3098],\n",
            "        [-2.1946,  0.8208,  0.9407],\n",
            "        [-1.9103,  2.0507, -0.1014],\n",
            "        [-1.6268,  1.8597, -0.2414]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8279,  1.9857, -0.2974],\n",
            "        [-2.0801,  1.9076, -0.1380],\n",
            "        [-1.0927,  1.6291, -0.5943],\n",
            "        [-1.8365,  1.9915, -0.1607],\n",
            "        [-1.8487,  1.9624, -0.2091],\n",
            "        [-1.8986,  0.2878,  1.1534],\n",
            "        [-1.7578,  2.0044, -0.1555],\n",
            "        [-1.6784,  0.9127,  0.6119],\n",
            "        [-0.6701,  0.4714,  0.0276],\n",
            "        [ 0.3275,  0.3538, -1.0149],\n",
            "        [ 0.4775, -0.0735, -0.9274],\n",
            "        [-1.8205,  0.4103,  1.1676],\n",
            "        [-1.7463,  1.9320, -0.3098],\n",
            "        [-2.1946,  0.8208,  0.9407],\n",
            "        [-1.9103,  2.0507, -0.1014],\n",
            "        [-1.6268,  1.8597, -0.2414]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0388e+00,  1.0728e+00,  7.9340e-01],\n",
            "        [-1.4539e+00,  1.0004e-02,  1.1918e+00],\n",
            "        [-1.9009e+00,  4.7413e-01,  1.1358e+00],\n",
            "        [-2.2065e+00,  2.1130e+00, -7.7575e-02],\n",
            "        [-1.7585e+00,  5.0874e-01,  9.7516e-01],\n",
            "        [-1.6437e+00, -1.1966e-05,  1.1165e+00],\n",
            "        [ 7.1616e-01, -1.2322e-01, -7.5012e-01],\n",
            "        [-1.7946e+00,  4.0875e-01,  1.1555e+00],\n",
            "        [-1.7019e+00,  1.9019e+00, -1.6133e-01],\n",
            "        [-2.1422e+00,  1.9547e+00,  1.1015e-01],\n",
            "        [-1.7902e+00,  1.9501e+00, -5.0211e-01],\n",
            "        [ 3.7349e-01,  1.4800e-01, -8.6248e-01],\n",
            "        [-2.0096e+00,  1.5265e+00,  3.2996e-01],\n",
            "        [-1.7811e+00,  4.8739e-01,  1.0496e+00],\n",
            "        [-2.0588e+00,  2.0116e+00, -3.5530e-01],\n",
            "        [-2.0061e+00,  2.1467e+00, -8.3223e-02]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0388e+00,  1.0728e+00,  7.9340e-01],\n",
            "        [-1.4539e+00,  1.0004e-02,  1.1918e+00],\n",
            "        [-1.9009e+00,  4.7413e-01,  1.1358e+00],\n",
            "        [-2.2065e+00,  2.1130e+00, -7.7575e-02],\n",
            "        [-1.7585e+00,  5.0874e-01,  9.7516e-01],\n",
            "        [-1.6437e+00, -1.1966e-05,  1.1165e+00],\n",
            "        [ 7.1616e-01, -1.2322e-01, -7.5012e-01],\n",
            "        [-1.7946e+00,  4.0875e-01,  1.1555e+00],\n",
            "        [-1.7019e+00,  1.9019e+00, -1.6133e-01],\n",
            "        [-2.1422e+00,  1.9547e+00,  1.1015e-01],\n",
            "        [-1.7902e+00,  1.9501e+00, -5.0211e-01],\n",
            "        [ 3.7349e-01,  1.4800e-01, -8.6248e-01],\n",
            "        [-2.0096e+00,  1.5265e+00,  3.2996e-01],\n",
            "        [-1.7811e+00,  4.8739e-01,  1.0496e+00],\n",
            "        [-2.0588e+00,  2.0116e+00, -3.5530e-01],\n",
            "        [-2.0061e+00,  2.1467e+00, -8.3223e-02]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5806,  0.0221, -0.9597],\n",
            "        [ 0.4003,  0.0712, -0.9199],\n",
            "        [-2.0314,  0.2000,  1.1166],\n",
            "        [-2.2018,  0.6254,  1.1223],\n",
            "        [-1.6982,  0.2416,  1.0703],\n",
            "        [-1.9643,  2.1376, -0.3440],\n",
            "        [-1.5122,  1.7228, -0.4589],\n",
            "        [-1.9314,  1.9469,  0.0346],\n",
            "        [ 0.1911,  0.3618, -0.8753],\n",
            "        [-1.7308,  1.9075, -0.3242],\n",
            "        [-1.8062,  1.7791, -0.0131],\n",
            "        [-1.7874,  1.7601, -0.2427],\n",
            "        [-2.3728,  1.4065,  0.6269],\n",
            "        [-1.8851,  1.7462, -0.0983],\n",
            "        [-2.1310,  0.2729,  1.2602],\n",
            "        [-1.6905,  1.8812, -0.1379]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.5806,  0.0221, -0.9597],\n",
            "        [ 0.4003,  0.0712, -0.9199],\n",
            "        [-2.0314,  0.2000,  1.1166],\n",
            "        [-2.2018,  0.6254,  1.1223],\n",
            "        [-1.6982,  0.2416,  1.0703],\n",
            "        [-1.9643,  2.1376, -0.3440],\n",
            "        [-1.5122,  1.7228, -0.4589],\n",
            "        [-1.9314,  1.9469,  0.0346],\n",
            "        [ 0.1911,  0.3618, -0.8753],\n",
            "        [-1.7308,  1.9075, -0.3242],\n",
            "        [-1.8062,  1.7791, -0.0131],\n",
            "        [-1.7874,  1.7601, -0.2427],\n",
            "        [-2.3728,  1.4065,  0.6269],\n",
            "        [-1.8851,  1.7462, -0.0983],\n",
            "        [-2.1310,  0.2729,  1.2602],\n",
            "        [-1.6905,  1.8812, -0.1379]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1033,  2.1409,  0.0359],\n",
            "        [-0.7506,  0.9531, -0.4982],\n",
            "        [-1.9322,  1.8228, -0.0079],\n",
            "        [-2.3090,  0.7984,  1.4036],\n",
            "        [ 0.6599, -0.1417, -0.7787],\n",
            "        [-1.3674,  1.4400, -0.3603],\n",
            "        [-1.8710,  0.4578,  1.3015],\n",
            "        [-2.0478,  1.9460,  0.0642],\n",
            "        [-1.8070,  1.8811, -0.1702],\n",
            "        [-0.7849,  0.5451, -0.0476],\n",
            "        [-2.0877,  2.0487,  0.1280],\n",
            "        [ 0.5784,  0.1368, -0.6619],\n",
            "        [-2.0919,  1.8102,  0.1177],\n",
            "        [-1.8314,  1.7714, -0.1927],\n",
            "        [ 0.5368,  0.0398, -1.0978],\n",
            "        [-1.4090,  1.8171, -0.0725]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1033,  2.1409,  0.0359],\n",
            "        [-0.7506,  0.9531, -0.4982],\n",
            "        [-1.9322,  1.8228, -0.0079],\n",
            "        [-2.3090,  0.7984,  1.4036],\n",
            "        [ 0.6599, -0.1417, -0.7787],\n",
            "        [-1.3674,  1.4400, -0.3603],\n",
            "        [-1.8710,  0.4578,  1.3015],\n",
            "        [-2.0478,  1.9460,  0.0642],\n",
            "        [-1.8070,  1.8811, -0.1702],\n",
            "        [-0.7849,  0.5451, -0.0476],\n",
            "        [-2.0877,  2.0487,  0.1280],\n",
            "        [ 0.5784,  0.1368, -0.6619],\n",
            "        [-2.0919,  1.8102,  0.1177],\n",
            "        [-1.8314,  1.7714, -0.1927],\n",
            "        [ 0.5368,  0.0398, -1.0978],\n",
            "        [-1.4090,  1.8171, -0.0725]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6939,  0.1158,  1.1838],\n",
            "        [-1.8216,  1.9027, -0.2193],\n",
            "        [-1.6249, -0.0549,  1.2068],\n",
            "        [-1.9235,  1.9204, -0.0116],\n",
            "        [-2.0690,  1.5191,  0.1612],\n",
            "        [-2.1277,  1.8087,  0.3343],\n",
            "        [-1.8385,  0.5172,  0.7381],\n",
            "        [-2.0105,  0.1977,  1.2735],\n",
            "        [ 0.5281, -0.0678, -0.9905],\n",
            "        [-1.6922,  1.8607, -0.3567],\n",
            "        [-1.5217, -0.1141,  1.3411],\n",
            "        [-2.0466,  1.9453,  0.0757],\n",
            "        [-1.8716,  1.8692,  0.0061],\n",
            "        [ 0.2473,  0.3033, -0.8771],\n",
            "        [-1.6401,  1.7091, -0.1087],\n",
            "        [ 0.5816,  0.0304, -0.7649]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6939,  0.1158,  1.1838],\n",
            "        [-1.8216,  1.9027, -0.2193],\n",
            "        [-1.6249, -0.0549,  1.2068],\n",
            "        [-1.9235,  1.9204, -0.0116],\n",
            "        [-2.0690,  1.5191,  0.1612],\n",
            "        [-2.1277,  1.8087,  0.3343],\n",
            "        [-1.8385,  0.5172,  0.7381],\n",
            "        [-2.0105,  0.1977,  1.2735],\n",
            "        [ 0.5281, -0.0678, -0.9905],\n",
            "        [-1.6922,  1.8607, -0.3567],\n",
            "        [-1.5217, -0.1141,  1.3411],\n",
            "        [-2.0466,  1.9453,  0.0757],\n",
            "        [-1.8716,  1.8692,  0.0061],\n",
            "        [ 0.2473,  0.3033, -0.8771],\n",
            "        [-1.6401,  1.7091, -0.1087],\n",
            "        [ 0.5816,  0.0304, -0.7649]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1409,  1.5472,  0.2009],\n",
            "        [ 0.2975,  0.0987, -0.7971],\n",
            "        [-2.0046,  0.4248,  1.2094],\n",
            "        [-1.1714,  1.3737, -0.4926],\n",
            "        [-1.4673,  1.7673, -0.2091],\n",
            "        [-1.8740,  1.8335, -0.0509],\n",
            "        [-2.0571,  1.9667,  0.1943],\n",
            "        [-1.9716,  0.4308,  1.2065],\n",
            "        [-1.7679,  1.6528, -0.0704],\n",
            "        [-0.6361,  1.0113, -0.5591],\n",
            "        [ 0.5161, -0.0299, -1.0043],\n",
            "        [-1.6463,  0.6808,  0.7744],\n",
            "        [-1.9951,  1.6743,  0.0552],\n",
            "        [ 0.6161, -0.1273, -0.8353],\n",
            "        [-1.8555,  1.8967, -0.2088],\n",
            "        [-1.8254,  1.9096, -0.0500]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1409,  1.5472,  0.2009],\n",
            "        [ 0.2975,  0.0987, -0.7971],\n",
            "        [-2.0046,  0.4248,  1.2094],\n",
            "        [-1.1714,  1.3737, -0.4926],\n",
            "        [-1.4673,  1.7673, -0.2091],\n",
            "        [-1.8740,  1.8335, -0.0509],\n",
            "        [-2.0571,  1.9667,  0.1943],\n",
            "        [-1.9716,  0.4308,  1.2065],\n",
            "        [-1.7679,  1.6528, -0.0704],\n",
            "        [-0.6361,  1.0113, -0.5591],\n",
            "        [ 0.5161, -0.0299, -1.0043],\n",
            "        [-1.6463,  0.6808,  0.7744],\n",
            "        [-1.9951,  1.6743,  0.0552],\n",
            "        [ 0.6161, -0.1273, -0.8353],\n",
            "        [-1.8555,  1.8967, -0.2088],\n",
            "        [-1.8254,  1.9096, -0.0500]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9986,  1.9892, -0.0401],\n",
            "        [-2.0546,  1.8604,  0.0294],\n",
            "        [-2.1170,  1.9269, -0.1032],\n",
            "        [-0.0488,  0.5116, -0.8600],\n",
            "        [-1.8008,  0.6259,  0.9415],\n",
            "        [-1.7673,  1.8669, -0.2276],\n",
            "        [-1.8233,  2.0263,  0.1019],\n",
            "        [-2.0224,  2.0370,  0.0346],\n",
            "        [-2.1376,  2.1673, -0.2032],\n",
            "        [ 0.3915, -0.0174, -0.7377],\n",
            "        [-1.9740,  2.1278, -0.0608],\n",
            "        [-1.8764,  1.6321, -0.1261],\n",
            "        [-1.5108,  1.2970,  0.0290],\n",
            "        [-2.0603,  2.0318,  0.0441],\n",
            "        [-1.8769,  1.8121, -0.0669],\n",
            "        [-2.0328,  0.5732,  1.1487]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9986,  1.9892, -0.0401],\n",
            "        [-2.0546,  1.8604,  0.0294],\n",
            "        [-2.1170,  1.9269, -0.1032],\n",
            "        [-0.0488,  0.5116, -0.8600],\n",
            "        [-1.8008,  0.6259,  0.9415],\n",
            "        [-1.7673,  1.8669, -0.2276],\n",
            "        [-1.8233,  2.0263,  0.1019],\n",
            "        [-2.0224,  2.0370,  0.0346],\n",
            "        [-2.1376,  2.1673, -0.2032],\n",
            "        [ 0.3915, -0.0174, -0.7377],\n",
            "        [-1.9740,  2.1278, -0.0608],\n",
            "        [-1.8764,  1.6321, -0.1261],\n",
            "        [-1.5108,  1.2970,  0.0290],\n",
            "        [-2.0603,  2.0318,  0.0441],\n",
            "        [-1.8769,  1.8121, -0.0669],\n",
            "        [-2.0328,  0.5732,  1.1487]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2429,  1.9614,  0.1404],\n",
            "        [-1.7766,  1.7295,  0.0293],\n",
            "        [-2.2854,  1.5669,  0.4702],\n",
            "        [-1.5702, -0.1204,  1.3506],\n",
            "        [-2.2436,  1.5027,  0.4552],\n",
            "        [-1.9607,  1.7375,  0.1340],\n",
            "        [-2.2638,  1.5732,  0.2601],\n",
            "        [-2.0281,  0.2873,  1.3472],\n",
            "        [-2.1977,  0.8094,  1.2240],\n",
            "        [-2.3911,  1.1915,  0.7232],\n",
            "        [-2.0322,  1.7049,  0.0798],\n",
            "        [ 0.3782,  0.0433, -0.7843],\n",
            "        [-2.2657,  2.0306, -0.0386],\n",
            "        [-0.1154,  0.0572, -0.3321],\n",
            "        [ 0.2114,  0.0765, -0.8176],\n",
            "        [-2.3311,  1.9211,  0.1678]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.2429,  1.9614,  0.1404],\n",
            "        [-1.7766,  1.7295,  0.0293],\n",
            "        [-2.2854,  1.5669,  0.4702],\n",
            "        [-1.5702, -0.1204,  1.3506],\n",
            "        [-2.2436,  1.5027,  0.4552],\n",
            "        [-1.9607,  1.7375,  0.1340],\n",
            "        [-2.2638,  1.5732,  0.2601],\n",
            "        [-2.0281,  0.2873,  1.3472],\n",
            "        [-2.1977,  0.8094,  1.2240],\n",
            "        [-2.3911,  1.1915,  0.7232],\n",
            "        [-2.0322,  1.7049,  0.0798],\n",
            "        [ 0.3782,  0.0433, -0.7843],\n",
            "        [-2.2657,  2.0306, -0.0386],\n",
            "        [-0.1154,  0.0572, -0.3321],\n",
            "        [ 0.2114,  0.0765, -0.8176],\n",
            "        [-2.3311,  1.9211,  0.1678]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9879,  0.3601,  1.2459],\n",
            "        [-2.0899,  1.5898,  0.2870],\n",
            "        [-1.7409,  0.3856,  1.2300],\n",
            "        [-0.4615,  0.3539, -0.5364],\n",
            "        [-1.0700,  0.5692,  0.3435],\n",
            "        [-1.5005,  0.7350,  0.5259],\n",
            "        [-2.2444,  1.6210,  0.0534],\n",
            "        [-1.6915,  0.5293,  0.9911],\n",
            "        [-2.0955,  1.7662, -0.1679],\n",
            "        [-2.1602,  1.9549,  0.0625],\n",
            "        [-2.3003,  0.6487,  1.3337],\n",
            "        [ 0.3956,  0.0258, -0.6257],\n",
            "        [-2.1501,  1.5451,  0.2912],\n",
            "        [ 0.5523, -0.1414, -0.6962],\n",
            "        [-1.2506,  1.2559, -0.3018],\n",
            "        [ 0.3406,  0.0046, -0.8321]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9879,  0.3601,  1.2459],\n",
            "        [-2.0899,  1.5898,  0.2870],\n",
            "        [-1.7409,  0.3856,  1.2300],\n",
            "        [-0.4615,  0.3539, -0.5364],\n",
            "        [-1.0700,  0.5692,  0.3435],\n",
            "        [-1.5005,  0.7350,  0.5259],\n",
            "        [-2.2444,  1.6210,  0.0534],\n",
            "        [-1.6915,  0.5293,  0.9911],\n",
            "        [-2.0955,  1.7662, -0.1679],\n",
            "        [-2.1602,  1.9549,  0.0625],\n",
            "        [-2.3003,  0.6487,  1.3337],\n",
            "        [ 0.3956,  0.0258, -0.6257],\n",
            "        [-2.1501,  1.5451,  0.2912],\n",
            "        [ 0.5523, -0.1414, -0.6962],\n",
            "        [-1.2506,  1.2559, -0.3018],\n",
            "        [ 0.3406,  0.0046, -0.8321]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9524,  0.4004,  1.1391],\n",
            "        [-2.1815,  0.8654,  1.1246],\n",
            "        [-2.0985,  1.8226,  0.3026],\n",
            "        [-1.9281,  1.5126, -0.1114],\n",
            "        [-1.9253,  1.4716,  0.0805],\n",
            "        [-2.3453,  1.8988,  0.0808],\n",
            "        [ 0.4987, -0.0051, -0.6302],\n",
            "        [-2.2792,  1.5851,  0.1037],\n",
            "        [-1.8387,  1.9276, -0.2637],\n",
            "        [-2.1941,  1.7888,  0.0851],\n",
            "        [-2.1824,  1.9362,  0.1904],\n",
            "        [-2.1550,  1.8435, -0.0096],\n",
            "        [-1.5949, -0.1857,  1.3051],\n",
            "        [-2.2723,  1.7165,  0.2818],\n",
            "        [-1.7280, -0.0708,  1.3021],\n",
            "        [-2.0832,  1.6110, -0.1172]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9524,  0.4004,  1.1391],\n",
            "        [-2.1815,  0.8654,  1.1246],\n",
            "        [-2.0985,  1.8226,  0.3026],\n",
            "        [-1.9281,  1.5126, -0.1114],\n",
            "        [-1.9253,  1.4716,  0.0805],\n",
            "        [-2.3453,  1.8988,  0.0808],\n",
            "        [ 0.4987, -0.0051, -0.6302],\n",
            "        [-2.2792,  1.5851,  0.1037],\n",
            "        [-1.8387,  1.9276, -0.2637],\n",
            "        [-2.1941,  1.7888,  0.0851],\n",
            "        [-2.1824,  1.9362,  0.1904],\n",
            "        [-2.1550,  1.8435, -0.0096],\n",
            "        [-1.5949, -0.1857,  1.3051],\n",
            "        [-2.2723,  1.7165,  0.2818],\n",
            "        [-1.7280, -0.0708,  1.3021],\n",
            "        [-2.0832,  1.6110, -0.1172]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9827,  1.7538, -0.0169],\n",
            "        [ 0.5003, -0.1890, -0.6232],\n",
            "        [-2.4823,  1.1385,  0.9052],\n",
            "        [-2.2339,  1.9621,  0.0877],\n",
            "        [-1.9878, -0.0385,  1.3451],\n",
            "        [-1.8909,  1.6778,  0.2908],\n",
            "        [-1.7586,  1.4903,  0.1697],\n",
            "        [-2.2393,  1.9862,  0.2403],\n",
            "        [-1.8787,  1.7773,  0.1327],\n",
            "        [-2.1942,  1.8776,  0.1235],\n",
            "        [-1.7314,  1.6989, -0.0405],\n",
            "        [ 0.3638, -0.2842, -0.6592],\n",
            "        [ 0.2932,  0.0637, -0.6743],\n",
            "        [-1.6009,  0.3315,  0.9690],\n",
            "        [-1.5229,  0.1758,  0.9395],\n",
            "        [-0.5025, -0.0148,  0.3643]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9827,  1.7538, -0.0169],\n",
            "        [ 0.5003, -0.1890, -0.6232],\n",
            "        [-2.4823,  1.1385,  0.9052],\n",
            "        [-2.2339,  1.9621,  0.0877],\n",
            "        [-1.9878, -0.0385,  1.3451],\n",
            "        [-1.8909,  1.6778,  0.2908],\n",
            "        [-1.7586,  1.4903,  0.1697],\n",
            "        [-2.2393,  1.9862,  0.2403],\n",
            "        [-1.8787,  1.7773,  0.1327],\n",
            "        [-2.1942,  1.8776,  0.1235],\n",
            "        [-1.7314,  1.6989, -0.0405],\n",
            "        [ 0.3638, -0.2842, -0.6592],\n",
            "        [ 0.2932,  0.0637, -0.6743],\n",
            "        [-1.6009,  0.3315,  0.9690],\n",
            "        [-1.5229,  0.1758,  0.9395],\n",
            "        [-0.5025, -0.0148,  0.3643]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2578,  1.7243,  0.0671],\n",
            "        [-2.1748,  1.2107,  0.5614],\n",
            "        [-2.1959,  1.4926,  0.5417],\n",
            "        [-1.8145,  1.2943,  0.1614],\n",
            "        [-1.9308,  1.8557,  0.0608],\n",
            "        [-1.7417,  0.3074,  1.2116],\n",
            "        [-1.0098,  0.3557,  0.3407],\n",
            "        [-2.2339,  0.3379,  1.4817],\n",
            "        [-2.2410,  1.7564,  0.0820],\n",
            "        [-1.7643,  1.5932, -0.3065],\n",
            "        [-1.8952,  1.4384, -0.0115],\n",
            "        [ 0.3581, -0.1806, -0.8143],\n",
            "        [-2.1424,  1.7808,  0.2295],\n",
            "        [-1.8574,  0.2481,  1.3264],\n",
            "        [-1.9296,  1.9931, -0.0256],\n",
            "        [-1.8751,  0.0097,  1.4562]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.2578,  1.7243,  0.0671],\n",
            "        [-2.1748,  1.2107,  0.5614],\n",
            "        [-2.1959,  1.4926,  0.5417],\n",
            "        [-1.8145,  1.2943,  0.1614],\n",
            "        [-1.9308,  1.8557,  0.0608],\n",
            "        [-1.7417,  0.3074,  1.2116],\n",
            "        [-1.0098,  0.3557,  0.3407],\n",
            "        [-2.2339,  0.3379,  1.4817],\n",
            "        [-2.2410,  1.7564,  0.0820],\n",
            "        [-1.7643,  1.5932, -0.3065],\n",
            "        [-1.8952,  1.4384, -0.0115],\n",
            "        [ 0.3581, -0.1806, -0.8143],\n",
            "        [-2.1424,  1.7808,  0.2295],\n",
            "        [-1.8574,  0.2481,  1.3264],\n",
            "        [-1.9296,  1.9931, -0.0256],\n",
            "        [-1.8751,  0.0097,  1.4562]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 1.8550e-01, -6.6454e-02, -4.0802e-01],\n",
            "        [-2.3452e+00,  1.8774e+00,  2.7355e-01],\n",
            "        [-2.2182e+00,  6.7701e-01,  1.3160e+00],\n",
            "        [-2.0088e+00,  3.4774e-01,  1.2738e+00],\n",
            "        [-2.2997e+00,  1.9197e+00,  4.0437e-01],\n",
            "        [-1.9742e+00,  4.8095e-01,  1.4711e+00],\n",
            "        [-2.2824e+00,  6.9714e-01,  8.8607e-01],\n",
            "        [-1.7714e+00,  1.2956e-03,  1.4237e+00],\n",
            "        [-2.2842e+00,  1.5973e+00,  2.6539e-01],\n",
            "        [ 4.7060e-01, -6.1313e-02, -6.1803e-01],\n",
            "        [-1.8425e+00,  1.7588e+00,  1.7532e-01],\n",
            "        [-1.9967e+00,  1.6791e+00,  8.1486e-02],\n",
            "        [-2.2253e+00,  8.7285e-01,  1.2634e+00],\n",
            "        [-2.3670e+00,  1.1510e+00,  6.0493e-01],\n",
            "        [-2.2300e+00,  1.6938e+00,  2.0844e-01],\n",
            "        [ 2.0146e-01,  1.1447e-01, -7.7836e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 1.8550e-01, -6.6454e-02, -4.0802e-01],\n",
            "        [-2.3452e+00,  1.8774e+00,  2.7355e-01],\n",
            "        [-2.2182e+00,  6.7701e-01,  1.3160e+00],\n",
            "        [-2.0088e+00,  3.4774e-01,  1.2738e+00],\n",
            "        [-2.2997e+00,  1.9197e+00,  4.0437e-01],\n",
            "        [-1.9742e+00,  4.8095e-01,  1.4711e+00],\n",
            "        [-2.2824e+00,  6.9714e-01,  8.8607e-01],\n",
            "        [-1.7714e+00,  1.2956e-03,  1.4237e+00],\n",
            "        [-2.2842e+00,  1.5973e+00,  2.6539e-01],\n",
            "        [ 4.7060e-01, -6.1313e-02, -6.1803e-01],\n",
            "        [-1.8425e+00,  1.7588e+00,  1.7532e-01],\n",
            "        [-1.9967e+00,  1.6791e+00,  8.1486e-02],\n",
            "        [-2.2253e+00,  8.7285e-01,  1.2634e+00],\n",
            "        [-2.3670e+00,  1.1510e+00,  6.0493e-01],\n",
            "        [-2.2300e+00,  1.6938e+00,  2.0844e-01],\n",
            "        [ 2.0146e-01,  1.1447e-01, -7.7836e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1683e+00,  1.7596e-01,  1.3482e+00],\n",
            "        [-3.0844e-01, -7.4550e-03,  3.3931e-02],\n",
            "        [-1.9840e+00,  8.0633e-01,  8.8481e-01],\n",
            "        [-1.9342e+00,  1.7138e+00,  1.3777e-01],\n",
            "        [-2.2205e+00,  1.5264e+00,  5.9592e-01],\n",
            "        [-1.8981e+00,  1.2304e-02,  1.4844e+00],\n",
            "        [-1.9341e+00,  1.4548e+00,  2.9653e-01],\n",
            "        [-1.9298e+00,  1.2402e-01,  1.1993e+00],\n",
            "        [-1.6865e+00,  1.6469e+00, -6.9512e-02],\n",
            "        [-1.8857e+00,  1.7035e+00, -3.4553e-04],\n",
            "        [-2.2346e+00,  1.9992e+00, -2.9898e-02],\n",
            "        [ 4.4297e-01, -9.5890e-02, -5.5328e-01],\n",
            "        [-2.0639e+00,  4.5922e-01,  1.2944e+00],\n",
            "        [-1.8733e+00,  7.8179e-03,  1.5865e+00],\n",
            "        [-2.1405e+00,  1.1458e+00,  1.0892e+00],\n",
            "        [-1.9925e+00,  8.2877e-01,  8.0980e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1683e+00,  1.7596e-01,  1.3482e+00],\n",
            "        [-3.0844e-01, -7.4550e-03,  3.3931e-02],\n",
            "        [-1.9840e+00,  8.0633e-01,  8.8481e-01],\n",
            "        [-1.9342e+00,  1.7138e+00,  1.3777e-01],\n",
            "        [-2.2205e+00,  1.5264e+00,  5.9592e-01],\n",
            "        [-1.8981e+00,  1.2304e-02,  1.4844e+00],\n",
            "        [-1.9341e+00,  1.4548e+00,  2.9653e-01],\n",
            "        [-1.9298e+00,  1.2402e-01,  1.1993e+00],\n",
            "        [-1.6865e+00,  1.6469e+00, -6.9512e-02],\n",
            "        [-1.8857e+00,  1.7035e+00, -3.4553e-04],\n",
            "        [-2.2346e+00,  1.9992e+00, -2.9898e-02],\n",
            "        [ 4.4297e-01, -9.5890e-02, -5.5328e-01],\n",
            "        [-2.0639e+00,  4.5922e-01,  1.2944e+00],\n",
            "        [-1.8733e+00,  7.8179e-03,  1.5865e+00],\n",
            "        [-2.1405e+00,  1.1458e+00,  1.0892e+00],\n",
            "        [-1.9925e+00,  8.2877e-01,  8.0980e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.4071, -0.0584,  0.1550],\n",
            "        [-0.3623,  0.7068, -0.8859],\n",
            "        [-2.3095,  0.4446,  1.3430],\n",
            "        [-0.0716,  0.2316, -0.4129],\n",
            "        [-2.2325,  1.7076,  0.3211],\n",
            "        [-2.0347,  1.7504, -0.1966],\n",
            "        [-2.0991,  1.7922,  0.0904],\n",
            "        [-1.8346,  0.3604,  1.2811],\n",
            "        [-1.1536,  1.2716, -0.3680],\n",
            "        [-2.3599,  1.8179,  0.0844],\n",
            "        [-2.0132,  0.3440,  1.3561],\n",
            "        [-1.5066,  1.5607, -0.1114],\n",
            "        [ 0.4046, -0.1341, -0.7614],\n",
            "        [-1.4870,  0.8783,  0.4010],\n",
            "        [-1.7100,  0.0316,  1.3478],\n",
            "        [-1.8823,  1.7258,  0.0600]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-0.4071, -0.0584,  0.1550],\n",
            "        [-0.3623,  0.7068, -0.8859],\n",
            "        [-2.3095,  0.4446,  1.3430],\n",
            "        [-0.0716,  0.2316, -0.4129],\n",
            "        [-2.2325,  1.7076,  0.3211],\n",
            "        [-2.0347,  1.7504, -0.1966],\n",
            "        [-2.0991,  1.7922,  0.0904],\n",
            "        [-1.8346,  0.3604,  1.2811],\n",
            "        [-1.1536,  1.2716, -0.3680],\n",
            "        [-2.3599,  1.8179,  0.0844],\n",
            "        [-2.0132,  0.3440,  1.3561],\n",
            "        [-1.5066,  1.5607, -0.1114],\n",
            "        [ 0.4046, -0.1341, -0.7614],\n",
            "        [-1.4870,  0.8783,  0.4010],\n",
            "        [-1.7100,  0.0316,  1.3478],\n",
            "        [-1.8823,  1.7258,  0.0600]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1940,  0.9678,  0.8905],\n",
            "        [-2.3988,  1.1978,  0.8125],\n",
            "        [-1.5627,  0.1567,  1.0047],\n",
            "        [-1.8386,  1.7623,  0.3003],\n",
            "        [-2.0199,  0.0114,  1.2929],\n",
            "        [ 0.3544, -0.1047, -0.5480],\n",
            "        [-1.9406,  1.8089, -0.0545],\n",
            "        [-1.8423,  0.0801,  1.3246],\n",
            "        [ 0.3617, -0.1898, -0.5609],\n",
            "        [-2.5776,  1.4888,  0.8690],\n",
            "        [-0.9759,  1.2395, -0.4509],\n",
            "        [-1.8985,  0.2619,  1.1281],\n",
            "        [-1.9680,  1.7949,  0.1556],\n",
            "        [-1.9239,  0.2211,  1.3188],\n",
            "        [-1.9134,  0.2684,  1.2422],\n",
            "        [-2.1184,  0.7554,  0.9817]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1940,  0.9678,  0.8905],\n",
            "        [-2.3988,  1.1978,  0.8125],\n",
            "        [-1.5627,  0.1567,  1.0047],\n",
            "        [-1.8386,  1.7623,  0.3003],\n",
            "        [-2.0199,  0.0114,  1.2929],\n",
            "        [ 0.3544, -0.1047, -0.5480],\n",
            "        [-1.9406,  1.8089, -0.0545],\n",
            "        [-1.8423,  0.0801,  1.3246],\n",
            "        [ 0.3617, -0.1898, -0.5609],\n",
            "        [-2.5776,  1.4888,  0.8690],\n",
            "        [-0.9759,  1.2395, -0.4509],\n",
            "        [-1.8985,  0.2619,  1.1281],\n",
            "        [-1.9680,  1.7949,  0.1556],\n",
            "        [-1.9239,  0.2211,  1.3188],\n",
            "        [-1.9134,  0.2684,  1.2422],\n",
            "        [-2.1184,  0.7554,  0.9817]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.3614,  1.1380,  1.0301],\n",
            "        [ 0.4110, -0.1803, -0.3939],\n",
            "        [-2.2228,  1.5175,  0.5413],\n",
            "        [-1.3929,  1.7136, -0.3633],\n",
            "        [-2.1800,  0.9457,  0.9585],\n",
            "        [-2.0276,  0.5464,  1.1645],\n",
            "        [-2.0455,  1.8832,  0.0643],\n",
            "        [-0.5774,  0.8598, -0.8602],\n",
            "        [-2.1465,  1.9067,  0.0156],\n",
            "        [-2.2301,  1.0629,  1.2173],\n",
            "        [ 0.2639,  0.0082, -0.5808],\n",
            "        [-1.5646,  0.1184,  1.1207],\n",
            "        [-2.0399,  0.5422,  1.3090],\n",
            "        [-1.9191,  1.9304, -0.0533],\n",
            "        [-1.9114,  1.8515, -0.0068],\n",
            "        [-1.7856,  1.5590, -0.0460]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.3614,  1.1380,  1.0301],\n",
            "        [ 0.4110, -0.1803, -0.3939],\n",
            "        [-2.2228,  1.5175,  0.5413],\n",
            "        [-1.3929,  1.7136, -0.3633],\n",
            "        [-2.1800,  0.9457,  0.9585],\n",
            "        [-2.0276,  0.5464,  1.1645],\n",
            "        [-2.0455,  1.8832,  0.0643],\n",
            "        [-0.5774,  0.8598, -0.8602],\n",
            "        [-2.1465,  1.9067,  0.0156],\n",
            "        [-2.2301,  1.0629,  1.2173],\n",
            "        [ 0.2639,  0.0082, -0.5808],\n",
            "        [-1.5646,  0.1184,  1.1207],\n",
            "        [-2.0399,  0.5422,  1.3090],\n",
            "        [-1.9191,  1.9304, -0.0533],\n",
            "        [-1.9114,  1.8515, -0.0068],\n",
            "        [-1.7856,  1.5590, -0.0460]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1384,  1.7499,  0.1229],\n",
            "        [-0.3868,  0.0195,  0.0995],\n",
            "        [-1.5003,  0.0654,  1.2575],\n",
            "        [-2.1200,  1.6607,  0.2727],\n",
            "        [-2.1375,  1.8108,  0.0888],\n",
            "        [-1.2767,  0.3778,  0.8539],\n",
            "        [-1.9883,  1.4429, -0.0473],\n",
            "        [-1.9132,  0.3411,  1.3088],\n",
            "        [ 0.3115,  0.0916, -0.7521],\n",
            "        [ 0.3214,  0.0421, -0.7095],\n",
            "        [-1.7365,  0.1405,  1.3313],\n",
            "        [-1.8219,  2.0185,  0.0314],\n",
            "        [-1.7574,  1.7531, -0.0812],\n",
            "        [-1.8857,  0.4573,  1.1570],\n",
            "        [-2.0843,  1.4320,  0.4892],\n",
            "        [-2.2087,  1.8138, -0.0059]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1384,  1.7499,  0.1229],\n",
            "        [-0.3868,  0.0195,  0.0995],\n",
            "        [-1.5003,  0.0654,  1.2575],\n",
            "        [-2.1200,  1.6607,  0.2727],\n",
            "        [-2.1375,  1.8108,  0.0888],\n",
            "        [-1.2767,  0.3778,  0.8539],\n",
            "        [-1.9883,  1.4429, -0.0473],\n",
            "        [-1.9132,  0.3411,  1.3088],\n",
            "        [ 0.3115,  0.0916, -0.7521],\n",
            "        [ 0.3214,  0.0421, -0.7095],\n",
            "        [-1.7365,  0.1405,  1.3313],\n",
            "        [-1.8219,  2.0185,  0.0314],\n",
            "        [-1.7574,  1.7531, -0.0812],\n",
            "        [-1.8857,  0.4573,  1.1570],\n",
            "        [-2.0843,  1.4320,  0.4892],\n",
            "        [-2.2087,  1.8138, -0.0059]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0240,  0.5834,  1.1283],\n",
            "        [-1.7183,  0.1488,  1.2269],\n",
            "        [-2.0897,  1.7379,  0.1642],\n",
            "        [-2.2035,  0.7779,  1.0803],\n",
            "        [-2.0807,  1.6935, -0.0776],\n",
            "        [-1.6213,  0.2046,  1.3093],\n",
            "        [ 0.1707,  0.0140, -0.5242],\n",
            "        [-1.8224,  1.4902,  0.2507],\n",
            "        [-1.6947,  1.9286,  0.1757],\n",
            "        [-2.4373,  2.1449, -0.0732],\n",
            "        [-1.9168,  1.6835,  0.1190],\n",
            "        [-0.2636,  0.6146, -0.6983],\n",
            "        [-1.8572,  1.9584,  0.0559],\n",
            "        [-1.8726,  1.9005, -0.0672],\n",
            "        [-2.1811,  0.2137,  1.2652],\n",
            "        [-0.7078,  0.5874, -0.1122]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0240,  0.5834,  1.1283],\n",
            "        [-1.7183,  0.1488,  1.2269],\n",
            "        [-2.0897,  1.7379,  0.1642],\n",
            "        [-2.2035,  0.7779,  1.0803],\n",
            "        [-2.0807,  1.6935, -0.0776],\n",
            "        [-1.6213,  0.2046,  1.3093],\n",
            "        [ 0.1707,  0.0140, -0.5242],\n",
            "        [-1.8224,  1.4902,  0.2507],\n",
            "        [-1.6947,  1.9286,  0.1757],\n",
            "        [-2.4373,  2.1449, -0.0732],\n",
            "        [-1.9168,  1.6835,  0.1190],\n",
            "        [-0.2636,  0.6146, -0.6983],\n",
            "        [-1.8572,  1.9584,  0.0559],\n",
            "        [-1.8726,  1.9005, -0.0672],\n",
            "        [-2.1811,  0.2137,  1.2652],\n",
            "        [-0.7078,  0.5874, -0.1122]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6439,  0.3138,  1.2551],\n",
            "        [-1.6702,  1.5267, -0.3727],\n",
            "        [-2.0169,  0.7118,  0.8616],\n",
            "        [-1.7934,  1.8505, -0.1025],\n",
            "        [-2.2947,  1.1398,  0.7626],\n",
            "        [-2.2112,  2.1920, -0.1253],\n",
            "        [ 0.2009, -0.0256, -0.5132],\n",
            "        [-2.1766,  1.6477,  0.2479],\n",
            "        [-2.4674,  1.4888,  0.6668],\n",
            "        [-1.9279,  2.0197, -0.1968],\n",
            "        [-2.1702,  2.1130, -0.1999],\n",
            "        [ 0.3988, -0.2165, -0.5653],\n",
            "        [-1.6635,  1.8969, -0.2454],\n",
            "        [-1.7774,  1.6064, -0.2258],\n",
            "        [-2.2335,  1.6717,  0.0502],\n",
            "        [-2.0220,  1.7896, -0.0185]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6439,  0.3138,  1.2551],\n",
            "        [-1.6702,  1.5267, -0.3727],\n",
            "        [-2.0169,  0.7118,  0.8616],\n",
            "        [-1.7934,  1.8505, -0.1025],\n",
            "        [-2.2947,  1.1398,  0.7626],\n",
            "        [-2.2112,  2.1920, -0.1253],\n",
            "        [ 0.2009, -0.0256, -0.5132],\n",
            "        [-2.1766,  1.6477,  0.2479],\n",
            "        [-2.4674,  1.4888,  0.6668],\n",
            "        [-1.9279,  2.0197, -0.1968],\n",
            "        [-2.1702,  2.1130, -0.1999],\n",
            "        [ 0.3988, -0.2165, -0.5653],\n",
            "        [-1.6635,  1.8969, -0.2454],\n",
            "        [-1.7774,  1.6064, -0.2258],\n",
            "        [-2.2335,  1.6717,  0.0502],\n",
            "        [-2.0220,  1.7896, -0.0185]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7549,  0.7328,  0.4039],\n",
            "        [ 0.2895, -0.0801, -0.5515],\n",
            "        [-1.9835,  2.0172, -0.0486],\n",
            "        [-1.7308,  1.7772, -0.2612],\n",
            "        [-1.8490,  1.8546, -0.1503],\n",
            "        [-1.9326,  1.9569, -0.1776],\n",
            "        [-1.5144,  1.6662, -0.4058],\n",
            "        [-1.9684,  1.9657, -0.0482],\n",
            "        [ 0.3548, -0.1471, -0.7216],\n",
            "        [ 0.2574,  0.0077, -0.6658],\n",
            "        [-1.8839,  2.0874, -0.3498],\n",
            "        [-1.8929,  2.1075, -0.1763],\n",
            "        [-2.4657,  1.3390,  0.9454],\n",
            "        [-1.7176,  1.7948, -0.2376],\n",
            "        [-1.8821,  1.6426, -0.0597],\n",
            "        [-1.8487,  0.5825,  1.1267]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7549,  0.7328,  0.4039],\n",
            "        [ 0.2895, -0.0801, -0.5515],\n",
            "        [-1.9835,  2.0172, -0.0486],\n",
            "        [-1.7308,  1.7772, -0.2612],\n",
            "        [-1.8490,  1.8546, -0.1503],\n",
            "        [-1.9326,  1.9569, -0.1776],\n",
            "        [-1.5144,  1.6662, -0.4058],\n",
            "        [-1.9684,  1.9657, -0.0482],\n",
            "        [ 0.3548, -0.1471, -0.7216],\n",
            "        [ 0.2574,  0.0077, -0.6658],\n",
            "        [-1.8839,  2.0874, -0.3498],\n",
            "        [-1.8929,  2.1075, -0.1763],\n",
            "        [-2.4657,  1.3390,  0.9454],\n",
            "        [-1.7176,  1.7948, -0.2376],\n",
            "        [-1.8821,  1.6426, -0.0597],\n",
            "        [-1.8487,  0.5825,  1.1267]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.2826,  0.1501, -0.8328],\n",
            "        [ 0.2755,  0.0087, -0.6638],\n",
            "        [-2.0299,  1.8631, -0.1432],\n",
            "        [-2.0139,  1.9577, -0.2332],\n",
            "        [-1.9429,  1.8388, -0.1134],\n",
            "        [-2.0182,  1.7790, -0.2344],\n",
            "        [-1.9457,  1.9980, -0.0561],\n",
            "        [-1.8038,  1.7324, -0.3496],\n",
            "        [-1.9849,  1.9060, -0.1028],\n",
            "        [ 0.0825,  0.1639, -0.5873],\n",
            "        [ 0.2449,  0.0213, -0.7051],\n",
            "        [-1.3982,  1.3944, -0.5707],\n",
            "        [-2.3346,  1.3084,  0.7468],\n",
            "        [-1.9931,  1.5528,  0.0134],\n",
            "        [-1.7922,  1.8609, -0.1935],\n",
            "        [-1.8100,  0.5899,  0.8082]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.2826,  0.1501, -0.8328],\n",
            "        [ 0.2755,  0.0087, -0.6638],\n",
            "        [-2.0299,  1.8631, -0.1432],\n",
            "        [-2.0139,  1.9577, -0.2332],\n",
            "        [-1.9429,  1.8388, -0.1134],\n",
            "        [-2.0182,  1.7790, -0.2344],\n",
            "        [-1.9457,  1.9980, -0.0561],\n",
            "        [-1.8038,  1.7324, -0.3496],\n",
            "        [-1.9849,  1.9060, -0.1028],\n",
            "        [ 0.0825,  0.1639, -0.5873],\n",
            "        [ 0.2449,  0.0213, -0.7051],\n",
            "        [-1.3982,  1.3944, -0.5707],\n",
            "        [-2.3346,  1.3084,  0.7468],\n",
            "        [-1.9931,  1.5528,  0.0134],\n",
            "        [-1.7922,  1.8609, -0.1935],\n",
            "        [-1.8100,  0.5899,  0.8082]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7501,  0.6862,  0.7280],\n",
            "        [-1.9211,  1.9553, -0.2012],\n",
            "        [-2.0001,  1.9428, -0.2515],\n",
            "        [-1.8213,  1.9829, -0.2607],\n",
            "        [-2.2371,  1.4698,  0.4496],\n",
            "        [-1.6691,  0.5143,  0.9057],\n",
            "        [-2.3334,  1.1120,  0.8973],\n",
            "        [-1.5597,  0.5505,  0.7185],\n",
            "        [-1.9727,  1.6849,  0.2625],\n",
            "        [-2.3728,  0.9357,  0.9793],\n",
            "        [-2.1159,  0.4489,  1.1196],\n",
            "        [-1.7320,  0.4637,  1.1406],\n",
            "        [-2.0510,  1.9693, -0.2150],\n",
            "        [-2.4250,  0.8491,  1.0057],\n",
            "        [-2.0708,  1.8928, -0.2013],\n",
            "        [-1.8983,  1.9538, -0.1508]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7501,  0.6862,  0.7280],\n",
            "        [-1.9211,  1.9553, -0.2012],\n",
            "        [-2.0001,  1.9428, -0.2515],\n",
            "        [-1.8213,  1.9829, -0.2607],\n",
            "        [-2.2371,  1.4698,  0.4496],\n",
            "        [-1.6691,  0.5143,  0.9057],\n",
            "        [-2.3334,  1.1120,  0.8973],\n",
            "        [-1.5597,  0.5505,  0.7185],\n",
            "        [-1.9727,  1.6849,  0.2625],\n",
            "        [-2.3728,  0.9357,  0.9793],\n",
            "        [-2.1159,  0.4489,  1.1196],\n",
            "        [-1.7320,  0.4637,  1.1406],\n",
            "        [-2.0510,  1.9693, -0.2150],\n",
            "        [-2.4250,  0.8491,  1.0057],\n",
            "        [-2.0708,  1.8928, -0.2013],\n",
            "        [-1.8983,  1.9538, -0.1508]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3327, -0.2144, -0.4604],\n",
            "        [-1.6136,  0.5918,  0.7576],\n",
            "        [-1.8637,  1.9608, -0.2252],\n",
            "        [-2.0785,  1.1700,  0.7060],\n",
            "        [ 0.4138, -0.1601, -0.7234],\n",
            "        [-2.0009,  0.6500,  1.0588],\n",
            "        [-2.1772,  1.2035,  0.8171],\n",
            "        [-1.9312,  2.0248, -0.1438],\n",
            "        [-2.1799,  1.0886,  1.0407],\n",
            "        [ 0.3216, -0.0735, -0.6430],\n",
            "        [-1.7455,  1.8386, -0.4077],\n",
            "        [-1.9492,  1.9423,  0.0341],\n",
            "        [-1.9112,  0.5874,  1.1702],\n",
            "        [-1.9190,  2.0275,  0.0036],\n",
            "        [-1.9467,  2.0114, -0.1583],\n",
            "        [-1.9342,  1.9379, -0.2027]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.3327, -0.2144, -0.4604],\n",
            "        [-1.6136,  0.5918,  0.7576],\n",
            "        [-1.8637,  1.9608, -0.2252],\n",
            "        [-2.0785,  1.1700,  0.7060],\n",
            "        [ 0.4138, -0.1601, -0.7234],\n",
            "        [-2.0009,  0.6500,  1.0588],\n",
            "        [-2.1772,  1.2035,  0.8171],\n",
            "        [-1.9312,  2.0248, -0.1438],\n",
            "        [-2.1799,  1.0886,  1.0407],\n",
            "        [ 0.3216, -0.0735, -0.6430],\n",
            "        [-1.7455,  1.8386, -0.4077],\n",
            "        [-1.9492,  1.9423,  0.0341],\n",
            "        [-1.9112,  0.5874,  1.1702],\n",
            "        [-1.9190,  2.0275,  0.0036],\n",
            "        [-1.9467,  2.0114, -0.1583],\n",
            "        [-1.9342,  1.9379, -0.2027]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3383, -0.1208, -0.5647],\n",
            "        [-1.9975,  0.5015,  1.2948],\n",
            "        [-1.9234,  1.9467, -0.0901],\n",
            "        [-1.5901,  1.7964, -0.7084],\n",
            "        [ 0.1963,  0.0539, -0.6886],\n",
            "        [ 0.3228,  0.0457, -0.7744],\n",
            "        [-2.0107,  0.7829,  1.1400],\n",
            "        [-2.2657,  0.8365,  0.8401],\n",
            "        [ 0.2290, -0.0478, -0.2443],\n",
            "        [-1.9262,  2.0177, -0.1345],\n",
            "        [-1.8076,  1.8180, -0.2609],\n",
            "        [-1.7220,  1.5027, -0.1744],\n",
            "        [-1.9109,  0.7208,  0.8693],\n",
            "        [-2.1894,  1.7405,  0.2135],\n",
            "        [-1.9404,  0.3486,  1.2165],\n",
            "        [ 0.3332, -0.0453, -0.6760]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.3383, -0.1208, -0.5647],\n",
            "        [-1.9975,  0.5015,  1.2948],\n",
            "        [-1.9234,  1.9467, -0.0901],\n",
            "        [-1.5901,  1.7964, -0.7084],\n",
            "        [ 0.1963,  0.0539, -0.6886],\n",
            "        [ 0.3228,  0.0457, -0.7744],\n",
            "        [-2.0107,  0.7829,  1.1400],\n",
            "        [-2.2657,  0.8365,  0.8401],\n",
            "        [ 0.2290, -0.0478, -0.2443],\n",
            "        [-1.9262,  2.0177, -0.1345],\n",
            "        [-1.8076,  1.8180, -0.2609],\n",
            "        [-1.7220,  1.5027, -0.1744],\n",
            "        [-1.9109,  0.7208,  0.8693],\n",
            "        [-2.1894,  1.7405,  0.2135],\n",
            "        [-1.9404,  0.3486,  1.2165],\n",
            "        [ 0.3332, -0.0453, -0.6760]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8422,  1.9656, -0.2923],\n",
            "        [-1.6314,  1.5139, -0.1757],\n",
            "        [-1.6300,  1.6077, -0.2910],\n",
            "        [ 0.3505, -0.1036, -0.5700],\n",
            "        [-1.9183,  2.0015, -0.4421],\n",
            "        [-1.8843,  2.0582, -0.4484],\n",
            "        [-1.8423,  1.5766, -0.0801],\n",
            "        [-1.9324,  1.8974, -0.1955],\n",
            "        [-1.7327,  1.7411, -0.1117],\n",
            "        [ 0.5660, -0.1318, -0.6085],\n",
            "        [-2.2457,  0.9831,  0.9038],\n",
            "        [-1.6041,  1.2048,  0.0526],\n",
            "        [-0.7426,  1.1820, -0.8448],\n",
            "        [-1.6953,  2.1308, -0.3348],\n",
            "        [-1.8428,  1.7744,  0.0801],\n",
            "        [-1.5882,  1.3855, -0.3809]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8422,  1.9656, -0.2923],\n",
            "        [-1.6314,  1.5139, -0.1757],\n",
            "        [-1.6300,  1.6077, -0.2910],\n",
            "        [ 0.3505, -0.1036, -0.5700],\n",
            "        [-1.9183,  2.0015, -0.4421],\n",
            "        [-1.8843,  2.0582, -0.4484],\n",
            "        [-1.8423,  1.5766, -0.0801],\n",
            "        [-1.9324,  1.8974, -0.1955],\n",
            "        [-1.7327,  1.7411, -0.1117],\n",
            "        [ 0.5660, -0.1318, -0.6085],\n",
            "        [-2.2457,  0.9831,  0.9038],\n",
            "        [-1.6041,  1.2048,  0.0526],\n",
            "        [-0.7426,  1.1820, -0.8448],\n",
            "        [-1.6953,  2.1308, -0.3348],\n",
            "        [-1.8428,  1.7744,  0.0801],\n",
            "        [-1.5882,  1.3855, -0.3809]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.6046, -0.2681, -0.4939],\n",
            "        [-1.9589,  2.0794, -0.1831],\n",
            "        [ 0.3738, -0.2106, -0.5040],\n",
            "        [-2.0299,  1.8561,  0.1633],\n",
            "        [-1.6060,  1.6782, -0.2209],\n",
            "        [-1.6331,  1.8780, -0.3861],\n",
            "        [-1.7302,  1.7020, -0.1430],\n",
            "        [-1.6720,  1.8437, -0.0957],\n",
            "        [-1.4949,  1.5722, -0.6568],\n",
            "        [-1.6800,  1.7706, -0.0705],\n",
            "        [-1.6151,  1.6932, -0.2948],\n",
            "        [ 0.1358, -0.0175, -0.1826],\n",
            "        [-2.0306,  0.7060,  1.1578],\n",
            "        [-2.0749,  1.2374,  0.7686],\n",
            "        [-1.8604,  2.1233, -0.2668],\n",
            "        [-1.9662,  2.0022, -0.0500]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.6046, -0.2681, -0.4939],\n",
            "        [-1.9589,  2.0794, -0.1831],\n",
            "        [ 0.3738, -0.2106, -0.5040],\n",
            "        [-2.0299,  1.8561,  0.1633],\n",
            "        [-1.6060,  1.6782, -0.2209],\n",
            "        [-1.6331,  1.8780, -0.3861],\n",
            "        [-1.7302,  1.7020, -0.1430],\n",
            "        [-1.6720,  1.8437, -0.0957],\n",
            "        [-1.4949,  1.5722, -0.6568],\n",
            "        [-1.6800,  1.7706, -0.0705],\n",
            "        [-1.6151,  1.6932, -0.2948],\n",
            "        [ 0.1358, -0.0175, -0.1826],\n",
            "        [-2.0306,  0.7060,  1.1578],\n",
            "        [-2.0749,  1.2374,  0.7686],\n",
            "        [-1.8604,  2.1233, -0.2668],\n",
            "        [-1.9662,  2.0022, -0.0500]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0053,  1.9630, -0.2635],\n",
            "        [-1.7212,  1.7683, -0.1600],\n",
            "        [-1.5804,  1.6754, -0.1747],\n",
            "        [-1.8246,  2.0506, -0.2326],\n",
            "        [ 0.5549, -0.3442, -0.5728],\n",
            "        [-1.6222,  1.9061, -0.2284],\n",
            "        [-2.0059,  1.3456,  0.3953],\n",
            "        [-1.7116,  1.9486, -0.2836],\n",
            "        [ 0.5424, -0.2562, -0.7357],\n",
            "        [-2.1031,  0.9706,  0.7918],\n",
            "        [-1.5315,  1.7214, -0.3573],\n",
            "        [-1.9696,  0.7237,  0.9097],\n",
            "        [-1.6891,  1.8513, -0.1964],\n",
            "        [-2.0974,  0.6349,  1.0521],\n",
            "        [-1.7463,  1.8837, -0.1926],\n",
            "        [-1.9457,  1.0880,  0.7165]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0053,  1.9630, -0.2635],\n",
            "        [-1.7212,  1.7683, -0.1600],\n",
            "        [-1.5804,  1.6754, -0.1747],\n",
            "        [-1.8246,  2.0506, -0.2326],\n",
            "        [ 0.5549, -0.3442, -0.5728],\n",
            "        [-1.6222,  1.9061, -0.2284],\n",
            "        [-2.0059,  1.3456,  0.3953],\n",
            "        [-1.7116,  1.9486, -0.2836],\n",
            "        [ 0.5424, -0.2562, -0.7357],\n",
            "        [-2.1031,  0.9706,  0.7918],\n",
            "        [-1.5315,  1.7214, -0.3573],\n",
            "        [-1.9696,  0.7237,  0.9097],\n",
            "        [-1.6891,  1.8513, -0.1964],\n",
            "        [-2.0974,  0.6349,  1.0521],\n",
            "        [-1.7463,  1.8837, -0.1926],\n",
            "        [-1.9457,  1.0880,  0.7165]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5921,  1.7952, -0.5719],\n",
            "        [ 0.6835, -0.2639, -0.6374],\n",
            "        [-2.0107,  1.6313, -0.2454],\n",
            "        [-2.1491,  1.2990,  0.8515],\n",
            "        [-1.9252,  1.8151, -0.0739],\n",
            "        [-1.5096,  1.9336, -0.3520],\n",
            "        [-1.9984,  1.3529,  0.1765],\n",
            "        [-1.9370,  1.8767, -0.1601],\n",
            "        [-1.6521,  1.7733, -0.3570],\n",
            "        [ 0.4416, -0.1979, -0.7911],\n",
            "        [-2.0955,  0.6307,  1.1763],\n",
            "        [-1.8926,  0.3659,  1.2650],\n",
            "        [-1.8250,  0.6338,  1.0186],\n",
            "        [-1.8260,  0.4561,  1.1119],\n",
            "        [-1.8770,  0.3462,  1.2695],\n",
            "        [-1.8650,  0.3518,  1.2318]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5921,  1.7952, -0.5719],\n",
            "        [ 0.6835, -0.2639, -0.6374],\n",
            "        [-2.0107,  1.6313, -0.2454],\n",
            "        [-2.1491,  1.2990,  0.8515],\n",
            "        [-1.9252,  1.8151, -0.0739],\n",
            "        [-1.5096,  1.9336, -0.3520],\n",
            "        [-1.9984,  1.3529,  0.1765],\n",
            "        [-1.9370,  1.8767, -0.1601],\n",
            "        [-1.6521,  1.7733, -0.3570],\n",
            "        [ 0.4416, -0.1979, -0.7911],\n",
            "        [-2.0955,  0.6307,  1.1763],\n",
            "        [-1.8926,  0.3659,  1.2650],\n",
            "        [-1.8250,  0.6338,  1.0186],\n",
            "        [-1.8260,  0.4561,  1.1119],\n",
            "        [-1.8770,  0.3462,  1.2695],\n",
            "        [-1.8650,  0.3518,  1.2318]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.6283, -0.1826, -0.7049],\n",
            "        [-1.7748,  1.6839, -0.2307],\n",
            "        [-1.9996,  1.7513, -0.1953],\n",
            "        [-1.5842,  0.1383,  1.1937],\n",
            "        [-0.8807,  1.2449, -0.5957],\n",
            "        [-1.5774,  1.8059, -0.1855],\n",
            "        [ 0.3287, -0.2067, -0.4829],\n",
            "        [-1.5462,  1.9049, -0.3444],\n",
            "        [-2.0603,  0.5104,  1.2070],\n",
            "        [-1.0619,  1.1828, -0.1818],\n",
            "        [-1.4085,  1.6259, -0.3607],\n",
            "        [-1.6584,  1.8479, -0.2547],\n",
            "        [-2.1705,  0.6494,  1.1099],\n",
            "        [-1.8988,  0.6122,  0.9639],\n",
            "        [-2.0991,  1.4746,  0.3426],\n",
            "        [-2.1831,  0.4791,  1.2352]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.6283, -0.1826, -0.7049],\n",
            "        [-1.7748,  1.6839, -0.2307],\n",
            "        [-1.9996,  1.7513, -0.1953],\n",
            "        [-1.5842,  0.1383,  1.1937],\n",
            "        [-0.8807,  1.2449, -0.5957],\n",
            "        [-1.5774,  1.8059, -0.1855],\n",
            "        [ 0.3287, -0.2067, -0.4829],\n",
            "        [-1.5462,  1.9049, -0.3444],\n",
            "        [-2.0603,  0.5104,  1.2070],\n",
            "        [-1.0619,  1.1828, -0.1818],\n",
            "        [-1.4085,  1.6259, -0.3607],\n",
            "        [-1.6584,  1.8479, -0.2547],\n",
            "        [-2.1705,  0.6494,  1.1099],\n",
            "        [-1.8988,  0.6122,  0.9639],\n",
            "        [-2.0991,  1.4746,  0.3426],\n",
            "        [-2.1831,  0.4791,  1.2352]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3901,  1.4092, -0.0511],\n",
            "        [-1.4465,  1.6953, -0.3598],\n",
            "        [-1.8695,  1.7841, -0.0262],\n",
            "        [-1.2305,  1.6056, -0.4609],\n",
            "        [-1.6284,  1.7681, -0.3665],\n",
            "        [-1.5633,  1.8026, -0.3127],\n",
            "        [-1.9050,  0.3854,  1.2984],\n",
            "        [-1.5886,  0.3281,  1.0247],\n",
            "        [ 0.5947, -0.2671, -0.5796],\n",
            "        [-1.5602,  1.5600, -0.1697],\n",
            "        [-1.8264,  1.4786,  0.3882],\n",
            "        [-1.5068,  1.7747, -0.3650],\n",
            "        [ 0.6347, -0.1367, -0.8848],\n",
            "        [-1.5514,  1.9702, -0.4218],\n",
            "        [-1.5795,  1.6672, -0.1137],\n",
            "        [-1.3950,  1.5794, -0.2023]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3901,  1.4092, -0.0511],\n",
            "        [-1.4465,  1.6953, -0.3598],\n",
            "        [-1.8695,  1.7841, -0.0262],\n",
            "        [-1.2305,  1.6056, -0.4609],\n",
            "        [-1.6284,  1.7681, -0.3665],\n",
            "        [-1.5633,  1.8026, -0.3127],\n",
            "        [-1.9050,  0.3854,  1.2984],\n",
            "        [-1.5886,  0.3281,  1.0247],\n",
            "        [ 0.5947, -0.2671, -0.5796],\n",
            "        [-1.5602,  1.5600, -0.1697],\n",
            "        [-1.8264,  1.4786,  0.3882],\n",
            "        [-1.5068,  1.7747, -0.3650],\n",
            "        [ 0.6347, -0.1367, -0.8848],\n",
            "        [-1.5514,  1.9702, -0.4218],\n",
            "        [-1.5795,  1.6672, -0.1137],\n",
            "        [-1.3950,  1.5794, -0.2023]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8408,  1.8151, -0.0258],\n",
            "        [-1.6678,  1.7961, -0.1367],\n",
            "        [-1.2831,  1.5526, -0.3167],\n",
            "        [-1.1016,  1.3384, -0.5793],\n",
            "        [ 0.4350, -0.0432, -0.7986],\n",
            "        [-1.7095,  1.5932,  0.1046],\n",
            "        [-1.4976,  1.5779, -0.4566],\n",
            "        [ 0.5996, -0.3481, -0.7182],\n",
            "        [-1.5852,  1.3729, -0.3650],\n",
            "        [-1.5143,  1.7373, -0.2262],\n",
            "        [-1.5872,  1.8143, -0.3000],\n",
            "        [-2.0723,  0.4465,  1.2569],\n",
            "        [-1.3636,  1.5796, -0.0614],\n",
            "        [-1.5025,  1.9414, -0.3255],\n",
            "        [-2.0911,  0.8937,  0.8682],\n",
            "        [-1.9078,  1.0182,  0.6844]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8408,  1.8151, -0.0258],\n",
            "        [-1.6678,  1.7961, -0.1367],\n",
            "        [-1.2831,  1.5526, -0.3167],\n",
            "        [-1.1016,  1.3384, -0.5793],\n",
            "        [ 0.4350, -0.0432, -0.7986],\n",
            "        [-1.7095,  1.5932,  0.1046],\n",
            "        [-1.4976,  1.5779, -0.4566],\n",
            "        [ 0.5996, -0.3481, -0.7182],\n",
            "        [-1.5852,  1.3729, -0.3650],\n",
            "        [-1.5143,  1.7373, -0.2262],\n",
            "        [-1.5872,  1.8143, -0.3000],\n",
            "        [-2.0723,  0.4465,  1.2569],\n",
            "        [-1.3636,  1.5796, -0.0614],\n",
            "        [-1.5025,  1.9414, -0.3255],\n",
            "        [-2.0911,  0.8937,  0.8682],\n",
            "        [-1.9078,  1.0182,  0.6844]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4944,  1.6047, -0.2635],\n",
            "        [-0.1791,  0.0941, -0.3416],\n",
            "        [-1.7691,  1.8495,  0.0372],\n",
            "        [-1.8817,  0.4052,  1.2445],\n",
            "        [-1.7408,  0.2653,  1.2230],\n",
            "        [-1.5548,  1.7629, -0.2701],\n",
            "        [-1.8317,  1.2728,  0.6713],\n",
            "        [ 0.1102, -0.3506, -0.2833],\n",
            "        [-1.7046,  1.9484, -0.2571],\n",
            "        [ 0.5964, -0.2380, -0.8013],\n",
            "        [-1.1743,  0.4940,  0.3489],\n",
            "        [-1.3196,  1.6114, -0.4265],\n",
            "        [-1.8662,  0.1184,  1.1918],\n",
            "        [-1.2087,  1.5047, -0.1798],\n",
            "        [-1.6372,  1.5383,  0.0233],\n",
            "        [-1.2254,  0.4552,  0.5615]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4944,  1.6047, -0.2635],\n",
            "        [-0.1791,  0.0941, -0.3416],\n",
            "        [-1.7691,  1.8495,  0.0372],\n",
            "        [-1.8817,  0.4052,  1.2445],\n",
            "        [-1.7408,  0.2653,  1.2230],\n",
            "        [-1.5548,  1.7629, -0.2701],\n",
            "        [-1.8317,  1.2728,  0.6713],\n",
            "        [ 0.1102, -0.3506, -0.2833],\n",
            "        [-1.7046,  1.9484, -0.2571],\n",
            "        [ 0.5964, -0.2380, -0.8013],\n",
            "        [-1.1743,  0.4940,  0.3489],\n",
            "        [-1.3196,  1.6114, -0.4265],\n",
            "        [-1.8662,  0.1184,  1.1918],\n",
            "        [-1.2087,  1.5047, -0.1798],\n",
            "        [-1.6372,  1.5383,  0.0233],\n",
            "        [-1.2254,  0.4552,  0.5615]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4955,  1.8767, -0.1760],\n",
            "        [-2.0662,  0.7212,  1.0551],\n",
            "        [-1.5056,  1.6040, -0.3254],\n",
            "        [-1.7858,  1.5633, -0.0123],\n",
            "        [ 0.5383, -0.3213, -0.7987],\n",
            "        [ 0.1820,  0.0437, -0.4260],\n",
            "        [-2.1241,  0.4418,  1.2268],\n",
            "        [-1.5846,  1.7956, -0.2847],\n",
            "        [-1.9541,  1.7477,  0.1119],\n",
            "        [-1.7652,  1.8529, -0.0703],\n",
            "        [-1.4398,  1.8733, -0.3436],\n",
            "        [-1.7914,  0.5977,  0.9998],\n",
            "        [-1.8585,  1.4072,  0.1210],\n",
            "        [-1.7044,  1.3285,  0.2770],\n",
            "        [-1.6164,  1.6647, -0.1685],\n",
            "        [-1.5548,  1.6137, -0.3061]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4955,  1.8767, -0.1760],\n",
            "        [-2.0662,  0.7212,  1.0551],\n",
            "        [-1.5056,  1.6040, -0.3254],\n",
            "        [-1.7858,  1.5633, -0.0123],\n",
            "        [ 0.5383, -0.3213, -0.7987],\n",
            "        [ 0.1820,  0.0437, -0.4260],\n",
            "        [-2.1241,  0.4418,  1.2268],\n",
            "        [-1.5846,  1.7956, -0.2847],\n",
            "        [-1.9541,  1.7477,  0.1119],\n",
            "        [-1.7652,  1.8529, -0.0703],\n",
            "        [-1.4398,  1.8733, -0.3436],\n",
            "        [-1.7914,  0.5977,  0.9998],\n",
            "        [-1.8585,  1.4072,  0.1210],\n",
            "        [-1.7044,  1.3285,  0.2770],\n",
            "        [-1.6164,  1.6647, -0.1685],\n",
            "        [-1.5548,  1.6137, -0.3061]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.6249, -0.0960, -0.9561],\n",
            "        [-1.4178,  1.6193, -0.0991],\n",
            "        [-1.6120,  0.9865,  0.4863],\n",
            "        [-1.6598,  1.7143, -0.3284],\n",
            "        [-1.7139,  0.3122,  1.3102],\n",
            "        [-1.7127,  1.8806, -0.0326],\n",
            "        [-0.6319, -0.0446,  0.4211],\n",
            "        [-1.8377,  1.3366,  0.4354],\n",
            "        [-1.4743,  1.7585, -0.3054],\n",
            "        [-1.5889,  1.7035, -0.2585],\n",
            "        [-1.4983,  1.3768, -0.1482],\n",
            "        [-1.6999,  1.4039,  0.1549],\n",
            "        [-1.6316,  1.7401, -0.1224],\n",
            "        [-1.5243,  1.7167, -0.3365],\n",
            "        [-1.6001,  1.7012, -0.1157],\n",
            "        [-1.5345,  1.4558, -0.0861]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.6249, -0.0960, -0.9561],\n",
            "        [-1.4178,  1.6193, -0.0991],\n",
            "        [-1.6120,  0.9865,  0.4863],\n",
            "        [-1.6598,  1.7143, -0.3284],\n",
            "        [-1.7139,  0.3122,  1.3102],\n",
            "        [-1.7127,  1.8806, -0.0326],\n",
            "        [-0.6319, -0.0446,  0.4211],\n",
            "        [-1.8377,  1.3366,  0.4354],\n",
            "        [-1.4743,  1.7585, -0.3054],\n",
            "        [-1.5889,  1.7035, -0.2585],\n",
            "        [-1.4983,  1.3768, -0.1482],\n",
            "        [-1.6999,  1.4039,  0.1549],\n",
            "        [-1.6316,  1.7401, -0.1224],\n",
            "        [-1.5243,  1.7167, -0.3365],\n",
            "        [-1.6001,  1.7012, -0.1157],\n",
            "        [-1.5345,  1.4558, -0.0861]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6343,  1.7427, -0.1658],\n",
            "        [-1.8266,  0.1946,  1.0970],\n",
            "        [-1.5207,  1.4862, -0.0067],\n",
            "        [ 0.0506,  0.2612, -0.8414],\n",
            "        [ 0.2638,  0.1914, -0.7276],\n",
            "        [-1.4637,  1.5000,  0.0496],\n",
            "        [-1.8880,  1.9234, -0.1622],\n",
            "        [-1.5329,  1.5569, -0.2602],\n",
            "        [-1.5939,  1.4886, -0.2003],\n",
            "        [-1.6847,  0.9071,  0.3746],\n",
            "        [-1.8103,  1.4769,  0.2853],\n",
            "        [-1.8994,  0.5477,  0.8349],\n",
            "        [-1.8936,  0.4547,  1.2716],\n",
            "        [-1.8210,  0.5271,  1.2407],\n",
            "        [-1.4860,  1.2120,  0.1349],\n",
            "        [-2.0524,  1.4360,  0.0783]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6343,  1.7427, -0.1658],\n",
            "        [-1.8266,  0.1946,  1.0970],\n",
            "        [-1.5207,  1.4862, -0.0067],\n",
            "        [ 0.0506,  0.2612, -0.8414],\n",
            "        [ 0.2638,  0.1914, -0.7276],\n",
            "        [-1.4637,  1.5000,  0.0496],\n",
            "        [-1.8880,  1.9234, -0.1622],\n",
            "        [-1.5329,  1.5569, -0.2602],\n",
            "        [-1.5939,  1.4886, -0.2003],\n",
            "        [-1.6847,  0.9071,  0.3746],\n",
            "        [-1.8103,  1.4769,  0.2853],\n",
            "        [-1.8994,  0.5477,  0.8349],\n",
            "        [-1.8936,  0.4547,  1.2716],\n",
            "        [-1.8210,  0.5271,  1.2407],\n",
            "        [-1.4860,  1.2120,  0.1349],\n",
            "        [-2.0524,  1.4360,  0.0783]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5381,  1.1984,  0.1751],\n",
            "        [-1.6014,  0.0479,  1.3752],\n",
            "        [-1.3216,  1.2579,  0.0205],\n",
            "        [-1.9269,  1.3544,  0.0929],\n",
            "        [-1.6707,  0.2839,  1.2107],\n",
            "        [-1.3197,  1.4474, -0.2152],\n",
            "        [-1.6671,  0.3669,  1.0056],\n",
            "        [ 0.2484,  0.0305, -0.7121],\n",
            "        [-1.4277,  1.6603, -0.3740],\n",
            "        [-1.3927,  1.4570, -0.0121],\n",
            "        [ 0.4968, -0.3757, -0.8160],\n",
            "        [-1.8559,  0.3816,  1.1995],\n",
            "        [ 0.4757, -0.1562, -0.9912],\n",
            "        [-1.5832,  0.0856,  1.3049],\n",
            "        [-1.1344,  1.2400, -0.0020],\n",
            "        [-1.5687,  1.5167,  0.0761]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5381,  1.1984,  0.1751],\n",
            "        [-1.6014,  0.0479,  1.3752],\n",
            "        [-1.3216,  1.2579,  0.0205],\n",
            "        [-1.9269,  1.3544,  0.0929],\n",
            "        [-1.6707,  0.2839,  1.2107],\n",
            "        [-1.3197,  1.4474, -0.2152],\n",
            "        [-1.6671,  0.3669,  1.0056],\n",
            "        [ 0.2484,  0.0305, -0.7121],\n",
            "        [-1.4277,  1.6603, -0.3740],\n",
            "        [-1.3927,  1.4570, -0.0121],\n",
            "        [ 0.4968, -0.3757, -0.8160],\n",
            "        [-1.8559,  0.3816,  1.1995],\n",
            "        [ 0.4757, -0.1562, -0.9912],\n",
            "        [-1.5832,  0.0856,  1.3049],\n",
            "        [-1.1344,  1.2400, -0.0020],\n",
            "        [-1.5687,  1.5167,  0.0761]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.8274, -0.2227, -0.9373],\n",
            "        [-1.8724,  1.3342,  0.1965],\n",
            "        [-1.3718,  1.1932, -0.1131],\n",
            "        [-1.3249,  1.1640, -0.0462],\n",
            "        [ 0.2409, -0.1041, -0.5989],\n",
            "        [-1.4274,  1.4218,  0.1351],\n",
            "        [ 0.5334, -0.3986, -0.6808],\n",
            "        [-1.3578,  1.3875, -0.0197],\n",
            "        [ 0.0264,  0.2692, -0.7970],\n",
            "        [-1.8650,  0.3672,  1.1732],\n",
            "        [-1.5088,  1.3052,  0.1008],\n",
            "        [-1.7631,  1.2673,  0.2880],\n",
            "        [-1.3413,  1.5022, -0.1829],\n",
            "        [-1.3787,  1.2702,  0.0825],\n",
            "        [-1.2799,  1.3542, -0.0038],\n",
            "        [ 0.4929,  0.2157, -0.8174]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.8274, -0.2227, -0.9373],\n",
            "        [-1.8724,  1.3342,  0.1965],\n",
            "        [-1.3718,  1.1932, -0.1131],\n",
            "        [-1.3249,  1.1640, -0.0462],\n",
            "        [ 0.2409, -0.1041, -0.5989],\n",
            "        [-1.4274,  1.4218,  0.1351],\n",
            "        [ 0.5334, -0.3986, -0.6808],\n",
            "        [-1.3578,  1.3875, -0.0197],\n",
            "        [ 0.0264,  0.2692, -0.7970],\n",
            "        [-1.8650,  0.3672,  1.1732],\n",
            "        [-1.5088,  1.3052,  0.1008],\n",
            "        [-1.7631,  1.2673,  0.2880],\n",
            "        [-1.3413,  1.5022, -0.1829],\n",
            "        [-1.3787,  1.2702,  0.0825],\n",
            "        [-1.2799,  1.3542, -0.0038],\n",
            "        [ 0.4929,  0.2157, -0.8174]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6754,  0.3446,  1.1233],\n",
            "        [-1.3263,  1.5419, -0.0268],\n",
            "        [-1.7029,  1.7913, -0.1859],\n",
            "        [-1.7108,  0.1192,  1.4258],\n",
            "        [-1.5442,  1.3685,  0.1262],\n",
            "        [-1.0713,  1.3391, -0.1216],\n",
            "        [-1.0985, -0.0144,  0.9212],\n",
            "        [-1.9366,  0.8564,  0.8132],\n",
            "        [-1.8413,  0.4964,  0.9844],\n",
            "        [-1.7162,  0.3388,  0.9613],\n",
            "        [-1.3313,  1.4235, -0.0172],\n",
            "        [-1.5741,  0.6552,  0.8263],\n",
            "        [-1.6451, -0.0928,  1.2361],\n",
            "        [-1.7812,  0.8226,  0.7294],\n",
            "        [-1.4350,  1.4176,  0.0321],\n",
            "        [-0.1105, -0.1614, -0.0429]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6754,  0.3446,  1.1233],\n",
            "        [-1.3263,  1.5419, -0.0268],\n",
            "        [-1.7029,  1.7913, -0.1859],\n",
            "        [-1.7108,  0.1192,  1.4258],\n",
            "        [-1.5442,  1.3685,  0.1262],\n",
            "        [-1.0713,  1.3391, -0.1216],\n",
            "        [-1.0985, -0.0144,  0.9212],\n",
            "        [-1.9366,  0.8564,  0.8132],\n",
            "        [-1.8413,  0.4964,  0.9844],\n",
            "        [-1.7162,  0.3388,  0.9613],\n",
            "        [-1.3313,  1.4235, -0.0172],\n",
            "        [-1.5741,  0.6552,  0.8263],\n",
            "        [-1.6451, -0.0928,  1.2361],\n",
            "        [-1.7812,  0.8226,  0.7294],\n",
            "        [-1.4350,  1.4176,  0.0321],\n",
            "        [-0.1105, -0.1614, -0.0429]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7332,  0.8843,  0.7106],\n",
            "        [-1.4708,  1.0852,  0.3193],\n",
            "        [-1.2075,  1.0982,  0.0969],\n",
            "        [-1.2352,  1.2779,  0.0344],\n",
            "        [-1.4556,  1.2725, -0.0605],\n",
            "        [-1.8672,  1.3499,  0.1319],\n",
            "        [-1.5653,  0.9536,  0.3420],\n",
            "        [-1.2785,  1.4626, -0.2228],\n",
            "        [-1.5167,  1.4099,  0.1879],\n",
            "        [-1.4044,  0.8809,  0.2933],\n",
            "        [ 0.4196, -0.1829, -0.7809],\n",
            "        [ 0.5996, -0.1231, -0.9879],\n",
            "        [-1.3790,  1.2909,  0.0477],\n",
            "        [-1.8351,  0.2391,  1.3917],\n",
            "        [ 0.2470, -0.0403, -0.5752],\n",
            "        [-1.4278,  1.4324, -0.0329]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7332,  0.8843,  0.7106],\n",
            "        [-1.4708,  1.0852,  0.3193],\n",
            "        [-1.2075,  1.0982,  0.0969],\n",
            "        [-1.2352,  1.2779,  0.0344],\n",
            "        [-1.4556,  1.2725, -0.0605],\n",
            "        [-1.8672,  1.3499,  0.1319],\n",
            "        [-1.5653,  0.9536,  0.3420],\n",
            "        [-1.2785,  1.4626, -0.2228],\n",
            "        [-1.5167,  1.4099,  0.1879],\n",
            "        [-1.4044,  0.8809,  0.2933],\n",
            "        [ 0.4196, -0.1829, -0.7809],\n",
            "        [ 0.5996, -0.1231, -0.9879],\n",
            "        [-1.3790,  1.2909,  0.0477],\n",
            "        [-1.8351,  0.2391,  1.3917],\n",
            "        [ 0.2470, -0.0403, -0.5752],\n",
            "        [-1.4278,  1.4324, -0.0329]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2752,  1.0903,  0.0509],\n",
            "        [-1.6599,  1.1704,  0.2927],\n",
            "        [ 0.4657, -0.0506, -0.8211],\n",
            "        [ 0.5251,  0.1161, -1.0495],\n",
            "        [ 0.3828,  0.2213, -0.9904],\n",
            "        [-1.3853,  0.9427,  0.0319],\n",
            "        [-1.6549,  0.2312,  1.2424],\n",
            "        [-1.4994,  1.2256,  0.1363],\n",
            "        [-1.9204,  0.4337,  1.1571],\n",
            "        [-0.4081, -0.0900,  0.2968],\n",
            "        [ 0.5020, -0.1757, -0.9514],\n",
            "        [-1.6905,  0.9876,  0.3250],\n",
            "        [-1.0487,  1.1481, -0.1633],\n",
            "        [-1.0798,  1.0682,  0.0562],\n",
            "        [ 0.1001, -0.0075, -0.3302],\n",
            "        [-2.0270,  0.3219,  1.2850]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2752,  1.0903,  0.0509],\n",
            "        [-1.6599,  1.1704,  0.2927],\n",
            "        [ 0.4657, -0.0506, -0.8211],\n",
            "        [ 0.5251,  0.1161, -1.0495],\n",
            "        [ 0.3828,  0.2213, -0.9904],\n",
            "        [-1.3853,  0.9427,  0.0319],\n",
            "        [-1.6549,  0.2312,  1.2424],\n",
            "        [-1.4994,  1.2256,  0.1363],\n",
            "        [-1.9204,  0.4337,  1.1571],\n",
            "        [-0.4081, -0.0900,  0.2968],\n",
            "        [ 0.5020, -0.1757, -0.9514],\n",
            "        [-1.6905,  0.9876,  0.3250],\n",
            "        [-1.0487,  1.1481, -0.1633],\n",
            "        [-1.0798,  1.0682,  0.0562],\n",
            "        [ 0.1001, -0.0075, -0.3302],\n",
            "        [-2.0270,  0.3219,  1.2850]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7267,  0.3379,  1.2051],\n",
            "        [-1.8049,  0.0194,  1.3827],\n",
            "        [ 0.2640, -0.0697, -0.5832],\n",
            "        [-1.3035,  1.5315, -0.1654],\n",
            "        [-1.6362,  1.2840, -0.0619],\n",
            "        [-1.7185,  0.2944,  1.4264],\n",
            "        [ 0.6259, -0.1948, -1.0903],\n",
            "        [-1.5189,  1.2686,  0.3431],\n",
            "        [-1.7054,  0.7130,  0.6288],\n",
            "        [-1.5938,  1.1734,  0.3499],\n",
            "        [ 0.3000, -0.1148, -0.7639],\n",
            "        [-1.5278,  0.3174,  0.9431],\n",
            "        [-1.8525,  0.3928,  1.1487],\n",
            "        [-1.4511,  1.4075, -0.1058],\n",
            "        [ 0.5879, -0.1329, -0.7995],\n",
            "        [-1.3239,  1.2044,  0.0504]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7267,  0.3379,  1.2051],\n",
            "        [-1.8049,  0.0194,  1.3827],\n",
            "        [ 0.2640, -0.0697, -0.5832],\n",
            "        [-1.3035,  1.5315, -0.1654],\n",
            "        [-1.6362,  1.2840, -0.0619],\n",
            "        [-1.7185,  0.2944,  1.4264],\n",
            "        [ 0.6259, -0.1948, -1.0903],\n",
            "        [-1.5189,  1.2686,  0.3431],\n",
            "        [-1.7054,  0.7130,  0.6288],\n",
            "        [-1.5938,  1.1734,  0.3499],\n",
            "        [ 0.3000, -0.1148, -0.7639],\n",
            "        [-1.5278,  0.3174,  0.9431],\n",
            "        [-1.8525,  0.3928,  1.1487],\n",
            "        [-1.4511,  1.4075, -0.1058],\n",
            "        [ 0.5879, -0.1329, -0.7995],\n",
            "        [-1.3239,  1.2044,  0.0504]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.0850,  1.4694, -0.5759],\n",
            "        [ 0.5341,  0.1782, -1.0246],\n",
            "        [-1.2459,  1.1444,  0.1973],\n",
            "        [-1.6194,  1.3439,  0.1856],\n",
            "        [ 0.4620, -0.0547, -0.8420],\n",
            "        [-1.3684,  1.2329,  0.0113],\n",
            "        [ 0.7515, -0.1860, -0.8134],\n",
            "        [ 0.5199,  0.0239, -0.8222],\n",
            "        [-1.1310,  1.2267, -0.6271],\n",
            "        [ 0.6012, -0.1328, -0.8262],\n",
            "        [-1.6435,  0.2610,  1.0828],\n",
            "        [ 0.4804,  0.0066, -0.9372],\n",
            "        [-1.4760,  1.3027,  0.1029],\n",
            "        [-1.5418,  1.2872, -0.1748],\n",
            "        [-1.3641,  1.0946,  0.0249],\n",
            "        [-1.5674,  0.1471,  1.1321]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.0850,  1.4694, -0.5759],\n",
            "        [ 0.5341,  0.1782, -1.0246],\n",
            "        [-1.2459,  1.1444,  0.1973],\n",
            "        [-1.6194,  1.3439,  0.1856],\n",
            "        [ 0.4620, -0.0547, -0.8420],\n",
            "        [-1.3684,  1.2329,  0.0113],\n",
            "        [ 0.7515, -0.1860, -0.8134],\n",
            "        [ 0.5199,  0.0239, -0.8222],\n",
            "        [-1.1310,  1.2267, -0.6271],\n",
            "        [ 0.6012, -0.1328, -0.8262],\n",
            "        [-1.6435,  0.2610,  1.0828],\n",
            "        [ 0.4804,  0.0066, -0.9372],\n",
            "        [-1.4760,  1.3027,  0.1029],\n",
            "        [-1.5418,  1.2872, -0.1748],\n",
            "        [-1.3641,  1.0946,  0.0249],\n",
            "        [-1.5674,  0.1471,  1.1321]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0140e-01,  3.3414e-01, -5.8073e-01],\n",
            "        [-1.7743e+00,  8.9174e-01,  7.0927e-01],\n",
            "        [-1.9361e+00,  1.5926e+00,  2.3969e-01],\n",
            "        [-1.5693e+00,  8.2812e-01,  6.9358e-01],\n",
            "        [-1.7199e+00,  2.0871e-01,  1.2610e+00],\n",
            "        [-1.0606e+00,  1.1059e+00, -1.8688e-04],\n",
            "        [ 2.7108e-01,  1.3764e-01, -9.0377e-01],\n",
            "        [-1.5115e+00,  1.4853e+00, -2.6728e-01],\n",
            "        [ 6.1963e-01, -2.1288e-02, -7.7768e-01],\n",
            "        [-1.3752e+00,  1.2639e+00, -8.2067e-02],\n",
            "        [-1.2392e+00,  1.2576e+00, -3.0805e-02],\n",
            "        [-1.3735e+00,  3.4863e-01,  9.9526e-01],\n",
            "        [-1.3876e+00,  1.2225e+00,  6.5730e-02],\n",
            "        [ 4.4718e-01, -7.5083e-02, -7.6457e-01],\n",
            "        [-1.1392e+00,  1.3173e+00, -4.1746e-02],\n",
            "        [ 2.2671e-01,  3.2475e-01, -8.6569e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0140e-01,  3.3414e-01, -5.8073e-01],\n",
            "        [-1.7743e+00,  8.9174e-01,  7.0927e-01],\n",
            "        [-1.9361e+00,  1.5926e+00,  2.3969e-01],\n",
            "        [-1.5693e+00,  8.2812e-01,  6.9358e-01],\n",
            "        [-1.7199e+00,  2.0871e-01,  1.2610e+00],\n",
            "        [-1.0606e+00,  1.1059e+00, -1.8688e-04],\n",
            "        [ 2.7108e-01,  1.3764e-01, -9.0377e-01],\n",
            "        [-1.5115e+00,  1.4853e+00, -2.6728e-01],\n",
            "        [ 6.1963e-01, -2.1288e-02, -7.7768e-01],\n",
            "        [-1.3752e+00,  1.2639e+00, -8.2067e-02],\n",
            "        [-1.2392e+00,  1.2576e+00, -3.0805e-02],\n",
            "        [-1.3735e+00,  3.4863e-01,  9.9526e-01],\n",
            "        [-1.3876e+00,  1.2225e+00,  6.5730e-02],\n",
            "        [ 4.4718e-01, -7.5083e-02, -7.6457e-01],\n",
            "        [-1.1392e+00,  1.3173e+00, -4.1746e-02],\n",
            "        [ 2.2671e-01,  3.2475e-01, -8.6569e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5406,  1.2338,  0.0671],\n",
            "        [-0.1343,  0.6280, -0.8277],\n",
            "        [ 0.2694, -0.1693, -0.5446],\n",
            "        [ 0.3956,  0.1016, -1.1015],\n",
            "        [-1.3505,  1.3351, -0.2408],\n",
            "        [-1.4774,  1.6251, -0.3501],\n",
            "        [-1.8450,  1.5492,  0.1108],\n",
            "        [ 0.0885, -0.1756, -0.3064],\n",
            "        [-1.6911,  1.2702,  0.2620],\n",
            "        [-1.6948,  1.5659, -0.1097],\n",
            "        [-1.4768,  1.4446,  0.0147],\n",
            "        [-1.4738,  1.0374,  0.0312],\n",
            "        [-1.5762,  1.6716,  0.0091],\n",
            "        [-1.7671,  1.1602,  0.4864],\n",
            "        [-1.3718,  1.2644,  0.1145],\n",
            "        [-1.6930,  0.4946,  1.1039]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5406,  1.2338,  0.0671],\n",
            "        [-0.1343,  0.6280, -0.8277],\n",
            "        [ 0.2694, -0.1693, -0.5446],\n",
            "        [ 0.3956,  0.1016, -1.1015],\n",
            "        [-1.3505,  1.3351, -0.2408],\n",
            "        [-1.4774,  1.6251, -0.3501],\n",
            "        [-1.8450,  1.5492,  0.1108],\n",
            "        [ 0.0885, -0.1756, -0.3064],\n",
            "        [-1.6911,  1.2702,  0.2620],\n",
            "        [-1.6948,  1.5659, -0.1097],\n",
            "        [-1.4768,  1.4446,  0.0147],\n",
            "        [-1.4738,  1.0374,  0.0312],\n",
            "        [-1.5762,  1.6716,  0.0091],\n",
            "        [-1.7671,  1.1602,  0.4864],\n",
            "        [-1.3718,  1.2644,  0.1145],\n",
            "        [-1.6930,  0.4946,  1.1039]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6405,  0.2032,  1.1575],\n",
            "        [-1.1115,  0.0056,  0.6102],\n",
            "        [ 0.3101, -0.0478, -0.7596],\n",
            "        [-1.6197,  1.1288, -0.0293],\n",
            "        [ 0.5268, -0.1358, -0.7584],\n",
            "        [-1.8106,  0.7106,  0.8023],\n",
            "        [-1.3334,  1.2698,  0.0785],\n",
            "        [-2.0541,  0.8664,  0.7210],\n",
            "        [-1.4129,  1.1886,  0.0426],\n",
            "        [-1.5637,  1.0169,  0.4110],\n",
            "        [-1.1496,  1.0881,  0.0635],\n",
            "        [-1.2558,  1.1909,  0.0800],\n",
            "        [-1.4638,  0.2158,  1.0488],\n",
            "        [-1.8492,  1.0481,  0.5014],\n",
            "        [-1.5725,  0.6013,  1.0538],\n",
            "        [-1.5425,  1.3956,  0.0592]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6405,  0.2032,  1.1575],\n",
            "        [-1.1115,  0.0056,  0.6102],\n",
            "        [ 0.3101, -0.0478, -0.7596],\n",
            "        [-1.6197,  1.1288, -0.0293],\n",
            "        [ 0.5268, -0.1358, -0.7584],\n",
            "        [-1.8106,  0.7106,  0.8023],\n",
            "        [-1.3334,  1.2698,  0.0785],\n",
            "        [-2.0541,  0.8664,  0.7210],\n",
            "        [-1.4129,  1.1886,  0.0426],\n",
            "        [-1.5637,  1.0169,  0.4110],\n",
            "        [-1.1496,  1.0881,  0.0635],\n",
            "        [-1.2558,  1.1909,  0.0800],\n",
            "        [-1.4638,  0.2158,  1.0488],\n",
            "        [-1.8492,  1.0481,  0.5014],\n",
            "        [-1.5725,  0.6013,  1.0538],\n",
            "        [-1.5425,  1.3956,  0.0592]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8240e+00,  4.3491e-01,  1.0697e+00],\n",
            "        [-1.7556e+00,  1.5119e+00,  1.4308e-03],\n",
            "        [-1.3197e+00,  1.9949e-01,  1.0614e+00],\n",
            "        [-1.6010e+00,  1.5597e+00, -6.8188e-02],\n",
            "        [ 3.5718e-01,  5.8909e-02, -9.4358e-01],\n",
            "        [ 4.7137e-01, -2.0690e-01, -8.1010e-01],\n",
            "        [-1.4879e+00,  1.3301e+00, -6.0698e-02],\n",
            "        [-1.4480e+00,  1.1040e+00, -2.4616e-02],\n",
            "        [-1.7804e+00,  6.7324e-01,  8.3161e-01],\n",
            "        [-1.7226e+00,  1.4934e+00,  1.3780e-01],\n",
            "        [-1.7983e+00,  1.3202e+00,  3.4764e-01],\n",
            "        [-1.4655e+00,  1.3894e-01,  1.2911e+00],\n",
            "        [-1.7275e+00,  1.3876e+00,  3.1341e-02],\n",
            "        [-1.6108e+00,  1.4974e+00, -7.4069e-02],\n",
            "        [-1.9197e+00,  1.0883e+00,  5.6735e-01],\n",
            "        [-1.6017e+00,  1.4602e-02,  1.4194e+00]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8240e+00,  4.3491e-01,  1.0697e+00],\n",
            "        [-1.7556e+00,  1.5119e+00,  1.4308e-03],\n",
            "        [-1.3197e+00,  1.9949e-01,  1.0614e+00],\n",
            "        [-1.6010e+00,  1.5597e+00, -6.8188e-02],\n",
            "        [ 3.5718e-01,  5.8909e-02, -9.4358e-01],\n",
            "        [ 4.7137e-01, -2.0690e-01, -8.1010e-01],\n",
            "        [-1.4879e+00,  1.3301e+00, -6.0698e-02],\n",
            "        [-1.4480e+00,  1.1040e+00, -2.4616e-02],\n",
            "        [-1.7804e+00,  6.7324e-01,  8.3161e-01],\n",
            "        [-1.7226e+00,  1.4934e+00,  1.3780e-01],\n",
            "        [-1.7983e+00,  1.3202e+00,  3.4764e-01],\n",
            "        [-1.4655e+00,  1.3894e-01,  1.2911e+00],\n",
            "        [-1.7275e+00,  1.3876e+00,  3.1341e-02],\n",
            "        [-1.6108e+00,  1.4974e+00, -7.4069e-02],\n",
            "        [-1.9197e+00,  1.0883e+00,  5.6735e-01],\n",
            "        [-1.6017e+00,  1.4602e-02,  1.4194e+00]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4347,  1.4259,  0.0052],\n",
            "        [-1.8950,  0.2950,  1.2582],\n",
            "        [-1.3129,  1.3578,  0.0041],\n",
            "        [-1.3011,  0.0434,  1.0184],\n",
            "        [-1.5029,  0.0243,  0.8957],\n",
            "        [-1.7484,  0.3695,  1.1634],\n",
            "        [-1.5519,  0.3373,  1.1858],\n",
            "        [-1.7856,  1.2405,  0.2642],\n",
            "        [-1.5629,  1.7158, -0.3755],\n",
            "        [-1.5940,  1.1144,  0.0865],\n",
            "        [-1.9289,  0.5261,  0.8173],\n",
            "        [ 0.5608,  0.0835, -1.1005],\n",
            "        [-1.5541,  1.0857, -0.0511],\n",
            "        [-1.5242,  1.3534, -0.0279],\n",
            "        [-1.4412,  1.2469,  0.1561],\n",
            "        [ 0.4977,  0.0152, -1.0171]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4347,  1.4259,  0.0052],\n",
            "        [-1.8950,  0.2950,  1.2582],\n",
            "        [-1.3129,  1.3578,  0.0041],\n",
            "        [-1.3011,  0.0434,  1.0184],\n",
            "        [-1.5029,  0.0243,  0.8957],\n",
            "        [-1.7484,  0.3695,  1.1634],\n",
            "        [-1.5519,  0.3373,  1.1858],\n",
            "        [-1.7856,  1.2405,  0.2642],\n",
            "        [-1.5629,  1.7158, -0.3755],\n",
            "        [-1.5940,  1.1144,  0.0865],\n",
            "        [-1.9289,  0.5261,  0.8173],\n",
            "        [ 0.5608,  0.0835, -1.1005],\n",
            "        [-1.5541,  1.0857, -0.0511],\n",
            "        [-1.5242,  1.3534, -0.0279],\n",
            "        [-1.4412,  1.2469,  0.1561],\n",
            "        [ 0.4977,  0.0152, -1.0171]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3774e+00,  1.3491e+00,  5.3384e-04],\n",
            "        [-7.9775e-01,  1.2066e+00, -4.0941e-01],\n",
            "        [-1.5110e+00,  1.1635e+00,  1.1793e-01],\n",
            "        [-1.6036e+00,  1.2292e+00,  3.6819e-01],\n",
            "        [-1.7060e+00,  1.6146e+00,  2.1022e-02],\n",
            "        [-1.5986e+00,  1.2245e+00, -5.9986e-02],\n",
            "        [-1.4346e+00,  1.0791e-01,  8.9763e-01],\n",
            "        [-1.5863e+00,  1.0855e+00,  2.2807e-01],\n",
            "        [-1.8507e+00,  6.4217e-01,  9.7364e-01],\n",
            "        [-1.8919e+00,  1.2499e+00,  3.4063e-01],\n",
            "        [-1.4142e+00,  1.1473e+00, -1.0589e-01],\n",
            "        [-2.2144e-01,  9.5724e-02, -2.5509e-01],\n",
            "        [-1.6531e+00,  5.0845e-01,  4.9132e-01],\n",
            "        [-1.9504e+00,  4.7484e-01,  1.2084e+00],\n",
            "        [ 7.4565e-02,  2.4506e-01, -6.9154e-01],\n",
            "        [-1.8512e+00,  1.6798e+00,  7.7640e-02]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3774e+00,  1.3491e+00,  5.3384e-04],\n",
            "        [-7.9775e-01,  1.2066e+00, -4.0941e-01],\n",
            "        [-1.5110e+00,  1.1635e+00,  1.1793e-01],\n",
            "        [-1.6036e+00,  1.2292e+00,  3.6819e-01],\n",
            "        [-1.7060e+00,  1.6146e+00,  2.1022e-02],\n",
            "        [-1.5986e+00,  1.2245e+00, -5.9986e-02],\n",
            "        [-1.4346e+00,  1.0791e-01,  8.9763e-01],\n",
            "        [-1.5863e+00,  1.0855e+00,  2.2807e-01],\n",
            "        [-1.8507e+00,  6.4217e-01,  9.7364e-01],\n",
            "        [-1.8919e+00,  1.2499e+00,  3.4063e-01],\n",
            "        [-1.4142e+00,  1.1473e+00, -1.0589e-01],\n",
            "        [-2.2144e-01,  9.5724e-02, -2.5509e-01],\n",
            "        [-1.6531e+00,  5.0845e-01,  4.9132e-01],\n",
            "        [-1.9504e+00,  4.7484e-01,  1.2084e+00],\n",
            "        [ 7.4565e-02,  2.4506e-01, -6.9154e-01],\n",
            "        [-1.8512e+00,  1.6798e+00,  7.7640e-02]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5988,  1.5680,  0.0646],\n",
            "        [-1.5752,  1.5649, -0.0633],\n",
            "        [ 0.4022,  0.0264, -1.0241],\n",
            "        [ 0.5311,  0.0292, -1.0300],\n",
            "        [-1.5631,  1.4599,  0.0874],\n",
            "        [-1.7773,  0.0711,  1.0051],\n",
            "        [-1.6797,  0.1546,  1.3194],\n",
            "        [-1.5606,  0.2702,  0.9794],\n",
            "        [-1.5409,  1.2513,  0.1188],\n",
            "        [-1.3540,  0.1240,  1.3123],\n",
            "        [ 0.5269,  0.0353, -0.8276],\n",
            "        [-1.2576,  1.1312,  0.1500],\n",
            "        [ 0.4046,  0.2338, -1.0288],\n",
            "        [-1.5261,  0.8091,  0.4610],\n",
            "        [-1.5306,  1.6742, -0.1396],\n",
            "        [-1.3197,  0.0766,  1.0444]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5988,  1.5680,  0.0646],\n",
            "        [-1.5752,  1.5649, -0.0633],\n",
            "        [ 0.4022,  0.0264, -1.0241],\n",
            "        [ 0.5311,  0.0292, -1.0300],\n",
            "        [-1.5631,  1.4599,  0.0874],\n",
            "        [-1.7773,  0.0711,  1.0051],\n",
            "        [-1.6797,  0.1546,  1.3194],\n",
            "        [-1.5606,  0.2702,  0.9794],\n",
            "        [-1.5409,  1.2513,  0.1188],\n",
            "        [-1.3540,  0.1240,  1.3123],\n",
            "        [ 0.5269,  0.0353, -0.8276],\n",
            "        [-1.2576,  1.1312,  0.1500],\n",
            "        [ 0.4046,  0.2338, -1.0288],\n",
            "        [-1.5261,  0.8091,  0.4610],\n",
            "        [-1.5306,  1.6742, -0.1396],\n",
            "        [-1.3197,  0.0766,  1.0444]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4043,  1.2494, -0.2870],\n",
            "        [-1.2591,  1.5246, -0.4960],\n",
            "        [-1.3841,  1.4757, -0.0234],\n",
            "        [ 0.1490,  0.5846, -1.0174],\n",
            "        [-1.3116,  1.5400, -0.3328],\n",
            "        [-1.5310,  1.3721, -0.1189],\n",
            "        [-1.7578,  0.4535,  1.0204],\n",
            "        [-1.4642,  1.5436, -0.2853],\n",
            "        [-1.6594,  1.5158,  0.1014],\n",
            "        [-2.0253,  0.4977,  1.1990],\n",
            "        [-1.5608,  1.3536,  0.2479],\n",
            "        [ 0.3350,  0.1108, -0.9865],\n",
            "        [-1.8074,  1.9347, -0.1663],\n",
            "        [-1.4224,  1.3062, -0.1261],\n",
            "        [-1.7988,  1.3463, -0.1657],\n",
            "        [-1.7957,  1.5599,  0.3014]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4043,  1.2494, -0.2870],\n",
            "        [-1.2591,  1.5246, -0.4960],\n",
            "        [-1.3841,  1.4757, -0.0234],\n",
            "        [ 0.1490,  0.5846, -1.0174],\n",
            "        [-1.3116,  1.5400, -0.3328],\n",
            "        [-1.5310,  1.3721, -0.1189],\n",
            "        [-1.7578,  0.4535,  1.0204],\n",
            "        [-1.4642,  1.5436, -0.2853],\n",
            "        [-1.6594,  1.5158,  0.1014],\n",
            "        [-2.0253,  0.4977,  1.1990],\n",
            "        [-1.5608,  1.3536,  0.2479],\n",
            "        [ 0.3350,  0.1108, -0.9865],\n",
            "        [-1.8074,  1.9347, -0.1663],\n",
            "        [-1.4224,  1.3062, -0.1261],\n",
            "        [-1.7988,  1.3463, -0.1657],\n",
            "        [-1.7957,  1.5599,  0.3014]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 4.8773e-01,  1.6422e-01, -1.0833e+00],\n",
            "        [-1.4927e+00,  1.6104e+00, -2.3649e-01],\n",
            "        [-1.8015e+00,  6.0284e-01,  1.1438e+00],\n",
            "        [-1.6781e+00,  1.8801e-01,  1.1323e+00],\n",
            "        [ 6.7304e-02,  6.4004e-01, -1.1722e+00],\n",
            "        [-1.6747e+00,  1.5605e+00, -4.5511e-02],\n",
            "        [-2.0814e+00,  1.0671e+00,  5.2518e-01],\n",
            "        [ 5.7903e-01,  2.0316e-01, -1.1209e+00],\n",
            "        [ 1.0761e-01,  1.5193e-03, -4.6654e-01],\n",
            "        [-1.5774e+00,  4.2154e-01,  1.0876e+00],\n",
            "        [-1.9767e+00,  1.3892e+00,  1.6594e-01],\n",
            "        [-1.5845e+00,  1.5327e+00, -2.1776e-01],\n",
            "        [ 5.1207e-01,  1.9021e-02, -9.9005e-01],\n",
            "        [-1.9290e+00,  1.6697e+00,  1.0314e-01],\n",
            "        [-1.7425e+00,  1.5502e+00, -5.6260e-02],\n",
            "        [-1.8699e+00,  1.7202e+00, -1.5457e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 4.8773e-01,  1.6422e-01, -1.0833e+00],\n",
            "        [-1.4927e+00,  1.6104e+00, -2.3649e-01],\n",
            "        [-1.8015e+00,  6.0284e-01,  1.1438e+00],\n",
            "        [-1.6781e+00,  1.8801e-01,  1.1323e+00],\n",
            "        [ 6.7304e-02,  6.4004e-01, -1.1722e+00],\n",
            "        [-1.6747e+00,  1.5605e+00, -4.5511e-02],\n",
            "        [-2.0814e+00,  1.0671e+00,  5.2518e-01],\n",
            "        [ 5.7903e-01,  2.0316e-01, -1.1209e+00],\n",
            "        [ 1.0761e-01,  1.5193e-03, -4.6654e-01],\n",
            "        [-1.5774e+00,  4.2154e-01,  1.0876e+00],\n",
            "        [-1.9767e+00,  1.3892e+00,  1.6594e-01],\n",
            "        [-1.5845e+00,  1.5327e+00, -2.1776e-01],\n",
            "        [ 5.1207e-01,  1.9021e-02, -9.9005e-01],\n",
            "        [-1.9290e+00,  1.6697e+00,  1.0314e-01],\n",
            "        [-1.7425e+00,  1.5502e+00, -5.6260e-02],\n",
            "        [-1.8699e+00,  1.7202e+00, -1.5457e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8233,  1.5853, -0.2400],\n",
            "        [-0.0897, -0.0030, -0.2684],\n",
            "        [-1.5785,  1.3103, -0.0986],\n",
            "        [-1.6523,  1.7152, -0.0551],\n",
            "        [ 0.4626,  0.2669, -1.1566],\n",
            "        [-1.7576,  0.7302,  0.7963],\n",
            "        [-1.5091,  1.7236, -0.0630],\n",
            "        [-1.5714,  1.5116,  0.0774],\n",
            "        [-0.8037,  1.4487, -0.7336],\n",
            "        [-1.8365,  1.7864, -0.0411],\n",
            "        [ 0.1088,  0.3826, -0.9204],\n",
            "        [-1.2552,  1.3660, -0.2644],\n",
            "        [ 0.5141,  0.1226, -1.0923],\n",
            "        [-0.9004,  1.1758, -0.6801],\n",
            "        [-1.4886,  1.5484,  0.0172],\n",
            "        [-1.6799,  1.3891,  0.1097]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8233,  1.5853, -0.2400],\n",
            "        [-0.0897, -0.0030, -0.2684],\n",
            "        [-1.5785,  1.3103, -0.0986],\n",
            "        [-1.6523,  1.7152, -0.0551],\n",
            "        [ 0.4626,  0.2669, -1.1566],\n",
            "        [-1.7576,  0.7302,  0.7963],\n",
            "        [-1.5091,  1.7236, -0.0630],\n",
            "        [-1.5714,  1.5116,  0.0774],\n",
            "        [-0.8037,  1.4487, -0.7336],\n",
            "        [-1.8365,  1.7864, -0.0411],\n",
            "        [ 0.1088,  0.3826, -0.9204],\n",
            "        [-1.2552,  1.3660, -0.2644],\n",
            "        [ 0.5141,  0.1226, -1.0923],\n",
            "        [-0.9004,  1.1758, -0.6801],\n",
            "        [-1.4886,  1.5484,  0.0172],\n",
            "        [-1.6799,  1.3891,  0.1097]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7150e+00,  1.9257e-01,  1.3709e+00],\n",
            "        [-1.5180e+00,  1.4361e+00,  4.7035e-03],\n",
            "        [-1.6922e+00,  1.5969e+00,  9.5192e-02],\n",
            "        [ 5.2747e-01,  2.9831e-01, -1.0035e+00],\n",
            "        [-6.4880e-01,  1.3299e+00, -7.6181e-01],\n",
            "        [-1.6524e+00,  4.4935e-01,  1.1226e+00],\n",
            "        [-1.6466e+00,  1.0508e+00,  1.5383e-01],\n",
            "        [-1.0143e+00,  6.0812e-01,  3.4682e-01],\n",
            "        [ 4.3454e-01, -1.4135e-03, -6.3426e-01],\n",
            "        [-1.7497e+00,  2.7209e-01,  1.1285e+00],\n",
            "        [-1.5315e+00,  6.1458e-01,  6.3165e-01],\n",
            "        [-1.4578e+00,  1.4970e+00, -1.6539e-01],\n",
            "        [-1.5117e+00,  1.5538e+00, -2.8478e-01],\n",
            "        [-1.9282e+00,  1.6423e+00,  4.6726e-02],\n",
            "        [-1.6750e+00,  1.6799e+00, -1.5301e-01],\n",
            "        [-1.4817e+00,  1.1786e+00,  4.0410e-02]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7150e+00,  1.9257e-01,  1.3709e+00],\n",
            "        [-1.5180e+00,  1.4361e+00,  4.7035e-03],\n",
            "        [-1.6922e+00,  1.5969e+00,  9.5192e-02],\n",
            "        [ 5.2747e-01,  2.9831e-01, -1.0035e+00],\n",
            "        [-6.4880e-01,  1.3299e+00, -7.6181e-01],\n",
            "        [-1.6524e+00,  4.4935e-01,  1.1226e+00],\n",
            "        [-1.6466e+00,  1.0508e+00,  1.5383e-01],\n",
            "        [-1.0143e+00,  6.0812e-01,  3.4682e-01],\n",
            "        [ 4.3454e-01, -1.4135e-03, -6.3426e-01],\n",
            "        [-1.7497e+00,  2.7209e-01,  1.1285e+00],\n",
            "        [-1.5315e+00,  6.1458e-01,  6.3165e-01],\n",
            "        [-1.4578e+00,  1.4970e+00, -1.6539e-01],\n",
            "        [-1.5117e+00,  1.5538e+00, -2.8478e-01],\n",
            "        [-1.9282e+00,  1.6423e+00,  4.6726e-02],\n",
            "        [-1.6750e+00,  1.6799e+00, -1.5301e-01],\n",
            "        [-1.4817e+00,  1.1786e+00,  4.0410e-02]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7328,  1.5762, -0.1616],\n",
            "        [-1.9475,  0.5378,  1.0089],\n",
            "        [ 0.3842,  0.2028, -1.1508],\n",
            "        [-0.1035,  0.6140, -0.9635],\n",
            "        [-1.6605,  0.4435,  1.2957],\n",
            "        [-1.8641,  0.2681,  1.0046],\n",
            "        [-1.5915,  1.5485, -0.1697],\n",
            "        [-1.7948,  1.5642, -0.1639],\n",
            "        [-1.6278,  1.6994, -0.1636],\n",
            "        [-1.5591,  0.7203,  0.6920],\n",
            "        [-1.0753,  0.2821,  0.6671],\n",
            "        [ 0.3960,  0.1171, -1.0726],\n",
            "        [-1.9128,  1.3134,  0.1784],\n",
            "        [-1.4533,  1.4374,  0.0281],\n",
            "        [-1.9593,  1.8695, -0.2747],\n",
            "        [-1.7809,  0.8938,  0.7059]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7328,  1.5762, -0.1616],\n",
            "        [-1.9475,  0.5378,  1.0089],\n",
            "        [ 0.3842,  0.2028, -1.1508],\n",
            "        [-0.1035,  0.6140, -0.9635],\n",
            "        [-1.6605,  0.4435,  1.2957],\n",
            "        [-1.8641,  0.2681,  1.0046],\n",
            "        [-1.5915,  1.5485, -0.1697],\n",
            "        [-1.7948,  1.5642, -0.1639],\n",
            "        [-1.6278,  1.6994, -0.1636],\n",
            "        [-1.5591,  0.7203,  0.6920],\n",
            "        [-1.0753,  0.2821,  0.6671],\n",
            "        [ 0.3960,  0.1171, -1.0726],\n",
            "        [-1.9128,  1.3134,  0.1784],\n",
            "        [-1.4533,  1.4374,  0.0281],\n",
            "        [-1.9593,  1.8695, -0.2747],\n",
            "        [-1.7809,  0.8938,  0.7059]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6874,  1.3671, -0.0529],\n",
            "        [-1.5714,  1.0241,  0.4602],\n",
            "        [-1.5468,  1.3847,  0.0306],\n",
            "        [ 0.1093,  0.6923, -1.1097],\n",
            "        [-1.7733,  1.6817, -0.0114],\n",
            "        [-1.7240,  1.5835, -0.2228],\n",
            "        [-1.7645,  1.8581, -0.1797],\n",
            "        [-1.4764,  1.4517, -0.2929],\n",
            "        [-1.6984,  0.3202,  1.2562],\n",
            "        [-1.7267,  1.7542, -0.1494],\n",
            "        [-1.3487,  1.4492, -0.0354],\n",
            "        [-1.4051,  1.5084, -0.1476],\n",
            "        [-1.6308,  1.7747, -0.1390],\n",
            "        [-1.4989,  1.5906, -0.2531],\n",
            "        [-2.0568,  0.1206,  1.2602],\n",
            "        [-1.8216,  0.0473,  1.3872]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6874,  1.3671, -0.0529],\n",
            "        [-1.5714,  1.0241,  0.4602],\n",
            "        [-1.5468,  1.3847,  0.0306],\n",
            "        [ 0.1093,  0.6923, -1.1097],\n",
            "        [-1.7733,  1.6817, -0.0114],\n",
            "        [-1.7240,  1.5835, -0.2228],\n",
            "        [-1.7645,  1.8581, -0.1797],\n",
            "        [-1.4764,  1.4517, -0.2929],\n",
            "        [-1.6984,  0.3202,  1.2562],\n",
            "        [-1.7267,  1.7542, -0.1494],\n",
            "        [-1.3487,  1.4492, -0.0354],\n",
            "        [-1.4051,  1.5084, -0.1476],\n",
            "        [-1.6308,  1.7747, -0.1390],\n",
            "        [-1.4989,  1.5906, -0.2531],\n",
            "        [-2.0568,  0.1206,  1.2602],\n",
            "        [-1.8216,  0.0473,  1.3872]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7311,  0.5898,  0.8662],\n",
            "        [ 0.5266,  0.1550, -1.3046],\n",
            "        [-1.6297,  1.7281, -0.2657],\n",
            "        [-1.5576,  0.2250,  1.2206],\n",
            "        [-1.6545,  1.7696, -0.3713],\n",
            "        [-1.0636,  1.2458, -0.4840],\n",
            "        [-1.6795,  1.5764,  0.0163],\n",
            "        [-1.8507,  1.7627, -0.2870],\n",
            "        [-1.5530,  1.5347, -0.1071],\n",
            "        [-1.9723,  1.1971,  0.3440],\n",
            "        [-1.7291,  1.6095,  0.0443],\n",
            "        [-1.8327,  1.4457,  0.4624],\n",
            "        [ 0.5797,  0.4467, -1.1790],\n",
            "        [-1.9476,  0.8112,  0.7260],\n",
            "        [-1.8158,  0.2409,  1.2241],\n",
            "        [-1.8973,  1.6976,  0.0584]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7311,  0.5898,  0.8662],\n",
            "        [ 0.5266,  0.1550, -1.3046],\n",
            "        [-1.6297,  1.7281, -0.2657],\n",
            "        [-1.5576,  0.2250,  1.2206],\n",
            "        [-1.6545,  1.7696, -0.3713],\n",
            "        [-1.0636,  1.2458, -0.4840],\n",
            "        [-1.6795,  1.5764,  0.0163],\n",
            "        [-1.8507,  1.7627, -0.2870],\n",
            "        [-1.5530,  1.5347, -0.1071],\n",
            "        [-1.9723,  1.1971,  0.3440],\n",
            "        [-1.7291,  1.6095,  0.0443],\n",
            "        [-1.8327,  1.4457,  0.4624],\n",
            "        [ 0.5797,  0.4467, -1.1790],\n",
            "        [-1.9476,  0.8112,  0.7260],\n",
            "        [-1.8158,  0.2409,  1.2241],\n",
            "        [-1.8973,  1.6976,  0.0584]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7076,  1.5558,  0.0649],\n",
            "        [-1.6371,  1.0105,  0.5634],\n",
            "        [ 0.6281,  0.0285, -1.2754],\n",
            "        [-1.5233,  1.8539, -0.2733],\n",
            "        [-1.8474,  0.3642,  1.3116],\n",
            "        [-1.7396,  2.0084, -0.1413],\n",
            "        [ 0.2835,  0.0049, -1.0683],\n",
            "        [-1.4295,  1.8070, -0.1921],\n",
            "        [-1.8686,  0.3440,  1.0822],\n",
            "        [-1.7977,  0.7824,  0.7732],\n",
            "        [-1.6424,  1.8321, -0.4987],\n",
            "        [-1.5879,  1.7947, -0.4378],\n",
            "        [-1.7618,  1.8081, -0.2463],\n",
            "        [-1.7607,  0.3214,  1.2043],\n",
            "        [-1.7629,  1.7408, -0.2581],\n",
            "        [ 0.2279,  0.1734, -1.0501]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7076,  1.5558,  0.0649],\n",
            "        [-1.6371,  1.0105,  0.5634],\n",
            "        [ 0.6281,  0.0285, -1.2754],\n",
            "        [-1.5233,  1.8539, -0.2733],\n",
            "        [-1.8474,  0.3642,  1.3116],\n",
            "        [-1.7396,  2.0084, -0.1413],\n",
            "        [ 0.2835,  0.0049, -1.0683],\n",
            "        [-1.4295,  1.8070, -0.1921],\n",
            "        [-1.8686,  0.3440,  1.0822],\n",
            "        [-1.7977,  0.7824,  0.7732],\n",
            "        [-1.6424,  1.8321, -0.4987],\n",
            "        [-1.5879,  1.7947, -0.4378],\n",
            "        [-1.7618,  1.8081, -0.2463],\n",
            "        [-1.7607,  0.3214,  1.2043],\n",
            "        [-1.7629,  1.7408, -0.2581],\n",
            "        [ 0.2279,  0.1734, -1.0501]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8267,  2.0654, -0.2306],\n",
            "        [-1.8935,  1.2777,  0.6264],\n",
            "        [-1.8639,  0.3729,  1.3272],\n",
            "        [-1.7690,  1.7687, -0.3630],\n",
            "        [-1.5734,  1.8831, -0.3874],\n",
            "        [-1.7589,  1.5292, -0.0147],\n",
            "        [-1.6698,  1.2952,  0.1582],\n",
            "        [-1.6026,  1.1946,  0.3688],\n",
            "        [-1.5800,  1.8070, -0.4066],\n",
            "        [-1.5058,  1.5341, -0.2084],\n",
            "        [ 0.5299,  0.2433, -1.2581],\n",
            "        [ 0.4143,  0.3010, -1.2606],\n",
            "        [-1.8524,  1.9505, -0.2893],\n",
            "        [-1.5025,  1.7677, -0.2287],\n",
            "        [-1.6609,  1.9490, -0.2101],\n",
            "        [-1.5321,  1.7406, -0.2647]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8267,  2.0654, -0.2306],\n",
            "        [-1.8935,  1.2777,  0.6264],\n",
            "        [-1.8639,  0.3729,  1.3272],\n",
            "        [-1.7690,  1.7687, -0.3630],\n",
            "        [-1.5734,  1.8831, -0.3874],\n",
            "        [-1.7589,  1.5292, -0.0147],\n",
            "        [-1.6698,  1.2952,  0.1582],\n",
            "        [-1.6026,  1.1946,  0.3688],\n",
            "        [-1.5800,  1.8070, -0.4066],\n",
            "        [-1.5058,  1.5341, -0.2084],\n",
            "        [ 0.5299,  0.2433, -1.2581],\n",
            "        [ 0.4143,  0.3010, -1.2606],\n",
            "        [-1.8524,  1.9505, -0.2893],\n",
            "        [-1.5025,  1.7677, -0.2287],\n",
            "        [-1.6609,  1.9490, -0.2101],\n",
            "        [-1.5321,  1.7406, -0.2647]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5760,  1.9634, -0.4918],\n",
            "        [-1.7606,  0.1933,  1.3688],\n",
            "        [ 0.4631,  0.2449, -1.0974],\n",
            "        [-1.6604,  1.7649, -0.2444],\n",
            "        [-1.3827,  1.6952, -0.4434],\n",
            "        [-1.8244,  1.7652, -0.1679],\n",
            "        [-1.5448,  1.6591, -0.2488],\n",
            "        [-1.7154,  0.1331,  1.2778],\n",
            "        [-1.6618,  1.8567, -0.3953],\n",
            "        [-1.7075,  0.4956,  1.0923],\n",
            "        [-1.7538,  1.7859, -0.0837],\n",
            "        [-1.6498,  1.8411, -0.1859],\n",
            "        [ 0.4508,  0.2071, -1.0559],\n",
            "        [-1.8047,  0.4381,  1.0016],\n",
            "        [-1.6646,  1.8217, -0.6678],\n",
            "        [-1.8605,  0.2523,  1.4498]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5760,  1.9634, -0.4918],\n",
            "        [-1.7606,  0.1933,  1.3688],\n",
            "        [ 0.4631,  0.2449, -1.0974],\n",
            "        [-1.6604,  1.7649, -0.2444],\n",
            "        [-1.3827,  1.6952, -0.4434],\n",
            "        [-1.8244,  1.7652, -0.1679],\n",
            "        [-1.5448,  1.6591, -0.2488],\n",
            "        [-1.7154,  0.1331,  1.2778],\n",
            "        [-1.6618,  1.8567, -0.3953],\n",
            "        [-1.7075,  0.4956,  1.0923],\n",
            "        [-1.7538,  1.7859, -0.0837],\n",
            "        [-1.6498,  1.8411, -0.1859],\n",
            "        [ 0.4508,  0.2071, -1.0559],\n",
            "        [-1.8047,  0.4381,  1.0016],\n",
            "        [-1.6646,  1.8217, -0.6678],\n",
            "        [-1.8605,  0.2523,  1.4498]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-9.4157e-01,  1.3919e+00, -8.2194e-01],\n",
            "        [-1.6483e+00,  2.1630e-01,  1.4804e+00],\n",
            "        [ 3.6638e-01,  2.1032e-01, -1.2299e+00],\n",
            "        [ 2.9982e-01,  3.1770e-01, -1.1921e+00],\n",
            "        [-1.7567e+00,  1.1956e+00,  5.7104e-01],\n",
            "        [-1.5920e+00,  1.6880e+00,  1.9019e-04],\n",
            "        [-1.9195e+00,  1.1301e+00,  6.0801e-01],\n",
            "        [-5.2892e-01,  3.0229e-01, -1.1621e-01],\n",
            "        [-1.0180e+00,  1.4688e+00, -6.5472e-01],\n",
            "        [-1.6874e+00,  4.2598e-02,  1.3475e+00],\n",
            "        [-1.1342e-01,  1.1230e-01, -5.7489e-01],\n",
            "        [-1.6313e+00,  2.0450e-01,  1.2058e+00],\n",
            "        [ 3.4800e-01,  3.5607e-01, -1.2233e+00],\n",
            "        [-1.9076e+00,  1.1515e+00,  6.0455e-01],\n",
            "        [-1.6822e+00,  2.0365e+00, -3.2051e-01],\n",
            "        [ 3.5212e-01,  2.8074e-01, -1.2400e+00]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-9.4157e-01,  1.3919e+00, -8.2194e-01],\n",
            "        [-1.6483e+00,  2.1630e-01,  1.4804e+00],\n",
            "        [ 3.6638e-01,  2.1032e-01, -1.2299e+00],\n",
            "        [ 2.9982e-01,  3.1770e-01, -1.1921e+00],\n",
            "        [-1.7567e+00,  1.1956e+00,  5.7104e-01],\n",
            "        [-1.5920e+00,  1.6880e+00,  1.9019e-04],\n",
            "        [-1.9195e+00,  1.1301e+00,  6.0801e-01],\n",
            "        [-5.2892e-01,  3.0229e-01, -1.1621e-01],\n",
            "        [-1.0180e+00,  1.4688e+00, -6.5472e-01],\n",
            "        [-1.6874e+00,  4.2598e-02,  1.3475e+00],\n",
            "        [-1.1342e-01,  1.1230e-01, -5.7489e-01],\n",
            "        [-1.6313e+00,  2.0450e-01,  1.2058e+00],\n",
            "        [ 3.4800e-01,  3.5607e-01, -1.2233e+00],\n",
            "        [-1.9076e+00,  1.1515e+00,  6.0455e-01],\n",
            "        [-1.6822e+00,  2.0365e+00, -3.2051e-01],\n",
            "        [ 3.5212e-01,  2.8074e-01, -1.2400e+00]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7344,  1.7751,  0.1480],\n",
            "        [-1.9432,  0.3059,  1.1133],\n",
            "        [-2.0526,  1.1942,  0.4277],\n",
            "        [ 0.5701,  0.4018, -1.2777],\n",
            "        [-1.6665,  0.7124,  0.7488],\n",
            "        [ 0.4891,  0.3204, -1.2989],\n",
            "        [-1.6684,  0.2439,  1.2760],\n",
            "        [-1.9982,  0.5700,  1.0685],\n",
            "        [-1.5895,  1.6957, -0.2906],\n",
            "        [-1.5937,  1.9984, -0.4099],\n",
            "        [-1.8677,  2.1438, -0.4215],\n",
            "        [ 0.1258,  0.4307, -1.0312],\n",
            "        [-1.6125,  1.8556, -0.4511],\n",
            "        [-1.5394,  1.9095, -0.3933],\n",
            "        [-1.8037,  2.1181, -0.2575],\n",
            "        [ 0.2713,  0.6176, -1.1831]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7344,  1.7751,  0.1480],\n",
            "        [-1.9432,  0.3059,  1.1133],\n",
            "        [-2.0526,  1.1942,  0.4277],\n",
            "        [ 0.5701,  0.4018, -1.2777],\n",
            "        [-1.6665,  0.7124,  0.7488],\n",
            "        [ 0.4891,  0.3204, -1.2989],\n",
            "        [-1.6684,  0.2439,  1.2760],\n",
            "        [-1.9982,  0.5700,  1.0685],\n",
            "        [-1.5895,  1.6957, -0.2906],\n",
            "        [-1.5937,  1.9984, -0.4099],\n",
            "        [-1.8677,  2.1438, -0.4215],\n",
            "        [ 0.1258,  0.4307, -1.0312],\n",
            "        [-1.6125,  1.8556, -0.4511],\n",
            "        [-1.5394,  1.9095, -0.3933],\n",
            "        [-1.8037,  2.1181, -0.2575],\n",
            "        [ 0.2713,  0.6176, -1.1831]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4884,  1.7074, -0.1277],\n",
            "        [ 0.3758,  0.2596, -1.3442],\n",
            "        [-1.7574,  0.5762,  1.0470],\n",
            "        [ 0.4303,  0.3631, -1.2397],\n",
            "        [-0.5585,  0.1059,  0.0064],\n",
            "        [-1.9498,  0.3662,  1.2487],\n",
            "        [-1.8099,  1.7121, -0.0621],\n",
            "        [-1.8930,  0.2391,  1.1967],\n",
            "        [-1.5762,  0.9048,  0.6212],\n",
            "        [-1.5037,  0.2562,  1.4114],\n",
            "        [-1.5182,  0.3954,  0.9144],\n",
            "        [-1.4667,  1.7550, -0.3375],\n",
            "        [ 0.2841,  0.7290, -1.2488],\n",
            "        [-1.8384,  0.8699,  0.8383],\n",
            "        [-1.7140,  1.0359,  0.6878],\n",
            "        [-1.7332,  2.0534, -0.6849]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4884,  1.7074, -0.1277],\n",
            "        [ 0.3758,  0.2596, -1.3442],\n",
            "        [-1.7574,  0.5762,  1.0470],\n",
            "        [ 0.4303,  0.3631, -1.2397],\n",
            "        [-0.5585,  0.1059,  0.0064],\n",
            "        [-1.9498,  0.3662,  1.2487],\n",
            "        [-1.8099,  1.7121, -0.0621],\n",
            "        [-1.8930,  0.2391,  1.1967],\n",
            "        [-1.5762,  0.9048,  0.6212],\n",
            "        [-1.5037,  0.2562,  1.4114],\n",
            "        [-1.5182,  0.3954,  0.9144],\n",
            "        [-1.4667,  1.7550, -0.3375],\n",
            "        [ 0.2841,  0.7290, -1.2488],\n",
            "        [-1.8384,  0.8699,  0.8383],\n",
            "        [-1.7140,  1.0359,  0.6878],\n",
            "        [-1.7332,  2.0534, -0.6849]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8291,  1.5084, -0.1764],\n",
            "        [-1.7540,  1.8619, -0.4229],\n",
            "        [ 0.3745,  0.4795, -1.0420],\n",
            "        [-1.7794, -0.0788,  1.2069],\n",
            "        [-0.0294,  0.4591, -0.9194],\n",
            "        [-1.7717,  0.9341,  0.2690],\n",
            "        [-1.6508,  0.3429,  1.0282],\n",
            "        [-1.4407,  1.9834, -0.4440],\n",
            "        [-1.8413,  0.1124,  1.2972],\n",
            "        [-1.6353,  2.0659, -0.5176],\n",
            "        [-0.7281,  1.1605, -0.4750],\n",
            "        [-1.7183,  2.0978, -0.5473],\n",
            "        [-1.4878,  1.5330, -0.1593],\n",
            "        [-1.6564,  2.0000, -0.3361],\n",
            "        [-1.5350,  0.2063,  1.3498],\n",
            "        [-1.7023,  1.9929, -0.3875]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8291,  1.5084, -0.1764],\n",
            "        [-1.7540,  1.8619, -0.4229],\n",
            "        [ 0.3745,  0.4795, -1.0420],\n",
            "        [-1.7794, -0.0788,  1.2069],\n",
            "        [-0.0294,  0.4591, -0.9194],\n",
            "        [-1.7717,  0.9341,  0.2690],\n",
            "        [-1.6508,  0.3429,  1.0282],\n",
            "        [-1.4407,  1.9834, -0.4440],\n",
            "        [-1.8413,  0.1124,  1.2972],\n",
            "        [-1.6353,  2.0659, -0.5176],\n",
            "        [-0.7281,  1.1605, -0.4750],\n",
            "        [-1.7183,  2.0978, -0.5473],\n",
            "        [-1.4878,  1.5330, -0.1593],\n",
            "        [-1.6564,  2.0000, -0.3361],\n",
            "        [-1.5350,  0.2063,  1.3498],\n",
            "        [-1.7023,  1.9929, -0.3875]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3268,  0.4995, -1.1391],\n",
            "        [-1.8351,  0.0069,  1.2039],\n",
            "        [-1.9394,  1.4339,  0.3483],\n",
            "        [ 0.4293,  0.3908, -1.2064],\n",
            "        [-1.1238,  0.1451,  0.5848],\n",
            "        [-1.9124,  1.0508,  0.5804],\n",
            "        [-1.5362,  1.4065,  0.0348],\n",
            "        [-1.7427,  2.0852, -0.2102],\n",
            "        [-1.6514,  2.0050, -0.4907],\n",
            "        [-1.9576,  1.0869,  0.4012],\n",
            "        [-1.5804,  0.1312,  1.2399],\n",
            "        [-1.8895,  1.3702,  0.1606],\n",
            "        [ 0.3761,  0.4053, -1.3211],\n",
            "        [-1.4869,  1.6654, -0.3208],\n",
            "        [ 0.3916,  0.3057, -1.1212],\n",
            "        [-1.4866,  1.7664, -0.4643]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.3268,  0.4995, -1.1391],\n",
            "        [-1.8351,  0.0069,  1.2039],\n",
            "        [-1.9394,  1.4339,  0.3483],\n",
            "        [ 0.4293,  0.3908, -1.2064],\n",
            "        [-1.1238,  0.1451,  0.5848],\n",
            "        [-1.9124,  1.0508,  0.5804],\n",
            "        [-1.5362,  1.4065,  0.0348],\n",
            "        [-1.7427,  2.0852, -0.2102],\n",
            "        [-1.6514,  2.0050, -0.4907],\n",
            "        [-1.9576,  1.0869,  0.4012],\n",
            "        [-1.5804,  0.1312,  1.2399],\n",
            "        [-1.8895,  1.3702,  0.1606],\n",
            "        [ 0.3761,  0.4053, -1.3211],\n",
            "        [-1.4869,  1.6654, -0.3208],\n",
            "        [ 0.3916,  0.3057, -1.1212],\n",
            "        [-1.4866,  1.7664, -0.4643]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.4618,  0.2711, -1.2033],\n",
            "        [ 0.0656,  0.7318, -1.2364],\n",
            "        [-1.8276,  0.3257,  1.5009],\n",
            "        [-1.4061,  1.6870, -0.5433],\n",
            "        [-1.7186,  0.0960,  1.3970],\n",
            "        [-1.6558,  1.7715, -0.0954],\n",
            "        [-1.5053,  0.2717,  1.0541],\n",
            "        [-1.7960,  1.6246, -0.0025],\n",
            "        [-1.7196,  0.3246,  1.0859],\n",
            "        [-1.7400,  1.9606, -0.6798],\n",
            "        [-1.6387,  0.9039,  0.3892],\n",
            "        [-1.7625,  2.1095, -0.4555],\n",
            "        [-1.7633,  0.4569,  0.8263],\n",
            "        [-1.4292,  1.7330, -0.2070],\n",
            "        [-1.7531,  0.5397,  1.1362],\n",
            "        [-1.4066,  1.8334, -0.7235]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.4618,  0.2711, -1.2033],\n",
            "        [ 0.0656,  0.7318, -1.2364],\n",
            "        [-1.8276,  0.3257,  1.5009],\n",
            "        [-1.4061,  1.6870, -0.5433],\n",
            "        [-1.7186,  0.0960,  1.3970],\n",
            "        [-1.6558,  1.7715, -0.0954],\n",
            "        [-1.5053,  0.2717,  1.0541],\n",
            "        [-1.7960,  1.6246, -0.0025],\n",
            "        [-1.7196,  0.3246,  1.0859],\n",
            "        [-1.7400,  1.9606, -0.6798],\n",
            "        [-1.6387,  0.9039,  0.3892],\n",
            "        [-1.7625,  2.1095, -0.4555],\n",
            "        [-1.7633,  0.4569,  0.8263],\n",
            "        [-1.4292,  1.7330, -0.2070],\n",
            "        [-1.7531,  0.5397,  1.1362],\n",
            "        [-1.4066,  1.8334, -0.7235]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3332,  0.3996, -1.2178],\n",
            "        [-1.3170,  1.6801, -0.5940],\n",
            "        [-1.6009,  1.8679, -0.5332],\n",
            "        [-1.6233,  0.8114,  0.8550],\n",
            "        [-1.7701,  2.1166, -0.5588],\n",
            "        [-1.7558,  1.7748, -0.0676],\n",
            "        [-1.7828,  0.0427,  1.5107],\n",
            "        [-1.5031,  1.6432, -0.4736],\n",
            "        [-1.8377,  0.1331,  1.2141],\n",
            "        [-1.7836,  1.6418, -0.1155],\n",
            "        [-1.6888,  1.9668, -0.5007],\n",
            "        [-1.6967, -0.0426,  1.3690],\n",
            "        [-1.5707,  0.3616,  0.8760],\n",
            "        [ 0.5618,  0.3189, -1.3209],\n",
            "        [-1.7482,  0.3832,  1.1861],\n",
            "        [-1.7737,  1.7628, -0.2543]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.3332,  0.3996, -1.2178],\n",
            "        [-1.3170,  1.6801, -0.5940],\n",
            "        [-1.6009,  1.8679, -0.5332],\n",
            "        [-1.6233,  0.8114,  0.8550],\n",
            "        [-1.7701,  2.1166, -0.5588],\n",
            "        [-1.7558,  1.7748, -0.0676],\n",
            "        [-1.7828,  0.0427,  1.5107],\n",
            "        [-1.5031,  1.6432, -0.4736],\n",
            "        [-1.8377,  0.1331,  1.2141],\n",
            "        [-1.7836,  1.6418, -0.1155],\n",
            "        [-1.6888,  1.9668, -0.5007],\n",
            "        [-1.6967, -0.0426,  1.3690],\n",
            "        [-1.5707,  0.3616,  0.8760],\n",
            "        [ 0.5618,  0.3189, -1.3209],\n",
            "        [-1.7482,  0.3832,  1.1861],\n",
            "        [-1.7737,  1.7628, -0.2543]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5296,  0.2119, -1.1879],\n",
            "        [-1.5975,  2.0142, -0.5254],\n",
            "        [-1.6831,  0.6012,  0.9468],\n",
            "        [-1.5535,  1.9735, -0.3223],\n",
            "        [-1.5850,  1.9472, -0.3468],\n",
            "        [-1.7444,  2.0428, -0.4787],\n",
            "        [-1.6131,  1.8681, -0.5985],\n",
            "        [-1.4223,  1.7962, -0.5601],\n",
            "        [-1.6250,  1.1963,  0.3523],\n",
            "        [-1.2185,  0.2143,  0.8481],\n",
            "        [-1.7560,  1.7918, -0.5102],\n",
            "        [-1.3069,  1.5724, -0.4184],\n",
            "        [ 0.4152,  0.3225, -1.1918],\n",
            "        [-1.5949,  2.0721, -0.4511],\n",
            "        [-1.5583,  2.0117, -0.4593],\n",
            "        [-1.2694,  0.5390,  0.5780]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.5296,  0.2119, -1.1879],\n",
            "        [-1.5975,  2.0142, -0.5254],\n",
            "        [-1.6831,  0.6012,  0.9468],\n",
            "        [-1.5535,  1.9735, -0.3223],\n",
            "        [-1.5850,  1.9472, -0.3468],\n",
            "        [-1.7444,  2.0428, -0.4787],\n",
            "        [-1.6131,  1.8681, -0.5985],\n",
            "        [-1.4223,  1.7962, -0.5601],\n",
            "        [-1.6250,  1.1963,  0.3523],\n",
            "        [-1.2185,  0.2143,  0.8481],\n",
            "        [-1.7560,  1.7918, -0.5102],\n",
            "        [-1.3069,  1.5724, -0.4184],\n",
            "        [ 0.4152,  0.3225, -1.1918],\n",
            "        [-1.5949,  2.0721, -0.4511],\n",
            "        [-1.5583,  2.0117, -0.4593],\n",
            "        [-1.2694,  0.5390,  0.5780]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0455,  1.7517, -0.1057],\n",
            "        [-1.3567,  0.3624,  0.6882],\n",
            "        [-1.7377,  1.5535, -0.0970],\n",
            "        [-1.5010,  1.7754, -0.5566],\n",
            "        [-1.5834,  0.0954,  1.0683],\n",
            "        [-1.2902,  1.6895, -0.7779],\n",
            "        [-1.6051,  0.2689,  1.2094],\n",
            "        [-1.4664,  1.7624, -0.4038],\n",
            "        [ 0.4325,  0.1185, -1.0598],\n",
            "        [-1.4583, -0.1061,  1.6323],\n",
            "        [-1.5830,  1.4911,  0.1335],\n",
            "        [-1.5047,  0.2328,  1.2433],\n",
            "        [-1.4471,  1.5972, -0.4202],\n",
            "        [-1.5451,  0.6308,  0.9527],\n",
            "        [ 0.3257,  0.3478, -1.0497],\n",
            "        [ 0.4359,  0.0788, -1.2347]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0455,  1.7517, -0.1057],\n",
            "        [-1.3567,  0.3624,  0.6882],\n",
            "        [-1.7377,  1.5535, -0.0970],\n",
            "        [-1.5010,  1.7754, -0.5566],\n",
            "        [-1.5834,  0.0954,  1.0683],\n",
            "        [-1.2902,  1.6895, -0.7779],\n",
            "        [-1.6051,  0.2689,  1.2094],\n",
            "        [-1.4664,  1.7624, -0.4038],\n",
            "        [ 0.4325,  0.1185, -1.0598],\n",
            "        [-1.4583, -0.1061,  1.6323],\n",
            "        [-1.5830,  1.4911,  0.1335],\n",
            "        [-1.5047,  0.2328,  1.2433],\n",
            "        [-1.4471,  1.5972, -0.4202],\n",
            "        [-1.5451,  0.6308,  0.9527],\n",
            "        [ 0.3257,  0.3478, -1.0497],\n",
            "        [ 0.4359,  0.0788, -1.2347]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6172,  0.1944,  1.2180],\n",
            "        [ 0.4446,  0.1177, -1.1033],\n",
            "        [-1.8686,  1.7087, -0.0927],\n",
            "        [-1.4338,  1.4766, -0.3710],\n",
            "        [-0.2094, -0.0071, -0.1716],\n",
            "        [-1.9076,  1.1429,  0.4563],\n",
            "        [ 0.4066,  0.2254, -1.0137],\n",
            "        [-1.3551,  1.8189, -0.8570],\n",
            "        [-1.5505,  0.6173,  0.8632],\n",
            "        [-1.5619,  0.5465,  0.8732],\n",
            "        [-1.4881, -0.0376,  1.4196],\n",
            "        [-0.1925,  0.6817, -1.1089],\n",
            "        [-1.4331,  1.5646, -0.5353],\n",
            "        [-1.4192,  0.2314,  1.1404],\n",
            "        [ 0.3664,  0.3409, -1.0644],\n",
            "        [ 0.4407,  0.2537, -1.2345]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6172,  0.1944,  1.2180],\n",
            "        [ 0.4446,  0.1177, -1.1033],\n",
            "        [-1.8686,  1.7087, -0.0927],\n",
            "        [-1.4338,  1.4766, -0.3710],\n",
            "        [-0.2094, -0.0071, -0.1716],\n",
            "        [-1.9076,  1.1429,  0.4563],\n",
            "        [ 0.4066,  0.2254, -1.0137],\n",
            "        [-1.3551,  1.8189, -0.8570],\n",
            "        [-1.5505,  0.6173,  0.8632],\n",
            "        [-1.5619,  0.5465,  0.8732],\n",
            "        [-1.4881, -0.0376,  1.4196],\n",
            "        [-0.1925,  0.6817, -1.1089],\n",
            "        [-1.4331,  1.5646, -0.5353],\n",
            "        [-1.4192,  0.2314,  1.1404],\n",
            "        [ 0.3664,  0.3409, -1.0644],\n",
            "        [ 0.4407,  0.2537, -1.2345]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5480e+00,  8.0399e-02,  1.2795e+00],\n",
            "        [-1.3190e+00,  1.7067e+00, -6.6505e-01],\n",
            "        [-1.5539e+00, -1.3599e-05,  1.3107e+00],\n",
            "        [-1.5152e+00,  1.8256e+00, -4.0869e-01],\n",
            "        [-1.5138e+00,  1.7773e+00, -9.8601e-02],\n",
            "        [-1.1009e+00,  9.0198e-01,  3.6408e-01],\n",
            "        [-1.4788e+00,  1.3133e-01,  1.0347e+00],\n",
            "        [-1.5636e+00,  1.8608e+00, -3.1653e-01],\n",
            "        [-1.5647e+00,  1.9193e+00, -4.9791e-01],\n",
            "        [-1.6009e+00,  4.4207e-01,  1.0252e+00],\n",
            "        [-1.5083e+00,  2.7256e-02,  1.4077e+00],\n",
            "        [-1.5195e+00,  3.6334e-02,  1.3258e+00],\n",
            "        [-1.3169e+00,  1.9627e+00, -5.6433e-01],\n",
            "        [-1.3254e+00,  6.7057e-01,  5.2465e-01],\n",
            "        [-1.7249e+00,  4.0823e-01,  1.1774e+00],\n",
            "        [ 3.0789e-01,  3.3249e-01, -9.0281e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5480e+00,  8.0399e-02,  1.2795e+00],\n",
            "        [-1.3190e+00,  1.7067e+00, -6.6505e-01],\n",
            "        [-1.5539e+00, -1.3599e-05,  1.3107e+00],\n",
            "        [-1.5152e+00,  1.8256e+00, -4.0869e-01],\n",
            "        [-1.5138e+00,  1.7773e+00, -9.8601e-02],\n",
            "        [-1.1009e+00,  9.0198e-01,  3.6408e-01],\n",
            "        [-1.4788e+00,  1.3133e-01,  1.0347e+00],\n",
            "        [-1.5636e+00,  1.8608e+00, -3.1653e-01],\n",
            "        [-1.5647e+00,  1.9193e+00, -4.9791e-01],\n",
            "        [-1.6009e+00,  4.4207e-01,  1.0252e+00],\n",
            "        [-1.5083e+00,  2.7256e-02,  1.4077e+00],\n",
            "        [-1.5195e+00,  3.6334e-02,  1.3258e+00],\n",
            "        [-1.3169e+00,  1.9627e+00, -5.6433e-01],\n",
            "        [-1.3254e+00,  6.7057e-01,  5.2465e-01],\n",
            "        [-1.7249e+00,  4.0823e-01,  1.1774e+00],\n",
            "        [ 3.0789e-01,  3.3249e-01, -9.0281e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6022, -0.0079,  1.2913],\n",
            "        [-1.6367,  0.5067,  1.2925],\n",
            "        [-1.7108,  0.0741,  1.5814],\n",
            "        [-1.2131,  1.7320, -0.4419],\n",
            "        [-1.5802,  1.5819,  0.1510],\n",
            "        [-1.2447,  0.9315, -0.0026],\n",
            "        [-1.5440, -0.0329,  1.1443],\n",
            "        [ 0.4988,  0.1312, -1.0523],\n",
            "        [-1.5362,  1.8466, -0.5458],\n",
            "        [ 0.2623,  0.1479, -1.0326],\n",
            "        [-1.5438,  1.9437, -0.5595],\n",
            "        [-1.9753,  0.2002,  1.3399],\n",
            "        [-1.5707, -0.0166,  1.3200],\n",
            "        [-1.5164,  0.4713,  0.7562],\n",
            "        [-1.4777,  1.3952, -0.5793],\n",
            "        [-1.5926,  0.0746,  1.4086]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6022, -0.0079,  1.2913],\n",
            "        [-1.6367,  0.5067,  1.2925],\n",
            "        [-1.7108,  0.0741,  1.5814],\n",
            "        [-1.2131,  1.7320, -0.4419],\n",
            "        [-1.5802,  1.5819,  0.1510],\n",
            "        [-1.2447,  0.9315, -0.0026],\n",
            "        [-1.5440, -0.0329,  1.1443],\n",
            "        [ 0.4988,  0.1312, -1.0523],\n",
            "        [-1.5362,  1.8466, -0.5458],\n",
            "        [ 0.2623,  0.1479, -1.0326],\n",
            "        [-1.5438,  1.9437, -0.5595],\n",
            "        [-1.9753,  0.2002,  1.3399],\n",
            "        [-1.5707, -0.0166,  1.3200],\n",
            "        [-1.5164,  0.4713,  0.7562],\n",
            "        [-1.4777,  1.3952, -0.5793],\n",
            "        [-1.5926,  0.0746,  1.4086]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4864,  1.5780, -0.2805],\n",
            "        [-1.4768,  1.7481, -0.1462],\n",
            "        [ 0.5578,  0.2706, -1.0826],\n",
            "        [-1.2333,  1.2709,  0.1100],\n",
            "        [-0.9817,  0.4337,  0.4984],\n",
            "        [-1.4584,  1.4617,  0.1032],\n",
            "        [-1.6388, -0.0541,  1.1293],\n",
            "        [-1.6030,  1.1728,  0.4252],\n",
            "        [-1.6858,  0.7465,  0.4658],\n",
            "        [-1.3282,  1.4717, -0.1853],\n",
            "        [ 0.2255,  0.1354, -0.9134],\n",
            "        [-1.4001,  1.6662, -0.5434],\n",
            "        [-1.5070,  0.2024,  1.3587],\n",
            "        [-1.4015,  1.6788, -0.2746],\n",
            "        [-1.5008,  1.5120, -0.4240],\n",
            "        [ 0.3393,  0.1116, -0.7732]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4864,  1.5780, -0.2805],\n",
            "        [-1.4768,  1.7481, -0.1462],\n",
            "        [ 0.5578,  0.2706, -1.0826],\n",
            "        [-1.2333,  1.2709,  0.1100],\n",
            "        [-0.9817,  0.4337,  0.4984],\n",
            "        [-1.4584,  1.4617,  0.1032],\n",
            "        [-1.6388, -0.0541,  1.1293],\n",
            "        [-1.6030,  1.1728,  0.4252],\n",
            "        [-1.6858,  0.7465,  0.4658],\n",
            "        [-1.3282,  1.4717, -0.1853],\n",
            "        [ 0.2255,  0.1354, -0.9134],\n",
            "        [-1.4001,  1.6662, -0.5434],\n",
            "        [-1.5070,  0.2024,  1.3587],\n",
            "        [-1.4015,  1.6788, -0.2746],\n",
            "        [-1.5008,  1.5120, -0.4240],\n",
            "        [ 0.3393,  0.1116, -0.7732]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3203,  0.1427,  1.3337],\n",
            "        [-1.7396,  0.3815,  1.1404],\n",
            "        [ 0.5136,  0.2786, -1.2197],\n",
            "        [-1.6912,  0.2618,  1.0688],\n",
            "        [-1.0565,  1.3968, -0.1228],\n",
            "        [-1.5587,  1.9296, -0.4756],\n",
            "        [-1.5210,  1.3617,  0.1213],\n",
            "        [-1.5286,  0.9792,  0.2246],\n",
            "        [-1.6613,  0.8485,  0.6723],\n",
            "        [-1.0946,  1.4610, -0.1646],\n",
            "        [-0.8187,  1.4076, -1.1329],\n",
            "        [-1.4674,  1.7325, -0.7461],\n",
            "        [-1.1103,  1.3574, -0.5478],\n",
            "        [ 0.5368,  0.1302, -1.2082],\n",
            "        [-1.4583,  1.0972,  0.2062],\n",
            "        [-1.4884,  0.2517,  1.1783]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3203,  0.1427,  1.3337],\n",
            "        [-1.7396,  0.3815,  1.1404],\n",
            "        [ 0.5136,  0.2786, -1.2197],\n",
            "        [-1.6912,  0.2618,  1.0688],\n",
            "        [-1.0565,  1.3968, -0.1228],\n",
            "        [-1.5587,  1.9296, -0.4756],\n",
            "        [-1.5210,  1.3617,  0.1213],\n",
            "        [-1.5286,  0.9792,  0.2246],\n",
            "        [-1.6613,  0.8485,  0.6723],\n",
            "        [-1.0946,  1.4610, -0.1646],\n",
            "        [-0.8187,  1.4076, -1.1329],\n",
            "        [-1.4674,  1.7325, -0.7461],\n",
            "        [-1.1103,  1.3574, -0.5478],\n",
            "        [ 0.5368,  0.1302, -1.2082],\n",
            "        [-1.4583,  1.0972,  0.2062],\n",
            "        [-1.4884,  0.2517,  1.1783]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5833,  1.4680, -0.2106],\n",
            "        [-1.4256,  1.7487, -0.3193],\n",
            "        [-1.2177,  1.6745, -0.4403],\n",
            "        [-1.5692,  1.6454, -0.2117],\n",
            "        [-1.0790,  1.6855, -0.4410],\n",
            "        [-1.4926,  1.1514,  0.2438],\n",
            "        [-1.3616,  1.6332, -0.3906],\n",
            "        [-1.1601,  1.2425, -0.1504],\n",
            "        [-1.5607,  1.3860, -0.1479],\n",
            "        [-1.2913,  1.9167, -0.6567],\n",
            "        [-0.6328,  0.7750, -0.4580],\n",
            "        [-1.1937,  1.5183, -0.4768],\n",
            "        [ 0.4622,  0.0805, -1.0238],\n",
            "        [-1.1215,  1.5936, -0.6052],\n",
            "        [-1.4579,  1.1679,  0.0485],\n",
            "        [-0.8252,  0.2151,  0.3894]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5833,  1.4680, -0.2106],\n",
            "        [-1.4256,  1.7487, -0.3193],\n",
            "        [-1.2177,  1.6745, -0.4403],\n",
            "        [-1.5692,  1.6454, -0.2117],\n",
            "        [-1.0790,  1.6855, -0.4410],\n",
            "        [-1.4926,  1.1514,  0.2438],\n",
            "        [-1.3616,  1.6332, -0.3906],\n",
            "        [-1.1601,  1.2425, -0.1504],\n",
            "        [-1.5607,  1.3860, -0.1479],\n",
            "        [-1.2913,  1.9167, -0.6567],\n",
            "        [-0.6328,  0.7750, -0.4580],\n",
            "        [-1.1937,  1.5183, -0.4768],\n",
            "        [ 0.4622,  0.0805, -1.0238],\n",
            "        [-1.1215,  1.5936, -0.6052],\n",
            "        [-1.4579,  1.1679,  0.0485],\n",
            "        [-0.8252,  0.2151,  0.3894]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5827,  0.1849,  1.1541],\n",
            "        [-1.6367,  1.2797,  0.0827],\n",
            "        [-1.7756,  0.9557,  0.6747],\n",
            "        [-1.5162,  0.5767,  0.9104],\n",
            "        [-1.3976,  1.9745, -0.4387],\n",
            "        [ 0.3150,  0.1986, -1.0103],\n",
            "        [-1.6373,  0.2782,  1.1819],\n",
            "        [-1.6005,  1.0687,  0.5281],\n",
            "        [-1.2609,  0.4586,  0.8847],\n",
            "        [-1.4543,  1.7025, -0.3051],\n",
            "        [-1.1837,  1.6218, -0.2445],\n",
            "        [-1.2730,  1.6702, -0.4491],\n",
            "        [-1.5974,  0.5388,  0.9425],\n",
            "        [ 0.3395,  0.1522, -0.8918],\n",
            "        [ 0.3780,  0.2085, -1.1187],\n",
            "        [-1.6624,  1.7238, -0.5187]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5827,  0.1849,  1.1541],\n",
            "        [-1.6367,  1.2797,  0.0827],\n",
            "        [-1.7756,  0.9557,  0.6747],\n",
            "        [-1.5162,  0.5767,  0.9104],\n",
            "        [-1.3976,  1.9745, -0.4387],\n",
            "        [ 0.3150,  0.1986, -1.0103],\n",
            "        [-1.6373,  0.2782,  1.1819],\n",
            "        [-1.6005,  1.0687,  0.5281],\n",
            "        [-1.2609,  0.4586,  0.8847],\n",
            "        [-1.4543,  1.7025, -0.3051],\n",
            "        [-1.1837,  1.6218, -0.2445],\n",
            "        [-1.2730,  1.6702, -0.4491],\n",
            "        [-1.5974,  0.5388,  0.9425],\n",
            "        [ 0.3395,  0.1522, -0.8918],\n",
            "        [ 0.3780,  0.2085, -1.1187],\n",
            "        [-1.6624,  1.7238, -0.5187]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5443,  0.7098,  0.7279],\n",
            "        [-1.5644,  1.6453, -0.3897],\n",
            "        [-1.1719,  1.9052, -0.9764],\n",
            "        [-1.4623,  1.7206, -0.3246],\n",
            "        [-1.5340,  0.7417,  0.7935],\n",
            "        [-1.3447,  1.9009, -0.6701],\n",
            "        [ 0.3399,  0.1703, -1.0889],\n",
            "        [-0.7518,  0.2519,  0.3901],\n",
            "        [-1.7728,  0.5606,  0.9677],\n",
            "        [ 0.0341,  0.2259, -0.8335],\n",
            "        [-1.5179,  1.9629, -0.3948],\n",
            "        [-1.6597, -0.0455,  1.4703],\n",
            "        [ 0.4389,  0.1132, -1.0524],\n",
            "        [-1.7490,  0.4655,  1.2511],\n",
            "        [-1.0089,  1.2969, -0.1093],\n",
            "        [-1.6822,  1.0537,  0.3305]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5443,  0.7098,  0.7279],\n",
            "        [-1.5644,  1.6453, -0.3897],\n",
            "        [-1.1719,  1.9052, -0.9764],\n",
            "        [-1.4623,  1.7206, -0.3246],\n",
            "        [-1.5340,  0.7417,  0.7935],\n",
            "        [-1.3447,  1.9009, -0.6701],\n",
            "        [ 0.3399,  0.1703, -1.0889],\n",
            "        [-0.7518,  0.2519,  0.3901],\n",
            "        [-1.7728,  0.5606,  0.9677],\n",
            "        [ 0.0341,  0.2259, -0.8335],\n",
            "        [-1.5179,  1.9629, -0.3948],\n",
            "        [-1.6597, -0.0455,  1.4703],\n",
            "        [ 0.4389,  0.1132, -1.0524],\n",
            "        [-1.7490,  0.4655,  1.2511],\n",
            "        [-1.0089,  1.2969, -0.1093],\n",
            "        [-1.6822,  1.0537,  0.3305]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5890,  1.9627, -0.2472],\n",
            "        [-1.2382,  1.4711, -0.6534],\n",
            "        [-1.3771,  1.5748, -0.5175],\n",
            "        [-1.4408,  1.0709,  0.2810],\n",
            "        [-1.5839,  0.2799,  1.0577],\n",
            "        [ 0.4732,  0.0232, -0.8018],\n",
            "        [-1.4254,  1.3427,  0.4882],\n",
            "        [-1.4108,  1.4401, -0.4915],\n",
            "        [ 0.3421,  0.0511, -0.8899],\n",
            "        [-1.4470,  0.2870,  1.0769],\n",
            "        [-1.5868,  1.3840, -0.1240],\n",
            "        [-1.6362,  1.4431, -0.0484],\n",
            "        [-1.0194,  1.5556, -0.8286],\n",
            "        [-1.6612,  1.3340,  0.2443],\n",
            "        [-1.6065,  1.8767, -0.3361],\n",
            "        [-1.3890,  1.8883, -0.3494]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5890,  1.9627, -0.2472],\n",
            "        [-1.2382,  1.4711, -0.6534],\n",
            "        [-1.3771,  1.5748, -0.5175],\n",
            "        [-1.4408,  1.0709,  0.2810],\n",
            "        [-1.5839,  0.2799,  1.0577],\n",
            "        [ 0.4732,  0.0232, -0.8018],\n",
            "        [-1.4254,  1.3427,  0.4882],\n",
            "        [-1.4108,  1.4401, -0.4915],\n",
            "        [ 0.3421,  0.0511, -0.8899],\n",
            "        [-1.4470,  0.2870,  1.0769],\n",
            "        [-1.5868,  1.3840, -0.1240],\n",
            "        [-1.6362,  1.4431, -0.0484],\n",
            "        [-1.0194,  1.5556, -0.8286],\n",
            "        [-1.6612,  1.3340,  0.2443],\n",
            "        [-1.6065,  1.8767, -0.3361],\n",
            "        [-1.3890,  1.8883, -0.3494]], grad_fn=<AddmmBackward0>)\n",
            "Epoch 1/3, Loss: 0.6177\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4485,  2.0752, -0.7274],\n",
            "        [-0.5155,  0.4191, -0.3043],\n",
            "        [-1.7204,  0.2690,  1.0380],\n",
            "        [-1.5407,  1.8707, -0.5008],\n",
            "        [-1.3855,  1.9309, -0.7021],\n",
            "        [-1.7423,  1.1646,  0.6149],\n",
            "        [ 0.5511,  0.0591, -1.0089],\n",
            "        [-1.7006,  1.9496, -0.3070],\n",
            "        [-1.5253,  1.7423, -0.2981],\n",
            "        [-1.5178,  1.6330, -0.2278],\n",
            "        [-1.5899,  1.3149,  0.2426],\n",
            "        [-1.4200,  0.5173,  1.1284],\n",
            "        [-1.5881,  1.8861, -0.4367],\n",
            "        [-1.4559,  0.4416,  0.8990],\n",
            "        [-0.4859,  0.1893,  0.0196],\n",
            "        [-1.7676,  1.8937, -0.2291]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4485,  2.0752, -0.7274],\n",
            "        [-0.5155,  0.4191, -0.3043],\n",
            "        [-1.7204,  0.2690,  1.0380],\n",
            "        [-1.5407,  1.8707, -0.5008],\n",
            "        [-1.3855,  1.9309, -0.7021],\n",
            "        [-1.7423,  1.1646,  0.6149],\n",
            "        [ 0.5511,  0.0591, -1.0089],\n",
            "        [-1.7006,  1.9496, -0.3070],\n",
            "        [-1.5253,  1.7423, -0.2981],\n",
            "        [-1.5178,  1.6330, -0.2278],\n",
            "        [-1.5899,  1.3149,  0.2426],\n",
            "        [-1.4200,  0.5173,  1.1284],\n",
            "        [-1.5881,  1.8861, -0.4367],\n",
            "        [-1.4559,  0.4416,  0.8990],\n",
            "        [-0.4859,  0.1893,  0.0196],\n",
            "        [-1.7676,  1.8937, -0.2291]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3878,  1.9606, -0.5221],\n",
            "        [-1.5723,  2.0585, -0.5577],\n",
            "        [-1.5952,  2.1116, -0.9646],\n",
            "        [-1.6014,  0.3774,  1.0650],\n",
            "        [-1.6391,  1.9252, -0.6249],\n",
            "        [-1.5581,  1.2263, -0.0059],\n",
            "        [-1.7241,  1.7379, -0.2880],\n",
            "        [-1.3670,  0.1675,  0.7775],\n",
            "        [-1.4339,  1.2548, -0.0682],\n",
            "        [ 0.4632, -0.0036, -0.9866],\n",
            "        [-1.5142,  1.5252, -0.2293],\n",
            "        [-1.5025,  2.0399, -0.4948],\n",
            "        [-1.6709,  1.7396, -0.0709],\n",
            "        [-1.2930,  0.4555,  0.5473],\n",
            "        [-1.4573,  0.4275,  0.8730],\n",
            "        [-1.3231,  0.2192,  0.9791]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3878,  1.9606, -0.5221],\n",
            "        [-1.5723,  2.0585, -0.5577],\n",
            "        [-1.5952,  2.1116, -0.9646],\n",
            "        [-1.6014,  0.3774,  1.0650],\n",
            "        [-1.6391,  1.9252, -0.6249],\n",
            "        [-1.5581,  1.2263, -0.0059],\n",
            "        [-1.7241,  1.7379, -0.2880],\n",
            "        [-1.3670,  0.1675,  0.7775],\n",
            "        [-1.4339,  1.2548, -0.0682],\n",
            "        [ 0.4632, -0.0036, -0.9866],\n",
            "        [-1.5142,  1.5252, -0.2293],\n",
            "        [-1.5025,  2.0399, -0.4948],\n",
            "        [-1.6709,  1.7396, -0.0709],\n",
            "        [-1.2930,  0.4555,  0.5473],\n",
            "        [-1.4573,  0.4275,  0.8730],\n",
            "        [-1.3231,  0.2192,  0.9791]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.1115,  1.5779, -0.6552],\n",
            "        [-1.5399,  1.8953, -0.3126],\n",
            "        [-1.5924,  1.8661, -0.0861],\n",
            "        [-1.5598,  1.8385, -0.4715],\n",
            "        [-1.7561,  0.8326,  0.7716],\n",
            "        [-1.7700,  0.4009,  1.1007],\n",
            "        [-1.7324,  0.5962,  0.8682],\n",
            "        [-1.6923,  0.4239,  1.1498],\n",
            "        [-1.6057,  1.9345, -0.7065],\n",
            "        [-1.4868,  0.8626,  0.3693],\n",
            "        [-1.2918,  1.7831, -0.5148],\n",
            "        [-1.7047,  1.7670, -0.1164],\n",
            "        [-1.4672,  0.3545,  1.0483],\n",
            "        [-1.2849,  1.4194, -0.3947],\n",
            "        [-1.5660,  0.3418,  0.9423],\n",
            "        [-1.6155,  0.6555,  1.1066]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.1115,  1.5779, -0.6552],\n",
            "        [-1.5399,  1.8953, -0.3126],\n",
            "        [-1.5924,  1.8661, -0.0861],\n",
            "        [-1.5598,  1.8385, -0.4715],\n",
            "        [-1.7561,  0.8326,  0.7716],\n",
            "        [-1.7700,  0.4009,  1.1007],\n",
            "        [-1.7324,  0.5962,  0.8682],\n",
            "        [-1.6923,  0.4239,  1.1498],\n",
            "        [-1.6057,  1.9345, -0.7065],\n",
            "        [-1.4868,  0.8626,  0.3693],\n",
            "        [-1.2918,  1.7831, -0.5148],\n",
            "        [-1.7047,  1.7670, -0.1164],\n",
            "        [-1.4672,  0.3545,  1.0483],\n",
            "        [-1.2849,  1.4194, -0.3947],\n",
            "        [-1.5660,  0.3418,  0.9423],\n",
            "        [-1.6155,  0.6555,  1.1066]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5593,  0.2843,  1.1484],\n",
            "        [-1.3850,  1.8727, -0.5840],\n",
            "        [-1.5304,  1.4264, -0.2573],\n",
            "        [-1.6775,  0.5830,  0.9966],\n",
            "        [-1.3580,  0.2842,  0.8110],\n",
            "        [ 0.3878,  0.0156, -1.0252],\n",
            "        [-1.5380,  1.8718, -0.2135],\n",
            "        [ 0.3107,  0.1543, -0.9282],\n",
            "        [-1.6730,  0.0942,  1.2986],\n",
            "        [-1.5033,  1.7717, -0.3517],\n",
            "        [-1.4022,  1.9869, -0.4783],\n",
            "        [-1.4801,  0.5605,  0.5590],\n",
            "        [-1.6711,  2.2582, -0.5488],\n",
            "        [-1.4757,  1.9766, -0.4140],\n",
            "        [-1.1789,  1.5351, -0.4388],\n",
            "        [-1.6154,  1.1828,  0.5317]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5593,  0.2843,  1.1484],\n",
            "        [-1.3850,  1.8727, -0.5840],\n",
            "        [-1.5304,  1.4264, -0.2573],\n",
            "        [-1.6775,  0.5830,  0.9966],\n",
            "        [-1.3580,  0.2842,  0.8110],\n",
            "        [ 0.3878,  0.0156, -1.0252],\n",
            "        [-1.5380,  1.8718, -0.2135],\n",
            "        [ 0.3107,  0.1543, -0.9282],\n",
            "        [-1.6730,  0.0942,  1.2986],\n",
            "        [-1.5033,  1.7717, -0.3517],\n",
            "        [-1.4022,  1.9869, -0.4783],\n",
            "        [-1.4801,  0.5605,  0.5590],\n",
            "        [-1.6711,  2.2582, -0.5488],\n",
            "        [-1.4757,  1.9766, -0.4140],\n",
            "        [-1.1789,  1.5351, -0.4388],\n",
            "        [-1.6154,  1.1828,  0.5317]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5205,  1.4853, -0.1467],\n",
            "        [-1.4950,  1.9429, -0.2826],\n",
            "        [-1.5981,  1.8700, -0.3216],\n",
            "        [-1.6286,  0.3489,  1.0298],\n",
            "        [-1.6904,  1.5971,  0.0142],\n",
            "        [-0.4270,  1.0714, -0.9768],\n",
            "        [ 0.5653, -0.1231, -0.8548],\n",
            "        [-1.4456,  1.6981, -0.4948],\n",
            "        [-1.7819,  1.2726,  0.2995],\n",
            "        [-1.7524,  2.1469, -0.4656],\n",
            "        [-1.6668,  1.9996, -0.3360],\n",
            "        [-1.4175,  0.5586,  0.8767],\n",
            "        [-1.2851,  1.7211, -0.4697],\n",
            "        [-0.9640,  0.4246,  0.3558],\n",
            "        [ 0.3155,  0.0995, -0.9192],\n",
            "        [-1.7245,  0.9527,  0.5298]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5205,  1.4853, -0.1467],\n",
            "        [-1.4950,  1.9429, -0.2826],\n",
            "        [-1.5981,  1.8700, -0.3216],\n",
            "        [-1.6286,  0.3489,  1.0298],\n",
            "        [-1.6904,  1.5971,  0.0142],\n",
            "        [-0.4270,  1.0714, -0.9768],\n",
            "        [ 0.5653, -0.1231, -0.8548],\n",
            "        [-1.4456,  1.6981, -0.4948],\n",
            "        [-1.7819,  1.2726,  0.2995],\n",
            "        [-1.7524,  2.1469, -0.4656],\n",
            "        [-1.6668,  1.9996, -0.3360],\n",
            "        [-1.4175,  0.5586,  0.8767],\n",
            "        [-1.2851,  1.7211, -0.4697],\n",
            "        [-0.9640,  0.4246,  0.3558],\n",
            "        [ 0.3155,  0.0995, -0.9192],\n",
            "        [-1.7245,  0.9527,  0.5298]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7350,  2.0024, -0.5823],\n",
            "        [-1.7047,  1.7994, -0.0239],\n",
            "        [-0.0208,  0.1432, -0.5033],\n",
            "        [ 0.4618, -0.0585, -0.9501],\n",
            "        [-0.9873,  0.3592,  0.3709],\n",
            "        [-1.8940,  0.4563,  1.0645],\n",
            "        [-1.4819,  1.8777, -0.3691],\n",
            "        [ 0.3855,  0.2402, -0.9408],\n",
            "        [-1.5760,  0.3585,  0.8729],\n",
            "        [-1.4066,  1.1415,  0.6052],\n",
            "        [-1.2735,  1.8023, -0.3911],\n",
            "        [-1.5922,  0.4994,  1.1693],\n",
            "        [ 0.2224,  0.3009, -1.0535],\n",
            "        [ 0.3887,  0.0180, -0.8738],\n",
            "        [-1.5390,  1.9939, -0.4690],\n",
            "        [-1.7676,  0.7212,  0.7845]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7350,  2.0024, -0.5823],\n",
            "        [-1.7047,  1.7994, -0.0239],\n",
            "        [-0.0208,  0.1432, -0.5033],\n",
            "        [ 0.4618, -0.0585, -0.9501],\n",
            "        [-0.9873,  0.3592,  0.3709],\n",
            "        [-1.8940,  0.4563,  1.0645],\n",
            "        [-1.4819,  1.8777, -0.3691],\n",
            "        [ 0.3855,  0.2402, -0.9408],\n",
            "        [-1.5760,  0.3585,  0.8729],\n",
            "        [-1.4066,  1.1415,  0.6052],\n",
            "        [-1.2735,  1.8023, -0.3911],\n",
            "        [-1.5922,  0.4994,  1.1693],\n",
            "        [ 0.2224,  0.3009, -1.0535],\n",
            "        [ 0.3887,  0.0180, -0.8738],\n",
            "        [-1.5390,  1.9939, -0.4690],\n",
            "        [-1.7676,  0.7212,  0.7845]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5800,  2.0931, -0.5048],\n",
            "        [-1.2564,  1.8702, -0.4041],\n",
            "        [-1.4384,  2.3145, -0.6760],\n",
            "        [-1.7901,  1.8990, -0.3479],\n",
            "        [-1.4885,  0.6866,  0.6823],\n",
            "        [-1.5971,  2.0120, -0.4495],\n",
            "        [-1.3430,  1.7421, -0.6463],\n",
            "        [-1.4037,  1.9837, -0.5669],\n",
            "        [-1.5933,  2.1382, -0.5400],\n",
            "        [-0.9778,  1.6387, -0.6988],\n",
            "        [-1.5027,  0.6699,  0.6166],\n",
            "        [-0.0752,  0.7625, -1.1183],\n",
            "        [-1.3007,  1.9486, -0.4322],\n",
            "        [-1.8119,  2.0350, -0.3080],\n",
            "        [-1.6130,  1.7910, -0.3154],\n",
            "        [ 0.5530, -0.1601, -0.9376]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5800,  2.0931, -0.5048],\n",
            "        [-1.2564,  1.8702, -0.4041],\n",
            "        [-1.4384,  2.3145, -0.6760],\n",
            "        [-1.7901,  1.8990, -0.3479],\n",
            "        [-1.4885,  0.6866,  0.6823],\n",
            "        [-1.5971,  2.0120, -0.4495],\n",
            "        [-1.3430,  1.7421, -0.6463],\n",
            "        [-1.4037,  1.9837, -0.5669],\n",
            "        [-1.5933,  2.1382, -0.5400],\n",
            "        [-0.9778,  1.6387, -0.6988],\n",
            "        [-1.5027,  0.6699,  0.6166],\n",
            "        [-0.0752,  0.7625, -1.1183],\n",
            "        [-1.3007,  1.9486, -0.4322],\n",
            "        [-1.8119,  2.0350, -0.3080],\n",
            "        [-1.6130,  1.7910, -0.3154],\n",
            "        [ 0.5530, -0.1601, -0.9376]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7048,  2.2333, -0.5352],\n",
            "        [-1.4017,  1.9627, -0.7903],\n",
            "        [-1.4257,  1.9160, -0.6687],\n",
            "        [-1.4338,  0.4215,  0.9311],\n",
            "        [-1.5569,  0.1093,  1.0928],\n",
            "        [-1.2824,  1.7868, -0.4973],\n",
            "        [-1.5267,  1.8422, -0.4887],\n",
            "        [-0.1602,  0.2169, -0.5604],\n",
            "        [ 0.0395,  0.6294, -1.0896],\n",
            "        [-1.5696,  0.5947,  0.9431],\n",
            "        [-1.5567,  0.5920,  0.7663],\n",
            "        [-1.5645,  2.3186, -0.4542],\n",
            "        [-1.5526,  0.4766,  0.9584],\n",
            "        [-1.5556,  1.0503,  0.4195],\n",
            "        [-1.5668,  0.2828,  0.9736],\n",
            "        [-1.3691,  0.0823,  1.1518]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7048,  2.2333, -0.5352],\n",
            "        [-1.4017,  1.9627, -0.7903],\n",
            "        [-1.4257,  1.9160, -0.6687],\n",
            "        [-1.4338,  0.4215,  0.9311],\n",
            "        [-1.5569,  0.1093,  1.0928],\n",
            "        [-1.2824,  1.7868, -0.4973],\n",
            "        [-1.5267,  1.8422, -0.4887],\n",
            "        [-0.1602,  0.2169, -0.5604],\n",
            "        [ 0.0395,  0.6294, -1.0896],\n",
            "        [-1.5696,  0.5947,  0.9431],\n",
            "        [-1.5567,  0.5920,  0.7663],\n",
            "        [-1.5645,  2.3186, -0.4542],\n",
            "        [-1.5526,  0.4766,  0.9584],\n",
            "        [-1.5556,  1.0503,  0.4195],\n",
            "        [-1.5668,  0.2828,  0.9736],\n",
            "        [-1.3691,  0.0823,  1.1518]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9076,  1.9435, -0.4114],\n",
            "        [-1.6627,  2.0398, -0.7955],\n",
            "        [-1.6634,  2.2645, -0.5654],\n",
            "        [-1.3159,  1.9568, -0.8007],\n",
            "        [ 0.0582,  0.6734, -1.0096],\n",
            "        [-1.7695,  1.9925, -0.7227],\n",
            "        [-1.3448,  2.0557, -0.2952],\n",
            "        [-0.2475,  0.9873, -1.0265],\n",
            "        [-1.7257,  0.6283,  0.9593],\n",
            "        [-1.5160,  2.0958, -0.6030],\n",
            "        [-1.6974,  2.0141, -0.5430],\n",
            "        [-1.5297,  1.8561, -0.5897],\n",
            "        [-1.6270,  1.9051, -0.4281],\n",
            "        [ 0.3101,  0.2424, -0.8375],\n",
            "        [-1.6247,  2.1146, -0.6298],\n",
            "        [-1.5481,  0.1260,  1.1617]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9076,  1.9435, -0.4114],\n",
            "        [-1.6627,  2.0398, -0.7955],\n",
            "        [-1.6634,  2.2645, -0.5654],\n",
            "        [-1.3159,  1.9568, -0.8007],\n",
            "        [ 0.0582,  0.6734, -1.0096],\n",
            "        [-1.7695,  1.9925, -0.7227],\n",
            "        [-1.3448,  2.0557, -0.2952],\n",
            "        [-0.2475,  0.9873, -1.0265],\n",
            "        [-1.7257,  0.6283,  0.9593],\n",
            "        [-1.5160,  2.0958, -0.6030],\n",
            "        [-1.6974,  2.0141, -0.5430],\n",
            "        [-1.5297,  1.8561, -0.5897],\n",
            "        [-1.6270,  1.9051, -0.4281],\n",
            "        [ 0.3101,  0.2424, -0.8375],\n",
            "        [-1.6247,  2.1146, -0.6298],\n",
            "        [-1.5481,  0.1260,  1.1617]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7307,  0.1253,  1.2508],\n",
            "        [-1.5947,  2.0215, -0.4498],\n",
            "        [-1.5863,  0.3703,  1.2194],\n",
            "        [-1.5590,  0.1473,  1.3219],\n",
            "        [-1.6012,  1.9353, -0.4563],\n",
            "        [ 0.3796,  0.1348, -0.9543],\n",
            "        [-1.5414,  0.1378,  0.8923],\n",
            "        [-1.7453,  1.9687, -0.6100],\n",
            "        [ 0.4415, -0.0477, -0.9116],\n",
            "        [-1.3327,  0.1059,  0.9296],\n",
            "        [-1.8142,  2.1961, -0.4565],\n",
            "        [-1.5767,  1.3757,  0.1179],\n",
            "        [-1.4900,  1.9936, -0.5401],\n",
            "        [-1.7545,  0.8928,  0.5924],\n",
            "        [-1.4762,  0.2997,  1.1875],\n",
            "        [-1.4209,  2.1333, -0.5005]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7307,  0.1253,  1.2508],\n",
            "        [-1.5947,  2.0215, -0.4498],\n",
            "        [-1.5863,  0.3703,  1.2194],\n",
            "        [-1.5590,  0.1473,  1.3219],\n",
            "        [-1.6012,  1.9353, -0.4563],\n",
            "        [ 0.3796,  0.1348, -0.9543],\n",
            "        [-1.5414,  0.1378,  0.8923],\n",
            "        [-1.7453,  1.9687, -0.6100],\n",
            "        [ 0.4415, -0.0477, -0.9116],\n",
            "        [-1.3327,  0.1059,  0.9296],\n",
            "        [-1.8142,  2.1961, -0.4565],\n",
            "        [-1.5767,  1.3757,  0.1179],\n",
            "        [-1.4900,  1.9936, -0.5401],\n",
            "        [-1.7545,  0.8928,  0.5924],\n",
            "        [-1.4762,  0.2997,  1.1875],\n",
            "        [-1.4209,  2.1333, -0.5005]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8332,  0.3511,  1.3822],\n",
            "        [-1.5541,  1.9061, -0.4221],\n",
            "        [-1.3373,  1.9666, -0.3987],\n",
            "        [-1.4998,  1.5656, -0.0593],\n",
            "        [-1.4586,  1.9508, -0.6267],\n",
            "        [-1.7434,  2.1379, -0.4103],\n",
            "        [ 0.5958, -0.0270, -0.8198],\n",
            "        [-1.6705,  1.8582, -0.6169],\n",
            "        [-1.6485,  1.3709,  0.3577],\n",
            "        [-1.5215,  2.0571, -0.7566],\n",
            "        [-1.0019,  0.1792,  0.8505],\n",
            "        [-1.7554,  1.9956, -0.2727],\n",
            "        [-1.9246,  1.9496, -0.1240],\n",
            "        [-1.0823,  1.6493, -0.9716],\n",
            "        [-1.6693,  0.3869,  1.0596],\n",
            "        [-1.4787,  2.1394, -0.6998]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8332,  0.3511,  1.3822],\n",
            "        [-1.5541,  1.9061, -0.4221],\n",
            "        [-1.3373,  1.9666, -0.3987],\n",
            "        [-1.4998,  1.5656, -0.0593],\n",
            "        [-1.4586,  1.9508, -0.6267],\n",
            "        [-1.7434,  2.1379, -0.4103],\n",
            "        [ 0.5958, -0.0270, -0.8198],\n",
            "        [-1.6705,  1.8582, -0.6169],\n",
            "        [-1.6485,  1.3709,  0.3577],\n",
            "        [-1.5215,  2.0571, -0.7566],\n",
            "        [-1.0019,  0.1792,  0.8505],\n",
            "        [-1.7554,  1.9956, -0.2727],\n",
            "        [-1.9246,  1.9496, -0.1240],\n",
            "        [-1.0823,  1.6493, -0.9716],\n",
            "        [-1.6693,  0.3869,  1.0596],\n",
            "        [-1.4787,  2.1394, -0.6998]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6614,  2.0562, -0.5259],\n",
            "        [ 0.3956, -0.0237, -0.8556],\n",
            "        [ 0.5006, -0.0052, -0.9478],\n",
            "        [-1.4442,  2.0449, -0.7562],\n",
            "        [-1.7427,  1.9222, -0.5191],\n",
            "        [-1.6649,  0.2110,  1.2069],\n",
            "        [-1.6223,  2.1472, -0.3781],\n",
            "        [-1.6895,  0.4824,  1.3191],\n",
            "        [-1.8603,  2.0387, -0.1372],\n",
            "        [-1.8556,  2.1060, -0.3136],\n",
            "        [-1.6384,  1.9662, -0.5038],\n",
            "        [-1.7325,  1.8890, -0.5069],\n",
            "        [-1.3270,  1.7068, -0.6694],\n",
            "        [-1.6570,  0.7528,  0.7536],\n",
            "        [-0.5801,  0.4565, -0.0532],\n",
            "        [-1.7355,  2.0345, -0.5429]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6614,  2.0562, -0.5259],\n",
            "        [ 0.3956, -0.0237, -0.8556],\n",
            "        [ 0.5006, -0.0052, -0.9478],\n",
            "        [-1.4442,  2.0449, -0.7562],\n",
            "        [-1.7427,  1.9222, -0.5191],\n",
            "        [-1.6649,  0.2110,  1.2069],\n",
            "        [-1.6223,  2.1472, -0.3781],\n",
            "        [-1.6895,  0.4824,  1.3191],\n",
            "        [-1.8603,  2.0387, -0.1372],\n",
            "        [-1.8556,  2.1060, -0.3136],\n",
            "        [-1.6384,  1.9662, -0.5038],\n",
            "        [-1.7325,  1.8890, -0.5069],\n",
            "        [-1.3270,  1.7068, -0.6694],\n",
            "        [-1.6570,  0.7528,  0.7536],\n",
            "        [-0.5801,  0.4565, -0.0532],\n",
            "        [-1.7355,  2.0345, -0.5429]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7705,  1.1449,  0.6890],\n",
            "        [-1.4835,  1.9739, -0.2355],\n",
            "        [-1.8668,  0.0754,  1.3514],\n",
            "        [-1.2743,  1.5267, -0.2662],\n",
            "        [-1.5754,  1.8011, -0.4968],\n",
            "        [-1.6361,  2.3602, -0.6656],\n",
            "        [-1.6379,  1.2929,  0.0470],\n",
            "        [-1.6786,  2.2319, -0.6267],\n",
            "        [-1.6823,  0.1384,  1.3622],\n",
            "        [-1.9048,  1.8657, -0.4649],\n",
            "        [-1.5941,  0.5088,  0.9850],\n",
            "        [-1.6444,  2.1990, -0.5127],\n",
            "        [-1.7394,  1.7428, -0.1104],\n",
            "        [-1.6055,  1.9518, -0.3847],\n",
            "        [-0.5914,  0.1151,  0.2187],\n",
            "        [-1.8129,  2.1793, -0.4090]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7705,  1.1449,  0.6890],\n",
            "        [-1.4835,  1.9739, -0.2355],\n",
            "        [-1.8668,  0.0754,  1.3514],\n",
            "        [-1.2743,  1.5267, -0.2662],\n",
            "        [-1.5754,  1.8011, -0.4968],\n",
            "        [-1.6361,  2.3602, -0.6656],\n",
            "        [-1.6379,  1.2929,  0.0470],\n",
            "        [-1.6786,  2.2319, -0.6267],\n",
            "        [-1.6823,  0.1384,  1.3622],\n",
            "        [-1.9048,  1.8657, -0.4649],\n",
            "        [-1.5941,  0.5088,  0.9850],\n",
            "        [-1.6444,  2.1990, -0.5127],\n",
            "        [-1.7394,  1.7428, -0.1104],\n",
            "        [-1.6055,  1.9518, -0.3847],\n",
            "        [-0.5914,  0.1151,  0.2187],\n",
            "        [-1.8129,  2.1793, -0.4090]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4778,  2.0819, -0.4722],\n",
            "        [-1.5266,  1.9775, -0.5446],\n",
            "        [-1.9716,  0.8743,  0.8611],\n",
            "        [-1.5595,  2.0351, -0.5766],\n",
            "        [-1.6878,  2.2156, -0.5854],\n",
            "        [-1.3773,  2.0433, -0.6264],\n",
            "        [-1.8681,  0.1422,  1.3255],\n",
            "        [ 0.5254, -0.0613, -0.8748],\n",
            "        [-1.7749,  2.0980, -0.5540],\n",
            "        [-1.6012,  0.1824,  1.2792],\n",
            "        [ 0.2622,  0.1147, -0.7708],\n",
            "        [-1.8573,  0.4497,  1.1385],\n",
            "        [-1.6212,  2.1378, -0.8758],\n",
            "        [-1.7843, -0.0031,  1.5358],\n",
            "        [-1.8321,  2.0488, -0.2711],\n",
            "        [ 0.3704,  0.0409, -0.8673]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4778,  2.0819, -0.4722],\n",
            "        [-1.5266,  1.9775, -0.5446],\n",
            "        [-1.9716,  0.8743,  0.8611],\n",
            "        [-1.5595,  2.0351, -0.5766],\n",
            "        [-1.6878,  2.2156, -0.5854],\n",
            "        [-1.3773,  2.0433, -0.6264],\n",
            "        [-1.8681,  0.1422,  1.3255],\n",
            "        [ 0.5254, -0.0613, -0.8748],\n",
            "        [-1.7749,  2.0980, -0.5540],\n",
            "        [-1.6012,  0.1824,  1.2792],\n",
            "        [ 0.2622,  0.1147, -0.7708],\n",
            "        [-1.8573,  0.4497,  1.1385],\n",
            "        [-1.6212,  2.1378, -0.8758],\n",
            "        [-1.7843, -0.0031,  1.5358],\n",
            "        [-1.8321,  2.0488, -0.2711],\n",
            "        [ 0.3704,  0.0409, -0.8673]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6231,  1.9852, -0.6181],\n",
            "        [-1.7993,  2.0818, -0.1544],\n",
            "        [-0.9035,  1.5219, -0.8779],\n",
            "        [-1.5718,  2.0574, -0.5419],\n",
            "        [-1.8853,  0.4694,  1.1745],\n",
            "        [-1.7238,  0.0634,  1.1843],\n",
            "        [-1.5875,  0.2973,  0.9024],\n",
            "        [-1.1523,  0.0870,  0.9664],\n",
            "        [-0.7490,  1.0780, -0.6804],\n",
            "        [-0.9207,  1.2856, -0.7141],\n",
            "        [-1.5991,  2.2241, -0.6105],\n",
            "        [-1.7433,  0.3347,  1.1302],\n",
            "        [-1.4086,  1.7253, -0.2969],\n",
            "        [-1.6867,  2.2905, -0.4666],\n",
            "        [-1.4992,  2.0364, -0.5715],\n",
            "        [-1.8562,  0.1279,  1.3397]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6231,  1.9852, -0.6181],\n",
            "        [-1.7993,  2.0818, -0.1544],\n",
            "        [-0.9035,  1.5219, -0.8779],\n",
            "        [-1.5718,  2.0574, -0.5419],\n",
            "        [-1.8853,  0.4694,  1.1745],\n",
            "        [-1.7238,  0.0634,  1.1843],\n",
            "        [-1.5875,  0.2973,  0.9024],\n",
            "        [-1.1523,  0.0870,  0.9664],\n",
            "        [-0.7490,  1.0780, -0.6804],\n",
            "        [-0.9207,  1.2856, -0.7141],\n",
            "        [-1.5991,  2.2241, -0.6105],\n",
            "        [-1.7433,  0.3347,  1.1302],\n",
            "        [-1.4086,  1.7253, -0.2969],\n",
            "        [-1.6867,  2.2905, -0.4666],\n",
            "        [-1.4992,  2.0364, -0.5715],\n",
            "        [-1.8562,  0.1279,  1.3397]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8165,  1.9379, -0.2983],\n",
            "        [-1.6862,  1.8563, -0.2461],\n",
            "        [-1.5634,  1.5595, -0.2269],\n",
            "        [-1.6806,  2.2781, -0.5167],\n",
            "        [-1.7580,  1.9326, -0.5052],\n",
            "        [ 0.2483,  0.0371, -0.9076],\n",
            "        [-1.8797,  2.2354, -0.2769],\n",
            "        [-1.6317,  1.7459, -0.2226],\n",
            "        [ 0.0654,  0.4249, -0.9411],\n",
            "        [-1.8538,  2.1374, -0.2678],\n",
            "        [-1.7397,  1.3553,  0.2856],\n",
            "        [ 0.3711, -0.1829, -0.7678],\n",
            "        [-1.7877,  1.5737,  0.2891],\n",
            "        [-1.3224,  1.3039, -0.1489],\n",
            "        [ 0.3084,  0.0259, -0.7640],\n",
            "        [-1.3741,  0.0237,  1.2784]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8165,  1.9379, -0.2983],\n",
            "        [-1.6862,  1.8563, -0.2461],\n",
            "        [-1.5634,  1.5595, -0.2269],\n",
            "        [-1.6806,  2.2781, -0.5167],\n",
            "        [-1.7580,  1.9326, -0.5052],\n",
            "        [ 0.2483,  0.0371, -0.9076],\n",
            "        [-1.8797,  2.2354, -0.2769],\n",
            "        [-1.6317,  1.7459, -0.2226],\n",
            "        [ 0.0654,  0.4249, -0.9411],\n",
            "        [-1.8538,  2.1374, -0.2678],\n",
            "        [-1.7397,  1.3553,  0.2856],\n",
            "        [ 0.3711, -0.1829, -0.7678],\n",
            "        [-1.7877,  1.5737,  0.2891],\n",
            "        [-1.3224,  1.3039, -0.1489],\n",
            "        [ 0.3084,  0.0259, -0.7640],\n",
            "        [-1.3741,  0.0237,  1.2784]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5531,  0.0280,  1.5801],\n",
            "        [ 0.3313,  0.0811, -0.8746],\n",
            "        [-1.8371,  1.9144, -0.5603],\n",
            "        [-1.0661,  1.3080, -0.6739],\n",
            "        [ 0.4588,  0.0310, -0.8608],\n",
            "        [ 0.3308, -0.1145, -0.7887],\n",
            "        [-1.6034,  1.8673, -0.4659],\n",
            "        [ 0.4352,  0.0089, -0.8894],\n",
            "        [-1.6911,  0.3739,  0.9754],\n",
            "        [-1.7405,  2.1642, -0.3712],\n",
            "        [-1.7163,  1.3134,  0.0237],\n",
            "        [-1.8297,  1.8668, -0.0499],\n",
            "        [-1.7949,  2.1510, -0.4506],\n",
            "        [-1.5289,  0.4267,  1.1432],\n",
            "        [-1.6205,  0.1166,  1.4220],\n",
            "        [-1.6280,  0.0895,  1.3533]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5531,  0.0280,  1.5801],\n",
            "        [ 0.3313,  0.0811, -0.8746],\n",
            "        [-1.8371,  1.9144, -0.5603],\n",
            "        [-1.0661,  1.3080, -0.6739],\n",
            "        [ 0.4588,  0.0310, -0.8608],\n",
            "        [ 0.3308, -0.1145, -0.7887],\n",
            "        [-1.6034,  1.8673, -0.4659],\n",
            "        [ 0.4352,  0.0089, -0.8894],\n",
            "        [-1.6911,  0.3739,  0.9754],\n",
            "        [-1.7405,  2.1642, -0.3712],\n",
            "        [-1.7163,  1.3134,  0.0237],\n",
            "        [-1.8297,  1.8668, -0.0499],\n",
            "        [-1.7949,  2.1510, -0.4506],\n",
            "        [-1.5289,  0.4267,  1.1432],\n",
            "        [-1.6205,  0.1166,  1.4220],\n",
            "        [-1.6280,  0.0895,  1.3533]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8038,  0.0813,  1.3856],\n",
            "        [-1.9471,  1.3156,  0.0795],\n",
            "        [-1.6725,  1.9204, -0.3756],\n",
            "        [-1.5898,  1.1930,  0.2293],\n",
            "        [-1.5674,  1.8475, -0.4882],\n",
            "        [-1.6163,  1.8869, -0.6319],\n",
            "        [-1.7730, -0.0627,  1.6469],\n",
            "        [-1.6866,  1.6996, -0.1548],\n",
            "        [-0.3131,  0.7519, -0.8307],\n",
            "        [-2.0407,  1.8807, -0.2765],\n",
            "        [-1.4494,  1.4902, -0.1957],\n",
            "        [-1.9152,  1.0644,  0.6990],\n",
            "        [-1.6360,  2.0106, -0.6467],\n",
            "        [-1.5315,  1.8011, -0.5887],\n",
            "        [-1.6414,  2.0343, -0.3175],\n",
            "        [-1.5573,  1.9806, -0.3286]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8038,  0.0813,  1.3856],\n",
            "        [-1.9471,  1.3156,  0.0795],\n",
            "        [-1.6725,  1.9204, -0.3756],\n",
            "        [-1.5898,  1.1930,  0.2293],\n",
            "        [-1.5674,  1.8475, -0.4882],\n",
            "        [-1.6163,  1.8869, -0.6319],\n",
            "        [-1.7730, -0.0627,  1.6469],\n",
            "        [-1.6866,  1.6996, -0.1548],\n",
            "        [-0.3131,  0.7519, -0.8307],\n",
            "        [-2.0407,  1.8807, -0.2765],\n",
            "        [-1.4494,  1.4902, -0.1957],\n",
            "        [-1.9152,  1.0644,  0.6990],\n",
            "        [-1.6360,  2.0106, -0.6467],\n",
            "        [-1.5315,  1.8011, -0.5887],\n",
            "        [-1.6414,  2.0343, -0.3175],\n",
            "        [-1.5573,  1.9806, -0.3286]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7215,  0.1154,  1.2276],\n",
            "        [-1.8117,  0.1755,  1.4723],\n",
            "        [-1.8328,  2.1312, -0.5187],\n",
            "        [-1.7385,  0.0921,  1.2811],\n",
            "        [ 0.3868, -0.0609, -0.7752],\n",
            "        [-1.5911,  1.8627, -0.5657],\n",
            "        [-1.7673,  0.5423,  1.0181],\n",
            "        [-1.7558,  0.1873,  1.2828],\n",
            "        [-0.6991,  0.2095,  0.0485],\n",
            "        [-1.9910,  1.6843,  0.1490],\n",
            "        [-0.1483,  0.4771, -1.0562],\n",
            "        [-2.0958,  0.5673,  1.1248],\n",
            "        [-1.7485, -0.0165,  1.5759],\n",
            "        [-1.9374,  0.1526,  1.4211],\n",
            "        [-1.7753,  1.8162, -0.4234],\n",
            "        [ 0.3999,  0.0610, -0.9096]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7215,  0.1154,  1.2276],\n",
            "        [-1.8117,  0.1755,  1.4723],\n",
            "        [-1.8328,  2.1312, -0.5187],\n",
            "        [-1.7385,  0.0921,  1.2811],\n",
            "        [ 0.3868, -0.0609, -0.7752],\n",
            "        [-1.5911,  1.8627, -0.5657],\n",
            "        [-1.7673,  0.5423,  1.0181],\n",
            "        [-1.7558,  0.1873,  1.2828],\n",
            "        [-0.6991,  0.2095,  0.0485],\n",
            "        [-1.9910,  1.6843,  0.1490],\n",
            "        [-0.1483,  0.4771, -1.0562],\n",
            "        [-2.0958,  0.5673,  1.1248],\n",
            "        [-1.7485, -0.0165,  1.5759],\n",
            "        [-1.9374,  0.1526,  1.4211],\n",
            "        [-1.7753,  1.8162, -0.4234],\n",
            "        [ 0.3999,  0.0610, -0.9096]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6785,  1.8300, -0.3898],\n",
            "        [-1.6730,  0.9391,  0.2842],\n",
            "        [-1.7387,  1.9310, -0.1856],\n",
            "        [-1.4798,  0.1689,  1.1534],\n",
            "        [-1.4892,  0.2604,  1.0486],\n",
            "        [-1.7267,  0.1707,  1.1931],\n",
            "        [-1.5666,  0.3413,  0.8821],\n",
            "        [-0.1647,  0.4552, -0.4586],\n",
            "        [-1.7994,  2.0155, -0.3464],\n",
            "        [-1.7427,  0.1785,  1.4520],\n",
            "        [-1.5818,  0.4846,  1.0847],\n",
            "        [-1.5879,  1.8821, -0.6391],\n",
            "        [-1.7782,  1.7537, -0.3864],\n",
            "        [-1.4428,  1.7457, -0.3065],\n",
            "        [-1.7338,  0.7130,  0.9999],\n",
            "        [-1.7036,  0.1703,  1.4775]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6785,  1.8300, -0.3898],\n",
            "        [-1.6730,  0.9391,  0.2842],\n",
            "        [-1.7387,  1.9310, -0.1856],\n",
            "        [-1.4798,  0.1689,  1.1534],\n",
            "        [-1.4892,  0.2604,  1.0486],\n",
            "        [-1.7267,  0.1707,  1.1931],\n",
            "        [-1.5666,  0.3413,  0.8821],\n",
            "        [-0.1647,  0.4552, -0.4586],\n",
            "        [-1.7994,  2.0155, -0.3464],\n",
            "        [-1.7427,  0.1785,  1.4520],\n",
            "        [-1.5818,  0.4846,  1.0847],\n",
            "        [-1.5879,  1.8821, -0.6391],\n",
            "        [-1.7782,  1.7537, -0.3864],\n",
            "        [-1.4428,  1.7457, -0.3065],\n",
            "        [-1.7338,  0.7130,  0.9999],\n",
            "        [-1.7036,  0.1703,  1.4775]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5135, -0.0867, -0.7853],\n",
            "        [-1.5212,  0.1740,  1.2492],\n",
            "        [ 0.4265,  0.0533, -0.9036],\n",
            "        [-1.7702,  1.0527,  0.7025],\n",
            "        [ 0.2807,  0.0292, -0.8393],\n",
            "        [-1.1542,  1.6368, -0.6917],\n",
            "        [ 0.0932,  0.1093, -0.8177],\n",
            "        [-1.8436,  0.1083,  1.3519],\n",
            "        [-1.5286,  1.7779, -0.5410],\n",
            "        [ 0.0959,  0.3445, -0.8596],\n",
            "        [-1.4119,  0.1555,  0.9834],\n",
            "        [-1.5482,  1.9907, -0.5045],\n",
            "        [-1.6901,  2.0649, -0.2534],\n",
            "        [-1.7320,  0.4279,  1.3182],\n",
            "        [-1.2351,  1.3801, -0.3586],\n",
            "        [-1.8307,  2.0323,  0.0110]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.5135, -0.0867, -0.7853],\n",
            "        [-1.5212,  0.1740,  1.2492],\n",
            "        [ 0.4265,  0.0533, -0.9036],\n",
            "        [-1.7702,  1.0527,  0.7025],\n",
            "        [ 0.2807,  0.0292, -0.8393],\n",
            "        [-1.1542,  1.6368, -0.6917],\n",
            "        [ 0.0932,  0.1093, -0.8177],\n",
            "        [-1.8436,  0.1083,  1.3519],\n",
            "        [-1.5286,  1.7779, -0.5410],\n",
            "        [ 0.0959,  0.3445, -0.8596],\n",
            "        [-1.4119,  0.1555,  0.9834],\n",
            "        [-1.5482,  1.9907, -0.5045],\n",
            "        [-1.6901,  2.0649, -0.2534],\n",
            "        [-1.7320,  0.4279,  1.3182],\n",
            "        [-1.2351,  1.3801, -0.3586],\n",
            "        [-1.8307,  2.0323,  0.0110]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7528,  2.3253, -0.3889],\n",
            "        [-1.5948,  2.0545, -0.3673],\n",
            "        [-1.5822,  1.5039, -0.2184],\n",
            "        [-1.7257,  1.8429, -0.3761],\n",
            "        [-1.8827,  1.0843,  0.3897],\n",
            "        [-1.7372,  2.0746, -0.3372],\n",
            "        [-1.4254,  1.6297, -0.2598],\n",
            "        [-1.9322,  0.2775,  1.3032],\n",
            "        [-1.6476,  0.5322,  1.0265],\n",
            "        [-1.2642,  1.6668, -0.2271],\n",
            "        [-1.7491,  2.1344, -0.3920],\n",
            "        [ 0.3172,  0.0484, -0.9910],\n",
            "        [-1.5407,  1.7757, -0.4294],\n",
            "        [-1.5503,  1.8033, -0.3218],\n",
            "        [-1.6855,  0.2679,  0.8705],\n",
            "        [-1.6151,  1.8466, -0.1601]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7528,  2.3253, -0.3889],\n",
            "        [-1.5948,  2.0545, -0.3673],\n",
            "        [-1.5822,  1.5039, -0.2184],\n",
            "        [-1.7257,  1.8429, -0.3761],\n",
            "        [-1.8827,  1.0843,  0.3897],\n",
            "        [-1.7372,  2.0746, -0.3372],\n",
            "        [-1.4254,  1.6297, -0.2598],\n",
            "        [-1.9322,  0.2775,  1.3032],\n",
            "        [-1.6476,  0.5322,  1.0265],\n",
            "        [-1.2642,  1.6668, -0.2271],\n",
            "        [-1.7491,  2.1344, -0.3920],\n",
            "        [ 0.3172,  0.0484, -0.9910],\n",
            "        [-1.5407,  1.7757, -0.4294],\n",
            "        [-1.5503,  1.8033, -0.3218],\n",
            "        [-1.6855,  0.2679,  0.8705],\n",
            "        [-1.6151,  1.8466, -0.1601]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3560,  0.4169,  0.7598],\n",
            "        [-1.8547,  1.5746,  0.0070],\n",
            "        [ 0.3053, -0.0191, -0.8235],\n",
            "        [-1.8260,  1.5312,  0.1719],\n",
            "        [ 0.3599,  0.1906, -1.0369],\n",
            "        [-1.7749,  1.3755,  0.2660],\n",
            "        [-1.4491,  1.6800, -0.2775],\n",
            "        [-1.8090,  0.5893,  0.8840],\n",
            "        [-1.8489,  0.2449,  1.3796],\n",
            "        [-1.8225,  1.7227, -0.1518],\n",
            "        [-1.8761,  0.7131,  0.7318],\n",
            "        [-1.8668,  0.2839,  1.3686],\n",
            "        [-1.7413,  0.5722,  0.9698],\n",
            "        [-1.6447,  1.6591, -0.2289],\n",
            "        [-1.9147,  0.5275,  1.0227],\n",
            "        [-1.8770,  0.3154,  1.1180]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3560,  0.4169,  0.7598],\n",
            "        [-1.8547,  1.5746,  0.0070],\n",
            "        [ 0.3053, -0.0191, -0.8235],\n",
            "        [-1.8260,  1.5312,  0.1719],\n",
            "        [ 0.3599,  0.1906, -1.0369],\n",
            "        [-1.7749,  1.3755,  0.2660],\n",
            "        [-1.4491,  1.6800, -0.2775],\n",
            "        [-1.8090,  0.5893,  0.8840],\n",
            "        [-1.8489,  0.2449,  1.3796],\n",
            "        [-1.8225,  1.7227, -0.1518],\n",
            "        [-1.8761,  0.7131,  0.7318],\n",
            "        [-1.8668,  0.2839,  1.3686],\n",
            "        [-1.7413,  0.5722,  0.9698],\n",
            "        [-1.6447,  1.6591, -0.2289],\n",
            "        [-1.9147,  0.5275,  1.0227],\n",
            "        [-1.8770,  0.3154,  1.1180]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6216,  2.0025, -0.4473],\n",
            "        [-1.5779,  1.4179,  0.4098],\n",
            "        [-1.5404,  1.5688, -0.1254],\n",
            "        [-1.7568,  1.8291, -0.1805],\n",
            "        [-1.6424,  1.3468,  0.1876],\n",
            "        [-1.5338,  1.4296, -0.2464],\n",
            "        [-0.0750,  0.1328, -0.4534],\n",
            "        [-1.4319,  0.6557,  0.3923],\n",
            "        [-1.5635,  1.7846, -0.2881],\n",
            "        [-1.4860,  1.4732, -0.6114],\n",
            "        [-1.5903,  1.8333, -0.4387],\n",
            "        [-1.7279,  1.6331, -0.2545],\n",
            "        [-1.5347,  1.4264, -0.4136],\n",
            "        [-1.7285,  2.0700, -0.4807],\n",
            "        [-1.7399,  1.2571,  0.4065],\n",
            "        [-1.8158,  1.7144, -0.0337]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6216,  2.0025, -0.4473],\n",
            "        [-1.5779,  1.4179,  0.4098],\n",
            "        [-1.5404,  1.5688, -0.1254],\n",
            "        [-1.7568,  1.8291, -0.1805],\n",
            "        [-1.6424,  1.3468,  0.1876],\n",
            "        [-1.5338,  1.4296, -0.2464],\n",
            "        [-0.0750,  0.1328, -0.4534],\n",
            "        [-1.4319,  0.6557,  0.3923],\n",
            "        [-1.5635,  1.7846, -0.2881],\n",
            "        [-1.4860,  1.4732, -0.6114],\n",
            "        [-1.5903,  1.8333, -0.4387],\n",
            "        [-1.7279,  1.6331, -0.2545],\n",
            "        [-1.5347,  1.4264, -0.4136],\n",
            "        [-1.7285,  2.0700, -0.4807],\n",
            "        [-1.7399,  1.2571,  0.4065],\n",
            "        [-1.8158,  1.7144, -0.0337]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0398,  0.3001,  1.2541],\n",
            "        [-1.7143,  1.3656,  0.1760],\n",
            "        [-1.6329,  0.3483,  1.2202],\n",
            "        [-1.6108,  1.6276, -0.1950],\n",
            "        [-0.0337,  0.2247, -0.6293],\n",
            "        [-1.7803,  0.5360,  1.0290],\n",
            "        [-1.7775,  0.1686,  1.2746],\n",
            "        [ 0.3204,  0.0145, -0.8777],\n",
            "        [-1.7806,  0.2844,  1.3206],\n",
            "        [-1.5339,  0.2799,  0.9405],\n",
            "        [-1.7330,  0.8943,  0.7269],\n",
            "        [-1.6384,  1.9887, -0.5086],\n",
            "        [-1.5453,  1.5151,  0.1041],\n",
            "        [ 0.5060, -0.0036, -0.9114],\n",
            "        [-1.5847,  0.7607,  0.5514],\n",
            "        [-1.4916,  0.7366,  0.6498]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0398,  0.3001,  1.2541],\n",
            "        [-1.7143,  1.3656,  0.1760],\n",
            "        [-1.6329,  0.3483,  1.2202],\n",
            "        [-1.6108,  1.6276, -0.1950],\n",
            "        [-0.0337,  0.2247, -0.6293],\n",
            "        [-1.7803,  0.5360,  1.0290],\n",
            "        [-1.7775,  0.1686,  1.2746],\n",
            "        [ 0.3204,  0.0145, -0.8777],\n",
            "        [-1.7806,  0.2844,  1.3206],\n",
            "        [-1.5339,  0.2799,  0.9405],\n",
            "        [-1.7330,  0.8943,  0.7269],\n",
            "        [-1.6384,  1.9887, -0.5086],\n",
            "        [-1.5453,  1.5151,  0.1041],\n",
            "        [ 0.5060, -0.0036, -0.9114],\n",
            "        [-1.5847,  0.7607,  0.5514],\n",
            "        [-1.4916,  0.7366,  0.6498]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3484,  1.6612, -0.2012],\n",
            "        [-1.3590,  1.3463, -0.3381],\n",
            "        [-1.6944,  1.9550, -0.3265],\n",
            "        [-1.1085,  1.4230, -0.2188],\n",
            "        [-1.5410,  0.4343,  1.1843],\n",
            "        [-1.2968,  1.5355, -0.2323],\n",
            "        [-1.6142,  0.5668,  0.9189],\n",
            "        [-1.3631,  1.4867, -0.4254],\n",
            "        [-1.4464,  1.6049, -0.3215],\n",
            "        [-1.6842,  1.2435,  0.4330],\n",
            "        [-1.0063,  0.2430,  0.5760],\n",
            "        [-1.2824,  1.1354,  0.1934],\n",
            "        [-1.5405,  0.3998,  1.2256],\n",
            "        [-1.7894,  0.9230,  0.8541],\n",
            "        [-1.5993,  1.6245, -0.3999],\n",
            "        [-1.5698,  1.7296, -0.4847]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3484,  1.6612, -0.2012],\n",
            "        [-1.3590,  1.3463, -0.3381],\n",
            "        [-1.6944,  1.9550, -0.3265],\n",
            "        [-1.1085,  1.4230, -0.2188],\n",
            "        [-1.5410,  0.4343,  1.1843],\n",
            "        [-1.2968,  1.5355, -0.2323],\n",
            "        [-1.6142,  0.5668,  0.9189],\n",
            "        [-1.3631,  1.4867, -0.4254],\n",
            "        [-1.4464,  1.6049, -0.3215],\n",
            "        [-1.6842,  1.2435,  0.4330],\n",
            "        [-1.0063,  0.2430,  0.5760],\n",
            "        [-1.2824,  1.1354,  0.1934],\n",
            "        [-1.5405,  0.3998,  1.2256],\n",
            "        [-1.7894,  0.9230,  0.8541],\n",
            "        [-1.5993,  1.6245, -0.3999],\n",
            "        [-1.5698,  1.7296, -0.4847]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5404,  1.2911,  0.2657],\n",
            "        [-1.6634,  1.3832, -0.0151],\n",
            "        [-1.6807,  0.3331,  1.4464],\n",
            "        [-1.4366,  1.4557, -0.0678],\n",
            "        [-1.6640,  1.7412, -0.1513],\n",
            "        [-1.7146,  0.4627,  1.1327],\n",
            "        [ 0.4328,  0.0463, -0.8151],\n",
            "        [-1.6821,  0.4517,  1.2687],\n",
            "        [-1.5330,  1.6420, -0.3794],\n",
            "        [-1.3730,  1.6970, -0.2895],\n",
            "        [-1.7421,  1.3456,  0.2881],\n",
            "        [ 0.3828, -0.0854, -0.8514],\n",
            "        [-1.5238,  0.3972,  1.0052],\n",
            "        [-1.7835,  0.0450,  1.5090],\n",
            "        [-1.6658,  1.7366, -0.0931],\n",
            "        [ 0.5685, -0.0904, -0.9773]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5404,  1.2911,  0.2657],\n",
            "        [-1.6634,  1.3832, -0.0151],\n",
            "        [-1.6807,  0.3331,  1.4464],\n",
            "        [-1.4366,  1.4557, -0.0678],\n",
            "        [-1.6640,  1.7412, -0.1513],\n",
            "        [-1.7146,  0.4627,  1.1327],\n",
            "        [ 0.4328,  0.0463, -0.8151],\n",
            "        [-1.6821,  0.4517,  1.2687],\n",
            "        [-1.5330,  1.6420, -0.3794],\n",
            "        [-1.3730,  1.6970, -0.2895],\n",
            "        [-1.7421,  1.3456,  0.2881],\n",
            "        [ 0.3828, -0.0854, -0.8514],\n",
            "        [-1.5238,  0.3972,  1.0052],\n",
            "        [-1.7835,  0.0450,  1.5090],\n",
            "        [-1.6658,  1.7366, -0.0931],\n",
            "        [ 0.5685, -0.0904, -0.9773]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5678,  0.9803,  0.5526],\n",
            "        [-1.5543,  0.3601,  1.0068],\n",
            "        [-1.8271,  0.3953,  1.3172],\n",
            "        [-1.6590,  0.3317,  1.2503],\n",
            "        [-1.7297,  0.3315,  1.0901],\n",
            "        [-0.2103,  0.2499, -0.4258],\n",
            "        [-1.2643,  1.1617,  0.0726],\n",
            "        [-1.2886,  0.1929,  0.9455],\n",
            "        [-1.1165,  1.2657, -0.1632],\n",
            "        [ 0.2384, -0.0324, -0.7331],\n",
            "        [-1.3037,  1.7127, -0.4807],\n",
            "        [-1.6162,  0.3092,  1.2642],\n",
            "        [ 0.4682,  0.0293, -0.9325],\n",
            "        [-1.6073,  1.7675, -0.3053],\n",
            "        [-1.1146,  1.0936, -0.1436],\n",
            "        [-1.6584,  1.8174, -0.3683]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5678,  0.9803,  0.5526],\n",
            "        [-1.5543,  0.3601,  1.0068],\n",
            "        [-1.8271,  0.3953,  1.3172],\n",
            "        [-1.6590,  0.3317,  1.2503],\n",
            "        [-1.7297,  0.3315,  1.0901],\n",
            "        [-0.2103,  0.2499, -0.4258],\n",
            "        [-1.2643,  1.1617,  0.0726],\n",
            "        [-1.2886,  0.1929,  0.9455],\n",
            "        [-1.1165,  1.2657, -0.1632],\n",
            "        [ 0.2384, -0.0324, -0.7331],\n",
            "        [-1.3037,  1.7127, -0.4807],\n",
            "        [-1.6162,  0.3092,  1.2642],\n",
            "        [ 0.4682,  0.0293, -0.9325],\n",
            "        [-1.6073,  1.7675, -0.3053],\n",
            "        [-1.1146,  1.0936, -0.1436],\n",
            "        [-1.6584,  1.8174, -0.3683]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7946,  0.2559,  1.3670],\n",
            "        [-1.8000,  0.5514,  1.1080],\n",
            "        [-1.6273,  1.5158, -0.0291],\n",
            "        [-0.8791,  1.3153, -0.4964],\n",
            "        [-1.6585,  1.3187,  0.3293],\n",
            "        [ 0.3095, -0.0254, -0.7457],\n",
            "        [-1.0819,  1.2903, -0.6478],\n",
            "        [-1.2781,  1.3809, -0.2024],\n",
            "        [-1.4177,  1.2832,  0.0943],\n",
            "        [-1.5405,  1.8144, -0.0929],\n",
            "        [-1.1247,  1.7136, -0.4958],\n",
            "        [ 0.2389, -0.0543, -0.8812],\n",
            "        [-1.4221,  1.5635, -0.3735],\n",
            "        [-1.4993,  1.2963,  0.0827],\n",
            "        [-1.5022,  1.6658, -0.3343],\n",
            "        [-1.2859,  1.6789, -0.3882]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7946,  0.2559,  1.3670],\n",
            "        [-1.8000,  0.5514,  1.1080],\n",
            "        [-1.6273,  1.5158, -0.0291],\n",
            "        [-0.8791,  1.3153, -0.4964],\n",
            "        [-1.6585,  1.3187,  0.3293],\n",
            "        [ 0.3095, -0.0254, -0.7457],\n",
            "        [-1.0819,  1.2903, -0.6478],\n",
            "        [-1.2781,  1.3809, -0.2024],\n",
            "        [-1.4177,  1.2832,  0.0943],\n",
            "        [-1.5405,  1.8144, -0.0929],\n",
            "        [-1.1247,  1.7136, -0.4958],\n",
            "        [ 0.2389, -0.0543, -0.8812],\n",
            "        [-1.4221,  1.5635, -0.3735],\n",
            "        [-1.4993,  1.2963,  0.0827],\n",
            "        [-1.5022,  1.6658, -0.3343],\n",
            "        [-1.2859,  1.6789, -0.3882]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2841,  1.6231, -0.3944],\n",
            "        [-1.4476,  0.7786,  0.5027],\n",
            "        [ 0.3933,  0.0125, -0.9762],\n",
            "        [-1.1080,  1.1599, -0.0070],\n",
            "        [-1.3838,  1.4142, -0.2665],\n",
            "        [-1.7545,  1.1259,  0.6280],\n",
            "        [-1.8741,  0.2736,  1.0869],\n",
            "        [-1.8300,  0.2413,  1.2261],\n",
            "        [-1.1837,  1.2744, -0.0191],\n",
            "        [-1.7308,  0.5675,  0.8626],\n",
            "        [-1.3494,  1.5638, -0.3730],\n",
            "        [-1.6285,  1.9489, -0.3425],\n",
            "        [-1.4272,  1.5679, -0.3009],\n",
            "        [-1.6063,  1.0609,  0.2468],\n",
            "        [ 0.2895, -0.0106, -0.6078],\n",
            "        [-1.4406,  1.6562, -0.2632]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2841,  1.6231, -0.3944],\n",
            "        [-1.4476,  0.7786,  0.5027],\n",
            "        [ 0.3933,  0.0125, -0.9762],\n",
            "        [-1.1080,  1.1599, -0.0070],\n",
            "        [-1.3838,  1.4142, -0.2665],\n",
            "        [-1.7545,  1.1259,  0.6280],\n",
            "        [-1.8741,  0.2736,  1.0869],\n",
            "        [-1.8300,  0.2413,  1.2261],\n",
            "        [-1.1837,  1.2744, -0.0191],\n",
            "        [-1.7308,  0.5675,  0.8626],\n",
            "        [-1.3494,  1.5638, -0.3730],\n",
            "        [-1.6285,  1.9489, -0.3425],\n",
            "        [-1.4272,  1.5679, -0.3009],\n",
            "        [-1.6063,  1.0609,  0.2468],\n",
            "        [ 0.2895, -0.0106, -0.6078],\n",
            "        [-1.4406,  1.6562, -0.2632]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7280,  1.3306,  0.0735],\n",
            "        [-1.4840,  1.5231, -0.6480],\n",
            "        [-1.5036,  1.7581, -0.2875],\n",
            "        [-1.1057,  0.3946,  0.7229],\n",
            "        [-1.3890,  1.3445, -0.0940],\n",
            "        [-1.4073,  1.4188, -0.1757],\n",
            "        [-1.3845,  1.5869, -0.3884],\n",
            "        [-1.5288,  1.3789,  0.1498],\n",
            "        [-1.7167,  0.6404,  1.2116],\n",
            "        [-1.3184,  1.4989, -0.3598],\n",
            "        [-1.7373,  0.9894,  0.6373],\n",
            "        [-1.6881,  0.4272,  1.3612],\n",
            "        [-1.2860,  0.3855,  1.0457],\n",
            "        [ 0.6227, -0.2985, -0.8861],\n",
            "        [ 0.4428, -0.1150, -0.8444],\n",
            "        [-1.7453,  1.8486, -0.2399]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7280,  1.3306,  0.0735],\n",
            "        [-1.4840,  1.5231, -0.6480],\n",
            "        [-1.5036,  1.7581, -0.2875],\n",
            "        [-1.1057,  0.3946,  0.7229],\n",
            "        [-1.3890,  1.3445, -0.0940],\n",
            "        [-1.4073,  1.4188, -0.1757],\n",
            "        [-1.3845,  1.5869, -0.3884],\n",
            "        [-1.5288,  1.3789,  0.1498],\n",
            "        [-1.7167,  0.6404,  1.2116],\n",
            "        [-1.3184,  1.4989, -0.3598],\n",
            "        [-1.7373,  0.9894,  0.6373],\n",
            "        [-1.6881,  0.4272,  1.3612],\n",
            "        [-1.2860,  0.3855,  1.0457],\n",
            "        [ 0.6227, -0.2985, -0.8861],\n",
            "        [ 0.4428, -0.1150, -0.8444],\n",
            "        [-1.7453,  1.8486, -0.2399]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3175,  0.0813, -0.9399],\n",
            "        [-1.4005,  1.5641, -0.3190],\n",
            "        [-1.5563,  0.3798,  1.0969],\n",
            "        [-1.6942,  0.7149,  0.6844],\n",
            "        [-1.5259,  0.2764,  1.1063],\n",
            "        [-1.0445,  0.3596,  0.2736],\n",
            "        [-1.2899,  1.6025, -0.2483],\n",
            "        [-1.5251,  0.3118,  1.0749],\n",
            "        [ 0.3540,  0.0032, -0.7585],\n",
            "        [ 0.6093,  0.1106, -0.8815],\n",
            "        [-1.7026,  1.0586,  0.4393],\n",
            "        [ 0.3769, -0.1272, -0.7465],\n",
            "        [-1.3920,  1.8465, -0.4877],\n",
            "        [-1.5640,  1.4783, -0.1551],\n",
            "        [-1.2717,  1.3820, -0.3332],\n",
            "        [-0.4176,  0.1928, -0.0421]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.3175,  0.0813, -0.9399],\n",
            "        [-1.4005,  1.5641, -0.3190],\n",
            "        [-1.5563,  0.3798,  1.0969],\n",
            "        [-1.6942,  0.7149,  0.6844],\n",
            "        [-1.5259,  0.2764,  1.1063],\n",
            "        [-1.0445,  0.3596,  0.2736],\n",
            "        [-1.2899,  1.6025, -0.2483],\n",
            "        [-1.5251,  0.3118,  1.0749],\n",
            "        [ 0.3540,  0.0032, -0.7585],\n",
            "        [ 0.6093,  0.1106, -0.8815],\n",
            "        [-1.7026,  1.0586,  0.4393],\n",
            "        [ 0.3769, -0.1272, -0.7465],\n",
            "        [-1.3920,  1.8465, -0.4877],\n",
            "        [-1.5640,  1.4783, -0.1551],\n",
            "        [-1.2717,  1.3820, -0.3332],\n",
            "        [-0.4176,  0.1928, -0.0421]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8202,  0.4728,  1.1181],\n",
            "        [-1.2459,  1.1139, -0.0738],\n",
            "        [-1.4667,  1.6009, -0.1728],\n",
            "        [-1.4920,  1.3921, -0.3580],\n",
            "        [-1.4094,  1.2686,  0.1735],\n",
            "        [-1.3314,  1.5682, -0.3023],\n",
            "        [-1.5989,  0.2820,  1.1612],\n",
            "        [-1.4261,  1.1915, -0.0104],\n",
            "        [-1.6198,  1.9932, -0.2268],\n",
            "        [-1.4038,  1.8064, -0.4323],\n",
            "        [-1.3506,  1.7825, -0.5272],\n",
            "        [-1.5472,  1.5917, -0.3323],\n",
            "        [-1.3518,  1.3700, -0.2502],\n",
            "        [-1.3879,  1.6518, -0.3355],\n",
            "        [-1.4443,  1.0853,  0.2282],\n",
            "        [-1.7727,  0.2124,  1.4873]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8202,  0.4728,  1.1181],\n",
            "        [-1.2459,  1.1139, -0.0738],\n",
            "        [-1.4667,  1.6009, -0.1728],\n",
            "        [-1.4920,  1.3921, -0.3580],\n",
            "        [-1.4094,  1.2686,  0.1735],\n",
            "        [-1.3314,  1.5682, -0.3023],\n",
            "        [-1.5989,  0.2820,  1.1612],\n",
            "        [-1.4261,  1.1915, -0.0104],\n",
            "        [-1.6198,  1.9932, -0.2268],\n",
            "        [-1.4038,  1.8064, -0.4323],\n",
            "        [-1.3506,  1.7825, -0.5272],\n",
            "        [-1.5472,  1.5917, -0.3323],\n",
            "        [-1.3518,  1.3700, -0.2502],\n",
            "        [-1.3879,  1.6518, -0.3355],\n",
            "        [-1.4443,  1.0853,  0.2282],\n",
            "        [-1.7727,  0.2124,  1.4873]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3983,  1.0189,  0.5649],\n",
            "        [-1.5488,  0.2975,  1.1005],\n",
            "        [-1.3811,  0.5272,  0.9292],\n",
            "        [ 0.6493, -0.0979, -0.8506],\n",
            "        [-1.5309,  0.6216,  0.8855],\n",
            "        [-1.5358,  1.4149,  0.0256],\n",
            "        [-1.5656,  0.5185,  0.9502],\n",
            "        [-0.5625,  0.2130,  0.1710],\n",
            "        [-1.5614,  1.7345, -0.4025],\n",
            "        [-1.4673,  1.5750, -0.4954],\n",
            "        [-1.2687,  0.8806,  0.4185],\n",
            "        [-1.4608,  0.4204,  1.0550],\n",
            "        [-1.5174,  0.3836,  1.0466],\n",
            "        [-1.6453,  1.9511, -0.3074],\n",
            "        [-1.5970,  0.8497,  0.6311],\n",
            "        [-1.7026,  0.3650,  1.3363]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3983,  1.0189,  0.5649],\n",
            "        [-1.5488,  0.2975,  1.1005],\n",
            "        [-1.3811,  0.5272,  0.9292],\n",
            "        [ 0.6493, -0.0979, -0.8506],\n",
            "        [-1.5309,  0.6216,  0.8855],\n",
            "        [-1.5358,  1.4149,  0.0256],\n",
            "        [-1.5656,  0.5185,  0.9502],\n",
            "        [-0.5625,  0.2130,  0.1710],\n",
            "        [-1.5614,  1.7345, -0.4025],\n",
            "        [-1.4673,  1.5750, -0.4954],\n",
            "        [-1.2687,  0.8806,  0.4185],\n",
            "        [-1.4608,  0.4204,  1.0550],\n",
            "        [-1.5174,  0.3836,  1.0466],\n",
            "        [-1.6453,  1.9511, -0.3074],\n",
            "        [-1.5970,  0.8497,  0.6311],\n",
            "        [-1.7026,  0.3650,  1.3363]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6071,  0.4458,  1.0080],\n",
            "        [-0.4947,  0.6841, -0.4864],\n",
            "        [-1.5823,  1.6948, -0.4218],\n",
            "        [-1.6179,  1.5935, -0.3209],\n",
            "        [ 0.4937,  0.0508, -0.8344],\n",
            "        [-1.4487,  0.2400,  1.1575],\n",
            "        [-1.7052,  1.3948,  0.2095],\n",
            "        [-1.7859,  0.3010,  1.0974],\n",
            "        [-1.0075,  1.3997, -0.5041],\n",
            "        [ 0.6170, -0.2117, -0.8853],\n",
            "        [-1.4317,  1.7449, -0.2120],\n",
            "        [-1.3339,  1.1836, -0.0653],\n",
            "        [ 0.5204, -0.0659, -0.8965],\n",
            "        [-1.4557,  1.4319, -0.3571],\n",
            "        [-1.4764,  0.1406,  1.0785],\n",
            "        [-1.5914,  1.7637, -0.3233]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6071,  0.4458,  1.0080],\n",
            "        [-0.4947,  0.6841, -0.4864],\n",
            "        [-1.5823,  1.6948, -0.4218],\n",
            "        [-1.6179,  1.5935, -0.3209],\n",
            "        [ 0.4937,  0.0508, -0.8344],\n",
            "        [-1.4487,  0.2400,  1.1575],\n",
            "        [-1.7052,  1.3948,  0.2095],\n",
            "        [-1.7859,  0.3010,  1.0974],\n",
            "        [-1.0075,  1.3997, -0.5041],\n",
            "        [ 0.6170, -0.2117, -0.8853],\n",
            "        [-1.4317,  1.7449, -0.2120],\n",
            "        [-1.3339,  1.1836, -0.0653],\n",
            "        [ 0.5204, -0.0659, -0.8965],\n",
            "        [-1.4557,  1.4319, -0.3571],\n",
            "        [-1.4764,  0.1406,  1.0785],\n",
            "        [-1.5914,  1.7637, -0.3233]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2964,  1.5653, -0.3592],\n",
            "        [-1.3136,  1.0574,  0.0980],\n",
            "        [-1.6748,  0.6936,  0.8819],\n",
            "        [-1.1910,  1.0867,  0.0132],\n",
            "        [-1.0298,  0.9062, -0.0055],\n",
            "        [-0.1892,  0.6103, -0.8066],\n",
            "        [ 0.3668,  0.1614, -0.9849],\n",
            "        [-1.4874,  0.6129,  0.9216],\n",
            "        [-1.3543,  1.7981, -0.5375],\n",
            "        [-1.6141,  0.2118,  1.2387],\n",
            "        [-1.5299,  1.9864, -0.4899],\n",
            "        [-1.7140,  1.5678, -0.5352],\n",
            "        [ 0.7135, -0.1390, -1.0658],\n",
            "        [-1.4167,  1.5507, -0.0479],\n",
            "        [ 0.5204, -0.0874, -0.8780],\n",
            "        [-1.7617,  0.3928,  1.1969]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2964,  1.5653, -0.3592],\n",
            "        [-1.3136,  1.0574,  0.0980],\n",
            "        [-1.6748,  0.6936,  0.8819],\n",
            "        [-1.1910,  1.0867,  0.0132],\n",
            "        [-1.0298,  0.9062, -0.0055],\n",
            "        [-0.1892,  0.6103, -0.8066],\n",
            "        [ 0.3668,  0.1614, -0.9849],\n",
            "        [-1.4874,  0.6129,  0.9216],\n",
            "        [-1.3543,  1.7981, -0.5375],\n",
            "        [-1.6141,  0.2118,  1.2387],\n",
            "        [-1.5299,  1.9864, -0.4899],\n",
            "        [-1.7140,  1.5678, -0.5352],\n",
            "        [ 0.7135, -0.1390, -1.0658],\n",
            "        [-1.4167,  1.5507, -0.0479],\n",
            "        [ 0.5204, -0.0874, -0.8780],\n",
            "        [-1.7617,  0.3928,  1.1969]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.8039, -0.1927, -1.1503],\n",
            "        [-1.3283,  1.5542, -0.4308],\n",
            "        [-1.4636,  1.4113, -0.2277],\n",
            "        [-1.5966,  0.4308,  1.0654],\n",
            "        [-1.3946,  1.7923, -0.4717],\n",
            "        [-1.4066,  1.5693, -0.3897],\n",
            "        [ 0.7169, -0.1620, -1.0351],\n",
            "        [-1.1319,  1.1760, -0.0766],\n",
            "        [ 0.6054, -0.0059, -0.9910],\n",
            "        [-1.4937,  1.8291, -0.5118],\n",
            "        [-1.5715,  0.4827,  1.0459],\n",
            "        [ 0.5288,  0.0169, -0.9970],\n",
            "        [-1.6705,  1.9662, -0.4866],\n",
            "        [-1.4035,  0.3904,  0.7845],\n",
            "        [-1.6326,  0.9219,  0.6324],\n",
            "        [ 0.6421, -0.1753, -0.8134]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.8039, -0.1927, -1.1503],\n",
            "        [-1.3283,  1.5542, -0.4308],\n",
            "        [-1.4636,  1.4113, -0.2277],\n",
            "        [-1.5966,  0.4308,  1.0654],\n",
            "        [-1.3946,  1.7923, -0.4717],\n",
            "        [-1.4066,  1.5693, -0.3897],\n",
            "        [ 0.7169, -0.1620, -1.0351],\n",
            "        [-1.1319,  1.1760, -0.0766],\n",
            "        [ 0.6054, -0.0059, -0.9910],\n",
            "        [-1.4937,  1.8291, -0.5118],\n",
            "        [-1.5715,  0.4827,  1.0459],\n",
            "        [ 0.5288,  0.0169, -0.9970],\n",
            "        [-1.6705,  1.9662, -0.4866],\n",
            "        [-1.4035,  0.3904,  0.7845],\n",
            "        [-1.6326,  0.9219,  0.6324],\n",
            "        [ 0.6421, -0.1753, -0.8134]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5671,  1.7084, -0.2822],\n",
            "        [ 0.9017, -0.1788, -0.9165],\n",
            "        [-1.7840,  0.4150,  1.0576],\n",
            "        [-1.5502,  0.4188,  1.0320],\n",
            "        [-1.6879,  1.8159, -0.2441],\n",
            "        [ 0.6381, -0.2332, -1.0288],\n",
            "        [ 0.8501, -0.1490, -1.0606],\n",
            "        [ 0.6435, -0.2112, -1.0661],\n",
            "        [-1.4142,  0.4224,  0.8363],\n",
            "        [-1.4633,  1.2162,  0.0941],\n",
            "        [-1.7123,  1.7660, -0.2512],\n",
            "        [-1.6987,  2.0610, -0.2913],\n",
            "        [-1.3855,  1.0749,  0.4411],\n",
            "        [ 0.4989,  0.0596, -0.9922],\n",
            "        [-1.6012,  0.8841,  0.6769],\n",
            "        [-1.4843,  0.7463,  0.7674]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5671,  1.7084, -0.2822],\n",
            "        [ 0.9017, -0.1788, -0.9165],\n",
            "        [-1.7840,  0.4150,  1.0576],\n",
            "        [-1.5502,  0.4188,  1.0320],\n",
            "        [-1.6879,  1.8159, -0.2441],\n",
            "        [ 0.6381, -0.2332, -1.0288],\n",
            "        [ 0.8501, -0.1490, -1.0606],\n",
            "        [ 0.6435, -0.2112, -1.0661],\n",
            "        [-1.4142,  0.4224,  0.8363],\n",
            "        [-1.4633,  1.2162,  0.0941],\n",
            "        [-1.7123,  1.7660, -0.2512],\n",
            "        [-1.6987,  2.0610, -0.2913],\n",
            "        [-1.3855,  1.0749,  0.4411],\n",
            "        [ 0.4989,  0.0596, -0.9922],\n",
            "        [-1.6012,  0.8841,  0.6769],\n",
            "        [-1.4843,  0.7463,  0.7674]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5080,  0.2918, -0.7832],\n",
            "        [-1.3903,  1.7599, -0.5258],\n",
            "        [-1.5318,  1.7638, -0.3773],\n",
            "        [-1.5321,  1.7127, -0.3207],\n",
            "        [-1.5182,  1.9905, -0.3620],\n",
            "        [ 0.4372,  0.2232, -1.0773],\n",
            "        [ 0.6893, -0.1010, -1.1229],\n",
            "        [-1.5508,  1.9823, -0.4224],\n",
            "        [-1.0506,  0.5281,  0.2776],\n",
            "        [-1.6418,  1.9268, -0.5137],\n",
            "        [-1.4095,  1.7877, -0.5039],\n",
            "        [-1.6336,  2.0154, -0.3405],\n",
            "        [-1.5563,  1.6903, -0.3312],\n",
            "        [-1.4107,  1.1404,  0.2635],\n",
            "        [-0.4391,  0.2839, -0.1601],\n",
            "        [ 0.2289,  0.2694, -0.9287]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.5080,  0.2918, -0.7832],\n",
            "        [-1.3903,  1.7599, -0.5258],\n",
            "        [-1.5318,  1.7638, -0.3773],\n",
            "        [-1.5321,  1.7127, -0.3207],\n",
            "        [-1.5182,  1.9905, -0.3620],\n",
            "        [ 0.4372,  0.2232, -1.0773],\n",
            "        [ 0.6893, -0.1010, -1.1229],\n",
            "        [-1.5508,  1.9823, -0.4224],\n",
            "        [-1.0506,  0.5281,  0.2776],\n",
            "        [-1.6418,  1.9268, -0.5137],\n",
            "        [-1.4095,  1.7877, -0.5039],\n",
            "        [-1.6336,  2.0154, -0.3405],\n",
            "        [-1.5563,  1.6903, -0.3312],\n",
            "        [-1.4107,  1.1404,  0.2635],\n",
            "        [-0.4391,  0.2839, -0.1601],\n",
            "        [ 0.2289,  0.2694, -0.9287]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8065,  0.5786,  1.1738],\n",
            "        [-1.3001,  1.6346, -0.2137],\n",
            "        [-1.4557,  0.5608,  0.6759],\n",
            "        [-1.3195,  1.3404, -0.0755],\n",
            "        [-1.0579,  1.3292, -0.5816],\n",
            "        [-1.4588,  1.3240,  0.0321],\n",
            "        [-1.5858,  1.9250, -0.3375],\n",
            "        [-1.6872,  0.6004,  0.9818],\n",
            "        [-0.7267,  0.4974,  0.0423],\n",
            "        [-1.5422,  1.1886,  0.0468],\n",
            "        [-1.6517,  1.5687,  0.0571],\n",
            "        [-1.7582,  0.4159,  1.1362],\n",
            "        [-1.6803,  1.9294, -0.4656],\n",
            "        [-1.4329,  1.4502, -0.2569],\n",
            "        [-1.6579,  1.7229, -0.4289],\n",
            "        [-1.5118,  1.7111, -0.3575]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8065,  0.5786,  1.1738],\n",
            "        [-1.3001,  1.6346, -0.2137],\n",
            "        [-1.4557,  0.5608,  0.6759],\n",
            "        [-1.3195,  1.3404, -0.0755],\n",
            "        [-1.0579,  1.3292, -0.5816],\n",
            "        [-1.4588,  1.3240,  0.0321],\n",
            "        [-1.5858,  1.9250, -0.3375],\n",
            "        [-1.6872,  0.6004,  0.9818],\n",
            "        [-0.7267,  0.4974,  0.0423],\n",
            "        [-1.5422,  1.1886,  0.0468],\n",
            "        [-1.6517,  1.5687,  0.0571],\n",
            "        [-1.7582,  0.4159,  1.1362],\n",
            "        [-1.6803,  1.9294, -0.4656],\n",
            "        [-1.4329,  1.4502, -0.2569],\n",
            "        [-1.6579,  1.7229, -0.4289],\n",
            "        [-1.5118,  1.7111, -0.3575]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6089,  1.5335,  0.0763],\n",
            "        [ 0.5815, -0.0103, -0.9066],\n",
            "        [-1.3670,  1.6096, -0.3144],\n",
            "        [-1.6741,  0.5820,  1.0193],\n",
            "        [-1.4888,  1.7409, -0.3798],\n",
            "        [-1.8732,  1.3966,  0.0983],\n",
            "        [-1.0064,  0.5473, -0.0739],\n",
            "        [-1.5261,  1.6944, -0.3232],\n",
            "        [ 0.6169, -0.2436, -1.1093],\n",
            "        [ 0.3665, -0.1115, -0.8817],\n",
            "        [-1.4731,  1.9459, -0.4118],\n",
            "        [-1.7520,  1.7987, -0.1127],\n",
            "        [-1.5439,  1.3793,  0.0751],\n",
            "        [-1.5255,  1.7280, -0.3763],\n",
            "        [-1.6804,  1.9130, -0.1272],\n",
            "        [-1.4011,  1.7201, -0.6861]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6089,  1.5335,  0.0763],\n",
            "        [ 0.5815, -0.0103, -0.9066],\n",
            "        [-1.3670,  1.6096, -0.3144],\n",
            "        [-1.6741,  0.5820,  1.0193],\n",
            "        [-1.4888,  1.7409, -0.3798],\n",
            "        [-1.8732,  1.3966,  0.0983],\n",
            "        [-1.0064,  0.5473, -0.0739],\n",
            "        [-1.5261,  1.6944, -0.3232],\n",
            "        [ 0.6169, -0.2436, -1.1093],\n",
            "        [ 0.3665, -0.1115, -0.8817],\n",
            "        [-1.4731,  1.9459, -0.4118],\n",
            "        [-1.7520,  1.7987, -0.1127],\n",
            "        [-1.5439,  1.3793,  0.0751],\n",
            "        [-1.5255,  1.7280, -0.3763],\n",
            "        [-1.6804,  1.9130, -0.1272],\n",
            "        [-1.4011,  1.7201, -0.6861]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6876,  0.7235,  0.8723],\n",
            "        [-1.7339,  1.4474,  0.1040],\n",
            "        [-1.6630,  1.7818, -0.2214],\n",
            "        [-1.3896,  1.5481, -0.1955],\n",
            "        [-1.7964,  2.0319, -0.6756],\n",
            "        [-1.5754,  1.4030,  0.3039],\n",
            "        [ 0.5670,  0.0912, -0.9198],\n",
            "        [-1.5918,  1.9792, -0.4765],\n",
            "        [-1.6475,  1.6918,  0.0048],\n",
            "        [ 0.7656, -0.1237, -1.1646],\n",
            "        [-1.6956,  1.4389, -0.0309],\n",
            "        [-1.5333,  1.7980, -0.4542],\n",
            "        [-1.7964,  0.3429,  1.0754],\n",
            "        [-1.4613,  2.0164, -0.3351],\n",
            "        [-1.7341,  1.9386, -0.2760],\n",
            "        [-1.8373,  1.9801, -0.4247]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6876,  0.7235,  0.8723],\n",
            "        [-1.7339,  1.4474,  0.1040],\n",
            "        [-1.6630,  1.7818, -0.2214],\n",
            "        [-1.3896,  1.5481, -0.1955],\n",
            "        [-1.7964,  2.0319, -0.6756],\n",
            "        [-1.5754,  1.4030,  0.3039],\n",
            "        [ 0.5670,  0.0912, -0.9198],\n",
            "        [-1.5918,  1.9792, -0.4765],\n",
            "        [-1.6475,  1.6918,  0.0048],\n",
            "        [ 0.7656, -0.1237, -1.1646],\n",
            "        [-1.6956,  1.4389, -0.0309],\n",
            "        [-1.5333,  1.7980, -0.4542],\n",
            "        [-1.7964,  0.3429,  1.0754],\n",
            "        [-1.4613,  2.0164, -0.3351],\n",
            "        [-1.7341,  1.9386, -0.2760],\n",
            "        [-1.8373,  1.9801, -0.4247]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6500,  1.8810, -0.2811],\n",
            "        [-1.7712,  2.0845, -0.3382],\n",
            "        [-1.1787,  1.4976, -0.5893],\n",
            "        [-1.8242,  2.0132, -0.1290],\n",
            "        [ 0.5607,  0.0926, -1.1884],\n",
            "        [-1.8991,  0.5180,  1.3642],\n",
            "        [-1.8924,  1.9114, -0.3484],\n",
            "        [-1.7780,  2.1515, -0.4486],\n",
            "        [-1.6223,  1.8569, -0.0375],\n",
            "        [-1.7112,  0.4525,  1.0046],\n",
            "        [ 0.7630, -0.1574, -1.1166],\n",
            "        [-0.7294,  0.8234, -0.7114],\n",
            "        [-1.6484,  1.5502,  0.2080],\n",
            "        [-1.7164,  1.8377, -0.3464],\n",
            "        [-1.8207,  0.2941,  0.9730],\n",
            "        [ 0.3020,  0.2974, -1.0670]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6500,  1.8810, -0.2811],\n",
            "        [-1.7712,  2.0845, -0.3382],\n",
            "        [-1.1787,  1.4976, -0.5893],\n",
            "        [-1.8242,  2.0132, -0.1290],\n",
            "        [ 0.5607,  0.0926, -1.1884],\n",
            "        [-1.8991,  0.5180,  1.3642],\n",
            "        [-1.8924,  1.9114, -0.3484],\n",
            "        [-1.7780,  2.1515, -0.4486],\n",
            "        [-1.6223,  1.8569, -0.0375],\n",
            "        [-1.7112,  0.4525,  1.0046],\n",
            "        [ 0.7630, -0.1574, -1.1166],\n",
            "        [-0.7294,  0.8234, -0.7114],\n",
            "        [-1.6484,  1.5502,  0.2080],\n",
            "        [-1.7164,  1.8377, -0.3464],\n",
            "        [-1.8207,  0.2941,  0.9730],\n",
            "        [ 0.3020,  0.2974, -1.0670]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8207,  2.1766, -0.3122],\n",
            "        [ 0.3410,  0.3166, -1.2471],\n",
            "        [-1.6127,  1.8059, -0.5151],\n",
            "        [-1.8391,  2.0600, -0.4975],\n",
            "        [-1.9724,  1.0774,  0.6136],\n",
            "        [-1.8534,  0.5692,  1.1380],\n",
            "        [ 0.6064,  0.0177, -1.2158],\n",
            "        [-1.9445,  1.7625, -0.1130],\n",
            "        [-1.8157,  2.0740, -0.3229],\n",
            "        [-1.8132,  2.0032, -0.0675],\n",
            "        [-1.9307,  1.1214,  0.6198],\n",
            "        [-2.0204,  2.1297, -0.5654],\n",
            "        [-1.8345,  0.9209,  0.7634],\n",
            "        [-1.8086,  1.3150,  0.1809],\n",
            "        [-1.7163,  2.2443, -0.5848],\n",
            "        [-1.9531,  1.4376,  0.4195]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8207,  2.1766, -0.3122],\n",
            "        [ 0.3410,  0.3166, -1.2471],\n",
            "        [-1.6127,  1.8059, -0.5151],\n",
            "        [-1.8391,  2.0600, -0.4975],\n",
            "        [-1.9724,  1.0774,  0.6136],\n",
            "        [-1.8534,  0.5692,  1.1380],\n",
            "        [ 0.6064,  0.0177, -1.2158],\n",
            "        [-1.9445,  1.7625, -0.1130],\n",
            "        [-1.8157,  2.0740, -0.3229],\n",
            "        [-1.8132,  2.0032, -0.0675],\n",
            "        [-1.9307,  1.1214,  0.6198],\n",
            "        [-2.0204,  2.1297, -0.5654],\n",
            "        [-1.8345,  0.9209,  0.7634],\n",
            "        [-1.8086,  1.3150,  0.1809],\n",
            "        [-1.7163,  2.2443, -0.5848],\n",
            "        [-1.9531,  1.4376,  0.4195]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9668,  0.6298,  1.2886],\n",
            "        [-1.8843,  2.2780, -0.4539],\n",
            "        [-1.5761,  1.7709,  0.0079],\n",
            "        [-1.7318,  1.0106,  0.4099],\n",
            "        [-1.6627,  0.5497,  0.9678],\n",
            "        [-1.7832,  0.7301,  0.9641],\n",
            "        [-1.7954,  0.8018,  0.7312],\n",
            "        [-2.1447,  1.5855,  0.2379],\n",
            "        [-1.6714,  0.5623,  1.0130],\n",
            "        [-1.6370,  0.6991,  1.0335],\n",
            "        [-1.9241,  2.3286, -0.2539],\n",
            "        [-1.6630,  0.8402,  1.2545],\n",
            "        [-1.7444,  0.8629,  0.7208],\n",
            "        [-1.6912,  1.3977,  0.2204],\n",
            "        [-1.7201,  2.0459, -0.4019],\n",
            "        [-1.7545,  0.5466,  1.1286]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9668,  0.6298,  1.2886],\n",
            "        [-1.8843,  2.2780, -0.4539],\n",
            "        [-1.5761,  1.7709,  0.0079],\n",
            "        [-1.7318,  1.0106,  0.4099],\n",
            "        [-1.6627,  0.5497,  0.9678],\n",
            "        [-1.7832,  0.7301,  0.9641],\n",
            "        [-1.7954,  0.8018,  0.7312],\n",
            "        [-2.1447,  1.5855,  0.2379],\n",
            "        [-1.6714,  0.5623,  1.0130],\n",
            "        [-1.6370,  0.6991,  1.0335],\n",
            "        [-1.9241,  2.3286, -0.2539],\n",
            "        [-1.6630,  0.8402,  1.2545],\n",
            "        [-1.7444,  0.8629,  0.7208],\n",
            "        [-1.6912,  1.3977,  0.2204],\n",
            "        [-1.7201,  2.0459, -0.4019],\n",
            "        [-1.7545,  0.5466,  1.1286]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9491,  1.9294,  0.1814],\n",
            "        [-1.7947,  0.3566,  1.2900],\n",
            "        [-1.9408,  2.3319, -0.4492],\n",
            "        [-1.7597,  1.7471, -0.2486],\n",
            "        [ 0.6276, -0.0165, -1.1206],\n",
            "        [-1.9773,  1.1452,  0.7318],\n",
            "        [-2.1344,  2.4958, -0.3244],\n",
            "        [-1.9630,  1.0593,  0.7103],\n",
            "        [-1.9211,  0.5447,  1.0300],\n",
            "        [-1.7597,  2.4080, -0.4631],\n",
            "        [-1.9407,  1.7691, -0.3092],\n",
            "        [-2.1477,  2.1110, -0.1361],\n",
            "        [-1.8159,  0.7567,  0.8596],\n",
            "        [-2.0827,  2.3447, -0.2960],\n",
            "        [-1.6425,  1.9595, -0.6143],\n",
            "        [-1.7737,  2.2532, -0.4818]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9491,  1.9294,  0.1814],\n",
            "        [-1.7947,  0.3566,  1.2900],\n",
            "        [-1.9408,  2.3319, -0.4492],\n",
            "        [-1.7597,  1.7471, -0.2486],\n",
            "        [ 0.6276, -0.0165, -1.1206],\n",
            "        [-1.9773,  1.1452,  0.7318],\n",
            "        [-2.1344,  2.4958, -0.3244],\n",
            "        [-1.9630,  1.0593,  0.7103],\n",
            "        [-1.9211,  0.5447,  1.0300],\n",
            "        [-1.7597,  2.4080, -0.4631],\n",
            "        [-1.9407,  1.7691, -0.3092],\n",
            "        [-2.1477,  2.1110, -0.1361],\n",
            "        [-1.8159,  0.7567,  0.8596],\n",
            "        [-2.0827,  2.3447, -0.2960],\n",
            "        [-1.6425,  1.9595, -0.6143],\n",
            "        [-1.7737,  2.2532, -0.4818]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8641,  0.9141,  0.9778],\n",
            "        [ 0.5147, -0.1086, -1.1776],\n",
            "        [-1.8528,  1.9191,  0.0211],\n",
            "        [-1.8233,  1.4728,  0.1179],\n",
            "        [-1.9090,  1.9558, -0.4669],\n",
            "        [-1.7383,  1.8430, -0.5229],\n",
            "        [-1.6478,  1.1091,  0.4232],\n",
            "        [-1.9195,  0.5703,  1.0206],\n",
            "        [-1.7770,  2.0252, -0.1762],\n",
            "        [-1.7379,  0.6128,  1.0086],\n",
            "        [-1.7610,  1.7332,  0.0596],\n",
            "        [-1.7573,  1.0668,  0.6957],\n",
            "        [-1.7391,  0.5350,  1.2104],\n",
            "        [-1.7291,  0.5806,  1.0721],\n",
            "        [ 0.5501, -0.0112, -1.1210],\n",
            "        [-2.1065,  1.1185,  0.5113]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8641,  0.9141,  0.9778],\n",
            "        [ 0.5147, -0.1086, -1.1776],\n",
            "        [-1.8528,  1.9191,  0.0211],\n",
            "        [-1.8233,  1.4728,  0.1179],\n",
            "        [-1.9090,  1.9558, -0.4669],\n",
            "        [-1.7383,  1.8430, -0.5229],\n",
            "        [-1.6478,  1.1091,  0.4232],\n",
            "        [-1.9195,  0.5703,  1.0206],\n",
            "        [-1.7770,  2.0252, -0.1762],\n",
            "        [-1.7379,  0.6128,  1.0086],\n",
            "        [-1.7610,  1.7332,  0.0596],\n",
            "        [-1.7573,  1.0668,  0.6957],\n",
            "        [-1.7391,  0.5350,  1.2104],\n",
            "        [-1.7291,  0.5806,  1.0721],\n",
            "        [ 0.5501, -0.0112, -1.1210],\n",
            "        [-2.1065,  1.1185,  0.5113]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9735,  0.6236,  1.0674],\n",
            "        [-1.9541,  1.9232, -0.4994],\n",
            "        [-1.9374,  0.9563,  0.7539],\n",
            "        [-1.7051,  2.0096, -0.3315],\n",
            "        [-1.8848,  0.7851,  1.1022],\n",
            "        [ 0.7814, -0.2405, -1.1767],\n",
            "        [-1.8904,  1.7222, -0.0358],\n",
            "        [-1.9245,  0.6369,  0.9842],\n",
            "        [ 0.7246,  0.0282, -1.3488],\n",
            "        [-1.9557,  1.0236,  0.9678],\n",
            "        [-1.9228,  0.5350,  1.1890],\n",
            "        [ 0.6348,  0.0335, -1.2176],\n",
            "        [ 0.9124, -0.1193, -1.0237],\n",
            "        [-1.9363,  0.4751,  1.2850],\n",
            "        [-1.7275,  2.0069, -0.4085],\n",
            "        [-1.4588,  1.6994, -0.3921]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9735,  0.6236,  1.0674],\n",
            "        [-1.9541,  1.9232, -0.4994],\n",
            "        [-1.9374,  0.9563,  0.7539],\n",
            "        [-1.7051,  2.0096, -0.3315],\n",
            "        [-1.8848,  0.7851,  1.1022],\n",
            "        [ 0.7814, -0.2405, -1.1767],\n",
            "        [-1.8904,  1.7222, -0.0358],\n",
            "        [-1.9245,  0.6369,  0.9842],\n",
            "        [ 0.7246,  0.0282, -1.3488],\n",
            "        [-1.9557,  1.0236,  0.9678],\n",
            "        [-1.9228,  0.5350,  1.1890],\n",
            "        [ 0.6348,  0.0335, -1.2176],\n",
            "        [ 0.9124, -0.1193, -1.0237],\n",
            "        [-1.9363,  0.4751,  1.2850],\n",
            "        [-1.7275,  2.0069, -0.4085],\n",
            "        [-1.4588,  1.6994, -0.3921]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2292,  1.6123,  0.6995],\n",
            "        [-2.3656,  1.0969,  0.8342],\n",
            "        [-0.7607,  1.1739, -0.8377],\n",
            "        [-1.5628,  1.2535,  0.0679],\n",
            "        [-0.5718,  1.2267, -1.0460],\n",
            "        [-1.9926,  2.1183, -0.2132],\n",
            "        [-1.9328,  1.4695,  0.3834],\n",
            "        [-2.0004,  1.1305,  0.6354],\n",
            "        [ 0.2898,  0.1989, -1.0716],\n",
            "        [-1.9934,  1.6592,  0.3426],\n",
            "        [-1.9734,  1.9200, -0.0235],\n",
            "        [-1.7115,  0.3966,  1.1890],\n",
            "        [ 0.1728,  0.2345, -1.1292],\n",
            "        [-1.9989,  0.4961,  1.3857],\n",
            "        [-1.7242,  1.8647, -0.0138],\n",
            "        [-2.0545,  1.8180, -0.1053]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.2292,  1.6123,  0.6995],\n",
            "        [-2.3656,  1.0969,  0.8342],\n",
            "        [-0.7607,  1.1739, -0.8377],\n",
            "        [-1.5628,  1.2535,  0.0679],\n",
            "        [-0.5718,  1.2267, -1.0460],\n",
            "        [-1.9926,  2.1183, -0.2132],\n",
            "        [-1.9328,  1.4695,  0.3834],\n",
            "        [-2.0004,  1.1305,  0.6354],\n",
            "        [ 0.2898,  0.1989, -1.0716],\n",
            "        [-1.9934,  1.6592,  0.3426],\n",
            "        [-1.9734,  1.9200, -0.0235],\n",
            "        [-1.7115,  0.3966,  1.1890],\n",
            "        [ 0.1728,  0.2345, -1.1292],\n",
            "        [-1.9989,  0.4961,  1.3857],\n",
            "        [-1.7242,  1.8647, -0.0138],\n",
            "        [-2.0545,  1.8180, -0.1053]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1170,  2.1902, -0.4607],\n",
            "        [-2.0577,  1.4811,  0.1394],\n",
            "        [-1.8924,  2.0659, -0.3826],\n",
            "        [-2.0476,  2.0799, -0.0854],\n",
            "        [-1.9935,  2.0835, -0.2457],\n",
            "        [-2.0727,  2.0042,  0.1120],\n",
            "        [-2.0580,  0.7653,  1.2203],\n",
            "        [-2.2585,  2.0322, -0.0536],\n",
            "        [-1.7531,  1.8357, -0.0561],\n",
            "        [ 0.3319,  0.3723, -1.2516],\n",
            "        [-2.1214,  2.1723, -0.3182],\n",
            "        [-2.0319,  1.8940, -0.2828],\n",
            "        [-2.2809,  0.4702,  1.4819],\n",
            "        [-1.8600,  2.0046, -0.1793],\n",
            "        [-1.7956,  2.3206, -0.2998],\n",
            "        [-1.9236,  1.9590, -0.2244]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1170,  2.1902, -0.4607],\n",
            "        [-2.0577,  1.4811,  0.1394],\n",
            "        [-1.8924,  2.0659, -0.3826],\n",
            "        [-2.0476,  2.0799, -0.0854],\n",
            "        [-1.9935,  2.0835, -0.2457],\n",
            "        [-2.0727,  2.0042,  0.1120],\n",
            "        [-2.0580,  0.7653,  1.2203],\n",
            "        [-2.2585,  2.0322, -0.0536],\n",
            "        [-1.7531,  1.8357, -0.0561],\n",
            "        [ 0.3319,  0.3723, -1.2516],\n",
            "        [-2.1214,  2.1723, -0.3182],\n",
            "        [-2.0319,  1.8940, -0.2828],\n",
            "        [-2.2809,  0.4702,  1.4819],\n",
            "        [-1.8600,  2.0046, -0.1793],\n",
            "        [-1.7956,  2.3206, -0.2998],\n",
            "        [-1.9236,  1.9590, -0.2244]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.4775,  0.1040, -1.2240],\n",
            "        [-1.9517,  0.6065,  1.3460],\n",
            "        [-2.1107,  2.0184, -0.1848],\n",
            "        [-1.8237,  1.8923, -0.0025],\n",
            "        [-1.9402,  2.0196, -0.1095],\n",
            "        [-1.8982,  1.8560, -0.0334],\n",
            "        [-1.9596,  1.9899, -0.0247],\n",
            "        [-2.1070,  2.1608, -0.5008],\n",
            "        [-1.9532,  0.4775,  1.3200],\n",
            "        [-1.8672,  2.0747, -0.1959],\n",
            "        [-2.2002,  1.6776,  0.4746],\n",
            "        [-1.8834,  0.8257,  0.7013],\n",
            "        [-2.0334,  0.8546,  1.1672],\n",
            "        [-1.9172,  1.0001,  0.7898],\n",
            "        [ 0.7132,  0.0562, -1.2556],\n",
            "        [-2.0107,  1.8836, -0.2480]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.4775,  0.1040, -1.2240],\n",
            "        [-1.9517,  0.6065,  1.3460],\n",
            "        [-2.1107,  2.0184, -0.1848],\n",
            "        [-1.8237,  1.8923, -0.0025],\n",
            "        [-1.9402,  2.0196, -0.1095],\n",
            "        [-1.8982,  1.8560, -0.0334],\n",
            "        [-1.9596,  1.9899, -0.0247],\n",
            "        [-2.1070,  2.1608, -0.5008],\n",
            "        [-1.9532,  0.4775,  1.3200],\n",
            "        [-1.8672,  2.0747, -0.1959],\n",
            "        [-2.2002,  1.6776,  0.4746],\n",
            "        [-1.8834,  0.8257,  0.7013],\n",
            "        [-2.0334,  0.8546,  1.1672],\n",
            "        [-1.9172,  1.0001,  0.7898],\n",
            "        [ 0.7132,  0.0562, -1.2556],\n",
            "        [-2.0107,  1.8836, -0.2480]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0699,  1.6010,  0.0027],\n",
            "        [-2.0452,  0.5150,  1.2269],\n",
            "        [-1.7279,  0.5040,  0.9272],\n",
            "        [-2.0503,  2.3329, -0.1930],\n",
            "        [-1.8678,  1.8877, -0.1048],\n",
            "        [-1.8468,  1.7860,  0.2894],\n",
            "        [-2.1027,  1.8676, -0.1990],\n",
            "        [-1.9707,  0.6386,  1.3421],\n",
            "        [-1.8293,  1.5787,  0.2258],\n",
            "        [-1.8046,  0.7213,  1.0999],\n",
            "        [-1.9970,  1.8764, -0.2013],\n",
            "        [-1.9795,  1.9785, -0.1175],\n",
            "        [-2.1784,  1.8793, -0.0616],\n",
            "        [-2.1630,  1.1568,  0.5844],\n",
            "        [-2.0654,  1.6018,  0.4898],\n",
            "        [-2.2817,  0.9603,  0.9650]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0699,  1.6010,  0.0027],\n",
            "        [-2.0452,  0.5150,  1.2269],\n",
            "        [-1.7279,  0.5040,  0.9272],\n",
            "        [-2.0503,  2.3329, -0.1930],\n",
            "        [-1.8678,  1.8877, -0.1048],\n",
            "        [-1.8468,  1.7860,  0.2894],\n",
            "        [-2.1027,  1.8676, -0.1990],\n",
            "        [-1.9707,  0.6386,  1.3421],\n",
            "        [-1.8293,  1.5787,  0.2258],\n",
            "        [-1.8046,  0.7213,  1.0999],\n",
            "        [-1.9970,  1.8764, -0.2013],\n",
            "        [-1.9795,  1.9785, -0.1175],\n",
            "        [-2.1784,  1.8793, -0.0616],\n",
            "        [-2.1630,  1.1568,  0.5844],\n",
            "        [-2.0654,  1.6018,  0.4898],\n",
            "        [-2.2817,  0.9603,  0.9650]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.0542,  0.5864, -1.1789],\n",
            "        [-2.0303,  1.9518,  0.1649],\n",
            "        [-1.9631,  0.8432,  0.8595],\n",
            "        [-2.0901,  2.0665, -0.3278],\n",
            "        [-1.9257,  2.2320, -0.2800],\n",
            "        [-2.3267,  2.3315,  0.0660],\n",
            "        [-2.1915,  2.2310, -0.0227],\n",
            "        [-1.8409,  0.7775,  1.3181],\n",
            "        [ 0.7533, -0.2509, -1.1474],\n",
            "        [-1.9777,  1.6873,  0.0610],\n",
            "        [ 0.5789,  0.0743, -1.0745],\n",
            "        [-2.2949,  1.8458,  0.4408],\n",
            "        [-2.0013,  1.8812, -0.0947],\n",
            "        [-2.1249,  0.5657,  1.2163],\n",
            "        [-1.9912,  1.5608,  0.0917],\n",
            "        [-2.1829,  0.4015,  0.9998]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-0.0542,  0.5864, -1.1789],\n",
            "        [-2.0303,  1.9518,  0.1649],\n",
            "        [-1.9631,  0.8432,  0.8595],\n",
            "        [-2.0901,  2.0665, -0.3278],\n",
            "        [-1.9257,  2.2320, -0.2800],\n",
            "        [-2.3267,  2.3315,  0.0660],\n",
            "        [-2.1915,  2.2310, -0.0227],\n",
            "        [-1.8409,  0.7775,  1.3181],\n",
            "        [ 0.7533, -0.2509, -1.1474],\n",
            "        [-1.9777,  1.6873,  0.0610],\n",
            "        [ 0.5789,  0.0743, -1.0745],\n",
            "        [-2.2949,  1.8458,  0.4408],\n",
            "        [-2.0013,  1.8812, -0.0947],\n",
            "        [-2.1249,  0.5657,  1.2163],\n",
            "        [-1.9912,  1.5608,  0.0917],\n",
            "        [-2.1829,  0.4015,  0.9998]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1234,  1.9841, -0.0132],\n",
            "        [-2.1560,  0.6066,  1.2508],\n",
            "        [ 0.5989,  0.2888, -1.1512],\n",
            "        [ 0.0647,  0.2929, -0.9637],\n",
            "        [-2.1680,  2.1275, -0.1429],\n",
            "        [-2.2184,  1.3719,  0.5643],\n",
            "        [-1.9026,  0.6169,  1.1091],\n",
            "        [-2.0942,  1.3316,  0.5197],\n",
            "        [-1.9421,  2.0990, -0.3341],\n",
            "        [-2.0466,  1.2152,  0.7401],\n",
            "        [-2.1308,  2.0961, -0.3190],\n",
            "        [-2.2153,  2.2341, -0.1613],\n",
            "        [-2.0693,  1.3062,  0.0132],\n",
            "        [-2.0719,  2.1492, -0.3356],\n",
            "        [-2.2321,  0.8349,  1.0973],\n",
            "        [-1.9965,  2.2063, -0.0985]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1234,  1.9841, -0.0132],\n",
            "        [-2.1560,  0.6066,  1.2508],\n",
            "        [ 0.5989,  0.2888, -1.1512],\n",
            "        [ 0.0647,  0.2929, -0.9637],\n",
            "        [-2.1680,  2.1275, -0.1429],\n",
            "        [-2.2184,  1.3719,  0.5643],\n",
            "        [-1.9026,  0.6169,  1.1091],\n",
            "        [-2.0942,  1.3316,  0.5197],\n",
            "        [-1.9421,  2.0990, -0.3341],\n",
            "        [-2.0466,  1.2152,  0.7401],\n",
            "        [-2.1308,  2.0961, -0.3190],\n",
            "        [-2.2153,  2.2341, -0.1613],\n",
            "        [-2.0693,  1.3062,  0.0132],\n",
            "        [-2.0719,  2.1492, -0.3356],\n",
            "        [-2.2321,  0.8349,  1.0973],\n",
            "        [-1.9965,  2.2063, -0.0985]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0966,  2.2229, -0.3478],\n",
            "        [ 0.5151,  0.1312, -1.1714],\n",
            "        [-1.8466,  2.0661, -0.4124],\n",
            "        [-2.1629,  1.4212,  0.6910],\n",
            "        [-1.9098,  2.1128, -0.1877],\n",
            "        [-1.4013,  1.9152, -0.7539],\n",
            "        [-2.0215,  1.8646,  0.3940],\n",
            "        [-1.9599,  2.1715,  0.0321],\n",
            "        [-1.8614,  1.8106,  0.2005],\n",
            "        [-2.0278,  1.0041,  0.5946],\n",
            "        [ 0.6655, -0.0124, -0.9777],\n",
            "        [-2.0850,  1.9112,  0.0707],\n",
            "        [-2.0327,  1.8603, -0.0175],\n",
            "        [-2.1276,  2.2307, -0.3067],\n",
            "        [-1.8221,  0.7383,  1.0536],\n",
            "        [ 0.3979,  0.0599, -0.9285]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0966,  2.2229, -0.3478],\n",
            "        [ 0.5151,  0.1312, -1.1714],\n",
            "        [-1.8466,  2.0661, -0.4124],\n",
            "        [-2.1629,  1.4212,  0.6910],\n",
            "        [-1.9098,  2.1128, -0.1877],\n",
            "        [-1.4013,  1.9152, -0.7539],\n",
            "        [-2.0215,  1.8646,  0.3940],\n",
            "        [-1.9599,  2.1715,  0.0321],\n",
            "        [-1.8614,  1.8106,  0.2005],\n",
            "        [-2.0278,  1.0041,  0.5946],\n",
            "        [ 0.6655, -0.0124, -0.9777],\n",
            "        [-2.0850,  1.9112,  0.0707],\n",
            "        [-2.0327,  1.8603, -0.0175],\n",
            "        [-2.1276,  2.2307, -0.3067],\n",
            "        [-1.8221,  0.7383,  1.0536],\n",
            "        [ 0.3979,  0.0599, -0.9285]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1278,  2.2138, -0.1600],\n",
            "        [-2.2351,  2.1976, -0.2771],\n",
            "        [ 0.4400, -0.1867, -1.1980],\n",
            "        [-2.2606,  1.8608,  0.2750],\n",
            "        [-2.4362,  2.0534,  0.1828],\n",
            "        [-1.9982,  2.0802, -0.3131],\n",
            "        [-1.9566,  1.9898, -0.0548],\n",
            "        [-2.3283,  2.2405, -0.0522],\n",
            "        [ 0.6022, -0.1210, -1.1503],\n",
            "        [-2.2009,  2.2058,  0.1559],\n",
            "        [-2.1701,  0.6887,  1.2832],\n",
            "        [-2.4474,  2.1316, -0.2336],\n",
            "        [-2.2578,  0.7108,  1.1962],\n",
            "        [-2.2526,  1.9698, -0.1274],\n",
            "        [-2.0763,  2.0975, -0.3042],\n",
            "        [ 0.9512, -0.1556, -1.2645]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1278,  2.2138, -0.1600],\n",
            "        [-2.2351,  2.1976, -0.2771],\n",
            "        [ 0.4400, -0.1867, -1.1980],\n",
            "        [-2.2606,  1.8608,  0.2750],\n",
            "        [-2.4362,  2.0534,  0.1828],\n",
            "        [-1.9982,  2.0802, -0.3131],\n",
            "        [-1.9566,  1.9898, -0.0548],\n",
            "        [-2.3283,  2.2405, -0.0522],\n",
            "        [ 0.6022, -0.1210, -1.1503],\n",
            "        [-2.2009,  2.2058,  0.1559],\n",
            "        [-2.1701,  0.6887,  1.2832],\n",
            "        [-2.4474,  2.1316, -0.2336],\n",
            "        [-2.2578,  0.7108,  1.1962],\n",
            "        [-2.2526,  1.9698, -0.1274],\n",
            "        [-2.0763,  2.0975, -0.3042],\n",
            "        [ 0.9512, -0.1556, -1.2645]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0461,  1.8873, -0.0364],\n",
            "        [ 0.5654, -0.0161, -1.1706],\n",
            "        [-2.4040,  2.1617,  0.0133],\n",
            "        [-2.2205,  1.4452,  0.3742],\n",
            "        [-1.9424,  2.1596, -0.3335],\n",
            "        [ 0.3149,  0.1999, -1.0837],\n",
            "        [-2.2971,  2.0980, -0.1576],\n",
            "        [-2.0962,  2.2517, -0.1459],\n",
            "        [-1.9324,  2.1573, -0.4309],\n",
            "        [-2.1800,  1.8267, -0.0452],\n",
            "        [-2.1021,  2.2626, -0.2007],\n",
            "        [-2.1163,  0.6493,  1.1058],\n",
            "        [-1.9682,  2.1943, -0.5442],\n",
            "        [-2.0089,  1.4936,  0.2800],\n",
            "        [-1.8543,  1.9950, -0.0846],\n",
            "        [-2.0088,  0.5582,  1.0771]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0461,  1.8873, -0.0364],\n",
            "        [ 0.5654, -0.0161, -1.1706],\n",
            "        [-2.4040,  2.1617,  0.0133],\n",
            "        [-2.2205,  1.4452,  0.3742],\n",
            "        [-1.9424,  2.1596, -0.3335],\n",
            "        [ 0.3149,  0.1999, -1.0837],\n",
            "        [-2.2971,  2.0980, -0.1576],\n",
            "        [-2.0962,  2.2517, -0.1459],\n",
            "        [-1.9324,  2.1573, -0.4309],\n",
            "        [-2.1800,  1.8267, -0.0452],\n",
            "        [-2.1021,  2.2626, -0.2007],\n",
            "        [-2.1163,  0.6493,  1.1058],\n",
            "        [-1.9682,  2.1943, -0.5442],\n",
            "        [-2.0089,  1.4936,  0.2800],\n",
            "        [-1.8543,  1.9950, -0.0846],\n",
            "        [-2.0088,  0.5582,  1.0771]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2311,  2.2924, -0.0979],\n",
            "        [-2.1339,  1.1902,  0.8105],\n",
            "        [-2.1072,  1.8472, -0.0532],\n",
            "        [-2.1660,  1.7961,  0.3066],\n",
            "        [-1.8965,  2.1118, -0.0910],\n",
            "        [-1.9602,  1.7418,  0.1977],\n",
            "        [-2.1132,  1.0653,  0.7909],\n",
            "        [ 0.5655,  0.2005, -1.0329],\n",
            "        [-1.9815,  2.0200,  0.1004],\n",
            "        [-2.3077,  1.2203,  0.7309],\n",
            "        [-2.2247,  2.1043, -0.2468],\n",
            "        [-2.4094,  1.7049,  0.2608],\n",
            "        [-2.1585,  2.0884, -0.0328],\n",
            "        [-2.2957,  1.2068,  0.8818],\n",
            "        [-2.4039,  2.5237, -0.0969],\n",
            "        [-2.1418,  2.2364, -0.2148]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.2311,  2.2924, -0.0979],\n",
            "        [-2.1339,  1.1902,  0.8105],\n",
            "        [-2.1072,  1.8472, -0.0532],\n",
            "        [-2.1660,  1.7961,  0.3066],\n",
            "        [-1.8965,  2.1118, -0.0910],\n",
            "        [-1.9602,  1.7418,  0.1977],\n",
            "        [-2.1132,  1.0653,  0.7909],\n",
            "        [ 0.5655,  0.2005, -1.0329],\n",
            "        [-1.9815,  2.0200,  0.1004],\n",
            "        [-2.3077,  1.2203,  0.7309],\n",
            "        [-2.2247,  2.1043, -0.2468],\n",
            "        [-2.4094,  1.7049,  0.2608],\n",
            "        [-2.1585,  2.0884, -0.0328],\n",
            "        [-2.2957,  1.2068,  0.8818],\n",
            "        [-2.4039,  2.5237, -0.0969],\n",
            "        [-2.1418,  2.2364, -0.2148]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0514,  0.6662,  1.1864],\n",
            "        [-2.1052,  0.8191,  1.1464],\n",
            "        [-2.1782,  1.4664,  0.5983],\n",
            "        [-1.8814,  1.4883,  0.2837],\n",
            "        [-1.9664,  1.9789, -0.0793],\n",
            "        [-2.2037,  2.2837, -0.0764],\n",
            "        [-2.0827,  0.9767,  1.1097],\n",
            "        [-2.0337,  0.8569,  1.1035],\n",
            "        [-1.9473,  0.9536,  0.9050],\n",
            "        [-2.1211,  1.1948,  0.6980],\n",
            "        [-2.2588,  1.8803,  0.5365],\n",
            "        [-1.9671,  2.0398, -0.6185],\n",
            "        [-2.1604,  2.2070, -0.3986],\n",
            "        [-2.0854,  2.1482, -0.2190],\n",
            "        [-2.1742,  0.8104,  1.0711],\n",
            "        [-2.2619,  2.3461, -0.3685]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0514,  0.6662,  1.1864],\n",
            "        [-2.1052,  0.8191,  1.1464],\n",
            "        [-2.1782,  1.4664,  0.5983],\n",
            "        [-1.8814,  1.4883,  0.2837],\n",
            "        [-1.9664,  1.9789, -0.0793],\n",
            "        [-2.2037,  2.2837, -0.0764],\n",
            "        [-2.0827,  0.9767,  1.1097],\n",
            "        [-2.0337,  0.8569,  1.1035],\n",
            "        [-1.9473,  0.9536,  0.9050],\n",
            "        [-2.1211,  1.1948,  0.6980],\n",
            "        [-2.2588,  1.8803,  0.5365],\n",
            "        [-1.9671,  2.0398, -0.6185],\n",
            "        [-2.1604,  2.2070, -0.3986],\n",
            "        [-2.0854,  2.1482, -0.2190],\n",
            "        [-2.1742,  0.8104,  1.0711],\n",
            "        [-2.2619,  2.3461, -0.3685]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9139,  2.3562, -0.3512],\n",
            "        [-1.9667,  1.8563,  0.0505],\n",
            "        [-1.9987,  2.1860, -0.2676],\n",
            "        [-0.6239,  0.4432, -0.2084],\n",
            "        [-2.2130,  1.2175,  0.8662],\n",
            "        [-2.0642,  1.9791, -0.0683],\n",
            "        [ 0.1922,  0.3218, -1.3173],\n",
            "        [-2.1448,  1.4505,  0.5662],\n",
            "        [-2.0784,  2.1678, -0.3641],\n",
            "        [-2.2039,  1.1320,  0.9414],\n",
            "        [-1.8273,  1.8800, -0.6838],\n",
            "        [-2.1827,  0.7395,  1.2455],\n",
            "        [-1.8658,  2.0844, -0.4931],\n",
            "        [-1.7452,  1.1743,  0.2445],\n",
            "        [-2.0302,  0.9575,  0.8273],\n",
            "        [-2.0712,  1.9055,  0.1502]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9139,  2.3562, -0.3512],\n",
            "        [-1.9667,  1.8563,  0.0505],\n",
            "        [-1.9987,  2.1860, -0.2676],\n",
            "        [-0.6239,  0.4432, -0.2084],\n",
            "        [-2.2130,  1.2175,  0.8662],\n",
            "        [-2.0642,  1.9791, -0.0683],\n",
            "        [ 0.1922,  0.3218, -1.3173],\n",
            "        [-2.1448,  1.4505,  0.5662],\n",
            "        [-2.0784,  2.1678, -0.3641],\n",
            "        [-2.2039,  1.1320,  0.9414],\n",
            "        [-1.8273,  1.8800, -0.6838],\n",
            "        [-2.1827,  0.7395,  1.2455],\n",
            "        [-1.8658,  2.0844, -0.4931],\n",
            "        [-1.7452,  1.1743,  0.2445],\n",
            "        [-2.0302,  0.9575,  0.8273],\n",
            "        [-2.0712,  1.9055,  0.1502]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8872,  2.0606, -0.3291],\n",
            "        [-1.8652,  1.8234, -0.1162],\n",
            "        [-1.9690,  2.1481, -0.5070],\n",
            "        [-2.0818,  1.3793,  0.6021],\n",
            "        [-2.3498,  1.5257,  0.3367],\n",
            "        [-1.8268,  1.6793,  0.0298],\n",
            "        [-2.0159,  1.7237,  0.2037],\n",
            "        [-1.9626,  1.4966,  0.3514],\n",
            "        [-2.0640,  1.0937,  0.9625],\n",
            "        [-1.8647,  2.1453, -0.5299],\n",
            "        [-2.1262,  2.2139, -0.1734],\n",
            "        [-1.9311,  2.0216, -0.4322],\n",
            "        [-2.0273,  2.1460, -0.2385],\n",
            "        [-2.0349,  2.3183, -0.3803],\n",
            "        [-2.2478,  2.1753, -0.3013],\n",
            "        [-1.6922,  2.2639, -0.4232]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8872,  2.0606, -0.3291],\n",
            "        [-1.8652,  1.8234, -0.1162],\n",
            "        [-1.9690,  2.1481, -0.5070],\n",
            "        [-2.0818,  1.3793,  0.6021],\n",
            "        [-2.3498,  1.5257,  0.3367],\n",
            "        [-1.8268,  1.6793,  0.0298],\n",
            "        [-2.0159,  1.7237,  0.2037],\n",
            "        [-1.9626,  1.4966,  0.3514],\n",
            "        [-2.0640,  1.0937,  0.9625],\n",
            "        [-1.8647,  2.1453, -0.5299],\n",
            "        [-2.1262,  2.2139, -0.1734],\n",
            "        [-1.9311,  2.0216, -0.4322],\n",
            "        [-2.0273,  2.1460, -0.2385],\n",
            "        [-2.0349,  2.3183, -0.3803],\n",
            "        [-2.2478,  2.1753, -0.3013],\n",
            "        [-1.6922,  2.2639, -0.4232]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9388,  2.0164, -0.3205],\n",
            "        [-2.2213,  0.8662,  1.1237],\n",
            "        [-2.0232,  2.1687, -0.1584],\n",
            "        [-2.1688,  1.0352,  0.6610],\n",
            "        [-1.5711,  2.1260, -0.6315],\n",
            "        [-2.2254,  0.8573,  1.2324],\n",
            "        [-1.9958,  2.0835, -0.1847],\n",
            "        [-1.9909,  2.1869, -0.4229],\n",
            "        [-2.2793,  0.9579,  0.7563],\n",
            "        [ 0.3219,  0.4891, -1.0127],\n",
            "        [-1.7119,  1.4762, -0.1566],\n",
            "        [-2.2053,  1.5150,  0.5140],\n",
            "        [ 0.3231,  0.1925, -1.1793],\n",
            "        [-2.3670,  1.0121,  0.9579],\n",
            "        [-1.8595,  2.2625, -0.2969],\n",
            "        [-1.7776,  1.8497, -0.2427]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9388,  2.0164, -0.3205],\n",
            "        [-2.2213,  0.8662,  1.1237],\n",
            "        [-2.0232,  2.1687, -0.1584],\n",
            "        [-2.1688,  1.0352,  0.6610],\n",
            "        [-1.5711,  2.1260, -0.6315],\n",
            "        [-2.2254,  0.8573,  1.2324],\n",
            "        [-1.9958,  2.0835, -0.1847],\n",
            "        [-1.9909,  2.1869, -0.4229],\n",
            "        [-2.2793,  0.9579,  0.7563],\n",
            "        [ 0.3219,  0.4891, -1.0127],\n",
            "        [-1.7119,  1.4762, -0.1566],\n",
            "        [-2.2053,  1.5150,  0.5140],\n",
            "        [ 0.3231,  0.1925, -1.1793],\n",
            "        [-2.3670,  1.0121,  0.9579],\n",
            "        [-1.8595,  2.2625, -0.2969],\n",
            "        [-1.7776,  1.8497, -0.2427]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.8686,  1.0871, -1.0531],\n",
            "        [-2.1283,  0.8494,  1.1733],\n",
            "        [ 0.2223,  0.3207, -1.1602],\n",
            "        [-1.9464,  1.0830,  0.9907],\n",
            "        [ 0.5824,  0.1679, -1.0490],\n",
            "        [-2.2349,  1.5490,  0.5563],\n",
            "        [-1.9089,  1.7658,  0.0983],\n",
            "        [-1.7387,  2.1923, -0.4414],\n",
            "        [ 0.4879,  0.0481, -1.2778],\n",
            "        [-2.2017,  1.9462, -0.2898],\n",
            "        [-2.0897,  0.7600,  1.4555],\n",
            "        [-1.9588,  1.9699, -0.4351],\n",
            "        [-2.0103,  2.0239,  0.0034],\n",
            "        [-2.2882,  1.9479,  0.3035],\n",
            "        [-1.9978,  1.9574,  0.0646],\n",
            "        [-2.1032,  1.3513,  0.6440]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-0.8686,  1.0871, -1.0531],\n",
            "        [-2.1283,  0.8494,  1.1733],\n",
            "        [ 0.2223,  0.3207, -1.1602],\n",
            "        [-1.9464,  1.0830,  0.9907],\n",
            "        [ 0.5824,  0.1679, -1.0490],\n",
            "        [-2.2349,  1.5490,  0.5563],\n",
            "        [-1.9089,  1.7658,  0.0983],\n",
            "        [-1.7387,  2.1923, -0.4414],\n",
            "        [ 0.4879,  0.0481, -1.2778],\n",
            "        [-2.2017,  1.9462, -0.2898],\n",
            "        [-2.0897,  0.7600,  1.4555],\n",
            "        [-1.9588,  1.9699, -0.4351],\n",
            "        [-2.0103,  2.0239,  0.0034],\n",
            "        [-2.2882,  1.9479,  0.3035],\n",
            "        [-1.9978,  1.9574,  0.0646],\n",
            "        [-2.1032,  1.3513,  0.6440]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7189,  2.0344, -0.3572],\n",
            "        [-2.2466,  0.7972,  1.2925],\n",
            "        [-2.2966,  0.6322,  1.3553],\n",
            "        [-1.7663,  1.9830, -0.0770],\n",
            "        [-1.9963,  2.2055, -0.4502],\n",
            "        [ 0.4413,  0.1240, -1.1291],\n",
            "        [-2.0067,  0.8859,  0.9538],\n",
            "        [-1.7986,  2.0446, -0.4022],\n",
            "        [ 0.2777,  0.2000, -1.0955],\n",
            "        [-2.0470,  1.8594,  0.1087],\n",
            "        [-1.9738,  2.0176, -0.4938],\n",
            "        [-2.3844,  2.0454,  0.0254],\n",
            "        [-2.0686,  1.6555,  0.0998],\n",
            "        [ 0.4743,  0.1123, -1.2973],\n",
            "        [-1.9361,  0.7926,  0.9768],\n",
            "        [-2.0946,  0.7633,  1.3169]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7189,  2.0344, -0.3572],\n",
            "        [-2.2466,  0.7972,  1.2925],\n",
            "        [-2.2966,  0.6322,  1.3553],\n",
            "        [-1.7663,  1.9830, -0.0770],\n",
            "        [-1.9963,  2.2055, -0.4502],\n",
            "        [ 0.4413,  0.1240, -1.1291],\n",
            "        [-2.0067,  0.8859,  0.9538],\n",
            "        [-1.7986,  2.0446, -0.4022],\n",
            "        [ 0.2777,  0.2000, -1.0955],\n",
            "        [-2.0470,  1.8594,  0.1087],\n",
            "        [-1.9738,  2.0176, -0.4938],\n",
            "        [-2.3844,  2.0454,  0.0254],\n",
            "        [-2.0686,  1.6555,  0.0998],\n",
            "        [ 0.4743,  0.1123, -1.2973],\n",
            "        [-1.9361,  0.7926,  0.9768],\n",
            "        [-2.0946,  0.7633,  1.3169]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7154,  1.9449, -0.3431],\n",
            "        [-1.8105,  2.0477, -0.2544],\n",
            "        [-1.8874,  2.3700, -0.5358],\n",
            "        [-2.2082,  0.6538,  0.9779],\n",
            "        [-2.4088,  1.9239,  0.1366],\n",
            "        [-2.3036,  0.8239,  1.2682],\n",
            "        [-2.0500,  2.0913, -0.1734],\n",
            "        [-2.0138,  1.8660, -0.2755],\n",
            "        [-2.1912,  0.8106,  1.1464],\n",
            "        [-1.6172,  1.4804, -0.2241],\n",
            "        [-1.8160,  2.0625, -0.4677],\n",
            "        [-2.0589,  0.8034,  1.1179],\n",
            "        [-2.1970,  0.7355,  0.9959],\n",
            "        [-2.0698,  1.7817, -0.3276],\n",
            "        [-1.9610,  2.0590, -0.2073],\n",
            "        [-1.8235,  2.1269, -0.4578]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7154,  1.9449, -0.3431],\n",
            "        [-1.8105,  2.0477, -0.2544],\n",
            "        [-1.8874,  2.3700, -0.5358],\n",
            "        [-2.2082,  0.6538,  0.9779],\n",
            "        [-2.4088,  1.9239,  0.1366],\n",
            "        [-2.3036,  0.8239,  1.2682],\n",
            "        [-2.0500,  2.0913, -0.1734],\n",
            "        [-2.0138,  1.8660, -0.2755],\n",
            "        [-2.1912,  0.8106,  1.1464],\n",
            "        [-1.6172,  1.4804, -0.2241],\n",
            "        [-1.8160,  2.0625, -0.4677],\n",
            "        [-2.0589,  0.8034,  1.1179],\n",
            "        [-2.1970,  0.7355,  0.9959],\n",
            "        [-2.0698,  1.7817, -0.3276],\n",
            "        [-1.9610,  2.0590, -0.2073],\n",
            "        [-1.8235,  2.1269, -0.4578]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1970,  0.5930,  1.0666],\n",
            "        [-1.9896,  1.9537, -0.0040],\n",
            "        [-2.0595,  1.8562, -0.0367],\n",
            "        [-1.9353,  1.9823,  0.0869],\n",
            "        [-2.1829,  1.8686,  0.3783],\n",
            "        [-1.9221,  1.8241,  0.0532],\n",
            "        [-1.9347,  1.8213,  0.0580],\n",
            "        [-1.6863,  1.8631, -0.1141],\n",
            "        [-2.0152,  1.7506, -0.2285],\n",
            "        [-1.6510,  1.9609, -0.0419],\n",
            "        [-2.1363,  1.4063,  0.6277],\n",
            "        [-2.0481,  2.1436, -0.1913],\n",
            "        [-1.6951,  2.0708, -0.3254],\n",
            "        [-2.0578,  2.0421, -0.1338],\n",
            "        [-1.6647,  2.0276, -0.3033],\n",
            "        [-1.8332,  1.9415, -0.1836]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1970,  0.5930,  1.0666],\n",
            "        [-1.9896,  1.9537, -0.0040],\n",
            "        [-2.0595,  1.8562, -0.0367],\n",
            "        [-1.9353,  1.9823,  0.0869],\n",
            "        [-2.1829,  1.8686,  0.3783],\n",
            "        [-1.9221,  1.8241,  0.0532],\n",
            "        [-1.9347,  1.8213,  0.0580],\n",
            "        [-1.6863,  1.8631, -0.1141],\n",
            "        [-2.0152,  1.7506, -0.2285],\n",
            "        [-1.6510,  1.9609, -0.0419],\n",
            "        [-2.1363,  1.4063,  0.6277],\n",
            "        [-2.0481,  2.1436, -0.1913],\n",
            "        [-1.6951,  2.0708, -0.3254],\n",
            "        [-2.0578,  2.0421, -0.1338],\n",
            "        [-1.6647,  2.0276, -0.3033],\n",
            "        [-1.8332,  1.9415, -0.1836]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2087,  0.7629,  1.0986],\n",
            "        [-1.6403,  2.0309, -0.1931],\n",
            "        [-1.8835,  1.9050, -0.1246],\n",
            "        [ 0.5479, -0.0344, -1.1814],\n",
            "        [-2.1120,  0.4799,  1.2377],\n",
            "        [-1.9582,  1.5319,  0.1563],\n",
            "        [-1.9804,  1.7348, -0.1086],\n",
            "        [-2.2280,  0.7240,  0.9942],\n",
            "        [-2.0100,  0.5300,  1.1412],\n",
            "        [-2.1200,  2.0063,  0.2847],\n",
            "        [-2.0005,  2.1343, -0.0097],\n",
            "        [-2.0915,  1.3479,  0.4842],\n",
            "        [-2.2187,  0.7657,  1.3719],\n",
            "        [-1.8058,  1.6183,  0.4307],\n",
            "        [-2.0920,  0.5567,  1.3353],\n",
            "        [-1.9170,  1.5540,  0.1022]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.2087,  0.7629,  1.0986],\n",
            "        [-1.6403,  2.0309, -0.1931],\n",
            "        [-1.8835,  1.9050, -0.1246],\n",
            "        [ 0.5479, -0.0344, -1.1814],\n",
            "        [-2.1120,  0.4799,  1.2377],\n",
            "        [-1.9582,  1.5319,  0.1563],\n",
            "        [-1.9804,  1.7348, -0.1086],\n",
            "        [-2.2280,  0.7240,  0.9942],\n",
            "        [-2.0100,  0.5300,  1.1412],\n",
            "        [-2.1200,  2.0063,  0.2847],\n",
            "        [-2.0005,  2.1343, -0.0097],\n",
            "        [-2.0915,  1.3479,  0.4842],\n",
            "        [-2.2187,  0.7657,  1.3719],\n",
            "        [-1.8058,  1.6183,  0.4307],\n",
            "        [-2.0920,  0.5567,  1.3353],\n",
            "        [-1.9170,  1.5540,  0.1022]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0278,  1.8908, -0.2736],\n",
            "        [-1.3840,  1.9021, -0.2669],\n",
            "        [-2.0637,  1.7744,  0.0559],\n",
            "        [-2.2556,  0.6597,  1.3678],\n",
            "        [-1.9330,  2.0550, -0.1579],\n",
            "        [-1.6871,  1.8936, -0.1408],\n",
            "        [-1.7916,  1.3348,  0.1654],\n",
            "        [ 0.0492, -0.0736, -0.8351],\n",
            "        [-1.8045,  2.0300,  0.0110],\n",
            "        [-2.0068,  0.6566,  1.1385],\n",
            "        [-1.8764,  1.8574, -0.3144],\n",
            "        [-1.5660,  1.7840, -0.1910],\n",
            "        [-1.7235,  1.6467, -0.0088],\n",
            "        [-2.3584,  0.5117,  1.2204],\n",
            "        [-1.8502,  1.7716, -0.2059],\n",
            "        [-1.8308,  1.8270,  0.0588]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0278,  1.8908, -0.2736],\n",
            "        [-1.3840,  1.9021, -0.2669],\n",
            "        [-2.0637,  1.7744,  0.0559],\n",
            "        [-2.2556,  0.6597,  1.3678],\n",
            "        [-1.9330,  2.0550, -0.1579],\n",
            "        [-1.6871,  1.8936, -0.1408],\n",
            "        [-1.7916,  1.3348,  0.1654],\n",
            "        [ 0.0492, -0.0736, -0.8351],\n",
            "        [-1.8045,  2.0300,  0.0110],\n",
            "        [-2.0068,  0.6566,  1.1385],\n",
            "        [-1.8764,  1.8574, -0.3144],\n",
            "        [-1.5660,  1.7840, -0.1910],\n",
            "        [-1.7235,  1.6467, -0.0088],\n",
            "        [-2.3584,  0.5117,  1.2204],\n",
            "        [-1.8502,  1.7716, -0.2059],\n",
            "        [-1.8308,  1.8270,  0.0588]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3042,  0.0834, -1.0186],\n",
            "        [ 0.5261,  0.2989, -1.0544],\n",
            "        [ 0.0732,  0.1672, -0.8858],\n",
            "        [-2.2367,  1.4680,  0.7288],\n",
            "        [-2.0157,  1.0832,  0.8136],\n",
            "        [-2.0268,  0.5264,  1.3172],\n",
            "        [-2.0650,  0.6487,  1.3167],\n",
            "        [-2.2156,  0.4208,  1.4343],\n",
            "        [-1.9827,  1.3227,  0.5005],\n",
            "        [-1.6410,  1.5831, -0.1982],\n",
            "        [ 0.0243,  0.5582, -1.2556],\n",
            "        [-2.2211,  0.5077,  1.4161],\n",
            "        [-2.1026,  1.3324,  0.5239],\n",
            "        [-1.9045,  1.6342,  0.1501],\n",
            "        [-2.1811,  0.7340,  1.1671],\n",
            "        [-1.8886,  1.8908, -0.0637]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.3042,  0.0834, -1.0186],\n",
            "        [ 0.5261,  0.2989, -1.0544],\n",
            "        [ 0.0732,  0.1672, -0.8858],\n",
            "        [-2.2367,  1.4680,  0.7288],\n",
            "        [-2.0157,  1.0832,  0.8136],\n",
            "        [-2.0268,  0.5264,  1.3172],\n",
            "        [-2.0650,  0.6487,  1.3167],\n",
            "        [-2.2156,  0.4208,  1.4343],\n",
            "        [-1.9827,  1.3227,  0.5005],\n",
            "        [-1.6410,  1.5831, -0.1982],\n",
            "        [ 0.0243,  0.5582, -1.2556],\n",
            "        [-2.2211,  0.5077,  1.4161],\n",
            "        [-2.1026,  1.3324,  0.5239],\n",
            "        [-1.9045,  1.6342,  0.1501],\n",
            "        [-2.1811,  0.7340,  1.1671],\n",
            "        [-1.8886,  1.8908, -0.0637]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2261,  0.8265,  1.0314],\n",
            "        [-1.8933,  1.7015,  0.0422],\n",
            "        [-1.8279,  1.7596,  0.1928],\n",
            "        [ 0.2714,  0.1915, -1.2193],\n",
            "        [-1.9945,  0.3763,  1.2884],\n",
            "        [ 0.3528,  0.1377, -1.1414],\n",
            "        [-2.0828,  0.7120,  1.0043],\n",
            "        [-1.9875,  1.6742, -0.0034],\n",
            "        [-2.4305,  0.4432,  1.1049],\n",
            "        [-2.0035,  2.0194, -0.2675],\n",
            "        [-2.1909,  1.3040,  0.8690],\n",
            "        [-2.0237,  1.6685,  0.4271],\n",
            "        [-0.7284,  0.8303, -0.6147],\n",
            "        [-1.8342,  1.9407, -0.1105],\n",
            "        [-0.9474,  0.6769,  0.0580],\n",
            "        [-1.4441,  1.4388, -0.4503]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.2261,  0.8265,  1.0314],\n",
            "        [-1.8933,  1.7015,  0.0422],\n",
            "        [-1.8279,  1.7596,  0.1928],\n",
            "        [ 0.2714,  0.1915, -1.2193],\n",
            "        [-1.9945,  0.3763,  1.2884],\n",
            "        [ 0.3528,  0.1377, -1.1414],\n",
            "        [-2.0828,  0.7120,  1.0043],\n",
            "        [-1.9875,  1.6742, -0.0034],\n",
            "        [-2.4305,  0.4432,  1.1049],\n",
            "        [-2.0035,  2.0194, -0.2675],\n",
            "        [-2.1909,  1.3040,  0.8690],\n",
            "        [-2.0237,  1.6685,  0.4271],\n",
            "        [-0.7284,  0.8303, -0.6147],\n",
            "        [-1.8342,  1.9407, -0.1105],\n",
            "        [-0.9474,  0.6769,  0.0580],\n",
            "        [-1.4441,  1.4388, -0.4503]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1482,  1.6674,  0.2930],\n",
            "        [-1.7846,  1.7235, -0.1688],\n",
            "        [-2.1723,  0.5135,  1.1611],\n",
            "        [-2.0015,  1.1555,  0.7705],\n",
            "        [-2.1270,  0.6100,  1.3642],\n",
            "        [-1.8389,  1.1873,  0.4985],\n",
            "        [-1.3353,  1.9103, -0.7445],\n",
            "        [-2.2503,  0.9338,  0.8591],\n",
            "        [-1.7451,  1.8111, -0.3168],\n",
            "        [-1.9300,  0.4947,  1.0909],\n",
            "        [ 0.4307,  0.1548, -1.0834],\n",
            "        [-1.7191,  1.9828, -0.5884],\n",
            "        [-1.9049,  1.8715,  0.0687],\n",
            "        [-2.2866,  0.6291,  1.2506],\n",
            "        [-1.3070,  1.7469, -0.3807],\n",
            "        [-2.1939,  0.7004,  1.1158]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1482,  1.6674,  0.2930],\n",
            "        [-1.7846,  1.7235, -0.1688],\n",
            "        [-2.1723,  0.5135,  1.1611],\n",
            "        [-2.0015,  1.1555,  0.7705],\n",
            "        [-2.1270,  0.6100,  1.3642],\n",
            "        [-1.8389,  1.1873,  0.4985],\n",
            "        [-1.3353,  1.9103, -0.7445],\n",
            "        [-2.2503,  0.9338,  0.8591],\n",
            "        [-1.7451,  1.8111, -0.3168],\n",
            "        [-1.9300,  0.4947,  1.0909],\n",
            "        [ 0.4307,  0.1548, -1.0834],\n",
            "        [-1.7191,  1.9828, -0.5884],\n",
            "        [-1.9049,  1.8715,  0.0687],\n",
            "        [-2.2866,  0.6291,  1.2506],\n",
            "        [-1.3070,  1.7469, -0.3807],\n",
            "        [-2.1939,  0.7004,  1.1158]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7744e+00,  1.7364e+00, -6.3627e-04],\n",
            "        [-1.9365e+00,  1.7298e+00,  5.1011e-02],\n",
            "        [-2.3246e+00,  6.3141e-01,  1.1653e+00],\n",
            "        [-1.7655e+00,  1.8608e+00, -1.8253e-01],\n",
            "        [-1.7896e+00,  1.4309e+00,  4.0192e-01],\n",
            "        [-2.2204e+00,  8.0701e-01,  1.3499e+00],\n",
            "        [-1.9006e+00,  1.2636e+00,  6.4173e-01],\n",
            "        [-2.2342e+00,  4.2685e-01,  1.4329e+00],\n",
            "        [-2.0919e+00,  1.2427e+00,  5.8822e-01],\n",
            "        [-1.9874e+00,  6.0888e-01,  1.2794e+00],\n",
            "        [-1.7835e+00,  1.6690e+00, -2.7327e-01],\n",
            "        [-1.4783e+00,  1.6507e+00, -5.4078e-01],\n",
            "        [-1.5066e+00,  1.7956e+00, -3.4990e-01],\n",
            "        [-1.9172e+00,  1.4412e+00,  5.6498e-02],\n",
            "        [ 4.2814e-01,  6.6264e-02, -1.0610e+00],\n",
            "        [-2.0578e+00,  9.6868e-01,  8.9048e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7744e+00,  1.7364e+00, -6.3627e-04],\n",
            "        [-1.9365e+00,  1.7298e+00,  5.1011e-02],\n",
            "        [-2.3246e+00,  6.3141e-01,  1.1653e+00],\n",
            "        [-1.7655e+00,  1.8608e+00, -1.8253e-01],\n",
            "        [-1.7896e+00,  1.4309e+00,  4.0192e-01],\n",
            "        [-2.2204e+00,  8.0701e-01,  1.3499e+00],\n",
            "        [-1.9006e+00,  1.2636e+00,  6.4173e-01],\n",
            "        [-2.2342e+00,  4.2685e-01,  1.4329e+00],\n",
            "        [-2.0919e+00,  1.2427e+00,  5.8822e-01],\n",
            "        [-1.9874e+00,  6.0888e-01,  1.2794e+00],\n",
            "        [-1.7835e+00,  1.6690e+00, -2.7327e-01],\n",
            "        [-1.4783e+00,  1.6507e+00, -5.4078e-01],\n",
            "        [-1.5066e+00,  1.7956e+00, -3.4990e-01],\n",
            "        [-1.9172e+00,  1.4412e+00,  5.6498e-02],\n",
            "        [ 4.2814e-01,  6.6264e-02, -1.0610e+00],\n",
            "        [-2.0578e+00,  9.6868e-01,  8.9048e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.4371,  0.1817, -1.2157],\n",
            "        [-1.9783,  0.5664,  1.3216],\n",
            "        [-1.5641,  1.9293, -0.4354],\n",
            "        [-1.7390,  1.5558,  0.2335],\n",
            "        [-1.6193,  1.7487, -0.2610],\n",
            "        [-1.6541,  1.7739, -0.0443],\n",
            "        [-1.6481,  1.6558, -0.1084],\n",
            "        [-1.7813,  1.8264, -0.3801],\n",
            "        [ 0.6431,  0.1650, -1.2940],\n",
            "        [-2.3928,  0.6681,  1.3511],\n",
            "        [-2.0799,  0.7426,  1.0916],\n",
            "        [-1.8469,  1.5887,  0.2574],\n",
            "        [-1.9951,  1.7347,  0.1130],\n",
            "        [-2.1654,  0.3064,  1.3908],\n",
            "        [-1.7673,  1.8243, -0.3023],\n",
            "        [-1.5140,  1.7581, -0.2221]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.4371,  0.1817, -1.2157],\n",
            "        [-1.9783,  0.5664,  1.3216],\n",
            "        [-1.5641,  1.9293, -0.4354],\n",
            "        [-1.7390,  1.5558,  0.2335],\n",
            "        [-1.6193,  1.7487, -0.2610],\n",
            "        [-1.6541,  1.7739, -0.0443],\n",
            "        [-1.6481,  1.6558, -0.1084],\n",
            "        [-1.7813,  1.8264, -0.3801],\n",
            "        [ 0.6431,  0.1650, -1.2940],\n",
            "        [-2.3928,  0.6681,  1.3511],\n",
            "        [-2.0799,  0.7426,  1.0916],\n",
            "        [-1.8469,  1.5887,  0.2574],\n",
            "        [-1.9951,  1.7347,  0.1130],\n",
            "        [-2.1654,  0.3064,  1.3908],\n",
            "        [-1.7673,  1.8243, -0.3023],\n",
            "        [-1.5140,  1.7581, -0.2221]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7700,  2.1070, -0.4344],\n",
            "        [-2.0502,  0.8251,  1.2017],\n",
            "        [-1.9414,  1.1882,  0.6461],\n",
            "        [-2.0006,  0.6326,  1.1504],\n",
            "        [-1.5521,  1.7761, -0.3503],\n",
            "        [-1.6646,  1.8528, -0.4455],\n",
            "        [ 0.4389,  0.1613, -1.1754],\n",
            "        [-2.0899,  0.8782,  0.9366],\n",
            "        [-2.0900,  0.4649,  1.2380],\n",
            "        [-2.0120,  1.6263,  0.2856],\n",
            "        [ 0.5829,  0.1119, -1.3963],\n",
            "        [-1.8621,  1.8334, -0.3072],\n",
            "        [-2.0085,  1.4782,  0.1588],\n",
            "        [-1.8724,  1.7935, -0.0454],\n",
            "        [-1.6974,  1.6192, -0.0245],\n",
            "        [-1.5445,  1.8455, -0.4327]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7700,  2.1070, -0.4344],\n",
            "        [-2.0502,  0.8251,  1.2017],\n",
            "        [-1.9414,  1.1882,  0.6461],\n",
            "        [-2.0006,  0.6326,  1.1504],\n",
            "        [-1.5521,  1.7761, -0.3503],\n",
            "        [-1.6646,  1.8528, -0.4455],\n",
            "        [ 0.4389,  0.1613, -1.1754],\n",
            "        [-2.0899,  0.8782,  0.9366],\n",
            "        [-2.0900,  0.4649,  1.2380],\n",
            "        [-2.0120,  1.6263,  0.2856],\n",
            "        [ 0.5829,  0.1119, -1.3963],\n",
            "        [-1.8621,  1.8334, -0.3072],\n",
            "        [-2.0085,  1.4782,  0.1588],\n",
            "        [-1.8724,  1.7935, -0.0454],\n",
            "        [-1.6974,  1.6192, -0.0245],\n",
            "        [-1.5445,  1.8455, -0.4327]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0680,  0.3846,  1.2530],\n",
            "        [ 0.6308,  0.0650, -1.2821],\n",
            "        [-1.7752,  1.5327,  0.0805],\n",
            "        [-1.9280,  0.5050,  1.3407],\n",
            "        [-2.0894,  0.4448,  1.2733],\n",
            "        [ 0.6226,  0.2591, -1.3792],\n",
            "        [-1.4537,  1.7601, -0.2921],\n",
            "        [-2.0502,  0.5032,  1.3378],\n",
            "        [ 0.7016, -0.0450, -1.2358],\n",
            "        [-2.1957,  0.4968,  1.4407],\n",
            "        [-1.5155,  1.8496, -0.2407],\n",
            "        [ 0.3676, -0.0127, -1.1029],\n",
            "        [-1.4867,  1.6405, -0.4090],\n",
            "        [-1.5140,  1.5658, -0.0469],\n",
            "        [-1.8889,  1.5298,  0.2135],\n",
            "        [-2.0844,  0.5865,  1.2108]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0680,  0.3846,  1.2530],\n",
            "        [ 0.6308,  0.0650, -1.2821],\n",
            "        [-1.7752,  1.5327,  0.0805],\n",
            "        [-1.9280,  0.5050,  1.3407],\n",
            "        [-2.0894,  0.4448,  1.2733],\n",
            "        [ 0.6226,  0.2591, -1.3792],\n",
            "        [-1.4537,  1.7601, -0.2921],\n",
            "        [-2.0502,  0.5032,  1.3378],\n",
            "        [ 0.7016, -0.0450, -1.2358],\n",
            "        [-2.1957,  0.4968,  1.4407],\n",
            "        [-1.5155,  1.8496, -0.2407],\n",
            "        [ 0.3676, -0.0127, -1.1029],\n",
            "        [-1.4867,  1.6405, -0.4090],\n",
            "        [-1.5140,  1.5658, -0.0469],\n",
            "        [-1.8889,  1.5298,  0.2135],\n",
            "        [-2.0844,  0.5865,  1.2108]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4275,  1.8857, -0.5434],\n",
            "        [-1.5677,  1.8403, -0.3143],\n",
            "        [-1.6145,  1.4749, -0.0973],\n",
            "        [ 0.3514,  0.3503, -1.2969],\n",
            "        [-1.5124,  1.5743, -0.2030],\n",
            "        [-2.2980,  0.6132,  1.1091],\n",
            "        [-1.9034,  1.7228,  0.0600],\n",
            "        [-1.4194,  1.5877, -0.2764],\n",
            "        [-2.0004,  0.8539,  0.8033],\n",
            "        [-1.9444,  1.1276,  0.7114],\n",
            "        [-2.2329,  1.1517,  1.0604],\n",
            "        [-2.0356,  0.6334,  1.1168],\n",
            "        [-2.2653,  0.4814,  1.2836],\n",
            "        [-1.8935,  2.0770, -0.1364],\n",
            "        [-1.4758,  1.4741,  0.1013],\n",
            "        [-2.1497,  0.3690,  1.3492]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4275,  1.8857, -0.5434],\n",
            "        [-1.5677,  1.8403, -0.3143],\n",
            "        [-1.6145,  1.4749, -0.0973],\n",
            "        [ 0.3514,  0.3503, -1.2969],\n",
            "        [-1.5124,  1.5743, -0.2030],\n",
            "        [-2.2980,  0.6132,  1.1091],\n",
            "        [-1.9034,  1.7228,  0.0600],\n",
            "        [-1.4194,  1.5877, -0.2764],\n",
            "        [-2.0004,  0.8539,  0.8033],\n",
            "        [-1.9444,  1.1276,  0.7114],\n",
            "        [-2.2329,  1.1517,  1.0604],\n",
            "        [-2.0356,  0.6334,  1.1168],\n",
            "        [-2.2653,  0.4814,  1.2836],\n",
            "        [-1.8935,  2.0770, -0.1364],\n",
            "        [-1.4758,  1.4741,  0.1013],\n",
            "        [-2.1497,  0.3690,  1.3492]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6036,  1.7754, -0.3838],\n",
            "        [-1.6627,  1.4591,  0.3960],\n",
            "        [-2.1452,  0.7919,  1.1798],\n",
            "        [-1.5158,  1.5349, -0.3259],\n",
            "        [-1.5010,  1.6189, -0.3564],\n",
            "        [-1.7613,  0.7688,  0.7064],\n",
            "        [-1.6792,  1.8220, -0.2262],\n",
            "        [-1.4458,  1.6376, -0.3246],\n",
            "        [-1.8705,  0.4658,  1.2202],\n",
            "        [-1.4303,  1.5731, -0.0331],\n",
            "        [-1.5753,  1.4748, -0.1590],\n",
            "        [-2.1266,  0.5016,  1.1647],\n",
            "        [ 0.8696, -0.0408, -1.2907],\n",
            "        [-2.1133,  0.5985,  1.3193],\n",
            "        [-1.1906,  1.9480, -0.4931],\n",
            "        [-1.3779,  1.6936, -0.4467]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6036,  1.7754, -0.3838],\n",
            "        [-1.6627,  1.4591,  0.3960],\n",
            "        [-2.1452,  0.7919,  1.1798],\n",
            "        [-1.5158,  1.5349, -0.3259],\n",
            "        [-1.5010,  1.6189, -0.3564],\n",
            "        [-1.7613,  0.7688,  0.7064],\n",
            "        [-1.6792,  1.8220, -0.2262],\n",
            "        [-1.4458,  1.6376, -0.3246],\n",
            "        [-1.8705,  0.4658,  1.2202],\n",
            "        [-1.4303,  1.5731, -0.0331],\n",
            "        [-1.5753,  1.4748, -0.1590],\n",
            "        [-2.1266,  0.5016,  1.1647],\n",
            "        [ 0.8696, -0.0408, -1.2907],\n",
            "        [-2.1133,  0.5985,  1.3193],\n",
            "        [-1.1906,  1.9480, -0.4931],\n",
            "        [-1.3779,  1.6936, -0.4467]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6430,  1.8200, -0.4528],\n",
            "        [-2.1152,  0.7125,  1.2232],\n",
            "        [-1.8913,  1.2449,  0.4786],\n",
            "        [-2.0824,  0.6900,  1.2677],\n",
            "        [-1.8490,  1.2789,  0.6043],\n",
            "        [-1.2817,  1.5467, -0.6196],\n",
            "        [-1.4578,  1.8085, -0.3809],\n",
            "        [-1.3479,  1.5987, -0.3484],\n",
            "        [ 0.8639, -0.0292, -1.1289],\n",
            "        [-1.6943,  1.0639,  0.2872],\n",
            "        [-1.3530,  1.6270, -0.3142],\n",
            "        [-2.1100,  0.5202,  1.3543],\n",
            "        [-1.4582,  1.7935, -0.5642],\n",
            "        [-2.1298,  0.4163,  1.4155],\n",
            "        [-1.6560,  1.5863, -0.2836],\n",
            "        [-1.3569,  1.4009, -0.0364]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6430,  1.8200, -0.4528],\n",
            "        [-2.1152,  0.7125,  1.2232],\n",
            "        [-1.8913,  1.2449,  0.4786],\n",
            "        [-2.0824,  0.6900,  1.2677],\n",
            "        [-1.8490,  1.2789,  0.6043],\n",
            "        [-1.2817,  1.5467, -0.6196],\n",
            "        [-1.4578,  1.8085, -0.3809],\n",
            "        [-1.3479,  1.5987, -0.3484],\n",
            "        [ 0.8639, -0.0292, -1.1289],\n",
            "        [-1.6943,  1.0639,  0.2872],\n",
            "        [-1.3530,  1.6270, -0.3142],\n",
            "        [-2.1100,  0.5202,  1.3543],\n",
            "        [-1.4582,  1.7935, -0.5642],\n",
            "        [-2.1298,  0.4163,  1.4155],\n",
            "        [-1.6560,  1.5863, -0.2836],\n",
            "        [-1.3569,  1.4009, -0.0364]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7091,  1.2747,  0.2455],\n",
            "        [-2.0644,  1.1379,  0.5544],\n",
            "        [-1.8658,  0.5972,  0.9914],\n",
            "        [-1.4446,  1.6457, -0.3790],\n",
            "        [-1.2427,  1.8800, -0.5873],\n",
            "        [-1.3875,  1.8957, -0.3655],\n",
            "        [ 0.6997,  0.0087, -1.4136],\n",
            "        [-1.4048,  1.9460, -0.6549],\n",
            "        [ 0.6836,  0.0296, -1.1335],\n",
            "        [-1.3977,  1.5744, -0.4604],\n",
            "        [-1.3797,  1.8501, -0.6644],\n",
            "        [-2.1322,  0.5232,  1.2318],\n",
            "        [-1.6985,  1.8314, -0.3480],\n",
            "        [-1.4587,  1.6165, -0.6113],\n",
            "        [-1.4979,  2.1582, -0.5309],\n",
            "        [-1.3282,  1.8292, -0.7027]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7091,  1.2747,  0.2455],\n",
            "        [-2.0644,  1.1379,  0.5544],\n",
            "        [-1.8658,  0.5972,  0.9914],\n",
            "        [-1.4446,  1.6457, -0.3790],\n",
            "        [-1.2427,  1.8800, -0.5873],\n",
            "        [-1.3875,  1.8957, -0.3655],\n",
            "        [ 0.6997,  0.0087, -1.4136],\n",
            "        [-1.4048,  1.9460, -0.6549],\n",
            "        [ 0.6836,  0.0296, -1.1335],\n",
            "        [-1.3977,  1.5744, -0.4604],\n",
            "        [-1.3797,  1.8501, -0.6644],\n",
            "        [-2.1322,  0.5232,  1.2318],\n",
            "        [-1.6985,  1.8314, -0.3480],\n",
            "        [-1.4587,  1.6165, -0.6113],\n",
            "        [-1.4979,  2.1582, -0.5309],\n",
            "        [-1.3282,  1.8292, -0.7027]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4307,  1.7797, -0.3557],\n",
            "        [-1.5763,  1.5317, -0.2567],\n",
            "        [-1.7503,  1.6742,  0.0958],\n",
            "        [-1.4134,  1.7317, -0.3477],\n",
            "        [-1.0490,  1.8366, -0.7156],\n",
            "        [-2.1515,  0.8311,  0.8790],\n",
            "        [-1.4899,  1.9087, -0.6580],\n",
            "        [-1.9180,  0.3413,  1.1226],\n",
            "        [-1.4417,  1.7664, -0.4665],\n",
            "        [-1.6933,  1.4883, -0.0877],\n",
            "        [-1.9794,  1.0201,  0.6594],\n",
            "        [ 0.6716,  0.0218, -1.2978],\n",
            "        [-1.7065,  1.8456, -0.1414],\n",
            "        [-1.4476,  1.8623, -0.7150],\n",
            "        [-2.0862,  1.0048,  0.9254],\n",
            "        [-2.0286,  0.7037,  1.1953]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4307,  1.7797, -0.3557],\n",
            "        [-1.5763,  1.5317, -0.2567],\n",
            "        [-1.7503,  1.6742,  0.0958],\n",
            "        [-1.4134,  1.7317, -0.3477],\n",
            "        [-1.0490,  1.8366, -0.7156],\n",
            "        [-2.1515,  0.8311,  0.8790],\n",
            "        [-1.4899,  1.9087, -0.6580],\n",
            "        [-1.9180,  0.3413,  1.1226],\n",
            "        [-1.4417,  1.7664, -0.4665],\n",
            "        [-1.6933,  1.4883, -0.0877],\n",
            "        [-1.9794,  1.0201,  0.6594],\n",
            "        [ 0.6716,  0.0218, -1.2978],\n",
            "        [-1.7065,  1.8456, -0.1414],\n",
            "        [-1.4476,  1.8623, -0.7150],\n",
            "        [-2.0862,  1.0048,  0.9254],\n",
            "        [-2.0286,  0.7037,  1.1953]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9182,  0.6705,  1.2135],\n",
            "        [-1.4147,  1.9409, -0.6385],\n",
            "        [-1.3212,  1.7437, -0.6972],\n",
            "        [-1.8652,  0.6957,  1.1057],\n",
            "        [ 0.8869,  0.0180, -1.0531],\n",
            "        [-1.8557,  0.4067,  1.1731],\n",
            "        [-1.1706,  1.7244, -0.6950],\n",
            "        [-1.5109,  1.9220, -0.5945],\n",
            "        [-2.0722,  0.4845,  1.2829],\n",
            "        [-1.2609,  1.7952, -0.4736],\n",
            "        [-1.1271,  1.7924, -0.5193],\n",
            "        [-2.0926,  0.4744,  0.8705],\n",
            "        [-2.1410,  0.3834,  1.2187],\n",
            "        [-1.7444,  1.0950,  0.4633],\n",
            "        [-2.1424,  0.4369,  1.2400],\n",
            "        [ 0.6134,  0.1705, -1.2637]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9182,  0.6705,  1.2135],\n",
            "        [-1.4147,  1.9409, -0.6385],\n",
            "        [-1.3212,  1.7437, -0.6972],\n",
            "        [-1.8652,  0.6957,  1.1057],\n",
            "        [ 0.8869,  0.0180, -1.0531],\n",
            "        [-1.8557,  0.4067,  1.1731],\n",
            "        [-1.1706,  1.7244, -0.6950],\n",
            "        [-1.5109,  1.9220, -0.5945],\n",
            "        [-2.0722,  0.4845,  1.2829],\n",
            "        [-1.2609,  1.7952, -0.4736],\n",
            "        [-1.1271,  1.7924, -0.5193],\n",
            "        [-2.0926,  0.4744,  0.8705],\n",
            "        [-2.1410,  0.3834,  1.2187],\n",
            "        [-1.7444,  1.0950,  0.4633],\n",
            "        [-2.1424,  0.4369,  1.2400],\n",
            "        [ 0.6134,  0.1705, -1.2637]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2230,  1.7260, -0.5721],\n",
            "        [ 0.4844,  0.0548, -1.2928],\n",
            "        [-1.9146,  0.4881,  1.1401],\n",
            "        [-1.1236,  1.8237, -0.6936],\n",
            "        [-1.2575,  1.8025, -0.7942],\n",
            "        [-1.7539,  0.9195,  0.7819],\n",
            "        [-1.3229,  1.7824, -0.6866],\n",
            "        [-1.2576,  1.6920, -0.7410],\n",
            "        [-1.1460,  1.6915, -0.4082],\n",
            "        [-1.2487,  1.8380, -0.6483],\n",
            "        [-1.4020,  1.9758, -0.6805],\n",
            "        [-1.4553,  1.6299, -0.5433],\n",
            "        [ 0.8784, -0.0973, -1.5148],\n",
            "        [-2.1698,  0.9719,  1.0023],\n",
            "        [-1.5623,  2.0327, -0.5930],\n",
            "        [-1.4193,  1.6842, -0.6759]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2230,  1.7260, -0.5721],\n",
            "        [ 0.4844,  0.0548, -1.2928],\n",
            "        [-1.9146,  0.4881,  1.1401],\n",
            "        [-1.1236,  1.8237, -0.6936],\n",
            "        [-1.2575,  1.8025, -0.7942],\n",
            "        [-1.7539,  0.9195,  0.7819],\n",
            "        [-1.3229,  1.7824, -0.6866],\n",
            "        [-1.2576,  1.6920, -0.7410],\n",
            "        [-1.1460,  1.6915, -0.4082],\n",
            "        [-1.2487,  1.8380, -0.6483],\n",
            "        [-1.4020,  1.9758, -0.6805],\n",
            "        [-1.4553,  1.6299, -0.5433],\n",
            "        [ 0.8784, -0.0973, -1.5148],\n",
            "        [-2.1698,  0.9719,  1.0023],\n",
            "        [-1.5623,  2.0327, -0.5930],\n",
            "        [-1.4193,  1.6842, -0.6759]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5464,  1.9728, -0.5843],\n",
            "        [ 0.2994,  0.5409, -1.3286],\n",
            "        [-1.2858,  1.9562, -0.6760],\n",
            "        [-1.3944,  1.8175, -0.5205],\n",
            "        [-1.2658,  1.9602, -0.5192],\n",
            "        [-0.9726,  1.5920, -0.6153],\n",
            "        [-1.3663,  2.0263, -0.5498],\n",
            "        [-1.1800,  2.0644, -0.8729],\n",
            "        [-1.3224,  1.8881, -0.5845],\n",
            "        [-1.1211,  1.6591, -0.6654],\n",
            "        [-1.8040,  0.8419,  1.0696],\n",
            "        [-1.3856,  1.8127, -0.5920],\n",
            "        [-1.3789,  1.7856, -0.8844],\n",
            "        [-2.0842,  0.5684,  1.3097],\n",
            "        [-1.8666,  0.4077,  1.4099],\n",
            "        [-1.1933,  1.6860, -0.6123]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5464,  1.9728, -0.5843],\n",
            "        [ 0.2994,  0.5409, -1.3286],\n",
            "        [-1.2858,  1.9562, -0.6760],\n",
            "        [-1.3944,  1.8175, -0.5205],\n",
            "        [-1.2658,  1.9602, -0.5192],\n",
            "        [-0.9726,  1.5920, -0.6153],\n",
            "        [-1.3663,  2.0263, -0.5498],\n",
            "        [-1.1800,  2.0644, -0.8729],\n",
            "        [-1.3224,  1.8881, -0.5845],\n",
            "        [-1.1211,  1.6591, -0.6654],\n",
            "        [-1.8040,  0.8419,  1.0696],\n",
            "        [-1.3856,  1.8127, -0.5920],\n",
            "        [-1.3789,  1.7856, -0.8844],\n",
            "        [-2.0842,  0.5684,  1.3097],\n",
            "        [-1.8666,  0.4077,  1.4099],\n",
            "        [-1.1933,  1.6860, -0.6123]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0654,  0.7857,  0.9667],\n",
            "        [-2.0715,  0.6821,  1.1525],\n",
            "        [-1.1638,  1.8495, -0.7548],\n",
            "        [-1.9374,  0.3100,  1.1615],\n",
            "        [-1.9757,  0.5018,  1.1756],\n",
            "        [ 0.5410,  0.5442, -1.4320],\n",
            "        [-1.1750,  1.7128, -0.7033],\n",
            "        [-1.9599,  1.4369, -0.0343],\n",
            "        [-1.6082,  1.2177,  0.2608],\n",
            "        [-2.1619,  0.3883,  1.4059],\n",
            "        [-1.2408,  1.8533, -0.6565],\n",
            "        [-2.0921,  0.4307,  1.3296],\n",
            "        [-1.2488,  1.7007, -0.5931],\n",
            "        [-1.8630,  0.7860,  0.9583],\n",
            "        [-1.2012,  1.6320, -0.7519],\n",
            "        [-0.3129,  0.4164, -0.4739]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0654,  0.7857,  0.9667],\n",
            "        [-2.0715,  0.6821,  1.1525],\n",
            "        [-1.1638,  1.8495, -0.7548],\n",
            "        [-1.9374,  0.3100,  1.1615],\n",
            "        [-1.9757,  0.5018,  1.1756],\n",
            "        [ 0.5410,  0.5442, -1.4320],\n",
            "        [-1.1750,  1.7128, -0.7033],\n",
            "        [-1.9599,  1.4369, -0.0343],\n",
            "        [-1.6082,  1.2177,  0.2608],\n",
            "        [-2.1619,  0.3883,  1.4059],\n",
            "        [-1.2408,  1.8533, -0.6565],\n",
            "        [-2.0921,  0.4307,  1.3296],\n",
            "        [-1.2488,  1.7007, -0.5931],\n",
            "        [-1.8630,  0.7860,  0.9583],\n",
            "        [-1.2012,  1.6320, -0.7519],\n",
            "        [-0.3129,  0.4164, -0.4739]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5568,  0.4292, -1.3453],\n",
            "        [-1.8409,  1.0242,  0.7166],\n",
            "        [-1.1672,  1.8231, -0.7262],\n",
            "        [-1.3786,  1.6938, -0.6403],\n",
            "        [-1.6864,  0.9725,  0.4815],\n",
            "        [-1.7907,  0.6383,  1.2391],\n",
            "        [-1.1072,  1.7749, -0.9505],\n",
            "        [ 0.6613,  0.0315, -1.3803],\n",
            "        [-1.3122,  1.7186, -0.3937],\n",
            "        [-0.1576,  1.2097, -1.3143],\n",
            "        [-2.0510,  0.5821,  1.0222],\n",
            "        [-1.4201,  1.8472, -0.7247],\n",
            "        [-1.2571,  1.8037, -0.5596],\n",
            "        [-1.2376,  1.9978, -0.7919],\n",
            "        [-1.5114,  1.8378, -0.6587],\n",
            "        [-0.9912,  1.5882, -0.9602]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.5568,  0.4292, -1.3453],\n",
            "        [-1.8409,  1.0242,  0.7166],\n",
            "        [-1.1672,  1.8231, -0.7262],\n",
            "        [-1.3786,  1.6938, -0.6403],\n",
            "        [-1.6864,  0.9725,  0.4815],\n",
            "        [-1.7907,  0.6383,  1.2391],\n",
            "        [-1.1072,  1.7749, -0.9505],\n",
            "        [ 0.6613,  0.0315, -1.3803],\n",
            "        [-1.3122,  1.7186, -0.3937],\n",
            "        [-0.1576,  1.2097, -1.3143],\n",
            "        [-2.0510,  0.5821,  1.0222],\n",
            "        [-1.4201,  1.8472, -0.7247],\n",
            "        [-1.2571,  1.8037, -0.5596],\n",
            "        [-1.2376,  1.9978, -0.7919],\n",
            "        [-1.5114,  1.8378, -0.6587],\n",
            "        [-0.9912,  1.5882, -0.9602]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3022e+00,  1.9159e+00, -7.8685e-01],\n",
            "        [ 7.0236e-01, -6.1270e-04, -1.3235e+00],\n",
            "        [-1.0925e+00,  1.6672e+00, -6.3969e-01],\n",
            "        [-1.3856e+00,  1.8600e+00, -5.8580e-01],\n",
            "        [-1.1209e+00,  1.9830e+00, -7.8471e-01],\n",
            "        [-1.1855e+00,  1.8249e+00, -7.4370e-01],\n",
            "        [-1.5269e+00,  1.7148e+00, -4.1585e-01],\n",
            "        [-1.3917e+00,  1.7128e+00, -5.0233e-01],\n",
            "        [-1.4011e+00,  2.0413e+00, -6.4042e-01],\n",
            "        [-1.9527e+00,  9.6954e-01,  8.2678e-01],\n",
            "        [-1.3062e+00,  2.2253e+00, -9.1745e-01],\n",
            "        [-1.1559e+00,  1.9323e+00, -9.1174e-01],\n",
            "        [-1.3734e+00,  1.8555e+00, -7.8837e-01],\n",
            "        [-1.1349e+00,  1.7496e+00, -6.5388e-01],\n",
            "        [ 6.0231e-01,  2.6591e-01, -1.2346e+00],\n",
            "        [ 7.0978e-01,  2.5408e-01, -1.2132e+00]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3022e+00,  1.9159e+00, -7.8685e-01],\n",
            "        [ 7.0236e-01, -6.1270e-04, -1.3235e+00],\n",
            "        [-1.0925e+00,  1.6672e+00, -6.3969e-01],\n",
            "        [-1.3856e+00,  1.8600e+00, -5.8580e-01],\n",
            "        [-1.1209e+00,  1.9830e+00, -7.8471e-01],\n",
            "        [-1.1855e+00,  1.8249e+00, -7.4370e-01],\n",
            "        [-1.5269e+00,  1.7148e+00, -4.1585e-01],\n",
            "        [-1.3917e+00,  1.7128e+00, -5.0233e-01],\n",
            "        [-1.4011e+00,  2.0413e+00, -6.4042e-01],\n",
            "        [-1.9527e+00,  9.6954e-01,  8.2678e-01],\n",
            "        [-1.3062e+00,  2.2253e+00, -9.1745e-01],\n",
            "        [-1.1559e+00,  1.9323e+00, -9.1174e-01],\n",
            "        [-1.3734e+00,  1.8555e+00, -7.8837e-01],\n",
            "        [-1.1349e+00,  1.7496e+00, -6.5388e-01],\n",
            "        [ 6.0231e-01,  2.6591e-01, -1.2346e+00],\n",
            "        [ 7.0978e-01,  2.5408e-01, -1.2132e+00]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.0045,  1.7508, -0.7985],\n",
            "        [-1.7530,  1.3519,  0.3213],\n",
            "        [-1.9702,  0.4337,  0.9729],\n",
            "        [ 0.7948,  0.0865, -1.3782],\n",
            "        [ 0.9227, -0.0269, -1.4967],\n",
            "        [-1.4366,  2.0554, -1.1314],\n",
            "        [-1.9684,  0.8793,  0.8256],\n",
            "        [-1.5901,  0.6566,  0.7490],\n",
            "        [-2.1799,  0.6012,  1.1130],\n",
            "        [-1.6804,  1.0236,  0.6753],\n",
            "        [ 0.5366,  0.2473, -1.2606],\n",
            "        [-1.1310,  1.9484, -0.9212],\n",
            "        [-0.8821,  1.8953, -0.7711],\n",
            "        [-1.2510,  1.7944, -0.4676],\n",
            "        [-1.0121,  1.8656, -0.9432],\n",
            "        [-1.2250,  1.5960, -0.8978]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.0045,  1.7508, -0.7985],\n",
            "        [-1.7530,  1.3519,  0.3213],\n",
            "        [-1.9702,  0.4337,  0.9729],\n",
            "        [ 0.7948,  0.0865, -1.3782],\n",
            "        [ 0.9227, -0.0269, -1.4967],\n",
            "        [-1.4366,  2.0554, -1.1314],\n",
            "        [-1.9684,  0.8793,  0.8256],\n",
            "        [-1.5901,  0.6566,  0.7490],\n",
            "        [-2.1799,  0.6012,  1.1130],\n",
            "        [-1.6804,  1.0236,  0.6753],\n",
            "        [ 0.5366,  0.2473, -1.2606],\n",
            "        [-1.1310,  1.9484, -0.9212],\n",
            "        [-0.8821,  1.8953, -0.7711],\n",
            "        [-1.2510,  1.7944, -0.4676],\n",
            "        [-1.0121,  1.8656, -0.9432],\n",
            "        [-1.2250,  1.5960, -0.8978]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.0879,  1.6673, -0.8520],\n",
            "        [-1.8490,  0.5803,  1.1191],\n",
            "        [-1.2699,  1.7404, -0.8651],\n",
            "        [-0.9991,  1.7683, -0.9722],\n",
            "        [-1.5849,  2.0401, -0.6617],\n",
            "        [-1.7385,  0.6299,  1.0002],\n",
            "        [-1.2610,  1.8504, -0.8388],\n",
            "        [-1.0468,  1.9685, -0.9539],\n",
            "        [-1.3102,  1.7936, -1.0276],\n",
            "        [-1.3861,  1.7502, -0.8206],\n",
            "        [-1.1645,  1.9035, -0.9399],\n",
            "        [-1.8903,  0.6225,  0.9835],\n",
            "        [-1.0608,  1.7873, -1.2894],\n",
            "        [-1.2349,  1.6266, -0.8761],\n",
            "        [-0.8548,  1.8699, -0.8309],\n",
            "        [ 0.7458,  0.1585, -1.2875]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.0879,  1.6673, -0.8520],\n",
            "        [-1.8490,  0.5803,  1.1191],\n",
            "        [-1.2699,  1.7404, -0.8651],\n",
            "        [-0.9991,  1.7683, -0.9722],\n",
            "        [-1.5849,  2.0401, -0.6617],\n",
            "        [-1.7385,  0.6299,  1.0002],\n",
            "        [-1.2610,  1.8504, -0.8388],\n",
            "        [-1.0468,  1.9685, -0.9539],\n",
            "        [-1.3102,  1.7936, -1.0276],\n",
            "        [-1.3861,  1.7502, -0.8206],\n",
            "        [-1.1645,  1.9035, -0.9399],\n",
            "        [-1.8903,  0.6225,  0.9835],\n",
            "        [-1.0608,  1.7873, -1.2894],\n",
            "        [-1.2349,  1.6266, -0.8761],\n",
            "        [-0.8548,  1.8699, -0.8309],\n",
            "        [ 0.7458,  0.1585, -1.2875]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5460,  1.5132, -0.2246],\n",
            "        [-1.1616,  1.9937, -0.9842],\n",
            "        [-1.1928,  2.0404, -0.9426],\n",
            "        [-1.0432,  1.7096, -0.9011],\n",
            "        [-1.0689,  1.8844, -1.0115],\n",
            "        [-1.0370,  1.8997, -0.7174],\n",
            "        [-1.9597,  0.3398,  1.3562],\n",
            "        [-1.3898,  1.8579, -0.7156],\n",
            "        [-1.1565,  2.0296, -1.1172],\n",
            "        [-1.7355,  1.1915,  0.6051],\n",
            "        [ 0.8996,  0.0133, -1.4088],\n",
            "        [-1.7188,  0.2684,  1.1036],\n",
            "        [-1.2149,  2.2147, -0.8110],\n",
            "        [-1.1661,  1.9460, -1.0870],\n",
            "        [-1.1402,  1.7817, -0.8169],\n",
            "        [-1.6898,  0.8359,  0.5573]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5460,  1.5132, -0.2246],\n",
            "        [-1.1616,  1.9937, -0.9842],\n",
            "        [-1.1928,  2.0404, -0.9426],\n",
            "        [-1.0432,  1.7096, -0.9011],\n",
            "        [-1.0689,  1.8844, -1.0115],\n",
            "        [-1.0370,  1.8997, -0.7174],\n",
            "        [-1.9597,  0.3398,  1.3562],\n",
            "        [-1.3898,  1.8579, -0.7156],\n",
            "        [-1.1565,  2.0296, -1.1172],\n",
            "        [-1.7355,  1.1915,  0.6051],\n",
            "        [ 0.8996,  0.0133, -1.4088],\n",
            "        [-1.7188,  0.2684,  1.1036],\n",
            "        [-1.2149,  2.2147, -0.8110],\n",
            "        [-1.1661,  1.9460, -1.0870],\n",
            "        [-1.1402,  1.7817, -0.8169],\n",
            "        [-1.6898,  0.8359,  0.5573]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.1539,  1.8567, -0.9108],\n",
            "        [-1.0757,  1.7874, -0.9408],\n",
            "        [ 0.6980,  0.1571, -1.5232],\n",
            "        [-0.9135,  1.7426, -0.8436],\n",
            "        [-1.2011,  1.9592, -0.8463],\n",
            "        [-1.1043,  1.9942, -0.8999],\n",
            "        [ 0.7722,  0.2031, -1.4467],\n",
            "        [-1.3314,  1.7983, -1.2084],\n",
            "        [-1.0578,  1.8830, -0.8569],\n",
            "        [ 0.7598,  0.1153, -1.5907],\n",
            "        [-1.1494,  2.0112, -0.7062],\n",
            "        [-1.2194,  1.9500, -0.9169],\n",
            "        [-1.0593,  1.7605, -0.9848],\n",
            "        [-0.9623,  1.7225, -0.7948],\n",
            "        [-1.1187,  1.7423, -0.6794],\n",
            "        [-0.7864,  0.3707, -0.1227]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.1539,  1.8567, -0.9108],\n",
            "        [-1.0757,  1.7874, -0.9408],\n",
            "        [ 0.6980,  0.1571, -1.5232],\n",
            "        [-0.9135,  1.7426, -0.8436],\n",
            "        [-1.2011,  1.9592, -0.8463],\n",
            "        [-1.1043,  1.9942, -0.8999],\n",
            "        [ 0.7722,  0.2031, -1.4467],\n",
            "        [-1.3314,  1.7983, -1.2084],\n",
            "        [-1.0578,  1.8830, -0.8569],\n",
            "        [ 0.7598,  0.1153, -1.5907],\n",
            "        [-1.1494,  2.0112, -0.7062],\n",
            "        [-1.2194,  1.9500, -0.9169],\n",
            "        [-1.0593,  1.7605, -0.9848],\n",
            "        [-0.9623,  1.7225, -0.7948],\n",
            "        [-1.1187,  1.7423, -0.6794],\n",
            "        [-0.7864,  0.3707, -0.1227]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2572,  2.0995, -0.9043],\n",
            "        [-1.5693,  1.1207,  0.2180],\n",
            "        [-1.7638,  0.6563,  1.2064],\n",
            "        [-1.1339,  1.8548, -0.8653],\n",
            "        [-1.8923,  0.3318,  1.0385],\n",
            "        [-1.1638,  2.0942, -0.8223],\n",
            "        [-0.9418,  1.9050, -1.1166],\n",
            "        [-1.3714,  1.6882, -0.3002],\n",
            "        [-1.1794,  1.9711, -0.9391],\n",
            "        [-1.1239,  1.7946, -0.9890],\n",
            "        [-0.9185,  1.6848, -0.7656],\n",
            "        [-1.1132,  1.8664, -1.1011],\n",
            "        [-1.0569,  1.9514, -0.8969],\n",
            "        [ 0.7641,  0.1688, -1.5592],\n",
            "        [-1.7221,  0.4351,  1.1763],\n",
            "        [-1.8044,  0.4678,  0.7190]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2572,  2.0995, -0.9043],\n",
            "        [-1.5693,  1.1207,  0.2180],\n",
            "        [-1.7638,  0.6563,  1.2064],\n",
            "        [-1.1339,  1.8548, -0.8653],\n",
            "        [-1.8923,  0.3318,  1.0385],\n",
            "        [-1.1638,  2.0942, -0.8223],\n",
            "        [-0.9418,  1.9050, -1.1166],\n",
            "        [-1.3714,  1.6882, -0.3002],\n",
            "        [-1.1794,  1.9711, -0.9391],\n",
            "        [-1.1239,  1.7946, -0.9890],\n",
            "        [-0.9185,  1.6848, -0.7656],\n",
            "        [-1.1132,  1.8664, -1.1011],\n",
            "        [-1.0569,  1.9514, -0.8969],\n",
            "        [ 0.7641,  0.1688, -1.5592],\n",
            "        [-1.7221,  0.4351,  1.1763],\n",
            "        [-1.8044,  0.4678,  0.7190]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3968,  1.1170,  0.1600],\n",
            "        [-1.1105,  1.8828, -0.9412],\n",
            "        [ 0.7416,  0.1530, -1.4807],\n",
            "        [-1.2506,  1.6742, -0.7394],\n",
            "        [-1.1582,  1.6643, -0.8424],\n",
            "        [-1.4683,  2.0730, -1.0563],\n",
            "        [-1.2266,  1.8609, -0.8621],\n",
            "        [-1.1568,  1.6935, -0.7392],\n",
            "        [-1.0782,  1.7536, -0.9230],\n",
            "        [-1.0543,  2.0300, -1.2610],\n",
            "        [-1.2875,  2.0253, -1.0269],\n",
            "        [-1.2144,  1.5157, -0.6906],\n",
            "        [-1.3458,  1.8697, -0.5831],\n",
            "        [ 0.9517,  0.1654, -1.5232],\n",
            "        [ 0.6612,  0.2588, -1.4772],\n",
            "        [-1.5680,  2.0453, -0.5553]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3968,  1.1170,  0.1600],\n",
            "        [-1.1105,  1.8828, -0.9412],\n",
            "        [ 0.7416,  0.1530, -1.4807],\n",
            "        [-1.2506,  1.6742, -0.7394],\n",
            "        [-1.1582,  1.6643, -0.8424],\n",
            "        [-1.4683,  2.0730, -1.0563],\n",
            "        [-1.2266,  1.8609, -0.8621],\n",
            "        [-1.1568,  1.6935, -0.7392],\n",
            "        [-1.0782,  1.7536, -0.9230],\n",
            "        [-1.0543,  2.0300, -1.2610],\n",
            "        [-1.2875,  2.0253, -1.0269],\n",
            "        [-1.2144,  1.5157, -0.6906],\n",
            "        [-1.3458,  1.8697, -0.5831],\n",
            "        [ 0.9517,  0.1654, -1.5232],\n",
            "        [ 0.6612,  0.2588, -1.4772],\n",
            "        [-1.5680,  2.0453, -0.5553]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9363,  0.7292,  0.9451],\n",
            "        [-0.9691,  1.8176, -0.9657],\n",
            "        [-0.1176,  1.1636, -1.3991],\n",
            "        [ 0.4409,  0.5328, -1.4785],\n",
            "        [-0.8600,  1.6185, -1.1559],\n",
            "        [-1.2246,  1.8541, -0.9727],\n",
            "        [ 1.0418,  0.0141, -1.4413],\n",
            "        [ 0.9509, -0.0255, -1.5660],\n",
            "        [-1.1041,  1.8692, -0.9663],\n",
            "        [-1.0476,  1.9305, -1.0825],\n",
            "        [-1.2880,  1.8826, -0.6314],\n",
            "        [-1.2366,  2.0376, -0.9280],\n",
            "        [-1.4903,  1.1711,  0.3159],\n",
            "        [-1.2137,  2.0383, -1.0807],\n",
            "        [-1.5031,  0.9657,  0.4169],\n",
            "        [-0.9496,  1.6362, -0.6836]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9363,  0.7292,  0.9451],\n",
            "        [-0.9691,  1.8176, -0.9657],\n",
            "        [-0.1176,  1.1636, -1.3991],\n",
            "        [ 0.4409,  0.5328, -1.4785],\n",
            "        [-0.8600,  1.6185, -1.1559],\n",
            "        [-1.2246,  1.8541, -0.9727],\n",
            "        [ 1.0418,  0.0141, -1.4413],\n",
            "        [ 0.9509, -0.0255, -1.5660],\n",
            "        [-1.1041,  1.8692, -0.9663],\n",
            "        [-1.0476,  1.9305, -1.0825],\n",
            "        [-1.2880,  1.8826, -0.6314],\n",
            "        [-1.2366,  2.0376, -0.9280],\n",
            "        [-1.4903,  1.1711,  0.3159],\n",
            "        [-1.2137,  2.0383, -1.0807],\n",
            "        [-1.5031,  0.9657,  0.4169],\n",
            "        [-0.9496,  1.6362, -0.6836]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2209,  1.7011, -0.8016],\n",
            "        [-0.2799,  0.6785, -1.1007],\n",
            "        [-1.1602,  1.8352, -0.9001],\n",
            "        [-1.9805,  0.3911,  1.3652],\n",
            "        [-1.0625,  1.8297, -0.7860],\n",
            "        [-1.1465,  1.9567, -0.8079],\n",
            "        [-1.3293,  1.8865, -0.7376],\n",
            "        [-1.6228,  0.4929,  1.1897],\n",
            "        [-2.0465,  0.4673,  1.3679],\n",
            "        [-1.3154,  1.7574, -0.3704],\n",
            "        [-0.9323,  1.6516, -0.7405],\n",
            "        [-1.6412,  0.5156,  0.9000],\n",
            "        [-1.1796,  1.8227, -0.8473],\n",
            "        [ 0.8915,  0.0726, -1.4268],\n",
            "        [-1.4766,  0.6681,  0.9950],\n",
            "        [-1.0744,  1.8677, -0.6860]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2209,  1.7011, -0.8016],\n",
            "        [-0.2799,  0.6785, -1.1007],\n",
            "        [-1.1602,  1.8352, -0.9001],\n",
            "        [-1.9805,  0.3911,  1.3652],\n",
            "        [-1.0625,  1.8297, -0.7860],\n",
            "        [-1.1465,  1.9567, -0.8079],\n",
            "        [-1.3293,  1.8865, -0.7376],\n",
            "        [-1.6228,  0.4929,  1.1897],\n",
            "        [-2.0465,  0.4673,  1.3679],\n",
            "        [-1.3154,  1.7574, -0.3704],\n",
            "        [-0.9323,  1.6516, -0.7405],\n",
            "        [-1.6412,  0.5156,  0.9000],\n",
            "        [-1.1796,  1.8227, -0.8473],\n",
            "        [ 0.8915,  0.0726, -1.4268],\n",
            "        [-1.4766,  0.6681,  0.9950],\n",
            "        [-1.0744,  1.8677, -0.6860]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2481e+00,  1.6101e+00, -6.4918e-01],\n",
            "        [ 9.0738e-01,  4.2274e-02, -1.6025e+00],\n",
            "        [-1.2278e+00,  1.8212e+00, -9.5408e-01],\n",
            "        [-1.2248e+00,  1.6238e+00, -7.1598e-01],\n",
            "        [-1.2919e+00,  1.8981e+00, -1.0462e+00],\n",
            "        [-1.2756e+00,  1.8487e+00, -7.5254e-01],\n",
            "        [-1.7241e+00,  5.8346e-01,  9.6085e-01],\n",
            "        [-1.2902e+00,  1.8767e+00, -9.1800e-01],\n",
            "        [-1.2703e+00,  1.7327e+00, -7.0105e-01],\n",
            "        [ 7.2231e-01, -9.1702e-04, -1.4584e+00],\n",
            "        [-1.8788e+00,  5.6083e-01,  1.1984e+00],\n",
            "        [-1.8518e+00,  3.5096e-01,  9.6794e-01],\n",
            "        [-1.7351e+00,  4.3894e-01,  1.2448e+00],\n",
            "        [-1.4215e+00,  2.0234e+00, -8.3062e-01],\n",
            "        [-1.1393e+00,  1.9277e+00, -7.3338e-01],\n",
            "        [-1.1849e+00,  1.7090e+00, -6.6905e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2481e+00,  1.6101e+00, -6.4918e-01],\n",
            "        [ 9.0738e-01,  4.2274e-02, -1.6025e+00],\n",
            "        [-1.2278e+00,  1.8212e+00, -9.5408e-01],\n",
            "        [-1.2248e+00,  1.6238e+00, -7.1598e-01],\n",
            "        [-1.2919e+00,  1.8981e+00, -1.0462e+00],\n",
            "        [-1.2756e+00,  1.8487e+00, -7.5254e-01],\n",
            "        [-1.7241e+00,  5.8346e-01,  9.6085e-01],\n",
            "        [-1.2902e+00,  1.8767e+00, -9.1800e-01],\n",
            "        [-1.2703e+00,  1.7327e+00, -7.0105e-01],\n",
            "        [ 7.2231e-01, -9.1702e-04, -1.4584e+00],\n",
            "        [-1.8788e+00,  5.6083e-01,  1.1984e+00],\n",
            "        [-1.8518e+00,  3.5096e-01,  9.6794e-01],\n",
            "        [-1.7351e+00,  4.3894e-01,  1.2448e+00],\n",
            "        [-1.4215e+00,  2.0234e+00, -8.3062e-01],\n",
            "        [-1.1393e+00,  1.9277e+00, -7.3338e-01],\n",
            "        [-1.1849e+00,  1.7090e+00, -6.6905e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2338,  1.7177, -0.4985],\n",
            "        [-1.1805,  1.7912, -0.6841],\n",
            "        [ 0.9378,  0.1752, -1.6889],\n",
            "        [-1.5436,  0.5266,  0.5592],\n",
            "        [-1.2166,  1.9537, -0.7880],\n",
            "        [-1.3335,  1.4409, -0.4241],\n",
            "        [-1.7363,  0.5391,  0.7738],\n",
            "        [-1.0982,  1.9428, -0.7983],\n",
            "        [-1.8147,  0.4436,  1.0849],\n",
            "        [-1.5541,  0.2378,  1.2293],\n",
            "        [-1.1311,  1.7413, -0.8503],\n",
            "        [ 0.7526, -0.0091, -1.4832],\n",
            "        [-1.0009,  1.7955, -0.9088],\n",
            "        [-1.9593,  0.2709,  1.1546],\n",
            "        [ 0.1098,  0.8952, -1.4808],\n",
            "        [ 0.8535,  0.0531, -1.6597]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2338,  1.7177, -0.4985],\n",
            "        [-1.1805,  1.7912, -0.6841],\n",
            "        [ 0.9378,  0.1752, -1.6889],\n",
            "        [-1.5436,  0.5266,  0.5592],\n",
            "        [-1.2166,  1.9537, -0.7880],\n",
            "        [-1.3335,  1.4409, -0.4241],\n",
            "        [-1.7363,  0.5391,  0.7738],\n",
            "        [-1.0982,  1.9428, -0.7983],\n",
            "        [-1.8147,  0.4436,  1.0849],\n",
            "        [-1.5541,  0.2378,  1.2293],\n",
            "        [-1.1311,  1.7413, -0.8503],\n",
            "        [ 0.7526, -0.0091, -1.4832],\n",
            "        [-1.0009,  1.7955, -0.9088],\n",
            "        [-1.9593,  0.2709,  1.1546],\n",
            "        [ 0.1098,  0.8952, -1.4808],\n",
            "        [ 0.8535,  0.0531, -1.6597]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.9450,  0.1052, -1.3090],\n",
            "        [-1.2086,  1.3895, -0.2545],\n",
            "        [-1.0190,  1.6859, -0.5554],\n",
            "        [ 0.7835,  0.0860, -1.4539],\n",
            "        [ 0.9375,  0.0878, -1.5258],\n",
            "        [-1.7934,  0.3142,  1.2431],\n",
            "        [-1.1605,  1.8327, -0.9538],\n",
            "        [-1.0869,  1.5878, -0.6539],\n",
            "        [-1.7040,  0.4626,  1.0026],\n",
            "        [-1.3446,  1.7849, -0.6961],\n",
            "        [-1.2607,  1.5759, -0.6249],\n",
            "        [-1.1654,  1.9066, -0.7969],\n",
            "        [-1.7107,  0.1848,  1.3696],\n",
            "        [-1.5572,  0.4600,  1.0537],\n",
            "        [-1.2287,  1.8028, -0.8689],\n",
            "        [-1.7073,  0.1150,  1.2444]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.9450,  0.1052, -1.3090],\n",
            "        [-1.2086,  1.3895, -0.2545],\n",
            "        [-1.0190,  1.6859, -0.5554],\n",
            "        [ 0.7835,  0.0860, -1.4539],\n",
            "        [ 0.9375,  0.0878, -1.5258],\n",
            "        [-1.7934,  0.3142,  1.2431],\n",
            "        [-1.1605,  1.8327, -0.9538],\n",
            "        [-1.0869,  1.5878, -0.6539],\n",
            "        [-1.7040,  0.4626,  1.0026],\n",
            "        [-1.3446,  1.7849, -0.6961],\n",
            "        [-1.2607,  1.5759, -0.6249],\n",
            "        [-1.1654,  1.9066, -0.7969],\n",
            "        [-1.7107,  0.1848,  1.3696],\n",
            "        [-1.5572,  0.4600,  1.0537],\n",
            "        [-1.2287,  1.8028, -0.8689],\n",
            "        [-1.7073,  0.1150,  1.2444]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7845,  0.4552,  1.2346],\n",
            "        [ 0.8440,  0.1666, -1.4210],\n",
            "        [-1.1233,  1.4841, -0.4240],\n",
            "        [-0.9956,  1.6255, -0.7161],\n",
            "        [-1.1959,  1.7438, -0.7610],\n",
            "        [ 0.8869,  0.0531, -1.4117],\n",
            "        [ 0.7825,  0.0673, -1.5320],\n",
            "        [-1.3825,  1.1081,  0.1086],\n",
            "        [ 0.1039,  0.5704, -1.3997],\n",
            "        [-1.7065,  0.2163,  1.3812],\n",
            "        [-1.2708,  1.6437, -0.5231],\n",
            "        [-1.2938,  1.2109, -0.2221],\n",
            "        [-1.2406,  1.7289, -0.7072],\n",
            "        [-1.1225,  1.5731, -0.7730],\n",
            "        [ 0.8619, -0.0785, -1.5279],\n",
            "        [-1.8423,  0.4825,  1.0006]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7845,  0.4552,  1.2346],\n",
            "        [ 0.8440,  0.1666, -1.4210],\n",
            "        [-1.1233,  1.4841, -0.4240],\n",
            "        [-0.9956,  1.6255, -0.7161],\n",
            "        [-1.1959,  1.7438, -0.7610],\n",
            "        [ 0.8869,  0.0531, -1.4117],\n",
            "        [ 0.7825,  0.0673, -1.5320],\n",
            "        [-1.3825,  1.1081,  0.1086],\n",
            "        [ 0.1039,  0.5704, -1.3997],\n",
            "        [-1.7065,  0.2163,  1.3812],\n",
            "        [-1.2708,  1.6437, -0.5231],\n",
            "        [-1.2938,  1.2109, -0.2221],\n",
            "        [-1.2406,  1.7289, -0.7072],\n",
            "        [-1.1225,  1.5731, -0.7730],\n",
            "        [ 0.8619, -0.0785, -1.5279],\n",
            "        [-1.8423,  0.4825,  1.0006]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5473,  0.7803,  0.6165],\n",
            "        [-1.4082,  0.6253,  0.5837],\n",
            "        [-1.7222,  0.4513,  0.7043],\n",
            "        [-1.7344,  0.6622,  0.9333],\n",
            "        [-1.2916,  1.6426, -0.5133],\n",
            "        [-1.6109,  0.3032,  1.0685],\n",
            "        [-1.0674,  1.5396, -0.3808],\n",
            "        [-1.1699,  1.3881, -0.4750],\n",
            "        [-1.4407,  1.4239, -0.0321],\n",
            "        [-1.6251,  0.3611,  0.8804],\n",
            "        [ 1.0697, -0.0382, -1.6058],\n",
            "        [-1.6235,  0.8798,  0.6938],\n",
            "        [-1.3666,  1.2061, -0.0809],\n",
            "        [-1.6660,  0.3404,  0.9834],\n",
            "        [ 0.8424,  0.0662, -1.4357],\n",
            "        [ 0.9498, -0.0369, -1.4848]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5473,  0.7803,  0.6165],\n",
            "        [-1.4082,  0.6253,  0.5837],\n",
            "        [-1.7222,  0.4513,  0.7043],\n",
            "        [-1.7344,  0.6622,  0.9333],\n",
            "        [-1.2916,  1.6426, -0.5133],\n",
            "        [-1.6109,  0.3032,  1.0685],\n",
            "        [-1.0674,  1.5396, -0.3808],\n",
            "        [-1.1699,  1.3881, -0.4750],\n",
            "        [-1.4407,  1.4239, -0.0321],\n",
            "        [-1.6251,  0.3611,  0.8804],\n",
            "        [ 1.0697, -0.0382, -1.6058],\n",
            "        [-1.6235,  0.8798,  0.6938],\n",
            "        [-1.3666,  1.2061, -0.0809],\n",
            "        [-1.6660,  0.3404,  0.9834],\n",
            "        [ 0.8424,  0.0662, -1.4357],\n",
            "        [ 0.9498, -0.0369, -1.4848]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7395,  0.0594,  1.2972],\n",
            "        [-1.2829,  1.5133, -0.7517],\n",
            "        [-1.5283,  0.2230,  1.0148],\n",
            "        [ 0.6335,  0.1647, -1.5151],\n",
            "        [-1.0690,  1.4453, -0.7077],\n",
            "        [-1.9143,  0.1568,  1.2654],\n",
            "        [-1.6928,  0.9902,  0.4754],\n",
            "        [ 0.7896, -0.1167, -1.3857],\n",
            "        [-1.4923,  1.4078, -0.0893],\n",
            "        [-0.8384,  1.3448, -0.3420],\n",
            "        [-1.6880,  0.1416,  1.3195],\n",
            "        [-1.3519,  1.3868, -0.1737],\n",
            "        [ 0.8461,  0.0455, -1.4572],\n",
            "        [ 0.8685, -0.0135, -1.5054],\n",
            "        [-1.9520,  0.1426,  1.3394],\n",
            "        [-1.7225,  0.2304,  1.2305]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7395,  0.0594,  1.2972],\n",
            "        [-1.2829,  1.5133, -0.7517],\n",
            "        [-1.5283,  0.2230,  1.0148],\n",
            "        [ 0.6335,  0.1647, -1.5151],\n",
            "        [-1.0690,  1.4453, -0.7077],\n",
            "        [-1.9143,  0.1568,  1.2654],\n",
            "        [-1.6928,  0.9902,  0.4754],\n",
            "        [ 0.7896, -0.1167, -1.3857],\n",
            "        [-1.4923,  1.4078, -0.0893],\n",
            "        [-0.8384,  1.3448, -0.3420],\n",
            "        [-1.6880,  0.1416,  1.3195],\n",
            "        [-1.3519,  1.3868, -0.1737],\n",
            "        [ 0.8461,  0.0455, -1.4572],\n",
            "        [ 0.8685, -0.0135, -1.5054],\n",
            "        [-1.9520,  0.1426,  1.3394],\n",
            "        [-1.7225,  0.2304,  1.2305]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4194,  1.4233, -0.4683],\n",
            "        [-1.2843,  1.5269, -0.5704],\n",
            "        [-1.2215,  1.5642, -0.6836],\n",
            "        [-1.0153,  1.2649, -0.7450],\n",
            "        [-1.0909,  1.3958, -0.4184],\n",
            "        [ 0.8235,  0.2344, -1.3819],\n",
            "        [-0.8785,  1.2923, -0.7392],\n",
            "        [-1.2760,  1.4570, -0.4326],\n",
            "        [ 0.9348,  0.1582, -1.4956],\n",
            "        [-1.2649,  1.3128, -0.3762],\n",
            "        [-1.3653,  0.9772,  0.1114],\n",
            "        [-1.1063,  1.3956, -0.3967],\n",
            "        [ 0.2966,  0.4154, -1.1788],\n",
            "        [-1.2358,  1.6846, -0.5981],\n",
            "        [-1.1069,  1.5519, -0.5028],\n",
            "        [-1.2776,  1.6619, -0.4673]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4194,  1.4233, -0.4683],\n",
            "        [-1.2843,  1.5269, -0.5704],\n",
            "        [-1.2215,  1.5642, -0.6836],\n",
            "        [-1.0153,  1.2649, -0.7450],\n",
            "        [-1.0909,  1.3958, -0.4184],\n",
            "        [ 0.8235,  0.2344, -1.3819],\n",
            "        [-0.8785,  1.2923, -0.7392],\n",
            "        [-1.2760,  1.4570, -0.4326],\n",
            "        [ 0.9348,  0.1582, -1.4956],\n",
            "        [-1.2649,  1.3128, -0.3762],\n",
            "        [-1.3653,  0.9772,  0.1114],\n",
            "        [-1.1063,  1.3956, -0.3967],\n",
            "        [ 0.2966,  0.4154, -1.1788],\n",
            "        [-1.2358,  1.6846, -0.5981],\n",
            "        [-1.1069,  1.5519, -0.5028],\n",
            "        [-1.2776,  1.6619, -0.4673]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.7311, -0.0650, -1.3182],\n",
            "        [-1.5111,  1.6931, -0.5944],\n",
            "        [-1.1448,  1.4995, -0.2483],\n",
            "        [-1.6911,  0.3942,  1.1317],\n",
            "        [-1.5439,  1.6742, -0.3924],\n",
            "        [-1.2498,  1.3907, -0.5784],\n",
            "        [-1.0719,  1.3836, -0.6486],\n",
            "        [-1.0495,  1.5175, -0.5909],\n",
            "        [-1.5975,  0.9455,  0.3678],\n",
            "        [-1.5062,  0.2657,  1.2227],\n",
            "        [-1.3058,  1.5403, -0.5557],\n",
            "        [-1.6271,  0.6143,  0.4407],\n",
            "        [-1.5424,  0.3577,  1.1948],\n",
            "        [ 0.8443, -0.0388, -1.3555],\n",
            "        [-1.8571,  0.5172,  1.1264],\n",
            "        [-1.2189,  1.3568, -0.6057]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.7311, -0.0650, -1.3182],\n",
            "        [-1.5111,  1.6931, -0.5944],\n",
            "        [-1.1448,  1.4995, -0.2483],\n",
            "        [-1.6911,  0.3942,  1.1317],\n",
            "        [-1.5439,  1.6742, -0.3924],\n",
            "        [-1.2498,  1.3907, -0.5784],\n",
            "        [-1.0719,  1.3836, -0.6486],\n",
            "        [-1.0495,  1.5175, -0.5909],\n",
            "        [-1.5975,  0.9455,  0.3678],\n",
            "        [-1.5062,  0.2657,  1.2227],\n",
            "        [-1.3058,  1.5403, -0.5557],\n",
            "        [-1.6271,  0.6143,  0.4407],\n",
            "        [-1.5424,  0.3577,  1.1948],\n",
            "        [ 0.8443, -0.0388, -1.3555],\n",
            "        [-1.8571,  0.5172,  1.1264],\n",
            "        [-1.2189,  1.3568, -0.6057]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2319,  1.3747, -0.4830],\n",
            "        [-1.4232,  1.6019, -0.5232],\n",
            "        [ 0.8824,  0.1264, -1.2420],\n",
            "        [-1.0115,  1.5204, -0.6015],\n",
            "        [ 0.8742, -0.0176, -1.2907],\n",
            "        [-0.3580,  0.0865, -0.4361],\n",
            "        [-1.3002,  1.5524, -0.5966],\n",
            "        [-1.2322,  1.4855, -0.4186],\n",
            "        [-1.2239,  1.1088,  0.2638],\n",
            "        [-1.1872,  1.4020, -0.4268],\n",
            "        [-1.2022,  1.6373, -0.7079],\n",
            "        [-1.1509,  1.4039, -0.4190],\n",
            "        [-1.2008,  1.5685, -0.5751],\n",
            "        [-1.0146,  1.4621, -0.5386],\n",
            "        [-1.8223,  0.9962,  0.7762],\n",
            "        [-1.1531,  1.4324, -0.2690]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2319,  1.3747, -0.4830],\n",
            "        [-1.4232,  1.6019, -0.5232],\n",
            "        [ 0.8824,  0.1264, -1.2420],\n",
            "        [-1.0115,  1.5204, -0.6015],\n",
            "        [ 0.8742, -0.0176, -1.2907],\n",
            "        [-0.3580,  0.0865, -0.4361],\n",
            "        [-1.3002,  1.5524, -0.5966],\n",
            "        [-1.2322,  1.4855, -0.4186],\n",
            "        [-1.2239,  1.1088,  0.2638],\n",
            "        [-1.1872,  1.4020, -0.4268],\n",
            "        [-1.2022,  1.6373, -0.7079],\n",
            "        [-1.1509,  1.4039, -0.4190],\n",
            "        [-1.2008,  1.5685, -0.5751],\n",
            "        [-1.0146,  1.4621, -0.5386],\n",
            "        [-1.8223,  0.9962,  0.7762],\n",
            "        [-1.1531,  1.4324, -0.2690]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6500,  0.2648,  1.1344],\n",
            "        [-1.8280,  0.3065,  1.3491],\n",
            "        [-1.5803,  0.4109,  0.8618],\n",
            "        [-1.3347,  1.6757, -0.4845],\n",
            "        [-1.8669,  0.3047,  1.2771],\n",
            "        [-1.8367,  0.7435,  0.6953],\n",
            "        [ 0.7155, -0.2095, -1.2811],\n",
            "        [-1.5144,  0.4050,  0.6611],\n",
            "        [ 0.5909,  0.0516, -1.2843],\n",
            "        [-1.2118,  1.6497, -0.5463],\n",
            "        [-1.2012,  1.5865, -0.3231],\n",
            "        [-1.2974,  1.5765, -0.5196],\n",
            "        [-1.7316,  0.5576,  1.0830],\n",
            "        [ 0.3425,  0.1548, -1.2967],\n",
            "        [-1.9221,  0.3196,  1.3028],\n",
            "        [-1.3030,  1.3680, -0.4324]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6500,  0.2648,  1.1344],\n",
            "        [-1.8280,  0.3065,  1.3491],\n",
            "        [-1.5803,  0.4109,  0.8618],\n",
            "        [-1.3347,  1.6757, -0.4845],\n",
            "        [-1.8669,  0.3047,  1.2771],\n",
            "        [-1.8367,  0.7435,  0.6953],\n",
            "        [ 0.7155, -0.2095, -1.2811],\n",
            "        [-1.5144,  0.4050,  0.6611],\n",
            "        [ 0.5909,  0.0516, -1.2843],\n",
            "        [-1.2118,  1.6497, -0.5463],\n",
            "        [-1.2012,  1.5865, -0.3231],\n",
            "        [-1.2974,  1.5765, -0.5196],\n",
            "        [-1.7316,  0.5576,  1.0830],\n",
            "        [ 0.3425,  0.1548, -1.2967],\n",
            "        [-1.9221,  0.3196,  1.3028],\n",
            "        [-1.3030,  1.3680, -0.4324]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7127,  0.6542,  0.8089],\n",
            "        [-1.9784,  0.3024,  1.1467],\n",
            "        [-1.4240,  1.7167, -0.4325],\n",
            "        [-1.8239,  0.3555,  1.4811],\n",
            "        [-1.4296,  1.4566, -0.3509],\n",
            "        [ 0.7373,  0.0763, -1.1247],\n",
            "        [-1.7304,  1.0373,  0.3476],\n",
            "        [-1.5278,  1.6722, -0.4388],\n",
            "        [-2.1506,  0.2411,  1.1690],\n",
            "        [-1.4712,  1.5008, -0.4876],\n",
            "        [-1.4334,  1.2518, -0.0951],\n",
            "        [-1.8495,  0.4049,  1.0965],\n",
            "        [ 0.7611,  0.1529, -1.3797],\n",
            "        [-2.0108,  0.2234,  1.2850],\n",
            "        [-1.7896,  0.5349,  0.7742],\n",
            "        [-1.9435,  0.3320,  1.3788]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7127,  0.6542,  0.8089],\n",
            "        [-1.9784,  0.3024,  1.1467],\n",
            "        [-1.4240,  1.7167, -0.4325],\n",
            "        [-1.8239,  0.3555,  1.4811],\n",
            "        [-1.4296,  1.4566, -0.3509],\n",
            "        [ 0.7373,  0.0763, -1.1247],\n",
            "        [-1.7304,  1.0373,  0.3476],\n",
            "        [-1.5278,  1.6722, -0.4388],\n",
            "        [-2.1506,  0.2411,  1.1690],\n",
            "        [-1.4712,  1.5008, -0.4876],\n",
            "        [-1.4334,  1.2518, -0.0951],\n",
            "        [-1.8495,  0.4049,  1.0965],\n",
            "        [ 0.7611,  0.1529, -1.3797],\n",
            "        [-2.0108,  0.2234,  1.2850],\n",
            "        [-1.7896,  0.5349,  0.7742],\n",
            "        [-1.9435,  0.3320,  1.3788]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8646,  0.2702,  1.1433],\n",
            "        [-1.7733,  0.9756,  0.2533],\n",
            "        [-1.1991,  1.6099, -0.4840],\n",
            "        [-1.3933,  1.3644, -0.2193],\n",
            "        [-0.7151,  1.1705, -0.9671],\n",
            "        [-1.1931,  1.3953, -0.5147],\n",
            "        [ 0.4185,  0.3924, -1.0878],\n",
            "        [-1.1967,  1.7546, -0.4502],\n",
            "        [-1.5091,  1.2852, -0.2201],\n",
            "        [-1.4127,  1.4071, -0.3239],\n",
            "        [-1.9795,  0.3961,  1.1312],\n",
            "        [-1.1576,  1.3166, -0.2295],\n",
            "        [-1.3776,  1.5198, -0.4447],\n",
            "        [-1.0778,  1.1876, -0.1084],\n",
            "        [ 0.8626, -0.1333, -1.2625],\n",
            "        [-1.2398,  1.5753, -0.4338]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8646,  0.2702,  1.1433],\n",
            "        [-1.7733,  0.9756,  0.2533],\n",
            "        [-1.1991,  1.6099, -0.4840],\n",
            "        [-1.3933,  1.3644, -0.2193],\n",
            "        [-0.7151,  1.1705, -0.9671],\n",
            "        [-1.1931,  1.3953, -0.5147],\n",
            "        [ 0.4185,  0.3924, -1.0878],\n",
            "        [-1.1967,  1.7546, -0.4502],\n",
            "        [-1.5091,  1.2852, -0.2201],\n",
            "        [-1.4127,  1.4071, -0.3239],\n",
            "        [-1.9795,  0.3961,  1.1312],\n",
            "        [-1.1576,  1.3166, -0.2295],\n",
            "        [-1.3776,  1.5198, -0.4447],\n",
            "        [-1.0778,  1.1876, -0.1084],\n",
            "        [ 0.8626, -0.1333, -1.2625],\n",
            "        [-1.2398,  1.5753, -0.4338]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3478,  1.6947, -0.3865],\n",
            "        [-1.9357,  0.4183,  1.2156],\n",
            "        [-1.2414,  1.5292, -0.5826],\n",
            "        [-1.9644,  0.4724,  1.1213],\n",
            "        [ 0.7355, -0.0554, -1.1373],\n",
            "        [-1.3071,  1.6060, -0.2901],\n",
            "        [-1.4915,  1.5927, -0.2930],\n",
            "        [-1.4906,  1.4856, -0.5445],\n",
            "        [-1.6913,  0.4430,  1.1161],\n",
            "        [-1.1363,  1.5962, -0.2959],\n",
            "        [ 0.8704, -0.0848, -1.2662],\n",
            "        [-1.3308,  1.6376, -0.3967],\n",
            "        [-1.3795,  1.4462, -0.3199],\n",
            "        [ 0.7124,  0.1545, -1.0887],\n",
            "        [ 0.8813, -0.0183, -1.1687],\n",
            "        [ 0.8702, -0.0266, -1.1140]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3478,  1.6947, -0.3865],\n",
            "        [-1.9357,  0.4183,  1.2156],\n",
            "        [-1.2414,  1.5292, -0.5826],\n",
            "        [-1.9644,  0.4724,  1.1213],\n",
            "        [ 0.7355, -0.0554, -1.1373],\n",
            "        [-1.3071,  1.6060, -0.2901],\n",
            "        [-1.4915,  1.5927, -0.2930],\n",
            "        [-1.4906,  1.4856, -0.5445],\n",
            "        [-1.6913,  0.4430,  1.1161],\n",
            "        [-1.1363,  1.5962, -0.2959],\n",
            "        [ 0.8704, -0.0848, -1.2662],\n",
            "        [-1.3308,  1.6376, -0.3967],\n",
            "        [-1.3795,  1.4462, -0.3199],\n",
            "        [ 0.7124,  0.1545, -1.0887],\n",
            "        [ 0.8813, -0.0183, -1.1687],\n",
            "        [ 0.8702, -0.0266, -1.1140]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6604,  1.0155,  0.5482],\n",
            "        [-1.2378,  1.6229, -0.3434],\n",
            "        [-1.7073,  0.4479,  1.0907],\n",
            "        [-1.7688,  0.6071,  1.0239],\n",
            "        [-1.3926,  1.3165, -0.4828],\n",
            "        [-1.7956,  0.5813,  0.9887],\n",
            "        [-1.1401,  1.5316, -0.6384],\n",
            "        [-1.7839,  0.7698,  0.9600],\n",
            "        [-1.3770,  1.7243, -0.7434],\n",
            "        [-1.2547,  1.7151, -0.5165],\n",
            "        [-1.4982,  1.6194, -0.4914],\n",
            "        [-1.3244,  1.6066, -0.5537],\n",
            "        [-1.7099,  0.6024,  0.7702],\n",
            "        [-1.9391,  0.4967,  1.3140],\n",
            "        [ 0.6076,  0.0162, -1.2623],\n",
            "        [-1.2562,  1.5436, -0.3713]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6604,  1.0155,  0.5482],\n",
            "        [-1.2378,  1.6229, -0.3434],\n",
            "        [-1.7073,  0.4479,  1.0907],\n",
            "        [-1.7688,  0.6071,  1.0239],\n",
            "        [-1.3926,  1.3165, -0.4828],\n",
            "        [-1.7956,  0.5813,  0.9887],\n",
            "        [-1.1401,  1.5316, -0.6384],\n",
            "        [-1.7839,  0.7698,  0.9600],\n",
            "        [-1.3770,  1.7243, -0.7434],\n",
            "        [-1.2547,  1.7151, -0.5165],\n",
            "        [-1.4982,  1.6194, -0.4914],\n",
            "        [-1.3244,  1.6066, -0.5537],\n",
            "        [-1.7099,  0.6024,  0.7702],\n",
            "        [-1.9391,  0.4967,  1.3140],\n",
            "        [ 0.6076,  0.0162, -1.2623],\n",
            "        [-1.2562,  1.5436, -0.3713]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.8332,  0.0454, -1.1640],\n",
            "        [-1.5699,  1.5436, -0.2541],\n",
            "        [-1.7987,  1.1147,  0.6372],\n",
            "        [-2.0563,  0.4580,  1.1145],\n",
            "        [-1.5753,  1.8549, -0.6522],\n",
            "        [-2.0364,  0.4692,  1.3504],\n",
            "        [-1.4394,  1.8417, -0.5128],\n",
            "        [-1.7371,  0.6059,  1.0673],\n",
            "        [-1.3650,  1.7555, -0.3829],\n",
            "        [-1.3187,  1.6373, -0.4381],\n",
            "        [-1.5279,  1.7628, -0.3859],\n",
            "        [-1.3328,  1.7343, -0.4530],\n",
            "        [-1.3860,  1.5962, -0.1153],\n",
            "        [-1.4257,  1.5689, -0.4959],\n",
            "        [-1.6327,  1.3521, -0.1773],\n",
            "        [ 0.7857,  0.0276, -1.1685]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.8332,  0.0454, -1.1640],\n",
            "        [-1.5699,  1.5436, -0.2541],\n",
            "        [-1.7987,  1.1147,  0.6372],\n",
            "        [-2.0563,  0.4580,  1.1145],\n",
            "        [-1.5753,  1.8549, -0.6522],\n",
            "        [-2.0364,  0.4692,  1.3504],\n",
            "        [-1.4394,  1.8417, -0.5128],\n",
            "        [-1.7371,  0.6059,  1.0673],\n",
            "        [-1.3650,  1.7555, -0.3829],\n",
            "        [-1.3187,  1.6373, -0.4381],\n",
            "        [-1.5279,  1.7628, -0.3859],\n",
            "        [-1.3328,  1.7343, -0.4530],\n",
            "        [-1.3860,  1.5962, -0.1153],\n",
            "        [-1.4257,  1.5689, -0.4959],\n",
            "        [-1.6327,  1.3521, -0.1773],\n",
            "        [ 0.7857,  0.0276, -1.1685]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.3130,  0.5464, -0.7475],\n",
            "        [-1.2938,  1.7043, -0.3873],\n",
            "        [-1.5365,  1.5644, -0.0504],\n",
            "        [-2.0903,  0.5578,  1.2598],\n",
            "        [-2.1467,  0.8975,  1.1075],\n",
            "        [ 0.6997,  0.0311, -1.2849],\n",
            "        [-1.6216,  0.2548,  0.9040],\n",
            "        [-1.5677,  1.4653, -0.0430],\n",
            "        [-1.8674,  0.9818,  0.6507],\n",
            "        [-1.7389,  1.8073, -0.4413],\n",
            "        [-1.8331,  0.8003,  0.9739],\n",
            "        [-1.5813,  1.8667, -0.5390],\n",
            "        [-1.8847,  0.5511,  1.0722],\n",
            "        [-1.5226,  1.6107, -0.0027],\n",
            "        [-1.5127,  1.8899, -0.3856],\n",
            "        [-0.4887,  0.2154, -0.2878]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-0.3130,  0.5464, -0.7475],\n",
            "        [-1.2938,  1.7043, -0.3873],\n",
            "        [-1.5365,  1.5644, -0.0504],\n",
            "        [-2.0903,  0.5578,  1.2598],\n",
            "        [-2.1467,  0.8975,  1.1075],\n",
            "        [ 0.6997,  0.0311, -1.2849],\n",
            "        [-1.6216,  0.2548,  0.9040],\n",
            "        [-1.5677,  1.4653, -0.0430],\n",
            "        [-1.8674,  0.9818,  0.6507],\n",
            "        [-1.7389,  1.8073, -0.4413],\n",
            "        [-1.8331,  0.8003,  0.9739],\n",
            "        [-1.5813,  1.8667, -0.5390],\n",
            "        [-1.8847,  0.5511,  1.0722],\n",
            "        [-1.5226,  1.6107, -0.0027],\n",
            "        [-1.5127,  1.8899, -0.3856],\n",
            "        [-0.4887,  0.2154, -0.2878]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9783,  0.8449,  0.9736],\n",
            "        [-1.7054,  0.6322,  1.2184],\n",
            "        [-1.3637,  1.6659, -0.3531],\n",
            "        [-1.6383,  1.7700, -0.2650],\n",
            "        [-0.9550,  1.5749, -0.9238],\n",
            "        [-0.9746,  1.5981, -0.7315],\n",
            "        [-1.4975,  1.5045, -0.4240],\n",
            "        [-1.8196,  0.6680,  0.9109],\n",
            "        [-2.0048,  0.3002,  0.8922],\n",
            "        [-1.2780,  1.7291, -0.2388],\n",
            "        [-1.5051,  1.7916, -0.4947],\n",
            "        [-1.9982,  0.4547,  0.9998],\n",
            "        [-1.4016,  1.6161, -0.6049],\n",
            "        [-1.5443,  1.7188, -0.3842],\n",
            "        [-1.5866,  1.6066, -0.2372],\n",
            "        [-1.5463,  1.8993, -0.3644]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9783,  0.8449,  0.9736],\n",
            "        [-1.7054,  0.6322,  1.2184],\n",
            "        [-1.3637,  1.6659, -0.3531],\n",
            "        [-1.6383,  1.7700, -0.2650],\n",
            "        [-0.9550,  1.5749, -0.9238],\n",
            "        [-0.9746,  1.5981, -0.7315],\n",
            "        [-1.4975,  1.5045, -0.4240],\n",
            "        [-1.8196,  0.6680,  0.9109],\n",
            "        [-2.0048,  0.3002,  0.8922],\n",
            "        [-1.2780,  1.7291, -0.2388],\n",
            "        [-1.5051,  1.7916, -0.4947],\n",
            "        [-1.9982,  0.4547,  0.9998],\n",
            "        [-1.4016,  1.6161, -0.6049],\n",
            "        [-1.5443,  1.7188, -0.3842],\n",
            "        [-1.5866,  1.6066, -0.2372],\n",
            "        [-1.5463,  1.8993, -0.3644]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3136,  1.5902, -0.5112],\n",
            "        [ 0.7096, -0.1270, -1.2147],\n",
            "        [-1.0270,  1.1001, -0.2966],\n",
            "        [-1.9627,  0.4918,  1.2720],\n",
            "        [ 0.8780, -0.1102, -1.2956],\n",
            "        [-1.2584,  1.7526, -0.3917],\n",
            "        [-2.1053,  0.5603,  1.1325],\n",
            "        [-1.9079,  0.7782,  0.7833],\n",
            "        [-1.8409,  1.3804,  0.0776],\n",
            "        [ 0.4777, -0.0935, -1.2431],\n",
            "        [-1.5096,  1.8867, -0.4133],\n",
            "        [-1.9709,  0.5486,  1.2458],\n",
            "        [-1.5286,  1.6605, -0.0954],\n",
            "        [-1.8676,  0.5191,  0.9045],\n",
            "        [-1.5490,  1.9116, -0.6679],\n",
            "        [ 0.6980, -0.0974, -1.1223]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3136,  1.5902, -0.5112],\n",
            "        [ 0.7096, -0.1270, -1.2147],\n",
            "        [-1.0270,  1.1001, -0.2966],\n",
            "        [-1.9627,  0.4918,  1.2720],\n",
            "        [ 0.8780, -0.1102, -1.2956],\n",
            "        [-1.2584,  1.7526, -0.3917],\n",
            "        [-2.1053,  0.5603,  1.1325],\n",
            "        [-1.9079,  0.7782,  0.7833],\n",
            "        [-1.8409,  1.3804,  0.0776],\n",
            "        [ 0.4777, -0.0935, -1.2431],\n",
            "        [-1.5096,  1.8867, -0.4133],\n",
            "        [-1.9709,  0.5486,  1.2458],\n",
            "        [-1.5286,  1.6605, -0.0954],\n",
            "        [-1.8676,  0.5191,  0.9045],\n",
            "        [-1.5490,  1.9116, -0.6679],\n",
            "        [ 0.6980, -0.0974, -1.1223]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7610,  1.7175, -0.0374],\n",
            "        [-1.5387,  1.7460, -0.4824],\n",
            "        [ 0.4251, -0.0502, -1.1125],\n",
            "        [-1.2672,  1.5132, -0.5068],\n",
            "        [-1.4891,  1.6385, -0.4849],\n",
            "        [-1.4609,  1.6613, -0.3905],\n",
            "        [ 0.5579, -0.0233, -1.0235],\n",
            "        [-1.9201,  1.2441,  0.2777],\n",
            "        [-1.6950,  1.7653, -0.2647],\n",
            "        [-1.6592,  1.8762, -0.2554],\n",
            "        [-2.0511,  0.5309,  1.0319],\n",
            "        [-2.0605,  0.6900,  1.1617],\n",
            "        [-1.9827,  0.5754,  1.2170],\n",
            "        [-1.5506,  1.9015, -0.5592],\n",
            "        [-1.9444,  0.4830,  1.1188],\n",
            "        [-0.4614,  0.0955,  0.0528]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7610,  1.7175, -0.0374],\n",
            "        [-1.5387,  1.7460, -0.4824],\n",
            "        [ 0.4251, -0.0502, -1.1125],\n",
            "        [-1.2672,  1.5132, -0.5068],\n",
            "        [-1.4891,  1.6385, -0.4849],\n",
            "        [-1.4609,  1.6613, -0.3905],\n",
            "        [ 0.5579, -0.0233, -1.0235],\n",
            "        [-1.9201,  1.2441,  0.2777],\n",
            "        [-1.6950,  1.7653, -0.2647],\n",
            "        [-1.6592,  1.8762, -0.2554],\n",
            "        [-2.0511,  0.5309,  1.0319],\n",
            "        [-2.0605,  0.6900,  1.1617],\n",
            "        [-1.9827,  0.5754,  1.2170],\n",
            "        [-1.5506,  1.9015, -0.5592],\n",
            "        [-1.9444,  0.4830,  1.1188],\n",
            "        [-0.4614,  0.0955,  0.0528]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3870,  1.8747, -0.5252],\n",
            "        [-0.6808,  0.5764, -0.3189],\n",
            "        [-1.5552,  1.6978, -0.5673],\n",
            "        [-1.8719,  0.6016,  1.2056],\n",
            "        [ 0.3636,  0.1326, -1.1680],\n",
            "        [ 0.4047,  0.0034, -1.0980],\n",
            "        [ 0.6545, -0.1523, -1.1883],\n",
            "        [-1.5553,  1.4817, -0.1674],\n",
            "        [-1.8692,  1.7253,  0.1265],\n",
            "        [-2.0642,  1.0620,  0.6283],\n",
            "        [-1.5214,  1.7471, -0.3785],\n",
            "        [-1.9054,  0.4298,  1.1921],\n",
            "        [ 0.6562,  0.0435, -1.0392],\n",
            "        [-1.8737,  1.7900, -0.3048],\n",
            "        [ 0.6531, -0.0565, -1.0490],\n",
            "        [-1.3043,  1.8035, -0.6089]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3870,  1.8747, -0.5252],\n",
            "        [-0.6808,  0.5764, -0.3189],\n",
            "        [-1.5552,  1.6978, -0.5673],\n",
            "        [-1.8719,  0.6016,  1.2056],\n",
            "        [ 0.3636,  0.1326, -1.1680],\n",
            "        [ 0.4047,  0.0034, -1.0980],\n",
            "        [ 0.6545, -0.1523, -1.1883],\n",
            "        [-1.5553,  1.4817, -0.1674],\n",
            "        [-1.8692,  1.7253,  0.1265],\n",
            "        [-2.0642,  1.0620,  0.6283],\n",
            "        [-1.5214,  1.7471, -0.3785],\n",
            "        [-1.9054,  0.4298,  1.1921],\n",
            "        [ 0.6562,  0.0435, -1.0392],\n",
            "        [-1.8737,  1.7900, -0.3048],\n",
            "        [ 0.6531, -0.0565, -1.0490],\n",
            "        [-1.3043,  1.8035, -0.6089]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.6877,  0.0825, -1.0842],\n",
            "        [ 0.3188,  0.0414, -0.9937],\n",
            "        [-1.9203,  0.5059,  1.1309],\n",
            "        [-1.8470,  1.6172, -0.1391],\n",
            "        [-1.7868,  0.5889,  1.0344],\n",
            "        [-1.6309,  1.7605, -0.4309],\n",
            "        [-1.7507,  0.6170,  1.0000],\n",
            "        [-1.7595,  0.7326,  1.1672],\n",
            "        [-1.7489,  1.6784, -0.0684],\n",
            "        [-1.6789,  1.8460, -0.5965],\n",
            "        [-1.6598,  1.5342, -0.1678],\n",
            "        [-1.8706,  0.6895,  1.0202],\n",
            "        [ 0.4774,  0.0574, -1.0752],\n",
            "        [-1.9362,  1.5017,  0.0409],\n",
            "        [-1.8719,  1.9139, -0.3835],\n",
            "        [-1.7111,  1.8147, -0.2902]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.6877,  0.0825, -1.0842],\n",
            "        [ 0.3188,  0.0414, -0.9937],\n",
            "        [-1.9203,  0.5059,  1.1309],\n",
            "        [-1.8470,  1.6172, -0.1391],\n",
            "        [-1.7868,  0.5889,  1.0344],\n",
            "        [-1.6309,  1.7605, -0.4309],\n",
            "        [-1.7507,  0.6170,  1.0000],\n",
            "        [-1.7595,  0.7326,  1.1672],\n",
            "        [-1.7489,  1.6784, -0.0684],\n",
            "        [-1.6789,  1.8460, -0.5965],\n",
            "        [-1.6598,  1.5342, -0.1678],\n",
            "        [-1.8706,  0.6895,  1.0202],\n",
            "        [ 0.4774,  0.0574, -1.0752],\n",
            "        [-1.9362,  1.5017,  0.0409],\n",
            "        [-1.8719,  1.9139, -0.3835],\n",
            "        [-1.7111,  1.8147, -0.2902]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7926,  1.2538,  0.1324],\n",
            "        [-1.4643,  1.5333, -0.3716],\n",
            "        [-1.2582,  1.7926, -0.7374],\n",
            "        [-1.7174,  1.8820, -0.3118],\n",
            "        [-1.3848,  1.7812, -0.1496],\n",
            "        [-1.3915,  1.7756, -0.3984],\n",
            "        [-2.0721,  0.3824,  1.0687],\n",
            "        [-1.8623,  0.5505,  1.3003],\n",
            "        [-1.3988,  1.8949, -0.6814],\n",
            "        [ 0.5483, -0.1260, -0.9051],\n",
            "        [-1.5344,  1.7347, -0.4198],\n",
            "        [-1.8799,  0.6302,  0.7981],\n",
            "        [-1.2248,  1.7088, -0.3904],\n",
            "        [ 0.6741, -0.1529, -1.0382],\n",
            "        [-1.6245,  1.7248, -0.1776],\n",
            "        [ 0.5092,  0.3719, -1.1278]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7926,  1.2538,  0.1324],\n",
            "        [-1.4643,  1.5333, -0.3716],\n",
            "        [-1.2582,  1.7926, -0.7374],\n",
            "        [-1.7174,  1.8820, -0.3118],\n",
            "        [-1.3848,  1.7812, -0.1496],\n",
            "        [-1.3915,  1.7756, -0.3984],\n",
            "        [-2.0721,  0.3824,  1.0687],\n",
            "        [-1.8623,  0.5505,  1.3003],\n",
            "        [-1.3988,  1.8949, -0.6814],\n",
            "        [ 0.5483, -0.1260, -0.9051],\n",
            "        [-1.5344,  1.7347, -0.4198],\n",
            "        [-1.8799,  0.6302,  0.7981],\n",
            "        [-1.2248,  1.7088, -0.3904],\n",
            "        [ 0.6741, -0.1529, -1.0382],\n",
            "        [-1.6245,  1.7248, -0.1776],\n",
            "        [ 0.5092,  0.3719, -1.1278]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7493,  1.8066, -0.3060],\n",
            "        [-1.8466,  1.6551, -0.1940],\n",
            "        [-1.6501,  2.0675, -0.2103],\n",
            "        [-1.8050,  0.4219,  1.0088],\n",
            "        [-1.6517,  1.6133, -0.0089],\n",
            "        [-1.4355,  1.6309, -0.4093],\n",
            "        [-1.6227,  1.9014, -0.4526],\n",
            "        [-2.0161,  0.5188,  1.0512],\n",
            "        [-0.1399,  0.0906, -0.7190],\n",
            "        [-1.2718,  1.7319, -0.3560],\n",
            "        [ 0.5033,  0.0126, -1.0248],\n",
            "        [-1.6985,  1.9408, -0.6873],\n",
            "        [ 0.4278,  0.0590, -0.9776],\n",
            "        [-1.7257,  1.8730, -0.6668],\n",
            "        [-1.5839,  1.8679, -0.2501],\n",
            "        [-1.4954,  1.8168, -0.4137]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7493,  1.8066, -0.3060],\n",
            "        [-1.8466,  1.6551, -0.1940],\n",
            "        [-1.6501,  2.0675, -0.2103],\n",
            "        [-1.8050,  0.4219,  1.0088],\n",
            "        [-1.6517,  1.6133, -0.0089],\n",
            "        [-1.4355,  1.6309, -0.4093],\n",
            "        [-1.6227,  1.9014, -0.4526],\n",
            "        [-2.0161,  0.5188,  1.0512],\n",
            "        [-0.1399,  0.0906, -0.7190],\n",
            "        [-1.2718,  1.7319, -0.3560],\n",
            "        [ 0.5033,  0.0126, -1.0248],\n",
            "        [-1.6985,  1.9408, -0.6873],\n",
            "        [ 0.4278,  0.0590, -0.9776],\n",
            "        [-1.7257,  1.8730, -0.6668],\n",
            "        [-1.5839,  1.8679, -0.2501],\n",
            "        [-1.4954,  1.8168, -0.4137]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7259,  1.7368, -0.2479],\n",
            "        [-1.6895,  1.6306, -0.3804],\n",
            "        [ 0.4343, -0.0604, -1.0008],\n",
            "        [-1.3779,  1.8124, -0.3625],\n",
            "        [ 0.6756,  0.0095, -0.9997],\n",
            "        [-1.8957,  0.2728,  1.1351],\n",
            "        [-1.3018,  1.6902, -0.5133],\n",
            "        [-1.8607,  0.5557,  1.0020],\n",
            "        [ 0.4196,  0.1003, -1.2012],\n",
            "        [-2.0616,  0.6477,  1.2719],\n",
            "        [-1.8006,  1.8503, -0.4527],\n",
            "        [-1.4441,  1.7524, -0.4437],\n",
            "        [ 0.5141,  0.0537, -0.9983],\n",
            "        [-1.9433,  0.5941,  0.9625],\n",
            "        [-1.3910,  1.8121, -0.4031],\n",
            "        [-1.4052,  1.7558, -0.4799]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7259,  1.7368, -0.2479],\n",
            "        [-1.6895,  1.6306, -0.3804],\n",
            "        [ 0.4343, -0.0604, -1.0008],\n",
            "        [-1.3779,  1.8124, -0.3625],\n",
            "        [ 0.6756,  0.0095, -0.9997],\n",
            "        [-1.8957,  0.2728,  1.1351],\n",
            "        [-1.3018,  1.6902, -0.5133],\n",
            "        [-1.8607,  0.5557,  1.0020],\n",
            "        [ 0.4196,  0.1003, -1.2012],\n",
            "        [-2.0616,  0.6477,  1.2719],\n",
            "        [-1.8006,  1.8503, -0.4527],\n",
            "        [-1.4441,  1.7524, -0.4437],\n",
            "        [ 0.5141,  0.0537, -0.9983],\n",
            "        [-1.9433,  0.5941,  0.9625],\n",
            "        [-1.3910,  1.8121, -0.4031],\n",
            "        [-1.4052,  1.7558, -0.4799]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5915,  1.6810, -0.4745],\n",
            "        [-1.1975,  1.5447, -0.3282],\n",
            "        [-1.4628,  1.5660, -0.4459],\n",
            "        [-2.0123,  0.7495,  0.9439],\n",
            "        [-1.6156,  1.7273, -0.5315],\n",
            "        [-0.0138,  0.6013, -1.0542],\n",
            "        [ 0.5276,  0.0164, -0.8731],\n",
            "        [ 0.5389, -0.2086, -1.1330],\n",
            "        [ 0.4266, -0.0875, -1.0895],\n",
            "        [-1.6777,  1.5985, -0.2665],\n",
            "        [-1.7716,  1.9595, -0.3429],\n",
            "        [-0.6334,  0.3456, -0.1269],\n",
            "        [-2.0059,  1.1196,  0.8211],\n",
            "        [-1.4174,  1.8089, -0.1430],\n",
            "        [ 0.5941, -0.0174, -1.0389],\n",
            "        [-1.7215,  2.0467, -0.5487]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5915,  1.6810, -0.4745],\n",
            "        [-1.1975,  1.5447, -0.3282],\n",
            "        [-1.4628,  1.5660, -0.4459],\n",
            "        [-2.0123,  0.7495,  0.9439],\n",
            "        [-1.6156,  1.7273, -0.5315],\n",
            "        [-0.0138,  0.6013, -1.0542],\n",
            "        [ 0.5276,  0.0164, -0.8731],\n",
            "        [ 0.5389, -0.2086, -1.1330],\n",
            "        [ 0.4266, -0.0875, -1.0895],\n",
            "        [-1.6777,  1.5985, -0.2665],\n",
            "        [-1.7716,  1.9595, -0.3429],\n",
            "        [-0.6334,  0.3456, -0.1269],\n",
            "        [-2.0059,  1.1196,  0.8211],\n",
            "        [-1.4174,  1.8089, -0.1430],\n",
            "        [ 0.5941, -0.0174, -1.0389],\n",
            "        [-1.7215,  2.0467, -0.5487]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8738,  0.9999,  0.7472],\n",
            "        [-1.7668,  0.3663,  1.0391],\n",
            "        [-1.5064,  1.9793, -0.7428],\n",
            "        [-1.6527,  1.7843, -0.3672],\n",
            "        [-1.5615,  1.4983, -0.2631],\n",
            "        [-1.9133,  0.9148,  0.7166],\n",
            "        [-1.8024,  0.6218,  0.9474],\n",
            "        [-1.9101,  0.8138,  1.0283],\n",
            "        [-1.5873,  1.6972, -0.3673],\n",
            "        [ 0.4719,  0.1115, -0.9263],\n",
            "        [-1.6149,  1.5395,  0.2697],\n",
            "        [-1.5896,  1.7750, -0.2543],\n",
            "        [-1.6042,  2.1437, -0.5672],\n",
            "        [-2.1619,  0.7106,  1.0542],\n",
            "        [-1.7202,  1.0387,  0.5896],\n",
            "        [ 0.3119, -0.0426, -1.1309]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8738,  0.9999,  0.7472],\n",
            "        [-1.7668,  0.3663,  1.0391],\n",
            "        [-1.5064,  1.9793, -0.7428],\n",
            "        [-1.6527,  1.7843, -0.3672],\n",
            "        [-1.5615,  1.4983, -0.2631],\n",
            "        [-1.9133,  0.9148,  0.7166],\n",
            "        [-1.8024,  0.6218,  0.9474],\n",
            "        [-1.9101,  0.8138,  1.0283],\n",
            "        [-1.5873,  1.6972, -0.3673],\n",
            "        [ 0.4719,  0.1115, -0.9263],\n",
            "        [-1.6149,  1.5395,  0.2697],\n",
            "        [-1.5896,  1.7750, -0.2543],\n",
            "        [-1.6042,  2.1437, -0.5672],\n",
            "        [-2.1619,  0.7106,  1.0542],\n",
            "        [-1.7202,  1.0387,  0.5896],\n",
            "        [ 0.3119, -0.0426, -1.1309]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7022,  1.8766, -0.3303],\n",
            "        [-1.6848,  1.7804,  0.0296],\n",
            "        [-1.3732,  1.7541, -0.6703],\n",
            "        [-1.6590,  1.3935, -0.0576],\n",
            "        [-1.4124,  1.5945, -0.5280],\n",
            "        [-1.7464,  0.7454,  0.8787],\n",
            "        [ 0.2333,  0.0666, -0.9316],\n",
            "        [-1.6996,  0.6265,  0.9180],\n",
            "        [-1.6029,  1.7154, -0.1192],\n",
            "        [-2.0075,  0.8397,  0.8324],\n",
            "        [ 0.4199,  0.0363, -0.9235],\n",
            "        [-1.7616,  1.5063,  0.0929],\n",
            "        [-1.6413,  0.5028,  0.9327],\n",
            "        [-1.8800,  0.5749,  1.0072],\n",
            "        [ 0.2321, -0.1021, -0.8881],\n",
            "        [-1.8112,  0.6606,  0.9214]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7022,  1.8766, -0.3303],\n",
            "        [-1.6848,  1.7804,  0.0296],\n",
            "        [-1.3732,  1.7541, -0.6703],\n",
            "        [-1.6590,  1.3935, -0.0576],\n",
            "        [-1.4124,  1.5945, -0.5280],\n",
            "        [-1.7464,  0.7454,  0.8787],\n",
            "        [ 0.2333,  0.0666, -0.9316],\n",
            "        [-1.6996,  0.6265,  0.9180],\n",
            "        [-1.6029,  1.7154, -0.1192],\n",
            "        [-2.0075,  0.8397,  0.8324],\n",
            "        [ 0.4199,  0.0363, -0.9235],\n",
            "        [-1.7616,  1.5063,  0.0929],\n",
            "        [-1.6413,  0.5028,  0.9327],\n",
            "        [-1.8800,  0.5749,  1.0072],\n",
            "        [ 0.2321, -0.1021, -0.8881],\n",
            "        [-1.8112,  0.6606,  0.9214]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6509,  1.7240, -0.4084],\n",
            "        [-1.6662,  1.8180,  0.0030],\n",
            "        [-1.8449,  1.2857, -0.0028],\n",
            "        [-1.5329,  1.4043,  0.0221],\n",
            "        [-1.4670,  1.5271, -0.3293],\n",
            "        [-1.6408,  1.2345, -0.0190],\n",
            "        [-1.8369,  0.5460,  1.0128],\n",
            "        [-1.6930,  1.6429, -0.3711],\n",
            "        [-1.7184,  1.7716, -0.0739],\n",
            "        [-1.8335,  0.5122,  1.0599],\n",
            "        [-1.7393,  0.5746,  0.8765],\n",
            "        [-1.5766,  1.7982, -0.0382],\n",
            "        [-1.9390,  0.5352,  0.8296],\n",
            "        [-1.7382,  0.4407,  0.9546],\n",
            "        [-1.6217,  1.5794, -0.0860],\n",
            "        [-1.5763,  1.7593, -0.1771]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6509,  1.7240, -0.4084],\n",
            "        [-1.6662,  1.8180,  0.0030],\n",
            "        [-1.8449,  1.2857, -0.0028],\n",
            "        [-1.5329,  1.4043,  0.0221],\n",
            "        [-1.4670,  1.5271, -0.3293],\n",
            "        [-1.6408,  1.2345, -0.0190],\n",
            "        [-1.8369,  0.5460,  1.0128],\n",
            "        [-1.6930,  1.6429, -0.3711],\n",
            "        [-1.7184,  1.7716, -0.0739],\n",
            "        [-1.8335,  0.5122,  1.0599],\n",
            "        [-1.7393,  0.5746,  0.8765],\n",
            "        [-1.5766,  1.7982, -0.0382],\n",
            "        [-1.9390,  0.5352,  0.8296],\n",
            "        [-1.7382,  0.4407,  0.9546],\n",
            "        [-1.6217,  1.5794, -0.0860],\n",
            "        [-1.5763,  1.7593, -0.1771]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3802,  1.2849, -0.0542],\n",
            "        [ 0.3511,  0.0776, -0.9710],\n",
            "        [-1.6171,  1.8058, -0.0964],\n",
            "        [-1.6557,  0.3513,  1.0410],\n",
            "        [-1.6253,  1.6181, -0.0555],\n",
            "        [-1.6384,  1.6075, -0.1877],\n",
            "        [ 0.5009,  0.1121, -0.8591],\n",
            "        [-1.4952,  1.7549, -0.1316],\n",
            "        [ 0.4035,  0.0761, -0.8058],\n",
            "        [-2.0544,  1.1643,  0.7762],\n",
            "        [-1.5359,  1.4548, -0.1110],\n",
            "        [-1.6754,  0.5099,  0.8383],\n",
            "        [ 0.4792, -0.0197, -1.0175],\n",
            "        [-1.7186,  0.5084,  1.0729],\n",
            "        [-1.6672,  0.4393,  0.8619],\n",
            "        [-0.1713,  0.0681, -0.6034]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3802,  1.2849, -0.0542],\n",
            "        [ 0.3511,  0.0776, -0.9710],\n",
            "        [-1.6171,  1.8058, -0.0964],\n",
            "        [-1.6557,  0.3513,  1.0410],\n",
            "        [-1.6253,  1.6181, -0.0555],\n",
            "        [-1.6384,  1.6075, -0.1877],\n",
            "        [ 0.5009,  0.1121, -0.8591],\n",
            "        [-1.4952,  1.7549, -0.1316],\n",
            "        [ 0.4035,  0.0761, -0.8058],\n",
            "        [-2.0544,  1.1643,  0.7762],\n",
            "        [-1.5359,  1.4548, -0.1110],\n",
            "        [-1.6754,  0.5099,  0.8383],\n",
            "        [ 0.4792, -0.0197, -1.0175],\n",
            "        [-1.7186,  0.5084,  1.0729],\n",
            "        [-1.6672,  0.4393,  0.8619],\n",
            "        [-0.1713,  0.0681, -0.6034]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2086,  0.9485,  0.8228],\n",
            "        [-1.6310,  1.8045, -0.3475],\n",
            "        [-1.6272,  1.9088, -0.0549],\n",
            "        [-1.7628,  0.5359,  1.0229],\n",
            "        [-1.6580,  1.6644, -0.3388],\n",
            "        [-1.5936,  1.7318, -0.5406],\n",
            "        [-1.7973,  0.7020,  1.2605],\n",
            "        [-1.7312,  1.6755, -0.1264],\n",
            "        [-1.4174,  1.8860, -0.1012],\n",
            "        [-1.7911,  1.5370, -0.2294],\n",
            "        [-1.4961,  1.5409, -0.3471],\n",
            "        [-1.5226,  1.1931,  0.2591],\n",
            "        [-1.8824,  1.2255,  0.4844],\n",
            "        [-1.6116,  2.1356, -0.5208],\n",
            "        [-1.5408,  1.5306, -0.2389],\n",
            "        [-1.8781,  1.4343,  0.1380]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.2086,  0.9485,  0.8228],\n",
            "        [-1.6310,  1.8045, -0.3475],\n",
            "        [-1.6272,  1.9088, -0.0549],\n",
            "        [-1.7628,  0.5359,  1.0229],\n",
            "        [-1.6580,  1.6644, -0.3388],\n",
            "        [-1.5936,  1.7318, -0.5406],\n",
            "        [-1.7973,  0.7020,  1.2605],\n",
            "        [-1.7312,  1.6755, -0.1264],\n",
            "        [-1.4174,  1.8860, -0.1012],\n",
            "        [-1.7911,  1.5370, -0.2294],\n",
            "        [-1.4961,  1.5409, -0.3471],\n",
            "        [-1.5226,  1.1931,  0.2591],\n",
            "        [-1.8824,  1.2255,  0.4844],\n",
            "        [-1.6116,  2.1356, -0.5208],\n",
            "        [-1.5408,  1.5306, -0.2389],\n",
            "        [-1.8781,  1.4343,  0.1380]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7121,  1.4517, -0.0955],\n",
            "        [-1.5181,  1.7374, -0.3168],\n",
            "        [-1.7725,  0.6270,  1.0591],\n",
            "        [-1.6666,  1.8874, -0.4567],\n",
            "        [-1.7137,  1.9366, -0.3336],\n",
            "        [-0.7007,  1.0823, -0.8382],\n",
            "        [-1.7512,  1.7924, -0.5256],\n",
            "        [ 0.2514, -0.0343, -0.9109],\n",
            "        [-1.5483,  1.6970, -0.2156],\n",
            "        [ 0.2626, -0.0306, -0.9062],\n",
            "        [-1.4696,  1.7020, -0.1306],\n",
            "        [-1.7043,  1.7023, -0.3423],\n",
            "        [-2.0564,  0.6373,  1.1336],\n",
            "        [-1.5670,  1.7854, -0.3273],\n",
            "        [-1.7100,  1.6082, -0.1675],\n",
            "        [-1.5897,  1.9176, -0.2263]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7121,  1.4517, -0.0955],\n",
            "        [-1.5181,  1.7374, -0.3168],\n",
            "        [-1.7725,  0.6270,  1.0591],\n",
            "        [-1.6666,  1.8874, -0.4567],\n",
            "        [-1.7137,  1.9366, -0.3336],\n",
            "        [-0.7007,  1.0823, -0.8382],\n",
            "        [-1.7512,  1.7924, -0.5256],\n",
            "        [ 0.2514, -0.0343, -0.9109],\n",
            "        [-1.5483,  1.6970, -0.2156],\n",
            "        [ 0.2626, -0.0306, -0.9062],\n",
            "        [-1.4696,  1.7020, -0.1306],\n",
            "        [-1.7043,  1.7023, -0.3423],\n",
            "        [-2.0564,  0.6373,  1.1336],\n",
            "        [-1.5670,  1.7854, -0.3273],\n",
            "        [-1.7100,  1.6082, -0.1675],\n",
            "        [-1.5897,  1.9176, -0.2263]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3801,  0.2338, -0.9375],\n",
            "        [-1.6211,  1.9860, -0.4975],\n",
            "        [-1.7957,  0.4672,  0.9757],\n",
            "        [-1.9741,  0.9226,  0.7266],\n",
            "        [-1.6841,  0.4602,  0.8981],\n",
            "        [-1.5944,  1.8431, -0.2109],\n",
            "        [ 0.3315,  0.1338, -0.8914],\n",
            "        [-1.7478,  0.6228,  0.8693],\n",
            "        [ 0.3064, -0.1256, -0.9325],\n",
            "        [-1.3969,  1.7262, -0.6361],\n",
            "        [-1.7543,  1.3060,  0.1969],\n",
            "        [-1.8196,  0.8097,  0.9570],\n",
            "        [-1.5026,  1.6751, -0.0532],\n",
            "        [-1.6889,  1.0472,  0.7146],\n",
            "        [-2.0123,  0.5538,  0.8540],\n",
            "        [-1.5723,  1.8600, -0.3206]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.3801,  0.2338, -0.9375],\n",
            "        [-1.6211,  1.9860, -0.4975],\n",
            "        [-1.7957,  0.4672,  0.9757],\n",
            "        [-1.9741,  0.9226,  0.7266],\n",
            "        [-1.6841,  0.4602,  0.8981],\n",
            "        [-1.5944,  1.8431, -0.2109],\n",
            "        [ 0.3315,  0.1338, -0.8914],\n",
            "        [-1.7478,  0.6228,  0.8693],\n",
            "        [ 0.3064, -0.1256, -0.9325],\n",
            "        [-1.3969,  1.7262, -0.6361],\n",
            "        [-1.7543,  1.3060,  0.1969],\n",
            "        [-1.8196,  0.8097,  0.9570],\n",
            "        [-1.5026,  1.6751, -0.0532],\n",
            "        [-1.6889,  1.0472,  0.7146],\n",
            "        [-2.0123,  0.5538,  0.8540],\n",
            "        [-1.5723,  1.8600, -0.3206]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.5633,  0.0499,  0.0585],\n",
            "        [-1.7509,  1.7157, -0.2564],\n",
            "        [-1.6317,  1.8051, -0.5502],\n",
            "        [-1.9252,  1.9191, -0.4182],\n",
            "        [-1.6463,  1.8332, -0.0860],\n",
            "        [-1.7795,  1.0855,  0.6090],\n",
            "        [-1.7038,  0.8228,  0.6337],\n",
            "        [-1.5327,  1.4852, -0.1349],\n",
            "        [-1.6047,  1.8957, -0.4550],\n",
            "        [-1.7642,  0.5718,  0.8998],\n",
            "        [-2.0118,  0.7838,  0.9195],\n",
            "        [ 0.3696, -0.0115, -0.8378],\n",
            "        [-1.6408,  1.7329, -0.2990],\n",
            "        [-1.7751,  0.8846,  0.8574],\n",
            "        [-1.6503,  0.5879,  0.8486],\n",
            "        [-1.7746,  1.9312, -0.3806]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-0.5633,  0.0499,  0.0585],\n",
            "        [-1.7509,  1.7157, -0.2564],\n",
            "        [-1.6317,  1.8051, -0.5502],\n",
            "        [-1.9252,  1.9191, -0.4182],\n",
            "        [-1.6463,  1.8332, -0.0860],\n",
            "        [-1.7795,  1.0855,  0.6090],\n",
            "        [-1.7038,  0.8228,  0.6337],\n",
            "        [-1.5327,  1.4852, -0.1349],\n",
            "        [-1.6047,  1.8957, -0.4550],\n",
            "        [-1.7642,  0.5718,  0.8998],\n",
            "        [-2.0118,  0.7838,  0.9195],\n",
            "        [ 0.3696, -0.0115, -0.8378],\n",
            "        [-1.6408,  1.7329, -0.2990],\n",
            "        [-1.7751,  0.8846,  0.8574],\n",
            "        [-1.6503,  0.5879,  0.8486],\n",
            "        [-1.7746,  1.9312, -0.3806]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8517,  0.5981,  1.0467],\n",
            "        [-1.5945,  1.9346, -0.2156],\n",
            "        [-1.4919,  1.7977, -0.4101],\n",
            "        [-1.5277,  1.9043, -0.7973],\n",
            "        [ 0.0987,  0.1077, -1.0276],\n",
            "        [-1.7561,  1.7392,  0.0134],\n",
            "        [ 0.2128,  0.3110, -0.9650],\n",
            "        [-1.6700,  1.9100, -0.5321],\n",
            "        [-1.8558,  2.0826, -0.1712],\n",
            "        [-1.7170,  0.5772,  1.0371],\n",
            "        [-1.6391,  1.8957, -0.5136],\n",
            "        [-1.5922,  1.5265, -0.2298],\n",
            "        [-1.9091,  0.6726,  0.8843],\n",
            "        [-1.6938,  1.9434, -0.4080],\n",
            "        [-1.5649,  0.3384,  1.0274],\n",
            "        [-2.0017,  1.6207,  0.1490]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8517,  0.5981,  1.0467],\n",
            "        [-1.5945,  1.9346, -0.2156],\n",
            "        [-1.4919,  1.7977, -0.4101],\n",
            "        [-1.5277,  1.9043, -0.7973],\n",
            "        [ 0.0987,  0.1077, -1.0276],\n",
            "        [-1.7561,  1.7392,  0.0134],\n",
            "        [ 0.2128,  0.3110, -0.9650],\n",
            "        [-1.6700,  1.9100, -0.5321],\n",
            "        [-1.8558,  2.0826, -0.1712],\n",
            "        [-1.7170,  0.5772,  1.0371],\n",
            "        [-1.6391,  1.8957, -0.5136],\n",
            "        [-1.5922,  1.5265, -0.2298],\n",
            "        [-1.9091,  0.6726,  0.8843],\n",
            "        [-1.6938,  1.9434, -0.4080],\n",
            "        [-1.5649,  0.3384,  1.0274],\n",
            "        [-2.0017,  1.6207,  0.1490]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3493, -0.1457, -0.8999],\n",
            "        [-1.5813,  1.7386, -0.2679],\n",
            "        [-1.9161,  0.6639,  1.1261],\n",
            "        [-1.7899,  1.7630, -0.1966],\n",
            "        [-2.0045,  1.1728,  0.6611],\n",
            "        [-1.8848,  0.8672,  0.6822],\n",
            "        [-1.8870,  1.2379,  0.3015],\n",
            "        [-1.7384,  1.9443, -0.3798],\n",
            "        [-1.6802,  0.3418,  1.0362],\n",
            "        [-1.6925,  2.0153, -0.4035],\n",
            "        [-1.7644,  1.8636, -0.4417],\n",
            "        [-1.7842,  0.7821,  0.8121],\n",
            "        [ 0.2843, -0.1404, -0.8527],\n",
            "        [-1.4883,  1.7667, -0.3606],\n",
            "        [ 0.3434, -0.0639, -0.8469],\n",
            "        [-1.5391,  2.0920, -0.3897]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.3493, -0.1457, -0.8999],\n",
            "        [-1.5813,  1.7386, -0.2679],\n",
            "        [-1.9161,  0.6639,  1.1261],\n",
            "        [-1.7899,  1.7630, -0.1966],\n",
            "        [-2.0045,  1.1728,  0.6611],\n",
            "        [-1.8848,  0.8672,  0.6822],\n",
            "        [-1.8870,  1.2379,  0.3015],\n",
            "        [-1.7384,  1.9443, -0.3798],\n",
            "        [-1.6802,  0.3418,  1.0362],\n",
            "        [-1.6925,  2.0153, -0.4035],\n",
            "        [-1.7644,  1.8636, -0.4417],\n",
            "        [-1.7842,  0.7821,  0.8121],\n",
            "        [ 0.2843, -0.1404, -0.8527],\n",
            "        [-1.4883,  1.7667, -0.3606],\n",
            "        [ 0.3434, -0.0639, -0.8469],\n",
            "        [-1.5391,  2.0920, -0.3897]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6053,  1.9436, -0.5422],\n",
            "        [-1.8089,  1.8275, -0.5344],\n",
            "        [ 0.4776, -0.2012, -0.9687],\n",
            "        [-1.6384,  1.8452, -0.4524],\n",
            "        [ 0.3514,  0.0295, -0.9570],\n",
            "        [-1.7714,  1.6923, -0.1573],\n",
            "        [-1.8362,  1.5493,  0.1061],\n",
            "        [-1.7656,  1.3173,  0.0874],\n",
            "        [-1.7632,  1.6686, -0.4125],\n",
            "        [-1.7684,  1.2561,  0.3205],\n",
            "        [-1.5590,  1.8245, -0.3079],\n",
            "        [ 0.2408,  0.0152, -0.8492],\n",
            "        [-1.8124,  0.5650,  1.0243],\n",
            "        [-1.5567,  1.9612, -0.3240],\n",
            "        [-1.7590,  0.7368,  0.5774],\n",
            "        [-1.6754,  2.0079, -0.3971]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6053,  1.9436, -0.5422],\n",
            "        [-1.8089,  1.8275, -0.5344],\n",
            "        [ 0.4776, -0.2012, -0.9687],\n",
            "        [-1.6384,  1.8452, -0.4524],\n",
            "        [ 0.3514,  0.0295, -0.9570],\n",
            "        [-1.7714,  1.6923, -0.1573],\n",
            "        [-1.8362,  1.5493,  0.1061],\n",
            "        [-1.7656,  1.3173,  0.0874],\n",
            "        [-1.7632,  1.6686, -0.4125],\n",
            "        [-1.7684,  1.2561,  0.3205],\n",
            "        [-1.5590,  1.8245, -0.3079],\n",
            "        [ 0.2408,  0.0152, -0.8492],\n",
            "        [-1.8124,  0.5650,  1.0243],\n",
            "        [-1.5567,  1.9612, -0.3240],\n",
            "        [-1.7590,  0.7368,  0.5774],\n",
            "        [-1.6754,  2.0079, -0.3971]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7322,  0.5833,  0.8712],\n",
            "        [-1.5441,  1.7207, -0.1714],\n",
            "        [-1.4173,  1.9071, -0.6055],\n",
            "        [-1.7539,  0.7153,  0.8468],\n",
            "        [-0.3406,  0.7273, -0.9769],\n",
            "        [-1.8413,  0.4675,  1.0166],\n",
            "        [-1.7750,  0.7875,  0.9322],\n",
            "        [-1.7127,  0.9301,  0.8975],\n",
            "        [-1.6560,  1.9659, -0.5360],\n",
            "        [-1.7196,  1.9586, -0.3239],\n",
            "        [-1.7311,  0.4297,  0.9182],\n",
            "        [-1.0358,  0.7666,  0.4168],\n",
            "        [-1.5250,  1.8217, -0.4477],\n",
            "        [-1.8247,  1.8839, -0.7165],\n",
            "        [-1.6689,  1.8355, -0.2694],\n",
            "        [ 0.4420, -0.0880, -0.9167]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7322,  0.5833,  0.8712],\n",
            "        [-1.5441,  1.7207, -0.1714],\n",
            "        [-1.4173,  1.9071, -0.6055],\n",
            "        [-1.7539,  0.7153,  0.8468],\n",
            "        [-0.3406,  0.7273, -0.9769],\n",
            "        [-1.8413,  0.4675,  1.0166],\n",
            "        [-1.7750,  0.7875,  0.9322],\n",
            "        [-1.7127,  0.9301,  0.8975],\n",
            "        [-1.6560,  1.9659, -0.5360],\n",
            "        [-1.7196,  1.9586, -0.3239],\n",
            "        [-1.7311,  0.4297,  0.9182],\n",
            "        [-1.0358,  0.7666,  0.4168],\n",
            "        [-1.5250,  1.8217, -0.4477],\n",
            "        [-1.8247,  1.8839, -0.7165],\n",
            "        [-1.6689,  1.8355, -0.2694],\n",
            "        [ 0.4420, -0.0880, -0.9167]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7437,  2.0448, -0.5546],\n",
            "        [-1.6738,  1.9089, -0.4855],\n",
            "        [-1.4335,  1.7948, -0.6577],\n",
            "        [-1.7304,  1.9475, -0.3578],\n",
            "        [-1.7789,  2.0496, -0.5071],\n",
            "        [-1.2005,  0.6983,  0.4250],\n",
            "        [-1.7411,  2.0197, -0.4741],\n",
            "        [-0.4037,  0.2771, -0.3014],\n",
            "        [-1.6126,  0.2149,  1.0812],\n",
            "        [ 0.5812, -0.1288, -0.8380],\n",
            "        [-1.6224,  1.9599, -0.3730],\n",
            "        [-1.8983,  0.7563,  0.7534],\n",
            "        [-1.7568,  1.7041, -0.4759],\n",
            "        [ 0.0692,  0.1435, -0.9741],\n",
            "        [ 0.1324,  0.2429, -1.0195],\n",
            "        [-1.7623,  0.7693,  0.7694]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7437,  2.0448, -0.5546],\n",
            "        [-1.6738,  1.9089, -0.4855],\n",
            "        [-1.4335,  1.7948, -0.6577],\n",
            "        [-1.7304,  1.9475, -0.3578],\n",
            "        [-1.7789,  2.0496, -0.5071],\n",
            "        [-1.2005,  0.6983,  0.4250],\n",
            "        [-1.7411,  2.0197, -0.4741],\n",
            "        [-0.4037,  0.2771, -0.3014],\n",
            "        [-1.6126,  0.2149,  1.0812],\n",
            "        [ 0.5812, -0.1288, -0.8380],\n",
            "        [-1.6224,  1.9599, -0.3730],\n",
            "        [-1.8983,  0.7563,  0.7534],\n",
            "        [-1.7568,  1.7041, -0.4759],\n",
            "        [ 0.0692,  0.1435, -0.9741],\n",
            "        [ 0.1324,  0.2429, -1.0195],\n",
            "        [-1.7623,  0.7693,  0.7694]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6019,  2.0041, -0.8306],\n",
            "        [-1.6421,  2.0453, -0.4202],\n",
            "        [ 0.4389, -0.1379, -0.8017],\n",
            "        [-1.5533,  1.8997, -0.5175],\n",
            "        [-1.8128,  0.5446,  1.1388],\n",
            "        [-1.6396,  1.7638, -0.5588],\n",
            "        [-1.5916,  2.0492, -0.7416],\n",
            "        [ 0.4771, -0.2299, -0.8506],\n",
            "        [-1.9977,  0.5615,  0.9539],\n",
            "        [-1.6164,  2.0879, -0.4113],\n",
            "        [ 0.3795, -0.1234, -0.6830],\n",
            "        [-1.5766,  0.6052,  0.8614],\n",
            "        [-1.5846,  1.9017, -0.1139],\n",
            "        [-1.7014,  1.7508, -0.2860],\n",
            "        [-1.4770,  1.4877, -0.5657],\n",
            "        [-1.5585,  1.9586, -0.6742]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6019,  2.0041, -0.8306],\n",
            "        [-1.6421,  2.0453, -0.4202],\n",
            "        [ 0.4389, -0.1379, -0.8017],\n",
            "        [-1.5533,  1.8997, -0.5175],\n",
            "        [-1.8128,  0.5446,  1.1388],\n",
            "        [-1.6396,  1.7638, -0.5588],\n",
            "        [-1.5916,  2.0492, -0.7416],\n",
            "        [ 0.4771, -0.2299, -0.8506],\n",
            "        [-1.9977,  0.5615,  0.9539],\n",
            "        [-1.6164,  2.0879, -0.4113],\n",
            "        [ 0.3795, -0.1234, -0.6830],\n",
            "        [-1.5766,  0.6052,  0.8614],\n",
            "        [-1.5846,  1.9017, -0.1139],\n",
            "        [-1.7014,  1.7508, -0.2860],\n",
            "        [-1.4770,  1.4877, -0.5657],\n",
            "        [-1.5585,  1.9586, -0.6742]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7065,  1.8254, -0.3477],\n",
            "        [ 0.2224,  0.1974, -0.9744],\n",
            "        [-1.6090,  0.7140,  1.1357],\n",
            "        [-1.5833,  2.1213, -0.5496],\n",
            "        [-1.8342,  0.5057,  1.0899],\n",
            "        [-1.5672,  1.6880, -0.5944],\n",
            "        [-1.7604,  0.4576,  0.8434],\n",
            "        [-1.8244,  1.9796, -0.8075],\n",
            "        [-1.5622,  1.9199, -0.2403],\n",
            "        [-1.7333,  1.9685, -0.6525],\n",
            "        [-1.8403,  2.1271, -0.4833],\n",
            "        [-1.6670,  0.8526,  0.8462],\n",
            "        [-1.6258,  2.2357, -0.5507],\n",
            "        [-1.2688,  1.9601, -0.7827],\n",
            "        [-1.5731,  2.1601, -0.4835],\n",
            "        [-1.5495,  0.6542,  0.6791]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7065,  1.8254, -0.3477],\n",
            "        [ 0.2224,  0.1974, -0.9744],\n",
            "        [-1.6090,  0.7140,  1.1357],\n",
            "        [-1.5833,  2.1213, -0.5496],\n",
            "        [-1.8342,  0.5057,  1.0899],\n",
            "        [-1.5672,  1.6880, -0.5944],\n",
            "        [-1.7604,  0.4576,  0.8434],\n",
            "        [-1.8244,  1.9796, -0.8075],\n",
            "        [-1.5622,  1.9199, -0.2403],\n",
            "        [-1.7333,  1.9685, -0.6525],\n",
            "        [-1.8403,  2.1271, -0.4833],\n",
            "        [-1.6670,  0.8526,  0.8462],\n",
            "        [-1.6258,  2.2357, -0.5507],\n",
            "        [-1.2688,  1.9601, -0.7827],\n",
            "        [-1.5731,  2.1601, -0.4835],\n",
            "        [-1.5495,  0.6542,  0.6791]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7118,  2.2183, -0.6238],\n",
            "        [-1.6831,  1.8727, -0.6320],\n",
            "        [-1.3401,  1.9675, -0.4143],\n",
            "        [ 0.1783,  0.2057, -1.1051],\n",
            "        [-2.0132,  2.0027, -0.1249],\n",
            "        [ 0.5054, -0.2267, -0.9375],\n",
            "        [-1.5523,  1.3576, -0.0148],\n",
            "        [-1.8589,  0.4266,  1.1245],\n",
            "        [-1.8025,  1.4686,  0.0481],\n",
            "        [-1.7106,  2.0143, -0.4253],\n",
            "        [-1.5467,  2.0352, -0.3726],\n",
            "        [-1.0385,  0.1158,  0.5062],\n",
            "        [-1.5078,  1.8373, -0.5735],\n",
            "        [ 0.0368,  0.2646, -1.1202],\n",
            "        [-1.4570,  1.8124, -0.2613],\n",
            "        [-1.7669,  1.6671,  0.0975]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7118,  2.2183, -0.6238],\n",
            "        [-1.6831,  1.8727, -0.6320],\n",
            "        [-1.3401,  1.9675, -0.4143],\n",
            "        [ 0.1783,  0.2057, -1.1051],\n",
            "        [-2.0132,  2.0027, -0.1249],\n",
            "        [ 0.5054, -0.2267, -0.9375],\n",
            "        [-1.5523,  1.3576, -0.0148],\n",
            "        [-1.8589,  0.4266,  1.1245],\n",
            "        [-1.8025,  1.4686,  0.0481],\n",
            "        [-1.7106,  2.0143, -0.4253],\n",
            "        [-1.5467,  2.0352, -0.3726],\n",
            "        [-1.0385,  0.1158,  0.5062],\n",
            "        [-1.5078,  1.8373, -0.5735],\n",
            "        [ 0.0368,  0.2646, -1.1202],\n",
            "        [-1.4570,  1.8124, -0.2613],\n",
            "        [-1.7669,  1.6671,  0.0975]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6655,  2.0827, -0.3907],\n",
            "        [-1.9213,  2.0319, -0.4715],\n",
            "        [-1.7127,  2.0406, -0.3392],\n",
            "        [-1.6673,  0.7010,  0.7634],\n",
            "        [-1.5330,  1.9561, -0.5189],\n",
            "        [ 0.2909, -0.1607, -0.6177],\n",
            "        [ 0.4890, -0.3274, -0.6618],\n",
            "        [-1.5621,  1.9332, -0.6246],\n",
            "        [-1.4838,  1.8994, -0.5419],\n",
            "        [-1.8331,  0.5519,  0.9931],\n",
            "        [-1.6209,  2.0409, -0.6764],\n",
            "        [-1.6443,  1.9465, -0.3636],\n",
            "        [-1.8636,  2.0527, -0.2969],\n",
            "        [-1.4469,  1.8125, -0.2063],\n",
            "        [-1.7338,  2.1229, -0.5602],\n",
            "        [-1.6909,  1.6198, -0.2978]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6655,  2.0827, -0.3907],\n",
            "        [-1.9213,  2.0319, -0.4715],\n",
            "        [-1.7127,  2.0406, -0.3392],\n",
            "        [-1.6673,  0.7010,  0.7634],\n",
            "        [-1.5330,  1.9561, -0.5189],\n",
            "        [ 0.2909, -0.1607, -0.6177],\n",
            "        [ 0.4890, -0.3274, -0.6618],\n",
            "        [-1.5621,  1.9332, -0.6246],\n",
            "        [-1.4838,  1.8994, -0.5419],\n",
            "        [-1.8331,  0.5519,  0.9931],\n",
            "        [-1.6209,  2.0409, -0.6764],\n",
            "        [-1.6443,  1.9465, -0.3636],\n",
            "        [-1.8636,  2.0527, -0.2969],\n",
            "        [-1.4469,  1.8125, -0.2063],\n",
            "        [-1.7338,  2.1229, -0.5602],\n",
            "        [-1.6909,  1.6198, -0.2978]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8094,  1.8633, -0.6160],\n",
            "        [-1.7225,  0.3433,  1.0621],\n",
            "        [-1.7957,  1.9848, -0.4167],\n",
            "        [-1.9262,  0.7486,  0.8310],\n",
            "        [ 0.4763, -0.2744, -0.7507],\n",
            "        [-1.9679,  0.4663,  1.1724],\n",
            "        [-1.5480,  0.5361,  1.0039],\n",
            "        [-1.7245,  2.1123, -0.5769],\n",
            "        [-1.8360,  1.9398, -0.3278],\n",
            "        [-1.8872,  0.6248,  1.0219],\n",
            "        [-1.6805,  0.3840,  1.1367],\n",
            "        [-1.7665,  1.9022, -0.2766],\n",
            "        [-1.2665,  1.7644, -0.4730],\n",
            "        [-1.6298,  2.0635, -0.4711],\n",
            "        [-1.6417,  0.4009,  0.9251],\n",
            "        [-1.6630,  2.0078, -0.4439]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8094,  1.8633, -0.6160],\n",
            "        [-1.7225,  0.3433,  1.0621],\n",
            "        [-1.7957,  1.9848, -0.4167],\n",
            "        [-1.9262,  0.7486,  0.8310],\n",
            "        [ 0.4763, -0.2744, -0.7507],\n",
            "        [-1.9679,  0.4663,  1.1724],\n",
            "        [-1.5480,  0.5361,  1.0039],\n",
            "        [-1.7245,  2.1123, -0.5769],\n",
            "        [-1.8360,  1.9398, -0.3278],\n",
            "        [-1.8872,  0.6248,  1.0219],\n",
            "        [-1.6805,  0.3840,  1.1367],\n",
            "        [-1.7665,  1.9022, -0.2766],\n",
            "        [-1.2665,  1.7644, -0.4730],\n",
            "        [-1.6298,  2.0635, -0.4711],\n",
            "        [-1.6417,  0.4009,  0.9251],\n",
            "        [-1.6630,  2.0078, -0.4439]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7707,  1.7335, -0.2259],\n",
            "        [-1.5566,  1.7763, -0.5101],\n",
            "        [-1.9082,  2.0146, -0.1573],\n",
            "        [-1.8710,  1.7731,  0.1729],\n",
            "        [-1.7237,  2.1202, -0.3626],\n",
            "        [-1.5457,  0.3285,  1.0272],\n",
            "        [-1.7147,  1.9887, -0.5448],\n",
            "        [-1.8297,  1.4826,  0.3143],\n",
            "        [-1.3802,  0.0455,  0.6718],\n",
            "        [-1.8738,  1.7058, -0.0769],\n",
            "        [-1.8756,  1.4405, -0.0903],\n",
            "        [-1.7592,  1.3426,  0.3612],\n",
            "        [-1.5435,  1.8204, -0.4647],\n",
            "        [-1.7759,  0.5901,  0.9739],\n",
            "        [ 0.5486, -0.2652, -0.7763],\n",
            "        [-1.6763,  2.0776, -0.2302]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7707,  1.7335, -0.2259],\n",
            "        [-1.5566,  1.7763, -0.5101],\n",
            "        [-1.9082,  2.0146, -0.1573],\n",
            "        [-1.8710,  1.7731,  0.1729],\n",
            "        [-1.7237,  2.1202, -0.3626],\n",
            "        [-1.5457,  0.3285,  1.0272],\n",
            "        [-1.7147,  1.9887, -0.5448],\n",
            "        [-1.8297,  1.4826,  0.3143],\n",
            "        [-1.3802,  0.0455,  0.6718],\n",
            "        [-1.8738,  1.7058, -0.0769],\n",
            "        [-1.8756,  1.4405, -0.0903],\n",
            "        [-1.7592,  1.3426,  0.3612],\n",
            "        [-1.5435,  1.8204, -0.4647],\n",
            "        [-1.7759,  0.5901,  0.9739],\n",
            "        [ 0.5486, -0.2652, -0.7763],\n",
            "        [-1.6763,  2.0776, -0.2302]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3289,  1.6413, -0.7728],\n",
            "        [ 0.4096, -0.1663, -0.8247],\n",
            "        [-2.0974,  2.0976, -0.3369],\n",
            "        [-1.7512,  0.8841,  0.9885],\n",
            "        [ 0.5345, -0.1702, -0.8664],\n",
            "        [-1.6641,  0.2440,  0.9708],\n",
            "        [-1.9175,  0.4807,  1.3735],\n",
            "        [-1.7679,  2.0421, -0.4198],\n",
            "        [-1.8150,  0.7540,  0.9288],\n",
            "        [-1.8085,  1.5231,  0.0976],\n",
            "        [-1.6194,  1.9576, -0.5871],\n",
            "        [-0.8456,  0.0736,  0.2901],\n",
            "        [-1.6709,  2.0734, -0.2772],\n",
            "        [ 0.4604, -0.2250, -0.6429],\n",
            "        [-1.6285,  0.3698,  1.0869],\n",
            "        [-1.7858,  0.3491,  1.2211]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3289,  1.6413, -0.7728],\n",
            "        [ 0.4096, -0.1663, -0.8247],\n",
            "        [-2.0974,  2.0976, -0.3369],\n",
            "        [-1.7512,  0.8841,  0.9885],\n",
            "        [ 0.5345, -0.1702, -0.8664],\n",
            "        [-1.6641,  0.2440,  0.9708],\n",
            "        [-1.9175,  0.4807,  1.3735],\n",
            "        [-1.7679,  2.0421, -0.4198],\n",
            "        [-1.8150,  0.7540,  0.9288],\n",
            "        [-1.8085,  1.5231,  0.0976],\n",
            "        [-1.6194,  1.9576, -0.5871],\n",
            "        [-0.8456,  0.0736,  0.2901],\n",
            "        [-1.6709,  2.0734, -0.2772],\n",
            "        [ 0.4604, -0.2250, -0.6429],\n",
            "        [-1.6285,  0.3698,  1.0869],\n",
            "        [-1.7858,  0.3491,  1.2211]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6308,  1.7296, -0.3942],\n",
            "        [-1.9579,  1.7922,  0.0146],\n",
            "        [-1.4591,  0.1624,  1.1802],\n",
            "        [ 0.4970, -0.1785, -0.9226],\n",
            "        [-1.7179,  1.9122, -0.4836],\n",
            "        [-1.7995,  2.1261, -0.2306],\n",
            "        [-1.8418,  1.9652, -0.3473],\n",
            "        [-1.4297,  0.1334,  1.1818],\n",
            "        [-1.8699,  0.5926,  0.8324],\n",
            "        [-1.9244,  0.9474,  0.5301],\n",
            "        [-1.7440,  0.9746,  1.0141],\n",
            "        [-2.0022,  2.0746,  0.0764],\n",
            "        [-1.5102,  1.9464, -0.4964],\n",
            "        [-1.8486,  2.1571, -0.2800],\n",
            "        [-1.8504,  0.5147,  1.0303],\n",
            "        [-1.7886,  1.5782, -0.3427]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6308,  1.7296, -0.3942],\n",
            "        [-1.9579,  1.7922,  0.0146],\n",
            "        [-1.4591,  0.1624,  1.1802],\n",
            "        [ 0.4970, -0.1785, -0.9226],\n",
            "        [-1.7179,  1.9122, -0.4836],\n",
            "        [-1.7995,  2.1261, -0.2306],\n",
            "        [-1.8418,  1.9652, -0.3473],\n",
            "        [-1.4297,  0.1334,  1.1818],\n",
            "        [-1.8699,  0.5926,  0.8324],\n",
            "        [-1.9244,  0.9474,  0.5301],\n",
            "        [-1.7440,  0.9746,  1.0141],\n",
            "        [-2.0022,  2.0746,  0.0764],\n",
            "        [-1.5102,  1.9464, -0.4964],\n",
            "        [-1.8486,  2.1571, -0.2800],\n",
            "        [-1.8504,  0.5147,  1.0303],\n",
            "        [-1.7886,  1.5782, -0.3427]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.3920,  0.7532, -0.6900],\n",
            "        [-1.8025,  1.9164, -0.4972],\n",
            "        [-1.8844,  2.1888, -0.2351],\n",
            "        [-1.6875,  0.7625,  0.6862],\n",
            "        [-1.7248,  1.9270, -0.4190],\n",
            "        [ 0.0719,  0.2219, -0.7717],\n",
            "        [-1.7970,  0.2967,  1.2698],\n",
            "        [-2.0413,  0.5414,  1.2319],\n",
            "        [-1.5996,  1.9234, -0.4221],\n",
            "        [ 0.6151, -0.2913, -0.7568],\n",
            "        [-1.7363,  1.9348, -0.0990],\n",
            "        [-1.6429,  0.3479,  1.2216],\n",
            "        [-1.9164,  1.8624, -0.4039],\n",
            "        [-1.7619,  0.3300,  1.1911],\n",
            "        [-1.6175,  0.8652,  0.3778],\n",
            "        [-1.6818,  0.2448,  1.2245]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-0.3920,  0.7532, -0.6900],\n",
            "        [-1.8025,  1.9164, -0.4972],\n",
            "        [-1.8844,  2.1888, -0.2351],\n",
            "        [-1.6875,  0.7625,  0.6862],\n",
            "        [-1.7248,  1.9270, -0.4190],\n",
            "        [ 0.0719,  0.2219, -0.7717],\n",
            "        [-1.7970,  0.2967,  1.2698],\n",
            "        [-2.0413,  0.5414,  1.2319],\n",
            "        [-1.5996,  1.9234, -0.4221],\n",
            "        [ 0.6151, -0.2913, -0.7568],\n",
            "        [-1.7363,  1.9348, -0.0990],\n",
            "        [-1.6429,  0.3479,  1.2216],\n",
            "        [-1.9164,  1.8624, -0.4039],\n",
            "        [-1.7619,  0.3300,  1.1911],\n",
            "        [-1.6175,  0.8652,  0.3778],\n",
            "        [-1.6818,  0.2448,  1.2245]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6843,  0.1769,  1.3577],\n",
            "        [-1.6072,  0.1309,  1.3600],\n",
            "        [-1.7617,  2.0308, -0.3095],\n",
            "        [-1.5440,  0.2296,  1.2404],\n",
            "        [-1.7038,  1.9413, -0.5335],\n",
            "        [-1.7616,  0.8513,  0.8934],\n",
            "        [-1.8252,  0.5180,  1.0525],\n",
            "        [-1.9035,  2.0929, -0.4117],\n",
            "        [-1.9184,  1.9947, -0.4135],\n",
            "        [-1.7971,  2.0681, -0.2863],\n",
            "        [-1.3335,  0.9165,  0.2362],\n",
            "        [-1.6263,  1.5903, -0.4650],\n",
            "        [-1.5783,  1.6040, -0.4449],\n",
            "        [-1.8806,  1.9936, -0.4118],\n",
            "        [-2.0156,  0.4158,  1.1894],\n",
            "        [-1.9758,  1.8286, -0.1532]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6843,  0.1769,  1.3577],\n",
            "        [-1.6072,  0.1309,  1.3600],\n",
            "        [-1.7617,  2.0308, -0.3095],\n",
            "        [-1.5440,  0.2296,  1.2404],\n",
            "        [-1.7038,  1.9413, -0.5335],\n",
            "        [-1.7616,  0.8513,  0.8934],\n",
            "        [-1.8252,  0.5180,  1.0525],\n",
            "        [-1.9035,  2.0929, -0.4117],\n",
            "        [-1.9184,  1.9947, -0.4135],\n",
            "        [-1.7971,  2.0681, -0.2863],\n",
            "        [-1.3335,  0.9165,  0.2362],\n",
            "        [-1.6263,  1.5903, -0.4650],\n",
            "        [-1.5783,  1.6040, -0.4449],\n",
            "        [-1.8806,  1.9936, -0.4118],\n",
            "        [-2.0156,  0.4158,  1.1894],\n",
            "        [-1.9758,  1.8286, -0.1532]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4401,  1.7471, -0.4319],\n",
            "        [-1.8308,  1.9789, -0.4953],\n",
            "        [ 0.4783, -0.2634, -0.7905],\n",
            "        [-1.8522,  1.4586, -0.0225],\n",
            "        [-1.7396,  1.6992, -0.3369],\n",
            "        [-1.9616,  1.9712, -0.1244],\n",
            "        [-1.7606,  1.9050,  0.0033],\n",
            "        [-1.7555,  0.3587,  1.1986],\n",
            "        [-1.9027,  1.7576, -0.1189],\n",
            "        [-1.9804,  0.7706,  1.0117],\n",
            "        [-1.7503,  0.1044,  1.1608],\n",
            "        [ 0.2854, -0.1032, -0.7467],\n",
            "        [-1.1399,  1.4867, -0.8154],\n",
            "        [-1.9156,  0.7014,  0.9613],\n",
            "        [-1.3528,  0.2496,  0.7380],\n",
            "        [ 0.3150, -0.1402, -0.7129]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4401,  1.7471, -0.4319],\n",
            "        [-1.8308,  1.9789, -0.4953],\n",
            "        [ 0.4783, -0.2634, -0.7905],\n",
            "        [-1.8522,  1.4586, -0.0225],\n",
            "        [-1.7396,  1.6992, -0.3369],\n",
            "        [-1.9616,  1.9712, -0.1244],\n",
            "        [-1.7606,  1.9050,  0.0033],\n",
            "        [-1.7555,  0.3587,  1.1986],\n",
            "        [-1.9027,  1.7576, -0.1189],\n",
            "        [-1.9804,  0.7706,  1.0117],\n",
            "        [-1.7503,  0.1044,  1.1608],\n",
            "        [ 0.2854, -0.1032, -0.7467],\n",
            "        [-1.1399,  1.4867, -0.8154],\n",
            "        [-1.9156,  0.7014,  0.9613],\n",
            "        [-1.3528,  0.2496,  0.7380],\n",
            "        [ 0.3150, -0.1402, -0.7129]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7807e+00,  1.7876e+00, -4.2513e-01],\n",
            "        [-1.7246e+00,  1.7366e+00, -4.2808e-01],\n",
            "        [-2.0551e+00,  1.9004e+00, -8.0623e-02],\n",
            "        [-1.8931e+00,  1.7496e+00, -1.1227e-01],\n",
            "        [ 5.6146e-01, -4.1001e-01, -7.4135e-01],\n",
            "        [-2.1209e+00,  1.1192e+00,  7.5940e-01],\n",
            "        [-1.6049e+00,  1.3540e+00, -9.3923e-04],\n",
            "        [-1.8110e+00,  2.0291e+00, -3.3600e-01],\n",
            "        [-1.8309e+00,  2.9771e-01,  1.1976e+00],\n",
            "        [-1.6937e+00,  1.9827e+00, -4.9205e-01],\n",
            "        [-1.7052e+00,  1.6801e+00, -3.6186e-01],\n",
            "        [-1.7495e+00,  1.9099e+00, -2.9835e-01],\n",
            "        [-1.8756e+00,  2.0135e+00, -1.6908e-01],\n",
            "        [-1.9282e+00,  2.0731e+00, -4.7202e-01],\n",
            "        [-2.0190e+00,  1.0086e+00,  7.5922e-01],\n",
            "        [-1.7815e+00,  2.9947e-01,  1.3453e+00]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7807e+00,  1.7876e+00, -4.2513e-01],\n",
            "        [-1.7246e+00,  1.7366e+00, -4.2808e-01],\n",
            "        [-2.0551e+00,  1.9004e+00, -8.0623e-02],\n",
            "        [-1.8931e+00,  1.7496e+00, -1.1227e-01],\n",
            "        [ 5.6146e-01, -4.1001e-01, -7.4135e-01],\n",
            "        [-2.1209e+00,  1.1192e+00,  7.5940e-01],\n",
            "        [-1.6049e+00,  1.3540e+00, -9.3923e-04],\n",
            "        [-1.8110e+00,  2.0291e+00, -3.3600e-01],\n",
            "        [-1.8309e+00,  2.9771e-01,  1.1976e+00],\n",
            "        [-1.6937e+00,  1.9827e+00, -4.9205e-01],\n",
            "        [-1.7052e+00,  1.6801e+00, -3.6186e-01],\n",
            "        [-1.7495e+00,  1.9099e+00, -2.9835e-01],\n",
            "        [-1.8756e+00,  2.0135e+00, -1.6908e-01],\n",
            "        [-1.9282e+00,  2.0731e+00, -4.7202e-01],\n",
            "        [-2.0190e+00,  1.0086e+00,  7.5922e-01],\n",
            "        [-1.7815e+00,  2.9947e-01,  1.3453e+00]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9591,  1.9848, -0.4950],\n",
            "        [-1.8128,  0.3613,  1.1985],\n",
            "        [-1.6925, -0.0460,  1.1841],\n",
            "        [-2.0027,  1.9906, -0.2109],\n",
            "        [-2.0759,  1.8091,  0.1674],\n",
            "        [-1.9404,  1.9098, -0.5035],\n",
            "        [-1.6906,  1.6400, -0.5598],\n",
            "        [-0.4487, -0.1111,  0.3103],\n",
            "        [-1.8152,  2.0337, -0.4377],\n",
            "        [-1.6800,  0.3643,  1.4768],\n",
            "        [-1.8685,  0.4880,  1.1960],\n",
            "        [-1.7564,  1.9096, -0.5442],\n",
            "        [ 0.1167, -0.3576, -0.2345],\n",
            "        [-1.8418,  2.0271, -0.0193],\n",
            "        [ 0.4915, -0.1280, -0.8629],\n",
            "        [-1.7678,  0.6611,  0.9612]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9591,  1.9848, -0.4950],\n",
            "        [-1.8128,  0.3613,  1.1985],\n",
            "        [-1.6925, -0.0460,  1.1841],\n",
            "        [-2.0027,  1.9906, -0.2109],\n",
            "        [-2.0759,  1.8091,  0.1674],\n",
            "        [-1.9404,  1.9098, -0.5035],\n",
            "        [-1.6906,  1.6400, -0.5598],\n",
            "        [-0.4487, -0.1111,  0.3103],\n",
            "        [-1.8152,  2.0337, -0.4377],\n",
            "        [-1.6800,  0.3643,  1.4768],\n",
            "        [-1.8685,  0.4880,  1.1960],\n",
            "        [-1.7564,  1.9096, -0.5442],\n",
            "        [ 0.1167, -0.3576, -0.2345],\n",
            "        [-1.8418,  2.0271, -0.0193],\n",
            "        [ 0.4915, -0.1280, -0.8629],\n",
            "        [-1.7678,  0.6611,  0.9612]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8886,  1.8432, -0.4014],\n",
            "        [-1.6874,  0.2042,  1.0564],\n",
            "        [-1.7265,  0.1982,  1.3502],\n",
            "        [-2.0174,  0.9551,  0.7042],\n",
            "        [-1.8036,  1.7396, -0.1978],\n",
            "        [-1.7975,  0.1959,  1.1254],\n",
            "        [-1.6980,  0.0931,  1.3476],\n",
            "        [-1.8170,  1.9174, -0.1391],\n",
            "        [ 0.5860, -0.2478, -0.7467],\n",
            "        [-1.8614,  0.3235,  1.3141],\n",
            "        [-1.7047,  0.3196,  1.1920],\n",
            "        [-2.0189,  1.3377,  0.5843],\n",
            "        [-2.0697,  1.3644,  0.4477],\n",
            "        [-1.7230,  1.6711, -0.0886],\n",
            "        [-1.6518,  1.5920, -0.2389],\n",
            "        [-1.7698,  2.0265, -0.3664]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8886,  1.8432, -0.4014],\n",
            "        [-1.6874,  0.2042,  1.0564],\n",
            "        [-1.7265,  0.1982,  1.3502],\n",
            "        [-2.0174,  0.9551,  0.7042],\n",
            "        [-1.8036,  1.7396, -0.1978],\n",
            "        [-1.7975,  0.1959,  1.1254],\n",
            "        [-1.6980,  0.0931,  1.3476],\n",
            "        [-1.8170,  1.9174, -0.1391],\n",
            "        [ 0.5860, -0.2478, -0.7467],\n",
            "        [-1.8614,  0.3235,  1.3141],\n",
            "        [-1.7047,  0.3196,  1.1920],\n",
            "        [-2.0189,  1.3377,  0.5843],\n",
            "        [-2.0697,  1.3644,  0.4477],\n",
            "        [-1.7230,  1.6711, -0.0886],\n",
            "        [-1.6518,  1.5920, -0.2389],\n",
            "        [-1.7698,  2.0265, -0.3664]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8703,  2.0375, -0.3745],\n",
            "        [ 0.4498, -0.3314, -0.5276],\n",
            "        [-1.8296,  2.0449, -0.2855],\n",
            "        [ 0.4702, -0.2653, -0.6470],\n",
            "        [ 0.4545, -0.2352, -0.5545],\n",
            "        [-1.7816,  0.2990,  1.2059],\n",
            "        [-1.8029,  1.3795,  0.5076],\n",
            "        [-1.7112,  2.1280, -0.1571],\n",
            "        [-1.6846,  0.2005,  1.2975],\n",
            "        [-1.7614,  0.3176,  1.2898],\n",
            "        [-1.8518,  0.0038,  1.3602],\n",
            "        [-1.9010,  0.5104,  1.2126],\n",
            "        [-1.8700,  1.8871, -0.3431],\n",
            "        [ 0.5457, -0.3524, -0.6591],\n",
            "        [-1.7149,  1.8313, -0.3377],\n",
            "        [-1.9166,  2.0826, -0.4553]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8703,  2.0375, -0.3745],\n",
            "        [ 0.4498, -0.3314, -0.5276],\n",
            "        [-1.8296,  2.0449, -0.2855],\n",
            "        [ 0.4702, -0.2653, -0.6470],\n",
            "        [ 0.4545, -0.2352, -0.5545],\n",
            "        [-1.7816,  0.2990,  1.2059],\n",
            "        [-1.8029,  1.3795,  0.5076],\n",
            "        [-1.7112,  2.1280, -0.1571],\n",
            "        [-1.6846,  0.2005,  1.2975],\n",
            "        [-1.7614,  0.3176,  1.2898],\n",
            "        [-1.8518,  0.0038,  1.3602],\n",
            "        [-1.9010,  0.5104,  1.2126],\n",
            "        [-1.8700,  1.8871, -0.3431],\n",
            "        [ 0.5457, -0.3524, -0.6591],\n",
            "        [-1.7149,  1.8313, -0.3377],\n",
            "        [-1.9166,  2.0826, -0.4553]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5395, -0.3721, -0.4823],\n",
            "        [-1.8125,  1.8929, -0.3455],\n",
            "        [-1.7749,  0.1634,  1.1482],\n",
            "        [-1.9298,  0.4172,  1.4179],\n",
            "        [-1.5416,  0.0719,  1.2284],\n",
            "        [-1.8498,  2.1528, -0.2375],\n",
            "        [-1.7350,  1.8910, -0.3426],\n",
            "        [-1.6599,  0.1748,  1.3470],\n",
            "        [-1.6160,  0.0694,  1.3876],\n",
            "        [-1.9034,  0.9514,  0.8598],\n",
            "        [-2.0746,  1.3503,  0.2479],\n",
            "        [-1.9786,  1.9734, -0.3770],\n",
            "        [-1.8187,  2.0177,  0.0131],\n",
            "        [-2.1479,  1.4218,  0.3714],\n",
            "        [ 0.6155, -0.0675, -1.0099],\n",
            "        [-1.7672,  0.6291,  1.0321]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.5395, -0.3721, -0.4823],\n",
            "        [-1.8125,  1.8929, -0.3455],\n",
            "        [-1.7749,  0.1634,  1.1482],\n",
            "        [-1.9298,  0.4172,  1.4179],\n",
            "        [-1.5416,  0.0719,  1.2284],\n",
            "        [-1.8498,  2.1528, -0.2375],\n",
            "        [-1.7350,  1.8910, -0.3426],\n",
            "        [-1.6599,  0.1748,  1.3470],\n",
            "        [-1.6160,  0.0694,  1.3876],\n",
            "        [-1.9034,  0.9514,  0.8598],\n",
            "        [-2.0746,  1.3503,  0.2479],\n",
            "        [-1.9786,  1.9734, -0.3770],\n",
            "        [-1.8187,  2.0177,  0.0131],\n",
            "        [-2.1479,  1.4218,  0.3714],\n",
            "        [ 0.6155, -0.0675, -1.0099],\n",
            "        [-1.7672,  0.6291,  1.0321]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6417,  0.0209,  1.0898],\n",
            "        [-1.9437,  1.6656, -0.2564],\n",
            "        [-1.8523,  1.7375, -0.0519],\n",
            "        [-1.7421,  0.1594,  1.3260],\n",
            "        [-1.9392,  0.2180,  1.4721],\n",
            "        [-1.8019,  2.1797, -0.3790],\n",
            "        [-1.7822,  0.3324,  1.3926],\n",
            "        [-1.8517,  0.3612,  1.2866],\n",
            "        [-1.8370, -0.0113,  1.3769],\n",
            "        [-1.6706,  1.2658,  0.2034],\n",
            "        [-1.6699,  0.1073,  1.3629],\n",
            "        [-1.4715,  1.7640, -0.2369],\n",
            "        [-1.7433,  1.4366,  0.3219],\n",
            "        [-2.0055,  1.5747,  0.4604],\n",
            "        [-1.8676,  1.9647, -0.1825],\n",
            "        [ 0.5906, -0.3750, -0.6570]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6417,  0.0209,  1.0898],\n",
            "        [-1.9437,  1.6656, -0.2564],\n",
            "        [-1.8523,  1.7375, -0.0519],\n",
            "        [-1.7421,  0.1594,  1.3260],\n",
            "        [-1.9392,  0.2180,  1.4721],\n",
            "        [-1.8019,  2.1797, -0.3790],\n",
            "        [-1.7822,  0.3324,  1.3926],\n",
            "        [-1.8517,  0.3612,  1.2866],\n",
            "        [-1.8370, -0.0113,  1.3769],\n",
            "        [-1.6706,  1.2658,  0.2034],\n",
            "        [-1.6699,  0.1073,  1.3629],\n",
            "        [-1.4715,  1.7640, -0.2369],\n",
            "        [-1.7433,  1.4366,  0.3219],\n",
            "        [-2.0055,  1.5747,  0.4604],\n",
            "        [-1.8676,  1.9647, -0.1825],\n",
            "        [ 0.5906, -0.3750, -0.6570]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8931,  2.0495, -0.2419],\n",
            "        [-1.9637,  1.9117, -0.0381],\n",
            "        [-1.9247,  2.0737, -0.1458],\n",
            "        [-1.5088,  0.1296,  1.2519],\n",
            "        [ 0.5192, -0.2805, -0.7036],\n",
            "        [-1.6604,  1.8089, -0.5408],\n",
            "        [-1.6813,  0.2542,  1.2028],\n",
            "        [-1.7607,  1.7305, -0.2105],\n",
            "        [-1.9380,  2.0496, -0.1304],\n",
            "        [ 0.1920,  0.0380, -0.7151],\n",
            "        [ 0.5217, -0.3065, -0.6612],\n",
            "        [-2.0030,  1.7364,  0.3692],\n",
            "        [-1.6273,  0.3169,  1.2388],\n",
            "        [-1.9336,  1.9714, -0.3434],\n",
            "        [-1.6065,  0.1750,  1.2159],\n",
            "        [-2.1647,  1.4079,  0.5221]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8931,  2.0495, -0.2419],\n",
            "        [-1.9637,  1.9117, -0.0381],\n",
            "        [-1.9247,  2.0737, -0.1458],\n",
            "        [-1.5088,  0.1296,  1.2519],\n",
            "        [ 0.5192, -0.2805, -0.7036],\n",
            "        [-1.6604,  1.8089, -0.5408],\n",
            "        [-1.6813,  0.2542,  1.2028],\n",
            "        [-1.7607,  1.7305, -0.2105],\n",
            "        [-1.9380,  2.0496, -0.1304],\n",
            "        [ 0.1920,  0.0380, -0.7151],\n",
            "        [ 0.5217, -0.3065, -0.6612],\n",
            "        [-2.0030,  1.7364,  0.3692],\n",
            "        [-1.6273,  0.3169,  1.2388],\n",
            "        [-1.9336,  1.9714, -0.3434],\n",
            "        [-1.6065,  0.1750,  1.2159],\n",
            "        [-2.1647,  1.4079,  0.5221]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1525e-01,  4.4840e-01, -7.3604e-01],\n",
            "        [-1.1952e+00, -1.4731e-03,  7.8673e-01],\n",
            "        [-1.7758e+00,  8.7489e-02,  1.4558e+00],\n",
            "        [-1.7848e+00,  1.6653e+00,  1.3726e-01],\n",
            "        [-2.0209e+00,  6.5676e-01,  1.0358e+00],\n",
            "        [-1.9971e+00,  1.0282e+00,  6.8901e-01],\n",
            "        [-2.1296e+00,  1.8007e+00,  1.6147e-01],\n",
            "        [-1.8087e+00,  3.2696e-01,  1.2659e+00],\n",
            "        [-1.8852e+00,  1.9149e-01,  1.3444e+00],\n",
            "        [-1.9916e+00,  2.1724e+00, -3.9776e-02],\n",
            "        [-1.8943e+00,  1.8954e+00, -1.7236e-01],\n",
            "        [-2.0126e+00,  1.9431e+00, -3.9563e-02],\n",
            "        [-2.0094e+00,  1.5383e+00,  1.2323e-01],\n",
            "        [-1.5184e+00,  1.6918e-01,  1.2311e+00],\n",
            "        [-1.9519e+00,  4.5030e-01,  1.1876e+00],\n",
            "        [-1.9226e+00,  1.6026e+00, -1.1362e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1525e-01,  4.4840e-01, -7.3604e-01],\n",
            "        [-1.1952e+00, -1.4731e-03,  7.8673e-01],\n",
            "        [-1.7758e+00,  8.7489e-02,  1.4558e+00],\n",
            "        [-1.7848e+00,  1.6653e+00,  1.3726e-01],\n",
            "        [-2.0209e+00,  6.5676e-01,  1.0358e+00],\n",
            "        [-1.9971e+00,  1.0282e+00,  6.8901e-01],\n",
            "        [-2.1296e+00,  1.8007e+00,  1.6147e-01],\n",
            "        [-1.8087e+00,  3.2696e-01,  1.2659e+00],\n",
            "        [-1.8852e+00,  1.9149e-01,  1.3444e+00],\n",
            "        [-1.9916e+00,  2.1724e+00, -3.9776e-02],\n",
            "        [-1.8943e+00,  1.8954e+00, -1.7236e-01],\n",
            "        [-2.0126e+00,  1.9431e+00, -3.9563e-02],\n",
            "        [-2.0094e+00,  1.5383e+00,  1.2323e-01],\n",
            "        [-1.5184e+00,  1.6918e-01,  1.2311e+00],\n",
            "        [-1.9519e+00,  4.5030e-01,  1.1876e+00],\n",
            "        [-1.9226e+00,  1.6026e+00, -1.1362e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5797,  1.5619, -0.1841],\n",
            "        [ 0.4033, -0.3110, -0.6366],\n",
            "        [-2.0159,  0.7345,  1.0301],\n",
            "        [-1.6959,  0.2869,  1.2141],\n",
            "        [-2.0938,  2.0062, -0.1665],\n",
            "        [-1.7929,  0.2637,  1.3208],\n",
            "        [-1.8544,  1.9201, -0.2765],\n",
            "        [-1.8827,  0.2916,  1.2978],\n",
            "        [-1.6822,  0.1366,  1.1805],\n",
            "        [-1.7741,  0.1703,  1.1474],\n",
            "        [-1.9546,  1.9004, -0.2761],\n",
            "        [ 0.4406, -0.2960, -0.6011],\n",
            "        [-2.0298,  1.8378,  0.3122],\n",
            "        [-1.9376,  1.8065, -0.0492],\n",
            "        [-1.9413,  2.1012, -0.2113],\n",
            "        [-1.7281,  2.0292, -0.2028]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5797,  1.5619, -0.1841],\n",
            "        [ 0.4033, -0.3110, -0.6366],\n",
            "        [-2.0159,  0.7345,  1.0301],\n",
            "        [-1.6959,  0.2869,  1.2141],\n",
            "        [-2.0938,  2.0062, -0.1665],\n",
            "        [-1.7929,  0.2637,  1.3208],\n",
            "        [-1.8544,  1.9201, -0.2765],\n",
            "        [-1.8827,  0.2916,  1.2978],\n",
            "        [-1.6822,  0.1366,  1.1805],\n",
            "        [-1.7741,  0.1703,  1.1474],\n",
            "        [-1.9546,  1.9004, -0.2761],\n",
            "        [ 0.4406, -0.2960, -0.6011],\n",
            "        [-2.0298,  1.8378,  0.3122],\n",
            "        [-1.9376,  1.8065, -0.0492],\n",
            "        [-1.9413,  2.1012, -0.2113],\n",
            "        [-1.7281,  2.0292, -0.2028]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9040,  0.3191,  1.2624],\n",
            "        [-1.8317,  1.7365, -0.2838],\n",
            "        [-1.9062,  1.6405, -0.0745],\n",
            "        [-1.9965,  2.0625, -0.3428],\n",
            "        [-1.7629,  0.0165,  1.2940],\n",
            "        [-1.6235,  1.5081,  0.0501],\n",
            "        [-2.0516,  1.4360,  0.4331],\n",
            "        [-2.0246,  1.8520,  0.0543],\n",
            "        [-1.7723,  0.0607,  1.1290],\n",
            "        [-2.0805,  0.6259,  1.0571],\n",
            "        [-2.2728,  1.9049, -0.0030],\n",
            "        [-1.9261,  0.8980,  0.7692],\n",
            "        [-1.9357,  2.0784, -0.3157],\n",
            "        [-1.8302,  0.3942,  1.2044],\n",
            "        [-1.9622,  0.3462,  1.2181],\n",
            "        [-2.2025,  1.4694,  0.3780]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9040,  0.3191,  1.2624],\n",
            "        [-1.8317,  1.7365, -0.2838],\n",
            "        [-1.9062,  1.6405, -0.0745],\n",
            "        [-1.9965,  2.0625, -0.3428],\n",
            "        [-1.7629,  0.0165,  1.2940],\n",
            "        [-1.6235,  1.5081,  0.0501],\n",
            "        [-2.0516,  1.4360,  0.4331],\n",
            "        [-2.0246,  1.8520,  0.0543],\n",
            "        [-1.7723,  0.0607,  1.1290],\n",
            "        [-2.0805,  0.6259,  1.0571],\n",
            "        [-2.2728,  1.9049, -0.0030],\n",
            "        [-1.9261,  0.8980,  0.7692],\n",
            "        [-1.9357,  2.0784, -0.3157],\n",
            "        [-1.8302,  0.3942,  1.2044],\n",
            "        [-1.9622,  0.3462,  1.2181],\n",
            "        [-2.2025,  1.4694,  0.3780]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1508,  2.1157, -0.0844],\n",
            "        [-2.0445,  1.7399,  0.1653],\n",
            "        [-2.0639,  2.1908,  0.0153],\n",
            "        [ 0.6842, -0.4120, -0.7304],\n",
            "        [-2.1147,  1.7749, -0.2860],\n",
            "        [ 0.5524, -0.3747, -0.6106],\n",
            "        [-2.0058,  0.5799,  0.9978],\n",
            "        [-1.6463,  0.3354,  1.1800],\n",
            "        [-1.5613,  1.7739, -0.1684],\n",
            "        [-1.6162,  0.2460,  1.1453],\n",
            "        [-1.9810,  2.0154, -0.1399],\n",
            "        [-1.7103,  0.3298,  1.4100],\n",
            "        [-1.7642,  0.2989,  1.4783],\n",
            "        [-2.0868,  2.0116,  0.1137],\n",
            "        [-1.6753,  0.1799,  1.2345],\n",
            "        [-1.8975,  0.7500,  0.9080]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1508,  2.1157, -0.0844],\n",
            "        [-2.0445,  1.7399,  0.1653],\n",
            "        [-2.0639,  2.1908,  0.0153],\n",
            "        [ 0.6842, -0.4120, -0.7304],\n",
            "        [-2.1147,  1.7749, -0.2860],\n",
            "        [ 0.5524, -0.3747, -0.6106],\n",
            "        [-2.0058,  0.5799,  0.9978],\n",
            "        [-1.6463,  0.3354,  1.1800],\n",
            "        [-1.5613,  1.7739, -0.1684],\n",
            "        [-1.6162,  0.2460,  1.1453],\n",
            "        [-1.9810,  2.0154, -0.1399],\n",
            "        [-1.7103,  0.3298,  1.4100],\n",
            "        [-1.7642,  0.2989,  1.4783],\n",
            "        [-2.0868,  2.0116,  0.1137],\n",
            "        [-1.6753,  0.1799,  1.2345],\n",
            "        [-1.8975,  0.7500,  0.9080]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0530,  1.3896,  0.4569],\n",
            "        [ 0.4655, -0.1691, -0.8925],\n",
            "        [-2.2295,  1.7352,  0.4504],\n",
            "        [-0.2436, -0.2033,  0.1926],\n",
            "        [-2.0389,  1.9485,  0.0586],\n",
            "        [-2.2112,  2.0202, -0.1152],\n",
            "        [-1.7956,  2.0562, -0.2731],\n",
            "        [-2.0115,  1.7215,  0.3722],\n",
            "        [-2.1531,  1.9398,  0.2716],\n",
            "        [-1.8908,  1.8438, -0.2331],\n",
            "        [-1.8036,  1.7498,  0.1791],\n",
            "        [-1.4995,  1.1897,  0.2119],\n",
            "        [-1.9935,  1.9426,  0.0598],\n",
            "        [-1.9112,  1.5886,  0.2603],\n",
            "        [ 0.5265, -0.3638, -0.5571],\n",
            "        [-1.9292,  1.9759, -0.1274]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0530,  1.3896,  0.4569],\n",
            "        [ 0.4655, -0.1691, -0.8925],\n",
            "        [-2.2295,  1.7352,  0.4504],\n",
            "        [-0.2436, -0.2033,  0.1926],\n",
            "        [-2.0389,  1.9485,  0.0586],\n",
            "        [-2.2112,  2.0202, -0.1152],\n",
            "        [-1.7956,  2.0562, -0.2731],\n",
            "        [-2.0115,  1.7215,  0.3722],\n",
            "        [-2.1531,  1.9398,  0.2716],\n",
            "        [-1.8908,  1.8438, -0.2331],\n",
            "        [-1.8036,  1.7498,  0.1791],\n",
            "        [-1.4995,  1.1897,  0.2119],\n",
            "        [-1.9935,  1.9426,  0.0598],\n",
            "        [-1.9112,  1.5886,  0.2603],\n",
            "        [ 0.5265, -0.3638, -0.5571],\n",
            "        [-1.9292,  1.9759, -0.1274]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0190,  1.8902,  0.0921],\n",
            "        [-1.4648,  0.4068,  1.1492],\n",
            "        [-1.6236,  0.0995,  0.9791],\n",
            "        [-1.7912,  0.3169,  1.3152],\n",
            "        [-2.2625,  1.4440,  0.5272],\n",
            "        [-2.0620,  1.7150, -0.1161],\n",
            "        [-1.9353,  0.4469,  1.0454],\n",
            "        [-1.6377,  1.5938, -0.7938],\n",
            "        [-1.9824,  1.8237, -0.0951],\n",
            "        [-1.6412,  0.3116,  1.2957],\n",
            "        [-1.8038,  1.9834, -0.2496],\n",
            "        [-1.8081,  0.7006,  1.1352],\n",
            "        [-1.8593,  0.3553,  1.2386],\n",
            "        [-1.8453,  2.1005, -0.2585],\n",
            "        [-2.3704,  2.0814, -0.0670],\n",
            "        [-1.8468,  1.9887, -0.1745]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0190,  1.8902,  0.0921],\n",
            "        [-1.4648,  0.4068,  1.1492],\n",
            "        [-1.6236,  0.0995,  0.9791],\n",
            "        [-1.7912,  0.3169,  1.3152],\n",
            "        [-2.2625,  1.4440,  0.5272],\n",
            "        [-2.0620,  1.7150, -0.1161],\n",
            "        [-1.9353,  0.4469,  1.0454],\n",
            "        [-1.6377,  1.5938, -0.7938],\n",
            "        [-1.9824,  1.8237, -0.0951],\n",
            "        [-1.6412,  0.3116,  1.2957],\n",
            "        [-1.8038,  1.9834, -0.2496],\n",
            "        [-1.8081,  0.7006,  1.1352],\n",
            "        [-1.8593,  0.3553,  1.2386],\n",
            "        [-1.8453,  2.1005, -0.2585],\n",
            "        [-2.3704,  2.0814, -0.0670],\n",
            "        [-1.8468,  1.9887, -0.1745]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8982,  1.8575, -0.1670],\n",
            "        [-1.9041,  2.1491, -0.1489],\n",
            "        [-2.0045,  2.2060, -0.2544],\n",
            "        [-2.1197,  1.5508,  0.1969],\n",
            "        [ 0.3906, -0.3121, -0.4689],\n",
            "        [ 0.2879, -0.1317, -0.5682],\n",
            "        [-2.0377,  0.6480,  1.0348],\n",
            "        [-2.0649,  2.1799, -0.2084],\n",
            "        [-2.0142,  0.7870,  0.9118],\n",
            "        [-2.1416,  1.6956,  0.0731],\n",
            "        [-2.0702,  1.4710,  0.3179],\n",
            "        [-2.1149,  1.3431,  0.7531],\n",
            "        [ 0.4613, -0.0889, -0.6067],\n",
            "        [-2.0112,  1.9811,  0.0096],\n",
            "        [-2.1597,  2.0078, -0.0897],\n",
            "        [-1.8137,  2.0989, -0.3450]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8982,  1.8575, -0.1670],\n",
            "        [-1.9041,  2.1491, -0.1489],\n",
            "        [-2.0045,  2.2060, -0.2544],\n",
            "        [-2.1197,  1.5508,  0.1969],\n",
            "        [ 0.3906, -0.3121, -0.4689],\n",
            "        [ 0.2879, -0.1317, -0.5682],\n",
            "        [-2.0377,  0.6480,  1.0348],\n",
            "        [-2.0649,  2.1799, -0.2084],\n",
            "        [-2.0142,  0.7870,  0.9118],\n",
            "        [-2.1416,  1.6956,  0.0731],\n",
            "        [-2.0702,  1.4710,  0.3179],\n",
            "        [-2.1149,  1.3431,  0.7531],\n",
            "        [ 0.4613, -0.0889, -0.6067],\n",
            "        [-2.0112,  1.9811,  0.0096],\n",
            "        [-2.1597,  2.0078, -0.0897],\n",
            "        [-1.8137,  2.0989, -0.3450]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7441,  1.9693, -0.4576],\n",
            "        [ 0.6212, -0.3752, -0.6486],\n",
            "        [-1.8506,  2.1404, -0.2364],\n",
            "        [ 0.4420, -0.1604, -0.6945],\n",
            "        [-1.8267,  2.0880, -0.4502],\n",
            "        [-2.0077,  0.7526,  1.0061],\n",
            "        [-1.9348,  0.4480,  1.2014],\n",
            "        [-1.9930,  1.9113,  0.1144],\n",
            "        [-1.8969,  2.2834, -0.3945],\n",
            "        [-1.6737,  0.6108,  1.1524],\n",
            "        [-2.0411,  1.8948, -0.0995],\n",
            "        [-2.1341,  1.8382,  0.0025],\n",
            "        [-2.1564,  1.7983,  0.1806],\n",
            "        [-2.0366,  2.2174, -0.3440],\n",
            "        [-2.1234,  1.0999,  0.9496],\n",
            "        [-2.1260,  2.0978, -0.2445]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7441,  1.9693, -0.4576],\n",
            "        [ 0.6212, -0.3752, -0.6486],\n",
            "        [-1.8506,  2.1404, -0.2364],\n",
            "        [ 0.4420, -0.1604, -0.6945],\n",
            "        [-1.8267,  2.0880, -0.4502],\n",
            "        [-2.0077,  0.7526,  1.0061],\n",
            "        [-1.9348,  0.4480,  1.2014],\n",
            "        [-1.9930,  1.9113,  0.1144],\n",
            "        [-1.8969,  2.2834, -0.3945],\n",
            "        [-1.6737,  0.6108,  1.1524],\n",
            "        [-2.0411,  1.8948, -0.0995],\n",
            "        [-2.1341,  1.8382,  0.0025],\n",
            "        [-2.1564,  1.7983,  0.1806],\n",
            "        [-2.0366,  2.2174, -0.3440],\n",
            "        [-2.1234,  1.0999,  0.9496],\n",
            "        [-2.1260,  2.0978, -0.2445]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9551,  2.0948, -0.7409],\n",
            "        [-1.2043,  1.1230, -0.2497],\n",
            "        [-1.9584,  2.0826, -0.1850],\n",
            "        [ 0.2401, -0.3239, -0.4739],\n",
            "        [-1.7957,  1.9391, -0.3577],\n",
            "        [-1.7922,  0.8093,  0.8744],\n",
            "        [-1.9673,  0.5434,  1.2153],\n",
            "        [-1.9692,  1.8176,  0.0136],\n",
            "        [-2.0775,  2.3198, -0.4444],\n",
            "        [-1.6306,  0.3392,  0.9780],\n",
            "        [-2.1600,  1.8533,  0.2841],\n",
            "        [-2.2056,  1.1423,  0.7785],\n",
            "        [-2.0882,  2.0214, -0.3014],\n",
            "        [-2.1024,  1.1839,  0.4812],\n",
            "        [-1.7640,  0.7770,  0.9612],\n",
            "        [-1.8933,  2.0121, -0.5023]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9551,  2.0948, -0.7409],\n",
            "        [-1.2043,  1.1230, -0.2497],\n",
            "        [-1.9584,  2.0826, -0.1850],\n",
            "        [ 0.2401, -0.3239, -0.4739],\n",
            "        [-1.7957,  1.9391, -0.3577],\n",
            "        [-1.7922,  0.8093,  0.8744],\n",
            "        [-1.9673,  0.5434,  1.2153],\n",
            "        [-1.9692,  1.8176,  0.0136],\n",
            "        [-2.0775,  2.3198, -0.4444],\n",
            "        [-1.6306,  0.3392,  0.9780],\n",
            "        [-2.1600,  1.8533,  0.2841],\n",
            "        [-2.2056,  1.1423,  0.7785],\n",
            "        [-2.0882,  2.0214, -0.3014],\n",
            "        [-2.1024,  1.1839,  0.4812],\n",
            "        [-1.7640,  0.7770,  0.9612],\n",
            "        [-1.8933,  2.0121, -0.5023]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7056,  0.5542,  1.1721],\n",
            "        [ 0.2749, -0.1447, -0.7523],\n",
            "        [-1.7161,  0.5878,  0.8619],\n",
            "        [-1.8809,  2.1240, -0.2583],\n",
            "        [-1.7149,  0.6827,  0.8691],\n",
            "        [-1.9544,  2.2063, -0.2236],\n",
            "        [-1.5261,  0.3856,  0.9738],\n",
            "        [-1.6837,  0.5277,  1.0083],\n",
            "        [ 0.3398,  0.0100, -0.6318],\n",
            "        [-2.0358,  2.1599, -0.2504],\n",
            "        [-1.9881,  2.2171, -0.4003],\n",
            "        [ 0.3760, -0.4207, -0.4899],\n",
            "        [-2.0476,  2.1581, -0.1192],\n",
            "        [-1.6446,  0.2416,  1.1619],\n",
            "        [-1.9397,  2.1188, -0.4396],\n",
            "        [-2.0232,  2.0339, -0.2389]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7056,  0.5542,  1.1721],\n",
            "        [ 0.2749, -0.1447, -0.7523],\n",
            "        [-1.7161,  0.5878,  0.8619],\n",
            "        [-1.8809,  2.1240, -0.2583],\n",
            "        [-1.7149,  0.6827,  0.8691],\n",
            "        [-1.9544,  2.2063, -0.2236],\n",
            "        [-1.5261,  0.3856,  0.9738],\n",
            "        [-1.6837,  0.5277,  1.0083],\n",
            "        [ 0.3398,  0.0100, -0.6318],\n",
            "        [-2.0358,  2.1599, -0.2504],\n",
            "        [-1.9881,  2.2171, -0.4003],\n",
            "        [ 0.3760, -0.4207, -0.4899],\n",
            "        [-2.0476,  2.1581, -0.1192],\n",
            "        [-1.6446,  0.2416,  1.1619],\n",
            "        [-1.9397,  2.1188, -0.4396],\n",
            "        [-2.0232,  2.0339, -0.2389]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6216,  0.4080,  1.1239],\n",
            "        [-2.1500,  2.1079, -0.2706],\n",
            "        [-1.9219,  2.0905, -0.2795],\n",
            "        [-1.5441,  0.3479,  1.0921],\n",
            "        [-0.4379, -0.0036,  0.0757],\n",
            "        [-2.0334,  1.1711,  0.8045],\n",
            "        [-2.0601,  1.7063,  0.2438],\n",
            "        [ 0.4211, -0.3911, -0.5609],\n",
            "        [-1.9514,  0.7898,  1.1208],\n",
            "        [-2.1000,  2.3234, -0.4967],\n",
            "        [-2.1422,  2.3984, -0.2929],\n",
            "        [-2.0895,  2.0877, -0.2077],\n",
            "        [-2.1315,  2.0161,  0.0554],\n",
            "        [-0.7393,  0.0446,  0.2152],\n",
            "        [-2.1645,  2.2157, -0.2793],\n",
            "        [-2.1107,  1.4639,  0.7034]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6216,  0.4080,  1.1239],\n",
            "        [-2.1500,  2.1079, -0.2706],\n",
            "        [-1.9219,  2.0905, -0.2795],\n",
            "        [-1.5441,  0.3479,  1.0921],\n",
            "        [-0.4379, -0.0036,  0.0757],\n",
            "        [-2.0334,  1.1711,  0.8045],\n",
            "        [-2.0601,  1.7063,  0.2438],\n",
            "        [ 0.4211, -0.3911, -0.5609],\n",
            "        [-1.9514,  0.7898,  1.1208],\n",
            "        [-2.1000,  2.3234, -0.4967],\n",
            "        [-2.1422,  2.3984, -0.2929],\n",
            "        [-2.0895,  2.0877, -0.2077],\n",
            "        [-2.1315,  2.0161,  0.0554],\n",
            "        [-0.7393,  0.0446,  0.2152],\n",
            "        [-2.1645,  2.2157, -0.2793],\n",
            "        [-2.1107,  1.4639,  0.7034]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7307,  2.0880, -0.3760],\n",
            "        [ 0.3925, -0.3332, -0.3962],\n",
            "        [-1.6472,  0.4631,  0.9789],\n",
            "        [-1.6214,  0.5359,  1.0217],\n",
            "        [-1.9769,  1.8589,  0.0375],\n",
            "        [-1.7447,  2.0196, -0.3445],\n",
            "        [-1.8305,  0.4980,  1.1344],\n",
            "        [-2.4135,  1.6477,  0.3643],\n",
            "        [-2.0313,  2.1573, -0.2593],\n",
            "        [-2.0098,  2.2692, -0.3217],\n",
            "        [-2.0519,  2.2994, -0.2340],\n",
            "        [-0.5400,  0.0763,  0.1698],\n",
            "        [-1.7807,  1.9231, -0.2168],\n",
            "        [-2.0897,  0.9368,  0.4655],\n",
            "        [-2.0544,  2.2323, -0.3661],\n",
            "        [-2.0736,  2.1863,  0.0382]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7307,  2.0880, -0.3760],\n",
            "        [ 0.3925, -0.3332, -0.3962],\n",
            "        [-1.6472,  0.4631,  0.9789],\n",
            "        [-1.6214,  0.5359,  1.0217],\n",
            "        [-1.9769,  1.8589,  0.0375],\n",
            "        [-1.7447,  2.0196, -0.3445],\n",
            "        [-1.8305,  0.4980,  1.1344],\n",
            "        [-2.4135,  1.6477,  0.3643],\n",
            "        [-2.0313,  2.1573, -0.2593],\n",
            "        [-2.0098,  2.2692, -0.3217],\n",
            "        [-2.0519,  2.2994, -0.2340],\n",
            "        [-0.5400,  0.0763,  0.1698],\n",
            "        [-1.7807,  1.9231, -0.2168],\n",
            "        [-2.0897,  0.9368,  0.4655],\n",
            "        [-2.0544,  2.2323, -0.3661],\n",
            "        [-2.0736,  2.1863,  0.0382]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0293,  1.1253,  0.8817],\n",
            "        [-1.9259,  1.7974,  0.0818],\n",
            "        [-1.9832,  0.8944,  0.9076],\n",
            "        [-1.9466,  0.5699,  1.0736],\n",
            "        [-2.0926,  1.9708, -0.4159],\n",
            "        [-2.1057,  2.3305, -0.5604],\n",
            "        [-0.9996,  0.7789, -0.2754],\n",
            "        [-1.8326,  2.1770, -0.3537],\n",
            "        [-1.9304,  2.1795, -0.3767],\n",
            "        [ 0.1441,  0.2902, -0.8446],\n",
            "        [-2.1375,  2.0549, -0.0567],\n",
            "        [-2.0133,  1.4925,  0.6535],\n",
            "        [-2.0494,  0.7895,  0.8340],\n",
            "        [ 0.4068, -0.2716, -0.6346],\n",
            "        [-1.9494,  2.1848, -0.2142],\n",
            "        [-2.1015,  2.2722, -0.3073]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0293,  1.1253,  0.8817],\n",
            "        [-1.9259,  1.7974,  0.0818],\n",
            "        [-1.9832,  0.8944,  0.9076],\n",
            "        [-1.9466,  0.5699,  1.0736],\n",
            "        [-2.0926,  1.9708, -0.4159],\n",
            "        [-2.1057,  2.3305, -0.5604],\n",
            "        [-0.9996,  0.7789, -0.2754],\n",
            "        [-1.8326,  2.1770, -0.3537],\n",
            "        [-1.9304,  2.1795, -0.3767],\n",
            "        [ 0.1441,  0.2902, -0.8446],\n",
            "        [-2.1375,  2.0549, -0.0567],\n",
            "        [-2.0133,  1.4925,  0.6535],\n",
            "        [-2.0494,  0.7895,  0.8340],\n",
            "        [ 0.4068, -0.2716, -0.6346],\n",
            "        [-1.9494,  2.1848, -0.2142],\n",
            "        [-2.1015,  2.2722, -0.3073]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9280,  1.7247, -0.1962],\n",
            "        [ 0.3515, -0.1977, -0.4271],\n",
            "        [-2.2401,  2.0365,  0.0210],\n",
            "        [-1.5931,  0.3681,  1.1825],\n",
            "        [-1.9375,  1.4880,  0.1919],\n",
            "        [ 0.3523, -0.0276, -0.3998],\n",
            "        [-1.9340,  1.8704, -0.2562],\n",
            "        [-2.1674,  1.9839, -0.3429],\n",
            "        [-1.5916,  0.3897,  0.9962],\n",
            "        [-1.8240,  0.6802,  0.9629],\n",
            "        [-2.0828,  1.8866, -0.4015],\n",
            "        [-1.8163,  1.9776, -0.3466],\n",
            "        [-1.8664,  0.4674,  1.0749],\n",
            "        [-1.9734,  1.9053, -0.1702],\n",
            "        [-1.6717,  0.5178,  0.7523],\n",
            "        [-2.0656,  0.8500,  0.8370]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9280,  1.7247, -0.1962],\n",
            "        [ 0.3515, -0.1977, -0.4271],\n",
            "        [-2.2401,  2.0365,  0.0210],\n",
            "        [-1.5931,  0.3681,  1.1825],\n",
            "        [-1.9375,  1.4880,  0.1919],\n",
            "        [ 0.3523, -0.0276, -0.3998],\n",
            "        [-1.9340,  1.8704, -0.2562],\n",
            "        [-2.1674,  1.9839, -0.3429],\n",
            "        [-1.5916,  0.3897,  0.9962],\n",
            "        [-1.8240,  0.6802,  0.9629],\n",
            "        [-2.0828,  1.8866, -0.4015],\n",
            "        [-1.8163,  1.9776, -0.3466],\n",
            "        [-1.8664,  0.4674,  1.0749],\n",
            "        [-1.9734,  1.9053, -0.1702],\n",
            "        [-1.6717,  0.5178,  0.7523],\n",
            "        [-2.0656,  0.8500,  0.8370]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8979e+00,  7.0519e-01,  1.1801e+00],\n",
            "        [-1.5951e+00,  4.1678e-01,  9.8371e-01],\n",
            "        [-1.9854e+00,  1.6247e+00,  1.1751e-04],\n",
            "        [-1.7697e+00,  3.2248e-01,  1.0056e+00],\n",
            "        [-1.6489e+00,  3.4829e-01,  9.1054e-01],\n",
            "        [-1.9816e+00,  2.1756e+00, -1.0065e-01],\n",
            "        [-1.9767e+00,  1.7930e+00, -6.9692e-02],\n",
            "        [-2.1866e+00,  1.4722e+00,  4.8242e-01],\n",
            "        [-1.6298e+00,  4.4718e-01,  9.3425e-01],\n",
            "        [-1.9583e+00,  2.4018e+00, -3.7784e-01],\n",
            "        [-1.0993e+00,  1.3882e+00, -8.2803e-01],\n",
            "        [-1.7071e+00,  8.0199e-01,  6.1283e-01],\n",
            "        [-1.7957e+00,  1.9407e+00, -4.9200e-01],\n",
            "        [-1.9385e+00,  2.0732e+00, -2.4162e-01],\n",
            "        [-1.5425e+00,  5.4942e-01,  8.4694e-01],\n",
            "        [-1.8352e+00,  1.9658e+00, -1.5862e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8979e+00,  7.0519e-01,  1.1801e+00],\n",
            "        [-1.5951e+00,  4.1678e-01,  9.8371e-01],\n",
            "        [-1.9854e+00,  1.6247e+00,  1.1751e-04],\n",
            "        [-1.7697e+00,  3.2248e-01,  1.0056e+00],\n",
            "        [-1.6489e+00,  3.4829e-01,  9.1054e-01],\n",
            "        [-1.9816e+00,  2.1756e+00, -1.0065e-01],\n",
            "        [-1.9767e+00,  1.7930e+00, -6.9692e-02],\n",
            "        [-2.1866e+00,  1.4722e+00,  4.8242e-01],\n",
            "        [-1.6298e+00,  4.4718e-01,  9.3425e-01],\n",
            "        [-1.9583e+00,  2.4018e+00, -3.7784e-01],\n",
            "        [-1.0993e+00,  1.3882e+00, -8.2803e-01],\n",
            "        [-1.7071e+00,  8.0199e-01,  6.1283e-01],\n",
            "        [-1.7957e+00,  1.9407e+00, -4.9200e-01],\n",
            "        [-1.9385e+00,  2.0732e+00, -2.4162e-01],\n",
            "        [-1.5425e+00,  5.4942e-01,  8.4694e-01],\n",
            "        [-1.8352e+00,  1.9658e+00, -1.5862e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7203,  1.6547,  0.0772],\n",
            "        [-1.9963,  1.9926, -0.1208],\n",
            "        [-1.6106,  0.4219,  0.8785],\n",
            "        [-1.8870,  1.9904, -0.1449],\n",
            "        [ 0.4855, -0.2227, -0.5661],\n",
            "        [-1.5840,  0.4163,  1.0463],\n",
            "        [-1.9545,  1.9473, -0.2612],\n",
            "        [-2.0888,  2.1887, -0.4122],\n",
            "        [-1.5048,  1.7337, -0.4655],\n",
            "        [-2.0608,  1.8705, -0.1998],\n",
            "        [-2.0135,  2.0033, -0.2776],\n",
            "        [-1.6948,  1.8687, -0.2225],\n",
            "        [-1.7790,  1.8635, -0.3702],\n",
            "        [ 0.2273,  0.0565, -0.6486],\n",
            "        [-1.6292,  1.7346, -0.4019],\n",
            "        [-2.0886,  2.1368, -0.1333]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7203,  1.6547,  0.0772],\n",
            "        [-1.9963,  1.9926, -0.1208],\n",
            "        [-1.6106,  0.4219,  0.8785],\n",
            "        [-1.8870,  1.9904, -0.1449],\n",
            "        [ 0.4855, -0.2227, -0.5661],\n",
            "        [-1.5840,  0.4163,  1.0463],\n",
            "        [-1.9545,  1.9473, -0.2612],\n",
            "        [-2.0888,  2.1887, -0.4122],\n",
            "        [-1.5048,  1.7337, -0.4655],\n",
            "        [-2.0608,  1.8705, -0.1998],\n",
            "        [-2.0135,  2.0033, -0.2776],\n",
            "        [-1.6948,  1.8687, -0.2225],\n",
            "        [-1.7790,  1.8635, -0.3702],\n",
            "        [ 0.2273,  0.0565, -0.6486],\n",
            "        [-1.6292,  1.7346, -0.4019],\n",
            "        [-2.0886,  2.1368, -0.1333]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6950,  1.7902, -0.4915],\n",
            "        [-2.0714,  1.9333, -0.3824],\n",
            "        [-1.7611,  1.8555, -0.2025],\n",
            "        [-1.7201,  0.5477,  1.0353],\n",
            "        [-2.0211,  2.0530, -0.2857],\n",
            "        [-0.6003, -0.1698,  0.5554],\n",
            "        [-1.5315,  1.1946,  0.6461],\n",
            "        [-1.8430,  0.6228,  0.9161],\n",
            "        [-1.8523,  1.9239, -0.4998],\n",
            "        [-1.7433,  0.5994,  1.0570],\n",
            "        [-1.7232,  0.8939,  0.6069],\n",
            "        [-1.6826,  0.3872,  1.0917],\n",
            "        [-1.9115,  2.0010, -0.4837],\n",
            "        [-1.9768,  0.7747,  0.8966],\n",
            "        [-1.5880,  0.6290,  0.9349],\n",
            "        [-1.8098,  1.6826, -0.0082]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6950,  1.7902, -0.4915],\n",
            "        [-2.0714,  1.9333, -0.3824],\n",
            "        [-1.7611,  1.8555, -0.2025],\n",
            "        [-1.7201,  0.5477,  1.0353],\n",
            "        [-2.0211,  2.0530, -0.2857],\n",
            "        [-0.6003, -0.1698,  0.5554],\n",
            "        [-1.5315,  1.1946,  0.6461],\n",
            "        [-1.8430,  0.6228,  0.9161],\n",
            "        [-1.8523,  1.9239, -0.4998],\n",
            "        [-1.7433,  0.5994,  1.0570],\n",
            "        [-1.7232,  0.8939,  0.6069],\n",
            "        [-1.6826,  0.3872,  1.0917],\n",
            "        [-1.9115,  2.0010, -0.4837],\n",
            "        [-1.9768,  0.7747,  0.8966],\n",
            "        [-1.5880,  0.6290,  0.9349],\n",
            "        [-1.8098,  1.6826, -0.0082]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1069,  1.8984, -0.0531],\n",
            "        [-1.6321,  0.8869,  0.5563],\n",
            "        [-1.8670,  0.9525,  0.6462],\n",
            "        [-1.6342,  0.5913,  1.0895],\n",
            "        [-1.7233,  1.8863, -0.2787],\n",
            "        [ 0.3565,  0.0664, -0.6597],\n",
            "        [-1.4624,  0.4535,  0.9757],\n",
            "        [-1.5441,  0.1857,  0.8076],\n",
            "        [-1.7902,  1.8078, -0.1875],\n",
            "        [-1.4875,  0.4366,  1.0735],\n",
            "        [-1.8612,  1.9501, -0.4329],\n",
            "        [-1.7023,  0.3103,  1.0717],\n",
            "        [-0.4134,  0.7170, -0.8061],\n",
            "        [-1.7585,  0.7949,  0.6551],\n",
            "        [-1.3901,  0.2314,  0.7600],\n",
            "        [-1.6845,  1.9080, -0.2295]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1069,  1.8984, -0.0531],\n",
            "        [-1.6321,  0.8869,  0.5563],\n",
            "        [-1.8670,  0.9525,  0.6462],\n",
            "        [-1.6342,  0.5913,  1.0895],\n",
            "        [-1.7233,  1.8863, -0.2787],\n",
            "        [ 0.3565,  0.0664, -0.6597],\n",
            "        [-1.4624,  0.4535,  0.9757],\n",
            "        [-1.5441,  0.1857,  0.8076],\n",
            "        [-1.7902,  1.8078, -0.1875],\n",
            "        [-1.4875,  0.4366,  1.0735],\n",
            "        [-1.8612,  1.9501, -0.4329],\n",
            "        [-1.7023,  0.3103,  1.0717],\n",
            "        [-0.4134,  0.7170, -0.8061],\n",
            "        [-1.7585,  0.7949,  0.6551],\n",
            "        [-1.3901,  0.2314,  0.7600],\n",
            "        [-1.6845,  1.9080, -0.2295]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8556,  0.4453,  1.0464],\n",
            "        [-1.9379,  1.4019,  0.2683],\n",
            "        [-0.6171,  0.2913, -0.2343],\n",
            "        [-1.8722,  2.1962, -0.1492],\n",
            "        [-1.9814,  1.9535, -0.1092],\n",
            "        [-1.6447,  0.4356,  0.8447],\n",
            "        [-1.8059,  2.0275, -0.2996],\n",
            "        [ 0.2657, -0.3026, -0.3986],\n",
            "        [-1.5425,  0.5631,  0.9800],\n",
            "        [ 0.3042, -0.2980, -0.5396],\n",
            "        [-1.4275,  0.3969,  0.7261],\n",
            "        [-1.9389,  1.4901,  0.1423],\n",
            "        [-1.9907,  1.5478,  0.4418],\n",
            "        [ 0.2857, -0.1582, -0.7167],\n",
            "        [-1.8656,  1.9090, -0.3747],\n",
            "        [-1.8698,  1.8488, -0.2092]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8556,  0.4453,  1.0464],\n",
            "        [-1.9379,  1.4019,  0.2683],\n",
            "        [-0.6171,  0.2913, -0.2343],\n",
            "        [-1.8722,  2.1962, -0.1492],\n",
            "        [-1.9814,  1.9535, -0.1092],\n",
            "        [-1.6447,  0.4356,  0.8447],\n",
            "        [-1.8059,  2.0275, -0.2996],\n",
            "        [ 0.2657, -0.3026, -0.3986],\n",
            "        [-1.5425,  0.5631,  0.9800],\n",
            "        [ 0.3042, -0.2980, -0.5396],\n",
            "        [-1.4275,  0.3969,  0.7261],\n",
            "        [-1.9389,  1.4901,  0.1423],\n",
            "        [-1.9907,  1.5478,  0.4418],\n",
            "        [ 0.2857, -0.1582, -0.7167],\n",
            "        [-1.8656,  1.9090, -0.3747],\n",
            "        [-1.8698,  1.8488, -0.2092]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9177,  1.6329,  0.0486],\n",
            "        [-1.6253,  1.8923, -0.1788],\n",
            "        [-1.8763,  1.9184, -0.3069],\n",
            "        [-1.7523,  0.5890,  1.0086],\n",
            "        [ 0.4090, -0.2858, -0.4933],\n",
            "        [-1.5451,  0.2479,  0.9341],\n",
            "        [-1.6950,  0.8093,  0.5982],\n",
            "        [-1.7385,  1.6457, -0.3238],\n",
            "        [-1.5685,  0.2823,  0.8485],\n",
            "        [-1.7104,  1.6968, -0.3130],\n",
            "        [-1.5998,  1.8629, -0.2458],\n",
            "        [-1.6123,  0.4069,  0.8256],\n",
            "        [-1.6192,  1.8948, -0.3680],\n",
            "        [-1.9683,  1.7061,  0.1536],\n",
            "        [-1.5161,  0.4123,  1.0043],\n",
            "        [-2.0219,  2.1080, -0.2087]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9177,  1.6329,  0.0486],\n",
            "        [-1.6253,  1.8923, -0.1788],\n",
            "        [-1.8763,  1.9184, -0.3069],\n",
            "        [-1.7523,  0.5890,  1.0086],\n",
            "        [ 0.4090, -0.2858, -0.4933],\n",
            "        [-1.5451,  0.2479,  0.9341],\n",
            "        [-1.6950,  0.8093,  0.5982],\n",
            "        [-1.7385,  1.6457, -0.3238],\n",
            "        [-1.5685,  0.2823,  0.8485],\n",
            "        [-1.7104,  1.6968, -0.3130],\n",
            "        [-1.5998,  1.8629, -0.2458],\n",
            "        [-1.6123,  0.4069,  0.8256],\n",
            "        [-1.6192,  1.8948, -0.3680],\n",
            "        [-1.9683,  1.7061,  0.1536],\n",
            "        [-1.5161,  0.4123,  1.0043],\n",
            "        [-2.0219,  2.1080, -0.2087]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5305,  0.3602,  0.9203],\n",
            "        [-1.5843,  0.6238,  0.8661],\n",
            "        [-1.7916,  1.8936, -0.2844],\n",
            "        [-1.8852,  1.8820, -0.1425],\n",
            "        [-1.7219,  1.0479,  0.4552],\n",
            "        [-1.7601,  1.8933, -0.1689],\n",
            "        [-1.9711,  1.3720,  0.3383],\n",
            "        [-1.8099,  1.9046, -0.3051],\n",
            "        [-1.7800,  1.8037,  0.1282],\n",
            "        [-1.8905,  1.7399, -0.2010],\n",
            "        [-1.5868,  0.3131,  0.9888],\n",
            "        [-1.7563,  1.8196, -0.3938],\n",
            "        [-0.0752,  0.2788, -0.6751],\n",
            "        [-1.7638,  0.4484,  1.0698],\n",
            "        [-1.9571,  1.7221, -0.0701],\n",
            "        [ 0.4725, -0.3241, -0.6027]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5305,  0.3602,  0.9203],\n",
            "        [-1.5843,  0.6238,  0.8661],\n",
            "        [-1.7916,  1.8936, -0.2844],\n",
            "        [-1.8852,  1.8820, -0.1425],\n",
            "        [-1.7219,  1.0479,  0.4552],\n",
            "        [-1.7601,  1.8933, -0.1689],\n",
            "        [-1.9711,  1.3720,  0.3383],\n",
            "        [-1.8099,  1.9046, -0.3051],\n",
            "        [-1.7800,  1.8037,  0.1282],\n",
            "        [-1.8905,  1.7399, -0.2010],\n",
            "        [-1.5868,  0.3131,  0.9888],\n",
            "        [-1.7563,  1.8196, -0.3938],\n",
            "        [-0.0752,  0.2788, -0.6751],\n",
            "        [-1.7638,  0.4484,  1.0698],\n",
            "        [-1.9571,  1.7221, -0.0701],\n",
            "        [ 0.4725, -0.3241, -0.6027]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7146,  0.5669,  0.8921],\n",
            "        [-1.6759,  1.8033, -0.1811],\n",
            "        [-1.6993,  0.8914,  0.7003],\n",
            "        [-1.4241,  0.4443,  1.1050],\n",
            "        [ 0.1523,  0.0771, -0.6875],\n",
            "        [-1.7039,  0.4674,  0.9456],\n",
            "        [-1.6655,  1.8078,  0.0571],\n",
            "        [-1.6749,  1.8432, -0.0218],\n",
            "        [-1.2712,  1.5361, -0.6020],\n",
            "        [-1.7523,  0.4655,  0.6506],\n",
            "        [-1.7449,  1.9379, -0.5365],\n",
            "        [-1.7149,  0.9410,  0.7139],\n",
            "        [-2.0074,  1.7855, -0.1615],\n",
            "        [-1.2209,  0.1343,  1.0590],\n",
            "        [-1.8603,  1.6360, -0.1039],\n",
            "        [-2.0778,  1.6908,  0.0135]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7146,  0.5669,  0.8921],\n",
            "        [-1.6759,  1.8033, -0.1811],\n",
            "        [-1.6993,  0.8914,  0.7003],\n",
            "        [-1.4241,  0.4443,  1.1050],\n",
            "        [ 0.1523,  0.0771, -0.6875],\n",
            "        [-1.7039,  0.4674,  0.9456],\n",
            "        [-1.6655,  1.8078,  0.0571],\n",
            "        [-1.6749,  1.8432, -0.0218],\n",
            "        [-1.2712,  1.5361, -0.6020],\n",
            "        [-1.7523,  0.4655,  0.6506],\n",
            "        [-1.7449,  1.9379, -0.5365],\n",
            "        [-1.7149,  0.9410,  0.7139],\n",
            "        [-2.0074,  1.7855, -0.1615],\n",
            "        [-1.2209,  0.1343,  1.0590],\n",
            "        [-1.8603,  1.6360, -0.1039],\n",
            "        [-2.0778,  1.6908,  0.0135]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7883,  1.9507, -0.1453],\n",
            "        [-1.5661,  0.2366,  1.0108],\n",
            "        [-1.6623,  1.4040,  0.2851],\n",
            "        [-1.7531,  1.8065, -0.1699],\n",
            "        [-1.7353,  0.7217,  0.8540],\n",
            "        [-1.4980,  0.2498,  1.1284],\n",
            "        [-1.4304,  0.2168,  1.0398],\n",
            "        [-1.7959,  1.5534, -0.1154],\n",
            "        [-0.4270,  0.2891, -0.2713],\n",
            "        [-1.5765,  0.9987,  0.2496],\n",
            "        [-2.0578,  0.9293,  0.8836],\n",
            "        [-1.7083,  1.5179, -0.1594],\n",
            "        [-1.6774,  0.7989,  0.6841],\n",
            "        [-1.7256,  1.4939, -0.2231],\n",
            "        [ 0.3882, -0.2854, -0.5156],\n",
            "        [-1.4859,  1.7050, -0.2460]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7883,  1.9507, -0.1453],\n",
            "        [-1.5661,  0.2366,  1.0108],\n",
            "        [-1.6623,  1.4040,  0.2851],\n",
            "        [-1.7531,  1.8065, -0.1699],\n",
            "        [-1.7353,  0.7217,  0.8540],\n",
            "        [-1.4980,  0.2498,  1.1284],\n",
            "        [-1.4304,  0.2168,  1.0398],\n",
            "        [-1.7959,  1.5534, -0.1154],\n",
            "        [-0.4270,  0.2891, -0.2713],\n",
            "        [-1.5765,  0.9987,  0.2496],\n",
            "        [-2.0578,  0.9293,  0.8836],\n",
            "        [-1.7083,  1.5179, -0.1594],\n",
            "        [-1.6774,  0.7989,  0.6841],\n",
            "        [-1.7256,  1.4939, -0.2231],\n",
            "        [ 0.3882, -0.2854, -0.5156],\n",
            "        [-1.4859,  1.7050, -0.2460]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5122,  0.4061,  0.9924],\n",
            "        [ 0.3285, -0.1500, -0.4319],\n",
            "        [-1.5488,  0.0301,  0.7999],\n",
            "        [-1.9377,  1.7279, -0.1499],\n",
            "        [-1.5981,  1.9370, -0.2123],\n",
            "        [-1.5785,  1.5026, -0.2472],\n",
            "        [-1.2899,  0.2413,  0.8271],\n",
            "        [-1.8283,  1.6210, -0.0966],\n",
            "        [ 0.4227, -0.2600, -0.5006],\n",
            "        [ 0.3118, -0.2649, -0.3832],\n",
            "        [-1.5880,  1.6987, -0.1838],\n",
            "        [-1.8540,  1.7086, -0.0374],\n",
            "        [-1.6751,  1.0912,  0.3555],\n",
            "        [-1.8694,  2.0058, -0.5167],\n",
            "        [-1.8480,  1.8329, -0.2310],\n",
            "        [-1.7954,  1.4219,  0.3230]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5122,  0.4061,  0.9924],\n",
            "        [ 0.3285, -0.1500, -0.4319],\n",
            "        [-1.5488,  0.0301,  0.7999],\n",
            "        [-1.9377,  1.7279, -0.1499],\n",
            "        [-1.5981,  1.9370, -0.2123],\n",
            "        [-1.5785,  1.5026, -0.2472],\n",
            "        [-1.2899,  0.2413,  0.8271],\n",
            "        [-1.8283,  1.6210, -0.0966],\n",
            "        [ 0.4227, -0.2600, -0.5006],\n",
            "        [ 0.3118, -0.2649, -0.3832],\n",
            "        [-1.5880,  1.6987, -0.1838],\n",
            "        [-1.8540,  1.7086, -0.0374],\n",
            "        [-1.6751,  1.0912,  0.3555],\n",
            "        [-1.8694,  2.0058, -0.5167],\n",
            "        [-1.8480,  1.8329, -0.2310],\n",
            "        [-1.7954,  1.4219,  0.3230]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3406,  0.3552,  0.8883],\n",
            "        [-1.8439,  1.8643,  0.1725],\n",
            "        [-1.6762,  2.0335, -0.3329],\n",
            "        [-1.6481,  1.3355,  0.1047],\n",
            "        [-1.8099,  1.7386,  0.3518],\n",
            "        [-1.8987,  1.7393, -0.0394],\n",
            "        [-1.2578,  0.2810,  0.8320],\n",
            "        [-1.8127,  0.3523,  0.9573],\n",
            "        [-1.2058,  0.2094,  0.8611],\n",
            "        [-1.8199,  1.9482, -0.1484],\n",
            "        [-2.0910,  2.0032, -0.2544],\n",
            "        [ 0.3925, -0.2153, -0.4004],\n",
            "        [-1.8586,  1.9913, -0.2836],\n",
            "        [-1.8401,  1.6895, -0.2414],\n",
            "        [-1.8640,  1.6211, -0.2205],\n",
            "        [-2.0210,  1.0850,  0.5589]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3406,  0.3552,  0.8883],\n",
            "        [-1.8439,  1.8643,  0.1725],\n",
            "        [-1.6762,  2.0335, -0.3329],\n",
            "        [-1.6481,  1.3355,  0.1047],\n",
            "        [-1.8099,  1.7386,  0.3518],\n",
            "        [-1.8987,  1.7393, -0.0394],\n",
            "        [-1.2578,  0.2810,  0.8320],\n",
            "        [-1.8127,  0.3523,  0.9573],\n",
            "        [-1.2058,  0.2094,  0.8611],\n",
            "        [-1.8199,  1.9482, -0.1484],\n",
            "        [-2.0910,  2.0032, -0.2544],\n",
            "        [ 0.3925, -0.2153, -0.4004],\n",
            "        [-1.8586,  1.9913, -0.2836],\n",
            "        [-1.8401,  1.6895, -0.2414],\n",
            "        [-1.8640,  1.6211, -0.2205],\n",
            "        [-2.0210,  1.0850,  0.5589]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8602,  1.6958, -0.0824],\n",
            "        [-0.1176, -0.1872, -0.0540],\n",
            "        [-1.9265,  0.9071,  0.6519],\n",
            "        [-1.7593,  1.2191,  0.4981],\n",
            "        [ 0.2645,  0.0052, -0.4882],\n",
            "        [-1.2899,  0.9552, -0.0577],\n",
            "        [-1.0748, -0.0333,  0.9111],\n",
            "        [-1.2554,  0.3346,  0.8487],\n",
            "        [-1.7243,  0.9659,  0.4878],\n",
            "        [-1.9831,  1.2057,  0.5060],\n",
            "        [-1.3317,  0.1754,  0.9574],\n",
            "        [ 0.2015, -0.2953, -0.4152],\n",
            "        [-1.8246,  1.9027, -0.1317],\n",
            "        [-1.7939,  1.7237, -0.1448],\n",
            "        [-1.9110,  1.8197, -0.0361],\n",
            "        [-1.9373,  1.5119,  0.1924]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8602,  1.6958, -0.0824],\n",
            "        [-0.1176, -0.1872, -0.0540],\n",
            "        [-1.9265,  0.9071,  0.6519],\n",
            "        [-1.7593,  1.2191,  0.4981],\n",
            "        [ 0.2645,  0.0052, -0.4882],\n",
            "        [-1.2899,  0.9552, -0.0577],\n",
            "        [-1.0748, -0.0333,  0.9111],\n",
            "        [-1.2554,  0.3346,  0.8487],\n",
            "        [-1.7243,  0.9659,  0.4878],\n",
            "        [-1.9831,  1.2057,  0.5060],\n",
            "        [-1.3317,  0.1754,  0.9574],\n",
            "        [ 0.2015, -0.2953, -0.4152],\n",
            "        [-1.8246,  1.9027, -0.1317],\n",
            "        [-1.7939,  1.7237, -0.1448],\n",
            "        [-1.9110,  1.8197, -0.0361],\n",
            "        [-1.9373,  1.5119,  0.1924]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5704,  0.3371,  0.9759],\n",
            "        [-1.1658,  1.0345, -0.3749],\n",
            "        [-1.6962,  1.7708, -0.2534],\n",
            "        [ 0.2535, -0.0678, -0.5904],\n",
            "        [-1.8942,  1.6128, -0.2138],\n",
            "        [-1.8027,  1.1920,  0.2030],\n",
            "        [-1.6471,  1.8788, -0.2164],\n",
            "        [ 0.2666, -0.1797, -0.6001],\n",
            "        [-0.8457,  0.8956, -0.5896],\n",
            "        [-0.1046,  0.1874, -0.6853],\n",
            "        [-1.7413,  1.3446,  0.5145],\n",
            "        [-1.9530,  1.7420, -0.1466],\n",
            "        [-1.4332,  0.2467,  1.2042],\n",
            "        [-1.1542,  0.8837, -0.1883],\n",
            "        [-1.6803,  1.7925, -0.0861],\n",
            "        [-1.5964,  1.5972, -0.0020]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5704,  0.3371,  0.9759],\n",
            "        [-1.1658,  1.0345, -0.3749],\n",
            "        [-1.6962,  1.7708, -0.2534],\n",
            "        [ 0.2535, -0.0678, -0.5904],\n",
            "        [-1.8942,  1.6128, -0.2138],\n",
            "        [-1.8027,  1.1920,  0.2030],\n",
            "        [-1.6471,  1.8788, -0.2164],\n",
            "        [ 0.2666, -0.1797, -0.6001],\n",
            "        [-0.8457,  0.8956, -0.5896],\n",
            "        [-0.1046,  0.1874, -0.6853],\n",
            "        [-1.7413,  1.3446,  0.5145],\n",
            "        [-1.9530,  1.7420, -0.1466],\n",
            "        [-1.4332,  0.2467,  1.2042],\n",
            "        [-1.1542,  0.8837, -0.1883],\n",
            "        [-1.6803,  1.7925, -0.0861],\n",
            "        [-1.5964,  1.5972, -0.0020]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6422,  0.9528,  0.5068],\n",
            "        [-1.4279,  0.2979,  0.9838],\n",
            "        [-1.3741,  0.4202,  1.0064],\n",
            "        [-1.5946,  1.6881, -0.1748],\n",
            "        [-1.3145,  0.1893,  1.0846],\n",
            "        [-1.3127,  0.0491,  0.9406],\n",
            "        [ 0.4041, -0.1813, -0.4825],\n",
            "        [-1.4796,  0.1934,  0.8865],\n",
            "        [-1.6990,  1.7079, -0.2266],\n",
            "        [ 0.1657, -0.0286, -0.6825],\n",
            "        [-1.6344,  0.2350,  0.8837],\n",
            "        [ 0.0700, -0.2761, -0.1786],\n",
            "        [-1.7842,  1.8159, -0.0613],\n",
            "        [-1.2957,  0.2378,  0.9400],\n",
            "        [-1.6808,  1.3390, -0.1858],\n",
            "        [ 0.3413, -0.1444, -0.4671]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6422,  0.9528,  0.5068],\n",
            "        [-1.4279,  0.2979,  0.9838],\n",
            "        [-1.3741,  0.4202,  1.0064],\n",
            "        [-1.5946,  1.6881, -0.1748],\n",
            "        [-1.3145,  0.1893,  1.0846],\n",
            "        [-1.3127,  0.0491,  0.9406],\n",
            "        [ 0.4041, -0.1813, -0.4825],\n",
            "        [-1.4796,  0.1934,  0.8865],\n",
            "        [-1.6990,  1.7079, -0.2266],\n",
            "        [ 0.1657, -0.0286, -0.6825],\n",
            "        [-1.6344,  0.2350,  0.8837],\n",
            "        [ 0.0700, -0.2761, -0.1786],\n",
            "        [-1.7842,  1.8159, -0.0613],\n",
            "        [-1.2957,  0.2378,  0.9400],\n",
            "        [-1.6808,  1.3390, -0.1858],\n",
            "        [ 0.3413, -0.1444, -0.4671]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4650,  0.1915,  0.9670],\n",
            "        [-1.6190,  1.5602, -0.4194],\n",
            "        [-1.5998,  1.5092, -0.0611],\n",
            "        [-1.7205,  1.4263,  0.1331],\n",
            "        [-1.4074,  1.6731, -0.3743],\n",
            "        [-1.4364,  1.3040,  0.0981],\n",
            "        [-1.7499,  1.8220, -0.1179],\n",
            "        [-1.2190,  0.1089,  0.7377],\n",
            "        [-1.3949,  0.0310,  0.9003],\n",
            "        [-1.2310,  0.2821,  0.7725],\n",
            "        [-1.1682,  1.1663, -0.3912],\n",
            "        [-1.4888,  0.0351,  1.0403],\n",
            "        [-1.3696,  0.1324,  1.0545],\n",
            "        [-1.5484,  1.6259, -0.1946],\n",
            "        [-1.6394,  0.6776,  0.6578],\n",
            "        [-1.2185,  1.4851, -0.5432]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4650,  0.1915,  0.9670],\n",
            "        [-1.6190,  1.5602, -0.4194],\n",
            "        [-1.5998,  1.5092, -0.0611],\n",
            "        [-1.7205,  1.4263,  0.1331],\n",
            "        [-1.4074,  1.6731, -0.3743],\n",
            "        [-1.4364,  1.3040,  0.0981],\n",
            "        [-1.7499,  1.8220, -0.1179],\n",
            "        [-1.2190,  0.1089,  0.7377],\n",
            "        [-1.3949,  0.0310,  0.9003],\n",
            "        [-1.2310,  0.2821,  0.7725],\n",
            "        [-1.1682,  1.1663, -0.3912],\n",
            "        [-1.4888,  0.0351,  1.0403],\n",
            "        [-1.3696,  0.1324,  1.0545],\n",
            "        [-1.5484,  1.6259, -0.1946],\n",
            "        [-1.6394,  0.6776,  0.6578],\n",
            "        [-1.2185,  1.4851, -0.5432]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4609,  0.3165,  0.9512],\n",
            "        [-1.4667,  1.5669, -0.0661],\n",
            "        [-1.5282,  1.5204, -0.1168],\n",
            "        [-1.6329,  1.7366,  0.0441],\n",
            "        [-1.4492,  1.5498, -0.2158],\n",
            "        [-1.6344,  1.6173, -0.0418],\n",
            "        [-1.5517,  1.0077,  0.3104],\n",
            "        [-1.7214,  1.1908,  0.2173],\n",
            "        [-1.7332,  1.4952,  0.2109],\n",
            "        [-1.6687,  0.4860,  0.9115],\n",
            "        [-1.6651,  1.3918,  0.0977],\n",
            "        [-1.6041,  1.6837, -0.2398],\n",
            "        [-1.7107,  1.5760, -0.0319],\n",
            "        [-1.3768,  0.1288,  1.0335],\n",
            "        [-1.7892,  1.4599, -0.0571],\n",
            "        [-1.7726,  1.7226, -0.1102]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4609,  0.3165,  0.9512],\n",
            "        [-1.4667,  1.5669, -0.0661],\n",
            "        [-1.5282,  1.5204, -0.1168],\n",
            "        [-1.6329,  1.7366,  0.0441],\n",
            "        [-1.4492,  1.5498, -0.2158],\n",
            "        [-1.6344,  1.6173, -0.0418],\n",
            "        [-1.5517,  1.0077,  0.3104],\n",
            "        [-1.7214,  1.1908,  0.2173],\n",
            "        [-1.7332,  1.4952,  0.2109],\n",
            "        [-1.6687,  0.4860,  0.9115],\n",
            "        [-1.6651,  1.3918,  0.0977],\n",
            "        [-1.6041,  1.6837, -0.2398],\n",
            "        [-1.7107,  1.5760, -0.0319],\n",
            "        [-1.3768,  0.1288,  1.0335],\n",
            "        [-1.7892,  1.4599, -0.0571],\n",
            "        [-1.7726,  1.7226, -0.1102]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7864,  1.6557,  0.0863],\n",
            "        [-1.7568,  0.7768,  0.7463],\n",
            "        [-1.7182,  0.9680,  0.4907],\n",
            "        [-0.7460, -0.0480,  0.5871],\n",
            "        [-1.3828,  0.2526,  0.8746],\n",
            "        [-1.5107,  1.4938, -0.3720],\n",
            "        [-1.7927,  0.9726,  0.6224],\n",
            "        [-1.7329,  1.3943, -0.0537],\n",
            "        [-1.6818,  1.1677,  0.4432],\n",
            "        [-1.8928,  1.7844, -0.1542],\n",
            "        [-1.5485,  1.2671,  0.0899],\n",
            "        [-1.5301,  1.3553, -0.0228],\n",
            "        [-1.3190,  0.2199,  0.9575],\n",
            "        [-1.3867,  0.0326,  0.9607],\n",
            "        [-1.5576,  1.1752, -0.2347],\n",
            "        [-1.9026,  1.5299, -0.1863]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7864,  1.6557,  0.0863],\n",
            "        [-1.7568,  0.7768,  0.7463],\n",
            "        [-1.7182,  0.9680,  0.4907],\n",
            "        [-0.7460, -0.0480,  0.5871],\n",
            "        [-1.3828,  0.2526,  0.8746],\n",
            "        [-1.5107,  1.4938, -0.3720],\n",
            "        [-1.7927,  0.9726,  0.6224],\n",
            "        [-1.7329,  1.3943, -0.0537],\n",
            "        [-1.6818,  1.1677,  0.4432],\n",
            "        [-1.8928,  1.7844, -0.1542],\n",
            "        [-1.5485,  1.2671,  0.0899],\n",
            "        [-1.5301,  1.3553, -0.0228],\n",
            "        [-1.3190,  0.2199,  0.9575],\n",
            "        [-1.3867,  0.0326,  0.9607],\n",
            "        [-1.5576,  1.1752, -0.2347],\n",
            "        [-1.9026,  1.5299, -0.1863]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4975,  0.1686,  0.9857],\n",
            "        [ 0.1310,  0.0320, -0.6754],\n",
            "        [-0.6506,  1.0332, -0.6708],\n",
            "        [-1.5171,  0.3241,  0.9961],\n",
            "        [-0.5193,  0.4641, -0.5470],\n",
            "        [-1.7587,  1.2763,  0.5701],\n",
            "        [-1.4980,  1.0621,  0.3984],\n",
            "        [-1.4677,  1.5097, -0.0758],\n",
            "        [-1.5482,  1.5155, -0.2330],\n",
            "        [-1.4586,  1.2848, -0.1900],\n",
            "        [-1.5755,  0.3846,  1.1401],\n",
            "        [-1.7287,  1.7924, -0.2507],\n",
            "        [-1.7082,  1.6859, -0.4087],\n",
            "        [-1.2324,  0.0582,  0.8575],\n",
            "        [-1.4702,  1.6997, -0.1872],\n",
            "        [ 0.3093, -0.0373, -0.6132]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4975,  0.1686,  0.9857],\n",
            "        [ 0.1310,  0.0320, -0.6754],\n",
            "        [-0.6506,  1.0332, -0.6708],\n",
            "        [-1.5171,  0.3241,  0.9961],\n",
            "        [-0.5193,  0.4641, -0.5470],\n",
            "        [-1.7587,  1.2763,  0.5701],\n",
            "        [-1.4980,  1.0621,  0.3984],\n",
            "        [-1.4677,  1.5097, -0.0758],\n",
            "        [-1.5482,  1.5155, -0.2330],\n",
            "        [-1.4586,  1.2848, -0.1900],\n",
            "        [-1.5755,  0.3846,  1.1401],\n",
            "        [-1.7287,  1.7924, -0.2507],\n",
            "        [-1.7082,  1.6859, -0.4087],\n",
            "        [-1.2324,  0.0582,  0.8575],\n",
            "        [-1.4702,  1.6997, -0.1872],\n",
            "        [ 0.3093, -0.0373, -0.6132]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6543,  1.4891, -0.0428],\n",
            "        [-1.4159,  1.5801, -0.3646],\n",
            "        [-1.7949,  1.1391,  0.4081],\n",
            "        [ 0.1906, -0.2524, -0.5046],\n",
            "        [-1.5091,  1.5863, -0.3592],\n",
            "        [-1.3681,  1.4828, -0.2573],\n",
            "        [-1.4921,  0.1741,  1.0944],\n",
            "        [-1.6923,  1.5777, -0.2087],\n",
            "        [-1.7114,  1.6439,  0.0164],\n",
            "        [-1.9285,  1.0184,  0.4399],\n",
            "        [-1.7130,  1.7467, -0.2373],\n",
            "        [-1.7148,  1.2243,  0.0452],\n",
            "        [-1.7316,  0.7566,  0.4301],\n",
            "        [-0.1116,  0.4428, -0.9655],\n",
            "        [-1.8263,  1.4342,  0.4208],\n",
            "        [-1.5416,  1.5907, -0.3416]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6543,  1.4891, -0.0428],\n",
            "        [-1.4159,  1.5801, -0.3646],\n",
            "        [-1.7949,  1.1391,  0.4081],\n",
            "        [ 0.1906, -0.2524, -0.5046],\n",
            "        [-1.5091,  1.5863, -0.3592],\n",
            "        [-1.3681,  1.4828, -0.2573],\n",
            "        [-1.4921,  0.1741,  1.0944],\n",
            "        [-1.6923,  1.5777, -0.2087],\n",
            "        [-1.7114,  1.6439,  0.0164],\n",
            "        [-1.9285,  1.0184,  0.4399],\n",
            "        [-1.7130,  1.7467, -0.2373],\n",
            "        [-1.7148,  1.2243,  0.0452],\n",
            "        [-1.7316,  0.7566,  0.4301],\n",
            "        [-0.1116,  0.4428, -0.9655],\n",
            "        [-1.8263,  1.4342,  0.4208],\n",
            "        [-1.5416,  1.5907, -0.3416]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6002,  1.6663, -0.3978],\n",
            "        [-1.8235,  1.4550,  0.2530],\n",
            "        [-1.2568,  1.5976, -0.6218],\n",
            "        [-1.3140,  0.0774,  1.0708],\n",
            "        [-0.3598, -0.1279,  0.2134],\n",
            "        [-1.7428,  0.7871,  0.9112],\n",
            "        [ 0.2631, -0.1912, -0.6935],\n",
            "        [-1.4893,  1.6905, -0.4444],\n",
            "        [-1.5367,  0.2719,  1.0114],\n",
            "        [-1.4823,  1.4998,  0.0071],\n",
            "        [-1.6921,  1.4909, -0.0954],\n",
            "        [-1.4211,  0.7149,  0.1728],\n",
            "        [-1.4312,  0.2046,  0.9603],\n",
            "        [-1.5502,  1.5807, -0.3131],\n",
            "        [-0.6693,  0.8298, -0.5521],\n",
            "        [-1.4561,  1.6516, -0.3538]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6002,  1.6663, -0.3978],\n",
            "        [-1.8235,  1.4550,  0.2530],\n",
            "        [-1.2568,  1.5976, -0.6218],\n",
            "        [-1.3140,  0.0774,  1.0708],\n",
            "        [-0.3598, -0.1279,  0.2134],\n",
            "        [-1.7428,  0.7871,  0.9112],\n",
            "        [ 0.2631, -0.1912, -0.6935],\n",
            "        [-1.4893,  1.6905, -0.4444],\n",
            "        [-1.5367,  0.2719,  1.0114],\n",
            "        [-1.4823,  1.4998,  0.0071],\n",
            "        [-1.6921,  1.4909, -0.0954],\n",
            "        [-1.4211,  0.7149,  0.1728],\n",
            "        [-1.4312,  0.2046,  0.9603],\n",
            "        [-1.5502,  1.5807, -0.3131],\n",
            "        [-0.6693,  0.8298, -0.5521],\n",
            "        [-1.4561,  1.6516, -0.3538]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5039,  1.5629, -0.1926],\n",
            "        [-1.5414,  1.6076, -0.2633],\n",
            "        [-1.6356,  1.4153, -0.2694],\n",
            "        [-1.3122,  0.1675,  0.9520],\n",
            "        [-1.8534,  1.6977, -0.2535],\n",
            "        [-1.5263,  1.6144,  0.0651],\n",
            "        [-1.4377,  1.7075, -0.1753],\n",
            "        [-1.3969,  1.5025, -0.3025],\n",
            "        [-1.6467,  0.3251,  1.0636],\n",
            "        [-0.8025,  1.1116, -0.6895],\n",
            "        [-1.3971,  0.3503,  0.7876],\n",
            "        [-1.5268,  1.4551, -0.4449],\n",
            "        [-1.5432,  0.4482,  0.8256],\n",
            "        [-1.5210,  1.6508, -0.1950],\n",
            "        [-1.7139,  1.4789, -0.0821],\n",
            "        [-0.0352,  0.2524, -0.8105]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5039,  1.5629, -0.1926],\n",
            "        [-1.5414,  1.6076, -0.2633],\n",
            "        [-1.6356,  1.4153, -0.2694],\n",
            "        [-1.3122,  0.1675,  0.9520],\n",
            "        [-1.8534,  1.6977, -0.2535],\n",
            "        [-1.5263,  1.6144,  0.0651],\n",
            "        [-1.4377,  1.7075, -0.1753],\n",
            "        [-1.3969,  1.5025, -0.3025],\n",
            "        [-1.6467,  0.3251,  1.0636],\n",
            "        [-0.8025,  1.1116, -0.6895],\n",
            "        [-1.3971,  0.3503,  0.7876],\n",
            "        [-1.5268,  1.4551, -0.4449],\n",
            "        [-1.5432,  0.4482,  0.8256],\n",
            "        [-1.5210,  1.6508, -0.1950],\n",
            "        [-1.7139,  1.4789, -0.0821],\n",
            "        [-0.0352,  0.2524, -0.8105]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5414,  1.5050, -0.3351],\n",
            "        [-1.6120,  1.5549, -0.3075],\n",
            "        [-1.5454,  1.4726, -0.2790],\n",
            "        [-1.7279,  1.7502, -0.2338],\n",
            "        [-1.2884,  0.2232,  0.7760],\n",
            "        [ 0.0899,  0.4070, -0.8992],\n",
            "        [-1.5728,  1.4206, -0.1493],\n",
            "        [ 0.2129, -0.1970, -0.4246],\n",
            "        [-1.5334,  1.6625, -0.3509],\n",
            "        [-1.5924,  0.3264,  0.9303],\n",
            "        [-1.7247,  1.2535,  0.2935],\n",
            "        [-1.4849,  1.5764, -0.1283],\n",
            "        [ 0.3366, -0.1747, -0.7518],\n",
            "        [-1.7312,  1.4895, -0.2393],\n",
            "        [-1.7657,  1.1369,  0.3551],\n",
            "        [-1.7401,  1.7110, -0.2861]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5414,  1.5050, -0.3351],\n",
            "        [-1.6120,  1.5549, -0.3075],\n",
            "        [-1.5454,  1.4726, -0.2790],\n",
            "        [-1.7279,  1.7502, -0.2338],\n",
            "        [-1.2884,  0.2232,  0.7760],\n",
            "        [ 0.0899,  0.4070, -0.8992],\n",
            "        [-1.5728,  1.4206, -0.1493],\n",
            "        [ 0.2129, -0.1970, -0.4246],\n",
            "        [-1.5334,  1.6625, -0.3509],\n",
            "        [-1.5924,  0.3264,  0.9303],\n",
            "        [-1.7247,  1.2535,  0.2935],\n",
            "        [-1.4849,  1.5764, -0.1283],\n",
            "        [ 0.3366, -0.1747, -0.7518],\n",
            "        [-1.7312,  1.4895, -0.2393],\n",
            "        [-1.7657,  1.1369,  0.3551],\n",
            "        [-1.7401,  1.7110, -0.2861]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4536,  1.6587, -0.2285],\n",
            "        [-1.5313,  1.4217, -0.4563],\n",
            "        [-1.5336,  1.7283, -0.3728],\n",
            "        [-1.4815,  1.7449, -0.3263],\n",
            "        [-1.5327,  0.7301,  0.7764],\n",
            "        [-1.7208,  1.5624, -0.2408],\n",
            "        [-1.7051,  0.4442,  0.8621],\n",
            "        [-1.2710,  0.1173,  1.0319],\n",
            "        [-1.3305,  1.5176, -0.4067],\n",
            "        [-1.4279,  0.2603,  0.9414],\n",
            "        [-1.7885,  1.8305, -0.2329],\n",
            "        [-1.3992,  1.4214, -0.2593],\n",
            "        [-1.4925,  0.1146,  1.0997],\n",
            "        [-1.5077,  0.0535,  1.0683],\n",
            "        [ 0.2663, -0.1274, -0.6499],\n",
            "        [-1.7952,  1.5778, -0.3339]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4536,  1.6587, -0.2285],\n",
            "        [-1.5313,  1.4217, -0.4563],\n",
            "        [-1.5336,  1.7283, -0.3728],\n",
            "        [-1.4815,  1.7449, -0.3263],\n",
            "        [-1.5327,  0.7301,  0.7764],\n",
            "        [-1.7208,  1.5624, -0.2408],\n",
            "        [-1.7051,  0.4442,  0.8621],\n",
            "        [-1.2710,  0.1173,  1.0319],\n",
            "        [-1.3305,  1.5176, -0.4067],\n",
            "        [-1.4279,  0.2603,  0.9414],\n",
            "        [-1.7885,  1.8305, -0.2329],\n",
            "        [-1.3992,  1.4214, -0.2593],\n",
            "        [-1.4925,  0.1146,  1.0997],\n",
            "        [-1.5077,  0.0535,  1.0683],\n",
            "        [ 0.2663, -0.1274, -0.6499],\n",
            "        [-1.7952,  1.5778, -0.3339]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8154,  1.6703,  0.0820],\n",
            "        [-1.6066,  1.7289, -0.4824],\n",
            "        [-1.4976,  1.6302, -0.3315],\n",
            "        [-1.5199,  1.7651, -0.5435],\n",
            "        [-1.3630,  1.5187, -0.5266],\n",
            "        [-1.6910,  1.8499, -0.3425],\n",
            "        [-1.6532,  1.1154,  0.0644],\n",
            "        [-1.7904,  1.0063,  0.6535],\n",
            "        [-1.5859,  0.9191,  0.4464],\n",
            "        [-1.5481,  0.1242,  0.9783],\n",
            "        [-0.2344,  0.5874, -0.9642],\n",
            "        [ 0.0529,  0.4737, -0.8250],\n",
            "        [-1.6430,  1.6572, -0.2237],\n",
            "        [-1.6335,  0.6375,  0.8389],\n",
            "        [-1.5544,  1.6371, -0.3808],\n",
            "        [-1.5982,  0.3635,  1.0461]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8154,  1.6703,  0.0820],\n",
            "        [-1.6066,  1.7289, -0.4824],\n",
            "        [-1.4976,  1.6302, -0.3315],\n",
            "        [-1.5199,  1.7651, -0.5435],\n",
            "        [-1.3630,  1.5187, -0.5266],\n",
            "        [-1.6910,  1.8499, -0.3425],\n",
            "        [-1.6532,  1.1154,  0.0644],\n",
            "        [-1.7904,  1.0063,  0.6535],\n",
            "        [-1.5859,  0.9191,  0.4464],\n",
            "        [-1.5481,  0.1242,  0.9783],\n",
            "        [-0.2344,  0.5874, -0.9642],\n",
            "        [ 0.0529,  0.4737, -0.8250],\n",
            "        [-1.6430,  1.6572, -0.2237],\n",
            "        [-1.6335,  0.6375,  0.8389],\n",
            "        [-1.5544,  1.6371, -0.3808],\n",
            "        [-1.5982,  0.3635,  1.0461]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5453, -0.1110, -0.6912],\n",
            "        [-1.5632,  1.5973, -0.2784],\n",
            "        [-1.4183,  0.1077,  0.9425],\n",
            "        [-1.9185,  1.4670,  0.0945],\n",
            "        [ 0.4428, -0.1250, -0.8002],\n",
            "        [-1.5137,  1.7585, -0.4959],\n",
            "        [-1.5331,  1.6442, -0.1584],\n",
            "        [-1.6178,  1.5347, -0.3230],\n",
            "        [-0.8402,  0.0596,  0.7645],\n",
            "        [ 0.3594, -0.2459, -0.8257],\n",
            "        [-1.5050,  1.8176, -0.3569],\n",
            "        [ 0.1338, -0.0588, -0.6479],\n",
            "        [-1.3832,  1.5950, -0.2169],\n",
            "        [-1.5981,  1.6249, -0.5120],\n",
            "        [-1.3342,  1.6384, -0.2775],\n",
            "        [-1.6784,  1.7087, -0.3743]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.5453, -0.1110, -0.6912],\n",
            "        [-1.5632,  1.5973, -0.2784],\n",
            "        [-1.4183,  0.1077,  0.9425],\n",
            "        [-1.9185,  1.4670,  0.0945],\n",
            "        [ 0.4428, -0.1250, -0.8002],\n",
            "        [-1.5137,  1.7585, -0.4959],\n",
            "        [-1.5331,  1.6442, -0.1584],\n",
            "        [-1.6178,  1.5347, -0.3230],\n",
            "        [-0.8402,  0.0596,  0.7645],\n",
            "        [ 0.3594, -0.2459, -0.8257],\n",
            "        [-1.5050,  1.8176, -0.3569],\n",
            "        [ 0.1338, -0.0588, -0.6479],\n",
            "        [-1.3832,  1.5950, -0.2169],\n",
            "        [-1.5981,  1.6249, -0.5120],\n",
            "        [-1.3342,  1.6384, -0.2775],\n",
            "        [-1.6784,  1.7087, -0.3743]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7270,  1.7740, -0.1209],\n",
            "        [-1.4360,  1.5887, -0.3289],\n",
            "        [ 0.5066, -0.2212, -0.4803],\n",
            "        [-0.9280,  0.6164, -0.1292],\n",
            "        [ 0.4495, -0.2640, -0.7062],\n",
            "        [-1.2175,  1.4758, -0.3570],\n",
            "        [-1.3077,  0.2404,  1.1476],\n",
            "        [-1.7011,  1.7013, -0.1686],\n",
            "        [ 0.2913, -0.0301, -0.6076],\n",
            "        [-1.7178,  0.1032,  1.1677],\n",
            "        [-1.4916,  0.3557,  0.7168],\n",
            "        [-1.6643,  0.9866,  0.1737],\n",
            "        [-1.7428,  0.5572,  1.1013],\n",
            "        [-1.5578,  1.6765, -0.2505],\n",
            "        [-1.4638,  1.5317, -0.3959],\n",
            "        [-1.5478,  1.7196, -0.3160]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7270,  1.7740, -0.1209],\n",
            "        [-1.4360,  1.5887, -0.3289],\n",
            "        [ 0.5066, -0.2212, -0.4803],\n",
            "        [-0.9280,  0.6164, -0.1292],\n",
            "        [ 0.4495, -0.2640, -0.7062],\n",
            "        [-1.2175,  1.4758, -0.3570],\n",
            "        [-1.3077,  0.2404,  1.1476],\n",
            "        [-1.7011,  1.7013, -0.1686],\n",
            "        [ 0.2913, -0.0301, -0.6076],\n",
            "        [-1.7178,  0.1032,  1.1677],\n",
            "        [-1.4916,  0.3557,  0.7168],\n",
            "        [-1.6643,  0.9866,  0.1737],\n",
            "        [-1.7428,  0.5572,  1.1013],\n",
            "        [-1.5578,  1.6765, -0.2505],\n",
            "        [-1.4638,  1.5317, -0.3959],\n",
            "        [-1.5478,  1.7196, -0.3160]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.1597, -0.2046, -0.8707],\n",
            "        [-1.5388,  0.8941,  0.7359],\n",
            "        [-1.6609,  1.7892, -0.4378],\n",
            "        [-1.6921,  0.4208,  1.0034],\n",
            "        [-1.5557,  1.5806, -0.2155],\n",
            "        [-1.7035,  1.7014, -0.2780],\n",
            "        [-1.4309,  1.7114, -0.3257],\n",
            "        [-1.7006,  0.8506,  0.8789],\n",
            "        [ 0.4416, -0.1885, -0.7912],\n",
            "        [-1.4197,  1.8219, -0.4129],\n",
            "        [-1.6051,  1.3002,  0.2605],\n",
            "        [-1.5101,  1.6050, -0.2718],\n",
            "        [-1.3445,  0.5514,  0.8461],\n",
            "        [-1.4615,  1.7027, -0.5706],\n",
            "        [-1.5897,  1.7076, -0.3357],\n",
            "        [-1.5390,  1.5479, -0.2771]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.1597, -0.2046, -0.8707],\n",
            "        [-1.5388,  0.8941,  0.7359],\n",
            "        [-1.6609,  1.7892, -0.4378],\n",
            "        [-1.6921,  0.4208,  1.0034],\n",
            "        [-1.5557,  1.5806, -0.2155],\n",
            "        [-1.7035,  1.7014, -0.2780],\n",
            "        [-1.4309,  1.7114, -0.3257],\n",
            "        [-1.7006,  0.8506,  0.8789],\n",
            "        [ 0.4416, -0.1885, -0.7912],\n",
            "        [-1.4197,  1.8219, -0.4129],\n",
            "        [-1.6051,  1.3002,  0.2605],\n",
            "        [-1.5101,  1.6050, -0.2718],\n",
            "        [-1.3445,  0.5514,  0.8461],\n",
            "        [-1.4615,  1.7027, -0.5706],\n",
            "        [-1.5897,  1.7076, -0.3357],\n",
            "        [-1.5390,  1.5479, -0.2771]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5777, -0.0043,  1.0596],\n",
            "        [-1.4689,  1.7226, -0.2867],\n",
            "        [-1.4926,  1.6097, -0.3549],\n",
            "        [ 0.5543, -0.1903, -0.6267],\n",
            "        [-1.5241,  1.5244, -0.3101],\n",
            "        [-1.5272,  0.5103,  1.0256],\n",
            "        [-1.6260,  1.6816, -0.2968],\n",
            "        [ 0.3817, -0.2366, -0.9315],\n",
            "        [-1.5350,  1.6425, -0.4569],\n",
            "        [ 0.3383, -0.1946, -0.6495],\n",
            "        [-1.5231,  1.6636, -0.2969],\n",
            "        [-1.4396,  1.5275, -0.2744],\n",
            "        [-1.5974,  1.7054, -0.4160],\n",
            "        [-1.5525,  1.7583, -0.4141],\n",
            "        [-1.7395,  1.1403,  0.1766],\n",
            "        [-1.7677,  1.4349, -0.0568]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5777, -0.0043,  1.0596],\n",
            "        [-1.4689,  1.7226, -0.2867],\n",
            "        [-1.4926,  1.6097, -0.3549],\n",
            "        [ 0.5543, -0.1903, -0.6267],\n",
            "        [-1.5241,  1.5244, -0.3101],\n",
            "        [-1.5272,  0.5103,  1.0256],\n",
            "        [-1.6260,  1.6816, -0.2968],\n",
            "        [ 0.3817, -0.2366, -0.9315],\n",
            "        [-1.5350,  1.6425, -0.4569],\n",
            "        [ 0.3383, -0.1946, -0.6495],\n",
            "        [-1.5231,  1.6636, -0.2969],\n",
            "        [-1.4396,  1.5275, -0.2744],\n",
            "        [-1.5974,  1.7054, -0.4160],\n",
            "        [-1.5525,  1.7583, -0.4141],\n",
            "        [-1.7395,  1.1403,  0.1766],\n",
            "        [-1.7677,  1.4349, -0.0568]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3007, -0.0228, -0.9128],\n",
            "        [-1.8394,  1.3511,  0.4665],\n",
            "        [-1.5969,  1.9031, -0.5017],\n",
            "        [-1.5115,  1.7227, -0.3342],\n",
            "        [ 0.4062, -0.0868, -0.7614],\n",
            "        [-1.5192,  1.5180, -0.1211],\n",
            "        [-1.6556,  1.6783, -0.4374],\n",
            "        [-1.2499,  1.5970, -0.5862],\n",
            "        [-1.4145,  1.8549, -0.4484],\n",
            "        [-1.5729,  1.8672, -0.4780],\n",
            "        [-1.5563,  1.7447, -0.2540],\n",
            "        [-1.5344,  1.7727, -0.2782],\n",
            "        [-1.6795,  1.8360, -0.2010],\n",
            "        [-1.6603,  1.6149, -0.0258],\n",
            "        [-1.7151,  1.5678, -0.3529],\n",
            "        [-1.4707,  1.6560, -0.3010]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.3007, -0.0228, -0.9128],\n",
            "        [-1.8394,  1.3511,  0.4665],\n",
            "        [-1.5969,  1.9031, -0.5017],\n",
            "        [-1.5115,  1.7227, -0.3342],\n",
            "        [ 0.4062, -0.0868, -0.7614],\n",
            "        [-1.5192,  1.5180, -0.1211],\n",
            "        [-1.6556,  1.6783, -0.4374],\n",
            "        [-1.2499,  1.5970, -0.5862],\n",
            "        [-1.4145,  1.8549, -0.4484],\n",
            "        [-1.5729,  1.8672, -0.4780],\n",
            "        [-1.5563,  1.7447, -0.2540],\n",
            "        [-1.5344,  1.7727, -0.2782],\n",
            "        [-1.6795,  1.8360, -0.2010],\n",
            "        [-1.6603,  1.6149, -0.0258],\n",
            "        [-1.7151,  1.5678, -0.3529],\n",
            "        [-1.4707,  1.6560, -0.3010]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5330, -0.0802, -0.8477],\n",
            "        [-1.4648,  1.6837, -0.1472],\n",
            "        [-1.5629,  1.5294, -0.2176],\n",
            "        [-1.4552,  1.5239, -0.4555],\n",
            "        [-1.4265,  0.0755,  0.9470],\n",
            "        [-1.4075,  1.6216, -0.3518],\n",
            "        [-1.8345,  0.4074,  1.1200],\n",
            "        [-1.4340,  1.5672, -0.4984],\n",
            "        [-1.3820,  1.6074, -0.2760],\n",
            "        [-1.6093,  1.7677, -0.3387],\n",
            "        [-1.4058,  0.3268,  0.8673],\n",
            "        [-1.7299,  1.7718, -0.4240],\n",
            "        [-1.5460,  1.4175, -0.2538],\n",
            "        [-1.5188,  1.5553, -0.4432],\n",
            "        [-0.4487,  0.5458, -0.8455],\n",
            "        [-1.5681,  0.1376,  1.0761]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.5330, -0.0802, -0.8477],\n",
            "        [-1.4648,  1.6837, -0.1472],\n",
            "        [-1.5629,  1.5294, -0.2176],\n",
            "        [-1.4552,  1.5239, -0.4555],\n",
            "        [-1.4265,  0.0755,  0.9470],\n",
            "        [-1.4075,  1.6216, -0.3518],\n",
            "        [-1.8345,  0.4074,  1.1200],\n",
            "        [-1.4340,  1.5672, -0.4984],\n",
            "        [-1.3820,  1.6074, -0.2760],\n",
            "        [-1.6093,  1.7677, -0.3387],\n",
            "        [-1.4058,  0.3268,  0.8673],\n",
            "        [-1.7299,  1.7718, -0.4240],\n",
            "        [-1.5460,  1.4175, -0.2538],\n",
            "        [-1.5188,  1.5553, -0.4432],\n",
            "        [-0.4487,  0.5458, -0.8455],\n",
            "        [-1.5681,  0.1376,  1.0761]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6987,  1.7169, -0.2103],\n",
            "        [-1.4001,  0.3033,  0.8526],\n",
            "        [-1.4795,  1.7069, -0.4616],\n",
            "        [-1.4715,  0.4400,  1.0297],\n",
            "        [ 0.5456, -0.1937, -0.8013],\n",
            "        [-1.6979,  1.6079, -0.3129],\n",
            "        [ 0.4484, -0.1561, -0.8019],\n",
            "        [-1.5193,  1.4950,  0.1652],\n",
            "        [-1.5545,  1.5080, -0.3590],\n",
            "        [-1.4228,  1.5620, -0.4921],\n",
            "        [-1.6360,  1.6978, -0.5527],\n",
            "        [-1.7256,  1.6806, -0.2319],\n",
            "        [-1.3894,  0.1836,  1.0874],\n",
            "        [-1.6517,  1.7059, -0.4969],\n",
            "        [-1.2329,  1.5898, -0.4990],\n",
            "        [-1.5816,  1.8471, -0.3177]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6987,  1.7169, -0.2103],\n",
            "        [-1.4001,  0.3033,  0.8526],\n",
            "        [-1.4795,  1.7069, -0.4616],\n",
            "        [-1.4715,  0.4400,  1.0297],\n",
            "        [ 0.5456, -0.1937, -0.8013],\n",
            "        [-1.6979,  1.6079, -0.3129],\n",
            "        [ 0.4484, -0.1561, -0.8019],\n",
            "        [-1.5193,  1.4950,  0.1652],\n",
            "        [-1.5545,  1.5080, -0.3590],\n",
            "        [-1.4228,  1.5620, -0.4921],\n",
            "        [-1.6360,  1.6978, -0.5527],\n",
            "        [-1.7256,  1.6806, -0.2319],\n",
            "        [-1.3894,  0.1836,  1.0874],\n",
            "        [-1.6517,  1.7059, -0.4969],\n",
            "        [-1.2329,  1.5898, -0.4990],\n",
            "        [-1.5816,  1.8471, -0.3177]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4388,  0.2965,  1.1343],\n",
            "        [-1.4772,  1.8869, -0.4161],\n",
            "        [-1.7282,  0.4212,  0.9332],\n",
            "        [ 0.4945, -0.1153, -0.9469],\n",
            "        [-1.2927,  0.7547,  0.0923],\n",
            "        [ 0.3977, -0.1402, -0.8195],\n",
            "        [ 0.5382, -0.0838, -0.7783],\n",
            "        [ 0.3501,  0.0469, -0.7768],\n",
            "        [-1.6901,  0.4419,  0.8301],\n",
            "        [-1.4952,  1.6884, -0.3299],\n",
            "        [-1.7139,  1.9503, -0.3204],\n",
            "        [-1.5440,  1.6790, -0.3538],\n",
            "        [-1.4098,  1.6198, -0.2838],\n",
            "        [-1.3730,  1.4134, -0.3671],\n",
            "        [-1.3277,  1.6492, -0.4805],\n",
            "        [-1.7548,  0.6299,  0.8507]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4388,  0.2965,  1.1343],\n",
            "        [-1.4772,  1.8869, -0.4161],\n",
            "        [-1.7282,  0.4212,  0.9332],\n",
            "        [ 0.4945, -0.1153, -0.9469],\n",
            "        [-1.2927,  0.7547,  0.0923],\n",
            "        [ 0.3977, -0.1402, -0.8195],\n",
            "        [ 0.5382, -0.0838, -0.7783],\n",
            "        [ 0.3501,  0.0469, -0.7768],\n",
            "        [-1.6901,  0.4419,  0.8301],\n",
            "        [-1.4952,  1.6884, -0.3299],\n",
            "        [-1.7139,  1.9503, -0.3204],\n",
            "        [-1.5440,  1.6790, -0.3538],\n",
            "        [-1.4098,  1.6198, -0.2838],\n",
            "        [-1.3730,  1.4134, -0.3671],\n",
            "        [-1.3277,  1.6492, -0.4805],\n",
            "        [-1.7548,  0.6299,  0.8507]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5663e+00,  2.7197e-01,  1.0268e+00],\n",
            "        [-1.4256e+00,  3.8039e-01,  1.0420e+00],\n",
            "        [-1.6211e+00,  1.8182e+00, -5.2521e-01],\n",
            "        [-1.4853e+00,  1.7010e+00, -6.6117e-02],\n",
            "        [-1.4776e+00,  1.3707e+00,  6.4830e-02],\n",
            "        [-1.8602e+00,  1.0316e+00,  4.5215e-01],\n",
            "        [ 4.5270e-01, -1.6652e-01, -8.3899e-01],\n",
            "        [-1.1678e-01,  6.8320e-01, -6.0803e-01],\n",
            "        [-1.8548e+00,  1.6722e+00, -1.5389e-01],\n",
            "        [-1.8470e+00,  1.1126e+00,  5.0678e-01],\n",
            "        [-1.5739e+00,  1.5585e+00, -3.4155e-01],\n",
            "        [ 1.2976e-01, -3.8634e-02, -5.0318e-01],\n",
            "        [-1.8726e+00,  1.2137e+00,  3.5865e-01],\n",
            "        [-1.2352e+00,  1.3681e-03,  8.8560e-01],\n",
            "        [-1.4610e+00,  1.8544e+00, -4.2263e-01],\n",
            "        [-1.4774e+00,  1.5992e+00, -2.6034e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5663e+00,  2.7197e-01,  1.0268e+00],\n",
            "        [-1.4256e+00,  3.8039e-01,  1.0420e+00],\n",
            "        [-1.6211e+00,  1.8182e+00, -5.2521e-01],\n",
            "        [-1.4853e+00,  1.7010e+00, -6.6117e-02],\n",
            "        [-1.4776e+00,  1.3707e+00,  6.4830e-02],\n",
            "        [-1.8602e+00,  1.0316e+00,  4.5215e-01],\n",
            "        [ 4.5270e-01, -1.6652e-01, -8.3899e-01],\n",
            "        [-1.1678e-01,  6.8320e-01, -6.0803e-01],\n",
            "        [-1.8548e+00,  1.6722e+00, -1.5389e-01],\n",
            "        [-1.8470e+00,  1.1126e+00,  5.0678e-01],\n",
            "        [-1.5739e+00,  1.5585e+00, -3.4155e-01],\n",
            "        [ 1.2976e-01, -3.8634e-02, -5.0318e-01],\n",
            "        [-1.8726e+00,  1.2137e+00,  3.5865e-01],\n",
            "        [-1.2352e+00,  1.3681e-03,  8.8560e-01],\n",
            "        [-1.4610e+00,  1.8544e+00, -4.2263e-01],\n",
            "        [-1.4774e+00,  1.5992e+00, -2.6034e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5282,  1.4808, -0.5496],\n",
            "        [ 0.2756, -0.1297, -0.3936],\n",
            "        [-1.5467,  1.7357, -0.2684],\n",
            "        [-1.4915,  1.6058, -0.2988],\n",
            "        [-1.5390,  1.6932, -0.2095],\n",
            "        [-1.6999,  1.6882, -0.3205],\n",
            "        [ 0.2045,  0.0363, -0.9102],\n",
            "        [-1.2838,  1.4108, -0.3758],\n",
            "        [-1.5798,  1.5354, -0.2854],\n",
            "        [-1.5748,  1.3447, -0.2814],\n",
            "        [-1.4186,  1.5370, -0.1221],\n",
            "        [-1.5121,  1.6627, -0.2571],\n",
            "        [ 0.2676,  0.0243, -0.7772],\n",
            "        [-1.7395,  0.1855,  1.1395],\n",
            "        [-1.8658,  0.7914,  0.7610],\n",
            "        [-1.5582,  1.7532, -0.4279]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5282,  1.4808, -0.5496],\n",
            "        [ 0.2756, -0.1297, -0.3936],\n",
            "        [-1.5467,  1.7357, -0.2684],\n",
            "        [-1.4915,  1.6058, -0.2988],\n",
            "        [-1.5390,  1.6932, -0.2095],\n",
            "        [-1.6999,  1.6882, -0.3205],\n",
            "        [ 0.2045,  0.0363, -0.9102],\n",
            "        [-1.2838,  1.4108, -0.3758],\n",
            "        [-1.5798,  1.5354, -0.2854],\n",
            "        [-1.5748,  1.3447, -0.2814],\n",
            "        [-1.4186,  1.5370, -0.1221],\n",
            "        [-1.5121,  1.6627, -0.2571],\n",
            "        [ 0.2676,  0.0243, -0.7772],\n",
            "        [-1.7395,  0.1855,  1.1395],\n",
            "        [-1.8658,  0.7914,  0.7610],\n",
            "        [-1.5582,  1.7532, -0.4279]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8658e+00,  7.2888e-01,  9.5642e-01],\n",
            "        [-1.8702e+00,  8.2492e-01,  9.4928e-01],\n",
            "        [ 3.5974e-01, -6.2281e-04, -5.0509e-01],\n",
            "        [-1.5946e+00,  1.7099e+00, -4.2379e-01],\n",
            "        [-1.4914e+00,  1.7229e+00, -4.7052e-01],\n",
            "        [-1.5934e+00,  1.7427e+00, -4.4878e-01],\n",
            "        [-1.5755e+00,  1.8341e+00, -2.3678e-01],\n",
            "        [-1.6689e+00,  1.5859e+00, -4.2695e-01],\n",
            "        [-1.4788e+00,  1.7266e+00, -4.0582e-01],\n",
            "        [-1.6315e+00,  1.4851e+00, -3.8174e-01],\n",
            "        [-1.5016e+00,  1.6218e+00, -3.4059e-01],\n",
            "        [-1.4255e+00,  1.6768e+00, -5.1570e-01],\n",
            "        [-1.8396e+00,  3.8387e-01,  1.1448e+00],\n",
            "        [-1.7415e+00,  1.6755e+00, -1.9321e-01],\n",
            "        [ 5.4820e-01, -4.0627e-02, -8.8969e-01],\n",
            "        [-1.4588e+00,  1.4441e+00, -2.9387e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8658e+00,  7.2888e-01,  9.5642e-01],\n",
            "        [-1.8702e+00,  8.2492e-01,  9.4928e-01],\n",
            "        [ 3.5974e-01, -6.2281e-04, -5.0509e-01],\n",
            "        [-1.5946e+00,  1.7099e+00, -4.2379e-01],\n",
            "        [-1.4914e+00,  1.7229e+00, -4.7052e-01],\n",
            "        [-1.5934e+00,  1.7427e+00, -4.4878e-01],\n",
            "        [-1.5755e+00,  1.8341e+00, -2.3678e-01],\n",
            "        [-1.6689e+00,  1.5859e+00, -4.2695e-01],\n",
            "        [-1.4788e+00,  1.7266e+00, -4.0582e-01],\n",
            "        [-1.6315e+00,  1.4851e+00, -3.8174e-01],\n",
            "        [-1.5016e+00,  1.6218e+00, -3.4059e-01],\n",
            "        [-1.4255e+00,  1.6768e+00, -5.1570e-01],\n",
            "        [-1.8396e+00,  3.8387e-01,  1.1448e+00],\n",
            "        [-1.7415e+00,  1.6755e+00, -1.9321e-01],\n",
            "        [ 5.4820e-01, -4.0627e-02, -8.8969e-01],\n",
            "        [-1.4588e+00,  1.4441e+00, -2.9387e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6953,  1.8920, -0.4259],\n",
            "        [-1.4533,  1.7722, -0.4142],\n",
            "        [-1.7499,  1.7883, -0.4980],\n",
            "        [-1.4835,  0.0660,  1.0829],\n",
            "        [ 0.5630, -0.1048, -0.7709],\n",
            "        [-1.5452,  1.7493, -0.4105],\n",
            "        [-1.6663,  1.7336, -0.4515],\n",
            "        [-1.5794,  1.8579, -0.3817],\n",
            "        [-1.3845,  1.7216, -0.4340],\n",
            "        [ 0.3099,  0.1681, -1.0443],\n",
            "        [-1.6469,  1.6218, -0.3514],\n",
            "        [-1.7606,  1.6124, -0.2806],\n",
            "        [-0.7799,  0.9443, -0.8486],\n",
            "        [-1.8120,  1.7828, -0.3449],\n",
            "        [-1.7133,  1.5876, -0.0810],\n",
            "        [-0.7493, -0.0677,  0.5938]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6953,  1.8920, -0.4259],\n",
            "        [-1.4533,  1.7722, -0.4142],\n",
            "        [-1.7499,  1.7883, -0.4980],\n",
            "        [-1.4835,  0.0660,  1.0829],\n",
            "        [ 0.5630, -0.1048, -0.7709],\n",
            "        [-1.5452,  1.7493, -0.4105],\n",
            "        [-1.6663,  1.7336, -0.4515],\n",
            "        [-1.5794,  1.8579, -0.3817],\n",
            "        [-1.3845,  1.7216, -0.4340],\n",
            "        [ 0.3099,  0.1681, -1.0443],\n",
            "        [-1.6469,  1.6218, -0.3514],\n",
            "        [-1.7606,  1.6124, -0.2806],\n",
            "        [-0.7799,  0.9443, -0.8486],\n",
            "        [-1.8120,  1.7828, -0.3449],\n",
            "        [-1.7133,  1.5876, -0.0810],\n",
            "        [-0.7493, -0.0677,  0.5938]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.4721,  0.1276, -0.8382],\n",
            "        [-1.4529,  1.6115, -0.1851],\n",
            "        [-1.5012,  1.7224, -0.5894],\n",
            "        [-1.2996,  1.8990, -0.3971],\n",
            "        [ 0.2181, -0.0068, -0.7127],\n",
            "        [ 0.0767,  0.2336, -0.8980],\n",
            "        [-1.5307,  1.5611, -0.3463],\n",
            "        [-2.1414,  0.7476,  0.8473],\n",
            "        [-1.6779,  1.6758, -0.3862],\n",
            "        [ 0.2622, -0.2009, -0.7386],\n",
            "        [-1.5756,  1.8671, -0.5914],\n",
            "        [-1.4145,  1.6379, -0.5124],\n",
            "        [-1.4690,  0.1497,  1.0522],\n",
            "        [-1.6420,  1.6490, -0.3904],\n",
            "        [-1.5974,  1.6113, -0.4980],\n",
            "        [-1.8561,  0.0576,  1.1985]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.4721,  0.1276, -0.8382],\n",
            "        [-1.4529,  1.6115, -0.1851],\n",
            "        [-1.5012,  1.7224, -0.5894],\n",
            "        [-1.2996,  1.8990, -0.3971],\n",
            "        [ 0.2181, -0.0068, -0.7127],\n",
            "        [ 0.0767,  0.2336, -0.8980],\n",
            "        [-1.5307,  1.5611, -0.3463],\n",
            "        [-2.1414,  0.7476,  0.8473],\n",
            "        [-1.6779,  1.6758, -0.3862],\n",
            "        [ 0.2622, -0.2009, -0.7386],\n",
            "        [-1.5756,  1.8671, -0.5914],\n",
            "        [-1.4145,  1.6379, -0.5124],\n",
            "        [-1.4690,  0.1497,  1.0522],\n",
            "        [-1.6420,  1.6490, -0.3904],\n",
            "        [-1.5974,  1.6113, -0.4980],\n",
            "        [-1.8561,  0.0576,  1.1985]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5794,  1.6810, -0.3233],\n",
            "        [ 0.3810, -0.1794, -0.6938],\n",
            "        [-1.4327,  1.5899, -0.3728],\n",
            "        [ 0.4582, -0.2325, -0.7279],\n",
            "        [-1.7327,  0.4541,  1.1682],\n",
            "        [-1.8983,  0.6069,  1.0741],\n",
            "        [-1.7980,  0.1362,  1.4413],\n",
            "        [-1.5994,  1.7452, -0.4484],\n",
            "        [-1.7316,  0.2580,  1.1256],\n",
            "        [-1.6609,  1.5144,  0.0909],\n",
            "        [-2.0141,  1.2434,  0.7509],\n",
            "        [-1.6300,  1.6804, -0.4324],\n",
            "        [-1.7052,  1.7042, -0.3360],\n",
            "        [-1.7668,  0.7568,  0.8010],\n",
            "        [-1.8151,  1.4513, -0.3588],\n",
            "        [-1.6510,  0.1665,  1.0742]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5794,  1.6810, -0.3233],\n",
            "        [ 0.3810, -0.1794, -0.6938],\n",
            "        [-1.4327,  1.5899, -0.3728],\n",
            "        [ 0.4582, -0.2325, -0.7279],\n",
            "        [-1.7327,  0.4541,  1.1682],\n",
            "        [-1.8983,  0.6069,  1.0741],\n",
            "        [-1.7980,  0.1362,  1.4413],\n",
            "        [-1.5994,  1.7452, -0.4484],\n",
            "        [-1.7316,  0.2580,  1.1256],\n",
            "        [-1.6609,  1.5144,  0.0909],\n",
            "        [-2.0141,  1.2434,  0.7509],\n",
            "        [-1.6300,  1.6804, -0.4324],\n",
            "        [-1.7052,  1.7042, -0.3360],\n",
            "        [-1.7668,  0.7568,  0.8010],\n",
            "        [-1.8151,  1.4513, -0.3588],\n",
            "        [-1.6510,  0.1665,  1.0742]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5381,  1.7228, -0.4822],\n",
            "        [-1.6873,  1.7568, -0.1877],\n",
            "        [-1.6621,  1.2593,  0.2037],\n",
            "        [-1.4852,  1.4199, -0.4267],\n",
            "        [-1.8975,  0.2334,  1.0418],\n",
            "        [-1.4643,  1.3040, -0.1408],\n",
            "        [-1.7027,  0.1869,  1.2871],\n",
            "        [-1.5427,  0.0513,  1.2705],\n",
            "        [-1.3145,  1.5057, -0.5235],\n",
            "        [-1.5429,  0.1111,  1.1660],\n",
            "        [ 0.0469,  0.3790, -1.0454],\n",
            "        [-1.7450,  0.9871,  0.7026],\n",
            "        [-1.3882,  1.7385, -0.2750],\n",
            "        [-1.2901,  1.5691, -0.5973],\n",
            "        [-1.5397,  1.4345, -0.4842],\n",
            "        [-1.5359,  1.3923, -0.0045]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5381,  1.7228, -0.4822],\n",
            "        [-1.6873,  1.7568, -0.1877],\n",
            "        [-1.6621,  1.2593,  0.2037],\n",
            "        [-1.4852,  1.4199, -0.4267],\n",
            "        [-1.8975,  0.2334,  1.0418],\n",
            "        [-1.4643,  1.3040, -0.1408],\n",
            "        [-1.7027,  0.1869,  1.2871],\n",
            "        [-1.5427,  0.0513,  1.2705],\n",
            "        [-1.3145,  1.5057, -0.5235],\n",
            "        [-1.5429,  0.1111,  1.1660],\n",
            "        [ 0.0469,  0.3790, -1.0454],\n",
            "        [-1.7450,  0.9871,  0.7026],\n",
            "        [-1.3882,  1.7385, -0.2750],\n",
            "        [-1.2901,  1.5691, -0.5973],\n",
            "        [-1.5397,  1.4345, -0.4842],\n",
            "        [-1.5359,  1.3923, -0.0045]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5312,  1.7170, -0.1548],\n",
            "        [-1.9396,  0.5305,  0.8623],\n",
            "        [ 0.3603, -0.1292, -0.7219],\n",
            "        [-1.2148,  1.4118, -0.5409],\n",
            "        [-1.5141,  1.6232, -0.5005],\n",
            "        [-1.7339,  0.1736,  1.2063],\n",
            "        [-1.4534,  1.7937, -0.4791],\n",
            "        [-1.6277,  0.1695,  1.2463],\n",
            "        [-1.3947,  1.5770, -0.1186],\n",
            "        [ 0.4226, -0.1449, -0.7634],\n",
            "        [-1.6067, -0.0422,  1.1601],\n",
            "        [-1.5756,  0.2184,  1.0112],\n",
            "        [ 0.4704, -0.0735, -0.7244],\n",
            "        [-1.3834,  1.7831, -0.7523],\n",
            "        [-1.7232,  0.1332,  1.0053],\n",
            "        [-0.7622,  1.3085, -0.8759]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5312,  1.7170, -0.1548],\n",
            "        [-1.9396,  0.5305,  0.8623],\n",
            "        [ 0.3603, -0.1292, -0.7219],\n",
            "        [-1.2148,  1.4118, -0.5409],\n",
            "        [-1.5141,  1.6232, -0.5005],\n",
            "        [-1.7339,  0.1736,  1.2063],\n",
            "        [-1.4534,  1.7937, -0.4791],\n",
            "        [-1.6277,  0.1695,  1.2463],\n",
            "        [-1.3947,  1.5770, -0.1186],\n",
            "        [ 0.4226, -0.1449, -0.7634],\n",
            "        [-1.6067, -0.0422,  1.1601],\n",
            "        [-1.5756,  0.2184,  1.0112],\n",
            "        [ 0.4704, -0.0735, -0.7244],\n",
            "        [-1.3834,  1.7831, -0.7523],\n",
            "        [-1.7232,  0.1332,  1.0053],\n",
            "        [-0.7622,  1.3085, -0.8759]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.4178, -0.1710, -1.0664],\n",
            "        [-1.3989,  1.6262, -0.3893],\n",
            "        [-1.5068,  1.7341, -0.2868],\n",
            "        [-1.3640,  1.7260, -0.5554],\n",
            "        [-1.2924,  1.6705, -0.3325],\n",
            "        [-1.3260,  1.5570, -0.6110],\n",
            "        [-1.6167,  0.1437,  1.2279],\n",
            "        [-1.4900,  1.8668, -0.5665],\n",
            "        [-1.8934,  0.6248,  1.0926],\n",
            "        [ 0.0142, -0.0102, -0.5331],\n",
            "        [-1.5189,  1.6871, -0.6186],\n",
            "        [-1.5946,  0.1982,  1.1882],\n",
            "        [-1.4334,  1.7369, -0.3976],\n",
            "        [-1.5294,  1.6007, -0.2180],\n",
            "        [-1.3360,  1.7872, -0.6026],\n",
            "        [-1.6888,  0.2153,  1.2308]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.4178, -0.1710, -1.0664],\n",
            "        [-1.3989,  1.6262, -0.3893],\n",
            "        [-1.5068,  1.7341, -0.2868],\n",
            "        [-1.3640,  1.7260, -0.5554],\n",
            "        [-1.2924,  1.6705, -0.3325],\n",
            "        [-1.3260,  1.5570, -0.6110],\n",
            "        [-1.6167,  0.1437,  1.2279],\n",
            "        [-1.4900,  1.8668, -0.5665],\n",
            "        [-1.8934,  0.6248,  1.0926],\n",
            "        [ 0.0142, -0.0102, -0.5331],\n",
            "        [-1.5189,  1.6871, -0.6186],\n",
            "        [-1.5946,  0.1982,  1.1882],\n",
            "        [-1.4334,  1.7369, -0.3976],\n",
            "        [-1.5294,  1.6007, -0.2180],\n",
            "        [-1.3360,  1.7872, -0.6026],\n",
            "        [-1.6888,  0.2153,  1.2308]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3298,  1.5978, -0.1921],\n",
            "        [-1.8261,  0.2846,  1.1475],\n",
            "        [-1.6514,  1.5635, -0.3438],\n",
            "        [-1.6408,  1.4882, -0.2020],\n",
            "        [-1.5008,  0.1774,  1.2155],\n",
            "        [-1.5774,  1.6462, -0.2548],\n",
            "        [-1.4171,  1.2803, -0.4437],\n",
            "        [-1.8228,  0.0830,  1.3317],\n",
            "        [-1.5905,  1.6761, -0.5068],\n",
            "        [-1.4499,  1.6910, -0.4277],\n",
            "        [-1.8984,  0.6588,  1.3080],\n",
            "        [-1.6151,  1.1575,  0.4371],\n",
            "        [-1.4914,  1.5968, -0.5819],\n",
            "        [-1.8494,  0.8672,  0.7874],\n",
            "        [-1.8742,  1.6990, -0.0262],\n",
            "        [-1.4641,  1.6538, -0.5240]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3298,  1.5978, -0.1921],\n",
            "        [-1.8261,  0.2846,  1.1475],\n",
            "        [-1.6514,  1.5635, -0.3438],\n",
            "        [-1.6408,  1.4882, -0.2020],\n",
            "        [-1.5008,  0.1774,  1.2155],\n",
            "        [-1.5774,  1.6462, -0.2548],\n",
            "        [-1.4171,  1.2803, -0.4437],\n",
            "        [-1.8228,  0.0830,  1.3317],\n",
            "        [-1.5905,  1.6761, -0.5068],\n",
            "        [-1.4499,  1.6910, -0.4277],\n",
            "        [-1.8984,  0.6588,  1.3080],\n",
            "        [-1.6151,  1.1575,  0.4371],\n",
            "        [-1.4914,  1.5968, -0.5819],\n",
            "        [-1.8494,  0.8672,  0.7874],\n",
            "        [-1.8742,  1.6990, -0.0262],\n",
            "        [-1.4641,  1.6538, -0.5240]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6738,  0.2392,  1.2251],\n",
            "        [-1.6771,  0.1029,  1.3065],\n",
            "        [-1.6804,  1.6331, -0.0503],\n",
            "        [-1.6038,  0.1920,  1.2252],\n",
            "        [-1.4835,  1.3764, -0.0554],\n",
            "        [-1.7759,  0.1181,  1.2266],\n",
            "        [-1.7414,  0.1494,  1.2517],\n",
            "        [-1.4158,  1.9068, -0.6375],\n",
            "        [-1.4175,  1.8077, -0.5498],\n",
            "        [-1.5089,  1.4605, -0.2153],\n",
            "        [-1.6409,  1.8381, -0.5597],\n",
            "        [-1.3526,  1.4434, -0.4782],\n",
            "        [-1.4337,  1.6182, -0.5561],\n",
            "        [-0.4311,  0.7247, -0.6739],\n",
            "        [-1.4387,  1.8337, -0.4639],\n",
            "        [-1.8037,  0.0960,  1.2812]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6738,  0.2392,  1.2251],\n",
            "        [-1.6771,  0.1029,  1.3065],\n",
            "        [-1.6804,  1.6331, -0.0503],\n",
            "        [-1.6038,  0.1920,  1.2252],\n",
            "        [-1.4835,  1.3764, -0.0554],\n",
            "        [-1.7759,  0.1181,  1.2266],\n",
            "        [-1.7414,  0.1494,  1.2517],\n",
            "        [-1.4158,  1.9068, -0.6375],\n",
            "        [-1.4175,  1.8077, -0.5498],\n",
            "        [-1.5089,  1.4605, -0.2153],\n",
            "        [-1.6409,  1.8381, -0.5597],\n",
            "        [-1.3526,  1.4434, -0.4782],\n",
            "        [-1.4337,  1.6182, -0.5561],\n",
            "        [-0.4311,  0.7247, -0.6739],\n",
            "        [-1.4387,  1.8337, -0.4639],\n",
            "        [-1.8037,  0.0960,  1.2812]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8400,  0.0769,  1.2547],\n",
            "        [ 0.0511, -0.0228, -0.6657],\n",
            "        [-1.6437,  0.0531,  1.2605],\n",
            "        [ 0.3705, -0.1048, -0.9349],\n",
            "        [-1.6096,  1.6589, -0.2488],\n",
            "        [ 0.6033, -0.1777, -0.6988],\n",
            "        [-1.5096,  1.4525, -0.6269],\n",
            "        [-1.4353,  1.4535, -0.7636],\n",
            "        [-1.9481,  0.6169,  0.8668],\n",
            "        [-1.6410,  1.8252, -0.2979],\n",
            "        [-1.1274,  1.5838, -0.5364],\n",
            "        [-1.8573,  0.0659,  1.2486],\n",
            "        [-1.6615,  0.2996,  1.1626],\n",
            "        [-1.3707,  1.5800, -0.4402],\n",
            "        [-1.5722,  1.6132, -0.6034],\n",
            "        [-1.6244,  0.7232,  0.8164]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8400,  0.0769,  1.2547],\n",
            "        [ 0.0511, -0.0228, -0.6657],\n",
            "        [-1.6437,  0.0531,  1.2605],\n",
            "        [ 0.3705, -0.1048, -0.9349],\n",
            "        [-1.6096,  1.6589, -0.2488],\n",
            "        [ 0.6033, -0.1777, -0.6988],\n",
            "        [-1.5096,  1.4525, -0.6269],\n",
            "        [-1.4353,  1.4535, -0.7636],\n",
            "        [-1.9481,  0.6169,  0.8668],\n",
            "        [-1.6410,  1.8252, -0.2979],\n",
            "        [-1.1274,  1.5838, -0.5364],\n",
            "        [-1.8573,  0.0659,  1.2486],\n",
            "        [-1.6615,  0.2996,  1.1626],\n",
            "        [-1.3707,  1.5800, -0.4402],\n",
            "        [-1.5722,  1.6132, -0.6034],\n",
            "        [-1.6244,  0.7232,  0.8164]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4191,  1.6609, -0.5062],\n",
            "        [-1.2536,  1.6262, -0.4874],\n",
            "        [-1.1999,  1.4573, -0.7451],\n",
            "        [-1.8088,  0.9374,  0.6546],\n",
            "        [ 0.6166, -0.3138, -0.8455],\n",
            "        [-1.5433,  1.2691, -0.1153],\n",
            "        [-1.1926,  1.6602, -0.6942],\n",
            "        [-1.4067,  1.6395, -0.3469],\n",
            "        [ 0.4601, -0.0308, -0.7116],\n",
            "        [-1.2651,  1.5365, -0.6004],\n",
            "        [-1.2973,  1.5399, -0.4974],\n",
            "        [-1.5855,  1.7331, -0.2400],\n",
            "        [-1.6876,  0.1725,  1.1123],\n",
            "        [-1.8462,  0.1967,  1.3906],\n",
            "        [-1.3921,  1.7028, -0.1323],\n",
            "        [-1.8851,  1.0887,  0.2849]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4191,  1.6609, -0.5062],\n",
            "        [-1.2536,  1.6262, -0.4874],\n",
            "        [-1.1999,  1.4573, -0.7451],\n",
            "        [-1.8088,  0.9374,  0.6546],\n",
            "        [ 0.6166, -0.3138, -0.8455],\n",
            "        [-1.5433,  1.2691, -0.1153],\n",
            "        [-1.1926,  1.6602, -0.6942],\n",
            "        [-1.4067,  1.6395, -0.3469],\n",
            "        [ 0.4601, -0.0308, -0.7116],\n",
            "        [-1.2651,  1.5365, -0.6004],\n",
            "        [-1.2973,  1.5399, -0.4974],\n",
            "        [-1.5855,  1.7331, -0.2400],\n",
            "        [-1.6876,  0.1725,  1.1123],\n",
            "        [-1.8462,  0.1967,  1.3906],\n",
            "        [-1.3921,  1.7028, -0.1323],\n",
            "        [-1.8851,  1.0887,  0.2849]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8371,  0.3359,  1.0338],\n",
            "        [-1.4796,  1.8816, -0.4293],\n",
            "        [-1.4242,  1.8201, -0.4117],\n",
            "        [-1.7142,  1.4126,  0.0363],\n",
            "        [-1.3444,  1.6355, -0.6277],\n",
            "        [-1.8075,  1.2582,  0.3924],\n",
            "        [-0.7791,  0.0202,  0.4171],\n",
            "        [-1.8671,  0.3574,  1.4555],\n",
            "        [-1.3594,  1.2501, -0.5473],\n",
            "        [-1.3784,  1.2572, -0.1191],\n",
            "        [-1.3758,  1.8471, -0.6770],\n",
            "        [ 0.0252,  0.5221, -0.9414],\n",
            "        [-1.5312,  1.7072, -0.5170],\n",
            "        [ 0.4011, -0.2162, -0.6183],\n",
            "        [-1.9207,  0.2000,  1.3643],\n",
            "        [-1.4355,  1.4992, -0.2371]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8371,  0.3359,  1.0338],\n",
            "        [-1.4796,  1.8816, -0.4293],\n",
            "        [-1.4242,  1.8201, -0.4117],\n",
            "        [-1.7142,  1.4126,  0.0363],\n",
            "        [-1.3444,  1.6355, -0.6277],\n",
            "        [-1.8075,  1.2582,  0.3924],\n",
            "        [-0.7791,  0.0202,  0.4171],\n",
            "        [-1.8671,  0.3574,  1.4555],\n",
            "        [-1.3594,  1.2501, -0.5473],\n",
            "        [-1.3784,  1.2572, -0.1191],\n",
            "        [-1.3758,  1.8471, -0.6770],\n",
            "        [ 0.0252,  0.5221, -0.9414],\n",
            "        [-1.5312,  1.7072, -0.5170],\n",
            "        [ 0.4011, -0.2162, -0.6183],\n",
            "        [-1.9207,  0.2000,  1.3643],\n",
            "        [-1.4355,  1.4992, -0.2371]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8404,  0.3204,  1.3645],\n",
            "        [-1.3059,  1.5057, -0.3883],\n",
            "        [-1.4457,  1.7223, -0.5413],\n",
            "        [-1.6829,  0.0573,  1.3040],\n",
            "        [-1.7112,  0.2797,  1.1320],\n",
            "        [-1.8404,  0.1541,  1.4735],\n",
            "        [-1.3918,  1.5009, -0.1126],\n",
            "        [-1.8615,  0.7055,  0.6772],\n",
            "        [-1.2977,  1.4530, -0.7110],\n",
            "        [-1.3680,  1.7558, -0.4445],\n",
            "        [-1.8647,  0.3482,  1.3808],\n",
            "        [-1.8317,  0.2588,  1.3462],\n",
            "        [-1.1226,  1.3740, -0.6960],\n",
            "        [-0.7805,  0.9506, -0.6109],\n",
            "        [-1.7630, -0.1149,  1.4570],\n",
            "        [-1.4114,  1.6287, -0.3364]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8404,  0.3204,  1.3645],\n",
            "        [-1.3059,  1.5057, -0.3883],\n",
            "        [-1.4457,  1.7223, -0.5413],\n",
            "        [-1.6829,  0.0573,  1.3040],\n",
            "        [-1.7112,  0.2797,  1.1320],\n",
            "        [-1.8404,  0.1541,  1.4735],\n",
            "        [-1.3918,  1.5009, -0.1126],\n",
            "        [-1.8615,  0.7055,  0.6772],\n",
            "        [-1.2977,  1.4530, -0.7110],\n",
            "        [-1.3680,  1.7558, -0.4445],\n",
            "        [-1.8647,  0.3482,  1.3808],\n",
            "        [-1.8317,  0.2588,  1.3462],\n",
            "        [-1.1226,  1.3740, -0.6960],\n",
            "        [-0.7805,  0.9506, -0.6109],\n",
            "        [-1.7630, -0.1149,  1.4570],\n",
            "        [-1.4114,  1.6287, -0.3364]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0052,  0.7741,  0.8835],\n",
            "        [-1.7759,  0.8081,  0.8445],\n",
            "        [-1.3123,  1.5222, -0.5733],\n",
            "        [-1.7149,  0.0201,  1.3711],\n",
            "        [-1.7918,  0.8067,  0.8659],\n",
            "        [-1.9732,  0.1674,  1.3942],\n",
            "        [-0.0300, -0.0954, -0.1516],\n",
            "        [-1.9674,  0.8308,  0.5673],\n",
            "        [-1.5720,  1.4257, -0.0532],\n",
            "        [-1.6120,  1.5640, -0.3980],\n",
            "        [ 0.6908, -0.1350, -0.8179],\n",
            "        [-1.9681,  0.4830,  1.3712],\n",
            "        [-1.9398,  0.1324,  1.3509],\n",
            "        [-1.2689,  1.6483, -0.4429],\n",
            "        [-0.2184,  0.6676, -0.9272],\n",
            "        [ 0.3528, -0.2344, -0.6018]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0052,  0.7741,  0.8835],\n",
            "        [-1.7759,  0.8081,  0.8445],\n",
            "        [-1.3123,  1.5222, -0.5733],\n",
            "        [-1.7149,  0.0201,  1.3711],\n",
            "        [-1.7918,  0.8067,  0.8659],\n",
            "        [-1.9732,  0.1674,  1.3942],\n",
            "        [-0.0300, -0.0954, -0.1516],\n",
            "        [-1.9674,  0.8308,  0.5673],\n",
            "        [-1.5720,  1.4257, -0.0532],\n",
            "        [-1.6120,  1.5640, -0.3980],\n",
            "        [ 0.6908, -0.1350, -0.8179],\n",
            "        [-1.9681,  0.4830,  1.3712],\n",
            "        [-1.9398,  0.1324,  1.3509],\n",
            "        [-1.2689,  1.6483, -0.4429],\n",
            "        [-0.2184,  0.6676, -0.9272],\n",
            "        [ 0.3528, -0.2344, -0.6018]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2741,  1.8129, -0.3945],\n",
            "        [-1.1854,  1.5820, -0.3347],\n",
            "        [-2.0528,  0.1078,  1.5043],\n",
            "        [-1.1232,  1.6509, -0.7493],\n",
            "        [-1.9995,  0.0389,  1.4796],\n",
            "        [-1.6688,  0.5826,  0.9632],\n",
            "        [-1.4888,  1.8353, -0.5932],\n",
            "        [-1.3406,  1.6521, -0.6183],\n",
            "        [-1.1938,  1.4846, -0.5984],\n",
            "        [ 0.4815, -0.3056, -0.9037],\n",
            "        [-1.3246,  1.6454, -0.4175],\n",
            "        [-1.2725,  1.5154, -0.7270],\n",
            "        [-1.4786,  1.7952, -0.6567],\n",
            "        [-1.6580,  1.4434,  0.1524],\n",
            "        [-1.3315,  1.6882, -0.5829],\n",
            "        [-1.2108,  1.4866, -0.5945]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2741,  1.8129, -0.3945],\n",
            "        [-1.1854,  1.5820, -0.3347],\n",
            "        [-2.0528,  0.1078,  1.5043],\n",
            "        [-1.1232,  1.6509, -0.7493],\n",
            "        [-1.9995,  0.0389,  1.4796],\n",
            "        [-1.6688,  0.5826,  0.9632],\n",
            "        [-1.4888,  1.8353, -0.5932],\n",
            "        [-1.3406,  1.6521, -0.6183],\n",
            "        [-1.1938,  1.4846, -0.5984],\n",
            "        [ 0.4815, -0.3056, -0.9037],\n",
            "        [-1.3246,  1.6454, -0.4175],\n",
            "        [-1.2725,  1.5154, -0.7270],\n",
            "        [-1.4786,  1.7952, -0.6567],\n",
            "        [-1.6580,  1.4434,  0.1524],\n",
            "        [-1.3315,  1.6882, -0.5829],\n",
            "        [-1.2108,  1.4866, -0.5945]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2363,  1.5890, -0.4830],\n",
            "        [-1.2594,  1.7776, -0.3476],\n",
            "        [ 0.3630, -0.0859, -0.8690],\n",
            "        [-1.3373,  1.6390, -0.4982],\n",
            "        [-1.7754,  0.2505,  1.3710],\n",
            "        [-0.7805,  0.8397, -0.6401],\n",
            "        [-1.6397,  0.6101,  0.8659],\n",
            "        [-1.5731,  1.6586, -0.3373],\n",
            "        [-1.9265,  0.1411,  1.5105],\n",
            "        [ 0.5677, -0.3094, -0.8294],\n",
            "        [ 0.4691, -0.2033, -0.8759],\n",
            "        [-1.7470,  1.0144,  0.4243],\n",
            "        [ 0.3404, -0.3407, -0.6136],\n",
            "        [-1.3279,  1.6272, -0.4702],\n",
            "        [-1.8867,  0.1956,  1.3348],\n",
            "        [-1.1293,  1.3342, -0.5047]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2363,  1.5890, -0.4830],\n",
            "        [-1.2594,  1.7776, -0.3476],\n",
            "        [ 0.3630, -0.0859, -0.8690],\n",
            "        [-1.3373,  1.6390, -0.4982],\n",
            "        [-1.7754,  0.2505,  1.3710],\n",
            "        [-0.7805,  0.8397, -0.6401],\n",
            "        [-1.6397,  0.6101,  0.8659],\n",
            "        [-1.5731,  1.6586, -0.3373],\n",
            "        [-1.9265,  0.1411,  1.5105],\n",
            "        [ 0.5677, -0.3094, -0.8294],\n",
            "        [ 0.4691, -0.2033, -0.8759],\n",
            "        [-1.7470,  1.0144,  0.4243],\n",
            "        [ 0.3404, -0.3407, -0.6136],\n",
            "        [-1.3279,  1.6272, -0.4702],\n",
            "        [-1.8867,  0.1956,  1.3348],\n",
            "        [-1.1293,  1.3342, -0.5047]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3752,  1.9096, -0.6552],\n",
            "        [-1.2988,  1.7059, -0.6655],\n",
            "        [-2.0420,  0.1111,  1.4700],\n",
            "        [ 0.6601, -0.2273, -0.8923],\n",
            "        [-1.1410,  1.2030, -0.4821],\n",
            "        [-1.2423,  1.0611, -0.3329],\n",
            "        [-1.3204,  1.6454, -0.4420],\n",
            "        [-1.4738,  1.8673, -0.7113],\n",
            "        [-1.7641,  1.2907,  0.1833],\n",
            "        [-1.5202,  1.6689, -0.7497],\n",
            "        [ 0.2895, -0.2077, -0.7456],\n",
            "        [-1.2729,  1.7545, -0.7879],\n",
            "        [-1.9832,  0.8513,  1.0038],\n",
            "        [ 0.0261, -0.2102, -0.3151],\n",
            "        [-1.1886,  1.6218, -0.6958],\n",
            "        [-1.9754,  0.4544,  1.2801]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3752,  1.9096, -0.6552],\n",
            "        [-1.2988,  1.7059, -0.6655],\n",
            "        [-2.0420,  0.1111,  1.4700],\n",
            "        [ 0.6601, -0.2273, -0.8923],\n",
            "        [-1.1410,  1.2030, -0.4821],\n",
            "        [-1.2423,  1.0611, -0.3329],\n",
            "        [-1.3204,  1.6454, -0.4420],\n",
            "        [-1.4738,  1.8673, -0.7113],\n",
            "        [-1.7641,  1.2907,  0.1833],\n",
            "        [-1.5202,  1.6689, -0.7497],\n",
            "        [ 0.2895, -0.2077, -0.7456],\n",
            "        [-1.2729,  1.7545, -0.7879],\n",
            "        [-1.9832,  0.8513,  1.0038],\n",
            "        [ 0.0261, -0.2102, -0.3151],\n",
            "        [-1.1886,  1.6218, -0.6958],\n",
            "        [-1.9754,  0.4544,  1.2801]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8803,  0.8695,  0.8729],\n",
            "        [-2.0663,  0.1413,  1.6616],\n",
            "        [-1.1736,  1.7094, -0.7029],\n",
            "        [ 0.5438, -0.2780, -0.7520],\n",
            "        [-1.9700,  0.6045,  0.8962],\n",
            "        [-1.8412,  0.1438,  1.2979],\n",
            "        [-1.1802,  1.5904, -0.1980],\n",
            "        [-1.2830,  1.6283, -0.7419],\n",
            "        [-1.0725,  1.4442, -0.7880],\n",
            "        [-1.2947,  1.6099, -0.7612],\n",
            "        [-0.4886, -0.0711,  0.4730],\n",
            "        [-1.2174,  1.5789, -0.7488],\n",
            "        [-1.9055,  0.2009,  1.4346],\n",
            "        [ 0.0399,  0.4033, -1.0332],\n",
            "        [ 0.5689, -0.1632, -0.7281],\n",
            "        [-1.3239,  1.7698, -0.8400]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8803,  0.8695,  0.8729],\n",
            "        [-2.0663,  0.1413,  1.6616],\n",
            "        [-1.1736,  1.7094, -0.7029],\n",
            "        [ 0.5438, -0.2780, -0.7520],\n",
            "        [-1.9700,  0.6045,  0.8962],\n",
            "        [-1.8412,  0.1438,  1.2979],\n",
            "        [-1.1802,  1.5904, -0.1980],\n",
            "        [-1.2830,  1.6283, -0.7419],\n",
            "        [-1.0725,  1.4442, -0.7880],\n",
            "        [-1.2947,  1.6099, -0.7612],\n",
            "        [-0.4886, -0.0711,  0.4730],\n",
            "        [-1.2174,  1.5789, -0.7488],\n",
            "        [-1.9055,  0.2009,  1.4346],\n",
            "        [ 0.0399,  0.4033, -1.0332],\n",
            "        [ 0.5689, -0.1632, -0.7281],\n",
            "        [-1.3239,  1.7698, -0.8400]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.3042e+00,  3.8154e-02,  1.4723e+00],\n",
            "        [-1.3766e+00,  1.6980e+00, -5.0230e-01],\n",
            "        [-1.4006e+00,  1.4478e+00, -3.7470e-01],\n",
            "        [-1.5776e+00,  4.9251e-02,  1.2136e+00],\n",
            "        [-1.8201e+00,  1.9408e-01,  1.4369e+00],\n",
            "        [ 4.2648e-01,  1.9317e-01, -9.5834e-01],\n",
            "        [-1.2188e+00,  1.4496e+00, -6.1818e-01],\n",
            "        [-1.0883e+00,  1.8338e+00, -8.2992e-01],\n",
            "        [-1.0607e+00,  1.6011e+00, -8.5876e-01],\n",
            "        [-1.6975e+00,  1.5476e+00, -7.6429e-02],\n",
            "        [-1.1090e+00,  1.4891e+00, -4.5939e-01],\n",
            "        [-1.0054e+00,  1.3985e+00, -9.1941e-01],\n",
            "        [ 4.0699e-01,  2.5526e-03, -1.0234e+00],\n",
            "        [-1.0878e+00,  1.7974e+00, -7.2944e-01],\n",
            "        [-2.0271e+00, -1.8129e-03,  1.6829e+00],\n",
            "        [-1.7350e+00,  8.6226e-01,  8.4085e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.3042e+00,  3.8154e-02,  1.4723e+00],\n",
            "        [-1.3766e+00,  1.6980e+00, -5.0230e-01],\n",
            "        [-1.4006e+00,  1.4478e+00, -3.7470e-01],\n",
            "        [-1.5776e+00,  4.9251e-02,  1.2136e+00],\n",
            "        [-1.8201e+00,  1.9408e-01,  1.4369e+00],\n",
            "        [ 4.2648e-01,  1.9317e-01, -9.5834e-01],\n",
            "        [-1.2188e+00,  1.4496e+00, -6.1818e-01],\n",
            "        [-1.0883e+00,  1.8338e+00, -8.2992e-01],\n",
            "        [-1.0607e+00,  1.6011e+00, -8.5876e-01],\n",
            "        [-1.6975e+00,  1.5476e+00, -7.6429e-02],\n",
            "        [-1.1090e+00,  1.4891e+00, -4.5939e-01],\n",
            "        [-1.0054e+00,  1.3985e+00, -9.1941e-01],\n",
            "        [ 4.0699e-01,  2.5526e-03, -1.0234e+00],\n",
            "        [-1.0878e+00,  1.7974e+00, -7.2944e-01],\n",
            "        [-2.0271e+00, -1.8129e-03,  1.6829e+00],\n",
            "        [-1.7350e+00,  8.6226e-01,  8.4085e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9671,  0.0831,  1.2752],\n",
            "        [-0.7182, -0.1161,  0.5457],\n",
            "        [-1.3961,  1.3861, -0.2833],\n",
            "        [ 0.6834, -0.1178, -0.7958],\n",
            "        [-1.2357,  1.6892, -0.5152],\n",
            "        [-1.8306,  0.1648,  1.4271],\n",
            "        [-1.9811,  0.0641,  1.4506],\n",
            "        [-1.1176,  1.6245, -0.5046],\n",
            "        [-2.1111,  0.5011,  1.4621],\n",
            "        [-1.1038,  1.3968, -0.6593],\n",
            "        [-1.8535,  0.9896,  0.2404],\n",
            "        [-1.2898,  1.8157, -0.7248],\n",
            "        [-1.9341,  0.0955,  1.4808],\n",
            "        [-1.3634,  1.8056, -0.6491],\n",
            "        [ 0.3751, -0.2073, -0.7555],\n",
            "        [-2.0060,  0.2108,  1.6685]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9671,  0.0831,  1.2752],\n",
            "        [-0.7182, -0.1161,  0.5457],\n",
            "        [-1.3961,  1.3861, -0.2833],\n",
            "        [ 0.6834, -0.1178, -0.7958],\n",
            "        [-1.2357,  1.6892, -0.5152],\n",
            "        [-1.8306,  0.1648,  1.4271],\n",
            "        [-1.9811,  0.0641,  1.4506],\n",
            "        [-1.1176,  1.6245, -0.5046],\n",
            "        [-2.1111,  0.5011,  1.4621],\n",
            "        [-1.1038,  1.3968, -0.6593],\n",
            "        [-1.8535,  0.9896,  0.2404],\n",
            "        [-1.2898,  1.8157, -0.7248],\n",
            "        [-1.9341,  0.0955,  1.4808],\n",
            "        [-1.3634,  1.8056, -0.6491],\n",
            "        [ 0.3751, -0.2073, -0.7555],\n",
            "        [-2.0060,  0.2108,  1.6685]], grad_fn=<AddmmBackward0>)\n",
            "Epoch 2/3, Loss: 0.6025\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4193,  1.7030, -0.6536],\n",
            "        [-2.1103,  0.2947,  1.4580],\n",
            "        [-1.4710,  1.7076, -0.6102],\n",
            "        [-1.2073,  1.7804, -0.8777],\n",
            "        [-1.5131,  1.7694, -0.4873],\n",
            "        [-0.9811,  0.0109,  0.3823],\n",
            "        [-1.3377,  1.6726, -0.5325],\n",
            "        [-1.3490,  1.4266, -0.5032],\n",
            "        [-1.5182,  1.6899, -0.6127],\n",
            "        [-1.1671,  1.6608, -0.9529],\n",
            "        [-0.9427,  1.4583, -0.8423],\n",
            "        [-2.0271,  0.2098,  1.5688],\n",
            "        [-1.1574,  1.5486, -0.5985],\n",
            "        [-1.7703,  0.3657,  1.3405],\n",
            "        [-1.9578,  0.7924,  1.1799],\n",
            "        [-1.2351,  1.7214, -0.6795]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4193,  1.7030, -0.6536],\n",
            "        [-2.1103,  0.2947,  1.4580],\n",
            "        [-1.4710,  1.7076, -0.6102],\n",
            "        [-1.2073,  1.7804, -0.8777],\n",
            "        [-1.5131,  1.7694, -0.4873],\n",
            "        [-0.9811,  0.0109,  0.3823],\n",
            "        [-1.3377,  1.6726, -0.5325],\n",
            "        [-1.3490,  1.4266, -0.5032],\n",
            "        [-1.5182,  1.6899, -0.6127],\n",
            "        [-1.1671,  1.6608, -0.9529],\n",
            "        [-0.9427,  1.4583, -0.8423],\n",
            "        [-2.0271,  0.2098,  1.5688],\n",
            "        [-1.1574,  1.5486, -0.5985],\n",
            "        [-1.7703,  0.3657,  1.3405],\n",
            "        [-1.9578,  0.7924,  1.1799],\n",
            "        [-1.2351,  1.7214, -0.6795]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3215, -0.1050, -0.7276],\n",
            "        [-1.5160,  1.6485, -0.4672],\n",
            "        [-0.9540,  1.8687, -0.9279],\n",
            "        [-1.3259,  1.7395, -0.6482],\n",
            "        [-1.8902,  0.3401,  1.1044],\n",
            "        [-1.9305,  0.3032,  1.1931],\n",
            "        [-2.1630,  0.1831,  1.3141],\n",
            "        [-1.2888,  1.9189, -1.0127],\n",
            "        [-1.6834,  1.2513,  0.0231],\n",
            "        [ 0.5552, -0.0612, -0.9427],\n",
            "        [-1.2663,  1.4467, -0.4704],\n",
            "        [-1.2656,  1.7309, -0.6110],\n",
            "        [-1.1962,  1.8669, -0.7640],\n",
            "        [-1.0402, -0.0901,  0.7562],\n",
            "        [-2.1294,  0.0579,  1.4900],\n",
            "        [-1.3212,  1.7280, -0.8597]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.3215, -0.1050, -0.7276],\n",
            "        [-1.5160,  1.6485, -0.4672],\n",
            "        [-0.9540,  1.8687, -0.9279],\n",
            "        [-1.3259,  1.7395, -0.6482],\n",
            "        [-1.8902,  0.3401,  1.1044],\n",
            "        [-1.9305,  0.3032,  1.1931],\n",
            "        [-2.1630,  0.1831,  1.3141],\n",
            "        [-1.2888,  1.9189, -1.0127],\n",
            "        [-1.6834,  1.2513,  0.0231],\n",
            "        [ 0.5552, -0.0612, -0.9427],\n",
            "        [-1.2663,  1.4467, -0.4704],\n",
            "        [-1.2656,  1.7309, -0.6110],\n",
            "        [-1.1962,  1.8669, -0.7640],\n",
            "        [-1.0402, -0.0901,  0.7562],\n",
            "        [-2.1294,  0.0579,  1.4900],\n",
            "        [-1.3212,  1.7280, -0.8597]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1420,  0.6529,  1.1286],\n",
            "        [-1.2963,  1.7953, -0.6443],\n",
            "        [-1.0458,  1.7629, -0.7777],\n",
            "        [-1.8383,  1.0094,  0.5796],\n",
            "        [-1.9792,  0.3698,  1.4376],\n",
            "        [-1.3293,  1.5248, -1.0041],\n",
            "        [-0.8927, -0.0396,  0.3517],\n",
            "        [-1.4158,  1.1723,  0.0664],\n",
            "        [ 0.5724, -0.2939, -0.8349],\n",
            "        [-2.0433,  0.5499,  1.4244],\n",
            "        [-1.0249,  1.6521, -0.7574],\n",
            "        [ 0.1162,  0.5346, -1.1294],\n",
            "        [-2.0568,  0.2867,  1.4502],\n",
            "        [-1.2270,  1.8765, -0.8393],\n",
            "        [-1.0278,  1.6500, -0.8996],\n",
            "        [-1.1958,  1.8031, -0.9843]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1420,  0.6529,  1.1286],\n",
            "        [-1.2963,  1.7953, -0.6443],\n",
            "        [-1.0458,  1.7629, -0.7777],\n",
            "        [-1.8383,  1.0094,  0.5796],\n",
            "        [-1.9792,  0.3698,  1.4376],\n",
            "        [-1.3293,  1.5248, -1.0041],\n",
            "        [-0.8927, -0.0396,  0.3517],\n",
            "        [-1.4158,  1.1723,  0.0664],\n",
            "        [ 0.5724, -0.2939, -0.8349],\n",
            "        [-2.0433,  0.5499,  1.4244],\n",
            "        [-1.0249,  1.6521, -0.7574],\n",
            "        [ 0.1162,  0.5346, -1.1294],\n",
            "        [-2.0568,  0.2867,  1.4502],\n",
            "        [-1.2270,  1.8765, -0.8393],\n",
            "        [-1.0278,  1.6500, -0.8996],\n",
            "        [-1.1958,  1.8031, -0.9843]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2858,  1.6692, -0.7251],\n",
            "        [-1.1690,  1.7031, -0.6376],\n",
            "        [-2.0482,  0.2066,  1.4962],\n",
            "        [-1.1821,  1.8519, -0.7978],\n",
            "        [-1.3911,  1.7470, -0.4273],\n",
            "        [-1.5696,  0.0825,  0.9101],\n",
            "        [-1.8945,  0.8104,  0.7467],\n",
            "        [-1.4592,  1.6309, -0.4525],\n",
            "        [-1.3435,  1.7631, -0.5904],\n",
            "        [-1.4505,  1.6917, -0.5725],\n",
            "        [-1.9390,  0.3007,  1.4243],\n",
            "        [-1.2595,  1.5524, -0.6703],\n",
            "        [-1.1367,  1.7296, -0.7673],\n",
            "        [-2.1466,  0.2510,  1.4693],\n",
            "        [ 0.7237, -0.3840, -0.7992],\n",
            "        [-1.2346,  1.4716, -0.8086]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2858,  1.6692, -0.7251],\n",
            "        [-1.1690,  1.7031, -0.6376],\n",
            "        [-2.0482,  0.2066,  1.4962],\n",
            "        [-1.1821,  1.8519, -0.7978],\n",
            "        [-1.3911,  1.7470, -0.4273],\n",
            "        [-1.5696,  0.0825,  0.9101],\n",
            "        [-1.8945,  0.8104,  0.7467],\n",
            "        [-1.4592,  1.6309, -0.4525],\n",
            "        [-1.3435,  1.7631, -0.5904],\n",
            "        [-1.4505,  1.6917, -0.5725],\n",
            "        [-1.9390,  0.3007,  1.4243],\n",
            "        [-1.2595,  1.5524, -0.6703],\n",
            "        [-1.1367,  1.7296, -0.7673],\n",
            "        [-2.1466,  0.2510,  1.4693],\n",
            "        [ 0.7237, -0.3840, -0.7992],\n",
            "        [-1.2346,  1.4716, -0.8086]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0333,  0.3777,  1.4873],\n",
            "        [-1.4523,  1.7751, -0.4240],\n",
            "        [-2.2066,  0.4378,  1.2802],\n",
            "        [-1.9870,  0.6007,  1.0013],\n",
            "        [-1.4423,  1.5531, -0.7264],\n",
            "        [-1.3140,  1.6514, -0.7911],\n",
            "        [-1.2970,  1.7902, -0.4408],\n",
            "        [-1.3006,  1.8157, -0.8323],\n",
            "        [-1.3864,  1.5924, -0.6956],\n",
            "        [-1.3294,  1.5297, -0.4421],\n",
            "        [-2.2106,  0.3760,  1.4325],\n",
            "        [-1.3282,  1.6083, -0.3460],\n",
            "        [-1.1282,  1.8306, -0.8594],\n",
            "        [-1.2310,  1.5429, -0.6563],\n",
            "        [-1.0923,  1.6308, -1.0819],\n",
            "        [-2.1352,  0.3980,  1.4441]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0333,  0.3777,  1.4873],\n",
            "        [-1.4523,  1.7751, -0.4240],\n",
            "        [-2.2066,  0.4378,  1.2802],\n",
            "        [-1.9870,  0.6007,  1.0013],\n",
            "        [-1.4423,  1.5531, -0.7264],\n",
            "        [-1.3140,  1.6514, -0.7911],\n",
            "        [-1.2970,  1.7902, -0.4408],\n",
            "        [-1.3006,  1.8157, -0.8323],\n",
            "        [-1.3864,  1.5924, -0.6956],\n",
            "        [-1.3294,  1.5297, -0.4421],\n",
            "        [-2.2106,  0.3760,  1.4325],\n",
            "        [-1.3282,  1.6083, -0.3460],\n",
            "        [-1.1282,  1.8306, -0.8594],\n",
            "        [-1.2310,  1.5429, -0.6563],\n",
            "        [-1.0923,  1.6308, -1.0819],\n",
            "        [-2.1352,  0.3980,  1.4441]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.6262, -0.3082, -0.8915],\n",
            "        [-1.1986,  1.7466, -1.0105],\n",
            "        [-1.4192,  1.7318, -0.7946],\n",
            "        [-1.9039,  1.0298,  0.7750],\n",
            "        [-1.1259,  1.6442, -0.8734],\n",
            "        [-2.0452,  0.3767,  1.5661],\n",
            "        [-1.9245,  1.1106,  0.5016],\n",
            "        [-1.8586,  0.5137,  1.0473],\n",
            "        [-2.0207,  0.5112,  1.4096],\n",
            "        [-2.0695,  0.3015,  1.5073],\n",
            "        [-1.8694,  0.2872,  1.2784],\n",
            "        [ 0.5435, -0.3213, -0.8238],\n",
            "        [-1.3609,  1.7283, -0.7257],\n",
            "        [-1.0696,  1.5190, -0.5513],\n",
            "        [-1.2768,  1.6888, -0.7544],\n",
            "        [-1.0964,  1.5243, -0.7460]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.6262, -0.3082, -0.8915],\n",
            "        [-1.1986,  1.7466, -1.0105],\n",
            "        [-1.4192,  1.7318, -0.7946],\n",
            "        [-1.9039,  1.0298,  0.7750],\n",
            "        [-1.1259,  1.6442, -0.8734],\n",
            "        [-2.0452,  0.3767,  1.5661],\n",
            "        [-1.9245,  1.1106,  0.5016],\n",
            "        [-1.8586,  0.5137,  1.0473],\n",
            "        [-2.0207,  0.5112,  1.4096],\n",
            "        [-2.0695,  0.3015,  1.5073],\n",
            "        [-1.8694,  0.2872,  1.2784],\n",
            "        [ 0.5435, -0.3213, -0.8238],\n",
            "        [-1.3609,  1.7283, -0.7257],\n",
            "        [-1.0696,  1.5190, -0.5513],\n",
            "        [-1.2768,  1.6888, -0.7544],\n",
            "        [-1.0964,  1.5243, -0.7460]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1373,  0.4479,  1.5177],\n",
            "        [-1.1484,  1.8409, -0.8009],\n",
            "        [-1.9507,  0.3418,  1.2717],\n",
            "        [-1.3158,  1.8213, -0.7974],\n",
            "        [ 0.6009, -0.1810, -0.6746],\n",
            "        [-1.8285,  0.4584,  1.3962],\n",
            "        [-1.9139,  0.4501,  1.0555],\n",
            "        [-2.0569,  0.3693,  1.3207],\n",
            "        [ 0.4380, -0.1808, -0.6895],\n",
            "        [-1.2788,  1.7255, -0.9043],\n",
            "        [ 0.7008, -0.3931, -0.8887],\n",
            "        [-1.5224,  1.7598, -0.1498],\n",
            "        [-1.3301,  1.8159, -0.9121],\n",
            "        [ 0.6954, -0.0645, -0.7215],\n",
            "        [-1.3147,  1.7558, -0.6399],\n",
            "        [-1.4028,  1.9153, -0.7932]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1373,  0.4479,  1.5177],\n",
            "        [-1.1484,  1.8409, -0.8009],\n",
            "        [-1.9507,  0.3418,  1.2717],\n",
            "        [-1.3158,  1.8213, -0.7974],\n",
            "        [ 0.6009, -0.1810, -0.6746],\n",
            "        [-1.8285,  0.4584,  1.3962],\n",
            "        [-1.9139,  0.4501,  1.0555],\n",
            "        [-2.0569,  0.3693,  1.3207],\n",
            "        [ 0.4380, -0.1808, -0.6895],\n",
            "        [-1.2788,  1.7255, -0.9043],\n",
            "        [ 0.7008, -0.3931, -0.8887],\n",
            "        [-1.5224,  1.7598, -0.1498],\n",
            "        [-1.3301,  1.8159, -0.9121],\n",
            "        [ 0.6954, -0.0645, -0.7215],\n",
            "        [-1.3147,  1.7558, -0.6399],\n",
            "        [-1.4028,  1.9153, -0.7932]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.7368, -0.2514, -0.7886],\n",
            "        [-1.4682,  1.8094, -0.7191],\n",
            "        [-1.9540,  0.4839,  1.4685],\n",
            "        [ 0.5518, -0.2844, -0.9409],\n",
            "        [ 0.6507, -0.2725, -0.8077],\n",
            "        [-1.8640,  0.2733,  1.3482],\n",
            "        [-1.3363,  1.7933, -0.7910],\n",
            "        [ 0.6194, -0.1045, -0.8543],\n",
            "        [-2.1211,  0.4676,  1.3724],\n",
            "        [-1.8771,  0.3977,  1.0392],\n",
            "        [-1.4508,  1.6778, -0.6758],\n",
            "        [-1.0436,  1.5639, -0.6116],\n",
            "        [-1.1399,  1.8085, -0.6934],\n",
            "        [-1.1501,  1.7785, -0.7104],\n",
            "        [-1.3214,  1.8671, -0.8247],\n",
            "        [ 0.6447, -0.2470, -0.9796]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.7368, -0.2514, -0.7886],\n",
            "        [-1.4682,  1.8094, -0.7191],\n",
            "        [-1.9540,  0.4839,  1.4685],\n",
            "        [ 0.5518, -0.2844, -0.9409],\n",
            "        [ 0.6507, -0.2725, -0.8077],\n",
            "        [-1.8640,  0.2733,  1.3482],\n",
            "        [-1.3363,  1.7933, -0.7910],\n",
            "        [ 0.6194, -0.1045, -0.8543],\n",
            "        [-2.1211,  0.4676,  1.3724],\n",
            "        [-1.8771,  0.3977,  1.0392],\n",
            "        [-1.4508,  1.6778, -0.6758],\n",
            "        [-1.0436,  1.5639, -0.6116],\n",
            "        [-1.1399,  1.8085, -0.6934],\n",
            "        [-1.1501,  1.7785, -0.7104],\n",
            "        [-1.3214,  1.8671, -0.8247],\n",
            "        [ 0.6447, -0.2470, -0.9796]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.1604,  1.5758, -0.4697],\n",
            "        [-1.4604,  1.4518, -0.2132],\n",
            "        [-1.9131,  0.4069,  1.2456],\n",
            "        [-1.5920,  1.3860, -0.0509],\n",
            "        [-1.7651,  0.4934,  1.1461],\n",
            "        [ 0.7854, -0.3526, -0.7726],\n",
            "        [ 0.5834, -0.4536, -0.7747],\n",
            "        [-2.1661,  0.2538,  1.5007],\n",
            "        [-1.1991,  1.7350, -0.7124],\n",
            "        [-2.0541,  0.5141,  1.2024],\n",
            "        [-1.2068,  1.5147, -0.6151],\n",
            "        [-1.9579,  0.7493,  1.1367],\n",
            "        [-1.2042,  2.0086, -0.8534],\n",
            "        [-1.2655,  1.7756, -0.7067],\n",
            "        [-1.2958,  1.7068, -0.9810],\n",
            "        [-2.0214,  0.4281,  1.4194]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.1604,  1.5758, -0.4697],\n",
            "        [-1.4604,  1.4518, -0.2132],\n",
            "        [-1.9131,  0.4069,  1.2456],\n",
            "        [-1.5920,  1.3860, -0.0509],\n",
            "        [-1.7651,  0.4934,  1.1461],\n",
            "        [ 0.7854, -0.3526, -0.7726],\n",
            "        [ 0.5834, -0.4536, -0.7747],\n",
            "        [-2.1661,  0.2538,  1.5007],\n",
            "        [-1.1991,  1.7350, -0.7124],\n",
            "        [-2.0541,  0.5141,  1.2024],\n",
            "        [-1.2068,  1.5147, -0.6151],\n",
            "        [-1.9579,  0.7493,  1.1367],\n",
            "        [-1.2042,  2.0086, -0.8534],\n",
            "        [-1.2655,  1.7756, -0.7067],\n",
            "        [-1.2958,  1.7068, -0.9810],\n",
            "        [-2.0214,  0.4281,  1.4194]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2149,  1.7957, -0.6428],\n",
            "        [-1.1115,  1.6936, -0.7613],\n",
            "        [-1.8736,  0.3318,  1.3068],\n",
            "        [-2.1986,  0.4255,  1.4362],\n",
            "        [ 0.7270, -0.4412, -0.7124],\n",
            "        [-2.0109,  0.9417,  1.0271],\n",
            "        [-0.6607,  1.3085, -0.8623],\n",
            "        [-2.1528,  0.4799,  1.3860],\n",
            "        [ 0.4379, -0.2807, -0.7665],\n",
            "        [-2.0073,  0.6369,  1.1659],\n",
            "        [-1.4302,  1.6993, -0.6555],\n",
            "        [-1.4681,  1.8133, -0.5912],\n",
            "        [-1.9337,  0.4074,  1.1424],\n",
            "        [-1.2658,  1.7630, -0.8068],\n",
            "        [-1.8273,  0.4274,  1.2402],\n",
            "        [-1.3074,  1.5893, -0.7164]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2149,  1.7957, -0.6428],\n",
            "        [-1.1115,  1.6936, -0.7613],\n",
            "        [-1.8736,  0.3318,  1.3068],\n",
            "        [-2.1986,  0.4255,  1.4362],\n",
            "        [ 0.7270, -0.4412, -0.7124],\n",
            "        [-2.0109,  0.9417,  1.0271],\n",
            "        [-0.6607,  1.3085, -0.8623],\n",
            "        [-2.1528,  0.4799,  1.3860],\n",
            "        [ 0.4379, -0.2807, -0.7665],\n",
            "        [-2.0073,  0.6369,  1.1659],\n",
            "        [-1.4302,  1.6993, -0.6555],\n",
            "        [-1.4681,  1.8133, -0.5912],\n",
            "        [-1.9337,  0.4074,  1.1424],\n",
            "        [-1.2658,  1.7630, -0.8068],\n",
            "        [-1.8273,  0.4274,  1.2402],\n",
            "        [-1.3074,  1.5893, -0.7164]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5962,  1.7650, -0.3852],\n",
            "        [-1.2774,  1.8375, -0.5346],\n",
            "        [-1.5231,  1.6467, -0.3811],\n",
            "        [-1.3662,  1.6485, -0.6822],\n",
            "        [-2.0559,  0.5550,  1.3851],\n",
            "        [ 0.6828, -0.1133, -0.9840],\n",
            "        [-1.1888,  1.6961, -0.6406],\n",
            "        [-0.7322,  0.8383, -0.5616],\n",
            "        [-2.2230,  0.5302,  1.5322],\n",
            "        [-0.8669,  1.4624, -0.7470],\n",
            "        [-1.3801,  1.7099, -0.5405],\n",
            "        [-1.9118,  0.6050,  1.3296],\n",
            "        [ 0.7982, -0.3050, -0.8577],\n",
            "        [-2.1140,  0.5621,  1.5388],\n",
            "        [-1.2846,  1.7164, -0.5174],\n",
            "        [-1.5716,  1.5798, -0.3204]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5962,  1.7650, -0.3852],\n",
            "        [-1.2774,  1.8375, -0.5346],\n",
            "        [-1.5231,  1.6467, -0.3811],\n",
            "        [-1.3662,  1.6485, -0.6822],\n",
            "        [-2.0559,  0.5550,  1.3851],\n",
            "        [ 0.6828, -0.1133, -0.9840],\n",
            "        [-1.1888,  1.6961, -0.6406],\n",
            "        [-0.7322,  0.8383, -0.5616],\n",
            "        [-2.2230,  0.5302,  1.5322],\n",
            "        [-0.8669,  1.4624, -0.7470],\n",
            "        [-1.3801,  1.7099, -0.5405],\n",
            "        [-1.9118,  0.6050,  1.3296],\n",
            "        [ 0.7982, -0.3050, -0.8577],\n",
            "        [-2.1140,  0.5621,  1.5388],\n",
            "        [-1.2846,  1.7164, -0.5174],\n",
            "        [-1.5716,  1.5798, -0.3204]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4306,  1.5204, -0.4995],\n",
            "        [-1.4420,  1.7929, -0.4948],\n",
            "        [-0.6701,  0.8398, -0.8244],\n",
            "        [-1.1726,  1.7416, -0.6725],\n",
            "        [-1.4229,  1.9781, -0.7813],\n",
            "        [-1.1424,  1.4169, -0.6506],\n",
            "        [-1.4270,  1.7264, -0.7390],\n",
            "        [-1.8998,  1.3429, -0.0032],\n",
            "        [-2.1694,  0.6026,  1.1514],\n",
            "        [-1.9698,  0.5221,  1.2609],\n",
            "        [-1.2771,  1.6531, -0.7687],\n",
            "        [-1.4095,  1.9188, -0.6695],\n",
            "        [-2.1134,  0.5665,  1.2296],\n",
            "        [-1.9726,  1.0234,  0.9855],\n",
            "        [-0.9174,  1.3142, -0.7974],\n",
            "        [ 0.7683, -0.3470, -0.9094]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4306,  1.5204, -0.4995],\n",
            "        [-1.4420,  1.7929, -0.4948],\n",
            "        [-0.6701,  0.8398, -0.8244],\n",
            "        [-1.1726,  1.7416, -0.6725],\n",
            "        [-1.4229,  1.9781, -0.7813],\n",
            "        [-1.1424,  1.4169, -0.6506],\n",
            "        [-1.4270,  1.7264, -0.7390],\n",
            "        [-1.8998,  1.3429, -0.0032],\n",
            "        [-2.1694,  0.6026,  1.1514],\n",
            "        [-1.9698,  0.5221,  1.2609],\n",
            "        [-1.2771,  1.6531, -0.7687],\n",
            "        [-1.4095,  1.9188, -0.6695],\n",
            "        [-2.1134,  0.5665,  1.2296],\n",
            "        [-1.9726,  1.0234,  0.9855],\n",
            "        [-0.9174,  1.3142, -0.7974],\n",
            "        [ 0.7683, -0.3470, -0.9094]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2190,  1.6586, -0.4684],\n",
            "        [-1.8530,  0.8523,  0.8957],\n",
            "        [-1.4466,  1.9768, -0.5814],\n",
            "        [-1.7205,  1.3339,  0.6159],\n",
            "        [-1.4669,  1.8014, -0.7907],\n",
            "        [-1.4407,  1.6794, -0.6248],\n",
            "        [-2.0567,  0.3152,  1.3019],\n",
            "        [-1.9304,  0.7957,  0.7721],\n",
            "        [-1.5539,  1.9375, -0.6063],\n",
            "        [-1.3999,  1.8069, -0.5477],\n",
            "        [-1.6090,  1.6335, -0.2621],\n",
            "        [-1.9092,  1.7136,  0.0443],\n",
            "        [-2.0392,  0.5226,  1.1931],\n",
            "        [-1.4118,  1.7887, -0.6635],\n",
            "        [-1.6925,  1.5091,  0.1001],\n",
            "        [-1.6997,  1.1364,  0.3555]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2190,  1.6586, -0.4684],\n",
            "        [-1.8530,  0.8523,  0.8957],\n",
            "        [-1.4466,  1.9768, -0.5814],\n",
            "        [-1.7205,  1.3339,  0.6159],\n",
            "        [-1.4669,  1.8014, -0.7907],\n",
            "        [-1.4407,  1.6794, -0.6248],\n",
            "        [-2.0567,  0.3152,  1.3019],\n",
            "        [-1.9304,  0.7957,  0.7721],\n",
            "        [-1.5539,  1.9375, -0.6063],\n",
            "        [-1.3999,  1.8069, -0.5477],\n",
            "        [-1.6090,  1.6335, -0.2621],\n",
            "        [-1.9092,  1.7136,  0.0443],\n",
            "        [-2.0392,  0.5226,  1.1931],\n",
            "        [-1.4118,  1.7887, -0.6635],\n",
            "        [-1.6925,  1.5091,  0.1001],\n",
            "        [-1.6997,  1.1364,  0.3555]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2599,  1.4752, -0.5720],\n",
            "        [-1.3456,  1.6753, -0.5531],\n",
            "        [-1.2688,  1.7588, -0.7398],\n",
            "        [-1.4809,  1.8623, -0.6566],\n",
            "        [-2.0323,  0.6233,  1.1499],\n",
            "        [-1.3625,  1.8436, -0.7152],\n",
            "        [-1.2607,  1.7442, -0.6945],\n",
            "        [-1.8149,  1.6112, -0.3281],\n",
            "        [-1.3670,  1.6033, -0.6387],\n",
            "        [-1.2732,  1.7337, -0.6394],\n",
            "        [-1.4566,  1.8678, -0.5779],\n",
            "        [-1.4924,  1.8932, -0.4952],\n",
            "        [-2.3039,  0.4315,  1.3017],\n",
            "        [-1.5370,  1.4493, -0.1903],\n",
            "        [-1.6345,  1.2518, -0.0335],\n",
            "        [-1.2555,  1.7938, -0.5573]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2599,  1.4752, -0.5720],\n",
            "        [-1.3456,  1.6753, -0.5531],\n",
            "        [-1.2688,  1.7588, -0.7398],\n",
            "        [-1.4809,  1.8623, -0.6566],\n",
            "        [-2.0323,  0.6233,  1.1499],\n",
            "        [-1.3625,  1.8436, -0.7152],\n",
            "        [-1.2607,  1.7442, -0.6945],\n",
            "        [-1.8149,  1.6112, -0.3281],\n",
            "        [-1.3670,  1.6033, -0.6387],\n",
            "        [-1.2732,  1.7337, -0.6394],\n",
            "        [-1.4566,  1.8678, -0.5779],\n",
            "        [-1.4924,  1.8932, -0.4952],\n",
            "        [-2.3039,  0.4315,  1.3017],\n",
            "        [-1.5370,  1.4493, -0.1903],\n",
            "        [-1.6345,  1.2518, -0.0335],\n",
            "        [-1.2555,  1.7938, -0.5573]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3847,  1.7516, -0.5161],\n",
            "        [-2.0285,  0.5768,  1.1857],\n",
            "        [-2.1550,  0.5645,  1.1593],\n",
            "        [-1.5296,  1.9707, -0.5775],\n",
            "        [-1.3238,  1.6970, -0.4927],\n",
            "        [-1.6580,  0.3815,  1.0555],\n",
            "        [-2.0154,  0.6318,  1.2055],\n",
            "        [ 0.1850,  0.4126, -0.9949],\n",
            "        [-1.4644,  1.6642, -0.5766],\n",
            "        [ 0.7612, -0.3464, -0.7993],\n",
            "        [-1.4476,  1.4108, -0.4335],\n",
            "        [-1.4367,  1.8615, -0.4416],\n",
            "        [-2.0104,  0.6431,  1.2234],\n",
            "        [-1.7094,  1.4407, -0.0457],\n",
            "        [-1.4057,  1.7141, -0.3004],\n",
            "        [-2.1015,  0.5759,  1.4149]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3847,  1.7516, -0.5161],\n",
            "        [-2.0285,  0.5768,  1.1857],\n",
            "        [-2.1550,  0.5645,  1.1593],\n",
            "        [-1.5296,  1.9707, -0.5775],\n",
            "        [-1.3238,  1.6970, -0.4927],\n",
            "        [-1.6580,  0.3815,  1.0555],\n",
            "        [-2.0154,  0.6318,  1.2055],\n",
            "        [ 0.1850,  0.4126, -0.9949],\n",
            "        [-1.4644,  1.6642, -0.5766],\n",
            "        [ 0.7612, -0.3464, -0.7993],\n",
            "        [-1.4476,  1.4108, -0.4335],\n",
            "        [-1.4367,  1.8615, -0.4416],\n",
            "        [-2.0104,  0.6431,  1.2234],\n",
            "        [-1.7094,  1.4407, -0.0457],\n",
            "        [-1.4057,  1.7141, -0.3004],\n",
            "        [-2.1015,  0.5759,  1.4149]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0257,  0.5464,  1.1653],\n",
            "        [ 0.6244, -0.2142, -0.9198],\n",
            "        [-2.0470,  0.5035,  1.1766],\n",
            "        [-2.2781,  0.6355,  1.3383],\n",
            "        [ 0.6991, -0.1208, -0.9891],\n",
            "        [-2.0724,  0.6600,  1.1435],\n",
            "        [ 0.7679, -0.3123, -0.9527],\n",
            "        [-2.1178,  0.5060,  1.3095],\n",
            "        [-2.0189,  0.5533,  1.2639],\n",
            "        [-1.4787,  1.8234, -0.4852],\n",
            "        [-1.4984,  1.7165, -0.3856],\n",
            "        [-1.7601,  1.4960, -0.0806],\n",
            "        [-1.9809,  0.5152,  1.1877],\n",
            "        [-1.4722,  1.9971, -0.6124],\n",
            "        [-2.0814,  0.5980,  1.1023],\n",
            "        [-1.5510,  1.8658, -0.4876]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0257,  0.5464,  1.1653],\n",
            "        [ 0.6244, -0.2142, -0.9198],\n",
            "        [-2.0470,  0.5035,  1.1766],\n",
            "        [-2.2781,  0.6355,  1.3383],\n",
            "        [ 0.6991, -0.1208, -0.9891],\n",
            "        [-2.0724,  0.6600,  1.1435],\n",
            "        [ 0.7679, -0.3123, -0.9527],\n",
            "        [-2.1178,  0.5060,  1.3095],\n",
            "        [-2.0189,  0.5533,  1.2639],\n",
            "        [-1.4787,  1.8234, -0.4852],\n",
            "        [-1.4984,  1.7165, -0.3856],\n",
            "        [-1.7601,  1.4960, -0.0806],\n",
            "        [-1.9809,  0.5152,  1.1877],\n",
            "        [-1.4722,  1.9971, -0.6124],\n",
            "        [-2.0814,  0.5980,  1.1023],\n",
            "        [-1.5510,  1.8658, -0.4876]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5232,  1.7964, -0.5475],\n",
            "        [-1.4949,  0.2801,  1.0300],\n",
            "        [-2.1501,  0.6201,  1.2047],\n",
            "        [-2.1760,  0.3323,  1.3087],\n",
            "        [-1.9375,  1.4197,  0.5801],\n",
            "        [-1.6275,  1.7997, -0.3442],\n",
            "        [-1.4634,  1.8682, -0.2891],\n",
            "        [-1.6892,  1.7677, -0.2338],\n",
            "        [ 0.7392, -0.3949, -0.7982],\n",
            "        [-2.0941,  0.4307,  1.1244],\n",
            "        [-1.5671,  1.8430, -0.4915],\n",
            "        [-1.5453,  1.8312, -0.4098],\n",
            "        [-1.3453,  0.1008,  0.7827],\n",
            "        [-1.4684,  1.7660, -0.6294],\n",
            "        [-2.0850,  0.4072,  1.0519],\n",
            "        [-1.5939,  1.5793, -0.2857]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5232,  1.7964, -0.5475],\n",
            "        [-1.4949,  0.2801,  1.0300],\n",
            "        [-2.1501,  0.6201,  1.2047],\n",
            "        [-2.1760,  0.3323,  1.3087],\n",
            "        [-1.9375,  1.4197,  0.5801],\n",
            "        [-1.6275,  1.7997, -0.3442],\n",
            "        [-1.4634,  1.8682, -0.2891],\n",
            "        [-1.6892,  1.7677, -0.2338],\n",
            "        [ 0.7392, -0.3949, -0.7982],\n",
            "        [-2.0941,  0.4307,  1.1244],\n",
            "        [-1.5671,  1.8430, -0.4915],\n",
            "        [-1.5453,  1.8312, -0.4098],\n",
            "        [-1.3453,  0.1008,  0.7827],\n",
            "        [-1.4684,  1.7660, -0.6294],\n",
            "        [-2.0850,  0.4072,  1.0519],\n",
            "        [-1.5939,  1.5793, -0.2857]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4035,  1.5301, -0.2320],\n",
            "        [-2.1661,  0.5599,  1.2322],\n",
            "        [-1.3928,  1.7301, -0.4441],\n",
            "        [-1.6141,  1.6234, -0.3378],\n",
            "        [-1.8504,  0.8374,  0.9522],\n",
            "        [-1.9887,  1.3744,  0.3391],\n",
            "        [-1.3821,  1.6411, -0.6345],\n",
            "        [ 0.6239, -0.1661, -0.9799],\n",
            "        [-1.7109,  1.7092, -0.3920],\n",
            "        [-1.9428,  0.5054,  1.1571],\n",
            "        [ 0.5860, -0.3144, -0.9235],\n",
            "        [-1.9376,  0.5451,  0.9950],\n",
            "        [-1.4217,  1.9934, -0.5309],\n",
            "        [-1.9890,  0.5165,  1.2696],\n",
            "        [-1.8036,  0.5414,  1.2330],\n",
            "        [-1.4370,  1.7664, -0.3086]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4035,  1.5301, -0.2320],\n",
            "        [-2.1661,  0.5599,  1.2322],\n",
            "        [-1.3928,  1.7301, -0.4441],\n",
            "        [-1.6141,  1.6234, -0.3378],\n",
            "        [-1.8504,  0.8374,  0.9522],\n",
            "        [-1.9887,  1.3744,  0.3391],\n",
            "        [-1.3821,  1.6411, -0.6345],\n",
            "        [ 0.6239, -0.1661, -0.9799],\n",
            "        [-1.7109,  1.7092, -0.3920],\n",
            "        [-1.9428,  0.5054,  1.1571],\n",
            "        [ 0.5860, -0.3144, -0.9235],\n",
            "        [-1.9376,  0.5451,  0.9950],\n",
            "        [-1.4217,  1.9934, -0.5309],\n",
            "        [-1.9890,  0.5165,  1.2696],\n",
            "        [-1.8036,  0.5414,  1.2330],\n",
            "        [-1.4370,  1.7664, -0.3086]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9982,  0.5510,  0.7982],\n",
            "        [-2.2990,  0.5463,  1.2648],\n",
            "        [-2.2305,  0.4542,  1.2249],\n",
            "        [-1.8780,  0.5347,  1.1411],\n",
            "        [-1.5535,  1.8575, -0.4452],\n",
            "        [-2.0370,  1.1147,  0.6937],\n",
            "        [ 0.4160, -0.2136, -0.8507],\n",
            "        [-1.6867,  1.8394, -0.5203],\n",
            "        [-1.3267,  1.8309, -0.6165],\n",
            "        [-1.9790,  0.7889,  1.1578],\n",
            "        [-1.4836,  1.7156, -0.6211],\n",
            "        [ 0.1337, -0.1444, -0.3757],\n",
            "        [-1.5070,  1.7467, -0.4373],\n",
            "        [-1.6711,  2.1178, -0.6429],\n",
            "        [-1.9841,  0.4371,  1.2121],\n",
            "        [-1.5093,  1.5866, -0.1736]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9982,  0.5510,  0.7982],\n",
            "        [-2.2990,  0.5463,  1.2648],\n",
            "        [-2.2305,  0.4542,  1.2249],\n",
            "        [-1.8780,  0.5347,  1.1411],\n",
            "        [-1.5535,  1.8575, -0.4452],\n",
            "        [-2.0370,  1.1147,  0.6937],\n",
            "        [ 0.4160, -0.2136, -0.8507],\n",
            "        [-1.6867,  1.8394, -0.5203],\n",
            "        [-1.3267,  1.8309, -0.6165],\n",
            "        [-1.9790,  0.7889,  1.1578],\n",
            "        [-1.4836,  1.7156, -0.6211],\n",
            "        [ 0.1337, -0.1444, -0.3757],\n",
            "        [-1.5070,  1.7467, -0.4373],\n",
            "        [-1.6711,  2.1178, -0.6429],\n",
            "        [-1.9841,  0.4371,  1.2121],\n",
            "        [-1.5093,  1.5866, -0.1736]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6353,  1.7665, -0.4401],\n",
            "        [-1.5507,  1.8226, -0.4199],\n",
            "        [ 0.7607, -0.2781, -0.8645],\n",
            "        [-1.6298,  1.6324, -0.4388],\n",
            "        [-2.2566,  0.4974,  1.2185],\n",
            "        [-1.3530,  1.6484, -0.6168],\n",
            "        [-1.5299,  1.7503, -0.4802],\n",
            "        [-2.1815,  0.4250,  1.1006],\n",
            "        [-1.7228,  1.9581, -0.4734],\n",
            "        [-1.6666,  1.5606, -0.2003],\n",
            "        [-1.4292,  1.7054, -0.4896],\n",
            "        [-1.6544,  1.5933, -0.0922],\n",
            "        [-1.9450,  1.3118,  0.2705],\n",
            "        [-1.5853,  1.6825, -0.5065],\n",
            "        [ 0.6100, -0.4265, -0.9473],\n",
            "        [-2.0992,  0.5941,  1.2276]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6353,  1.7665, -0.4401],\n",
            "        [-1.5507,  1.8226, -0.4199],\n",
            "        [ 0.7607, -0.2781, -0.8645],\n",
            "        [-1.6298,  1.6324, -0.4388],\n",
            "        [-2.2566,  0.4974,  1.2185],\n",
            "        [-1.3530,  1.6484, -0.6168],\n",
            "        [-1.5299,  1.7503, -0.4802],\n",
            "        [-2.1815,  0.4250,  1.1006],\n",
            "        [-1.7228,  1.9581, -0.4734],\n",
            "        [-1.6666,  1.5606, -0.2003],\n",
            "        [-1.4292,  1.7054, -0.4896],\n",
            "        [-1.6544,  1.5933, -0.0922],\n",
            "        [-1.9450,  1.3118,  0.2705],\n",
            "        [-1.5853,  1.6825, -0.5065],\n",
            "        [ 0.6100, -0.4265, -0.9473],\n",
            "        [-2.0992,  0.5941,  1.2276]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0049,  0.7963,  0.7651],\n",
            "        [-1.4467,  1.7358, -0.3487],\n",
            "        [-2.0577,  0.4840,  1.2611],\n",
            "        [-1.6002,  1.6620, -0.2515],\n",
            "        [-2.3116,  1.0965,  0.6646],\n",
            "        [ 0.5982, -0.3555, -0.7313],\n",
            "        [-1.6300,  1.8087, -0.3446],\n",
            "        [ 0.7403, -0.4303, -0.9283],\n",
            "        [-1.4539,  0.3564,  1.0511],\n",
            "        [-1.9217,  1.6717, -0.1172],\n",
            "        [-2.1990,  0.6378,  1.0827],\n",
            "        [-1.9363,  1.8361, -0.3283],\n",
            "        [-1.5200,  1.7375, -0.4727],\n",
            "        [-1.4374,  1.7443, -0.4234],\n",
            "        [-1.8286,  0.4906,  1.3655],\n",
            "        [ 0.7879, -0.2778, -0.7374]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0049,  0.7963,  0.7651],\n",
            "        [-1.4467,  1.7358, -0.3487],\n",
            "        [-2.0577,  0.4840,  1.2611],\n",
            "        [-1.6002,  1.6620, -0.2515],\n",
            "        [-2.3116,  1.0965,  0.6646],\n",
            "        [ 0.5982, -0.3555, -0.7313],\n",
            "        [-1.6300,  1.8087, -0.3446],\n",
            "        [ 0.7403, -0.4303, -0.9283],\n",
            "        [-1.4539,  0.3564,  1.0511],\n",
            "        [-1.9217,  1.6717, -0.1172],\n",
            "        [-2.1990,  0.6378,  1.0827],\n",
            "        [-1.9363,  1.8361, -0.3283],\n",
            "        [-1.5200,  1.7375, -0.4727],\n",
            "        [-1.4374,  1.7443, -0.4234],\n",
            "        [-1.8286,  0.4906,  1.3655],\n",
            "        [ 0.7879, -0.2778, -0.7374]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3348,  1.6955, -0.6426],\n",
            "        [-2.1782,  0.4095,  1.4813],\n",
            "        [-1.7889,  1.9434, -0.7010],\n",
            "        [-2.1253,  0.5270,  1.3665],\n",
            "        [-2.0617,  0.5395,  1.3053],\n",
            "        [ 0.3641, -0.2552, -0.5883],\n",
            "        [-1.7538,  1.7783, -0.1395],\n",
            "        [-1.5308,  2.0882, -0.5548],\n",
            "        [-1.6563,  1.8628, -0.5103],\n",
            "        [-2.0063,  0.6174,  1.2254],\n",
            "        [-1.7141,  1.8444, -0.3877],\n",
            "        [-1.6235,  1.9526, -0.4746],\n",
            "        [-1.4377,  2.0413, -0.5292],\n",
            "        [-2.1157,  0.6476,  1.2421],\n",
            "        [-1.5914,  1.9072, -0.2272],\n",
            "        [ 0.7424, -0.4646, -0.7397]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3348,  1.6955, -0.6426],\n",
            "        [-2.1782,  0.4095,  1.4813],\n",
            "        [-1.7889,  1.9434, -0.7010],\n",
            "        [-2.1253,  0.5270,  1.3665],\n",
            "        [-2.0617,  0.5395,  1.3053],\n",
            "        [ 0.3641, -0.2552, -0.5883],\n",
            "        [-1.7538,  1.7783, -0.1395],\n",
            "        [-1.5308,  2.0882, -0.5548],\n",
            "        [-1.6563,  1.8628, -0.5103],\n",
            "        [-2.0063,  0.6174,  1.2254],\n",
            "        [-1.7141,  1.8444, -0.3877],\n",
            "        [-1.6235,  1.9526, -0.4746],\n",
            "        [-1.4377,  2.0413, -0.5292],\n",
            "        [-2.1157,  0.6476,  1.2421],\n",
            "        [-1.5914,  1.9072, -0.2272],\n",
            "        [ 0.7424, -0.4646, -0.7397]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9209,  0.3994,  1.0837],\n",
            "        [-1.8986,  0.5317,  1.3431],\n",
            "        [-2.0547,  0.5178,  1.2447],\n",
            "        [-1.9609,  0.4499,  1.3386],\n",
            "        [-2.0357,  0.3478,  1.4483],\n",
            "        [-1.3217,  1.5981, -0.3376],\n",
            "        [-1.5283,  2.0152, -0.5797],\n",
            "        [-1.4904,  1.8910, -0.4873],\n",
            "        [ 0.8139, -0.3678, -0.8598],\n",
            "        [-1.8085,  0.3773,  1.2065],\n",
            "        [ 0.4708, -0.2985, -0.8941],\n",
            "        [-1.3824,  1.8495, -0.5157],\n",
            "        [-1.4312,  1.7077, -0.6363],\n",
            "        [-1.4967,  2.0657, -0.7648],\n",
            "        [-1.6317,  1.8410, -0.4164],\n",
            "        [-1.6481,  1.6758, -0.6795]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9209,  0.3994,  1.0837],\n",
            "        [-1.8986,  0.5317,  1.3431],\n",
            "        [-2.0547,  0.5178,  1.2447],\n",
            "        [-1.9609,  0.4499,  1.3386],\n",
            "        [-2.0357,  0.3478,  1.4483],\n",
            "        [-1.3217,  1.5981, -0.3376],\n",
            "        [-1.5283,  2.0152, -0.5797],\n",
            "        [-1.4904,  1.8910, -0.4873],\n",
            "        [ 0.8139, -0.3678, -0.8598],\n",
            "        [-1.8085,  0.3773,  1.2065],\n",
            "        [ 0.4708, -0.2985, -0.8941],\n",
            "        [-1.3824,  1.8495, -0.5157],\n",
            "        [-1.4312,  1.7077, -0.6363],\n",
            "        [-1.4967,  2.0657, -0.7648],\n",
            "        [-1.6317,  1.8410, -0.4164],\n",
            "        [-1.6481,  1.6758, -0.6795]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6406,  1.8667, -0.5540],\n",
            "        [-1.7728,  1.6968, -0.0740],\n",
            "        [-1.5482,  1.8713, -0.5350],\n",
            "        [-1.7828,  1.7373, -0.4733],\n",
            "        [ 0.8248, -0.5385, -0.8313],\n",
            "        [ 0.8318, -0.4196, -0.7507],\n",
            "        [-1.4980,  1.7783, -0.4447],\n",
            "        [-2.0102,  1.0859,  0.3810],\n",
            "        [-1.6357,  1.8293, -0.4278],\n",
            "        [-2.0017,  0.5931,  1.2292],\n",
            "        [ 0.6716, -0.3941, -0.8717],\n",
            "        [-1.7008,  1.8401, -0.4959],\n",
            "        [-1.7226,  1.9423, -0.2800],\n",
            "        [-2.0415,  0.8369,  1.0613],\n",
            "        [-2.0033,  0.4951,  1.1829],\n",
            "        [ 0.9046, -0.4301, -0.8284]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6406,  1.8667, -0.5540],\n",
            "        [-1.7728,  1.6968, -0.0740],\n",
            "        [-1.5482,  1.8713, -0.5350],\n",
            "        [-1.7828,  1.7373, -0.4733],\n",
            "        [ 0.8248, -0.5385, -0.8313],\n",
            "        [ 0.8318, -0.4196, -0.7507],\n",
            "        [-1.4980,  1.7783, -0.4447],\n",
            "        [-2.0102,  1.0859,  0.3810],\n",
            "        [-1.6357,  1.8293, -0.4278],\n",
            "        [-2.0017,  0.5931,  1.2292],\n",
            "        [ 0.6716, -0.3941, -0.8717],\n",
            "        [-1.7008,  1.8401, -0.4959],\n",
            "        [-1.7226,  1.9423, -0.2800],\n",
            "        [-2.0415,  0.8369,  1.0613],\n",
            "        [-2.0033,  0.4951,  1.1829],\n",
            "        [ 0.9046, -0.4301, -0.8284]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1280,  0.5124,  1.3958],\n",
            "        [-1.7193,  0.5454,  1.1164],\n",
            "        [-1.3488,  1.8400, -0.5445],\n",
            "        [-1.6318,  1.9056, -0.6012],\n",
            "        [-2.0275,  0.3063,  1.4427],\n",
            "        [-1.6281,  1.8240, -0.5082],\n",
            "        [-1.6735,  2.0090, -0.5410],\n",
            "        [-1.7515,  1.8257, -0.1750],\n",
            "        [-1.3986,  1.7672, -0.3661],\n",
            "        [-1.8031,  0.6776,  1.1159],\n",
            "        [-1.6668,  1.7992, -0.4691],\n",
            "        [-1.2817,  1.4620, -0.6506],\n",
            "        [-1.9016,  0.4141,  1.3805],\n",
            "        [-1.8265,  2.0869, -0.4075],\n",
            "        [-1.9808,  0.8842,  0.7935],\n",
            "        [-1.8327,  2.0295, -0.4630]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1280,  0.5124,  1.3958],\n",
            "        [-1.7193,  0.5454,  1.1164],\n",
            "        [-1.3488,  1.8400, -0.5445],\n",
            "        [-1.6318,  1.9056, -0.6012],\n",
            "        [-2.0275,  0.3063,  1.4427],\n",
            "        [-1.6281,  1.8240, -0.5082],\n",
            "        [-1.6735,  2.0090, -0.5410],\n",
            "        [-1.7515,  1.8257, -0.1750],\n",
            "        [-1.3986,  1.7672, -0.3661],\n",
            "        [-1.8031,  0.6776,  1.1159],\n",
            "        [-1.6668,  1.7992, -0.4691],\n",
            "        [-1.2817,  1.4620, -0.6506],\n",
            "        [-1.9016,  0.4141,  1.3805],\n",
            "        [-1.8265,  2.0869, -0.4075],\n",
            "        [-1.9808,  0.8842,  0.7935],\n",
            "        [-1.8327,  2.0295, -0.4630]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7874,  1.3830,  0.0498],\n",
            "        [ 0.4047, -0.2431, -0.9765],\n",
            "        [-1.7210,  1.9633, -0.2111],\n",
            "        [-1.6198,  1.6743, -0.3068],\n",
            "        [-1.9882,  1.5797,  0.1463],\n",
            "        [-2.1390,  0.4389,  1.2435],\n",
            "        [-1.7798,  1.9520, -0.4399],\n",
            "        [-1.9710,  0.4381,  1.5667],\n",
            "        [-1.5503,  1.6448, -0.2935],\n",
            "        [-1.8732,  1.4965, -0.2188],\n",
            "        [-1.4797,  1.8983, -0.5149],\n",
            "        [-2.1181,  0.2965,  1.5182],\n",
            "        [-2.1021,  0.5874,  0.9489],\n",
            "        [-1.8911,  1.6599,  0.0951],\n",
            "        [-2.2136,  0.5659,  1.1935],\n",
            "        [-1.7555,  0.3767,  1.2631]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7874,  1.3830,  0.0498],\n",
            "        [ 0.4047, -0.2431, -0.9765],\n",
            "        [-1.7210,  1.9633, -0.2111],\n",
            "        [-1.6198,  1.6743, -0.3068],\n",
            "        [-1.9882,  1.5797,  0.1463],\n",
            "        [-2.1390,  0.4389,  1.2435],\n",
            "        [-1.7798,  1.9520, -0.4399],\n",
            "        [-1.9710,  0.4381,  1.5667],\n",
            "        [-1.5503,  1.6448, -0.2935],\n",
            "        [-1.8732,  1.4965, -0.2188],\n",
            "        [-1.4797,  1.8983, -0.5149],\n",
            "        [-2.1181,  0.2965,  1.5182],\n",
            "        [-2.1021,  0.5874,  0.9489],\n",
            "        [-1.8911,  1.6599,  0.0951],\n",
            "        [-2.2136,  0.5659,  1.1935],\n",
            "        [-1.7555,  0.3767,  1.2631]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1914,  0.5084,  1.3677],\n",
            "        [-2.0625,  0.3950,  1.5146],\n",
            "        [-1.7109,  1.4093, -0.0833],\n",
            "        [ 0.3316,  0.1398, -0.9050],\n",
            "        [-1.8592,  0.4371,  1.3313],\n",
            "        [-1.8304,  0.2666,  1.4956],\n",
            "        [ 0.8445, -0.3513, -0.8785],\n",
            "        [-1.8035,  1.8589, -0.4486],\n",
            "        [-0.1687, -0.1283,  0.1283],\n",
            "        [ 0.6407, -0.2998, -0.8114],\n",
            "        [-2.0180,  0.3078,  1.2598],\n",
            "        [ 0.5512, -0.1733, -1.0634],\n",
            "        [-2.0638,  0.2603,  1.4454],\n",
            "        [-1.6051,  2.0727, -0.3716],\n",
            "        [-1.5851,  1.8884, -0.4867],\n",
            "        [-1.7221,  1.8726, -0.5154]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1914,  0.5084,  1.3677],\n",
            "        [-2.0625,  0.3950,  1.5146],\n",
            "        [-1.7109,  1.4093, -0.0833],\n",
            "        [ 0.3316,  0.1398, -0.9050],\n",
            "        [-1.8592,  0.4371,  1.3313],\n",
            "        [-1.8304,  0.2666,  1.4956],\n",
            "        [ 0.8445, -0.3513, -0.8785],\n",
            "        [-1.8035,  1.8589, -0.4486],\n",
            "        [-0.1687, -0.1283,  0.1283],\n",
            "        [ 0.6407, -0.2998, -0.8114],\n",
            "        [-2.0180,  0.3078,  1.2598],\n",
            "        [ 0.5512, -0.1733, -1.0634],\n",
            "        [-2.0638,  0.2603,  1.4454],\n",
            "        [-1.6051,  2.0727, -0.3716],\n",
            "        [-1.5851,  1.8884, -0.4867],\n",
            "        [-1.7221,  1.8726, -0.5154]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7772,  2.0640, -0.5544],\n",
            "        [-1.7567,  1.9473, -0.5679],\n",
            "        [-1.5423,  1.9160, -0.3641],\n",
            "        [-1.9348,  0.5442,  1.3224],\n",
            "        [-1.6199,  2.0379, -0.3023],\n",
            "        [ 0.6684,  0.0254, -1.0011],\n",
            "        [-1.7635,  2.0837, -0.5067],\n",
            "        [-1.8426,  0.1808,  1.3160],\n",
            "        [-1.8242,  0.6990,  1.0519],\n",
            "        [-1.9006,  2.0865, -0.2842],\n",
            "        [-1.9321,  0.5630,  1.2927],\n",
            "        [-1.7311,  2.0127, -0.2915],\n",
            "        [-1.6225,  1.7671, -0.4068],\n",
            "        [-1.5777,  2.1289, -0.3603],\n",
            "        [-1.6882,  1.8044, -0.3337],\n",
            "        [ 0.4608, -0.3555, -0.6026]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7772,  2.0640, -0.5544],\n",
            "        [-1.7567,  1.9473, -0.5679],\n",
            "        [-1.5423,  1.9160, -0.3641],\n",
            "        [-1.9348,  0.5442,  1.3224],\n",
            "        [-1.6199,  2.0379, -0.3023],\n",
            "        [ 0.6684,  0.0254, -1.0011],\n",
            "        [-1.7635,  2.0837, -0.5067],\n",
            "        [-1.8426,  0.1808,  1.3160],\n",
            "        [-1.8242,  0.6990,  1.0519],\n",
            "        [-1.9006,  2.0865, -0.2842],\n",
            "        [-1.9321,  0.5630,  1.2927],\n",
            "        [-1.7311,  2.0127, -0.2915],\n",
            "        [-1.6225,  1.7671, -0.4068],\n",
            "        [-1.5777,  2.1289, -0.3603],\n",
            "        [-1.6882,  1.8044, -0.3337],\n",
            "        [ 0.4608, -0.3555, -0.6026]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.6244, -0.1774, -0.8937],\n",
            "        [-1.9826,  2.1356, -0.3225],\n",
            "        [-2.2187,  0.1773,  1.5474],\n",
            "        [-1.8816,  2.1149, -0.3247],\n",
            "        [-2.0344,  0.1676,  1.5429],\n",
            "        [-1.7091,  1.8208, -0.1792],\n",
            "        [-1.6824,  1.7704, -0.3983],\n",
            "        [-1.5655,  2.0067, -0.5756],\n",
            "        [-1.9351,  1.8454, -0.4566],\n",
            "        [-2.0385,  1.3831,  0.7049],\n",
            "        [ 0.6985, -0.4913, -0.8027],\n",
            "        [-1.5495,  1.9689, -0.2983],\n",
            "        [ 0.7599, -0.4211, -0.8321],\n",
            "        [-1.5788,  1.6670, -0.2578],\n",
            "        [-1.6949,  2.0380, -0.4498],\n",
            "        [-1.9654,  0.6517,  1.0845]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.6244, -0.1774, -0.8937],\n",
            "        [-1.9826,  2.1356, -0.3225],\n",
            "        [-2.2187,  0.1773,  1.5474],\n",
            "        [-1.8816,  2.1149, -0.3247],\n",
            "        [-2.0344,  0.1676,  1.5429],\n",
            "        [-1.7091,  1.8208, -0.1792],\n",
            "        [-1.6824,  1.7704, -0.3983],\n",
            "        [-1.5655,  2.0067, -0.5756],\n",
            "        [-1.9351,  1.8454, -0.4566],\n",
            "        [-2.0385,  1.3831,  0.7049],\n",
            "        [ 0.6985, -0.4913, -0.8027],\n",
            "        [-1.5495,  1.9689, -0.2983],\n",
            "        [ 0.7599, -0.4211, -0.8321],\n",
            "        [-1.5788,  1.6670, -0.2578],\n",
            "        [-1.6949,  2.0380, -0.4498],\n",
            "        [-1.9654,  0.6517,  1.0845]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7200,  2.1053, -0.2825],\n",
            "        [-1.8228,  1.7430, -0.5257],\n",
            "        [-1.4976,  1.9513, -0.5484],\n",
            "        [-1.7445,  2.0053, -0.4266],\n",
            "        [-1.6163,  1.8199, -0.3533],\n",
            "        [-1.5579,  1.8206, -0.5471],\n",
            "        [-2.0813,  0.3655,  1.5532],\n",
            "        [ 0.7516, -0.4143, -0.6572],\n",
            "        [-1.7220,  2.0153, -0.5127],\n",
            "        [-1.7071,  2.0916, -0.4352],\n",
            "        [-1.6354,  1.9024, -0.4700],\n",
            "        [-1.8972,  0.2745,  1.5167],\n",
            "        [-1.9756,  0.2248,  1.2911],\n",
            "        [-1.8730,  0.2625,  1.3161],\n",
            "        [-1.7216,  1.8327, -0.6388],\n",
            "        [ 0.3768, -0.2587, -0.8132]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7200,  2.1053, -0.2825],\n",
            "        [-1.8228,  1.7430, -0.5257],\n",
            "        [-1.4976,  1.9513, -0.5484],\n",
            "        [-1.7445,  2.0053, -0.4266],\n",
            "        [-1.6163,  1.8199, -0.3533],\n",
            "        [-1.5579,  1.8206, -0.5471],\n",
            "        [-2.0813,  0.3655,  1.5532],\n",
            "        [ 0.7516, -0.4143, -0.6572],\n",
            "        [-1.7220,  2.0153, -0.5127],\n",
            "        [-1.7071,  2.0916, -0.4352],\n",
            "        [-1.6354,  1.9024, -0.4700],\n",
            "        [-1.8972,  0.2745,  1.5167],\n",
            "        [-1.9756,  0.2248,  1.2911],\n",
            "        [-1.8730,  0.2625,  1.3161],\n",
            "        [-1.7216,  1.8327, -0.6388],\n",
            "        [ 0.3768, -0.2587, -0.8132]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8278,  2.0601, -0.5359],\n",
            "        [-1.8051,  1.7011, -0.1385],\n",
            "        [-1.7040,  1.8830, -0.4955],\n",
            "        [-2.1157,  0.4763,  1.3954],\n",
            "        [-1.5760,  1.9123, -0.4323],\n",
            "        [-1.7739,  1.9384, -0.4221],\n",
            "        [-1.7854,  1.9622, -0.2602],\n",
            "        [-1.5010,  1.9844, -0.6671],\n",
            "        [-1.9157,  2.0248, -0.5622],\n",
            "        [ 0.3934, -0.1047, -0.8455],\n",
            "        [-1.8002,  0.0874,  1.4221],\n",
            "        [-1.7056,  1.9484, -0.5149],\n",
            "        [ 0.3950, -0.2307, -0.7454],\n",
            "        [-1.9017,  1.8628, -0.4446],\n",
            "        [-1.7275,  1.9212, -0.2929],\n",
            "        [ 0.6993, -0.3744, -0.7534]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8278,  2.0601, -0.5359],\n",
            "        [-1.8051,  1.7011, -0.1385],\n",
            "        [-1.7040,  1.8830, -0.4955],\n",
            "        [-2.1157,  0.4763,  1.3954],\n",
            "        [-1.5760,  1.9123, -0.4323],\n",
            "        [-1.7739,  1.9384, -0.4221],\n",
            "        [-1.7854,  1.9622, -0.2602],\n",
            "        [-1.5010,  1.9844, -0.6671],\n",
            "        [-1.9157,  2.0248, -0.5622],\n",
            "        [ 0.3934, -0.1047, -0.8455],\n",
            "        [-1.8002,  0.0874,  1.4221],\n",
            "        [-1.7056,  1.9484, -0.5149],\n",
            "        [ 0.3950, -0.2307, -0.7454],\n",
            "        [-1.9017,  1.8628, -0.4446],\n",
            "        [-1.7275,  1.9212, -0.2929],\n",
            "        [ 0.6993, -0.3744, -0.7534]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5847,  1.7640, -0.4502],\n",
            "        [-1.9071,  0.3479,  1.3520],\n",
            "        [-1.8215,  2.0813, -0.2957],\n",
            "        [-1.5355,  2.0370, -0.5476],\n",
            "        [-1.7685,  1.9947, -0.3459],\n",
            "        [-1.8164,  1.8916, -0.3688],\n",
            "        [-2.0550,  0.0895,  1.3609],\n",
            "        [-1.8006,  1.3332,  0.2649],\n",
            "        [-1.8937,  2.1801, -0.3695],\n",
            "        [-1.2686,  1.3187, -0.2085],\n",
            "        [-1.7404,  2.0376, -0.3996],\n",
            "        [-1.7048,  1.9540, -0.4213],\n",
            "        [-2.1909,  0.3512,  1.7142],\n",
            "        [-1.8448,  2.0232, -0.3212],\n",
            "        [-1.7126,  2.1231, -0.4284],\n",
            "        [-1.7621,  1.9207, -0.4148]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5847,  1.7640, -0.4502],\n",
            "        [-1.9071,  0.3479,  1.3520],\n",
            "        [-1.8215,  2.0813, -0.2957],\n",
            "        [-1.5355,  2.0370, -0.5476],\n",
            "        [-1.7685,  1.9947, -0.3459],\n",
            "        [-1.8164,  1.8916, -0.3688],\n",
            "        [-2.0550,  0.0895,  1.3609],\n",
            "        [-1.8006,  1.3332,  0.2649],\n",
            "        [-1.8937,  2.1801, -0.3695],\n",
            "        [-1.2686,  1.3187, -0.2085],\n",
            "        [-1.7404,  2.0376, -0.3996],\n",
            "        [-1.7048,  1.9540, -0.4213],\n",
            "        [-2.1909,  0.3512,  1.7142],\n",
            "        [-1.8448,  2.0232, -0.3212],\n",
            "        [-1.7126,  2.1231, -0.4284],\n",
            "        [-1.7621,  1.9207, -0.4148]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9186,  0.2574,  1.4176],\n",
            "        [-1.8974,  0.1097,  1.5442],\n",
            "        [-1.5781,  1.7488, -0.4264],\n",
            "        [-1.8392,  2.0683, -0.5190],\n",
            "        [-1.7877,  2.0661, -0.6208],\n",
            "        [ 0.6743, -0.3073, -0.7801],\n",
            "        [-1.8219,  1.9188, -0.5094],\n",
            "        [-1.5631,  1.7787, -0.3773],\n",
            "        [-1.7562,  1.9828, -0.2961],\n",
            "        [-1.7402,  0.1082,  1.4247],\n",
            "        [-1.8195,  1.9928, -0.2140],\n",
            "        [-2.0146,  0.3431,  1.5188],\n",
            "        [-1.7388,  2.1065, -0.4431],\n",
            "        [-1.7144,  1.9813, -0.3261],\n",
            "        [-1.7174,  1.6245, -0.1371],\n",
            "        [-1.7476,  0.3184,  1.2421]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9186,  0.2574,  1.4176],\n",
            "        [-1.8974,  0.1097,  1.5442],\n",
            "        [-1.5781,  1.7488, -0.4264],\n",
            "        [-1.8392,  2.0683, -0.5190],\n",
            "        [-1.7877,  2.0661, -0.6208],\n",
            "        [ 0.6743, -0.3073, -0.7801],\n",
            "        [-1.8219,  1.9188, -0.5094],\n",
            "        [-1.5631,  1.7787, -0.3773],\n",
            "        [-1.7562,  1.9828, -0.2961],\n",
            "        [-1.7402,  0.1082,  1.4247],\n",
            "        [-1.8195,  1.9928, -0.2140],\n",
            "        [-2.0146,  0.3431,  1.5188],\n",
            "        [-1.7388,  2.1065, -0.4431],\n",
            "        [-1.7144,  1.9813, -0.3261],\n",
            "        [-1.7174,  1.6245, -0.1371],\n",
            "        [-1.7476,  0.3184,  1.2421]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5704, -0.3328, -0.6943],\n",
            "        [-1.9281,  0.3699,  1.3292],\n",
            "        [-1.7607,  0.1924,  1.1065],\n",
            "        [-0.5921,  1.1009, -1.0372],\n",
            "        [-1.9193,  0.2616,  1.5664],\n",
            "        [-1.9566,  0.2193,  1.3815],\n",
            "        [ 0.5289, -0.3962, -0.8371],\n",
            "        [-2.0668,  0.3114,  1.2892],\n",
            "        [-0.0749, -0.1925, -0.2281],\n",
            "        [-1.6824,  2.0281, -0.4394],\n",
            "        [-1.8515,  0.1497,  1.4560],\n",
            "        [-1.8262,  1.6851, -0.1404],\n",
            "        [-1.8116,  2.0586, -0.2431],\n",
            "        [-1.4792,  1.9161, -0.4992],\n",
            "        [-1.7867,  0.2142,  1.3349],\n",
            "        [-1.9693,  0.0687,  1.2284]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.5704, -0.3328, -0.6943],\n",
            "        [-1.9281,  0.3699,  1.3292],\n",
            "        [-1.7607,  0.1924,  1.1065],\n",
            "        [-0.5921,  1.1009, -1.0372],\n",
            "        [-1.9193,  0.2616,  1.5664],\n",
            "        [-1.9566,  0.2193,  1.3815],\n",
            "        [ 0.5289, -0.3962, -0.8371],\n",
            "        [-2.0668,  0.3114,  1.2892],\n",
            "        [-0.0749, -0.1925, -0.2281],\n",
            "        [-1.6824,  2.0281, -0.4394],\n",
            "        [-1.8515,  0.1497,  1.4560],\n",
            "        [-1.8262,  1.6851, -0.1404],\n",
            "        [-1.8116,  2.0586, -0.2431],\n",
            "        [-1.4792,  1.9161, -0.4992],\n",
            "        [-1.7867,  0.2142,  1.3349],\n",
            "        [-1.9693,  0.0687,  1.2284]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0860,  1.3141,  0.7167],\n",
            "        [-2.0381,  1.8258, -0.0391],\n",
            "        [-1.6240,  1.8675, -0.4273],\n",
            "        [-1.6539,  1.7705, -0.4562],\n",
            "        [-1.8660,  0.3671,  1.1213],\n",
            "        [-1.5852,  1.8608, -0.4807],\n",
            "        [-1.8636,  2.0071, -0.1424],\n",
            "        [-1.7810,  1.8698, -0.4626],\n",
            "        [-1.6223,  2.0465, -0.6581],\n",
            "        [-1.8972,  0.4639,  1.5095],\n",
            "        [ 0.7311, -0.4260, -0.7428],\n",
            "        [-1.6642,  1.9891, -0.6145],\n",
            "        [-1.7362,  0.2510,  1.2961],\n",
            "        [-1.7171,  1.9493, -0.4033],\n",
            "        [-1.5660,  1.7689, -0.4048],\n",
            "        [-1.7601,  1.6284, -0.2655]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0860,  1.3141,  0.7167],\n",
            "        [-2.0381,  1.8258, -0.0391],\n",
            "        [-1.6240,  1.8675, -0.4273],\n",
            "        [-1.6539,  1.7705, -0.4562],\n",
            "        [-1.8660,  0.3671,  1.1213],\n",
            "        [-1.5852,  1.8608, -0.4807],\n",
            "        [-1.8636,  2.0071, -0.1424],\n",
            "        [-1.7810,  1.8698, -0.4626],\n",
            "        [-1.6223,  2.0465, -0.6581],\n",
            "        [-1.8972,  0.4639,  1.5095],\n",
            "        [ 0.7311, -0.4260, -0.7428],\n",
            "        [-1.6642,  1.9891, -0.6145],\n",
            "        [-1.7362,  0.2510,  1.2961],\n",
            "        [-1.7171,  1.9493, -0.4033],\n",
            "        [-1.5660,  1.7689, -0.4048],\n",
            "        [-1.7601,  1.6284, -0.2655]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8199,  0.3822,  1.2776],\n",
            "        [-1.5390,  1.7917, -0.5264],\n",
            "        [-1.9156,  0.3068,  1.3451],\n",
            "        [-1.8280,  1.9841, -0.5177],\n",
            "        [-1.8512,  0.4016,  1.2880],\n",
            "        [-1.5528,  2.0575, -0.5039],\n",
            "        [-1.6546,  2.0537, -0.7152],\n",
            "        [-1.9283,  0.4279,  1.3940],\n",
            "        [-1.7788,  1.8817, -0.3454],\n",
            "        [-1.7706,  1.8674, -0.4783],\n",
            "        [-2.1220,  0.5930,  1.1646],\n",
            "        [-1.8139,  1.9901, -0.2620],\n",
            "        [-1.7798,  0.3212,  1.3207],\n",
            "        [-1.9965,  0.5315,  1.4303],\n",
            "        [-1.5932,  1.9364, -0.4399],\n",
            "        [-1.6544,  1.8425, -0.4065]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8199,  0.3822,  1.2776],\n",
            "        [-1.5390,  1.7917, -0.5264],\n",
            "        [-1.9156,  0.3068,  1.3451],\n",
            "        [-1.8280,  1.9841, -0.5177],\n",
            "        [-1.8512,  0.4016,  1.2880],\n",
            "        [-1.5528,  2.0575, -0.5039],\n",
            "        [-1.6546,  2.0537, -0.7152],\n",
            "        [-1.9283,  0.4279,  1.3940],\n",
            "        [-1.7788,  1.8817, -0.3454],\n",
            "        [-1.7706,  1.8674, -0.4783],\n",
            "        [-2.1220,  0.5930,  1.1646],\n",
            "        [-1.8139,  1.9901, -0.2620],\n",
            "        [-1.7798,  0.3212,  1.3207],\n",
            "        [-1.9965,  0.5315,  1.4303],\n",
            "        [-1.5932,  1.9364, -0.4399],\n",
            "        [-1.6544,  1.8425, -0.4065]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5514,  1.7810, -0.3237],\n",
            "        [-1.6858,  1.9327, -0.4579],\n",
            "        [-1.6774,  2.0548, -0.4737],\n",
            "        [-1.7164,  1.8876, -0.5156],\n",
            "        [-1.8277,  0.3859,  1.3495],\n",
            "        [ 0.3942,  0.0201, -1.1379],\n",
            "        [-1.5835,  1.9065, -0.4923],\n",
            "        [-1.8262,  0.3353,  1.4903],\n",
            "        [-1.4625,  1.5044, -0.2503],\n",
            "        [-1.5234,  1.7533, -0.3024],\n",
            "        [-1.8506,  1.9012, -0.1037],\n",
            "        [-1.6675,  1.7196, -0.4873],\n",
            "        [-1.6990,  2.0454, -0.3579],\n",
            "        [-2.0034,  0.5382,  1.2115],\n",
            "        [-1.7657,  1.4260, -0.3912],\n",
            "        [-1.4803,  1.7424, -0.3896]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5514,  1.7810, -0.3237],\n",
            "        [-1.6858,  1.9327, -0.4579],\n",
            "        [-1.6774,  2.0548, -0.4737],\n",
            "        [-1.7164,  1.8876, -0.5156],\n",
            "        [-1.8277,  0.3859,  1.3495],\n",
            "        [ 0.3942,  0.0201, -1.1379],\n",
            "        [-1.5835,  1.9065, -0.4923],\n",
            "        [-1.8262,  0.3353,  1.4903],\n",
            "        [-1.4625,  1.5044, -0.2503],\n",
            "        [-1.5234,  1.7533, -0.3024],\n",
            "        [-1.8506,  1.9012, -0.1037],\n",
            "        [-1.6675,  1.7196, -0.4873],\n",
            "        [-1.6990,  2.0454, -0.3579],\n",
            "        [-2.0034,  0.5382,  1.2115],\n",
            "        [-1.7657,  1.4260, -0.3912],\n",
            "        [-1.4803,  1.7424, -0.3896]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6612,  1.8865, -0.4084],\n",
            "        [-1.6985,  1.8803, -0.2423],\n",
            "        [-2.1013,  1.0445,  0.7445],\n",
            "        [-1.7314,  2.0948, -0.5667],\n",
            "        [-1.7128,  0.4799,  1.3220],\n",
            "        [ 0.1025,  0.4923, -1.0277],\n",
            "        [-1.6155,  1.6099, -0.2899],\n",
            "        [-1.6524,  1.9676, -0.4198],\n",
            "        [-1.7581,  2.0037, -0.5390],\n",
            "        [-1.6403,  1.7646, -0.3182],\n",
            "        [-1.8065,  1.7631, -0.3548],\n",
            "        [-1.8500,  1.9595, -0.4595],\n",
            "        [-0.3361,  0.9178, -0.9599],\n",
            "        [-1.4714,  1.9567, -0.6257],\n",
            "        [-1.9631,  0.4512,  1.2557],\n",
            "        [-1.1757,  0.0823,  1.0122]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6612,  1.8865, -0.4084],\n",
            "        [-1.6985,  1.8803, -0.2423],\n",
            "        [-2.1013,  1.0445,  0.7445],\n",
            "        [-1.7314,  2.0948, -0.5667],\n",
            "        [-1.7128,  0.4799,  1.3220],\n",
            "        [ 0.1025,  0.4923, -1.0277],\n",
            "        [-1.6155,  1.6099, -0.2899],\n",
            "        [-1.6524,  1.9676, -0.4198],\n",
            "        [-1.7581,  2.0037, -0.5390],\n",
            "        [-1.6403,  1.7646, -0.3182],\n",
            "        [-1.8065,  1.7631, -0.3548],\n",
            "        [-1.8500,  1.9595, -0.4595],\n",
            "        [-0.3361,  0.9178, -0.9599],\n",
            "        [-1.4714,  1.9567, -0.6257],\n",
            "        [-1.9631,  0.4512,  1.2557],\n",
            "        [-1.1757,  0.0823,  1.0122]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4349e+00,  1.7506e+00, -2.7144e-01],\n",
            "        [-2.0397e+00,  5.9577e-01,  1.2960e+00],\n",
            "        [-1.7220e+00,  1.8245e+00, -2.6808e-01],\n",
            "        [-1.5946e+00,  1.8844e+00, -2.8326e-01],\n",
            "        [-1.6721e+00,  1.8843e+00, -4.1333e-01],\n",
            "        [ 6.2858e-01, -3.6403e-01, -8.3379e-01],\n",
            "        [-1.8233e+00,  3.8058e-01,  1.0640e+00],\n",
            "        [-1.6307e+00,  1.6612e+00, -4.5697e-01],\n",
            "        [ 6.4083e-01, -1.6829e-01, -8.5690e-01],\n",
            "        [-1.7498e+00,  1.6035e+00,  5.5818e-04],\n",
            "        [-1.7939e+00,  3.9197e-01,  1.1163e+00],\n",
            "        [-2.6458e-01, -2.3657e-01,  4.5358e-03],\n",
            "        [-2.1880e+00,  1.0367e+00,  6.0173e-01],\n",
            "        [-1.2593e+00,  1.0565e+00, -2.3042e-01],\n",
            "        [-1.8768e+00,  2.0021e+00, -5.0798e-01],\n",
            "        [-2.1312e+00,  5.7647e-01,  1.3473e+00]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4349e+00,  1.7506e+00, -2.7144e-01],\n",
            "        [-2.0397e+00,  5.9577e-01,  1.2960e+00],\n",
            "        [-1.7220e+00,  1.8245e+00, -2.6808e-01],\n",
            "        [-1.5946e+00,  1.8844e+00, -2.8326e-01],\n",
            "        [-1.6721e+00,  1.8843e+00, -4.1333e-01],\n",
            "        [ 6.2858e-01, -3.6403e-01, -8.3379e-01],\n",
            "        [-1.8233e+00,  3.8058e-01,  1.0640e+00],\n",
            "        [-1.6307e+00,  1.6612e+00, -4.5697e-01],\n",
            "        [ 6.4083e-01, -1.6829e-01, -8.5690e-01],\n",
            "        [-1.7498e+00,  1.6035e+00,  5.5818e-04],\n",
            "        [-1.7939e+00,  3.9197e-01,  1.1163e+00],\n",
            "        [-2.6458e-01, -2.3657e-01,  4.5358e-03],\n",
            "        [-2.1880e+00,  1.0367e+00,  6.0173e-01],\n",
            "        [-1.2593e+00,  1.0565e+00, -2.3042e-01],\n",
            "        [-1.8768e+00,  2.0021e+00, -5.0798e-01],\n",
            "        [-2.1312e+00,  5.7647e-01,  1.3473e+00]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9318,  0.4461,  1.5011],\n",
            "        [-1.5309,  1.8706, -0.2954],\n",
            "        [-1.9473,  0.3233,  0.9567],\n",
            "        [-1.6929,  1.5563, -0.2980],\n",
            "        [-1.7846,  0.8876,  0.6146],\n",
            "        [ 0.6336, -0.2969, -0.7195],\n",
            "        [-0.1847,  0.0909, -0.2780],\n",
            "        [-1.3790,  1.6249, -0.6997],\n",
            "        [-1.5929,  1.9102, -0.5617],\n",
            "        [-1.6567,  1.9890, -0.2723],\n",
            "        [-1.8597,  1.8970,  0.0468],\n",
            "        [ 0.7300, -0.4344, -0.8166],\n",
            "        [-1.5871,  1.6681, -0.4566],\n",
            "        [-1.9420,  1.9571, -0.2903],\n",
            "        [-1.4514,  1.7650, -0.4473],\n",
            "        [-1.7827,  1.9673, -0.5086]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9318,  0.4461,  1.5011],\n",
            "        [-1.5309,  1.8706, -0.2954],\n",
            "        [-1.9473,  0.3233,  0.9567],\n",
            "        [-1.6929,  1.5563, -0.2980],\n",
            "        [-1.7846,  0.8876,  0.6146],\n",
            "        [ 0.6336, -0.2969, -0.7195],\n",
            "        [-0.1847,  0.0909, -0.2780],\n",
            "        [-1.3790,  1.6249, -0.6997],\n",
            "        [-1.5929,  1.9102, -0.5617],\n",
            "        [-1.6567,  1.9890, -0.2723],\n",
            "        [-1.8597,  1.8970,  0.0468],\n",
            "        [ 0.7300, -0.4344, -0.8166],\n",
            "        [-1.5871,  1.6681, -0.4566],\n",
            "        [-1.9420,  1.9571, -0.2903],\n",
            "        [-1.4514,  1.7650, -0.4473],\n",
            "        [-1.7827,  1.9673, -0.5086]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6808,  1.8377, -0.2857],\n",
            "        [ 0.4948, -0.3155, -0.8937],\n",
            "        [-1.8199,  1.9609, -0.1825],\n",
            "        [ 0.1908,  0.4005, -1.1673],\n",
            "        [-1.8100,  0.4624,  1.1128],\n",
            "        [-1.5951,  1.8130, -0.4154],\n",
            "        [-1.3356,  1.9255, -0.4149],\n",
            "        [-1.8264,  1.2003,  0.4749],\n",
            "        [-1.8942,  0.5149,  1.2509],\n",
            "        [-1.7755,  1.7964, -0.1060],\n",
            "        [-1.9382,  0.5967,  1.2037],\n",
            "        [-1.5276,  1.9418, -0.4981],\n",
            "        [-1.6276,  1.5943, -0.4725],\n",
            "        [-1.8572,  1.9237, -0.1621],\n",
            "        [-1.9186,  0.3889,  1.2105],\n",
            "        [-1.1996,  1.5869, -0.6414]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6808,  1.8377, -0.2857],\n",
            "        [ 0.4948, -0.3155, -0.8937],\n",
            "        [-1.8199,  1.9609, -0.1825],\n",
            "        [ 0.1908,  0.4005, -1.1673],\n",
            "        [-1.8100,  0.4624,  1.1128],\n",
            "        [-1.5951,  1.8130, -0.4154],\n",
            "        [-1.3356,  1.9255, -0.4149],\n",
            "        [-1.8264,  1.2003,  0.4749],\n",
            "        [-1.8942,  0.5149,  1.2509],\n",
            "        [-1.7755,  1.7964, -0.1060],\n",
            "        [-1.9382,  0.5967,  1.2037],\n",
            "        [-1.5276,  1.9418, -0.4981],\n",
            "        [-1.6276,  1.5943, -0.4725],\n",
            "        [-1.8572,  1.9237, -0.1621],\n",
            "        [-1.9186,  0.3889,  1.2105],\n",
            "        [-1.1996,  1.5869, -0.6414]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9132,  0.5224,  1.1151],\n",
            "        [-1.6913,  1.7883, -0.3674],\n",
            "        [-1.6099,  1.9169, -0.4747],\n",
            "        [-1.7291,  0.4365,  1.1320],\n",
            "        [-1.6515,  1.9381, -0.2421],\n",
            "        [-1.5405,  1.8702, -0.3196],\n",
            "        [ 0.6404, -0.1465, -1.0495],\n",
            "        [-2.2375,  0.8080,  0.9239],\n",
            "        [ 0.0680,  0.3771, -1.0868],\n",
            "        [-1.6456,  1.8424, -0.3791],\n",
            "        [-1.8056,  0.6629,  1.1853],\n",
            "        [-1.5666,  1.7533, -0.4090],\n",
            "        [-1.6741,  1.9242, -0.1690],\n",
            "        [ 0.6957, -0.2122, -0.8684],\n",
            "        [-0.2868,  0.7828, -1.0843],\n",
            "        [-1.6127,  1.6573, -0.3695]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9132,  0.5224,  1.1151],\n",
            "        [-1.6913,  1.7883, -0.3674],\n",
            "        [-1.6099,  1.9169, -0.4747],\n",
            "        [-1.7291,  0.4365,  1.1320],\n",
            "        [-1.6515,  1.9381, -0.2421],\n",
            "        [-1.5405,  1.8702, -0.3196],\n",
            "        [ 0.6404, -0.1465, -1.0495],\n",
            "        [-2.2375,  0.8080,  0.9239],\n",
            "        [ 0.0680,  0.3771, -1.0868],\n",
            "        [-1.6456,  1.8424, -0.3791],\n",
            "        [-1.8056,  0.6629,  1.1853],\n",
            "        [-1.5666,  1.7533, -0.4090],\n",
            "        [-1.6741,  1.9242, -0.1690],\n",
            "        [ 0.6957, -0.2122, -0.8684],\n",
            "        [-0.2868,  0.7828, -1.0843],\n",
            "        [-1.6127,  1.6573, -0.3695]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8414,  1.9981, -0.5238],\n",
            "        [-2.0437,  0.5741,  1.1347],\n",
            "        [-1.7305,  1.5719, -0.2109],\n",
            "        [-1.8016,  1.8491, -0.2870],\n",
            "        [-1.9364,  0.5786,  1.2609],\n",
            "        [ 0.7014, -0.3250, -0.8755],\n",
            "        [-1.5959,  1.6687, -0.4181],\n",
            "        [-1.6542,  1.7587, -0.1969],\n",
            "        [ 0.2341,  0.4500, -1.0398],\n",
            "        [-1.5708,  1.7218, -0.3547],\n",
            "        [-1.5997,  0.4809,  0.9966],\n",
            "        [-0.5918,  1.1108, -0.8138],\n",
            "        [-1.3145,  1.7891, -0.9156],\n",
            "        [-1.8129,  1.6749, -0.1850],\n",
            "        [-1.9259,  1.8596, -0.3740],\n",
            "        [-1.7846,  1.7778, -0.4027]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8414,  1.9981, -0.5238],\n",
            "        [-2.0437,  0.5741,  1.1347],\n",
            "        [-1.7305,  1.5719, -0.2109],\n",
            "        [-1.8016,  1.8491, -0.2870],\n",
            "        [-1.9364,  0.5786,  1.2609],\n",
            "        [ 0.7014, -0.3250, -0.8755],\n",
            "        [-1.5959,  1.6687, -0.4181],\n",
            "        [-1.6542,  1.7587, -0.1969],\n",
            "        [ 0.2341,  0.4500, -1.0398],\n",
            "        [-1.5708,  1.7218, -0.3547],\n",
            "        [-1.5997,  0.4809,  0.9966],\n",
            "        [-0.5918,  1.1108, -0.8138],\n",
            "        [-1.3145,  1.7891, -0.9156],\n",
            "        [-1.8129,  1.6749, -0.1850],\n",
            "        [-1.9259,  1.8596, -0.3740],\n",
            "        [-1.7846,  1.7778, -0.4027]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6767,  1.6492, -0.1980],\n",
            "        [ 0.5093, -0.1468, -0.9827],\n",
            "        [-1.8809,  1.9651, -0.3052],\n",
            "        [-1.6596,  0.4154,  1.1613],\n",
            "        [-1.6018,  1.7797, -0.4107],\n",
            "        [-1.8258,  1.7629,  0.0566],\n",
            "        [-1.9989,  1.4731,  0.2596],\n",
            "        [-1.8166,  1.1891,  0.4711],\n",
            "        [-1.7727,  1.9004, -0.3694],\n",
            "        [-1.7367,  0.5287,  0.9877],\n",
            "        [ 0.5889, -0.0846, -0.7587],\n",
            "        [-1.6779,  0.4410,  1.3148],\n",
            "        [-1.6185,  1.8742, -0.2694],\n",
            "        [-1.7082,  1.6684, -0.1952],\n",
            "        [-1.5162,  2.0016, -0.4487],\n",
            "        [-1.5803,  1.6510, -0.4539]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6767,  1.6492, -0.1980],\n",
            "        [ 0.5093, -0.1468, -0.9827],\n",
            "        [-1.8809,  1.9651, -0.3052],\n",
            "        [-1.6596,  0.4154,  1.1613],\n",
            "        [-1.6018,  1.7797, -0.4107],\n",
            "        [-1.8258,  1.7629,  0.0566],\n",
            "        [-1.9989,  1.4731,  0.2596],\n",
            "        [-1.8166,  1.1891,  0.4711],\n",
            "        [-1.7727,  1.9004, -0.3694],\n",
            "        [-1.7367,  0.5287,  0.9877],\n",
            "        [ 0.5889, -0.0846, -0.7587],\n",
            "        [-1.6779,  0.4410,  1.3148],\n",
            "        [-1.6185,  1.8742, -0.2694],\n",
            "        [-1.7082,  1.6684, -0.1952],\n",
            "        [-1.5162,  2.0016, -0.4487],\n",
            "        [-1.5803,  1.6510, -0.4539]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.6198, -0.2798, -0.9268],\n",
            "        [-1.4860,  1.6372, -0.3152],\n",
            "        [-1.7033,  1.6936, -0.2214],\n",
            "        [-1.6870,  0.4535,  1.1260],\n",
            "        [-1.7873,  1.7778, -0.3314],\n",
            "        [-1.6655,  1.6955, -0.5334],\n",
            "        [ 0.8095, -0.1772, -0.9347],\n",
            "        [-1.2176,  1.7860, -0.4211],\n",
            "        [-1.6838,  0.5048,  1.1266],\n",
            "        [ 0.6952, -0.4254, -0.7693],\n",
            "        [-1.7272,  0.5229,  1.0783],\n",
            "        [-1.6462,  1.6843, -0.3449],\n",
            "        [-1.0441,  1.2587, -0.5530],\n",
            "        [ 0.5353, -0.1000, -0.9311],\n",
            "        [-1.9007,  1.6606,  0.1321],\n",
            "        [-1.5769,  1.5444, -0.2287]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.6198, -0.2798, -0.9268],\n",
            "        [-1.4860,  1.6372, -0.3152],\n",
            "        [-1.7033,  1.6936, -0.2214],\n",
            "        [-1.6870,  0.4535,  1.1260],\n",
            "        [-1.7873,  1.7778, -0.3314],\n",
            "        [-1.6655,  1.6955, -0.5334],\n",
            "        [ 0.8095, -0.1772, -0.9347],\n",
            "        [-1.2176,  1.7860, -0.4211],\n",
            "        [-1.6838,  0.5048,  1.1266],\n",
            "        [ 0.6952, -0.4254, -0.7693],\n",
            "        [-1.7272,  0.5229,  1.0783],\n",
            "        [-1.6462,  1.6843, -0.3449],\n",
            "        [-1.0441,  1.2587, -0.5530],\n",
            "        [ 0.5353, -0.1000, -0.9311],\n",
            "        [-1.9007,  1.6606,  0.1321],\n",
            "        [-1.5769,  1.5444, -0.2287]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0720,  0.8250,  0.9116],\n",
            "        [-1.8440,  1.8419, -0.3867],\n",
            "        [-1.7144,  1.8183, -0.5590],\n",
            "        [-1.8009,  1.7881, -0.2946],\n",
            "        [-1.7953,  1.5042, -0.0489],\n",
            "        [-1.7321,  1.9809, -0.3528],\n",
            "        [-1.7212,  1.9055, -0.1863],\n",
            "        [-1.7379,  1.7611, -0.2437],\n",
            "        [-1.8300,  0.5146,  1.0621],\n",
            "        [-1.7424,  1.7703,  0.1453],\n",
            "        [-1.8370,  0.2897,  1.2636],\n",
            "        [-1.9216,  0.6810,  0.9194],\n",
            "        [-1.7865,  1.8500, -0.4751],\n",
            "        [-1.8571,  0.7625,  1.1031],\n",
            "        [-1.8632,  0.7188,  0.7906],\n",
            "        [-1.8619,  2.0693, -0.4092]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0720,  0.8250,  0.9116],\n",
            "        [-1.8440,  1.8419, -0.3867],\n",
            "        [-1.7144,  1.8183, -0.5590],\n",
            "        [-1.8009,  1.7881, -0.2946],\n",
            "        [-1.7953,  1.5042, -0.0489],\n",
            "        [-1.7321,  1.9809, -0.3528],\n",
            "        [-1.7212,  1.9055, -0.1863],\n",
            "        [-1.7379,  1.7611, -0.2437],\n",
            "        [-1.8300,  0.5146,  1.0621],\n",
            "        [-1.7424,  1.7703,  0.1453],\n",
            "        [-1.8370,  0.2897,  1.2636],\n",
            "        [-1.9216,  0.6810,  0.9194],\n",
            "        [-1.7865,  1.8500, -0.4751],\n",
            "        [-1.8571,  0.7625,  1.1031],\n",
            "        [-1.8632,  0.7188,  0.7906],\n",
            "        [-1.8619,  2.0693, -0.4092]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5818,  1.7307, -0.0100],\n",
            "        [-1.5188,  1.8058, -0.2931],\n",
            "        [-1.8103,  0.7057,  0.8654],\n",
            "        [-1.7951,  1.9965, -0.1571],\n",
            "        [-1.7970,  0.5691,  1.1387],\n",
            "        [ 0.6320, -0.3138, -0.9932],\n",
            "        [-1.7005,  0.6328,  1.0155],\n",
            "        [-1.8171,  2.2183, -0.1769],\n",
            "        [-1.9537,  0.7035,  1.1944],\n",
            "        [-1.5601,  1.7115, -0.3407],\n",
            "        [ 0.6182, -0.2395, -0.7269],\n",
            "        [-1.6750,  1.6891, -0.3279],\n",
            "        [-1.6717,  1.5079, -0.1605],\n",
            "        [-2.0380,  1.1643,  0.5203],\n",
            "        [-1.6337,  1.8013, -0.3706],\n",
            "        [-1.7594,  1.8112, -0.3949]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5818,  1.7307, -0.0100],\n",
            "        [-1.5188,  1.8058, -0.2931],\n",
            "        [-1.8103,  0.7057,  0.8654],\n",
            "        [-1.7951,  1.9965, -0.1571],\n",
            "        [-1.7970,  0.5691,  1.1387],\n",
            "        [ 0.6320, -0.3138, -0.9932],\n",
            "        [-1.7005,  0.6328,  1.0155],\n",
            "        [-1.8171,  2.2183, -0.1769],\n",
            "        [-1.9537,  0.7035,  1.1944],\n",
            "        [-1.5601,  1.7115, -0.3407],\n",
            "        [ 0.6182, -0.2395, -0.7269],\n",
            "        [-1.6750,  1.6891, -0.3279],\n",
            "        [-1.6717,  1.5079, -0.1605],\n",
            "        [-2.0380,  1.1643,  0.5203],\n",
            "        [-1.6337,  1.8013, -0.3706],\n",
            "        [-1.7594,  1.8112, -0.3949]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8532,  0.6356,  1.0969],\n",
            "        [-1.6807,  0.4110,  1.0215],\n",
            "        [-1.4171,  1.6790, -0.4349],\n",
            "        [-1.5586,  1.8224, -0.1758],\n",
            "        [-1.8866,  1.0202,  0.7121],\n",
            "        [ 0.6805, -0.0520, -0.9430],\n",
            "        [-1.9756,  0.6376,  1.1185],\n",
            "        [-1.8111,  1.6867, -0.3451],\n",
            "        [-1.4822,  1.6758, -0.2560],\n",
            "        [-1.4308,  1.7800, -0.1697],\n",
            "        [-1.9471,  0.6508,  1.0770],\n",
            "        [-1.6767,  0.6382,  0.8834],\n",
            "        [-1.8228,  1.6268,  0.1539],\n",
            "        [-1.8647,  0.2842,  1.0481],\n",
            "        [-1.6240,  1.9044, -0.2203],\n",
            "        [-1.8761,  1.8542, -0.3398]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8532,  0.6356,  1.0969],\n",
            "        [-1.6807,  0.4110,  1.0215],\n",
            "        [-1.4171,  1.6790, -0.4349],\n",
            "        [-1.5586,  1.8224, -0.1758],\n",
            "        [-1.8866,  1.0202,  0.7121],\n",
            "        [ 0.6805, -0.0520, -0.9430],\n",
            "        [-1.9756,  0.6376,  1.1185],\n",
            "        [-1.8111,  1.6867, -0.3451],\n",
            "        [-1.4822,  1.6758, -0.2560],\n",
            "        [-1.4308,  1.7800, -0.1697],\n",
            "        [-1.9471,  0.6508,  1.0770],\n",
            "        [-1.6767,  0.6382,  0.8834],\n",
            "        [-1.8228,  1.6268,  0.1539],\n",
            "        [-1.8647,  0.2842,  1.0481],\n",
            "        [-1.6240,  1.9044, -0.2203],\n",
            "        [-1.8761,  1.8542, -0.3398]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8810,  1.9750, -0.3237],\n",
            "        [-1.4676,  1.5046, -0.1602],\n",
            "        [ 0.7168, -0.3869, -0.7781],\n",
            "        [ 0.7472, -0.1534, -1.1688],\n",
            "        [-1.5628,  1.6055, -0.2072],\n",
            "        [ 0.5185, -0.0114, -1.0760],\n",
            "        [-1.9196,  2.0299, -0.3580],\n",
            "        [-1.6262,  1.9538, -0.2008],\n",
            "        [-1.2698,  1.5683, -0.5064],\n",
            "        [-2.0569,  1.8267, -0.2379],\n",
            "        [-1.8383,  1.8866, -0.0169],\n",
            "        [ 0.5167, -0.0026, -1.0254],\n",
            "        [ 0.7509, -0.3103, -0.7018],\n",
            "        [-1.5739,  1.5021, -0.3466],\n",
            "        [-1.6032,  1.8305, -0.2602],\n",
            "        [-1.9017,  0.5542,  1.0930]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8810,  1.9750, -0.3237],\n",
            "        [-1.4676,  1.5046, -0.1602],\n",
            "        [ 0.7168, -0.3869, -0.7781],\n",
            "        [ 0.7472, -0.1534, -1.1688],\n",
            "        [-1.5628,  1.6055, -0.2072],\n",
            "        [ 0.5185, -0.0114, -1.0760],\n",
            "        [-1.9196,  2.0299, -0.3580],\n",
            "        [-1.6262,  1.9538, -0.2008],\n",
            "        [-1.2698,  1.5683, -0.5064],\n",
            "        [-2.0569,  1.8267, -0.2379],\n",
            "        [-1.8383,  1.8866, -0.0169],\n",
            "        [ 0.5167, -0.0026, -1.0254],\n",
            "        [ 0.7509, -0.3103, -0.7018],\n",
            "        [-1.5739,  1.5021, -0.3466],\n",
            "        [-1.6032,  1.8305, -0.2602],\n",
            "        [-1.9017,  0.5542,  1.0930]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9621,  1.6353, -0.1883],\n",
            "        [-2.1103,  0.7259,  1.0725],\n",
            "        [-1.9194,  1.8513, -0.1834],\n",
            "        [-1.8333,  0.8279,  0.6127],\n",
            "        [-1.9936,  1.9200, -0.1437],\n",
            "        [-1.8456,  0.6315,  1.1247],\n",
            "        [-1.7952,  0.7233,  0.8319],\n",
            "        [-1.7978,  1.4449,  0.0321],\n",
            "        [ 0.5661, -0.2404, -1.0037],\n",
            "        [-1.8980,  1.6257, -0.1360],\n",
            "        [-1.7854,  1.7362, -0.1798],\n",
            "        [-1.9499,  1.8857, -0.1898],\n",
            "        [-1.6396,  1.7487, -0.2008],\n",
            "        [ 0.8867, -0.2198, -0.9794],\n",
            "        [-1.6825,  1.7851, -0.2686],\n",
            "        [-1.6297,  1.6531, -0.3434]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9621,  1.6353, -0.1883],\n",
            "        [-2.1103,  0.7259,  1.0725],\n",
            "        [-1.9194,  1.8513, -0.1834],\n",
            "        [-1.8333,  0.8279,  0.6127],\n",
            "        [-1.9936,  1.9200, -0.1437],\n",
            "        [-1.8456,  0.6315,  1.1247],\n",
            "        [-1.7952,  0.7233,  0.8319],\n",
            "        [-1.7978,  1.4449,  0.0321],\n",
            "        [ 0.5661, -0.2404, -1.0037],\n",
            "        [-1.8980,  1.6257, -0.1360],\n",
            "        [-1.7854,  1.7362, -0.1798],\n",
            "        [-1.9499,  1.8857, -0.1898],\n",
            "        [-1.6396,  1.7487, -0.2008],\n",
            "        [ 0.8867, -0.2198, -0.9794],\n",
            "        [-1.6825,  1.7851, -0.2686],\n",
            "        [-1.6297,  1.6531, -0.3434]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5235, -0.1596, -1.0515],\n",
            "        [-2.0008,  0.9451,  0.8715],\n",
            "        [-1.7539,  0.6929,  1.1001],\n",
            "        [ 0.8715, -0.1971, -0.9206],\n",
            "        [-1.6089,  0.5519,  1.0736],\n",
            "        [-1.8643,  1.6061,  0.2204],\n",
            "        [-1.8333,  0.7118,  0.8698],\n",
            "        [-1.9142,  0.5792,  0.9814],\n",
            "        [ 0.6513, -0.2879, -1.0481],\n",
            "        [-1.9182,  1.8745, -0.1743],\n",
            "        [-1.7487,  1.8204, -0.1222],\n",
            "        [-1.9172,  0.6942,  1.0129],\n",
            "        [-1.4045,  1.6950, -0.2625],\n",
            "        [-1.8222,  0.7161,  1.0663],\n",
            "        [-1.9684,  1.9730, -0.0756],\n",
            "        [-1.9074,  1.0379,  0.8543]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.5235, -0.1596, -1.0515],\n",
            "        [-2.0008,  0.9451,  0.8715],\n",
            "        [-1.7539,  0.6929,  1.1001],\n",
            "        [ 0.8715, -0.1971, -0.9206],\n",
            "        [-1.6089,  0.5519,  1.0736],\n",
            "        [-1.8643,  1.6061,  0.2204],\n",
            "        [-1.8333,  0.7118,  0.8698],\n",
            "        [-1.9142,  0.5792,  0.9814],\n",
            "        [ 0.6513, -0.2879, -1.0481],\n",
            "        [-1.9182,  1.8745, -0.1743],\n",
            "        [-1.7487,  1.8204, -0.1222],\n",
            "        [-1.9172,  0.6942,  1.0129],\n",
            "        [-1.4045,  1.6950, -0.2625],\n",
            "        [-1.8222,  0.7161,  1.0663],\n",
            "        [-1.9684,  1.9730, -0.0756],\n",
            "        [-1.9074,  1.0379,  0.8543]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8043,  1.4222,  0.4072],\n",
            "        [-1.8394,  1.8430, -0.0921],\n",
            "        [-1.7488,  1.9878, -0.2635],\n",
            "        [-1.7205,  1.8745, -0.1225],\n",
            "        [ 0.6453, -0.2644, -0.9667],\n",
            "        [-1.8903,  1.8710, -0.1345],\n",
            "        [-1.6879,  1.6957, -0.4292],\n",
            "        [ 0.7391, -0.2162, -0.9965],\n",
            "        [-1.9949,  1.3117,  0.6322],\n",
            "        [-1.8026,  0.6047,  1.0032],\n",
            "        [-1.7605,  1.6384, -0.1381],\n",
            "        [-1.8710,  1.9479, -0.3150],\n",
            "        [-1.7161,  1.8010, -0.1628],\n",
            "        [ 0.7365, -0.3129, -1.0305],\n",
            "        [-1.8163,  0.8797,  0.9460],\n",
            "        [-1.7379,  2.0187, -0.2285]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8043,  1.4222,  0.4072],\n",
            "        [-1.8394,  1.8430, -0.0921],\n",
            "        [-1.7488,  1.9878, -0.2635],\n",
            "        [-1.7205,  1.8745, -0.1225],\n",
            "        [ 0.6453, -0.2644, -0.9667],\n",
            "        [-1.8903,  1.8710, -0.1345],\n",
            "        [-1.6879,  1.6957, -0.4292],\n",
            "        [ 0.7391, -0.2162, -0.9965],\n",
            "        [-1.9949,  1.3117,  0.6322],\n",
            "        [-1.8026,  0.6047,  1.0032],\n",
            "        [-1.7605,  1.6384, -0.1381],\n",
            "        [-1.8710,  1.9479, -0.3150],\n",
            "        [-1.7161,  1.8010, -0.1628],\n",
            "        [ 0.7365, -0.3129, -1.0305],\n",
            "        [-1.8163,  0.8797,  0.9460],\n",
            "        [-1.7379,  2.0187, -0.2285]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5363,  0.8037,  1.0379],\n",
            "        [-1.5958,  1.7429, -0.2484],\n",
            "        [ 0.1019,  0.3186, -0.9829],\n",
            "        [-1.2041,  1.3891, -0.6259],\n",
            "        [-2.0258,  1.7231,  0.1567],\n",
            "        [-1.7819,  2.1006, -0.0451],\n",
            "        [-1.7087,  0.6986,  1.1054],\n",
            "        [-1.9102,  1.9796, -0.3440],\n",
            "        [ 0.6092, -0.3236, -1.0250],\n",
            "        [-2.0549,  2.1289, -0.2932],\n",
            "        [-1.8667,  1.9664, -0.1882],\n",
            "        [-1.7628,  1.8203, -0.3026],\n",
            "        [ 0.6873, -0.2342, -1.0121],\n",
            "        [ 0.5485,  0.0840, -1.1087],\n",
            "        [-1.6487,  0.5817,  1.0979],\n",
            "        [-1.7331,  0.3608,  1.0780]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5363,  0.8037,  1.0379],\n",
            "        [-1.5958,  1.7429, -0.2484],\n",
            "        [ 0.1019,  0.3186, -0.9829],\n",
            "        [-1.2041,  1.3891, -0.6259],\n",
            "        [-2.0258,  1.7231,  0.1567],\n",
            "        [-1.7819,  2.1006, -0.0451],\n",
            "        [-1.7087,  0.6986,  1.1054],\n",
            "        [-1.9102,  1.9796, -0.3440],\n",
            "        [ 0.6092, -0.3236, -1.0250],\n",
            "        [-2.0549,  2.1289, -0.2932],\n",
            "        [-1.8667,  1.9664, -0.1882],\n",
            "        [-1.7628,  1.8203, -0.3026],\n",
            "        [ 0.6873, -0.2342, -1.0121],\n",
            "        [ 0.5485,  0.0840, -1.1087],\n",
            "        [-1.6487,  0.5817,  1.0979],\n",
            "        [-1.7331,  0.3608,  1.0780]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9948,  1.9368, -0.2455],\n",
            "        [-1.7885,  0.6167,  1.0646],\n",
            "        [-1.9992,  1.0577,  0.6305],\n",
            "        [-1.5985,  0.5400,  0.9923],\n",
            "        [-1.7078,  1.6505, -0.2339],\n",
            "        [-1.8000,  0.6082,  1.1183],\n",
            "        [-1.9069,  1.9383, -0.3338],\n",
            "        [-1.7136,  0.3185,  1.1017],\n",
            "        [-1.9949,  0.7659,  0.9898],\n",
            "        [-1.7494,  1.8751, -0.1034],\n",
            "        [-1.7357,  1.2080,  0.4848],\n",
            "        [-1.8502,  2.0241, -0.1058],\n",
            "        [-2.0025,  1.7446, -0.0969],\n",
            "        [-1.7503,  1.5864, -0.3508],\n",
            "        [-1.7135,  0.5060,  0.8229],\n",
            "        [-1.5174,  1.5608, -0.4459]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9948,  1.9368, -0.2455],\n",
            "        [-1.7885,  0.6167,  1.0646],\n",
            "        [-1.9992,  1.0577,  0.6305],\n",
            "        [-1.5985,  0.5400,  0.9923],\n",
            "        [-1.7078,  1.6505, -0.2339],\n",
            "        [-1.8000,  0.6082,  1.1183],\n",
            "        [-1.9069,  1.9383, -0.3338],\n",
            "        [-1.7136,  0.3185,  1.1017],\n",
            "        [-1.9949,  0.7659,  0.9898],\n",
            "        [-1.7494,  1.8751, -0.1034],\n",
            "        [-1.7357,  1.2080,  0.4848],\n",
            "        [-1.8502,  2.0241, -0.1058],\n",
            "        [-2.0025,  1.7446, -0.0969],\n",
            "        [-1.7503,  1.5864, -0.3508],\n",
            "        [-1.7135,  0.5060,  0.8229],\n",
            "        [-1.5174,  1.5608, -0.4459]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9985,  1.9334, -0.1613],\n",
            "        [ 0.6449, -0.1787, -1.0367],\n",
            "        [-1.9675,  1.9810, -0.3310],\n",
            "        [-2.1625,  1.9933,  0.0290],\n",
            "        [ 0.6959, -0.2525, -1.0309],\n",
            "        [-1.7788,  1.8224, -0.2060],\n",
            "        [-2.0087,  0.7627,  0.8727],\n",
            "        [-1.8200,  0.5623,  1.1437],\n",
            "        [-1.8746,  0.8377,  0.8682],\n",
            "        [ 0.6982, -0.2185, -0.9387],\n",
            "        [-1.8776,  0.6312,  1.0859],\n",
            "        [-1.6574,  0.6797,  1.2508],\n",
            "        [-0.8303,  0.9112, -0.6370],\n",
            "        [-2.0029,  2.1142, -0.2049],\n",
            "        [-1.2445,  1.4564, -0.6350],\n",
            "        [-1.9025,  1.8428, -0.2660]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9985,  1.9334, -0.1613],\n",
            "        [ 0.6449, -0.1787, -1.0367],\n",
            "        [-1.9675,  1.9810, -0.3310],\n",
            "        [-2.1625,  1.9933,  0.0290],\n",
            "        [ 0.6959, -0.2525, -1.0309],\n",
            "        [-1.7788,  1.8224, -0.2060],\n",
            "        [-2.0087,  0.7627,  0.8727],\n",
            "        [-1.8200,  0.5623,  1.1437],\n",
            "        [-1.8746,  0.8377,  0.8682],\n",
            "        [ 0.6982, -0.2185, -0.9387],\n",
            "        [-1.8776,  0.6312,  1.0859],\n",
            "        [-1.6574,  0.6797,  1.2508],\n",
            "        [-0.8303,  0.9112, -0.6370],\n",
            "        [-2.0029,  2.1142, -0.2049],\n",
            "        [-1.2445,  1.4564, -0.6350],\n",
            "        [-1.9025,  1.8428, -0.2660]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9331,  1.8951,  0.0260],\n",
            "        [-1.9143,  0.5682,  1.1036],\n",
            "        [-2.2658,  0.7452,  0.9485],\n",
            "        [-1.9132,  1.7708,  0.2336],\n",
            "        [ 0.8540, -0.3027, -0.8771],\n",
            "        [ 0.6811, -0.2801, -0.9377],\n",
            "        [-1.7594,  1.6779, -0.2618],\n",
            "        [-2.0207,  2.0585, -0.1383],\n",
            "        [-1.8358,  1.8685, -0.1637],\n",
            "        [-1.8149,  1.7743, -0.5307],\n",
            "        [-1.9150,  1.9905, -0.1883],\n",
            "        [-2.0198,  0.7238,  1.3172],\n",
            "        [ 0.7078, -0.0976, -0.9179],\n",
            "        [ 0.5613, -0.1360, -1.0317],\n",
            "        [-1.7236,  0.8144,  0.4899],\n",
            "        [-2.0421,  1.9673, -0.0661]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9331,  1.8951,  0.0260],\n",
            "        [-1.9143,  0.5682,  1.1036],\n",
            "        [-2.2658,  0.7452,  0.9485],\n",
            "        [-1.9132,  1.7708,  0.2336],\n",
            "        [ 0.8540, -0.3027, -0.8771],\n",
            "        [ 0.6811, -0.2801, -0.9377],\n",
            "        [-1.7594,  1.6779, -0.2618],\n",
            "        [-2.0207,  2.0585, -0.1383],\n",
            "        [-1.8358,  1.8685, -0.1637],\n",
            "        [-1.8149,  1.7743, -0.5307],\n",
            "        [-1.9150,  1.9905, -0.1883],\n",
            "        [-2.0198,  0.7238,  1.3172],\n",
            "        [ 0.7078, -0.0976, -0.9179],\n",
            "        [ 0.5613, -0.1360, -1.0317],\n",
            "        [-1.7236,  0.8144,  0.4899],\n",
            "        [-2.0421,  1.9673, -0.0661]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2643,  1.4606,  0.4810],\n",
            "        [-1.9675,  2.0419, -0.1965],\n",
            "        [-1.8861,  1.8589, -0.0607],\n",
            "        [-1.7365,  1.7852,  0.0699],\n",
            "        [-1.8199,  1.9517, -0.1840],\n",
            "        [-1.7506,  1.8294, -0.0604],\n",
            "        [-1.7295,  1.9404, -0.3671],\n",
            "        [-2.1371,  0.8673,  1.0982],\n",
            "        [-1.8983,  1.8786, -0.1018],\n",
            "        [ 0.5924, -0.0099, -0.9913],\n",
            "        [-2.0409,  1.5201,  0.0183],\n",
            "        [-1.9488,  0.8327,  0.9463],\n",
            "        [-1.8726,  1.6503, -0.0172],\n",
            "        [ 0.7219, -0.3011, -1.1746],\n",
            "        [-2.0859,  1.8900, -0.2327],\n",
            "        [-2.0462,  0.7094,  1.2329]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.2643,  1.4606,  0.4810],\n",
            "        [-1.9675,  2.0419, -0.1965],\n",
            "        [-1.8861,  1.8589, -0.0607],\n",
            "        [-1.7365,  1.7852,  0.0699],\n",
            "        [-1.8199,  1.9517, -0.1840],\n",
            "        [-1.7506,  1.8294, -0.0604],\n",
            "        [-1.7295,  1.9404, -0.3671],\n",
            "        [-2.1371,  0.8673,  1.0982],\n",
            "        [-1.8983,  1.8786, -0.1018],\n",
            "        [ 0.5924, -0.0099, -0.9913],\n",
            "        [-2.0409,  1.5201,  0.0183],\n",
            "        [-1.9488,  0.8327,  0.9463],\n",
            "        [-1.8726,  1.6503, -0.0172],\n",
            "        [ 0.7219, -0.3011, -1.1746],\n",
            "        [-2.0859,  1.8900, -0.2327],\n",
            "        [-2.0462,  0.7094,  1.2329]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0745,  1.6300,  0.0409],\n",
            "        [-1.8321,  1.9685, -0.1503],\n",
            "        [-2.2917,  1.6920,  0.1762],\n",
            "        [-2.1372,  1.4006,  0.6379],\n",
            "        [-1.9552,  1.6589, -0.2100],\n",
            "        [-1.9018,  0.6654,  1.1176],\n",
            "        [-1.8733,  1.9566, -0.3496],\n",
            "        [-1.9156,  0.4847,  1.1790],\n",
            "        [-1.7856,  1.3906,  0.4417],\n",
            "        [-2.1159,  1.9394, -0.2985],\n",
            "        [-2.0539,  0.5065,  1.0964],\n",
            "        [-1.6600,  0.5867,  1.1171],\n",
            "        [-1.9864,  1.8989, -0.1980],\n",
            "        [-1.8204,  0.6293,  0.9826],\n",
            "        [-1.6265,  1.8513, -0.4270],\n",
            "        [-1.9827,  1.8952,  0.1371]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0745,  1.6300,  0.0409],\n",
            "        [-1.8321,  1.9685, -0.1503],\n",
            "        [-2.2917,  1.6920,  0.1762],\n",
            "        [-2.1372,  1.4006,  0.6379],\n",
            "        [-1.9552,  1.6589, -0.2100],\n",
            "        [-1.9018,  0.6654,  1.1176],\n",
            "        [-1.8733,  1.9566, -0.3496],\n",
            "        [-1.9156,  0.4847,  1.1790],\n",
            "        [-1.7856,  1.3906,  0.4417],\n",
            "        [-2.1159,  1.9394, -0.2985],\n",
            "        [-2.0539,  0.5065,  1.0964],\n",
            "        [-1.6600,  0.5867,  1.1171],\n",
            "        [-1.9864,  1.8989, -0.1980],\n",
            "        [-1.8204,  0.6293,  0.9826],\n",
            "        [-1.6265,  1.8513, -0.4270],\n",
            "        [-1.9827,  1.8952,  0.1371]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0796,  1.5926, -0.0224],\n",
            "        [-2.0651,  1.2403,  0.7167],\n",
            "        [-2.0058,  1.5066, -0.1117],\n",
            "        [ 0.5904, -0.0757, -1.0497],\n",
            "        [-0.0826,  0.1991, -0.4146],\n",
            "        [ 0.6160, -0.0050, -0.9756],\n",
            "        [-1.6827,  1.7573, -0.4025],\n",
            "        [-1.9482,  0.7943,  0.9419],\n",
            "        [-1.8733,  0.5555,  1.0271],\n",
            "        [-1.4186,  0.6514,  0.4980],\n",
            "        [-1.8092,  1.7874, -0.3140],\n",
            "        [-1.6623,  0.4181,  0.9154],\n",
            "        [ 0.7885,  0.1250, -1.1220],\n",
            "        [-1.9577,  2.0901, -0.1548],\n",
            "        [-2.0241,  1.3183,  0.4962],\n",
            "        [ 0.5153,  0.1428, -1.1269]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0796,  1.5926, -0.0224],\n",
            "        [-2.0651,  1.2403,  0.7167],\n",
            "        [-2.0058,  1.5066, -0.1117],\n",
            "        [ 0.5904, -0.0757, -1.0497],\n",
            "        [-0.0826,  0.1991, -0.4146],\n",
            "        [ 0.6160, -0.0050, -0.9756],\n",
            "        [-1.6827,  1.7573, -0.4025],\n",
            "        [-1.9482,  0.7943,  0.9419],\n",
            "        [-1.8733,  0.5555,  1.0271],\n",
            "        [-1.4186,  0.6514,  0.4980],\n",
            "        [-1.8092,  1.7874, -0.3140],\n",
            "        [-1.6623,  0.4181,  0.9154],\n",
            "        [ 0.7885,  0.1250, -1.1220],\n",
            "        [-1.9577,  2.0901, -0.1548],\n",
            "        [-2.0241,  1.3183,  0.4962],\n",
            "        [ 0.5153,  0.1428, -1.1269]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.4671,  0.1615, -1.1710],\n",
            "        [-1.8458,  1.7932, -0.0938],\n",
            "        [ 0.5809, -0.1655, -1.1646],\n",
            "        [-1.8108,  0.5825,  1.0544],\n",
            "        [-1.8130,  1.8553, -0.4272],\n",
            "        [-1.9795,  1.9620, -0.3285],\n",
            "        [-2.1029,  1.9010, -0.0279],\n",
            "        [-1.9275,  0.7389,  1.0629],\n",
            "        [-1.7310,  1.6210, -0.1779],\n",
            "        [-1.6383,  1.9046, -0.1799],\n",
            "        [-1.8310,  1.7271, -0.1535],\n",
            "        [-2.1325,  1.7497,  0.1559],\n",
            "        [-2.0302,  0.5922,  1.1526],\n",
            "        [-1.8355,  1.9919, -0.2384],\n",
            "        [-1.8093,  0.6669,  1.0102],\n",
            "        [-2.0828,  0.6715,  1.3356]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.4671,  0.1615, -1.1710],\n",
            "        [-1.8458,  1.7932, -0.0938],\n",
            "        [ 0.5809, -0.1655, -1.1646],\n",
            "        [-1.8108,  0.5825,  1.0544],\n",
            "        [-1.8130,  1.8553, -0.4272],\n",
            "        [-1.9795,  1.9620, -0.3285],\n",
            "        [-2.1029,  1.9010, -0.0279],\n",
            "        [-1.9275,  0.7389,  1.0629],\n",
            "        [-1.7310,  1.6210, -0.1779],\n",
            "        [-1.6383,  1.9046, -0.1799],\n",
            "        [-1.8310,  1.7271, -0.1535],\n",
            "        [-2.1325,  1.7497,  0.1559],\n",
            "        [-2.0302,  0.5922,  1.1526],\n",
            "        [-1.8355,  1.9919, -0.2384],\n",
            "        [-1.8093,  0.6669,  1.0102],\n",
            "        [-2.0828,  0.6715,  1.3356]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5557, -0.0187, -1.1778],\n",
            "        [-1.8838,  0.7025,  1.0661],\n",
            "        [-1.6457,  2.0632, -0.4261],\n",
            "        [-0.6431,  0.8249, -0.7859],\n",
            "        [-1.9919,  2.0959, -0.1615],\n",
            "        [-2.2344,  1.8686,  0.2798],\n",
            "        [-1.8062,  0.5149,  1.1510],\n",
            "        [-2.1029,  1.8168, -0.0596],\n",
            "        [-1.9927,  2.0921, -0.2968],\n",
            "        [-1.8950,  1.8977, -0.2199],\n",
            "        [-2.0400,  1.7720,  0.2715],\n",
            "        [-2.0345,  0.8644,  0.9179],\n",
            "        [-1.6732,  0.4669,  0.9177],\n",
            "        [-2.0127,  1.8628, -0.0531],\n",
            "        [-1.9482,  1.8997, -0.2681],\n",
            "        [-1.6088,  2.0251, -0.2223]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.5557, -0.0187, -1.1778],\n",
            "        [-1.8838,  0.7025,  1.0661],\n",
            "        [-1.6457,  2.0632, -0.4261],\n",
            "        [-0.6431,  0.8249, -0.7859],\n",
            "        [-1.9919,  2.0959, -0.1615],\n",
            "        [-2.2344,  1.8686,  0.2798],\n",
            "        [-1.8062,  0.5149,  1.1510],\n",
            "        [-2.1029,  1.8168, -0.0596],\n",
            "        [-1.9927,  2.0921, -0.2968],\n",
            "        [-1.8950,  1.8977, -0.2199],\n",
            "        [-2.0400,  1.7720,  0.2715],\n",
            "        [-2.0345,  0.8644,  0.9179],\n",
            "        [-1.6732,  0.4669,  0.9177],\n",
            "        [-2.0127,  1.8628, -0.0531],\n",
            "        [-1.9482,  1.8997, -0.2681],\n",
            "        [-1.6088,  2.0251, -0.2223]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9254,  2.0005,  0.1956],\n",
            "        [-1.5915,  0.8454,  0.3890],\n",
            "        [-1.9672,  0.7178,  1.1267],\n",
            "        [-1.8844,  0.6469,  1.2281],\n",
            "        [-1.8604,  0.6910,  1.1672],\n",
            "        [-2.1329,  1.5915,  0.4905],\n",
            "        [-1.7216,  1.8991, -0.1237],\n",
            "        [-2.2119,  2.0331, -0.1073],\n",
            "        [-1.8929,  1.8185, -0.2363],\n",
            "        [-2.1119,  0.7799,  1.0951],\n",
            "        [-1.9394,  0.6678,  1.0131],\n",
            "        [-1.7652,  0.6905,  1.0078],\n",
            "        [-1.2849,  1.4521, -0.5854],\n",
            "        [-2.0793,  0.6894,  1.0519],\n",
            "        [-1.7161,  0.5865,  1.0966],\n",
            "        [-1.9144,  2.0329, -0.1774]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9254,  2.0005,  0.1956],\n",
            "        [-1.5915,  0.8454,  0.3890],\n",
            "        [-1.9672,  0.7178,  1.1267],\n",
            "        [-1.8844,  0.6469,  1.2281],\n",
            "        [-1.8604,  0.6910,  1.1672],\n",
            "        [-2.1329,  1.5915,  0.4905],\n",
            "        [-1.7216,  1.8991, -0.1237],\n",
            "        [-2.2119,  2.0331, -0.1073],\n",
            "        [-1.8929,  1.8185, -0.2363],\n",
            "        [-2.1119,  0.7799,  1.0951],\n",
            "        [-1.9394,  0.6678,  1.0131],\n",
            "        [-1.7652,  0.6905,  1.0078],\n",
            "        [-1.2849,  1.4521, -0.5854],\n",
            "        [-2.0793,  0.6894,  1.0519],\n",
            "        [-1.7161,  0.5865,  1.0966],\n",
            "        [-1.9144,  2.0329, -0.1774]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.0826,  0.2981, -0.5399],\n",
            "        [-1.7736,  2.1029, -0.2673],\n",
            "        [-2.1360,  1.9807, -0.0778],\n",
            "        [-1.8733,  1.8113, -0.1610],\n",
            "        [-1.7613,  0.5925,  0.8507],\n",
            "        [-1.8264,  1.8617, -0.2723],\n",
            "        [-1.7184,  1.7886, -0.3101],\n",
            "        [-2.2206,  2.1406, -0.0368],\n",
            "        [-0.4308,  0.4344, -0.3153],\n",
            "        [ 0.1238,  0.4892, -1.0032],\n",
            "        [-1.9525,  1.7108, -0.1503],\n",
            "        [-2.0103,  0.6943,  1.3172],\n",
            "        [ 0.5033, -0.0724, -1.0117],\n",
            "        [-1.9083,  0.7005,  1.0049],\n",
            "        [-1.7502,  2.0679, -0.2151],\n",
            "        [-1.8999,  0.4548,  0.9918]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-0.0826,  0.2981, -0.5399],\n",
            "        [-1.7736,  2.1029, -0.2673],\n",
            "        [-2.1360,  1.9807, -0.0778],\n",
            "        [-1.8733,  1.8113, -0.1610],\n",
            "        [-1.7613,  0.5925,  0.8507],\n",
            "        [-1.8264,  1.8617, -0.2723],\n",
            "        [-1.7184,  1.7886, -0.3101],\n",
            "        [-2.2206,  2.1406, -0.0368],\n",
            "        [-0.4308,  0.4344, -0.3153],\n",
            "        [ 0.1238,  0.4892, -1.0032],\n",
            "        [-1.9525,  1.7108, -0.1503],\n",
            "        [-2.0103,  0.6943,  1.3172],\n",
            "        [ 0.5033, -0.0724, -1.0117],\n",
            "        [-1.9083,  0.7005,  1.0049],\n",
            "        [-1.7502,  2.0679, -0.2151],\n",
            "        [-1.8999,  0.4548,  0.9918]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7566,  1.7137, -0.2125],\n",
            "        [-1.8541,  1.8175, -0.1628],\n",
            "        [-1.8411,  0.6855,  1.1414],\n",
            "        [-1.9004,  0.7318,  1.1909],\n",
            "        [-1.8060,  2.0779, -0.3169],\n",
            "        [-1.9212,  0.6279,  1.0897],\n",
            "        [ 0.5602,  0.1293, -1.3113],\n",
            "        [ 0.4189,  0.1106, -1.1237],\n",
            "        [ 0.4553,  0.0985, -1.2317],\n",
            "        [-2.0991,  1.0728,  0.7912],\n",
            "        [-1.7595,  0.5375,  1.1672],\n",
            "        [-2.0394,  1.8781, -0.1712],\n",
            "        [-2.0655,  1.7609, -0.0274],\n",
            "        [-1.8906,  2.1423, -0.1881],\n",
            "        [-1.7241,  1.8925, -0.2282],\n",
            "        [-1.9553,  1.9291, -0.3007]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7566,  1.7137, -0.2125],\n",
            "        [-1.8541,  1.8175, -0.1628],\n",
            "        [-1.8411,  0.6855,  1.1414],\n",
            "        [-1.9004,  0.7318,  1.1909],\n",
            "        [-1.8060,  2.0779, -0.3169],\n",
            "        [-1.9212,  0.6279,  1.0897],\n",
            "        [ 0.5602,  0.1293, -1.3113],\n",
            "        [ 0.4189,  0.1106, -1.1237],\n",
            "        [ 0.4553,  0.0985, -1.2317],\n",
            "        [-2.0991,  1.0728,  0.7912],\n",
            "        [-1.7595,  0.5375,  1.1672],\n",
            "        [-2.0394,  1.8781, -0.1712],\n",
            "        [-2.0655,  1.7609, -0.0274],\n",
            "        [-1.8906,  2.1423, -0.1881],\n",
            "        [-1.7241,  1.8925, -0.2282],\n",
            "        [-1.9553,  1.9291, -0.3007]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3327,  0.0657, -0.9827],\n",
            "        [ 0.2524,  0.2450, -0.8644],\n",
            "        [-1.9344,  1.9978, -0.2653],\n",
            "        [-1.9360,  0.5674,  1.2548],\n",
            "        [-1.7411,  1.4147, -0.0644],\n",
            "        [-1.8682,  1.7943, -0.0561],\n",
            "        [-1.8127,  1.8459, -0.2706],\n",
            "        [-2.0632,  0.6067,  1.2717],\n",
            "        [-2.0395,  1.6848, -0.0637],\n",
            "        [-1.9588,  1.6591,  0.3793],\n",
            "        [-2.1086,  0.8823,  0.9152],\n",
            "        [-0.7738,  0.8656, -0.6944],\n",
            "        [-1.9307,  2.1609, -0.1027],\n",
            "        [-1.9600,  0.6210,  1.1101],\n",
            "        [-1.7854,  1.8595, -0.0262],\n",
            "        [-2.2108,  0.6524,  1.3167]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.3327,  0.0657, -0.9827],\n",
            "        [ 0.2524,  0.2450, -0.8644],\n",
            "        [-1.9344,  1.9978, -0.2653],\n",
            "        [-1.9360,  0.5674,  1.2548],\n",
            "        [-1.7411,  1.4147, -0.0644],\n",
            "        [-1.8682,  1.7943, -0.0561],\n",
            "        [-1.8127,  1.8459, -0.2706],\n",
            "        [-2.0632,  0.6067,  1.2717],\n",
            "        [-2.0395,  1.6848, -0.0637],\n",
            "        [-1.9588,  1.6591,  0.3793],\n",
            "        [-2.1086,  0.8823,  0.9152],\n",
            "        [-0.7738,  0.8656, -0.6944],\n",
            "        [-1.9307,  2.1609, -0.1027],\n",
            "        [-1.9600,  0.6210,  1.1101],\n",
            "        [-1.7854,  1.8595, -0.0262],\n",
            "        [-2.2108,  0.6524,  1.3167]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8503,  2.1632, -0.3697],\n",
            "        [-1.9619,  2.0018, -0.3459],\n",
            "        [-1.9023,  0.5524,  1.0958],\n",
            "        [-1.8129,  1.9542, -0.0871],\n",
            "        [-2.0479,  1.9939, -0.0397],\n",
            "        [-1.9168,  0.5434,  1.1867],\n",
            "        [-2.1185,  0.7769,  1.2364],\n",
            "        [-2.1852,  1.3933,  0.4958],\n",
            "        [-1.8299,  0.9155,  1.1833],\n",
            "        [ 0.3837,  0.1428, -1.0104],\n",
            "        [-1.9828,  1.8744, -0.0676],\n",
            "        [-1.7872,  0.4926,  1.1663],\n",
            "        [-2.1824,  1.4461,  0.7026],\n",
            "        [-1.8039,  2.0001, -0.4501],\n",
            "        [-2.1301,  1.0021,  0.9937],\n",
            "        [-2.1378,  1.0090,  0.9102]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8503,  2.1632, -0.3697],\n",
            "        [-1.9619,  2.0018, -0.3459],\n",
            "        [-1.9023,  0.5524,  1.0958],\n",
            "        [-1.8129,  1.9542, -0.0871],\n",
            "        [-2.0479,  1.9939, -0.0397],\n",
            "        [-1.9168,  0.5434,  1.1867],\n",
            "        [-2.1185,  0.7769,  1.2364],\n",
            "        [-2.1852,  1.3933,  0.4958],\n",
            "        [-1.8299,  0.9155,  1.1833],\n",
            "        [ 0.3837,  0.1428, -1.0104],\n",
            "        [-1.9828,  1.8744, -0.0676],\n",
            "        [-1.7872,  0.4926,  1.1663],\n",
            "        [-2.1824,  1.4461,  0.7026],\n",
            "        [-1.8039,  2.0001, -0.4501],\n",
            "        [-2.1301,  1.0021,  0.9937],\n",
            "        [-2.1378,  1.0090,  0.9102]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7275,  1.7313, -0.0949],\n",
            "        [-1.8180,  1.9753, -0.1340],\n",
            "        [ 0.6250, -0.0320, -1.2301],\n",
            "        [ 0.4423,  0.0029, -1.0949],\n",
            "        [-1.6944,  1.7442, -0.0854],\n",
            "        [-2.0687,  1.9239, -0.0324],\n",
            "        [-2.1088,  0.6882,  1.0593],\n",
            "        [ 0.4419,  0.1162, -1.2379],\n",
            "        [-1.8308,  1.9377, -0.2260],\n",
            "        [-2.2489,  1.8917,  0.0177],\n",
            "        [-1.9923,  0.4695,  1.1762],\n",
            "        [-1.9127,  0.4606,  1.1979],\n",
            "        [-1.8810,  1.9025, -0.0628],\n",
            "        [-1.8478,  1.8017, -0.1080],\n",
            "        [-2.0642,  0.6261,  1.4164],\n",
            "        [-1.9741,  1.9668, -0.2414]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7275,  1.7313, -0.0949],\n",
            "        [-1.8180,  1.9753, -0.1340],\n",
            "        [ 0.6250, -0.0320, -1.2301],\n",
            "        [ 0.4423,  0.0029, -1.0949],\n",
            "        [-1.6944,  1.7442, -0.0854],\n",
            "        [-2.0687,  1.9239, -0.0324],\n",
            "        [-2.1088,  0.6882,  1.0593],\n",
            "        [ 0.4419,  0.1162, -1.2379],\n",
            "        [-1.8308,  1.9377, -0.2260],\n",
            "        [-2.2489,  1.8917,  0.0177],\n",
            "        [-1.9923,  0.4695,  1.1762],\n",
            "        [-1.9127,  0.4606,  1.1979],\n",
            "        [-1.8810,  1.9025, -0.0628],\n",
            "        [-1.8478,  1.8017, -0.1080],\n",
            "        [-2.0642,  0.6261,  1.4164],\n",
            "        [-1.9741,  1.9668, -0.2414]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7809,  2.0295, -0.1052],\n",
            "        [ 0.4364, -0.0335, -1.2444],\n",
            "        [-1.5566,  1.7285, -0.3304],\n",
            "        [-1.7899,  1.9207,  0.0244],\n",
            "        [-2.0351,  0.5662,  1.1117],\n",
            "        [-1.9323,  1.9571, -0.0746],\n",
            "        [-2.0376,  0.5108,  1.1411],\n",
            "        [ 0.2392,  0.1162, -0.9641],\n",
            "        [-1.7159,  1.7684, -0.3854],\n",
            "        [-1.6134,  1.7514,  0.0132],\n",
            "        [-1.8666,  1.9191, -0.2525],\n",
            "        [ 0.4375,  0.1347, -0.9495],\n",
            "        [-2.1186,  0.4415,  1.2985],\n",
            "        [-2.1430,  1.7494, -0.1386],\n",
            "        [-1.8504,  1.7735,  0.0040],\n",
            "        [-1.5533,  1.6128, -0.2640]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7809,  2.0295, -0.1052],\n",
            "        [ 0.4364, -0.0335, -1.2444],\n",
            "        [-1.5566,  1.7285, -0.3304],\n",
            "        [-1.7899,  1.9207,  0.0244],\n",
            "        [-2.0351,  0.5662,  1.1117],\n",
            "        [-1.9323,  1.9571, -0.0746],\n",
            "        [-2.0376,  0.5108,  1.1411],\n",
            "        [ 0.2392,  0.1162, -0.9641],\n",
            "        [-1.7159,  1.7684, -0.3854],\n",
            "        [-1.6134,  1.7514,  0.0132],\n",
            "        [-1.8666,  1.9191, -0.2525],\n",
            "        [ 0.4375,  0.1347, -0.9495],\n",
            "        [-2.1186,  0.4415,  1.2985],\n",
            "        [-2.1430,  1.7494, -0.1386],\n",
            "        [-1.8504,  1.7735,  0.0040],\n",
            "        [-1.5533,  1.6128, -0.2640]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8215,  1.7513, -0.1947],\n",
            "        [ 0.1932,  0.0130, -1.0550],\n",
            "        [-2.0594,  2.1237, -0.0990],\n",
            "        [-1.7716,  1.9001, -0.2644],\n",
            "        [-1.8631,  1.7267, -0.2309],\n",
            "        [-1.8023,  1.7048,  0.0990],\n",
            "        [-2.1135,  0.6028,  1.3238],\n",
            "        [-2.1086,  1.7615, -0.1856],\n",
            "        [-1.7989,  1.8151, -0.1777],\n",
            "        [-1.9772,  1.5553, -0.0837],\n",
            "        [-1.9153,  2.0506, -0.2425],\n",
            "        [-2.0310,  0.7364,  1.2464],\n",
            "        [-2.2202,  1.5177,  0.4931],\n",
            "        [-1.9266,  1.7495, -0.3333],\n",
            "        [-1.9102,  1.8009, -0.2471],\n",
            "        [ 0.6017,  0.0135, -1.2259]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8215,  1.7513, -0.1947],\n",
            "        [ 0.1932,  0.0130, -1.0550],\n",
            "        [-2.0594,  2.1237, -0.0990],\n",
            "        [-1.7716,  1.9001, -0.2644],\n",
            "        [-1.8631,  1.7267, -0.2309],\n",
            "        [-1.8023,  1.7048,  0.0990],\n",
            "        [-2.1135,  0.6028,  1.3238],\n",
            "        [-2.1086,  1.7615, -0.1856],\n",
            "        [-1.7989,  1.8151, -0.1777],\n",
            "        [-1.9772,  1.5553, -0.0837],\n",
            "        [-1.9153,  2.0506, -0.2425],\n",
            "        [-2.0310,  0.7364,  1.2464],\n",
            "        [-2.2202,  1.5177,  0.4931],\n",
            "        [-1.9266,  1.7495, -0.3333],\n",
            "        [-1.9102,  1.8009, -0.2471],\n",
            "        [ 0.6017,  0.0135, -1.2259]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6975,  0.4335,  1.2119],\n",
            "        [-1.9290,  0.5222,  1.2472],\n",
            "        [-1.9679,  1.9639, -0.3437],\n",
            "        [-1.6730,  1.6978, -0.1892],\n",
            "        [-1.8076,  1.7964, -0.3868],\n",
            "        [ 0.2066,  0.5087, -0.9622],\n",
            "        [-1.8121,  0.3997,  1.1456],\n",
            "        [-2.0202,  0.5095,  1.2686],\n",
            "        [-1.5328,  1.6806, -0.3851],\n",
            "        [-2.1234,  0.4300,  1.1480],\n",
            "        [-1.9365,  1.2286,  0.3637],\n",
            "        [-1.8164,  1.9562, -0.2235],\n",
            "        [-2.0357,  1.0766,  0.7682],\n",
            "        [-1.9753,  1.9451, -0.1288],\n",
            "        [-2.1667,  2.2285, -0.0254],\n",
            "        [-1.8376,  1.7090,  0.0773]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6975,  0.4335,  1.2119],\n",
            "        [-1.9290,  0.5222,  1.2472],\n",
            "        [-1.9679,  1.9639, -0.3437],\n",
            "        [-1.6730,  1.6978, -0.1892],\n",
            "        [-1.8076,  1.7964, -0.3868],\n",
            "        [ 0.2066,  0.5087, -0.9622],\n",
            "        [-1.8121,  0.3997,  1.1456],\n",
            "        [-2.0202,  0.5095,  1.2686],\n",
            "        [-1.5328,  1.6806, -0.3851],\n",
            "        [-2.1234,  0.4300,  1.1480],\n",
            "        [-1.9365,  1.2286,  0.3637],\n",
            "        [-1.8164,  1.9562, -0.2235],\n",
            "        [-2.0357,  1.0766,  0.7682],\n",
            "        [-1.9753,  1.9451, -0.1288],\n",
            "        [-2.1667,  2.2285, -0.0254],\n",
            "        [-1.8376,  1.7090,  0.0773]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.4715, -0.0064, -1.1706],\n",
            "        [-2.2563,  1.6240,  0.2857],\n",
            "        [-1.9192,  1.8391, -0.2681],\n",
            "        [-1.9211,  1.6706, -0.3614],\n",
            "        [-2.2233,  1.8817, -0.2774],\n",
            "        [-1.8016,  1.8822, -0.2646],\n",
            "        [ 0.5047,  0.1388, -1.1576],\n",
            "        [-2.0590,  0.4797,  1.2465],\n",
            "        [-1.9451,  2.0281, -0.1788],\n",
            "        [-2.0478,  0.7807,  1.0560],\n",
            "        [-1.8245,  1.4814, -0.0385],\n",
            "        [-1.7613,  1.8244, -0.3424],\n",
            "        [ 0.2713,  0.1487, -1.0883],\n",
            "        [-1.7263,  1.3389,  0.5039],\n",
            "        [-1.8256,  1.8975, -0.2311],\n",
            "        [-1.4520,  1.7376, -0.4782]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.4715, -0.0064, -1.1706],\n",
            "        [-2.2563,  1.6240,  0.2857],\n",
            "        [-1.9192,  1.8391, -0.2681],\n",
            "        [-1.9211,  1.6706, -0.3614],\n",
            "        [-2.2233,  1.8817, -0.2774],\n",
            "        [-1.8016,  1.8822, -0.2646],\n",
            "        [ 0.5047,  0.1388, -1.1576],\n",
            "        [-2.0590,  0.4797,  1.2465],\n",
            "        [-1.9451,  2.0281, -0.1788],\n",
            "        [-2.0478,  0.7807,  1.0560],\n",
            "        [-1.8245,  1.4814, -0.0385],\n",
            "        [-1.7613,  1.8244, -0.3424],\n",
            "        [ 0.2713,  0.1487, -1.0883],\n",
            "        [-1.7263,  1.3389,  0.5039],\n",
            "        [-1.8256,  1.8975, -0.2311],\n",
            "        [-1.4520,  1.7376, -0.4782]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9942,  2.0902, -0.1385],\n",
            "        [-1.8151,  1.8665, -0.3283],\n",
            "        [-1.9723,  0.7737,  1.1359],\n",
            "        [-2.0030,  1.0159,  1.0065],\n",
            "        [-1.9815,  1.9627, -0.2953],\n",
            "        [-2.3292,  1.3103,  0.9692],\n",
            "        [-1.9389,  1.0161,  0.9921],\n",
            "        [-1.7675,  0.6732,  1.3080],\n",
            "        [ 0.6022,  0.1074, -1.1962],\n",
            "        [-1.9939,  0.8230,  1.1158],\n",
            "        [-1.7097,  1.8474, -0.5112],\n",
            "        [-2.0390,  1.8111, -0.1452],\n",
            "        [-2.0634,  0.5636,  1.2759],\n",
            "        [-2.0481,  0.5969,  1.2108],\n",
            "        [-1.8675,  0.4968,  1.3224],\n",
            "        [-1.9135,  2.0842, -0.3527]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9942,  2.0902, -0.1385],\n",
            "        [-1.8151,  1.8665, -0.3283],\n",
            "        [-1.9723,  0.7737,  1.1359],\n",
            "        [-2.0030,  1.0159,  1.0065],\n",
            "        [-1.9815,  1.9627, -0.2953],\n",
            "        [-2.3292,  1.3103,  0.9692],\n",
            "        [-1.9389,  1.0161,  0.9921],\n",
            "        [-1.7675,  0.6732,  1.3080],\n",
            "        [ 0.6022,  0.1074, -1.1962],\n",
            "        [-1.9939,  0.8230,  1.1158],\n",
            "        [-1.7097,  1.8474, -0.5112],\n",
            "        [-2.0390,  1.8111, -0.1452],\n",
            "        [-2.0634,  0.5636,  1.2759],\n",
            "        [-2.0481,  0.5969,  1.2108],\n",
            "        [-1.8675,  0.4968,  1.3224],\n",
            "        [-1.9135,  2.0842, -0.3527]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7980,  1.8182, -0.1999],\n",
            "        [ 0.5378, -0.1084, -1.1419],\n",
            "        [-1.5799,  1.6470, -0.1904],\n",
            "        [ 0.3984,  0.1839, -1.0960],\n",
            "        [-1.9080,  1.8313, -0.3037],\n",
            "        [-1.7530,  1.9266, -0.2786],\n",
            "        [-1.7286,  1.6291, -0.3510],\n",
            "        [-1.9607,  0.6654,  1.2436],\n",
            "        [-2.0890,  2.0549, -0.0959],\n",
            "        [-2.0596,  0.4082,  1.2142],\n",
            "        [-1.8706,  1.6287, -0.3982],\n",
            "        [-1.7543,  0.3972,  1.5293],\n",
            "        [-1.3795,  1.6849, -0.4770],\n",
            "        [-1.9658,  0.6488,  1.1112],\n",
            "        [ 0.3569,  0.2318, -1.1292],\n",
            "        [-1.8302,  0.5873,  1.1921]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7980,  1.8182, -0.1999],\n",
            "        [ 0.5378, -0.1084, -1.1419],\n",
            "        [-1.5799,  1.6470, -0.1904],\n",
            "        [ 0.3984,  0.1839, -1.0960],\n",
            "        [-1.9080,  1.8313, -0.3037],\n",
            "        [-1.7530,  1.9266, -0.2786],\n",
            "        [-1.7286,  1.6291, -0.3510],\n",
            "        [-1.9607,  0.6654,  1.2436],\n",
            "        [-2.0890,  2.0549, -0.0959],\n",
            "        [-2.0596,  0.4082,  1.2142],\n",
            "        [-1.8706,  1.6287, -0.3982],\n",
            "        [-1.7543,  0.3972,  1.5293],\n",
            "        [-1.3795,  1.6849, -0.4770],\n",
            "        [-1.9658,  0.6488,  1.1112],\n",
            "        [ 0.3569,  0.2318, -1.1292],\n",
            "        [-1.8302,  0.5873,  1.1921]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8479,  2.0584, -0.0996],\n",
            "        [ 0.3623,  0.1438, -1.2882],\n",
            "        [-1.9347,  0.6443,  1.1041],\n",
            "        [-1.9370,  0.6789,  1.1821],\n",
            "        [-1.7790,  1.9675, -0.4425],\n",
            "        [-1.7972,  1.9402, -0.1043],\n",
            "        [-1.8331,  1.7018, -0.3202],\n",
            "        [-1.9154,  1.8921, -0.3182],\n",
            "        [-1.9189,  0.6953,  0.9784],\n",
            "        [-1.7494,  0.8724,  0.9901],\n",
            "        [-1.8227,  2.0763, -0.3115],\n",
            "        [-1.9983,  2.0407, -0.3671],\n",
            "        [-1.6868,  0.5475,  1.1710],\n",
            "        [-1.7702,  1.8537, -0.2858],\n",
            "        [-1.9552,  0.4888,  1.2935],\n",
            "        [-1.7566,  1.6489, -0.4958]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8479,  2.0584, -0.0996],\n",
            "        [ 0.3623,  0.1438, -1.2882],\n",
            "        [-1.9347,  0.6443,  1.1041],\n",
            "        [-1.9370,  0.6789,  1.1821],\n",
            "        [-1.7790,  1.9675, -0.4425],\n",
            "        [-1.7972,  1.9402, -0.1043],\n",
            "        [-1.8331,  1.7018, -0.3202],\n",
            "        [-1.9154,  1.8921, -0.3182],\n",
            "        [-1.9189,  0.6953,  0.9784],\n",
            "        [-1.7494,  0.8724,  0.9901],\n",
            "        [-1.8227,  2.0763, -0.3115],\n",
            "        [-1.9983,  2.0407, -0.3671],\n",
            "        [-1.6868,  0.5475,  1.1710],\n",
            "        [-1.7702,  1.8537, -0.2858],\n",
            "        [-1.9552,  0.4888,  1.2935],\n",
            "        [-1.7566,  1.6489, -0.4958]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9307,  2.0363, -0.3245],\n",
            "        [-1.6219,  1.8414, -0.0714],\n",
            "        [-1.9649,  2.1018, -0.2763],\n",
            "        [-1.6731,  1.9228, -0.3601],\n",
            "        [-1.7037,  1.5106,  0.0371],\n",
            "        [ 0.2599,  0.0743, -0.9675],\n",
            "        [ 0.2748,  0.0330, -1.0775],\n",
            "        [-1.7224,  2.1108, -0.2542],\n",
            "        [-1.8804,  0.8747,  0.9933],\n",
            "        [-1.6732,  2.0709, -0.2981],\n",
            "        [-1.6539,  1.8554, -0.4258],\n",
            "        [-1.8355,  0.5844,  0.6613],\n",
            "        [-2.0574,  0.7337,  1.2831],\n",
            "        [-1.4836,  1.8052, -0.6323],\n",
            "        [-1.7690,  1.9873, -0.4126],\n",
            "        [-1.6033,  0.4178,  1.0673]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9307,  2.0363, -0.3245],\n",
            "        [-1.6219,  1.8414, -0.0714],\n",
            "        [-1.9649,  2.1018, -0.2763],\n",
            "        [-1.6731,  1.9228, -0.3601],\n",
            "        [-1.7037,  1.5106,  0.0371],\n",
            "        [ 0.2599,  0.0743, -0.9675],\n",
            "        [ 0.2748,  0.0330, -1.0775],\n",
            "        [-1.7224,  2.1108, -0.2542],\n",
            "        [-1.8804,  0.8747,  0.9933],\n",
            "        [-1.6732,  2.0709, -0.2981],\n",
            "        [-1.6539,  1.8554, -0.4258],\n",
            "        [-1.8355,  0.5844,  0.6613],\n",
            "        [-2.0574,  0.7337,  1.2831],\n",
            "        [-1.4836,  1.8052, -0.6323],\n",
            "        [-1.7690,  1.9873, -0.4126],\n",
            "        [-1.6033,  0.4178,  1.0673]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8083,  1.7724, -0.5149],\n",
            "        [-1.9951,  1.8223, -0.4616],\n",
            "        [-1.7856,  2.1509, -0.2868],\n",
            "        [-1.7153,  1.9446, -0.3100],\n",
            "        [-1.5731,  1.9493, -0.2597],\n",
            "        [-1.5344,  0.4096,  1.0032],\n",
            "        [-1.7836,  0.3695,  1.1569],\n",
            "        [-1.9661,  2.0626, -0.3652],\n",
            "        [ 0.3497,  0.1991, -1.0877],\n",
            "        [-1.8292,  0.3440,  1.0992],\n",
            "        [-1.8191,  2.1167, -0.2409],\n",
            "        [-1.9803,  2.1936, -0.2413],\n",
            "        [-1.6985,  1.7885, -0.1567],\n",
            "        [-2.0966,  0.6443,  1.3144],\n",
            "        [-1.2531,  1.6932, -0.4243],\n",
            "        [-1.7668,  1.6846, -0.3559]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8083,  1.7724, -0.5149],\n",
            "        [-1.9951,  1.8223, -0.4616],\n",
            "        [-1.7856,  2.1509, -0.2868],\n",
            "        [-1.7153,  1.9446, -0.3100],\n",
            "        [-1.5731,  1.9493, -0.2597],\n",
            "        [-1.5344,  0.4096,  1.0032],\n",
            "        [-1.7836,  0.3695,  1.1569],\n",
            "        [-1.9661,  2.0626, -0.3652],\n",
            "        [ 0.3497,  0.1991, -1.0877],\n",
            "        [-1.8292,  0.3440,  1.0992],\n",
            "        [-1.8191,  2.1167, -0.2409],\n",
            "        [-1.9803,  2.1936, -0.2413],\n",
            "        [-1.6985,  1.7885, -0.1567],\n",
            "        [-2.0966,  0.6443,  1.3144],\n",
            "        [-1.2531,  1.6932, -0.4243],\n",
            "        [-1.7668,  1.6846, -0.3559]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7525,  1.9652, -0.3241],\n",
            "        [-1.8975,  0.4272,  1.1395],\n",
            "        [ 0.2629,  0.3665, -1.1191],\n",
            "        [-1.7567,  2.0205, -0.2698],\n",
            "        [-1.7571,  1.9874, -0.3876],\n",
            "        [ 0.1211,  0.1156, -0.8422],\n",
            "        [-1.8915,  1.9172, -0.3969],\n",
            "        [-1.6747,  1.6847, -0.4213],\n",
            "        [-1.6744,  0.3784,  1.1378],\n",
            "        [-1.6920,  1.7475, -0.2400],\n",
            "        [-1.8550,  2.1188, -0.3315],\n",
            "        [-1.9267,  0.5915,  1.1201],\n",
            "        [-1.8264,  1.8960, -0.3748],\n",
            "        [-1.7115,  1.9335, -0.5082],\n",
            "        [-1.7704,  1.8712, -0.0452],\n",
            "        [-1.9056,  0.5679,  0.9822]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7525,  1.9652, -0.3241],\n",
            "        [-1.8975,  0.4272,  1.1395],\n",
            "        [ 0.2629,  0.3665, -1.1191],\n",
            "        [-1.7567,  2.0205, -0.2698],\n",
            "        [-1.7571,  1.9874, -0.3876],\n",
            "        [ 0.1211,  0.1156, -0.8422],\n",
            "        [-1.8915,  1.9172, -0.3969],\n",
            "        [-1.6747,  1.6847, -0.4213],\n",
            "        [-1.6744,  0.3784,  1.1378],\n",
            "        [-1.6920,  1.7475, -0.2400],\n",
            "        [-1.8550,  2.1188, -0.3315],\n",
            "        [-1.9267,  0.5915,  1.1201],\n",
            "        [-1.8264,  1.8960, -0.3748],\n",
            "        [-1.7115,  1.9335, -0.5082],\n",
            "        [-1.7704,  1.8712, -0.0452],\n",
            "        [-1.9056,  0.5679,  0.9822]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8660,  1.8749, -0.5445],\n",
            "        [-1.8426,  0.5804,  1.2778],\n",
            "        [-1.8822,  1.9538, -0.2412],\n",
            "        [-1.8126,  1.9790, -0.4160],\n",
            "        [-1.7901,  2.0532, -0.2859],\n",
            "        [-1.8853,  1.8744, -0.1772],\n",
            "        [ 0.5135,  0.0567, -1.1155],\n",
            "        [-1.3910,  1.5509, -0.4953],\n",
            "        [-1.5115,  1.9066, -0.6829],\n",
            "        [-1.9470,  0.6888,  1.1584],\n",
            "        [-1.7721,  2.0210, -0.4484],\n",
            "        [-1.6924,  1.7740, -0.3983],\n",
            "        [ 0.4272,  0.0373, -1.0885],\n",
            "        [-1.7705,  0.3702,  1.2029],\n",
            "        [-1.7932,  1.7822, -0.4328],\n",
            "        [-1.5846,  1.8354, -0.3797]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8660,  1.8749, -0.5445],\n",
            "        [-1.8426,  0.5804,  1.2778],\n",
            "        [-1.8822,  1.9538, -0.2412],\n",
            "        [-1.8126,  1.9790, -0.4160],\n",
            "        [-1.7901,  2.0532, -0.2859],\n",
            "        [-1.8853,  1.8744, -0.1772],\n",
            "        [ 0.5135,  0.0567, -1.1155],\n",
            "        [-1.3910,  1.5509, -0.4953],\n",
            "        [-1.5115,  1.9066, -0.6829],\n",
            "        [-1.9470,  0.6888,  1.1584],\n",
            "        [-1.7721,  2.0210, -0.4484],\n",
            "        [-1.6924,  1.7740, -0.3983],\n",
            "        [ 0.4272,  0.0373, -1.0885],\n",
            "        [-1.7705,  0.3702,  1.2029],\n",
            "        [-1.7932,  1.7822, -0.4328],\n",
            "        [-1.5846,  1.8354, -0.3797]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6748,  1.9600, -0.4428],\n",
            "        [-1.6248,  0.4356,  1.0657],\n",
            "        [-2.0002,  1.1919,  0.7020],\n",
            "        [-1.6277,  1.8079, -0.4701],\n",
            "        [-1.8650,  1.7775, -0.3249],\n",
            "        [-1.9540,  2.0137, -0.1804],\n",
            "        [-1.7163,  1.8050, -0.1945],\n",
            "        [-2.0278,  1.9535, -0.4901],\n",
            "        [-1.0150,  1.5149, -0.6359],\n",
            "        [-1.8702,  1.8903, -0.2577],\n",
            "        [-1.7972,  1.9464, -0.3362],\n",
            "        [-1.7838,  0.3794,  1.1399],\n",
            "        [-2.0173,  1.7785, -0.3003],\n",
            "        [ 0.2677,  0.1241, -1.2268],\n",
            "        [-1.5758,  1.9435, -0.4023],\n",
            "        [-1.8451,  1.2023,  0.6505]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6748,  1.9600, -0.4428],\n",
            "        [-1.6248,  0.4356,  1.0657],\n",
            "        [-2.0002,  1.1919,  0.7020],\n",
            "        [-1.6277,  1.8079, -0.4701],\n",
            "        [-1.8650,  1.7775, -0.3249],\n",
            "        [-1.9540,  2.0137, -0.1804],\n",
            "        [-1.7163,  1.8050, -0.1945],\n",
            "        [-2.0278,  1.9535, -0.4901],\n",
            "        [-1.0150,  1.5149, -0.6359],\n",
            "        [-1.8702,  1.8903, -0.2577],\n",
            "        [-1.7972,  1.9464, -0.3362],\n",
            "        [-1.7838,  0.3794,  1.1399],\n",
            "        [-2.0173,  1.7785, -0.3003],\n",
            "        [ 0.2677,  0.1241, -1.2268],\n",
            "        [-1.5758,  1.9435, -0.4023],\n",
            "        [-1.8451,  1.2023,  0.6505]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9606,  2.1562, -0.3095],\n",
            "        [-1.6698,  0.5230,  1.1168],\n",
            "        [-2.0048,  1.9029, -0.3187],\n",
            "        [-0.6298,  0.8456, -0.6928],\n",
            "        [-1.9193,  0.6646,  1.1171],\n",
            "        [-1.8636,  1.7973, -0.5010],\n",
            "        [-0.9564,  0.5730,  0.1302],\n",
            "        [-1.6832,  1.7630, -0.1887],\n",
            "        [-1.9827,  2.0621, -0.3679],\n",
            "        [-1.8827,  1.9858, -0.3370],\n",
            "        [-1.7297,  1.8601, -0.5081],\n",
            "        [-2.0898,  1.5150,  0.6650],\n",
            "        [-1.6904,  1.9821, -0.6824],\n",
            "        [-1.7981,  0.7138,  0.9162],\n",
            "        [-2.0074,  2.1407, -0.4088],\n",
            "        [-1.9032,  0.5762,  1.3409]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9606,  2.1562, -0.3095],\n",
            "        [-1.6698,  0.5230,  1.1168],\n",
            "        [-2.0048,  1.9029, -0.3187],\n",
            "        [-0.6298,  0.8456, -0.6928],\n",
            "        [-1.9193,  0.6646,  1.1171],\n",
            "        [-1.8636,  1.7973, -0.5010],\n",
            "        [-0.9564,  0.5730,  0.1302],\n",
            "        [-1.6832,  1.7630, -0.1887],\n",
            "        [-1.9827,  2.0621, -0.3679],\n",
            "        [-1.8827,  1.9858, -0.3370],\n",
            "        [-1.7297,  1.8601, -0.5081],\n",
            "        [-2.0898,  1.5150,  0.6650],\n",
            "        [-1.6904,  1.9821, -0.6824],\n",
            "        [-1.7981,  0.7138,  0.9162],\n",
            "        [-2.0074,  2.1407, -0.4088],\n",
            "        [-1.9032,  0.5762,  1.3409]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2036,  0.9262,  0.7218],\n",
            "        [-1.7497,  0.4749,  1.1178],\n",
            "        [-1.9861,  1.5614,  0.6529],\n",
            "        [-1.9982,  0.3998,  1.0781],\n",
            "        [-1.9056,  1.9130, -0.3591],\n",
            "        [-1.0480,  1.7295, -0.8152],\n",
            "        [ 0.2646,  0.3166, -1.0304],\n",
            "        [-1.9406,  0.4069,  1.3602],\n",
            "        [ 0.4075,  0.2348, -1.1179],\n",
            "        [-1.7512,  0.4268,  0.9516],\n",
            "        [-2.0296,  1.6191,  0.3028],\n",
            "        [-2.0461,  2.1408, -0.3807],\n",
            "        [-1.7303,  1.9916, -0.3444],\n",
            "        [-1.7037,  1.8755, -0.4344],\n",
            "        [ 0.3611,  0.2053, -1.2159],\n",
            "        [-1.9134,  1.7118, -0.4952]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.2036,  0.9262,  0.7218],\n",
            "        [-1.7497,  0.4749,  1.1178],\n",
            "        [-1.9861,  1.5614,  0.6529],\n",
            "        [-1.9982,  0.3998,  1.0781],\n",
            "        [-1.9056,  1.9130, -0.3591],\n",
            "        [-1.0480,  1.7295, -0.8152],\n",
            "        [ 0.2646,  0.3166, -1.0304],\n",
            "        [-1.9406,  0.4069,  1.3602],\n",
            "        [ 0.4075,  0.2348, -1.1179],\n",
            "        [-1.7512,  0.4268,  0.9516],\n",
            "        [-2.0296,  1.6191,  0.3028],\n",
            "        [-2.0461,  2.1408, -0.3807],\n",
            "        [-1.7303,  1.9916, -0.3444],\n",
            "        [-1.7037,  1.8755, -0.4344],\n",
            "        [ 0.3611,  0.2053, -1.2159],\n",
            "        [-1.9134,  1.7118, -0.4952]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8400,  1.9085, -0.4476],\n",
            "        [ 0.3590,  0.1874, -1.3033],\n",
            "        [-1.7842,  1.9746, -0.2446],\n",
            "        [-1.8644,  2.0313, -0.2448],\n",
            "        [-1.6365,  1.8469, -0.2758],\n",
            "        [-1.8771,  2.0469, -0.0540],\n",
            "        [-1.8565,  0.2294,  1.2499],\n",
            "        [-1.5799,  1.8119, -0.6076],\n",
            "        [-1.9380,  0.4329,  1.0873],\n",
            "        [-2.0572,  0.3752,  1.3735],\n",
            "        [-1.5742,  2.1793, -0.3366],\n",
            "        [-1.7516,  1.7845, -0.4661],\n",
            "        [-1.8871,  2.1306, -0.3173],\n",
            "        [-1.9003,  1.9443, -0.4837],\n",
            "        [-2.0384,  0.4263,  1.2963],\n",
            "        [-1.7777,  2.0657, -0.5315]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8400,  1.9085, -0.4476],\n",
            "        [ 0.3590,  0.1874, -1.3033],\n",
            "        [-1.7842,  1.9746, -0.2446],\n",
            "        [-1.8644,  2.0313, -0.2448],\n",
            "        [-1.6365,  1.8469, -0.2758],\n",
            "        [-1.8771,  2.0469, -0.0540],\n",
            "        [-1.8565,  0.2294,  1.2499],\n",
            "        [-1.5799,  1.8119, -0.6076],\n",
            "        [-1.9380,  0.4329,  1.0873],\n",
            "        [-2.0572,  0.3752,  1.3735],\n",
            "        [-1.5742,  2.1793, -0.3366],\n",
            "        [-1.7516,  1.7845, -0.4661],\n",
            "        [-1.8871,  2.1306, -0.3173],\n",
            "        [-1.9003,  1.9443, -0.4837],\n",
            "        [-2.0384,  0.4263,  1.2963],\n",
            "        [-1.7777,  2.0657, -0.5315]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6279,  0.3681,  0.7816],\n",
            "        [-1.7392,  0.2851,  1.4885],\n",
            "        [-1.7766,  1.9113, -0.3439],\n",
            "        [-1.8943,  2.1135, -0.4690],\n",
            "        [-1.8135,  0.4560,  1.1208],\n",
            "        [ 0.1411,  0.0766, -0.6246],\n",
            "        [-1.9609,  2.0792, -0.5031],\n",
            "        [-1.6989,  1.8595, -0.5281],\n",
            "        [-2.0025,  2.0317, -0.4098],\n",
            "        [-1.7915,  0.8376,  0.5425],\n",
            "        [-1.7606,  2.1153, -0.3894],\n",
            "        [-1.7181,  1.7677, -0.4273],\n",
            "        [ 0.4513,  0.2618, -1.3077],\n",
            "        [-1.8550,  2.1785, -0.5276],\n",
            "        [-1.0710,  1.5008, -0.8776],\n",
            "        [-1.8953,  0.4994,  1.3044]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6279,  0.3681,  0.7816],\n",
            "        [-1.7392,  0.2851,  1.4885],\n",
            "        [-1.7766,  1.9113, -0.3439],\n",
            "        [-1.8943,  2.1135, -0.4690],\n",
            "        [-1.8135,  0.4560,  1.1208],\n",
            "        [ 0.1411,  0.0766, -0.6246],\n",
            "        [-1.9609,  2.0792, -0.5031],\n",
            "        [-1.6989,  1.8595, -0.5281],\n",
            "        [-2.0025,  2.0317, -0.4098],\n",
            "        [-1.7915,  0.8376,  0.5425],\n",
            "        [-1.7606,  2.1153, -0.3894],\n",
            "        [-1.7181,  1.7677, -0.4273],\n",
            "        [ 0.4513,  0.2618, -1.3077],\n",
            "        [-1.8550,  2.1785, -0.5276],\n",
            "        [-1.0710,  1.5008, -0.8776],\n",
            "        [-1.8953,  0.4994,  1.3044]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7692,  2.0139, -0.5853],\n",
            "        [-2.2589,  0.8491,  1.0181],\n",
            "        [-1.6896,  1.8707, -0.5687],\n",
            "        [ 0.1733,  0.4885, -1.2557],\n",
            "        [-1.9978,  1.8205, -0.4790],\n",
            "        [ 0.2456,  0.2832, -1.2197],\n",
            "        [-1.9085,  2.3048, -0.5203],\n",
            "        [-1.5187,  1.8405, -0.3895],\n",
            "        [-1.6126,  1.9507, -0.5983],\n",
            "        [-1.8174,  1.9137, -0.3143],\n",
            "        [-1.6296,  2.1305, -0.3006],\n",
            "        [-1.0601,  0.2419,  0.7057],\n",
            "        [-1.7427,  2.0598, -0.4237],\n",
            "        [ 0.0922,  0.3264, -1.1137],\n",
            "        [ 0.5191,  0.2044, -1.1542],\n",
            "        [ 0.4931,  0.1730, -1.2406]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7692,  2.0139, -0.5853],\n",
            "        [-2.2589,  0.8491,  1.0181],\n",
            "        [-1.6896,  1.8707, -0.5687],\n",
            "        [ 0.1733,  0.4885, -1.2557],\n",
            "        [-1.9978,  1.8205, -0.4790],\n",
            "        [ 0.2456,  0.2832, -1.2197],\n",
            "        [-1.9085,  2.3048, -0.5203],\n",
            "        [-1.5187,  1.8405, -0.3895],\n",
            "        [-1.6126,  1.9507, -0.5983],\n",
            "        [-1.8174,  1.9137, -0.3143],\n",
            "        [-1.6296,  2.1305, -0.3006],\n",
            "        [-1.0601,  0.2419,  0.7057],\n",
            "        [-1.7427,  2.0598, -0.4237],\n",
            "        [ 0.0922,  0.3264, -1.1137],\n",
            "        [ 0.5191,  0.2044, -1.1542],\n",
            "        [ 0.4931,  0.1730, -1.2406]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5252,  1.9213, -0.4386],\n",
            "        [-1.7096,  0.3284,  1.0872],\n",
            "        [-1.8320,  0.3441,  1.2749],\n",
            "        [-1.7152,  2.1213, -0.6461],\n",
            "        [-1.9038,  1.1141,  0.2633],\n",
            "        [-1.8664,  0.2175,  1.2378],\n",
            "        [-1.8154,  0.3972,  1.2893],\n",
            "        [-1.8493,  1.7756, -0.2249],\n",
            "        [-1.6412,  0.4445,  1.0318],\n",
            "        [-1.8875,  1.7912, -0.4217],\n",
            "        [-1.6430,  1.8705, -0.2933],\n",
            "        [-1.8030,  1.8756, -0.5596],\n",
            "        [-1.5716,  0.0380,  1.2243],\n",
            "        [-1.3696,  1.8191, -0.6861],\n",
            "        [-1.7434,  1.8284, -0.5765],\n",
            "        [-1.6973,  2.0750, -0.5175]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5252,  1.9213, -0.4386],\n",
            "        [-1.7096,  0.3284,  1.0872],\n",
            "        [-1.8320,  0.3441,  1.2749],\n",
            "        [-1.7152,  2.1213, -0.6461],\n",
            "        [-1.9038,  1.1141,  0.2633],\n",
            "        [-1.8664,  0.2175,  1.2378],\n",
            "        [-1.8154,  0.3972,  1.2893],\n",
            "        [-1.8493,  1.7756, -0.2249],\n",
            "        [-1.6412,  0.4445,  1.0318],\n",
            "        [-1.8875,  1.7912, -0.4217],\n",
            "        [-1.6430,  1.8705, -0.2933],\n",
            "        [-1.8030,  1.8756, -0.5596],\n",
            "        [-1.5716,  0.0380,  1.2243],\n",
            "        [-1.3696,  1.8191, -0.6861],\n",
            "        [-1.7434,  1.8284, -0.5765],\n",
            "        [-1.6973,  2.0750, -0.5175]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7745,  1.9660, -0.4560],\n",
            "        [-1.7890,  0.5788,  0.9748],\n",
            "        [-1.6745,  1.9331, -0.3726],\n",
            "        [-1.7952,  0.6676,  1.0400],\n",
            "        [-1.8383,  2.2814, -0.1828],\n",
            "        [-1.6925,  1.9567, -0.4894],\n",
            "        [-1.7349,  1.9645, -0.6530],\n",
            "        [ 0.5281,  0.0752, -1.1620],\n",
            "        [-1.5582,  1.8518, -0.6458],\n",
            "        [-1.9488,  2.0139, -0.3065],\n",
            "        [-1.8632,  1.9149, -0.5723],\n",
            "        [-1.6943,  1.9115, -0.4038],\n",
            "        [-1.7650,  2.0306, -0.4803],\n",
            "        [-1.6937,  1.9408, -0.5429],\n",
            "        [ 0.4106,  0.1429, -1.0923],\n",
            "        [-1.5688,  0.4863,  1.2578]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7745,  1.9660, -0.4560],\n",
            "        [-1.7890,  0.5788,  0.9748],\n",
            "        [-1.6745,  1.9331, -0.3726],\n",
            "        [-1.7952,  0.6676,  1.0400],\n",
            "        [-1.8383,  2.2814, -0.1828],\n",
            "        [-1.6925,  1.9567, -0.4894],\n",
            "        [-1.7349,  1.9645, -0.6530],\n",
            "        [ 0.5281,  0.0752, -1.1620],\n",
            "        [-1.5582,  1.8518, -0.6458],\n",
            "        [-1.9488,  2.0139, -0.3065],\n",
            "        [-1.8632,  1.9149, -0.5723],\n",
            "        [-1.6943,  1.9115, -0.4038],\n",
            "        [-1.7650,  2.0306, -0.4803],\n",
            "        [-1.6937,  1.9408, -0.5429],\n",
            "        [ 0.4106,  0.1429, -1.0923],\n",
            "        [-1.5688,  0.4863,  1.2578]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7736,  2.0627, -0.6058],\n",
            "        [-1.8352,  0.2005,  1.3048],\n",
            "        [-1.6112,  2.0560, -0.5609],\n",
            "        [ 0.3491,  0.4007, -1.2989],\n",
            "        [-1.7068,  0.2969,  1.3284],\n",
            "        [-1.7138,  2.1404, -0.8328],\n",
            "        [-1.6378,  0.4053,  1.2730],\n",
            "        [-1.6290,  1.8353, -0.4253],\n",
            "        [-1.7594,  1.8212, -0.4312],\n",
            "        [-1.5416,  1.8649, -0.3969],\n",
            "        [-2.0323,  0.2427,  1.3426],\n",
            "        [-1.8022,  0.4753,  1.0479],\n",
            "        [-1.8517,  1.9885, -0.3742],\n",
            "        [-1.8189,  1.0586,  0.6515],\n",
            "        [-1.5893,  1.7368, -0.5048],\n",
            "        [ 0.4434,  0.1376, -1.1964]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7736,  2.0627, -0.6058],\n",
            "        [-1.8352,  0.2005,  1.3048],\n",
            "        [-1.6112,  2.0560, -0.5609],\n",
            "        [ 0.3491,  0.4007, -1.2989],\n",
            "        [-1.7068,  0.2969,  1.3284],\n",
            "        [-1.7138,  2.1404, -0.8328],\n",
            "        [-1.6378,  0.4053,  1.2730],\n",
            "        [-1.6290,  1.8353, -0.4253],\n",
            "        [-1.7594,  1.8212, -0.4312],\n",
            "        [-1.5416,  1.8649, -0.3969],\n",
            "        [-2.0323,  0.2427,  1.3426],\n",
            "        [-1.8022,  0.4753,  1.0479],\n",
            "        [-1.8517,  1.9885, -0.3742],\n",
            "        [-1.8189,  1.0586,  0.6515],\n",
            "        [-1.5893,  1.7368, -0.5048],\n",
            "        [ 0.4434,  0.1376, -1.1964]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7739,  1.9923, -0.4330],\n",
            "        [-1.6601,  1.8789, -0.6610],\n",
            "        [-1.4216,  1.6801, -0.6932],\n",
            "        [-1.6464,  1.7489, -0.4276],\n",
            "        [-1.7079,  0.2054,  1.2793],\n",
            "        [-1.3162,  1.9006, -0.8569],\n",
            "        [-1.6132,  1.4584,  0.0099],\n",
            "        [-1.5550,  1.8305, -0.8419],\n",
            "        [-1.7375,  0.1700,  1.3359],\n",
            "        [-1.0377,  1.3860, -0.7167],\n",
            "        [ 0.0174,  0.5501, -1.1787],\n",
            "        [-1.7928,  1.6526, -0.1569],\n",
            "        [-1.7193,  0.3138,  1.2413],\n",
            "        [-1.4750,  1.9862, -0.4033],\n",
            "        [-1.6392,  0.3088,  1.1460],\n",
            "        [-1.3113,  1.8278, -0.4939]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7739,  1.9923, -0.4330],\n",
            "        [-1.6601,  1.8789, -0.6610],\n",
            "        [-1.4216,  1.6801, -0.6932],\n",
            "        [-1.6464,  1.7489, -0.4276],\n",
            "        [-1.7079,  0.2054,  1.2793],\n",
            "        [-1.3162,  1.9006, -0.8569],\n",
            "        [-1.6132,  1.4584,  0.0099],\n",
            "        [-1.5550,  1.8305, -0.8419],\n",
            "        [-1.7375,  0.1700,  1.3359],\n",
            "        [-1.0377,  1.3860, -0.7167],\n",
            "        [ 0.0174,  0.5501, -1.1787],\n",
            "        [-1.7928,  1.6526, -0.1569],\n",
            "        [-1.7193,  0.3138,  1.2413],\n",
            "        [-1.4750,  1.9862, -0.4033],\n",
            "        [-1.6392,  0.3088,  1.1460],\n",
            "        [-1.3113,  1.8278, -0.4939]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5794e+00,  1.8629e+00, -6.4519e-01],\n",
            "        [-1.9590e+00,  8.6451e-01,  8.5850e-01],\n",
            "        [-1.6082e+00,  9.3913e-01,  7.6599e-01],\n",
            "        [-1.7271e+00,  1.5440e+00, -3.8058e-02],\n",
            "        [-1.5898e+00,  5.1686e-01,  9.0137e-01],\n",
            "        [-1.2308e+00,  1.6780e+00, -8.7869e-01],\n",
            "        [ 2.0115e-01,  2.4193e-01, -1.3580e+00],\n",
            "        [-5.9021e-01,  1.3048e-03,  1.8510e-01],\n",
            "        [-1.6009e+00,  4.0568e-01,  1.1234e+00],\n",
            "        [-1.8636e-01,  2.1929e-01, -3.8122e-01],\n",
            "        [ 3.4342e-01,  3.2392e-01, -1.1749e+00],\n",
            "        [-1.4418e+00,  2.1783e+00, -7.1542e-01],\n",
            "        [-1.5751e+00,  2.0010e+00, -6.6718e-01],\n",
            "        [-1.7376e+00,  4.2319e-01,  1.1537e+00],\n",
            "        [-1.7375e+00,  2.0880e+00, -3.6358e-01],\n",
            "        [-1.7941e+00,  3.4722e-01,  1.3819e+00]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5794e+00,  1.8629e+00, -6.4519e-01],\n",
            "        [-1.9590e+00,  8.6451e-01,  8.5850e-01],\n",
            "        [-1.6082e+00,  9.3913e-01,  7.6599e-01],\n",
            "        [-1.7271e+00,  1.5440e+00, -3.8058e-02],\n",
            "        [-1.5898e+00,  5.1686e-01,  9.0137e-01],\n",
            "        [-1.2308e+00,  1.6780e+00, -8.7869e-01],\n",
            "        [ 2.0115e-01,  2.4193e-01, -1.3580e+00],\n",
            "        [-5.9021e-01,  1.3048e-03,  1.8510e-01],\n",
            "        [-1.6009e+00,  4.0568e-01,  1.1234e+00],\n",
            "        [-1.8636e-01,  2.1929e-01, -3.8122e-01],\n",
            "        [ 3.4342e-01,  3.2392e-01, -1.1749e+00],\n",
            "        [-1.4418e+00,  2.1783e+00, -7.1542e-01],\n",
            "        [-1.5751e+00,  2.0010e+00, -6.6718e-01],\n",
            "        [-1.7376e+00,  4.2319e-01,  1.1537e+00],\n",
            "        [-1.7375e+00,  2.0880e+00, -3.6358e-01],\n",
            "        [-1.7941e+00,  3.4722e-01,  1.3819e+00]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6248,  2.0606, -0.6565],\n",
            "        [-1.9503,  0.7815,  0.8621],\n",
            "        [-1.6487,  0.4016,  1.0643],\n",
            "        [-1.7697,  1.8451, -0.8832],\n",
            "        [-1.6866,  0.3014,  1.1326],\n",
            "        [-1.5357,  1.7199, -0.5801],\n",
            "        [-1.7184,  0.2217,  1.2624],\n",
            "        [-1.7445,  0.2814,  1.1862],\n",
            "        [-1.7794,  1.9634, -0.4928],\n",
            "        [-1.5544,  0.3562,  1.2622],\n",
            "        [-0.9092,  0.1428,  0.5464],\n",
            "        [-1.6405,  1.1909,  0.2435],\n",
            "        [-1.5503,  2.0247, -0.7061],\n",
            "        [ 0.3406,  0.2806, -1.4682],\n",
            "        [-1.4167,  1.3452,  0.0232],\n",
            "        [-1.6396,  1.7918, -0.4996]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6248,  2.0606, -0.6565],\n",
            "        [-1.9503,  0.7815,  0.8621],\n",
            "        [-1.6487,  0.4016,  1.0643],\n",
            "        [-1.7697,  1.8451, -0.8832],\n",
            "        [-1.6866,  0.3014,  1.1326],\n",
            "        [-1.5357,  1.7199, -0.5801],\n",
            "        [-1.7184,  0.2217,  1.2624],\n",
            "        [-1.7445,  0.2814,  1.1862],\n",
            "        [-1.7794,  1.9634, -0.4928],\n",
            "        [-1.5544,  0.3562,  1.2622],\n",
            "        [-0.9092,  0.1428,  0.5464],\n",
            "        [-1.6405,  1.1909,  0.2435],\n",
            "        [-1.5503,  2.0247, -0.7061],\n",
            "        [ 0.3406,  0.2806, -1.4682],\n",
            "        [-1.4167,  1.3452,  0.0232],\n",
            "        [-1.6396,  1.7918, -0.4996]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3056,  0.2184, -1.1431],\n",
            "        [-1.8521,  0.5970,  1.1491],\n",
            "        [-0.9147,  1.4155, -0.8999],\n",
            "        [-1.5910,  1.7953, -0.4507],\n",
            "        [-1.6338,  0.3119,  0.8881],\n",
            "        [-1.5992,  2.0259, -0.4318],\n",
            "        [-1.8064,  1.5130,  0.1901],\n",
            "        [-1.5522,  1.3344,  0.0151],\n",
            "        [-1.5733, -0.0253,  1.1056],\n",
            "        [-1.5026,  1.8396, -0.5730],\n",
            "        [-1.6040,  0.9658,  0.5994],\n",
            "        [-1.7762,  0.3203,  1.3648],\n",
            "        [-1.6016,  2.2204, -0.8538],\n",
            "        [-1.5378,  1.9459, -0.5111],\n",
            "        [-1.6948,  2.0717, -0.6386],\n",
            "        [-1.4851,  0.0417,  1.2058]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.3056,  0.2184, -1.1431],\n",
            "        [-1.8521,  0.5970,  1.1491],\n",
            "        [-0.9147,  1.4155, -0.8999],\n",
            "        [-1.5910,  1.7953, -0.4507],\n",
            "        [-1.6338,  0.3119,  0.8881],\n",
            "        [-1.5992,  2.0259, -0.4318],\n",
            "        [-1.8064,  1.5130,  0.1901],\n",
            "        [-1.5522,  1.3344,  0.0151],\n",
            "        [-1.5733, -0.0253,  1.1056],\n",
            "        [-1.5026,  1.8396, -0.5730],\n",
            "        [-1.6040,  0.9658,  0.5994],\n",
            "        [-1.7762,  0.3203,  1.3648],\n",
            "        [-1.6016,  2.2204, -0.8538],\n",
            "        [-1.5378,  1.9459, -0.5111],\n",
            "        [-1.6948,  2.0717, -0.6386],\n",
            "        [-1.4851,  0.0417,  1.2058]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2615,  1.7893, -0.6798],\n",
            "        [-1.2038,  0.3943,  0.9898],\n",
            "        [ 0.3647,  0.2040, -1.2812],\n",
            "        [-1.3794,  1.8432, -0.7378],\n",
            "        [-1.4748,  2.0703, -0.4477],\n",
            "        [ 0.4292,  0.2698, -1.1390],\n",
            "        [-1.4523,  1.7731, -0.7638],\n",
            "        [-1.2680,  1.6996, -0.9897],\n",
            "        [-1.6568,  0.9851,  0.9644],\n",
            "        [-0.0494,  0.8286, -1.1555],\n",
            "        [-1.3237,  1.7759, -0.7526],\n",
            "        [-1.6277,  1.7708, -0.3252],\n",
            "        [-1.3630,  1.7443, -0.7142],\n",
            "        [-1.6425,  2.1538, -0.7228],\n",
            "        [-1.4518,  1.7022, -0.5117],\n",
            "        [-1.7142,  0.5255,  1.0116]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2615,  1.7893, -0.6798],\n",
            "        [-1.2038,  0.3943,  0.9898],\n",
            "        [ 0.3647,  0.2040, -1.2812],\n",
            "        [-1.3794,  1.8432, -0.7378],\n",
            "        [-1.4748,  2.0703, -0.4477],\n",
            "        [ 0.4292,  0.2698, -1.1390],\n",
            "        [-1.4523,  1.7731, -0.7638],\n",
            "        [-1.2680,  1.6996, -0.9897],\n",
            "        [-1.6568,  0.9851,  0.9644],\n",
            "        [-0.0494,  0.8286, -1.1555],\n",
            "        [-1.3237,  1.7759, -0.7526],\n",
            "        [-1.6277,  1.7708, -0.3252],\n",
            "        [-1.3630,  1.7443, -0.7142],\n",
            "        [-1.6425,  2.1538, -0.7228],\n",
            "        [-1.4518,  1.7022, -0.5117],\n",
            "        [-1.7142,  0.5255,  1.0116]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6267,  1.8620, -0.7135],\n",
            "        [-1.7319,  1.9165, -0.8047],\n",
            "        [-1.6068,  1.8157, -0.8278],\n",
            "        [-1.3443,  1.8232, -0.5394],\n",
            "        [ 0.4261,  0.3012, -1.2540],\n",
            "        [-1.6045,  1.8891, -0.5859],\n",
            "        [-1.4978,  0.4510,  0.7023],\n",
            "        [-1.5168,  1.8771, -0.5920],\n",
            "        [-1.3977,  0.5728,  0.8956],\n",
            "        [-1.6626,  1.8852, -0.4590],\n",
            "        [-1.5667,  0.3138,  1.2589],\n",
            "        [-1.5358,  1.7222, -0.6250],\n",
            "        [-0.4269,  0.0951, -0.0748],\n",
            "        [-1.6538,  1.9351, -0.9336],\n",
            "        [ 0.3320,  0.0877, -1.1219],\n",
            "        [-1.7280,  0.5643,  0.8074]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6267,  1.8620, -0.7135],\n",
            "        [-1.7319,  1.9165, -0.8047],\n",
            "        [-1.6068,  1.8157, -0.8278],\n",
            "        [-1.3443,  1.8232, -0.5394],\n",
            "        [ 0.4261,  0.3012, -1.2540],\n",
            "        [-1.6045,  1.8891, -0.5859],\n",
            "        [-1.4978,  0.4510,  0.7023],\n",
            "        [-1.5168,  1.8771, -0.5920],\n",
            "        [-1.3977,  0.5728,  0.8956],\n",
            "        [-1.6626,  1.8852, -0.4590],\n",
            "        [-1.5667,  0.3138,  1.2589],\n",
            "        [-1.5358,  1.7222, -0.6250],\n",
            "        [-0.4269,  0.0951, -0.0748],\n",
            "        [-1.6538,  1.9351, -0.9336],\n",
            "        [ 0.3320,  0.0877, -1.1219],\n",
            "        [-1.7280,  0.5643,  0.8074]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5949,  1.6930, -0.7674],\n",
            "        [-1.7462,  2.0470, -0.6234],\n",
            "        [-1.6251,  0.2798,  1.1876],\n",
            "        [-0.6523,  1.1605, -1.0752],\n",
            "        [-1.2129,  1.4906, -0.7974],\n",
            "        [-1.5819,  0.2393,  1.2834],\n",
            "        [-1.7473,  1.6802, -0.4893],\n",
            "        [-1.4404,  1.7460, -0.6432],\n",
            "        [-1.6423,  0.2522,  1.1973],\n",
            "        [-1.4397,  1.9393, -0.3364],\n",
            "        [-1.7097,  2.2586, -0.6995],\n",
            "        [ 0.4146,  0.2640, -1.1856],\n",
            "        [-1.5266,  1.7317, -0.8354],\n",
            "        [-1.5846,  1.8581, -0.4835],\n",
            "        [-1.4187,  0.2568,  1.1044],\n",
            "        [-1.6695,  1.9573, -0.7799]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5949,  1.6930, -0.7674],\n",
            "        [-1.7462,  2.0470, -0.6234],\n",
            "        [-1.6251,  0.2798,  1.1876],\n",
            "        [-0.6523,  1.1605, -1.0752],\n",
            "        [-1.2129,  1.4906, -0.7974],\n",
            "        [-1.5819,  0.2393,  1.2834],\n",
            "        [-1.7473,  1.6802, -0.4893],\n",
            "        [-1.4404,  1.7460, -0.6432],\n",
            "        [-1.6423,  0.2522,  1.1973],\n",
            "        [-1.4397,  1.9393, -0.3364],\n",
            "        [-1.7097,  2.2586, -0.6995],\n",
            "        [ 0.4146,  0.2640, -1.1856],\n",
            "        [-1.5266,  1.7317, -0.8354],\n",
            "        [-1.5846,  1.8581, -0.4835],\n",
            "        [-1.4187,  0.2568,  1.1044],\n",
            "        [-1.6695,  1.9573, -0.7799]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4103,  1.5968, -0.4879],\n",
            "        [-1.4696,  1.9246, -0.8021],\n",
            "        [-1.4646,  1.3495, -0.1813],\n",
            "        [ 0.4882,  0.1416, -1.2658],\n",
            "        [-1.5987,  2.0709, -0.7942],\n",
            "        [-1.4347,  1.8536, -0.7757],\n",
            "        [-1.3382,  1.7154, -0.8256],\n",
            "        [ 0.7612,  0.0726, -1.4210],\n",
            "        [-1.4080,  1.9100, -0.7227],\n",
            "        [-1.3468,  0.2724,  1.1778],\n",
            "        [ 0.1371, -0.0344, -0.7152],\n",
            "        [ 0.7288,  0.2870, -1.4738],\n",
            "        [-1.6139,  1.6255, -0.5193],\n",
            "        [-1.1176,  1.7535, -0.8651],\n",
            "        [-1.7235,  0.3208,  1.0815],\n",
            "        [-1.7297,  1.5854,  0.0543]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4103,  1.5968, -0.4879],\n",
            "        [-1.4696,  1.9246, -0.8021],\n",
            "        [-1.4646,  1.3495, -0.1813],\n",
            "        [ 0.4882,  0.1416, -1.2658],\n",
            "        [-1.5987,  2.0709, -0.7942],\n",
            "        [-1.4347,  1.8536, -0.7757],\n",
            "        [-1.3382,  1.7154, -0.8256],\n",
            "        [ 0.7612,  0.0726, -1.4210],\n",
            "        [-1.4080,  1.9100, -0.7227],\n",
            "        [-1.3468,  0.2724,  1.1778],\n",
            "        [ 0.1371, -0.0344, -0.7152],\n",
            "        [ 0.7288,  0.2870, -1.4738],\n",
            "        [-1.6139,  1.6255, -0.5193],\n",
            "        [-1.1176,  1.7535, -0.8651],\n",
            "        [-1.7235,  0.3208,  1.0815],\n",
            "        [-1.7297,  1.5854,  0.0543]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.7386,  0.2022, -1.4592],\n",
            "        [-1.3748,  1.6102, -0.4933],\n",
            "        [-1.4840,  0.2022,  0.9567],\n",
            "        [-1.4508,  0.1528,  1.0912],\n",
            "        [-1.5023,  1.9587, -0.7293],\n",
            "        [-1.7127,  2.0166, -0.6973],\n",
            "        [-1.5687,  0.2689,  1.2111],\n",
            "        [-1.6104,  0.0478,  1.2185],\n",
            "        [-1.6073,  2.0078, -0.5508],\n",
            "        [-1.4382,  0.2937,  1.1345],\n",
            "        [-1.6299,  0.2200,  1.1629],\n",
            "        [-1.4824,  1.8311, -0.8161],\n",
            "        [-1.3948,  1.7578, -0.7826],\n",
            "        [ 0.6491,  0.0335, -1.3558],\n",
            "        [-1.2489,  1.6290, -0.6191],\n",
            "        [-1.3132,  1.8084, -0.7679]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.7386,  0.2022, -1.4592],\n",
            "        [-1.3748,  1.6102, -0.4933],\n",
            "        [-1.4840,  0.2022,  0.9567],\n",
            "        [-1.4508,  0.1528,  1.0912],\n",
            "        [-1.5023,  1.9587, -0.7293],\n",
            "        [-1.7127,  2.0166, -0.6973],\n",
            "        [-1.5687,  0.2689,  1.2111],\n",
            "        [-1.6104,  0.0478,  1.2185],\n",
            "        [-1.6073,  2.0078, -0.5508],\n",
            "        [-1.4382,  0.2937,  1.1345],\n",
            "        [-1.6299,  0.2200,  1.1629],\n",
            "        [-1.4824,  1.8311, -0.8161],\n",
            "        [-1.3948,  1.7578, -0.7826],\n",
            "        [ 0.6491,  0.0335, -1.3558],\n",
            "        [-1.2489,  1.6290, -0.6191],\n",
            "        [-1.3132,  1.8084, -0.7679]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3799,  1.7977, -1.0113],\n",
            "        [-1.5380,  0.3352,  1.1703],\n",
            "        [-1.5539,  1.6315, -0.2549],\n",
            "        [ 0.5410,  0.1600, -1.4159],\n",
            "        [-1.2713,  1.8928, -1.0063],\n",
            "        [ 0.4859,  0.0517, -1.0312],\n",
            "        [-1.2688,  1.5800, -0.5714],\n",
            "        [-1.5044,  0.6172,  0.5374],\n",
            "        [-1.5221,  1.8660, -0.8490],\n",
            "        [-1.4664,  0.2288,  1.0059],\n",
            "        [-1.4556,  1.8418, -0.5898],\n",
            "        [-1.5388,  1.9072, -0.6873],\n",
            "        [-1.7716,  1.2250,  0.1851],\n",
            "        [-1.3570,  0.2108,  1.0871],\n",
            "        [-1.3364,  0.3857,  0.9022],\n",
            "        [-1.2440,  1.6420, -0.6525]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3799,  1.7977, -1.0113],\n",
            "        [-1.5380,  0.3352,  1.1703],\n",
            "        [-1.5539,  1.6315, -0.2549],\n",
            "        [ 0.5410,  0.1600, -1.4159],\n",
            "        [-1.2713,  1.8928, -1.0063],\n",
            "        [ 0.4859,  0.0517, -1.0312],\n",
            "        [-1.2688,  1.5800, -0.5714],\n",
            "        [-1.5044,  0.6172,  0.5374],\n",
            "        [-1.5221,  1.8660, -0.8490],\n",
            "        [-1.4664,  0.2288,  1.0059],\n",
            "        [-1.4556,  1.8418, -0.5898],\n",
            "        [-1.5388,  1.9072, -0.6873],\n",
            "        [-1.7716,  1.2250,  0.1851],\n",
            "        [-1.3570,  0.2108,  1.0871],\n",
            "        [-1.3364,  0.3857,  0.9022],\n",
            "        [-1.2440,  1.6420, -0.6525]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5203,  2.0591, -0.7262],\n",
            "        [-1.3530,  1.7454, -0.3023],\n",
            "        [-1.6462,  0.3273,  1.1934],\n",
            "        [ 0.4648,  0.0441, -0.8740],\n",
            "        [-1.3356,  1.7325, -0.5925],\n",
            "        [-1.5208,  0.1323,  1.0710],\n",
            "        [ 0.4730,  0.1952, -1.4075],\n",
            "        [ 0.3835,  0.2111, -1.1877],\n",
            "        [ 0.5203,  0.1691, -1.4886],\n",
            "        [-1.3490,  1.6457, -0.5763],\n",
            "        [-1.3452,  1.9406, -0.7232],\n",
            "        [-1.4545,  0.3666,  1.0590],\n",
            "        [-1.6455,  0.3589,  1.2902],\n",
            "        [-1.5157,  0.4307,  1.0527],\n",
            "        [-1.1476,  1.7973, -0.4372],\n",
            "        [-0.5398,  0.9738, -0.7616]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5203,  2.0591, -0.7262],\n",
            "        [-1.3530,  1.7454, -0.3023],\n",
            "        [-1.6462,  0.3273,  1.1934],\n",
            "        [ 0.4648,  0.0441, -0.8740],\n",
            "        [-1.3356,  1.7325, -0.5925],\n",
            "        [-1.5208,  0.1323,  1.0710],\n",
            "        [ 0.4730,  0.1952, -1.4075],\n",
            "        [ 0.3835,  0.2111, -1.1877],\n",
            "        [ 0.5203,  0.1691, -1.4886],\n",
            "        [-1.3490,  1.6457, -0.5763],\n",
            "        [-1.3452,  1.9406, -0.7232],\n",
            "        [-1.4545,  0.3666,  1.0590],\n",
            "        [-1.6455,  0.3589,  1.2902],\n",
            "        [-1.5157,  0.4307,  1.0527],\n",
            "        [-1.1476,  1.7973, -0.4372],\n",
            "        [-0.5398,  0.9738, -0.7616]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3825,  0.1172,  1.0562],\n",
            "        [-1.4655,  1.8026, -0.6624],\n",
            "        [-1.4372,  1.6030, -0.3759],\n",
            "        [-1.3615,  1.7861, -0.7011],\n",
            "        [-1.3567,  1.6605, -0.6606],\n",
            "        [-1.2777,  0.2590,  1.3349],\n",
            "        [-1.2351,  1.7134, -0.5503],\n",
            "        [-1.4489,  2.0403, -0.6365],\n",
            "        [ 0.5084,  0.2767, -1.4762],\n",
            "        [-1.4086,  0.1320,  1.1090],\n",
            "        [-1.5139,  0.0936,  1.2530],\n",
            "        [-1.4328,  2.0239, -0.6811],\n",
            "        [-1.2275,  1.8282, -0.4705],\n",
            "        [-1.3115,  1.6697, -0.4534],\n",
            "        [-1.6287,  1.2476, -0.0276],\n",
            "        [-1.6095,  1.9414, -0.7518]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3825,  0.1172,  1.0562],\n",
            "        [-1.4655,  1.8026, -0.6624],\n",
            "        [-1.4372,  1.6030, -0.3759],\n",
            "        [-1.3615,  1.7861, -0.7011],\n",
            "        [-1.3567,  1.6605, -0.6606],\n",
            "        [-1.2777,  0.2590,  1.3349],\n",
            "        [-1.2351,  1.7134, -0.5503],\n",
            "        [-1.4489,  2.0403, -0.6365],\n",
            "        [ 0.5084,  0.2767, -1.4762],\n",
            "        [-1.4086,  0.1320,  1.1090],\n",
            "        [-1.5139,  0.0936,  1.2530],\n",
            "        [-1.4328,  2.0239, -0.6811],\n",
            "        [-1.2275,  1.8282, -0.4705],\n",
            "        [-1.3115,  1.6697, -0.4534],\n",
            "        [-1.6287,  1.2476, -0.0276],\n",
            "        [-1.6095,  1.9414, -0.7518]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.3109,  0.0459, -0.1618],\n",
            "        [ 0.6676,  0.1048, -1.5207],\n",
            "        [-1.3157,  1.6943, -0.5320],\n",
            "        [-1.3887,  1.6967, -0.6819],\n",
            "        [ 0.6619,  0.1586, -1.3338],\n",
            "        [-1.1960,  1.5851, -1.0348],\n",
            "        [-1.4252,  1.8601, -0.6515],\n",
            "        [-0.9092,  0.8444, -0.2248],\n",
            "        [-1.3498,  1.5254, -0.4306],\n",
            "        [-1.1085,  1.6578, -0.5767],\n",
            "        [-1.6576,  0.1724,  1.1046],\n",
            "        [ 0.5225,  0.2775, -1.6163],\n",
            "        [-1.5592,  1.4310,  0.1022],\n",
            "        [ 0.5173,  0.0580, -1.1858],\n",
            "        [-1.2131,  1.5440, -0.6539],\n",
            "        [ 0.5941,  0.1345, -1.1727]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-0.3109,  0.0459, -0.1618],\n",
            "        [ 0.6676,  0.1048, -1.5207],\n",
            "        [-1.3157,  1.6943, -0.5320],\n",
            "        [-1.3887,  1.6967, -0.6819],\n",
            "        [ 0.6619,  0.1586, -1.3338],\n",
            "        [-1.1960,  1.5851, -1.0348],\n",
            "        [-1.4252,  1.8601, -0.6515],\n",
            "        [-0.9092,  0.8444, -0.2248],\n",
            "        [-1.3498,  1.5254, -0.4306],\n",
            "        [-1.1085,  1.6578, -0.5767],\n",
            "        [-1.6576,  0.1724,  1.1046],\n",
            "        [ 0.5225,  0.2775, -1.6163],\n",
            "        [-1.5592,  1.4310,  0.1022],\n",
            "        [ 0.5173,  0.0580, -1.1858],\n",
            "        [-1.2131,  1.5440, -0.6539],\n",
            "        [ 0.5941,  0.1345, -1.1727]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.1355,  1.6822, -0.5649],\n",
            "        [ 0.6089,  0.2918, -1.3596],\n",
            "        [-1.5807,  1.8587, -0.6396],\n",
            "        [ 0.6209,  0.0448, -1.4529],\n",
            "        [-1.2228,  0.2301,  0.8638],\n",
            "        [-1.2344,  1.8206, -0.8925],\n",
            "        [-1.6178,  0.1937,  1.0392],\n",
            "        [-1.6848,  0.2575,  1.5137],\n",
            "        [-1.5763,  0.1411,  1.3872],\n",
            "        [-1.3950,  1.7899, -0.4985],\n",
            "        [ 0.5028,  0.2712, -1.4927],\n",
            "        [-1.3119,  1.7029, -0.8379],\n",
            "        [-1.2231,  1.5961, -0.9040],\n",
            "        [-1.2467,  1.5311, -0.8807],\n",
            "        [-0.0410,  0.6381, -1.2448],\n",
            "        [-1.0969,  0.0939,  1.1210]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.1355,  1.6822, -0.5649],\n",
            "        [ 0.6089,  0.2918, -1.3596],\n",
            "        [-1.5807,  1.8587, -0.6396],\n",
            "        [ 0.6209,  0.0448, -1.4529],\n",
            "        [-1.2228,  0.2301,  0.8638],\n",
            "        [-1.2344,  1.8206, -0.8925],\n",
            "        [-1.6178,  0.1937,  1.0392],\n",
            "        [-1.6848,  0.2575,  1.5137],\n",
            "        [-1.5763,  0.1411,  1.3872],\n",
            "        [-1.3950,  1.7899, -0.4985],\n",
            "        [ 0.5028,  0.2712, -1.4927],\n",
            "        [-1.3119,  1.7029, -0.8379],\n",
            "        [-1.2231,  1.5961, -0.9040],\n",
            "        [-1.2467,  1.5311, -0.8807],\n",
            "        [-0.0410,  0.6381, -1.2448],\n",
            "        [-1.0969,  0.0939,  1.1210]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.1015, -0.0791, -0.5682],\n",
            "        [-1.4496,  1.2071,  0.2258],\n",
            "        [-1.2926,  1.7848, -0.6999],\n",
            "        [-1.3898,  2.0598, -0.6635],\n",
            "        [-1.0368,  1.4346, -0.6629],\n",
            "        [-1.4257,  1.9277, -0.6955],\n",
            "        [-1.4471,  0.1549,  1.0357],\n",
            "        [-1.6673, -0.0069,  1.1014],\n",
            "        [-1.3951,  1.8729, -0.9035],\n",
            "        [-1.4167,  1.4086, -0.0978],\n",
            "        [-0.9548,  1.5123, -0.9383],\n",
            "        [-1.4987,  0.2732,  1.2893],\n",
            "        [ 0.0832,  0.0072, -0.5108],\n",
            "        [-0.2035,  0.6087, -0.6282],\n",
            "        [-1.4877,  1.8677, -0.7819],\n",
            "        [ 0.4547,  0.0710, -1.1075]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.1015, -0.0791, -0.5682],\n",
            "        [-1.4496,  1.2071,  0.2258],\n",
            "        [-1.2926,  1.7848, -0.6999],\n",
            "        [-1.3898,  2.0598, -0.6635],\n",
            "        [-1.0368,  1.4346, -0.6629],\n",
            "        [-1.4257,  1.9277, -0.6955],\n",
            "        [-1.4471,  0.1549,  1.0357],\n",
            "        [-1.6673, -0.0069,  1.1014],\n",
            "        [-1.3951,  1.8729, -0.9035],\n",
            "        [-1.4167,  1.4086, -0.0978],\n",
            "        [-0.9548,  1.5123, -0.9383],\n",
            "        [-1.4987,  0.2732,  1.2893],\n",
            "        [ 0.0832,  0.0072, -0.5108],\n",
            "        [-0.2035,  0.6087, -0.6282],\n",
            "        [-1.4877,  1.8677, -0.7819],\n",
            "        [ 0.4547,  0.0710, -1.1075]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4335,  1.7635, -0.5781],\n",
            "        [-1.5403,  0.2028,  1.1485],\n",
            "        [-1.4440,  1.7070, -0.5265],\n",
            "        [-0.9745,  1.2578, -0.8592],\n",
            "        [ 0.5543,  0.2315, -1.5743],\n",
            "        [-1.3201,  0.0085,  0.9301],\n",
            "        [-1.4946,  0.2491,  1.3389],\n",
            "        [-1.4221,  1.7834, -0.5965],\n",
            "        [ 0.3228,  0.1199, -1.3126],\n",
            "        [-1.2369,  1.6792, -1.0019],\n",
            "        [-1.2454,  1.9459, -0.5557],\n",
            "        [-1.3725,  0.0991,  0.7948],\n",
            "        [-1.4357,  1.4610, -0.6780],\n",
            "        [-1.1522,  1.7738, -0.9735],\n",
            "        [-1.5170,  1.5769, -0.6222],\n",
            "        [-1.6086,  1.3311, -0.0306]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4335,  1.7635, -0.5781],\n",
            "        [-1.5403,  0.2028,  1.1485],\n",
            "        [-1.4440,  1.7070, -0.5265],\n",
            "        [-0.9745,  1.2578, -0.8592],\n",
            "        [ 0.5543,  0.2315, -1.5743],\n",
            "        [-1.3201,  0.0085,  0.9301],\n",
            "        [-1.4946,  0.2491,  1.3389],\n",
            "        [-1.4221,  1.7834, -0.5965],\n",
            "        [ 0.3228,  0.1199, -1.3126],\n",
            "        [-1.2369,  1.6792, -1.0019],\n",
            "        [-1.2454,  1.9459, -0.5557],\n",
            "        [-1.3725,  0.0991,  0.7948],\n",
            "        [-1.4357,  1.4610, -0.6780],\n",
            "        [-1.1522,  1.7738, -0.9735],\n",
            "        [-1.5170,  1.5769, -0.6222],\n",
            "        [-1.6086,  1.3311, -0.0306]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.1963,  1.6856, -0.9892],\n",
            "        [-1.0162,  1.6072, -0.7000],\n",
            "        [-1.5281,  0.4235,  1.1448],\n",
            "        [-1.4515,  1.2750, -0.0723],\n",
            "        [-1.5489,  0.1243,  1.2082],\n",
            "        [-1.4524,  1.8045, -0.6957],\n",
            "        [ 0.5931, -0.0659, -1.2501],\n",
            "        [-1.3880,  1.7025, -0.8101],\n",
            "        [-1.7663,  0.3079,  1.0794],\n",
            "        [-1.5552, -0.0114,  1.2546],\n",
            "        [-1.3326,  1.6581, -0.6018],\n",
            "        [ 0.6136,  0.0422, -1.3259],\n",
            "        [-1.4624,  0.3513,  1.0680],\n",
            "        [-1.6199,  1.5937, -0.3617],\n",
            "        [-1.2831,  1.7142, -0.5520],\n",
            "        [ 0.1179,  0.5671, -1.3170]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.1963,  1.6856, -0.9892],\n",
            "        [-1.0162,  1.6072, -0.7000],\n",
            "        [-1.5281,  0.4235,  1.1448],\n",
            "        [-1.4515,  1.2750, -0.0723],\n",
            "        [-1.5489,  0.1243,  1.2082],\n",
            "        [-1.4524,  1.8045, -0.6957],\n",
            "        [ 0.5931, -0.0659, -1.2501],\n",
            "        [-1.3880,  1.7025, -0.8101],\n",
            "        [-1.7663,  0.3079,  1.0794],\n",
            "        [-1.5552, -0.0114,  1.2546],\n",
            "        [-1.3326,  1.6581, -0.6018],\n",
            "        [ 0.6136,  0.0422, -1.3259],\n",
            "        [-1.4624,  0.3513,  1.0680],\n",
            "        [-1.6199,  1.5937, -0.3617],\n",
            "        [-1.2831,  1.7142, -0.5520],\n",
            "        [ 0.1179,  0.5671, -1.3170]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2922,  1.8358, -0.6134],\n",
            "        [-1.6285,  0.2551,  1.1264],\n",
            "        [-1.6143,  0.3443,  1.2313],\n",
            "        [-1.7885,  0.2591,  1.4378],\n",
            "        [ 0.5870,  0.2995, -1.4366],\n",
            "        [-1.3282,  1.7712, -0.4586],\n",
            "        [-1.4702,  0.6737,  0.8617],\n",
            "        [-1.6681,  0.0759,  1.0732],\n",
            "        [ 0.1928,  0.1152, -0.7015],\n",
            "        [-1.5291,  0.7131,  0.6849],\n",
            "        [-1.3426,  1.6842, -0.6255],\n",
            "        [-1.6015,  1.4460, -0.3200],\n",
            "        [ 0.5159, -0.0474, -0.8355],\n",
            "        [-1.2997,  1.9418, -0.7393],\n",
            "        [-1.3190,  1.6278, -0.7281],\n",
            "        [-1.4806,  1.8468, -0.9451]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2922,  1.8358, -0.6134],\n",
            "        [-1.6285,  0.2551,  1.1264],\n",
            "        [-1.6143,  0.3443,  1.2313],\n",
            "        [-1.7885,  0.2591,  1.4378],\n",
            "        [ 0.5870,  0.2995, -1.4366],\n",
            "        [-1.3282,  1.7712, -0.4586],\n",
            "        [-1.4702,  0.6737,  0.8617],\n",
            "        [-1.6681,  0.0759,  1.0732],\n",
            "        [ 0.1928,  0.1152, -0.7015],\n",
            "        [-1.5291,  0.7131,  0.6849],\n",
            "        [-1.3426,  1.6842, -0.6255],\n",
            "        [-1.6015,  1.4460, -0.3200],\n",
            "        [ 0.5159, -0.0474, -0.8355],\n",
            "        [-1.2997,  1.9418, -0.7393],\n",
            "        [-1.3190,  1.6278, -0.7281],\n",
            "        [-1.4806,  1.8468, -0.9451]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2417,  1.5254, -0.9294],\n",
            "        [-1.2228,  1.5149, -0.9639],\n",
            "        [ 0.4531,  0.1601, -1.3969],\n",
            "        [-0.8141,  1.3136, -0.9984],\n",
            "        [-1.7057,  0.2720,  1.3606],\n",
            "        [-1.6049,  0.3677,  1.0359],\n",
            "        [-1.7258,  0.3267,  1.1487],\n",
            "        [-1.3552,  1.7970, -0.6789],\n",
            "        [-1.3838,  1.5128, -0.2224],\n",
            "        [ 0.6595,  0.0516, -1.2853],\n",
            "        [-1.5329,  0.1892,  1.1852],\n",
            "        [-1.2697,  1.4817, -0.7771],\n",
            "        [-1.2882,  1.9728, -0.7061],\n",
            "        [-1.4143,  1.8137, -0.3308],\n",
            "        [-1.7480,  0.7784,  0.6155],\n",
            "        [-1.1486,  1.5877, -0.9659]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2417,  1.5254, -0.9294],\n",
            "        [-1.2228,  1.5149, -0.9639],\n",
            "        [ 0.4531,  0.1601, -1.3969],\n",
            "        [-0.8141,  1.3136, -0.9984],\n",
            "        [-1.7057,  0.2720,  1.3606],\n",
            "        [-1.6049,  0.3677,  1.0359],\n",
            "        [-1.7258,  0.3267,  1.1487],\n",
            "        [-1.3552,  1.7970, -0.6789],\n",
            "        [-1.3838,  1.5128, -0.2224],\n",
            "        [ 0.6595,  0.0516, -1.2853],\n",
            "        [-1.5329,  0.1892,  1.1852],\n",
            "        [-1.2697,  1.4817, -0.7771],\n",
            "        [-1.2882,  1.9728, -0.7061],\n",
            "        [-1.4143,  1.8137, -0.3308],\n",
            "        [-1.7480,  0.7784,  0.6155],\n",
            "        [-1.1486,  1.5877, -0.9659]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4576e+00,  1.6023e+00, -4.6419e-01],\n",
            "        [-1.4374e+00,  1.8897e+00, -8.0234e-01],\n",
            "        [-7.1400e-01,  1.3387e+00, -1.0870e+00],\n",
            "        [ 6.6748e-01, -4.6221e-04, -1.2090e+00],\n",
            "        [-1.4645e+00,  4.8635e-01,  8.4276e-01],\n",
            "        [-1.4161e+00,  1.0349e-01,  1.0789e+00],\n",
            "        [-1.6499e+00,  1.4696e+00, -2.0077e-01],\n",
            "        [ 7.4780e-01, -8.8378e-02, -1.2785e+00],\n",
            "        [-1.3939e+00,  3.6623e-01,  9.5069e-01],\n",
            "        [-1.5226e+00,  4.3630e-01,  1.0196e+00],\n",
            "        [-1.5382e+00,  1.9669e+00, -6.1502e-01],\n",
            "        [-1.4587e+00,  1.7122e+00, -5.5338e-01],\n",
            "        [-1.4192e+00,  1.5667e+00, -4.3115e-01],\n",
            "        [-1.4178e+00,  1.9538e+00, -7.9360e-01],\n",
            "        [ 3.7171e-01, -3.9997e-02, -1.0199e+00],\n",
            "        [-1.4638e+00,  1.8624e+00, -3.9297e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4576e+00,  1.6023e+00, -4.6419e-01],\n",
            "        [-1.4374e+00,  1.8897e+00, -8.0234e-01],\n",
            "        [-7.1400e-01,  1.3387e+00, -1.0870e+00],\n",
            "        [ 6.6748e-01, -4.6221e-04, -1.2090e+00],\n",
            "        [-1.4645e+00,  4.8635e-01,  8.4276e-01],\n",
            "        [-1.4161e+00,  1.0349e-01,  1.0789e+00],\n",
            "        [-1.6499e+00,  1.4696e+00, -2.0077e-01],\n",
            "        [ 7.4780e-01, -8.8378e-02, -1.2785e+00],\n",
            "        [-1.3939e+00,  3.6623e-01,  9.5069e-01],\n",
            "        [-1.5226e+00,  4.3630e-01,  1.0196e+00],\n",
            "        [-1.5382e+00,  1.9669e+00, -6.1502e-01],\n",
            "        [-1.4587e+00,  1.7122e+00, -5.5338e-01],\n",
            "        [-1.4192e+00,  1.5667e+00, -4.3115e-01],\n",
            "        [-1.4178e+00,  1.9538e+00, -7.9360e-01],\n",
            "        [ 3.7171e-01, -3.9997e-02, -1.0199e+00],\n",
            "        [-1.4638e+00,  1.8624e+00, -3.9297e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3417,  1.5446, -0.7654],\n",
            "        [-1.0413,  0.6375,  0.0790],\n",
            "        [-1.2326,  0.9455,  0.4509],\n",
            "        [-1.4941,  1.5653, -0.3333],\n",
            "        [-1.1577,  1.4745, -0.6995],\n",
            "        [-0.4568, -0.0374,  0.1467],\n",
            "        [-1.3641,  1.8431, -0.8884],\n",
            "        [-0.8789,  1.6239, -0.8672],\n",
            "        [-1.1156,  1.4702, -0.8861],\n",
            "        [-1.4716,  0.3078,  1.0065],\n",
            "        [-1.7929,  1.5155, -0.0893],\n",
            "        [-1.4712,  0.3598,  1.0195],\n",
            "        [-1.4171,  0.8029,  0.4586],\n",
            "        [-1.4813,  0.3320,  1.1267],\n",
            "        [ 0.6059,  0.0780, -1.0289],\n",
            "        [-1.2983,  1.8623, -0.9578]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3417,  1.5446, -0.7654],\n",
            "        [-1.0413,  0.6375,  0.0790],\n",
            "        [-1.2326,  0.9455,  0.4509],\n",
            "        [-1.4941,  1.5653, -0.3333],\n",
            "        [-1.1577,  1.4745, -0.6995],\n",
            "        [-0.4568, -0.0374,  0.1467],\n",
            "        [-1.3641,  1.8431, -0.8884],\n",
            "        [-0.8789,  1.6239, -0.8672],\n",
            "        [-1.1156,  1.4702, -0.8861],\n",
            "        [-1.4716,  0.3078,  1.0065],\n",
            "        [-1.7929,  1.5155, -0.0893],\n",
            "        [-1.4712,  0.3598,  1.0195],\n",
            "        [-1.4171,  0.8029,  0.4586],\n",
            "        [-1.4813,  0.3320,  1.1267],\n",
            "        [ 0.6059,  0.0780, -1.0289],\n",
            "        [-1.2983,  1.8623, -0.9578]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.2119,  0.2462, -0.6488],\n",
            "        [-1.2307,  1.7435, -0.7185],\n",
            "        [-1.5547,  0.3314,  1.0488],\n",
            "        [-1.6391,  0.0851,  1.0881],\n",
            "        [ 0.5907,  0.2001, -1.5641],\n",
            "        [-1.2549,  2.0748, -0.7728],\n",
            "        [-1.1399,  0.3910,  0.4040],\n",
            "        [-1.8637,  0.4306,  1.2083],\n",
            "        [-1.3443,  1.8161, -0.6816],\n",
            "        [ 0.4937,  0.0664, -1.4163],\n",
            "        [-1.4613,  0.3224,  1.1623],\n",
            "        [-1.3855,  0.2755,  1.0289],\n",
            "        [-1.2958,  1.9038, -0.6679],\n",
            "        [ 0.2600,  0.1553, -0.9980],\n",
            "        [ 0.5854,  0.1408, -1.2969],\n",
            "        [-1.6955,  0.5448,  1.1167]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.2119,  0.2462, -0.6488],\n",
            "        [-1.2307,  1.7435, -0.7185],\n",
            "        [-1.5547,  0.3314,  1.0488],\n",
            "        [-1.6391,  0.0851,  1.0881],\n",
            "        [ 0.5907,  0.2001, -1.5641],\n",
            "        [-1.2549,  2.0748, -0.7728],\n",
            "        [-1.1399,  0.3910,  0.4040],\n",
            "        [-1.8637,  0.4306,  1.2083],\n",
            "        [-1.3443,  1.8161, -0.6816],\n",
            "        [ 0.4937,  0.0664, -1.4163],\n",
            "        [-1.4613,  0.3224,  1.1623],\n",
            "        [-1.3855,  0.2755,  1.0289],\n",
            "        [-1.2958,  1.9038, -0.6679],\n",
            "        [ 0.2600,  0.1553, -0.9980],\n",
            "        [ 0.5854,  0.1408, -1.2969],\n",
            "        [-1.6955,  0.5448,  1.1167]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3755,  2.1426, -0.8591],\n",
            "        [-1.7024,  0.1977,  1.0209],\n",
            "        [-1.0998,  1.6850, -0.9508],\n",
            "        [-1.3143,  1.9514, -0.8515],\n",
            "        [-1.4665,  1.9895, -0.8096],\n",
            "        [-1.6457,  1.0588,  0.3451],\n",
            "        [-1.5638,  0.3388,  1.0461],\n",
            "        [-1.3785,  1.0428, -0.4493],\n",
            "        [ 0.6410,  0.0329, -1.2636],\n",
            "        [-1.4141,  1.3365, -0.0209],\n",
            "        [-1.4173,  2.0378, -0.8283],\n",
            "        [-1.4215,  1.7516, -0.7433],\n",
            "        [-1.8719,  0.3129,  1.1311],\n",
            "        [-1.3583,  1.7656, -0.9557],\n",
            "        [-1.5827,  0.4618,  1.0369],\n",
            "        [-1.5609,  1.9494, -0.8546]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3755,  2.1426, -0.8591],\n",
            "        [-1.7024,  0.1977,  1.0209],\n",
            "        [-1.0998,  1.6850, -0.9508],\n",
            "        [-1.3143,  1.9514, -0.8515],\n",
            "        [-1.4665,  1.9895, -0.8096],\n",
            "        [-1.6457,  1.0588,  0.3451],\n",
            "        [-1.5638,  0.3388,  1.0461],\n",
            "        [-1.3785,  1.0428, -0.4493],\n",
            "        [ 0.6410,  0.0329, -1.2636],\n",
            "        [-1.4141,  1.3365, -0.0209],\n",
            "        [-1.4173,  2.0378, -0.8283],\n",
            "        [-1.4215,  1.7516, -0.7433],\n",
            "        [-1.8719,  0.3129,  1.1311],\n",
            "        [-1.3583,  1.7656, -0.9557],\n",
            "        [-1.5827,  0.4618,  1.0369],\n",
            "        [-1.5609,  1.9494, -0.8546]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4001,  0.8245,  0.2342],\n",
            "        [-0.9884,  1.0375, -0.1934],\n",
            "        [-1.1506,  1.7707, -0.7433],\n",
            "        [ 0.6634,  0.0987, -1.3583],\n",
            "        [ 0.6583,  0.0432, -1.5128],\n",
            "        [-1.7133,  0.4065,  1.1457],\n",
            "        [-1.4811,  0.5848,  1.0255],\n",
            "        [-1.5753,  0.4754,  0.9027],\n",
            "        [-1.5132,  0.4566,  1.1696],\n",
            "        [-1.5420,  1.5131, -0.0022],\n",
            "        [-1.7295,  0.6379,  0.8780],\n",
            "        [-1.7792,  1.8856, -0.3966],\n",
            "        [-1.4436,  2.0058, -0.8524],\n",
            "        [-1.3278,  1.8070, -0.9900],\n",
            "        [-1.5218,  1.8683, -0.6019],\n",
            "        [-1.6504,  0.1922,  1.0569]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4001,  0.8245,  0.2342],\n",
            "        [-0.9884,  1.0375, -0.1934],\n",
            "        [-1.1506,  1.7707, -0.7433],\n",
            "        [ 0.6634,  0.0987, -1.3583],\n",
            "        [ 0.6583,  0.0432, -1.5128],\n",
            "        [-1.7133,  0.4065,  1.1457],\n",
            "        [-1.4811,  0.5848,  1.0255],\n",
            "        [-1.5753,  0.4754,  0.9027],\n",
            "        [-1.5132,  0.4566,  1.1696],\n",
            "        [-1.5420,  1.5131, -0.0022],\n",
            "        [-1.7295,  0.6379,  0.8780],\n",
            "        [-1.7792,  1.8856, -0.3966],\n",
            "        [-1.4436,  2.0058, -0.8524],\n",
            "        [-1.3278,  1.8070, -0.9900],\n",
            "        [-1.5218,  1.8683, -0.6019],\n",
            "        [-1.6504,  0.1922,  1.0569]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2175,  1.9715, -0.7071],\n",
            "        [-1.2603,  1.9252, -0.7456],\n",
            "        [-1.6415,  1.7806, -0.4952],\n",
            "        [-1.3130,  1.9710, -0.8723],\n",
            "        [-0.8563,  1.1243, -0.5339],\n",
            "        [-1.4529,  1.7975, -0.7454],\n",
            "        [-1.3170,  0.4612,  0.7882],\n",
            "        [-1.4900,  2.1368, -0.7378],\n",
            "        [-1.3558,  2.2388, -0.7799],\n",
            "        [-1.2037,  0.3688,  0.6879],\n",
            "        [-1.2010,  1.9861, -0.7545],\n",
            "        [ 0.5371,  0.2026, -1.4832],\n",
            "        [-1.3543,  2.0418, -0.7401],\n",
            "        [-1.3245,  0.9768, -0.1486],\n",
            "        [-1.1121,  1.9512, -0.9604],\n",
            "        [-1.3170,  1.6960, -0.8716]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2175,  1.9715, -0.7071],\n",
            "        [-1.2603,  1.9252, -0.7456],\n",
            "        [-1.6415,  1.7806, -0.4952],\n",
            "        [-1.3130,  1.9710, -0.8723],\n",
            "        [-0.8563,  1.1243, -0.5339],\n",
            "        [-1.4529,  1.7975, -0.7454],\n",
            "        [-1.3170,  0.4612,  0.7882],\n",
            "        [-1.4900,  2.1368, -0.7378],\n",
            "        [-1.3558,  2.2388, -0.7799],\n",
            "        [-1.2037,  0.3688,  0.6879],\n",
            "        [-1.2010,  1.9861, -0.7545],\n",
            "        [ 0.5371,  0.2026, -1.4832],\n",
            "        [-1.3543,  2.0418, -0.7401],\n",
            "        [-1.3245,  0.9768, -0.1486],\n",
            "        [-1.1121,  1.9512, -0.9604],\n",
            "        [-1.3170,  1.6960, -0.8716]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4029,  2.0622, -0.7082],\n",
            "        [-1.4638,  1.8643, -0.6801],\n",
            "        [ 0.4506,  0.2929, -1.3440],\n",
            "        [-1.5895,  2.0558, -0.8189],\n",
            "        [-1.4097,  1.9663, -0.8746],\n",
            "        [-1.7344,  0.3991,  1.2450],\n",
            "        [-0.9928,  1.4634, -0.9376],\n",
            "        [-1.3864,  1.7020, -0.8766],\n",
            "        [-1.4991,  1.7649, -0.7658],\n",
            "        [-1.4777,  2.0567, -0.7492],\n",
            "        [-1.5208,  0.4017,  0.9290],\n",
            "        [ 0.6013,  0.1306, -1.4710],\n",
            "        [-1.5833,  0.9449,  0.2840],\n",
            "        [ 0.7714,  0.2124, -1.2911],\n",
            "        [-1.0549,  1.5221, -0.8980],\n",
            "        [ 0.4637,  0.2415, -1.4090]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4029,  2.0622, -0.7082],\n",
            "        [-1.4638,  1.8643, -0.6801],\n",
            "        [ 0.4506,  0.2929, -1.3440],\n",
            "        [-1.5895,  2.0558, -0.8189],\n",
            "        [-1.4097,  1.9663, -0.8746],\n",
            "        [-1.7344,  0.3991,  1.2450],\n",
            "        [-0.9928,  1.4634, -0.9376],\n",
            "        [-1.3864,  1.7020, -0.8766],\n",
            "        [-1.4991,  1.7649, -0.7658],\n",
            "        [-1.4777,  2.0567, -0.7492],\n",
            "        [-1.5208,  0.4017,  0.9290],\n",
            "        [ 0.6013,  0.1306, -1.4710],\n",
            "        [-1.5833,  0.9449,  0.2840],\n",
            "        [ 0.7714,  0.2124, -1.2911],\n",
            "        [-1.0549,  1.5221, -0.8980],\n",
            "        [ 0.4637,  0.2415, -1.4090]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7139,  0.5166,  1.0853],\n",
            "        [-1.2861,  1.9427, -0.6889],\n",
            "        [ 0.5856,  0.4499, -1.3838],\n",
            "        [-1.3056,  1.7392, -0.8025],\n",
            "        [-1.6417,  0.4594,  1.1702],\n",
            "        [-1.0730,  0.9632, -0.4872],\n",
            "        [-1.2339,  1.6243, -0.6305],\n",
            "        [-1.3659,  0.2778,  0.7450],\n",
            "        [ 0.7571,  0.0525, -1.2198],\n",
            "        [ 0.5672,  0.0484, -1.1781],\n",
            "        [-1.3518,  2.0425, -0.7243],\n",
            "        [-1.0750,  1.5528, -0.8247],\n",
            "        [-1.7656,  0.5283,  0.9852],\n",
            "        [-1.2574,  1.7568, -0.9513],\n",
            "        [-1.1523,  1.9111, -0.7708],\n",
            "        [-1.4027,  1.9454, -0.5638]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7139,  0.5166,  1.0853],\n",
            "        [-1.2861,  1.9427, -0.6889],\n",
            "        [ 0.5856,  0.4499, -1.3838],\n",
            "        [-1.3056,  1.7392, -0.8025],\n",
            "        [-1.6417,  0.4594,  1.1702],\n",
            "        [-1.0730,  0.9632, -0.4872],\n",
            "        [-1.2339,  1.6243, -0.6305],\n",
            "        [-1.3659,  0.2778,  0.7450],\n",
            "        [ 0.7571,  0.0525, -1.2198],\n",
            "        [ 0.5672,  0.0484, -1.1781],\n",
            "        [-1.3518,  2.0425, -0.7243],\n",
            "        [-1.0750,  1.5528, -0.8247],\n",
            "        [-1.7656,  0.5283,  0.9852],\n",
            "        [-1.2574,  1.7568, -0.9513],\n",
            "        [-1.1523,  1.9111, -0.7708],\n",
            "        [-1.4027,  1.9454, -0.5638]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.8244, -0.0040, -1.3400],\n",
            "        [-1.2400,  1.5875, -0.7870],\n",
            "        [ 0.8260,  0.1809, -1.4925],\n",
            "        [-1.7588,  1.8035, -0.4421],\n",
            "        [-1.3788,  1.6144, -0.4999],\n",
            "        [-1.4165,  1.7036, -0.1525],\n",
            "        [ 0.4129,  0.4180, -1.4293],\n",
            "        [-0.9009,  1.1251, -0.8897],\n",
            "        [-1.8918,  0.5480,  1.0961],\n",
            "        [-1.3496,  1.8576, -0.3212],\n",
            "        [-1.0245,  1.3502, -0.8247],\n",
            "        [ 0.5883,  0.1295, -1.3056],\n",
            "        [-1.1755,  1.4173, -0.7386],\n",
            "        [-1.8115,  2.1519, -0.4278],\n",
            "        [-1.6237,  0.8524,  0.6325],\n",
            "        [-1.3300,  1.8894, -0.7827]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.8244, -0.0040, -1.3400],\n",
            "        [-1.2400,  1.5875, -0.7870],\n",
            "        [ 0.8260,  0.1809, -1.4925],\n",
            "        [-1.7588,  1.8035, -0.4421],\n",
            "        [-1.3788,  1.6144, -0.4999],\n",
            "        [-1.4165,  1.7036, -0.1525],\n",
            "        [ 0.4129,  0.4180, -1.4293],\n",
            "        [-0.9009,  1.1251, -0.8897],\n",
            "        [-1.8918,  0.5480,  1.0961],\n",
            "        [-1.3496,  1.8576, -0.3212],\n",
            "        [-1.0245,  1.3502, -0.8247],\n",
            "        [ 0.5883,  0.1295, -1.3056],\n",
            "        [-1.1755,  1.4173, -0.7386],\n",
            "        [-1.8115,  2.1519, -0.4278],\n",
            "        [-1.6237,  0.8524,  0.6325],\n",
            "        [-1.3300,  1.8894, -0.7827]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2891,  1.6215, -0.6026],\n",
            "        [-1.4693,  1.8870, -0.7311],\n",
            "        [-1.4997,  1.9819, -0.7713],\n",
            "        [-1.3635,  1.7370, -0.8080],\n",
            "        [-1.5954,  0.4717,  1.0776],\n",
            "        [ 0.7926,  0.0195, -1.2602],\n",
            "        [-1.7552,  1.4484, -0.0934],\n",
            "        [-1.6099,  2.1477, -0.6080],\n",
            "        [-1.6572,  0.4813,  1.0995],\n",
            "        [-1.3083,  1.7832, -0.7599],\n",
            "        [-1.2363,  0.6589,  0.6643],\n",
            "        [-1.5687,  2.1094, -0.5933],\n",
            "        [-1.6854,  1.9311, -0.6741],\n",
            "        [-1.5044,  0.9432,  0.5045],\n",
            "        [-1.4201,  1.4569, -0.4298],\n",
            "        [-1.3526,  1.9568, -0.6230]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2891,  1.6215, -0.6026],\n",
            "        [-1.4693,  1.8870, -0.7311],\n",
            "        [-1.4997,  1.9819, -0.7713],\n",
            "        [-1.3635,  1.7370, -0.8080],\n",
            "        [-1.5954,  0.4717,  1.0776],\n",
            "        [ 0.7926,  0.0195, -1.2602],\n",
            "        [-1.7552,  1.4484, -0.0934],\n",
            "        [-1.6099,  2.1477, -0.6080],\n",
            "        [-1.6572,  0.4813,  1.0995],\n",
            "        [-1.3083,  1.7832, -0.7599],\n",
            "        [-1.2363,  0.6589,  0.6643],\n",
            "        [-1.5687,  2.1094, -0.5933],\n",
            "        [-1.6854,  1.9311, -0.6741],\n",
            "        [-1.5044,  0.9432,  0.5045],\n",
            "        [-1.4201,  1.4569, -0.4298],\n",
            "        [-1.3526,  1.9568, -0.6230]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7095,  0.4334,  0.9249],\n",
            "        [ 0.6885,  0.2463, -1.5198],\n",
            "        [-1.6300,  2.0085, -0.7299],\n",
            "        [-1.5544,  1.9036, -0.6925],\n",
            "        [-1.5291,  1.9167, -0.6296],\n",
            "        [-1.9399,  0.3681,  1.0831],\n",
            "        [-1.5308,  1.6939, -0.3995],\n",
            "        [-1.6676,  0.4751,  1.2548],\n",
            "        [-1.2068,  2.0238, -0.6176],\n",
            "        [-1.3593,  1.8026, -0.6377],\n",
            "        [-1.4652,  0.5336,  0.9022],\n",
            "        [-1.3420,  1.8630, -0.6212],\n",
            "        [-1.6077,  0.8356,  0.7451],\n",
            "        [-1.1318,  1.5482, -0.7127],\n",
            "        [-1.5538,  1.9178, -0.3412],\n",
            "        [-1.6497,  0.4507,  1.1263]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7095,  0.4334,  0.9249],\n",
            "        [ 0.6885,  0.2463, -1.5198],\n",
            "        [-1.6300,  2.0085, -0.7299],\n",
            "        [-1.5544,  1.9036, -0.6925],\n",
            "        [-1.5291,  1.9167, -0.6296],\n",
            "        [-1.9399,  0.3681,  1.0831],\n",
            "        [-1.5308,  1.6939, -0.3995],\n",
            "        [-1.6676,  0.4751,  1.2548],\n",
            "        [-1.2068,  2.0238, -0.6176],\n",
            "        [-1.3593,  1.8026, -0.6377],\n",
            "        [-1.4652,  0.5336,  0.9022],\n",
            "        [-1.3420,  1.8630, -0.6212],\n",
            "        [-1.6077,  0.8356,  0.7451],\n",
            "        [-1.1318,  1.5482, -0.7127],\n",
            "        [-1.5538,  1.9178, -0.3412],\n",
            "        [-1.6497,  0.4507,  1.1263]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6473,  0.4620,  1.2686],\n",
            "        [ 0.8450,  0.0983, -1.3506],\n",
            "        [-1.6728,  0.1528,  1.2231],\n",
            "        [-1.4401,  1.9492, -0.5027],\n",
            "        [-1.5525,  1.7651, -0.5591],\n",
            "        [-1.8010,  0.4792,  1.0024],\n",
            "        [-1.3711,  2.1025, -0.7178],\n",
            "        [ 0.7350,  0.1988, -1.6062],\n",
            "        [-1.2576,  1.9212, -0.6321],\n",
            "        [-1.4171,  1.4696, -0.2655],\n",
            "        [-1.1438,  1.7686, -0.6901],\n",
            "        [-1.4972,  1.8886, -0.5000],\n",
            "        [-1.5629,  1.5219, -0.4871],\n",
            "        [-1.4608,  1.6461, -0.4372],\n",
            "        [-2.0143,  0.7163,  0.9413],\n",
            "        [-1.4001,  1.9290, -0.6062]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6473,  0.4620,  1.2686],\n",
            "        [ 0.8450,  0.0983, -1.3506],\n",
            "        [-1.6728,  0.1528,  1.2231],\n",
            "        [-1.4401,  1.9492, -0.5027],\n",
            "        [-1.5525,  1.7651, -0.5591],\n",
            "        [-1.8010,  0.4792,  1.0024],\n",
            "        [-1.3711,  2.1025, -0.7178],\n",
            "        [ 0.7350,  0.1988, -1.6062],\n",
            "        [-1.2576,  1.9212, -0.6321],\n",
            "        [-1.4171,  1.4696, -0.2655],\n",
            "        [-1.1438,  1.7686, -0.6901],\n",
            "        [-1.4972,  1.8886, -0.5000],\n",
            "        [-1.5629,  1.5219, -0.4871],\n",
            "        [-1.4608,  1.6461, -0.4372],\n",
            "        [-2.0143,  0.7163,  0.9413],\n",
            "        [-1.4001,  1.9290, -0.6062]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.7027,  0.1738, -1.2151],\n",
            "        [-1.3655,  1.7956, -0.4924],\n",
            "        [-1.5089,  1.1715,  0.2042],\n",
            "        [-1.6320,  0.4241,  1.0641],\n",
            "        [-1.5793,  1.7394, -0.6562],\n",
            "        [-1.8198,  1.1233,  0.1745],\n",
            "        [-0.8322,  1.3384, -0.9552],\n",
            "        [-1.3792,  1.9466, -0.6534],\n",
            "        [-1.9490,  0.4166,  1.2242],\n",
            "        [ 0.9888,  0.1125, -1.3806],\n",
            "        [-1.7393,  0.2552,  1.0706],\n",
            "        [-1.6364,  0.3616,  1.2527],\n",
            "        [-1.5195,  1.7084, -0.7047],\n",
            "        [-1.7800,  0.3774,  1.1994],\n",
            "        [ 0.2113,  0.0318, -0.5539],\n",
            "        [-1.4287,  1.7224, -0.6043]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.7027,  0.1738, -1.2151],\n",
            "        [-1.3655,  1.7956, -0.4924],\n",
            "        [-1.5089,  1.1715,  0.2042],\n",
            "        [-1.6320,  0.4241,  1.0641],\n",
            "        [-1.5793,  1.7394, -0.6562],\n",
            "        [-1.8198,  1.1233,  0.1745],\n",
            "        [-0.8322,  1.3384, -0.9552],\n",
            "        [-1.3792,  1.9466, -0.6534],\n",
            "        [-1.9490,  0.4166,  1.2242],\n",
            "        [ 0.9888,  0.1125, -1.3806],\n",
            "        [-1.7393,  0.2552,  1.0706],\n",
            "        [-1.6364,  0.3616,  1.2527],\n",
            "        [-1.5195,  1.7084, -0.7047],\n",
            "        [-1.7800,  0.3774,  1.1994],\n",
            "        [ 0.2113,  0.0318, -0.5539],\n",
            "        [-1.4287,  1.7224, -0.6043]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5459,  1.6650, -0.4934],\n",
            "        [-1.7187,  0.1758,  1.1843],\n",
            "        [-1.4875,  1.8605, -0.5925],\n",
            "        [-1.5949,  1.7183, -0.3055],\n",
            "        [ 0.6792,  0.1213, -1.3478],\n",
            "        [-1.8636,  0.3727,  1.1609],\n",
            "        [-1.6305,  1.7894, -0.4831],\n",
            "        [-1.7897,  0.4873,  1.1632],\n",
            "        [-1.5504,  1.8542, -0.5438],\n",
            "        [-1.7510,  0.4013,  1.3636],\n",
            "        [-1.4110,  0.9130,  0.5523],\n",
            "        [-1.3371,  1.5955, -0.5680],\n",
            "        [-1.4083,  0.5924,  0.8303],\n",
            "        [-1.7175,  0.5844,  0.9764],\n",
            "        [-1.5571,  0.5173,  1.1168],\n",
            "        [-1.4275,  1.7007, -0.6844]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5459,  1.6650, -0.4934],\n",
            "        [-1.7187,  0.1758,  1.1843],\n",
            "        [-1.4875,  1.8605, -0.5925],\n",
            "        [-1.5949,  1.7183, -0.3055],\n",
            "        [ 0.6792,  0.1213, -1.3478],\n",
            "        [-1.8636,  0.3727,  1.1609],\n",
            "        [-1.6305,  1.7894, -0.4831],\n",
            "        [-1.7897,  0.4873,  1.1632],\n",
            "        [-1.5504,  1.8542, -0.5438],\n",
            "        [-1.7510,  0.4013,  1.3636],\n",
            "        [-1.4110,  0.9130,  0.5523],\n",
            "        [-1.3371,  1.5955, -0.5680],\n",
            "        [-1.4083,  0.5924,  0.8303],\n",
            "        [-1.7175,  0.5844,  0.9764],\n",
            "        [-1.5571,  0.5173,  1.1168],\n",
            "        [-1.4275,  1.7007, -0.6844]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8034,  0.2395,  1.3275],\n",
            "        [-1.8079,  1.5940,  0.0484],\n",
            "        [-1.5396,  1.3538, -0.1632],\n",
            "        [ 0.7580, -0.0599, -1.5609],\n",
            "        [-1.4607,  1.6629, -0.4104],\n",
            "        [-1.5727,  1.6355, -0.0752],\n",
            "        [ 0.5808, -0.0698, -1.2758],\n",
            "        [-1.8240,  1.6864, -0.2755],\n",
            "        [-0.9199,  0.0909,  0.5461],\n",
            "        [ 0.7999, -0.0422, -1.3758],\n",
            "        [ 0.7026,  0.2487, -1.3761],\n",
            "        [-1.4016,  1.9427, -0.6782],\n",
            "        [-1.0001,  1.2283, -0.6679],\n",
            "        [ 0.6146, -0.0242, -1.2572],\n",
            "        [-1.7645,  0.4519,  1.2560],\n",
            "        [-1.7405,  0.1380,  1.2996]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8034,  0.2395,  1.3275],\n",
            "        [-1.8079,  1.5940,  0.0484],\n",
            "        [-1.5396,  1.3538, -0.1632],\n",
            "        [ 0.7580, -0.0599, -1.5609],\n",
            "        [-1.4607,  1.6629, -0.4104],\n",
            "        [-1.5727,  1.6355, -0.0752],\n",
            "        [ 0.5808, -0.0698, -1.2758],\n",
            "        [-1.8240,  1.6864, -0.2755],\n",
            "        [-0.9199,  0.0909,  0.5461],\n",
            "        [ 0.7999, -0.0422, -1.3758],\n",
            "        [ 0.7026,  0.2487, -1.3761],\n",
            "        [-1.4016,  1.9427, -0.6782],\n",
            "        [-1.0001,  1.2283, -0.6679],\n",
            "        [ 0.6146, -0.0242, -1.2572],\n",
            "        [-1.7645,  0.4519,  1.2560],\n",
            "        [-1.7405,  0.1380,  1.2996]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6455,  0.1886,  1.0640],\n",
            "        [-1.5458,  1.8045, -0.2615],\n",
            "        [-1.6532,  0.2434,  1.3217],\n",
            "        [-1.6186,  1.9501, -0.4406],\n",
            "        [-1.6399,  0.4392,  1.1024],\n",
            "        [-1.4930,  1.9789, -0.6577],\n",
            "        [-1.6473,  1.5422, -0.2624],\n",
            "        [-1.8298,  0.2291,  1.2849],\n",
            "        [-1.9871,  0.3537,  1.5067],\n",
            "        [ 0.9793,  0.0645, -1.4696],\n",
            "        [-1.4897,  1.7856, -0.5882],\n",
            "        [-1.6052,  1.8514, -0.2483],\n",
            "        [-1.7691,  0.4550,  1.2486],\n",
            "        [-1.7933,  0.2627,  1.4026],\n",
            "        [-2.0153,  1.0213,  0.4209],\n",
            "        [-1.8164,  0.4155,  1.2177]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6455,  0.1886,  1.0640],\n",
            "        [-1.5458,  1.8045, -0.2615],\n",
            "        [-1.6532,  0.2434,  1.3217],\n",
            "        [-1.6186,  1.9501, -0.4406],\n",
            "        [-1.6399,  0.4392,  1.1024],\n",
            "        [-1.4930,  1.9789, -0.6577],\n",
            "        [-1.6473,  1.5422, -0.2624],\n",
            "        [-1.8298,  0.2291,  1.2849],\n",
            "        [-1.9871,  0.3537,  1.5067],\n",
            "        [ 0.9793,  0.0645, -1.4696],\n",
            "        [-1.4897,  1.7856, -0.5882],\n",
            "        [-1.6052,  1.8514, -0.2483],\n",
            "        [-1.7691,  0.4550,  1.2486],\n",
            "        [-1.7933,  0.2627,  1.4026],\n",
            "        [-2.0153,  1.0213,  0.4209],\n",
            "        [-1.8164,  0.4155,  1.2177]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.0919,  1.7538, -0.5675],\n",
            "        [-1.6216,  2.1356, -0.4738],\n",
            "        [-1.5571,  1.7949, -0.4672],\n",
            "        [-1.5770,  1.8049, -0.5080],\n",
            "        [ 0.6216, -0.0470, -1.2080],\n",
            "        [-1.3837,  1.6800, -0.5847],\n",
            "        [-1.7398,  0.4802,  1.0378],\n",
            "        [-1.6354,  1.3868,  0.0348],\n",
            "        [-1.7141,  1.9724, -0.4538],\n",
            "        [-1.6105,  1.8272, -0.4978],\n",
            "        [-1.6669,  0.1009,  1.3233],\n",
            "        [-1.7573,  0.2784,  1.2434],\n",
            "        [-1.5972,  1.9443, -0.5767],\n",
            "        [-1.6015,  1.7146, -0.4049],\n",
            "        [-1.6266,  0.5770,  1.0599],\n",
            "        [-2.0660,  0.5507,  1.1572]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.0919,  1.7538, -0.5675],\n",
            "        [-1.6216,  2.1356, -0.4738],\n",
            "        [-1.5571,  1.7949, -0.4672],\n",
            "        [-1.5770,  1.8049, -0.5080],\n",
            "        [ 0.6216, -0.0470, -1.2080],\n",
            "        [-1.3837,  1.6800, -0.5847],\n",
            "        [-1.7398,  0.4802,  1.0378],\n",
            "        [-1.6354,  1.3868,  0.0348],\n",
            "        [-1.7141,  1.9724, -0.4538],\n",
            "        [-1.6105,  1.8272, -0.4978],\n",
            "        [-1.6669,  0.1009,  1.3233],\n",
            "        [-1.7573,  0.2784,  1.2434],\n",
            "        [-1.5972,  1.9443, -0.5767],\n",
            "        [-1.6015,  1.7146, -0.4049],\n",
            "        [-1.6266,  0.5770,  1.0599],\n",
            "        [-2.0660,  0.5507,  1.1572]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5464,  1.8385, -0.4594],\n",
            "        [-1.3501,  1.5491, -0.5732],\n",
            "        [-1.3490,  1.7204, -0.7160],\n",
            "        [ 0.6794,  0.0073, -1.1780],\n",
            "        [-1.8336,  0.2308,  1.3461],\n",
            "        [-1.5248,  0.3249,  1.0236],\n",
            "        [-1.6908,  0.2290,  1.1632],\n",
            "        [-1.5703,  2.0337, -0.2422],\n",
            "        [-0.8586,  1.0797, -0.6997],\n",
            "        [ 0.6112, -0.0258, -1.4130],\n",
            "        [ 0.8219,  0.0567, -1.3081],\n",
            "        [-1.6577,  1.9785, -0.3628],\n",
            "        [-1.6415,  1.5055, -0.3960],\n",
            "        [-1.7240,  1.8019, -0.3301],\n",
            "        [-1.0213,  1.5120, -0.7697],\n",
            "        [-1.6562,  0.3776,  1.3218]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5464,  1.8385, -0.4594],\n",
            "        [-1.3501,  1.5491, -0.5732],\n",
            "        [-1.3490,  1.7204, -0.7160],\n",
            "        [ 0.6794,  0.0073, -1.1780],\n",
            "        [-1.8336,  0.2308,  1.3461],\n",
            "        [-1.5248,  0.3249,  1.0236],\n",
            "        [-1.6908,  0.2290,  1.1632],\n",
            "        [-1.5703,  2.0337, -0.2422],\n",
            "        [-0.8586,  1.0797, -0.6997],\n",
            "        [ 0.6112, -0.0258, -1.4130],\n",
            "        [ 0.8219,  0.0567, -1.3081],\n",
            "        [-1.6577,  1.9785, -0.3628],\n",
            "        [-1.6415,  1.5055, -0.3960],\n",
            "        [-1.7240,  1.8019, -0.3301],\n",
            "        [-1.0213,  1.5120, -0.7697],\n",
            "        [-1.6562,  0.3776,  1.3218]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7522,  0.4658,  1.2039],\n",
            "        [-1.5282,  1.8810, -0.4734],\n",
            "        [-1.6637,  0.3564,  1.1880],\n",
            "        [ 0.7965, -0.0178, -1.4016],\n",
            "        [-1.5581,  1.5529, -0.3182],\n",
            "        [ 0.2480,  0.5331, -1.2701],\n",
            "        [-1.4973,  1.7949, -0.4478],\n",
            "        [ 0.6830,  0.0677, -1.2549],\n",
            "        [-1.6149,  1.7741, -0.5555],\n",
            "        [-1.7031,  1.8922, -0.2977],\n",
            "        [-2.0023,  0.5494,  1.2646],\n",
            "        [-1.4397,  1.6573, -0.4108],\n",
            "        [-1.8357,  0.2906,  1.3492],\n",
            "        [-1.5441,  1.8804, -0.4184],\n",
            "        [ 0.6796,  0.0694, -1.4098],\n",
            "        [ 0.7784, -0.1055, -1.2022]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7522,  0.4658,  1.2039],\n",
            "        [-1.5282,  1.8810, -0.4734],\n",
            "        [-1.6637,  0.3564,  1.1880],\n",
            "        [ 0.7965, -0.0178, -1.4016],\n",
            "        [-1.5581,  1.5529, -0.3182],\n",
            "        [ 0.2480,  0.5331, -1.2701],\n",
            "        [-1.4973,  1.7949, -0.4478],\n",
            "        [ 0.6830,  0.0677, -1.2549],\n",
            "        [-1.6149,  1.7741, -0.5555],\n",
            "        [-1.7031,  1.8922, -0.2977],\n",
            "        [-2.0023,  0.5494,  1.2646],\n",
            "        [-1.4397,  1.6573, -0.4108],\n",
            "        [-1.8357,  0.2906,  1.3492],\n",
            "        [-1.5441,  1.8804, -0.4184],\n",
            "        [ 0.6796,  0.0694, -1.4098],\n",
            "        [ 0.7784, -0.1055, -1.2022]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7507,  1.6571,  0.0291],\n",
            "        [-2.0733,  0.1586,  1.3278],\n",
            "        [-1.8330,  0.7909,  0.8154],\n",
            "        [ 0.3982, -0.0283, -0.9428],\n",
            "        [-1.8733,  0.3891,  1.4908],\n",
            "        [-2.0145,  0.6037,  1.0451],\n",
            "        [-0.7829,  0.9784, -0.5348],\n",
            "        [-1.6619,  1.5335, -0.0339],\n",
            "        [ 0.6157,  0.0469, -1.4175],\n",
            "        [-1.6580,  1.8454, -0.2901],\n",
            "        [-1.5629,  1.6685, -0.6073],\n",
            "        [-1.6383,  1.7234, -0.4243],\n",
            "        [-2.0269,  0.2572,  1.1546],\n",
            "        [-1.5930,  1.5307, -0.0770],\n",
            "        [ 0.5570, -0.0698, -1.2617],\n",
            "        [ 0.8234,  0.0134, -1.3035]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7507,  1.6571,  0.0291],\n",
            "        [-2.0733,  0.1586,  1.3278],\n",
            "        [-1.8330,  0.7909,  0.8154],\n",
            "        [ 0.3982, -0.0283, -0.9428],\n",
            "        [-1.8733,  0.3891,  1.4908],\n",
            "        [-2.0145,  0.6037,  1.0451],\n",
            "        [-0.7829,  0.9784, -0.5348],\n",
            "        [-1.6619,  1.5335, -0.0339],\n",
            "        [ 0.6157,  0.0469, -1.4175],\n",
            "        [-1.6580,  1.8454, -0.2901],\n",
            "        [-1.5629,  1.6685, -0.6073],\n",
            "        [-1.6383,  1.7234, -0.4243],\n",
            "        [-2.0269,  0.2572,  1.1546],\n",
            "        [-1.5930,  1.5307, -0.0770],\n",
            "        [ 0.5570, -0.0698, -1.2617],\n",
            "        [ 0.8234,  0.0134, -1.3035]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7023,  1.8762, -0.4178],\n",
            "        [-1.8262,  0.4883,  1.1933],\n",
            "        [-1.6854,  0.9269,  0.5817],\n",
            "        [-1.3397,  0.1501,  1.1276],\n",
            "        [-1.4580,  1.6436, -0.3854],\n",
            "        [-1.4078,  1.6742, -0.4490],\n",
            "        [-1.7656,  0.5061,  1.1941],\n",
            "        [-1.8636,  0.4131,  1.4813],\n",
            "        [-1.6787,  1.5211, -0.5560],\n",
            "        [-1.9729,  0.3791,  1.3281],\n",
            "        [-1.4978,  1.6863, -0.3384],\n",
            "        [-1.6757,  1.8819, -0.3203],\n",
            "        [-1.5730,  1.7135, -0.3579],\n",
            "        [-1.5085,  1.9836, -0.5148],\n",
            "        [ 0.7745,  0.0888, -1.3172],\n",
            "        [-2.0499,  0.5274,  1.2990]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7023,  1.8762, -0.4178],\n",
            "        [-1.8262,  0.4883,  1.1933],\n",
            "        [-1.6854,  0.9269,  0.5817],\n",
            "        [-1.3397,  0.1501,  1.1276],\n",
            "        [-1.4580,  1.6436, -0.3854],\n",
            "        [-1.4078,  1.6742, -0.4490],\n",
            "        [-1.7656,  0.5061,  1.1941],\n",
            "        [-1.8636,  0.4131,  1.4813],\n",
            "        [-1.6787,  1.5211, -0.5560],\n",
            "        [-1.9729,  0.3791,  1.3281],\n",
            "        [-1.4978,  1.6863, -0.3384],\n",
            "        [-1.6757,  1.8819, -0.3203],\n",
            "        [-1.5730,  1.7135, -0.3579],\n",
            "        [-1.5085,  1.9836, -0.5148],\n",
            "        [ 0.7745,  0.0888, -1.3172],\n",
            "        [-2.0499,  0.5274,  1.2990]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4438,  1.5717, -0.2711],\n",
            "        [-1.6938,  1.7774, -0.8054],\n",
            "        [-1.6785,  1.6451, -0.3310],\n",
            "        [-1.9624,  0.4411,  1.3015],\n",
            "        [-1.4167,  1.6942, -0.7657],\n",
            "        [-0.3970,  0.5597, -0.4747],\n",
            "        [-1.9286,  0.5015,  1.0730],\n",
            "        [-1.4131,  1.6687, -0.3503],\n",
            "        [-1.9193,  0.4158,  1.4183],\n",
            "        [-1.6458,  1.9601, -0.6257],\n",
            "        [-1.5508,  2.0265, -0.4992],\n",
            "        [ 0.6662,  0.0779, -1.3082],\n",
            "        [-1.5208,  1.0605,  0.0285],\n",
            "        [-1.8825,  0.3795,  1.3196],\n",
            "        [-1.9240,  0.3686,  1.3401],\n",
            "        [-1.4243,  0.3740,  1.0102]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4438,  1.5717, -0.2711],\n",
            "        [-1.6938,  1.7774, -0.8054],\n",
            "        [-1.6785,  1.6451, -0.3310],\n",
            "        [-1.9624,  0.4411,  1.3015],\n",
            "        [-1.4167,  1.6942, -0.7657],\n",
            "        [-0.3970,  0.5597, -0.4747],\n",
            "        [-1.9286,  0.5015,  1.0730],\n",
            "        [-1.4131,  1.6687, -0.3503],\n",
            "        [-1.9193,  0.4158,  1.4183],\n",
            "        [-1.6458,  1.9601, -0.6257],\n",
            "        [-1.5508,  2.0265, -0.4992],\n",
            "        [ 0.6662,  0.0779, -1.3082],\n",
            "        [-1.5208,  1.0605,  0.0285],\n",
            "        [-1.8825,  0.3795,  1.3196],\n",
            "        [-1.9240,  0.3686,  1.3401],\n",
            "        [-1.4243,  0.3740,  1.0102]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6069,  0.3926,  1.0995],\n",
            "        [-1.4745,  1.7791, -0.3908],\n",
            "        [-1.3961,  1.9108, -0.3685],\n",
            "        [-1.9448,  0.5697,  0.7947],\n",
            "        [-1.6617,  1.8620, -0.4451],\n",
            "        [-1.9965,  0.3815,  1.3245],\n",
            "        [-1.7843,  1.7761, -0.4942],\n",
            "        [-1.7012,  1.8548, -0.2948],\n",
            "        [-1.6868,  1.8131, -0.4255],\n",
            "        [ 0.6640,  0.3154, -1.3067],\n",
            "        [-1.8786,  0.5361,  1.2429],\n",
            "        [ 0.8256,  0.1161, -1.1988],\n",
            "        [-1.9210,  0.2272,  1.2318],\n",
            "        [-1.6292,  0.4722,  1.0511],\n",
            "        [-1.6524,  1.7518, -0.5480],\n",
            "        [-1.9423,  0.2085,  1.0959]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6069,  0.3926,  1.0995],\n",
            "        [-1.4745,  1.7791, -0.3908],\n",
            "        [-1.3961,  1.9108, -0.3685],\n",
            "        [-1.9448,  0.5697,  0.7947],\n",
            "        [-1.6617,  1.8620, -0.4451],\n",
            "        [-1.9965,  0.3815,  1.3245],\n",
            "        [-1.7843,  1.7761, -0.4942],\n",
            "        [-1.7012,  1.8548, -0.2948],\n",
            "        [-1.6868,  1.8131, -0.4255],\n",
            "        [ 0.6640,  0.3154, -1.3067],\n",
            "        [-1.8786,  0.5361,  1.2429],\n",
            "        [ 0.8256,  0.1161, -1.1988],\n",
            "        [-1.9210,  0.2272,  1.2318],\n",
            "        [-1.6292,  0.4722,  1.0511],\n",
            "        [-1.6524,  1.7518, -0.5480],\n",
            "        [-1.9423,  0.2085,  1.0959]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5804,  1.7114, -0.5291],\n",
            "        [-1.7297,  0.4435,  1.2674],\n",
            "        [-1.7135,  1.8600, -0.2919],\n",
            "        [ 0.4671,  0.0904, -1.4157],\n",
            "        [-1.8131,  1.0950,  0.4617],\n",
            "        [-2.0207,  1.0031,  0.7179],\n",
            "        [-1.5826,  1.7008, -0.2709],\n",
            "        [-1.4558,  1.6556, -0.4091],\n",
            "        [-1.7128,  1.9352, -0.3810],\n",
            "        [-1.6940,  1.7948, -0.3865],\n",
            "        [-1.6078,  1.9552, -0.3185],\n",
            "        [-1.6114,  2.0067, -0.4547],\n",
            "        [-1.8916,  0.9744,  0.8120],\n",
            "        [-1.8574,  1.8731, -0.3732],\n",
            "        [-1.7258,  1.9779, -0.5259],\n",
            "        [-1.5270,  0.8065,  0.8539]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5804,  1.7114, -0.5291],\n",
            "        [-1.7297,  0.4435,  1.2674],\n",
            "        [-1.7135,  1.8600, -0.2919],\n",
            "        [ 0.4671,  0.0904, -1.4157],\n",
            "        [-1.8131,  1.0950,  0.4617],\n",
            "        [-2.0207,  1.0031,  0.7179],\n",
            "        [-1.5826,  1.7008, -0.2709],\n",
            "        [-1.4558,  1.6556, -0.4091],\n",
            "        [-1.7128,  1.9352, -0.3810],\n",
            "        [-1.6940,  1.7948, -0.3865],\n",
            "        [-1.6078,  1.9552, -0.3185],\n",
            "        [-1.6114,  2.0067, -0.4547],\n",
            "        [-1.8916,  0.9744,  0.8120],\n",
            "        [-1.8574,  1.8731, -0.3732],\n",
            "        [-1.7258,  1.9779, -0.5259],\n",
            "        [-1.5270,  0.8065,  0.8539]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3651,  1.5789, -0.4686],\n",
            "        [-1.7383,  1.9857, -0.6613],\n",
            "        [-1.7893,  0.5931,  1.2151],\n",
            "        [-1.6928,  0.5006,  1.2444],\n",
            "        [-1.9247,  1.4394, -0.2714],\n",
            "        [-1.5583,  1.8207, -0.5392],\n",
            "        [-1.7623,  1.7856, -0.5026],\n",
            "        [ 0.6991,  0.0085, -1.2759],\n",
            "        [-1.5495,  1.8663, -0.2933],\n",
            "        [-1.4705,  1.9420, -0.5475],\n",
            "        [ 0.6400,  0.2305, -1.2052],\n",
            "        [-1.9635,  0.5341,  1.2138],\n",
            "        [-1.7048,  0.5269,  1.2421],\n",
            "        [-1.5069,  1.5568, -0.4731],\n",
            "        [-1.6557,  1.5548, -0.3116],\n",
            "        [-1.7164,  0.2932,  1.1277]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3651,  1.5789, -0.4686],\n",
            "        [-1.7383,  1.9857, -0.6613],\n",
            "        [-1.7893,  0.5931,  1.2151],\n",
            "        [-1.6928,  0.5006,  1.2444],\n",
            "        [-1.9247,  1.4394, -0.2714],\n",
            "        [-1.5583,  1.8207, -0.5392],\n",
            "        [-1.7623,  1.7856, -0.5026],\n",
            "        [ 0.6991,  0.0085, -1.2759],\n",
            "        [-1.5495,  1.8663, -0.2933],\n",
            "        [-1.4705,  1.9420, -0.5475],\n",
            "        [ 0.6400,  0.2305, -1.2052],\n",
            "        [-1.9635,  0.5341,  1.2138],\n",
            "        [-1.7048,  0.5269,  1.2421],\n",
            "        [-1.5069,  1.5568, -0.4731],\n",
            "        [-1.6557,  1.5548, -0.3116],\n",
            "        [-1.7164,  0.2932,  1.1277]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5308,  1.7191, -0.4926],\n",
            "        [-1.7843,  0.4914,  1.2383],\n",
            "        [-1.5476,  1.8071, -0.5675],\n",
            "        [-1.6987,  1.8626, -0.1047],\n",
            "        [-1.7309,  1.5846, -0.0516],\n",
            "        [-1.7820,  0.4202,  1.2909],\n",
            "        [-1.6672,  1.5935, -0.3349],\n",
            "        [-1.7707,  1.7791, -0.2941],\n",
            "        [-1.6651,  0.6856,  0.9736],\n",
            "        [ 0.8488,  0.0603, -1.5295],\n",
            "        [-1.4901,  1.9290, -0.3152],\n",
            "        [-1.4345,  1.9456, -0.5165],\n",
            "        [-1.0372,  1.0187, -0.2431],\n",
            "        [-1.6460,  1.6608, -0.4080],\n",
            "        [-1.5725,  1.8314, -0.3613],\n",
            "        [-1.6476,  1.9416, -0.3492]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5308,  1.7191, -0.4926],\n",
            "        [-1.7843,  0.4914,  1.2383],\n",
            "        [-1.5476,  1.8071, -0.5675],\n",
            "        [-1.6987,  1.8626, -0.1047],\n",
            "        [-1.7309,  1.5846, -0.0516],\n",
            "        [-1.7820,  0.4202,  1.2909],\n",
            "        [-1.6672,  1.5935, -0.3349],\n",
            "        [-1.7707,  1.7791, -0.2941],\n",
            "        [-1.6651,  0.6856,  0.9736],\n",
            "        [ 0.8488,  0.0603, -1.5295],\n",
            "        [-1.4901,  1.9290, -0.3152],\n",
            "        [-1.4345,  1.9456, -0.5165],\n",
            "        [-1.0372,  1.0187, -0.2431],\n",
            "        [-1.6460,  1.6608, -0.4080],\n",
            "        [-1.5725,  1.8314, -0.3613],\n",
            "        [-1.6476,  1.9416, -0.3492]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5557,  1.8233, -0.5749],\n",
            "        [-1.7107,  0.5279,  1.1847],\n",
            "        [-1.7810,  1.6950, -0.3087],\n",
            "        [-1.8202,  2.0178, -0.4036],\n",
            "        [-1.6182,  1.6896, -0.4094],\n",
            "        [-1.1081,  0.6583,  0.2458],\n",
            "        [-1.7944,  2.0410, -0.5939],\n",
            "        [-1.6163,  1.6400, -0.6879],\n",
            "        [-1.6536,  0.2708,  1.1928],\n",
            "        [-1.7836,  0.7098,  1.1148],\n",
            "        [-1.6667,  2.1145, -0.5158],\n",
            "        [-1.8418,  1.9192, -0.2472],\n",
            "        [-1.4117,  1.3440, -0.6411],\n",
            "        [-1.8254,  0.4880,  1.1809],\n",
            "        [ 0.5255,  0.0505, -1.1031],\n",
            "        [ 0.8269,  0.1334, -1.2351]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5557,  1.8233, -0.5749],\n",
            "        [-1.7107,  0.5279,  1.1847],\n",
            "        [-1.7810,  1.6950, -0.3087],\n",
            "        [-1.8202,  2.0178, -0.4036],\n",
            "        [-1.6182,  1.6896, -0.4094],\n",
            "        [-1.1081,  0.6583,  0.2458],\n",
            "        [-1.7944,  2.0410, -0.5939],\n",
            "        [-1.6163,  1.6400, -0.6879],\n",
            "        [-1.6536,  0.2708,  1.1928],\n",
            "        [-1.7836,  0.7098,  1.1148],\n",
            "        [-1.6667,  2.1145, -0.5158],\n",
            "        [-1.8418,  1.9192, -0.2472],\n",
            "        [-1.4117,  1.3440, -0.6411],\n",
            "        [-1.8254,  0.4880,  1.1809],\n",
            "        [ 0.5255,  0.0505, -1.1031],\n",
            "        [ 0.8269,  0.1334, -1.2351]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0487,  0.9040,  0.8758],\n",
            "        [-1.3820,  1.8187, -0.6256],\n",
            "        [ 0.6354,  0.1135, -1.5327],\n",
            "        [-1.7750,  1.8456, -0.3785],\n",
            "        [-1.6498,  1.9944, -0.8008],\n",
            "        [-1.7756,  0.7491,  1.0773],\n",
            "        [-1.7728,  1.9088, -0.4357],\n",
            "        [ 0.7585,  0.0552, -1.1470],\n",
            "        [-1.5579,  1.9037, -0.3627],\n",
            "        [ 0.5625,  0.2470, -1.3716],\n",
            "        [-1.8735,  0.4256,  1.3263],\n",
            "        [-1.6555,  2.0711, -0.4466],\n",
            "        [-1.7173,  1.7544, -0.2349],\n",
            "        [-1.6711,  1.6774, -0.6403],\n",
            "        [-1.6809,  1.9038, -0.4187],\n",
            "        [-1.8792,  0.5876,  1.1580]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0487,  0.9040,  0.8758],\n",
            "        [-1.3820,  1.8187, -0.6256],\n",
            "        [ 0.6354,  0.1135, -1.5327],\n",
            "        [-1.7750,  1.8456, -0.3785],\n",
            "        [-1.6498,  1.9944, -0.8008],\n",
            "        [-1.7756,  0.7491,  1.0773],\n",
            "        [-1.7728,  1.9088, -0.4357],\n",
            "        [ 0.7585,  0.0552, -1.1470],\n",
            "        [-1.5579,  1.9037, -0.3627],\n",
            "        [ 0.5625,  0.2470, -1.3716],\n",
            "        [-1.8735,  0.4256,  1.3263],\n",
            "        [-1.6555,  2.0711, -0.4466],\n",
            "        [-1.7173,  1.7544, -0.2349],\n",
            "        [-1.6711,  1.6774, -0.6403],\n",
            "        [-1.6809,  1.9038, -0.4187],\n",
            "        [-1.8792,  0.5876,  1.1580]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.7255,  0.0351, -1.2764],\n",
            "        [-1.4233,  2.0236, -0.5373],\n",
            "        [-1.9027,  0.4506,  1.1572],\n",
            "        [-1.6005,  0.4272,  0.9914],\n",
            "        [-1.4734,  1.5211, -0.6165],\n",
            "        [-1.4728,  1.9523, -0.7107],\n",
            "        [-1.7896,  0.4629,  1.0447],\n",
            "        [ 0.2421,  0.6067, -1.4026],\n",
            "        [-1.9012,  0.5591,  1.1467],\n",
            "        [-1.7729,  1.8836, -0.2634],\n",
            "        [-1.6756,  1.7764, -0.7233],\n",
            "        [-1.7547,  0.6113,  1.3260],\n",
            "        [-1.7030,  1.2714,  0.1243],\n",
            "        [-1.5258,  2.1638, -0.5965],\n",
            "        [-1.9062,  0.9288,  1.1712],\n",
            "        [-2.0912,  0.4640,  1.2654]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.7255,  0.0351, -1.2764],\n",
            "        [-1.4233,  2.0236, -0.5373],\n",
            "        [-1.9027,  0.4506,  1.1572],\n",
            "        [-1.6005,  0.4272,  0.9914],\n",
            "        [-1.4734,  1.5211, -0.6165],\n",
            "        [-1.4728,  1.9523, -0.7107],\n",
            "        [-1.7896,  0.4629,  1.0447],\n",
            "        [ 0.2421,  0.6067, -1.4026],\n",
            "        [-1.9012,  0.5591,  1.1467],\n",
            "        [-1.7729,  1.8836, -0.2634],\n",
            "        [-1.6756,  1.7764, -0.7233],\n",
            "        [-1.7547,  0.6113,  1.3260],\n",
            "        [-1.7030,  1.2714,  0.1243],\n",
            "        [-1.5258,  2.1638, -0.5965],\n",
            "        [-1.9062,  0.9288,  1.1712],\n",
            "        [-2.0912,  0.4640,  1.2654]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7757,  0.4997,  1.1070],\n",
            "        [-1.6288,  2.1040, -0.5774],\n",
            "        [-1.6203,  1.7760, -0.6475],\n",
            "        [-1.3899,  1.7301, -0.5897],\n",
            "        [-1.5370,  1.9209, -0.4287],\n",
            "        [-1.5396,  2.0377, -0.4774],\n",
            "        [ 0.8348, -0.0071, -1.2058],\n",
            "        [ 0.7002,  0.0962, -1.2460],\n",
            "        [-1.8794,  0.9296,  0.8306],\n",
            "        [-1.9543,  0.6519,  0.8297],\n",
            "        [-1.8749,  0.8058,  0.9750],\n",
            "        [-1.8380,  0.5955,  0.9830],\n",
            "        [-1.8974,  0.5918,  1.0499],\n",
            "        [-1.6044,  1.8876, -0.7318],\n",
            "        [-1.7459,  2.1360, -0.3120],\n",
            "        [-1.9435,  0.4867,  1.0979]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7757,  0.4997,  1.1070],\n",
            "        [-1.6288,  2.1040, -0.5774],\n",
            "        [-1.6203,  1.7760, -0.6475],\n",
            "        [-1.3899,  1.7301, -0.5897],\n",
            "        [-1.5370,  1.9209, -0.4287],\n",
            "        [-1.5396,  2.0377, -0.4774],\n",
            "        [ 0.8348, -0.0071, -1.2058],\n",
            "        [ 0.7002,  0.0962, -1.2460],\n",
            "        [-1.8794,  0.9296,  0.8306],\n",
            "        [-1.9543,  0.6519,  0.8297],\n",
            "        [-1.8749,  0.8058,  0.9750],\n",
            "        [-1.8380,  0.5955,  0.9830],\n",
            "        [-1.8974,  0.5918,  1.0499],\n",
            "        [-1.6044,  1.8876, -0.7318],\n",
            "        [-1.7459,  2.1360, -0.3120],\n",
            "        [-1.9435,  0.4867,  1.0979]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8195,  0.6451,  1.2097],\n",
            "        [-1.7459,  2.0565, -0.3606],\n",
            "        [-1.5837,  1.8518, -0.4282],\n",
            "        [-1.8994,  2.1622, -0.3904],\n",
            "        [-1.7270,  2.0542, -0.4965],\n",
            "        [ 0.7423, -0.0185, -1.5195],\n",
            "        [-0.9011,  1.2041, -0.8398],\n",
            "        [-1.4977,  1.9091, -0.7911],\n",
            "        [-1.5794,  1.6663, -0.3449],\n",
            "        [-1.7349,  0.4339,  1.1143],\n",
            "        [-2.1054,  0.7233,  1.3639],\n",
            "        [-1.7421,  1.8770, -0.4021],\n",
            "        [-1.5239,  1.9101, -0.5482],\n",
            "        [-1.6650,  1.8157, -0.5112],\n",
            "        [-1.6452,  0.5393,  1.2356],\n",
            "        [-2.0148,  0.5833,  1.1433]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8195,  0.6451,  1.2097],\n",
            "        [-1.7459,  2.0565, -0.3606],\n",
            "        [-1.5837,  1.8518, -0.4282],\n",
            "        [-1.8994,  2.1622, -0.3904],\n",
            "        [-1.7270,  2.0542, -0.4965],\n",
            "        [ 0.7423, -0.0185, -1.5195],\n",
            "        [-0.9011,  1.2041, -0.8398],\n",
            "        [-1.4977,  1.9091, -0.7911],\n",
            "        [-1.5794,  1.6663, -0.3449],\n",
            "        [-1.7349,  0.4339,  1.1143],\n",
            "        [-2.1054,  0.7233,  1.3639],\n",
            "        [-1.7421,  1.8770, -0.4021],\n",
            "        [-1.5239,  1.9101, -0.5482],\n",
            "        [-1.6650,  1.8157, -0.5112],\n",
            "        [-1.6452,  0.5393,  1.2356],\n",
            "        [-2.0148,  0.5833,  1.1433]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6722,  1.6329, -0.1019],\n",
            "        [-1.1722,  1.6289, -0.8291],\n",
            "        [-1.5704,  2.0294, -0.4810],\n",
            "        [-1.6921,  2.1359, -0.4240],\n",
            "        [-1.7222,  2.0737, -0.4935],\n",
            "        [-1.2903,  1.5775, -0.7419],\n",
            "        [-2.0015,  2.0769, -0.6380],\n",
            "        [-1.5814,  1.8795, -0.5686],\n",
            "        [-1.8165,  1.6895,  0.1609],\n",
            "        [-1.7340,  2.1343, -0.6416],\n",
            "        [-1.6342,  1.9105, -0.4708],\n",
            "        [-1.9080,  0.9602,  0.7480],\n",
            "        [ 0.5413,  0.0230, -1.2732],\n",
            "        [ 0.7139,  0.0612, -1.2678],\n",
            "        [-1.7700,  1.9891, -0.4539],\n",
            "        [-1.4841,  1.9893, -0.6597]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6722,  1.6329, -0.1019],\n",
            "        [-1.1722,  1.6289, -0.8291],\n",
            "        [-1.5704,  2.0294, -0.4810],\n",
            "        [-1.6921,  2.1359, -0.4240],\n",
            "        [-1.7222,  2.0737, -0.4935],\n",
            "        [-1.2903,  1.5775, -0.7419],\n",
            "        [-2.0015,  2.0769, -0.6380],\n",
            "        [-1.5814,  1.8795, -0.5686],\n",
            "        [-1.8165,  1.6895,  0.1609],\n",
            "        [-1.7340,  2.1343, -0.6416],\n",
            "        [-1.6342,  1.9105, -0.4708],\n",
            "        [-1.9080,  0.9602,  0.7480],\n",
            "        [ 0.5413,  0.0230, -1.2732],\n",
            "        [ 0.7139,  0.0612, -1.2678],\n",
            "        [-1.7700,  1.9891, -0.4539],\n",
            "        [-1.4841,  1.9893, -0.6597]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3327,  0.3477, -1.2694],\n",
            "        [-1.8374,  2.1619, -0.4732],\n",
            "        [-1.5847,  2.0719, -0.5046],\n",
            "        [-1.6509,  1.5730,  0.0268],\n",
            "        [ 0.5978,  0.2561, -1.3653],\n",
            "        [-1.8778,  0.5912,  1.1558],\n",
            "        [-1.9848,  1.1704,  0.4827],\n",
            "        [ 0.6287,  0.2408, -1.2477],\n",
            "        [-1.8415,  2.1878, -0.5018],\n",
            "        [-1.9651,  0.5807,  1.2498],\n",
            "        [-1.9099,  1.5624,  0.1294],\n",
            "        [-1.4666,  1.7566, -0.4499],\n",
            "        [-1.9854,  0.5858,  1.1785],\n",
            "        [-1.7184,  1.9137, -0.6124],\n",
            "        [-1.6487,  1.9429, -0.5838],\n",
            "        [-1.8107,  0.7469,  1.0624]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.3327,  0.3477, -1.2694],\n",
            "        [-1.8374,  2.1619, -0.4732],\n",
            "        [-1.5847,  2.0719, -0.5046],\n",
            "        [-1.6509,  1.5730,  0.0268],\n",
            "        [ 0.5978,  0.2561, -1.3653],\n",
            "        [-1.8778,  0.5912,  1.1558],\n",
            "        [-1.9848,  1.1704,  0.4827],\n",
            "        [ 0.6287,  0.2408, -1.2477],\n",
            "        [-1.8415,  2.1878, -0.5018],\n",
            "        [-1.9651,  0.5807,  1.2498],\n",
            "        [-1.9099,  1.5624,  0.1294],\n",
            "        [-1.4666,  1.7566, -0.4499],\n",
            "        [-1.9854,  0.5858,  1.1785],\n",
            "        [-1.7184,  1.9137, -0.6124],\n",
            "        [-1.6487,  1.9429, -0.5838],\n",
            "        [-1.8107,  0.7469,  1.0624]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7317,  1.9326, -0.6166],\n",
            "        [-1.7011,  1.8649, -0.5151],\n",
            "        [ 0.8450,  0.0702, -1.1610],\n",
            "        [-1.9406,  2.1253, -0.3229],\n",
            "        [-1.7551,  1.8700, -0.5173],\n",
            "        [ 0.1062,  0.4213, -1.2552],\n",
            "        [-1.5909,  1.8254, -0.4415],\n",
            "        [-1.7534,  1.7412, -0.5265],\n",
            "        [-1.9532,  1.2859,  0.3727],\n",
            "        [-1.7730,  2.1216, -0.4484],\n",
            "        [-1.6444,  0.6261,  0.9356],\n",
            "        [-1.4789,  1.8165, -0.6542],\n",
            "        [-1.6212,  1.8046, -0.5208],\n",
            "        [-1.7119,  1.9953, -0.4593],\n",
            "        [-1.7461,  1.0742,  0.9680],\n",
            "        [-1.8195,  0.7085,  0.9962]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7317,  1.9326, -0.6166],\n",
            "        [-1.7011,  1.8649, -0.5151],\n",
            "        [ 0.8450,  0.0702, -1.1610],\n",
            "        [-1.9406,  2.1253, -0.3229],\n",
            "        [-1.7551,  1.8700, -0.5173],\n",
            "        [ 0.1062,  0.4213, -1.2552],\n",
            "        [-1.5909,  1.8254, -0.4415],\n",
            "        [-1.7534,  1.7412, -0.5265],\n",
            "        [-1.9532,  1.2859,  0.3727],\n",
            "        [-1.7730,  2.1216, -0.4484],\n",
            "        [-1.6444,  0.6261,  0.9356],\n",
            "        [-1.4789,  1.8165, -0.6542],\n",
            "        [-1.6212,  1.8046, -0.5208],\n",
            "        [-1.7119,  1.9953, -0.4593],\n",
            "        [-1.7461,  1.0742,  0.9680],\n",
            "        [-1.8195,  0.7085,  0.9962]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4373,  1.6606, -0.7549],\n",
            "        [ 0.6991,  0.0736, -1.1811],\n",
            "        [-1.7792,  1.8096, -0.1912],\n",
            "        [-1.8895,  2.2303, -0.4581],\n",
            "        [-1.8693,  0.6112,  1.1991],\n",
            "        [-1.9049,  2.1651, -0.4425],\n",
            "        [-1.6498,  1.8441, -0.5276],\n",
            "        [-1.7251,  2.0355, -0.1765],\n",
            "        [-1.9068,  1.8308, -0.3284],\n",
            "        [-1.7140,  2.1919, -0.4827],\n",
            "        [-0.1964,  0.1380, -0.0551],\n",
            "        [-1.7337,  1.9972, -0.1616],\n",
            "        [-1.9977,  1.9026, -0.3689],\n",
            "        [-0.9150,  0.9832, -0.2595],\n",
            "        [ 0.4115,  0.3721, -1.2370],\n",
            "        [-1.7578,  2.1462, -0.2832]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4373,  1.6606, -0.7549],\n",
            "        [ 0.6991,  0.0736, -1.1811],\n",
            "        [-1.7792,  1.8096, -0.1912],\n",
            "        [-1.8895,  2.2303, -0.4581],\n",
            "        [-1.8693,  0.6112,  1.1991],\n",
            "        [-1.9049,  2.1651, -0.4425],\n",
            "        [-1.6498,  1.8441, -0.5276],\n",
            "        [-1.7251,  2.0355, -0.1765],\n",
            "        [-1.9068,  1.8308, -0.3284],\n",
            "        [-1.7140,  2.1919, -0.4827],\n",
            "        [-0.1964,  0.1380, -0.0551],\n",
            "        [-1.7337,  1.9972, -0.1616],\n",
            "        [-1.9977,  1.9026, -0.3689],\n",
            "        [-0.9150,  0.9832, -0.2595],\n",
            "        [ 0.4115,  0.3721, -1.2370],\n",
            "        [-1.7578,  2.1462, -0.2832]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6763,  1.8265, -0.1588],\n",
            "        [-1.6873,  1.8795, -0.2076],\n",
            "        [-1.9277,  2.0164, -0.2334],\n",
            "        [-1.9864,  0.6595,  1.2173],\n",
            "        [-1.9131,  2.0158, -0.3602],\n",
            "        [-1.8218,  2.2156, -0.4340],\n",
            "        [-1.9476,  0.3979,  1.3566],\n",
            "        [-1.6817,  0.6824,  0.8414],\n",
            "        [-0.8951,  0.2385,  0.4339],\n",
            "        [ 0.6820, -0.0258, -1.3029],\n",
            "        [-1.9108,  0.7492,  0.9018],\n",
            "        [ 0.3497,  0.3666, -1.2674],\n",
            "        [-1.6154,  0.6201,  1.0551],\n",
            "        [-1.7613,  1.9504, -0.5131],\n",
            "        [-1.8337,  1.9556, -0.4623],\n",
            "        [-1.7802,  0.5540,  1.0855]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6763,  1.8265, -0.1588],\n",
            "        [-1.6873,  1.8795, -0.2076],\n",
            "        [-1.9277,  2.0164, -0.2334],\n",
            "        [-1.9864,  0.6595,  1.2173],\n",
            "        [-1.9131,  2.0158, -0.3602],\n",
            "        [-1.8218,  2.2156, -0.4340],\n",
            "        [-1.9476,  0.3979,  1.3566],\n",
            "        [-1.6817,  0.6824,  0.8414],\n",
            "        [-0.8951,  0.2385,  0.4339],\n",
            "        [ 0.6820, -0.0258, -1.3029],\n",
            "        [-1.9108,  0.7492,  0.9018],\n",
            "        [ 0.3497,  0.3666, -1.2674],\n",
            "        [-1.6154,  0.6201,  1.0551],\n",
            "        [-1.7613,  1.9504, -0.5131],\n",
            "        [-1.8337,  1.9556, -0.4623],\n",
            "        [-1.7802,  0.5540,  1.0855]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8691,  0.4217,  1.2451],\n",
            "        [-1.6632,  1.8353, -0.5453],\n",
            "        [-1.7847,  1.7751, -0.6337],\n",
            "        [-1.8457,  1.9820, -0.3666],\n",
            "        [-1.8512,  1.2753, -0.1182],\n",
            "        [-1.9249,  2.0611, -0.4450],\n",
            "        [-2.0094,  2.0412, -0.2788],\n",
            "        [-1.9102,  2.0468, -0.4424],\n",
            "        [-2.0633,  1.9927,  0.0126],\n",
            "        [-1.9006,  1.9916, -0.2442],\n",
            "        [-2.0110,  0.3897,  1.3906],\n",
            "        [-1.7183,  1.9864, -0.3620],\n",
            "        [-1.7831,  0.4924,  0.9242],\n",
            "        [-1.9033,  0.2918,  1.2245],\n",
            "        [-1.8436,  2.0797, -0.2759],\n",
            "        [ 0.4174,  0.1364, -1.0915]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8691,  0.4217,  1.2451],\n",
            "        [-1.6632,  1.8353, -0.5453],\n",
            "        [-1.7847,  1.7751, -0.6337],\n",
            "        [-1.8457,  1.9820, -0.3666],\n",
            "        [-1.8512,  1.2753, -0.1182],\n",
            "        [-1.9249,  2.0611, -0.4450],\n",
            "        [-2.0094,  2.0412, -0.2788],\n",
            "        [-1.9102,  2.0468, -0.4424],\n",
            "        [-2.0633,  1.9927,  0.0126],\n",
            "        [-1.9006,  1.9916, -0.2442],\n",
            "        [-2.0110,  0.3897,  1.3906],\n",
            "        [-1.7183,  1.9864, -0.3620],\n",
            "        [-1.7831,  0.4924,  0.9242],\n",
            "        [-1.9033,  0.2918,  1.2245],\n",
            "        [-1.8436,  2.0797, -0.2759],\n",
            "        [ 0.4174,  0.1364, -1.0915]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9879,  0.5597,  0.9520],\n",
            "        [-1.9962,  0.4625,  1.2609],\n",
            "        [-1.5605,  1.9254, -0.6015],\n",
            "        [-1.6635,  1.7280, -0.1433],\n",
            "        [-0.4384,  0.8482, -0.6554],\n",
            "        [-1.9267,  1.8285, -0.0203],\n",
            "        [-1.9462,  1.8914, -0.0023],\n",
            "        [-1.8420,  1.7357, -0.2649],\n",
            "        [-1.7875,  1.7952, -0.1895],\n",
            "        [-1.8563,  1.8065, -0.4250],\n",
            "        [-1.5707,  1.9382, -0.4355],\n",
            "        [-1.7045,  0.4510,  1.1551],\n",
            "        [-1.7194,  2.0423, -0.3846],\n",
            "        [-1.9755,  1.8985, -0.1840],\n",
            "        [-1.9988,  0.9602,  1.0584],\n",
            "        [-1.9449,  1.6991, -0.5313]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9879,  0.5597,  0.9520],\n",
            "        [-1.9962,  0.4625,  1.2609],\n",
            "        [-1.5605,  1.9254, -0.6015],\n",
            "        [-1.6635,  1.7280, -0.1433],\n",
            "        [-0.4384,  0.8482, -0.6554],\n",
            "        [-1.9267,  1.8285, -0.0203],\n",
            "        [-1.9462,  1.8914, -0.0023],\n",
            "        [-1.8420,  1.7357, -0.2649],\n",
            "        [-1.7875,  1.7952, -0.1895],\n",
            "        [-1.8563,  1.8065, -0.4250],\n",
            "        [-1.5707,  1.9382, -0.4355],\n",
            "        [-1.7045,  0.4510,  1.1551],\n",
            "        [-1.7194,  2.0423, -0.3846],\n",
            "        [-1.9755,  1.8985, -0.1840],\n",
            "        [-1.9988,  0.9602,  1.0584],\n",
            "        [-1.9449,  1.6991, -0.5313]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.2057,  0.5244, -0.8543],\n",
            "        [-2.0731,  0.5210,  1.4388],\n",
            "        [-1.8307,  1.8782, -0.1721],\n",
            "        [-1.3436,  0.3562,  0.6869],\n",
            "        [-1.9384,  2.0155, -0.3020],\n",
            "        [-1.8360,  2.0503, -0.1851],\n",
            "        [-2.0014,  1.8715, -0.1787],\n",
            "        [-1.8083,  1.6268, -0.4879],\n",
            "        [-1.5901,  1.4484, -0.2410],\n",
            "        [-1.7518,  0.4883,  1.4504],\n",
            "        [ 0.3946,  0.2292, -1.0262],\n",
            "        [-1.7876,  1.9363, -0.3977],\n",
            "        [-1.3405,  1.4671, -0.6984],\n",
            "        [-1.8567,  0.4720,  1.3346],\n",
            "        [ 0.3807,  0.1170, -1.2145],\n",
            "        [-1.5327,  1.5159, -0.5358]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-0.2057,  0.5244, -0.8543],\n",
            "        [-2.0731,  0.5210,  1.4388],\n",
            "        [-1.8307,  1.8782, -0.1721],\n",
            "        [-1.3436,  0.3562,  0.6869],\n",
            "        [-1.9384,  2.0155, -0.3020],\n",
            "        [-1.8360,  2.0503, -0.1851],\n",
            "        [-2.0014,  1.8715, -0.1787],\n",
            "        [-1.8083,  1.6268, -0.4879],\n",
            "        [-1.5901,  1.4484, -0.2410],\n",
            "        [-1.7518,  0.4883,  1.4504],\n",
            "        [ 0.3946,  0.2292, -1.0262],\n",
            "        [-1.7876,  1.9363, -0.3977],\n",
            "        [-1.3405,  1.4671, -0.6984],\n",
            "        [-1.8567,  0.4720,  1.3346],\n",
            "        [ 0.3807,  0.1170, -1.2145],\n",
            "        [-1.5327,  1.5159, -0.5358]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8740,  0.8700,  0.8148],\n",
            "        [-1.8562,  1.8292, -0.0321],\n",
            "        [-2.1010,  0.5203,  1.3121],\n",
            "        [-1.8823,  0.4829,  1.3651],\n",
            "        [-2.1102,  2.0130, -0.0768],\n",
            "        [-1.9537,  1.8670, -0.0439],\n",
            "        [-1.7489,  1.8758, -0.1677],\n",
            "        [-1.8115,  0.3728,  1.3072],\n",
            "        [-2.0284,  2.0139, -0.0646],\n",
            "        [-2.0507,  2.0190, -0.1588],\n",
            "        [-1.9507,  0.4631,  1.3114],\n",
            "        [-1.4185,  1.4056, -0.4911],\n",
            "        [-1.6939,  2.1446, -0.3872],\n",
            "        [-1.8209,  0.5939,  1.4228],\n",
            "        [ 0.3290,  0.1209, -0.9416],\n",
            "        [-1.8865,  1.8532, -0.3453]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8740,  0.8700,  0.8148],\n",
            "        [-1.8562,  1.8292, -0.0321],\n",
            "        [-2.1010,  0.5203,  1.3121],\n",
            "        [-1.8823,  0.4829,  1.3651],\n",
            "        [-2.1102,  2.0130, -0.0768],\n",
            "        [-1.9537,  1.8670, -0.0439],\n",
            "        [-1.7489,  1.8758, -0.1677],\n",
            "        [-1.8115,  0.3728,  1.3072],\n",
            "        [-2.0284,  2.0139, -0.0646],\n",
            "        [-2.0507,  2.0190, -0.1588],\n",
            "        [-1.9507,  0.4631,  1.3114],\n",
            "        [-1.4185,  1.4056, -0.4911],\n",
            "        [-1.6939,  2.1446, -0.3872],\n",
            "        [-1.8209,  0.5939,  1.4228],\n",
            "        [ 0.3290,  0.1209, -0.9416],\n",
            "        [-1.8865,  1.8532, -0.3453]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7383,  2.0587, -0.3185],\n",
            "        [ 0.4710,  0.0754, -1.1852],\n",
            "        [ 0.3884,  0.0420, -1.0366],\n",
            "        [-1.7863,  1.9678, -0.4613],\n",
            "        [-1.6527,  0.1995,  1.2141],\n",
            "        [-1.8422,  1.9382, -0.2011],\n",
            "        [-1.8949,  0.5160,  1.3732],\n",
            "        [-1.9924,  0.3475,  1.3819],\n",
            "        [-1.8420,  1.6634,  0.1326],\n",
            "        [-2.2595,  0.6571,  1.2025],\n",
            "        [-1.8006,  2.0131, -0.1350],\n",
            "        [-1.8221,  0.5256,  1.4274],\n",
            "        [-1.8541,  1.9623, -0.4101],\n",
            "        [-1.9208,  0.4464,  1.3851],\n",
            "        [-1.7281,  0.4506,  1.2819],\n",
            "        [-1.6267,  0.3400,  1.2386]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7383,  2.0587, -0.3185],\n",
            "        [ 0.4710,  0.0754, -1.1852],\n",
            "        [ 0.3884,  0.0420, -1.0366],\n",
            "        [-1.7863,  1.9678, -0.4613],\n",
            "        [-1.6527,  0.1995,  1.2141],\n",
            "        [-1.8422,  1.9382, -0.2011],\n",
            "        [-1.8949,  0.5160,  1.3732],\n",
            "        [-1.9924,  0.3475,  1.3819],\n",
            "        [-1.8420,  1.6634,  0.1326],\n",
            "        [-2.2595,  0.6571,  1.2025],\n",
            "        [-1.8006,  2.0131, -0.1350],\n",
            "        [-1.8221,  0.5256,  1.4274],\n",
            "        [-1.8541,  1.9623, -0.4101],\n",
            "        [-1.9208,  0.4464,  1.3851],\n",
            "        [-1.7281,  0.4506,  1.2819],\n",
            "        [-1.6267,  0.3400,  1.2386]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9923,  0.4221,  1.5908],\n",
            "        [-1.9327,  0.3432,  1.3778],\n",
            "        [-1.4619,  1.2780, -0.3722],\n",
            "        [-1.7509,  1.8744, -0.1978],\n",
            "        [-2.0400,  1.9242, -0.3459],\n",
            "        [ 0.3989,  0.2295, -1.1242],\n",
            "        [-1.7030,  2.0477, -0.3796],\n",
            "        [-1.8179,  1.5111, -0.2884],\n",
            "        [-2.0468,  1.7242, -0.2359],\n",
            "        [-1.9433,  1.8416, -0.2432],\n",
            "        [ 0.4092,  0.2770, -1.0528],\n",
            "        [-1.7491,  1.8192, -0.4979],\n",
            "        [-1.8987,  1.7093, -0.2601],\n",
            "        [-1.6674,  1.8643, -0.4544],\n",
            "        [-1.7656,  1.8057, -0.3400],\n",
            "        [-1.7728,  2.1707, -0.4045]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9923,  0.4221,  1.5908],\n",
            "        [-1.9327,  0.3432,  1.3778],\n",
            "        [-1.4619,  1.2780, -0.3722],\n",
            "        [-1.7509,  1.8744, -0.1978],\n",
            "        [-2.0400,  1.9242, -0.3459],\n",
            "        [ 0.3989,  0.2295, -1.1242],\n",
            "        [-1.7030,  2.0477, -0.3796],\n",
            "        [-1.8179,  1.5111, -0.2884],\n",
            "        [-2.0468,  1.7242, -0.2359],\n",
            "        [-1.9433,  1.8416, -0.2432],\n",
            "        [ 0.4092,  0.2770, -1.0528],\n",
            "        [-1.7491,  1.8192, -0.4979],\n",
            "        [-1.8987,  1.7093, -0.2601],\n",
            "        [-1.6674,  1.8643, -0.4544],\n",
            "        [-1.7656,  1.8057, -0.3400],\n",
            "        [-1.7728,  2.1707, -0.4045]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9141,  1.8931, -0.3712],\n",
            "        [-1.8635,  1.8140, -0.2104],\n",
            "        [-2.0377,  0.4276,  1.4773],\n",
            "        [-1.7822,  1.7588, -0.1738],\n",
            "        [-2.1666,  1.4898,  0.3832],\n",
            "        [-1.4473,  1.4518, -0.3012],\n",
            "        [-1.7606,  0.2567,  1.4162],\n",
            "        [-1.8178,  1.8971, -0.2399],\n",
            "        [-1.9810,  1.7994, -0.2907],\n",
            "        [-0.5045,  0.1949, -0.0131],\n",
            "        [-2.1901,  0.5085,  1.3893],\n",
            "        [-1.9178,  1.8767, -0.3194],\n",
            "        [ 0.3325,  0.0888, -1.0134],\n",
            "        [-2.0899,  2.0702, -0.3145],\n",
            "        [-1.9362,  1.7713, -0.2886],\n",
            "        [-2.0289,  2.0896, -0.1923]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9141,  1.8931, -0.3712],\n",
            "        [-1.8635,  1.8140, -0.2104],\n",
            "        [-2.0377,  0.4276,  1.4773],\n",
            "        [-1.7822,  1.7588, -0.1738],\n",
            "        [-2.1666,  1.4898,  0.3832],\n",
            "        [-1.4473,  1.4518, -0.3012],\n",
            "        [-1.7606,  0.2567,  1.4162],\n",
            "        [-1.8178,  1.8971, -0.2399],\n",
            "        [-1.9810,  1.7994, -0.2907],\n",
            "        [-0.5045,  0.1949, -0.0131],\n",
            "        [-2.1901,  0.5085,  1.3893],\n",
            "        [-1.9178,  1.8767, -0.3194],\n",
            "        [ 0.3325,  0.0888, -1.0134],\n",
            "        [-2.0899,  2.0702, -0.3145],\n",
            "        [-1.9362,  1.7713, -0.2886],\n",
            "        [-2.0289,  2.0896, -0.1923]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9805,  1.8570, -0.4737],\n",
            "        [-1.9727,  1.5154,  0.1020],\n",
            "        [-1.8098,  1.8231, -0.3744],\n",
            "        [-1.9216,  0.4555,  1.4634],\n",
            "        [-0.5851,  0.8404, -0.7767],\n",
            "        [-0.8561,  1.0293, -0.5875],\n",
            "        [-0.3291,  0.6837, -0.7065],\n",
            "        [ 0.4691,  0.1638, -1.0170],\n",
            "        [-0.1806,  0.6156, -1.0056],\n",
            "        [-1.7026,  1.8552, -0.2929],\n",
            "        [-1.5901,  2.0216, -0.5086],\n",
            "        [-1.8864,  2.1256, -0.4050],\n",
            "        [-2.1121,  0.3714,  1.4189],\n",
            "        [ 0.2073, -0.0924, -0.6375],\n",
            "        [-1.7921,  0.2760,  1.3852],\n",
            "        [-1.9544,  0.3481,  1.4150]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9805,  1.8570, -0.4737],\n",
            "        [-1.9727,  1.5154,  0.1020],\n",
            "        [-1.8098,  1.8231, -0.3744],\n",
            "        [-1.9216,  0.4555,  1.4634],\n",
            "        [-0.5851,  0.8404, -0.7767],\n",
            "        [-0.8561,  1.0293, -0.5875],\n",
            "        [-0.3291,  0.6837, -0.7065],\n",
            "        [ 0.4691,  0.1638, -1.0170],\n",
            "        [-0.1806,  0.6156, -1.0056],\n",
            "        [-1.7026,  1.8552, -0.2929],\n",
            "        [-1.5901,  2.0216, -0.5086],\n",
            "        [-1.8864,  2.1256, -0.4050],\n",
            "        [-2.1121,  0.3714,  1.4189],\n",
            "        [ 0.2073, -0.0924, -0.6375],\n",
            "        [-1.7921,  0.2760,  1.3852],\n",
            "        [-1.9544,  0.3481,  1.4150]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9241,  0.4027,  1.5263],\n",
            "        [-1.8742,  1.9079, -0.1939],\n",
            "        [-1.7426,  1.7714, -0.3346],\n",
            "        [-1.7801,  0.5130,  1.3330],\n",
            "        [ 0.2786,  0.2294, -0.9422],\n",
            "        [-1.8964,  1.9165, -0.2669],\n",
            "        [-1.7824,  0.2587,  1.2647],\n",
            "        [-2.0393,  1.9211, -0.5050],\n",
            "        [-1.9107,  1.8595, -0.2695],\n",
            "        [-1.8851,  1.8378, -0.3746],\n",
            "        [-1.8386,  1.8103, -0.5183],\n",
            "        [-1.9675,  0.5749,  1.2974],\n",
            "        [-1.9410,  0.4312,  1.1316],\n",
            "        [-2.0653,  1.5586,  0.2462],\n",
            "        [-2.0699,  2.0555, -0.2966],\n",
            "        [-1.9651,  1.7558, -0.2267]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9241,  0.4027,  1.5263],\n",
            "        [-1.8742,  1.9079, -0.1939],\n",
            "        [-1.7426,  1.7714, -0.3346],\n",
            "        [-1.7801,  0.5130,  1.3330],\n",
            "        [ 0.2786,  0.2294, -0.9422],\n",
            "        [-1.8964,  1.9165, -0.2669],\n",
            "        [-1.7824,  0.2587,  1.2647],\n",
            "        [-2.0393,  1.9211, -0.5050],\n",
            "        [-1.9107,  1.8595, -0.2695],\n",
            "        [-1.8851,  1.8378, -0.3746],\n",
            "        [-1.8386,  1.8103, -0.5183],\n",
            "        [-1.9675,  0.5749,  1.2974],\n",
            "        [-1.9410,  0.4312,  1.1316],\n",
            "        [-2.0653,  1.5586,  0.2462],\n",
            "        [-2.0699,  2.0555, -0.2966],\n",
            "        [-1.9651,  1.7558, -0.2267]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9243e+00,  2.0201e+00, -2.7529e-04],\n",
            "        [ 4.0648e-01, -5.0526e-02, -1.0596e+00],\n",
            "        [-1.8586e+00,  2.0384e+00, -2.6743e-01],\n",
            "        [-1.9800e+00,  1.8505e+00, -2.5116e-01],\n",
            "        [-2.0362e+00,  1.7284e+00, -5.0376e-02],\n",
            "        [-1.8175e+00,  3.5106e-01,  1.2551e+00],\n",
            "        [-2.1393e+00,  1.4056e+00,  4.2152e-01],\n",
            "        [-1.8125e+00,  1.9345e+00, -1.4473e-01],\n",
            "        [-2.0293e+00,  1.9887e+00, -1.8726e-01],\n",
            "        [-1.8354e+00,  1.8500e+00, -4.7082e-01],\n",
            "        [-1.8494e+00,  6.7606e-01,  9.4084e-01],\n",
            "        [-1.6984e+00,  1.9940e-01,  1.5212e+00],\n",
            "        [-1.9689e+00,  1.7836e+00, -1.1533e-01],\n",
            "        [-1.9915e+00,  1.9471e+00, -2.1317e-01],\n",
            "        [ 4.6435e-01,  1.4673e-01, -9.4451e-01],\n",
            "        [-1.9004e+00,  1.8552e+00, -1.8060e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9243e+00,  2.0201e+00, -2.7529e-04],\n",
            "        [ 4.0648e-01, -5.0526e-02, -1.0596e+00],\n",
            "        [-1.8586e+00,  2.0384e+00, -2.6743e-01],\n",
            "        [-1.9800e+00,  1.8505e+00, -2.5116e-01],\n",
            "        [-2.0362e+00,  1.7284e+00, -5.0376e-02],\n",
            "        [-1.8175e+00,  3.5106e-01,  1.2551e+00],\n",
            "        [-2.1393e+00,  1.4056e+00,  4.2152e-01],\n",
            "        [-1.8125e+00,  1.9345e+00, -1.4473e-01],\n",
            "        [-2.0293e+00,  1.9887e+00, -1.8726e-01],\n",
            "        [-1.8354e+00,  1.8500e+00, -4.7082e-01],\n",
            "        [-1.8494e+00,  6.7606e-01,  9.4084e-01],\n",
            "        [-1.6984e+00,  1.9940e-01,  1.5212e+00],\n",
            "        [-1.9689e+00,  1.7836e+00, -1.1533e-01],\n",
            "        [-1.9915e+00,  1.9471e+00, -2.1317e-01],\n",
            "        [ 4.6435e-01,  1.4673e-01, -9.4451e-01],\n",
            "        [-1.9004e+00,  1.8552e+00, -1.8060e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.1257,  0.1098,  0.8949],\n",
            "        [ 0.5837, -0.0302, -0.9735],\n",
            "        [-1.8824,  1.7903, -0.0869],\n",
            "        [-1.8434,  1.9029, -0.3108],\n",
            "        [-1.8122,  1.8639, -0.4094],\n",
            "        [-2.0626,  2.0204, -0.0123],\n",
            "        [-1.7932,  1.9576, -0.1914],\n",
            "        [-0.5929,  0.6735, -0.6719],\n",
            "        [-1.6748,  1.9334, -0.3212],\n",
            "        [-1.9617,  0.1623,  1.4695],\n",
            "        [ 0.3704,  0.1782, -0.9683],\n",
            "        [-1.8042,  0.3497,  1.2515],\n",
            "        [-2.0689,  1.5474,  0.0419],\n",
            "        [-1.9449,  2.0767, -0.3605],\n",
            "        [-1.9201,  1.9172, -0.4271],\n",
            "        [-1.7930,  0.3201,  1.3503]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.1257,  0.1098,  0.8949],\n",
            "        [ 0.5837, -0.0302, -0.9735],\n",
            "        [-1.8824,  1.7903, -0.0869],\n",
            "        [-1.8434,  1.9029, -0.3108],\n",
            "        [-1.8122,  1.8639, -0.4094],\n",
            "        [-2.0626,  2.0204, -0.0123],\n",
            "        [-1.7932,  1.9576, -0.1914],\n",
            "        [-0.5929,  0.6735, -0.6719],\n",
            "        [-1.6748,  1.9334, -0.3212],\n",
            "        [-1.9617,  0.1623,  1.4695],\n",
            "        [ 0.3704,  0.1782, -0.9683],\n",
            "        [-1.8042,  0.3497,  1.2515],\n",
            "        [-2.0689,  1.5474,  0.0419],\n",
            "        [-1.9449,  2.0767, -0.3605],\n",
            "        [-1.9201,  1.9172, -0.4271],\n",
            "        [-1.7930,  0.3201,  1.3503]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5448,  0.0398, -1.0448],\n",
            "        [-1.8408,  1.6728, -0.1624],\n",
            "        [-1.8978,  1.7510, -0.2684],\n",
            "        [-1.9146,  1.9266, -0.4000],\n",
            "        [ 0.1302,  0.2405, -0.9285],\n",
            "        [ 0.4086,  0.1507, -0.8838],\n",
            "        [-1.8856,  1.9209, -0.1492],\n",
            "        [-1.8886,  0.5613,  1.2272],\n",
            "        [-1.9127,  1.9610, -0.0852],\n",
            "        [-2.0772,  1.8242,  0.0405],\n",
            "        [-1.9955,  1.1712,  0.6832],\n",
            "        [-1.8982,  0.4868,  1.4455],\n",
            "        [-1.8274,  1.6199, -0.2403],\n",
            "        [-2.2332,  1.2862,  0.7597],\n",
            "        [-2.1439,  1.9219,  0.0255],\n",
            "        [-1.9576,  1.9356, -0.3643]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.5448,  0.0398, -1.0448],\n",
            "        [-1.8408,  1.6728, -0.1624],\n",
            "        [-1.8978,  1.7510, -0.2684],\n",
            "        [-1.9146,  1.9266, -0.4000],\n",
            "        [ 0.1302,  0.2405, -0.9285],\n",
            "        [ 0.4086,  0.1507, -0.8838],\n",
            "        [-1.8856,  1.9209, -0.1492],\n",
            "        [-1.8886,  0.5613,  1.2272],\n",
            "        [-1.9127,  1.9610, -0.0852],\n",
            "        [-2.0772,  1.8242,  0.0405],\n",
            "        [-1.9955,  1.1712,  0.6832],\n",
            "        [-1.8982,  0.4868,  1.4455],\n",
            "        [-1.8274,  1.6199, -0.2403],\n",
            "        [-2.2332,  1.2862,  0.7597],\n",
            "        [-2.1439,  1.9219,  0.0255],\n",
            "        [-1.9576,  1.9356, -0.3643]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8640,  1.2299,  0.3200],\n",
            "        [-1.8810,  0.3233,  1.2943],\n",
            "        [-1.8304,  1.7377, -0.1373],\n",
            "        [-1.7617,  0.3743,  1.4807],\n",
            "        [-1.2315,  1.3688, -0.3494],\n",
            "        [-1.9624,  2.1003, -0.2370],\n",
            "        [-1.8036,  1.7458, -0.4931],\n",
            "        [-1.7048,  0.2904,  1.4768],\n",
            "        [-1.7456,  0.5240,  1.2298],\n",
            "        [-2.0045,  0.4477,  1.4150],\n",
            "        [ 0.5596, -0.0950, -1.0451],\n",
            "        [-1.8300,  2.1026, -0.1087],\n",
            "        [-1.8981,  1.6425, -0.2123],\n",
            "        [ 0.4997, -0.0036, -0.9776],\n",
            "        [-1.7197,  0.5221,  0.9168],\n",
            "        [-1.7409,  1.7883, -0.2240]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8640,  1.2299,  0.3200],\n",
            "        [-1.8810,  0.3233,  1.2943],\n",
            "        [-1.8304,  1.7377, -0.1373],\n",
            "        [-1.7617,  0.3743,  1.4807],\n",
            "        [-1.2315,  1.3688, -0.3494],\n",
            "        [-1.9624,  2.1003, -0.2370],\n",
            "        [-1.8036,  1.7458, -0.4931],\n",
            "        [-1.7048,  0.2904,  1.4768],\n",
            "        [-1.7456,  0.5240,  1.2298],\n",
            "        [-2.0045,  0.4477,  1.4150],\n",
            "        [ 0.5596, -0.0950, -1.0451],\n",
            "        [-1.8300,  2.1026, -0.1087],\n",
            "        [-1.8981,  1.6425, -0.2123],\n",
            "        [ 0.4997, -0.0036, -0.9776],\n",
            "        [-1.7197,  0.5221,  0.9168],\n",
            "        [-1.7409,  1.7883, -0.2240]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8518,  1.3228,  0.1262],\n",
            "        [-1.6766,  1.5529, -0.3146],\n",
            "        [-1.9349,  1.9016, -0.1118],\n",
            "        [-1.7460,  1.6945, -0.2453],\n",
            "        [-1.7687,  2.0455, -0.3749],\n",
            "        [-1.8829,  1.9734, -0.2627],\n",
            "        [-1.8540,  0.0973,  1.5106],\n",
            "        [-2.0682,  1.4571,  0.3379],\n",
            "        [-1.8894,  1.4579,  0.1122],\n",
            "        [-1.7971,  1.8817, -0.2816],\n",
            "        [ 0.5028, -0.0645, -1.0324],\n",
            "        [-1.5756,  1.8807, -0.3775],\n",
            "        [-1.7317,  1.9557, -0.1770],\n",
            "        [-1.8254,  1.7926, -0.1031],\n",
            "        [-1.7801,  1.8193, -0.2530],\n",
            "        [ 0.5585,  0.0309, -0.9428]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8518,  1.3228,  0.1262],\n",
            "        [-1.6766,  1.5529, -0.3146],\n",
            "        [-1.9349,  1.9016, -0.1118],\n",
            "        [-1.7460,  1.6945, -0.2453],\n",
            "        [-1.7687,  2.0455, -0.3749],\n",
            "        [-1.8829,  1.9734, -0.2627],\n",
            "        [-1.8540,  0.0973,  1.5106],\n",
            "        [-2.0682,  1.4571,  0.3379],\n",
            "        [-1.8894,  1.4579,  0.1122],\n",
            "        [-1.7971,  1.8817, -0.2816],\n",
            "        [ 0.5028, -0.0645, -1.0324],\n",
            "        [-1.5756,  1.8807, -0.3775],\n",
            "        [-1.7317,  1.9557, -0.1770],\n",
            "        [-1.8254,  1.7926, -0.1031],\n",
            "        [-1.7801,  1.8193, -0.2530],\n",
            "        [ 0.5585,  0.0309, -0.9428]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.4165, -0.0663, -0.8988],\n",
            "        [-1.7113,  1.6931,  0.0357],\n",
            "        [-1.9683,  0.4164,  1.2978],\n",
            "        [-1.7403,  1.9792, -0.1809],\n",
            "        [-1.6791,  1.6203, -0.4058],\n",
            "        [-1.6609,  1.9044, -0.2626],\n",
            "        [-2.0157,  1.9090, -0.2034],\n",
            "        [-1.5206,  1.9431, -0.3505],\n",
            "        [ 0.5468, -0.2714, -0.8770],\n",
            "        [-1.8908,  1.7013, -0.2138],\n",
            "        [-1.9510,  1.8867, -0.2171],\n",
            "        [-1.9417,  0.3516,  1.5124],\n",
            "        [-1.6584,  1.6847, -0.2954],\n",
            "        [-1.9930,  1.9943, -0.3060],\n",
            "        [-1.6656,  1.8658, -0.1221],\n",
            "        [-1.8835,  0.2353,  1.5162]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.4165, -0.0663, -0.8988],\n",
            "        [-1.7113,  1.6931,  0.0357],\n",
            "        [-1.9683,  0.4164,  1.2978],\n",
            "        [-1.7403,  1.9792, -0.1809],\n",
            "        [-1.6791,  1.6203, -0.4058],\n",
            "        [-1.6609,  1.9044, -0.2626],\n",
            "        [-2.0157,  1.9090, -0.2034],\n",
            "        [-1.5206,  1.9431, -0.3505],\n",
            "        [ 0.5468, -0.2714, -0.8770],\n",
            "        [-1.8908,  1.7013, -0.2138],\n",
            "        [-1.9510,  1.8867, -0.2171],\n",
            "        [-1.9417,  0.3516,  1.5124],\n",
            "        [-1.6584,  1.6847, -0.2954],\n",
            "        [-1.9930,  1.9943, -0.3060],\n",
            "        [-1.6656,  1.8658, -0.1221],\n",
            "        [-1.8835,  0.2353,  1.5162]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0054,  1.8951, -0.4050],\n",
            "        [-1.5630,  1.6334, -0.2437],\n",
            "        [-1.8749,  1.8470, -0.2128],\n",
            "        [ 0.5250, -0.1564, -0.9510],\n",
            "        [-1.8374,  1.4756,  0.0801],\n",
            "        [-1.6833,  1.7356, -0.2341],\n",
            "        [-1.4137,  1.4736, -0.0405],\n",
            "        [-1.8965,  0.7879,  0.6743],\n",
            "        [-1.8199,  0.2572,  1.5067],\n",
            "        [-1.7111,  1.9917, -0.3263],\n",
            "        [-1.7870,  0.6871,  1.0470],\n",
            "        [-1.8504,  2.1161, -0.4138],\n",
            "        [-2.0856,  1.2355,  0.4115],\n",
            "        [-2.1256,  2.1089, -0.2169],\n",
            "        [-1.5461,  1.7565, -0.3036],\n",
            "        [ 0.0480,  0.0840, -0.4070]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0054,  1.8951, -0.4050],\n",
            "        [-1.5630,  1.6334, -0.2437],\n",
            "        [-1.8749,  1.8470, -0.2128],\n",
            "        [ 0.5250, -0.1564, -0.9510],\n",
            "        [-1.8374,  1.4756,  0.0801],\n",
            "        [-1.6833,  1.7356, -0.2341],\n",
            "        [-1.4137,  1.4736, -0.0405],\n",
            "        [-1.8965,  0.7879,  0.6743],\n",
            "        [-1.8199,  0.2572,  1.5067],\n",
            "        [-1.7111,  1.9917, -0.3263],\n",
            "        [-1.7870,  0.6871,  1.0470],\n",
            "        [-1.8504,  2.1161, -0.4138],\n",
            "        [-2.0856,  1.2355,  0.4115],\n",
            "        [-2.1256,  2.1089, -0.2169],\n",
            "        [-1.5461,  1.7565, -0.3036],\n",
            "        [ 0.0480,  0.0840, -0.4070]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8777,  2.0038, -0.3692],\n",
            "        [-1.6344,  1.7876, -0.2548],\n",
            "        [-1.9122,  2.0029, -0.1439],\n",
            "        [-1.8236,  1.8698, -0.4406],\n",
            "        [-1.8161,  2.0304, -0.2420],\n",
            "        [-0.2041,  0.8572, -0.9469],\n",
            "        [-1.9374,  1.8808, -0.0437],\n",
            "        [-1.8660,  0.5609,  1.1173],\n",
            "        [-1.9835,  0.3973,  1.5065],\n",
            "        [ 0.2318, -0.1448, -0.6571],\n",
            "        [-1.5929,  1.8712,  0.0383],\n",
            "        [ 0.0950,  0.1611, -0.6625],\n",
            "        [-1.7173,  1.9023, -0.3754],\n",
            "        [-1.7379,  1.8014, -0.1776],\n",
            "        [-1.5227,  1.7978, -0.2974],\n",
            "        [-1.6687,  1.9548, -0.2660]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8777,  2.0038, -0.3692],\n",
            "        [-1.6344,  1.7876, -0.2548],\n",
            "        [-1.9122,  2.0029, -0.1439],\n",
            "        [-1.8236,  1.8698, -0.4406],\n",
            "        [-1.8161,  2.0304, -0.2420],\n",
            "        [-0.2041,  0.8572, -0.9469],\n",
            "        [-1.9374,  1.8808, -0.0437],\n",
            "        [-1.8660,  0.5609,  1.1173],\n",
            "        [-1.9835,  0.3973,  1.5065],\n",
            "        [ 0.2318, -0.1448, -0.6571],\n",
            "        [-1.5929,  1.8712,  0.0383],\n",
            "        [ 0.0950,  0.1611, -0.6625],\n",
            "        [-1.7173,  1.9023, -0.3754],\n",
            "        [-1.7379,  1.8014, -0.1776],\n",
            "        [-1.5227,  1.7978, -0.2974],\n",
            "        [-1.6687,  1.9548, -0.2660]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5635,  1.6368, -0.0535],\n",
            "        [-1.7626,  1.5450,  0.0491],\n",
            "        [-1.7770,  1.7240, -0.2160],\n",
            "        [-1.8965,  0.2247,  1.4817],\n",
            "        [ 0.2327,  0.1050, -0.7355],\n",
            "        [-1.6629,  1.8595, -0.3507],\n",
            "        [-1.7000,  0.4515,  1.2495],\n",
            "        [-1.6927,  0.0903,  1.3636],\n",
            "        [-2.0845,  0.3059,  1.5897],\n",
            "        [-1.9191,  1.8945, -0.2594],\n",
            "        [-1.9521,  1.3825,  0.2099],\n",
            "        [-2.0381,  0.5539,  1.2530],\n",
            "        [-1.8148,  1.8843,  0.0716],\n",
            "        [-1.7066,  1.7892, -0.3691],\n",
            "        [-1.9414,  2.2226, -0.3286],\n",
            "        [-1.8089,  0.4224,  1.4032]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5635,  1.6368, -0.0535],\n",
            "        [-1.7626,  1.5450,  0.0491],\n",
            "        [-1.7770,  1.7240, -0.2160],\n",
            "        [-1.8965,  0.2247,  1.4817],\n",
            "        [ 0.2327,  0.1050, -0.7355],\n",
            "        [-1.6629,  1.8595, -0.3507],\n",
            "        [-1.7000,  0.4515,  1.2495],\n",
            "        [-1.6927,  0.0903,  1.3636],\n",
            "        [-2.0845,  0.3059,  1.5897],\n",
            "        [-1.9191,  1.8945, -0.2594],\n",
            "        [-1.9521,  1.3825,  0.2099],\n",
            "        [-2.0381,  0.5539,  1.2530],\n",
            "        [-1.8148,  1.8843,  0.0716],\n",
            "        [-1.7066,  1.7892, -0.3691],\n",
            "        [-1.9414,  2.2226, -0.3286],\n",
            "        [-1.8089,  0.4224,  1.4032]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8081,  1.6825, -0.4677],\n",
            "        [-1.7754,  1.9143, -0.1710],\n",
            "        [-1.6164,  1.7248, -0.5588],\n",
            "        [-0.9869,  1.0634, -0.5330],\n",
            "        [-0.0692, -0.1453, -0.1931],\n",
            "        [-1.3699,  1.3482, -0.5587],\n",
            "        [-1.7993,  1.7925, -0.2658],\n",
            "        [-1.6448,  1.7564, -0.2158],\n",
            "        [-1.2564,  1.8014, -0.3753],\n",
            "        [-0.2458, -0.0686, -0.2005],\n",
            "        [ 0.0464,  0.2695, -0.9868],\n",
            "        [-1.4481,  1.7860, -0.2710],\n",
            "        [-1.8140,  1.7876, -0.1818],\n",
            "        [-1.7617,  1.9273, -0.2327],\n",
            "        [-1.8116,  0.3227,  1.4608],\n",
            "        [-0.5238,  0.5357, -0.5402]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8081,  1.6825, -0.4677],\n",
            "        [-1.7754,  1.9143, -0.1710],\n",
            "        [-1.6164,  1.7248, -0.5588],\n",
            "        [-0.9869,  1.0634, -0.5330],\n",
            "        [-0.0692, -0.1453, -0.1931],\n",
            "        [-1.3699,  1.3482, -0.5587],\n",
            "        [-1.7993,  1.7925, -0.2658],\n",
            "        [-1.6448,  1.7564, -0.2158],\n",
            "        [-1.2564,  1.8014, -0.3753],\n",
            "        [-0.2458, -0.0686, -0.2005],\n",
            "        [ 0.0464,  0.2695, -0.9868],\n",
            "        [-1.4481,  1.7860, -0.2710],\n",
            "        [-1.8140,  1.7876, -0.1818],\n",
            "        [-1.7617,  1.9273, -0.2327],\n",
            "        [-1.8116,  0.3227,  1.4608],\n",
            "        [-0.5238,  0.5357, -0.5402]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5765,  1.8257, -0.2812],\n",
            "        [-1.7000,  0.9791,  0.7323],\n",
            "        [ 0.3478, -0.0053, -0.8325],\n",
            "        [ 0.2581,  0.0240, -0.7967],\n",
            "        [-1.8627,  1.5502, -0.1767],\n",
            "        [-1.8549,  0.4450,  1.2964],\n",
            "        [-1.5620,  1.9172, -0.3785],\n",
            "        [-1.6410,  0.2102,  1.1755],\n",
            "        [-1.5910,  0.2007,  1.2438],\n",
            "        [-1.6445,  1.8768, -0.3851],\n",
            "        [-0.6337,  0.7073, -0.5349],\n",
            "        [-2.0221,  1.0691,  0.9594],\n",
            "        [-1.7770,  1.9053, -0.2010],\n",
            "        [-1.8042,  1.7516, -0.2204],\n",
            "        [-1.7916,  1.7003, -0.1132],\n",
            "        [-1.7869,  1.9354, -0.1854]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5765,  1.8257, -0.2812],\n",
            "        [-1.7000,  0.9791,  0.7323],\n",
            "        [ 0.3478, -0.0053, -0.8325],\n",
            "        [ 0.2581,  0.0240, -0.7967],\n",
            "        [-1.8627,  1.5502, -0.1767],\n",
            "        [-1.8549,  0.4450,  1.2964],\n",
            "        [-1.5620,  1.9172, -0.3785],\n",
            "        [-1.6410,  0.2102,  1.1755],\n",
            "        [-1.5910,  0.2007,  1.2438],\n",
            "        [-1.6445,  1.8768, -0.3851],\n",
            "        [-0.6337,  0.7073, -0.5349],\n",
            "        [-2.0221,  1.0691,  0.9594],\n",
            "        [-1.7770,  1.9053, -0.2010],\n",
            "        [-1.8042,  1.7516, -0.2204],\n",
            "        [-1.7916,  1.7003, -0.1132],\n",
            "        [-1.7869,  1.9354, -0.1854]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9113,  0.8653,  0.8500],\n",
            "        [-1.6522,  1.9270, -0.2064],\n",
            "        [ 0.2280, -0.1352, -0.7509],\n",
            "        [-1.8885,  0.1862,  1.6399],\n",
            "        [-1.8280,  1.7995, -0.2533],\n",
            "        [-1.6264,  1.7702, -0.1850],\n",
            "        [-1.6838,  1.8982, -0.3620],\n",
            "        [ 0.5057, -0.0807, -0.9469],\n",
            "        [-1.6749,  0.2578,  1.3248],\n",
            "        [-1.6872,  2.0467, -0.4152],\n",
            "        [ 0.1351,  0.1251, -0.7983],\n",
            "        [-1.5435,  1.8246, -0.5342],\n",
            "        [-1.5603,  0.2137,  1.5283],\n",
            "        [-0.0807, -0.0175, -0.2453],\n",
            "        [-2.0480,  0.2550,  1.5550],\n",
            "        [-0.8634,  0.8532, -0.4634]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9113,  0.8653,  0.8500],\n",
            "        [-1.6522,  1.9270, -0.2064],\n",
            "        [ 0.2280, -0.1352, -0.7509],\n",
            "        [-1.8885,  0.1862,  1.6399],\n",
            "        [-1.8280,  1.7995, -0.2533],\n",
            "        [-1.6264,  1.7702, -0.1850],\n",
            "        [-1.6838,  1.8982, -0.3620],\n",
            "        [ 0.5057, -0.0807, -0.9469],\n",
            "        [-1.6749,  0.2578,  1.3248],\n",
            "        [-1.6872,  2.0467, -0.4152],\n",
            "        [ 0.1351,  0.1251, -0.7983],\n",
            "        [-1.5435,  1.8246, -0.5342],\n",
            "        [-1.5603,  0.2137,  1.5283],\n",
            "        [-0.0807, -0.0175, -0.2453],\n",
            "        [-2.0480,  0.2550,  1.5550],\n",
            "        [-0.8634,  0.8532, -0.4634]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9986,  1.8901, -0.2439],\n",
            "        [ 0.4474,  0.0083, -0.9990],\n",
            "        [-1.7054,  1.9615, -0.0752],\n",
            "        [-1.5785,  1.7429, -0.3943],\n",
            "        [-1.7895,  0.5200,  1.1424],\n",
            "        [-1.8384,  0.5740,  1.1498],\n",
            "        [-1.9059,  0.3417,  1.5416],\n",
            "        [ 0.3843, -0.1603, -0.8261],\n",
            "        [-1.4177,  1.6929, -0.4598],\n",
            "        [-1.7478,  0.1479,  1.5194],\n",
            "        [-1.9804,  1.7378,  0.0889],\n",
            "        [-1.8510,  0.2773,  1.4960],\n",
            "        [-1.8036,  1.7226, -0.3566],\n",
            "        [-1.8003,  1.8233, -0.4454],\n",
            "        [-1.3177,  1.2995, -0.3749],\n",
            "        [-0.6449,  0.3396,  0.0827]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9986,  1.8901, -0.2439],\n",
            "        [ 0.4474,  0.0083, -0.9990],\n",
            "        [-1.7054,  1.9615, -0.0752],\n",
            "        [-1.5785,  1.7429, -0.3943],\n",
            "        [-1.7895,  0.5200,  1.1424],\n",
            "        [-1.8384,  0.5740,  1.1498],\n",
            "        [-1.9059,  0.3417,  1.5416],\n",
            "        [ 0.3843, -0.1603, -0.8261],\n",
            "        [-1.4177,  1.6929, -0.4598],\n",
            "        [-1.7478,  0.1479,  1.5194],\n",
            "        [-1.9804,  1.7378,  0.0889],\n",
            "        [-1.8510,  0.2773,  1.4960],\n",
            "        [-1.8036,  1.7226, -0.3566],\n",
            "        [-1.8003,  1.8233, -0.4454],\n",
            "        [-1.3177,  1.2995, -0.3749],\n",
            "        [-0.6449,  0.3396,  0.0827]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6908,  0.2476,  1.4550],\n",
            "        [ 0.3098,  0.0437, -0.7120],\n",
            "        [-1.7697,  2.1408, -0.4486],\n",
            "        [-1.5123,  1.6572, -0.2119],\n",
            "        [-1.7888,  0.2376,  1.4349],\n",
            "        [ 0.6351, -0.1173, -0.8078],\n",
            "        [-1.9401,  1.9095, -0.2201],\n",
            "        [ 0.6017, -0.0946, -0.9212],\n",
            "        [-1.5365,  1.7988, -0.3663],\n",
            "        [-1.7551,  1.6908, -0.1747],\n",
            "        [ 0.2796, -0.1451, -0.6615],\n",
            "        [ 0.5248, -0.2091, -0.9052],\n",
            "        [-1.6538,  1.8013, -0.2508],\n",
            "        [-1.2451,  1.4365, -0.4796],\n",
            "        [-1.8377,  0.2458,  1.3187],\n",
            "        [ 0.0188,  0.5292, -0.9993]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6908,  0.2476,  1.4550],\n",
            "        [ 0.3098,  0.0437, -0.7120],\n",
            "        [-1.7697,  2.1408, -0.4486],\n",
            "        [-1.5123,  1.6572, -0.2119],\n",
            "        [-1.7888,  0.2376,  1.4349],\n",
            "        [ 0.6351, -0.1173, -0.8078],\n",
            "        [-1.9401,  1.9095, -0.2201],\n",
            "        [ 0.6017, -0.0946, -0.9212],\n",
            "        [-1.5365,  1.7988, -0.3663],\n",
            "        [-1.7551,  1.6908, -0.1747],\n",
            "        [ 0.2796, -0.1451, -0.6615],\n",
            "        [ 0.5248, -0.2091, -0.9052],\n",
            "        [-1.6538,  1.8013, -0.2508],\n",
            "        [-1.2451,  1.4365, -0.4796],\n",
            "        [-1.8377,  0.2458,  1.3187],\n",
            "        [ 0.0188,  0.5292, -0.9993]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9176,  0.4157,  1.3244],\n",
            "        [-1.6961,  1.9250, -0.3460],\n",
            "        [-1.9261,  1.2330,  0.3473],\n",
            "        [ 0.6255, -0.0943, -0.8555],\n",
            "        [-1.8558,  0.1309,  1.3447],\n",
            "        [-1.7706,  0.2386,  1.4970],\n",
            "        [-1.9559,  0.4360,  1.4775],\n",
            "        [-1.6340,  0.2624,  1.1994],\n",
            "        [ 0.6791, -0.0944, -0.9856],\n",
            "        [-1.6055,  0.2586,  1.2666],\n",
            "        [-1.7663,  1.4022,  0.3640],\n",
            "        [-1.7906,  0.9032,  0.5223],\n",
            "        [-1.7950,  1.6553, -0.2443],\n",
            "        [-1.6749,  1.7167, -0.4042],\n",
            "        [-1.7289,  1.8866, -0.3532],\n",
            "        [-1.8979,  0.5415,  1.4347]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9176,  0.4157,  1.3244],\n",
            "        [-1.6961,  1.9250, -0.3460],\n",
            "        [-1.9261,  1.2330,  0.3473],\n",
            "        [ 0.6255, -0.0943, -0.8555],\n",
            "        [-1.8558,  0.1309,  1.3447],\n",
            "        [-1.7706,  0.2386,  1.4970],\n",
            "        [-1.9559,  0.4360,  1.4775],\n",
            "        [-1.6340,  0.2624,  1.1994],\n",
            "        [ 0.6791, -0.0944, -0.9856],\n",
            "        [-1.6055,  0.2586,  1.2666],\n",
            "        [-1.7663,  1.4022,  0.3640],\n",
            "        [-1.7906,  0.9032,  0.5223],\n",
            "        [-1.7950,  1.6553, -0.2443],\n",
            "        [-1.6749,  1.7167, -0.4042],\n",
            "        [-1.7289,  1.8866, -0.3532],\n",
            "        [-1.8979,  0.5415,  1.4347]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-9.0192e-02, -1.8864e-01,  3.9097e-02],\n",
            "        [-1.8467e+00,  1.9717e+00, -3.6350e-01],\n",
            "        [ 4.9121e-01, -1.3774e-03, -8.9525e-01],\n",
            "        [-1.8257e+00,  3.7567e-01,  1.3213e+00],\n",
            "        [-2.0085e+00,  2.3903e-01,  1.5630e+00],\n",
            "        [ 4.5604e-01, -1.2460e-01, -9.1459e-01],\n",
            "        [-1.8392e+00,  1.0454e-01,  1.2805e+00],\n",
            "        [-1.8275e+00,  3.6443e-01,  1.5158e+00],\n",
            "        [-1.5396e+00,  1.6662e+00, -3.1371e-01],\n",
            "        [-1.6718e+00,  1.9670e+00, -2.2817e-01],\n",
            "        [-1.5411e+00,  1.6409e+00, -3.6564e-01],\n",
            "        [-2.0775e+00,  1.1086e+00,  7.6816e-01],\n",
            "        [-1.8350e+00,  3.6225e-01,  1.3617e+00],\n",
            "        [-1.7721e+00,  7.2044e-01,  1.2944e+00],\n",
            "        [-1.6895e+00,  1.8508e+00, -4.4230e-01],\n",
            "        [-1.6656e+00,  1.8983e+00, -5.1346e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-9.0192e-02, -1.8864e-01,  3.9097e-02],\n",
            "        [-1.8467e+00,  1.9717e+00, -3.6350e-01],\n",
            "        [ 4.9121e-01, -1.3774e-03, -8.9525e-01],\n",
            "        [-1.8257e+00,  3.7567e-01,  1.3213e+00],\n",
            "        [-2.0085e+00,  2.3903e-01,  1.5630e+00],\n",
            "        [ 4.5604e-01, -1.2460e-01, -9.1459e-01],\n",
            "        [-1.8392e+00,  1.0454e-01,  1.2805e+00],\n",
            "        [-1.8275e+00,  3.6443e-01,  1.5158e+00],\n",
            "        [-1.5396e+00,  1.6662e+00, -3.1371e-01],\n",
            "        [-1.6718e+00,  1.9670e+00, -2.2817e-01],\n",
            "        [-1.5411e+00,  1.6409e+00, -3.6564e-01],\n",
            "        [-2.0775e+00,  1.1086e+00,  7.6816e-01],\n",
            "        [-1.8350e+00,  3.6225e-01,  1.3617e+00],\n",
            "        [-1.7721e+00,  7.2044e-01,  1.2944e+00],\n",
            "        [-1.6895e+00,  1.8508e+00, -4.4230e-01],\n",
            "        [-1.6656e+00,  1.8983e+00, -5.1346e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6553,  1.8761, -0.4093],\n",
            "        [-1.5961,  1.9471, -0.4401],\n",
            "        [-1.9486,  0.4220,  1.3454],\n",
            "        [-1.7603,  1.9892, -0.5095],\n",
            "        [-1.5238,  1.8894, -0.4471],\n",
            "        [-1.8555,  0.9604,  0.4033],\n",
            "        [-1.5553,  1.7212, -0.4351],\n",
            "        [-1.6172,  1.8027, -0.5336],\n",
            "        [-1.6166,  0.3960,  1.4168],\n",
            "        [-1.5616,  1.8339, -0.4058],\n",
            "        [ 0.3414, -0.0161, -1.0107],\n",
            "        [-1.6652,  1.8368, -0.6011],\n",
            "        [-1.5833,  1.7595, -0.3358],\n",
            "        [-1.4749,  1.6805, -0.2851],\n",
            "        [-1.9707,  1.6377, -0.1873],\n",
            "        [-1.5992,  1.8843, -0.3625]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6553,  1.8761, -0.4093],\n",
            "        [-1.5961,  1.9471, -0.4401],\n",
            "        [-1.9486,  0.4220,  1.3454],\n",
            "        [-1.7603,  1.9892, -0.5095],\n",
            "        [-1.5238,  1.8894, -0.4471],\n",
            "        [-1.8555,  0.9604,  0.4033],\n",
            "        [-1.5553,  1.7212, -0.4351],\n",
            "        [-1.6172,  1.8027, -0.5336],\n",
            "        [-1.6166,  0.3960,  1.4168],\n",
            "        [-1.5616,  1.8339, -0.4058],\n",
            "        [ 0.3414, -0.0161, -1.0107],\n",
            "        [-1.6652,  1.8368, -0.6011],\n",
            "        [-1.5833,  1.7595, -0.3358],\n",
            "        [-1.4749,  1.6805, -0.2851],\n",
            "        [-1.9707,  1.6377, -0.1873],\n",
            "        [-1.5992,  1.8843, -0.3625]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7829,  0.3453,  1.3632],\n",
            "        [-1.6124,  1.7628, -0.3869],\n",
            "        [-1.7431,  1.9179, -0.3997],\n",
            "        [-1.3706,  2.0909, -0.4809],\n",
            "        [-1.7700,  0.6874,  1.2249],\n",
            "        [-1.5808,  2.0584, -0.7261],\n",
            "        [-1.5576,  2.0662, -0.4316],\n",
            "        [-1.9599,  0.5795,  1.2953],\n",
            "        [ 0.5884, -0.1724, -0.9025],\n",
            "        [-1.9261,  0.3291,  1.4519],\n",
            "        [ 0.6929, -0.1672, -0.9888],\n",
            "        [ 0.4310, -0.0362, -1.0855],\n",
            "        [-1.5043,  1.8061, -0.5258],\n",
            "        [-2.0878,  0.4580,  1.3084],\n",
            "        [ 0.6782, -0.0523, -1.1670],\n",
            "        [-1.9611,  0.8349,  1.0047]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7829,  0.3453,  1.3632],\n",
            "        [-1.6124,  1.7628, -0.3869],\n",
            "        [-1.7431,  1.9179, -0.3997],\n",
            "        [-1.3706,  2.0909, -0.4809],\n",
            "        [-1.7700,  0.6874,  1.2249],\n",
            "        [-1.5808,  2.0584, -0.7261],\n",
            "        [-1.5576,  2.0662, -0.4316],\n",
            "        [-1.9599,  0.5795,  1.2953],\n",
            "        [ 0.5884, -0.1724, -0.9025],\n",
            "        [-1.9261,  0.3291,  1.4519],\n",
            "        [ 0.6929, -0.1672, -0.9888],\n",
            "        [ 0.4310, -0.0362, -1.0855],\n",
            "        [-1.5043,  1.8061, -0.5258],\n",
            "        [-2.0878,  0.4580,  1.3084],\n",
            "        [ 0.6782, -0.0523, -1.1670],\n",
            "        [-1.9611,  0.8349,  1.0047]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4828,  1.7958, -0.4858],\n",
            "        [-1.9804,  0.7324,  1.1154],\n",
            "        [-0.1015,  0.4377, -1.0351],\n",
            "        [-1.9543,  0.2148,  1.3795],\n",
            "        [ 0.1906,  0.1145, -0.7890],\n",
            "        [-1.7350,  0.2511,  1.2975],\n",
            "        [-1.6873,  0.2630,  1.2614],\n",
            "        [-1.6125,  0.5315,  1.3713],\n",
            "        [-1.6962,  0.1307,  1.4448],\n",
            "        [-1.8933,  0.6149,  1.0297],\n",
            "        [-1.8371,  1.8588, -0.4204],\n",
            "        [-1.9266,  0.6818,  1.1070],\n",
            "        [-1.6976,  1.8800, -0.5658],\n",
            "        [-1.5370,  1.6804, -0.3072],\n",
            "        [-1.7356,  1.7382, -0.4146],\n",
            "        [-1.4735,  2.1960, -0.4363]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4828,  1.7958, -0.4858],\n",
            "        [-1.9804,  0.7324,  1.1154],\n",
            "        [-0.1015,  0.4377, -1.0351],\n",
            "        [-1.9543,  0.2148,  1.3795],\n",
            "        [ 0.1906,  0.1145, -0.7890],\n",
            "        [-1.7350,  0.2511,  1.2975],\n",
            "        [-1.6873,  0.2630,  1.2614],\n",
            "        [-1.6125,  0.5315,  1.3713],\n",
            "        [-1.6962,  0.1307,  1.4448],\n",
            "        [-1.8933,  0.6149,  1.0297],\n",
            "        [-1.8371,  1.8588, -0.4204],\n",
            "        [-1.9266,  0.6818,  1.1070],\n",
            "        [-1.6976,  1.8800, -0.5658],\n",
            "        [-1.5370,  1.6804, -0.3072],\n",
            "        [-1.7356,  1.7382, -0.4146],\n",
            "        [-1.4735,  2.1960, -0.4363]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4781,  1.5416, -0.5765],\n",
            "        [-2.0512,  0.3748,  1.3397],\n",
            "        [-1.5235,  1.7714, -0.7433],\n",
            "        [-1.3267,  1.6331, -0.5894],\n",
            "        [-1.5142,  1.8837, -0.6773],\n",
            "        [-1.7607,  0.4831,  1.4365],\n",
            "        [-1.6342,  1.9061, -0.4290],\n",
            "        [-1.6445,  1.8376, -0.5774],\n",
            "        [-2.0364,  1.0147,  0.8008],\n",
            "        [-1.1159,  1.5718, -0.6881],\n",
            "        [-1.6908,  1.9197, -0.4856],\n",
            "        [ 0.5012,  0.1002, -1.1451],\n",
            "        [-1.1392,  1.7726, -0.7823],\n",
            "        [-1.5046,  1.8416, -0.5531],\n",
            "        [ 0.6975, -0.0660, -1.0283],\n",
            "        [ 0.5413, -0.0532, -1.0712]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4781,  1.5416, -0.5765],\n",
            "        [-2.0512,  0.3748,  1.3397],\n",
            "        [-1.5235,  1.7714, -0.7433],\n",
            "        [-1.3267,  1.6331, -0.5894],\n",
            "        [-1.5142,  1.8837, -0.6773],\n",
            "        [-1.7607,  0.4831,  1.4365],\n",
            "        [-1.6342,  1.9061, -0.4290],\n",
            "        [-1.6445,  1.8376, -0.5774],\n",
            "        [-2.0364,  1.0147,  0.8008],\n",
            "        [-1.1159,  1.5718, -0.6881],\n",
            "        [-1.6908,  1.9197, -0.4856],\n",
            "        [ 0.5012,  0.1002, -1.1451],\n",
            "        [-1.1392,  1.7726, -0.7823],\n",
            "        [-1.5046,  1.8416, -0.5531],\n",
            "        [ 0.6975, -0.0660, -1.0283],\n",
            "        [ 0.5413, -0.0532, -1.0712]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6964,  2.1559, -0.5362],\n",
            "        [-2.0269,  0.2502,  1.4536],\n",
            "        [-1.7119,  0.2654,  1.3533],\n",
            "        [-1.8283,  1.9092, -0.3885],\n",
            "        [-1.7925,  1.7350, -0.1231],\n",
            "        [-1.6540,  0.5832,  1.2898],\n",
            "        [-1.9305,  0.4167,  1.2988],\n",
            "        [-1.8283,  1.2928,  0.1757],\n",
            "        [-1.5962,  1.7162, -0.4312],\n",
            "        [ 0.1404,  0.2479, -0.9114],\n",
            "        [-1.5803,  1.7965, -0.5828],\n",
            "        [-1.1443,  0.0174,  1.0156],\n",
            "        [-2.0185,  0.4732,  1.4286],\n",
            "        [-1.0335, -0.0742,  0.9296],\n",
            "        [-1.7262,  1.9899, -0.6430],\n",
            "        [-1.6649,  1.9758, -0.3696]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6964,  2.1559, -0.5362],\n",
            "        [-2.0269,  0.2502,  1.4536],\n",
            "        [-1.7119,  0.2654,  1.3533],\n",
            "        [-1.8283,  1.9092, -0.3885],\n",
            "        [-1.7925,  1.7350, -0.1231],\n",
            "        [-1.6540,  0.5832,  1.2898],\n",
            "        [-1.9305,  0.4167,  1.2988],\n",
            "        [-1.8283,  1.2928,  0.1757],\n",
            "        [-1.5962,  1.7162, -0.4312],\n",
            "        [ 0.1404,  0.2479, -0.9114],\n",
            "        [-1.5803,  1.7965, -0.5828],\n",
            "        [-1.1443,  0.0174,  1.0156],\n",
            "        [-2.0185,  0.4732,  1.4286],\n",
            "        [-1.0335, -0.0742,  0.9296],\n",
            "        [-1.7262,  1.9899, -0.6430],\n",
            "        [-1.6649,  1.9758, -0.3696]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.1243,  0.2845, -0.9506],\n",
            "        [ 0.1603,  0.3390, -0.9878],\n",
            "        [-1.4425,  1.9317, -0.7428],\n",
            "        [ 0.6675, -0.1631, -1.0427],\n",
            "        [-1.5933,  1.8357, -0.3120],\n",
            "        [-1.9145,  0.2218,  1.6238],\n",
            "        [-2.0420,  0.1885,  1.3824],\n",
            "        [ 0.7380, -0.0959, -1.0379],\n",
            "        [-1.5096,  1.9890, -0.4044],\n",
            "        [-2.0117,  1.3146,  0.3765],\n",
            "        [-1.5487,  2.1263, -0.4547],\n",
            "        [-1.5890,  1.7981, -0.6710],\n",
            "        [-1.6280,  1.8128, -0.4526],\n",
            "        [-1.3729,  1.6309, -0.5848],\n",
            "        [-1.4001,  1.9410, -0.6137],\n",
            "        [-1.6151,  1.9406, -0.5164]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.1243,  0.2845, -0.9506],\n",
            "        [ 0.1603,  0.3390, -0.9878],\n",
            "        [-1.4425,  1.9317, -0.7428],\n",
            "        [ 0.6675, -0.1631, -1.0427],\n",
            "        [-1.5933,  1.8357, -0.3120],\n",
            "        [-1.9145,  0.2218,  1.6238],\n",
            "        [-2.0420,  0.1885,  1.3824],\n",
            "        [ 0.7380, -0.0959, -1.0379],\n",
            "        [-1.5096,  1.9890, -0.4044],\n",
            "        [-2.0117,  1.3146,  0.3765],\n",
            "        [-1.5487,  2.1263, -0.4547],\n",
            "        [-1.5890,  1.7981, -0.6710],\n",
            "        [-1.6280,  1.8128, -0.4526],\n",
            "        [-1.3729,  1.6309, -0.5848],\n",
            "        [-1.4001,  1.9410, -0.6137],\n",
            "        [-1.6151,  1.9406, -0.5164]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4871,  1.8067, -0.4771],\n",
            "        [ 0.6400, -0.0952, -0.9927],\n",
            "        [-1.1784,  1.6652, -0.5936],\n",
            "        [-1.7198,  1.8186, -0.5578],\n",
            "        [-1.9666,  0.9179,  0.5163],\n",
            "        [-1.6522,  2.2597, -0.4910],\n",
            "        [-1.5979,  2.0284, -0.6220],\n",
            "        [-1.7944,  0.2423,  1.2788],\n",
            "        [-1.5534,  1.9507, -0.5762],\n",
            "        [-1.5656,  1.7974, -0.5083],\n",
            "        [-1.5436,  1.9331, -0.5331],\n",
            "        [-1.4636,  1.5160, -0.3918],\n",
            "        [-1.7627,  0.4554,  1.0055],\n",
            "        [ 0.2888,  0.2379, -1.2570],\n",
            "        [-1.5113,  1.9860, -0.7450],\n",
            "        [ 0.0042,  0.4544, -0.8858]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4871,  1.8067, -0.4771],\n",
            "        [ 0.6400, -0.0952, -0.9927],\n",
            "        [-1.1784,  1.6652, -0.5936],\n",
            "        [-1.7198,  1.8186, -0.5578],\n",
            "        [-1.9666,  0.9179,  0.5163],\n",
            "        [-1.6522,  2.2597, -0.4910],\n",
            "        [-1.5979,  2.0284, -0.6220],\n",
            "        [-1.7944,  0.2423,  1.2788],\n",
            "        [-1.5534,  1.9507, -0.5762],\n",
            "        [-1.5656,  1.7974, -0.5083],\n",
            "        [-1.5436,  1.9331, -0.5331],\n",
            "        [-1.4636,  1.5160, -0.3918],\n",
            "        [-1.7627,  0.4554,  1.0055],\n",
            "        [ 0.2888,  0.2379, -1.2570],\n",
            "        [-1.5113,  1.9860, -0.7450],\n",
            "        [ 0.0042,  0.4544, -0.8858]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4602,  2.0343, -0.5661],\n",
            "        [-1.5394,  1.9852, -0.4787],\n",
            "        [-1.7189,  1.8133, -0.6063],\n",
            "        [-1.6122,  1.9488, -0.5634],\n",
            "        [-1.8595,  0.4398,  1.1182],\n",
            "        [-1.6601,  1.9522, -0.4564],\n",
            "        [ 0.7043, -0.1336, -1.0651],\n",
            "        [-1.4555,  1.7703, -0.9262],\n",
            "        [-1.5211,  2.0829, -0.4495],\n",
            "        [-1.4670,  1.7205, -0.6459],\n",
            "        [-1.9944,  0.1889,  1.5283],\n",
            "        [-1.6616,  1.9839, -0.3790],\n",
            "        [-1.0410,  1.3509, -0.8393],\n",
            "        [-1.3425,  1.8525, -0.6707],\n",
            "        [-1.9598,  0.3372,  1.4370],\n",
            "        [-1.5520,  1.9015, -0.6225]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4602,  2.0343, -0.5661],\n",
            "        [-1.5394,  1.9852, -0.4787],\n",
            "        [-1.7189,  1.8133, -0.6063],\n",
            "        [-1.6122,  1.9488, -0.5634],\n",
            "        [-1.8595,  0.4398,  1.1182],\n",
            "        [-1.6601,  1.9522, -0.4564],\n",
            "        [ 0.7043, -0.1336, -1.0651],\n",
            "        [-1.4555,  1.7703, -0.9262],\n",
            "        [-1.5211,  2.0829, -0.4495],\n",
            "        [-1.4670,  1.7205, -0.6459],\n",
            "        [-1.9944,  0.1889,  1.5283],\n",
            "        [-1.6616,  1.9839, -0.3790],\n",
            "        [-1.0410,  1.3509, -0.8393],\n",
            "        [-1.3425,  1.8525, -0.6707],\n",
            "        [-1.9598,  0.3372,  1.4370],\n",
            "        [-1.5520,  1.9015, -0.6225]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5316,  1.9995, -0.5348],\n",
            "        [-1.8606,  0.4009,  1.2354],\n",
            "        [-1.3704,  1.9425, -0.4774],\n",
            "        [-1.7963,  0.1884,  1.4166],\n",
            "        [-1.4975,  1.9718, -0.5033],\n",
            "        [-1.3554,  1.8975, -0.6647],\n",
            "        [-0.5774,  0.0285,  0.2801],\n",
            "        [-1.5251,  2.0347, -0.5148],\n",
            "        [-1.8619,  0.7364,  1.2584],\n",
            "        [-1.3689,  1.7333, -0.8782],\n",
            "        [-1.6154,  1.7507, -0.5872],\n",
            "        [-1.4411,  1.9082, -0.5157],\n",
            "        [-1.6538,  1.9698, -0.3498],\n",
            "        [-1.6071,  1.7585, -0.3484],\n",
            "        [-1.3669,  1.8464, -0.5818],\n",
            "        [-1.6725,  1.7900, -0.6453]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5316,  1.9995, -0.5348],\n",
            "        [-1.8606,  0.4009,  1.2354],\n",
            "        [-1.3704,  1.9425, -0.4774],\n",
            "        [-1.7963,  0.1884,  1.4166],\n",
            "        [-1.4975,  1.9718, -0.5033],\n",
            "        [-1.3554,  1.8975, -0.6647],\n",
            "        [-0.5774,  0.0285,  0.2801],\n",
            "        [-1.5251,  2.0347, -0.5148],\n",
            "        [-1.8619,  0.7364,  1.2584],\n",
            "        [-1.3689,  1.7333, -0.8782],\n",
            "        [-1.6154,  1.7507, -0.5872],\n",
            "        [-1.4411,  1.9082, -0.5157],\n",
            "        [-1.6538,  1.9698, -0.3498],\n",
            "        [-1.6071,  1.7585, -0.3484],\n",
            "        [-1.3669,  1.8464, -0.5818],\n",
            "        [-1.6725,  1.7900, -0.6453]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5504,  1.9559, -0.6604],\n",
            "        [-1.2806,  1.8095, -0.7027],\n",
            "        [-1.7515,  0.2140,  1.5019],\n",
            "        [-1.8201,  0.1742,  1.2969],\n",
            "        [-2.2380,  0.3346,  1.6523],\n",
            "        [-1.3969,  1.6827, -0.5620],\n",
            "        [-2.0351,  0.6621,  1.2414],\n",
            "        [-1.4968,  1.7139, -0.6330],\n",
            "        [-1.2904,  1.7889, -0.7413],\n",
            "        [-1.6709,  0.3247,  1.1757],\n",
            "        [-1.2996,  1.7338, -0.6664],\n",
            "        [-1.5700,  1.8662, -0.5001],\n",
            "        [-1.2744,  1.6015, -0.5503],\n",
            "        [-1.5073,  1.9557, -0.5257],\n",
            "        [-1.4321,  1.8895, -0.5517],\n",
            "        [-1.5701,  1.9670, -0.4707]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5504,  1.9559, -0.6604],\n",
            "        [-1.2806,  1.8095, -0.7027],\n",
            "        [-1.7515,  0.2140,  1.5019],\n",
            "        [-1.8201,  0.1742,  1.2969],\n",
            "        [-2.2380,  0.3346,  1.6523],\n",
            "        [-1.3969,  1.6827, -0.5620],\n",
            "        [-2.0351,  0.6621,  1.2414],\n",
            "        [-1.4968,  1.7139, -0.6330],\n",
            "        [-1.2904,  1.7889, -0.7413],\n",
            "        [-1.6709,  0.3247,  1.1757],\n",
            "        [-1.2996,  1.7338, -0.6664],\n",
            "        [-1.5700,  1.8662, -0.5001],\n",
            "        [-1.2744,  1.6015, -0.5503],\n",
            "        [-1.5073,  1.9557, -0.5257],\n",
            "        [-1.4321,  1.8895, -0.5517],\n",
            "        [-1.5701,  1.9670, -0.4707]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1107,  0.7541,  0.9032],\n",
            "        [-1.5725,  1.7693, -0.3009],\n",
            "        [-1.2456,  1.7466, -0.2587],\n",
            "        [-1.3986,  1.8542, -0.6781],\n",
            "        [ 0.5896, -0.2421, -1.0433],\n",
            "        [-1.9607,  0.6040,  1.1283],\n",
            "        [-1.3977,  1.8123, -0.3277],\n",
            "        [-1.4611,  1.9896, -0.4640],\n",
            "        [-1.5515,  1.8097, -0.5666],\n",
            "        [-0.9426,  1.2910, -0.7472],\n",
            "        [-1.5396,  2.2202, -0.6763],\n",
            "        [-1.6943,  0.2186,  1.3435],\n",
            "        [-1.6034,  1.8496, -0.5071],\n",
            "        [-1.4922,  1.7107, -0.4702],\n",
            "        [-0.9955,  1.3244, -0.6015],\n",
            "        [ 0.5762, -0.0064, -0.9862]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1107,  0.7541,  0.9032],\n",
            "        [-1.5725,  1.7693, -0.3009],\n",
            "        [-1.2456,  1.7466, -0.2587],\n",
            "        [-1.3986,  1.8542, -0.6781],\n",
            "        [ 0.5896, -0.2421, -1.0433],\n",
            "        [-1.9607,  0.6040,  1.1283],\n",
            "        [-1.3977,  1.8123, -0.3277],\n",
            "        [-1.4611,  1.9896, -0.4640],\n",
            "        [-1.5515,  1.8097, -0.5666],\n",
            "        [-0.9426,  1.2910, -0.7472],\n",
            "        [-1.5396,  2.2202, -0.6763],\n",
            "        [-1.6943,  0.2186,  1.3435],\n",
            "        [-1.6034,  1.8496, -0.5071],\n",
            "        [-1.4922,  1.7107, -0.4702],\n",
            "        [-0.9955,  1.3244, -0.6015],\n",
            "        [ 0.5762, -0.0064, -0.9862]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4277,  1.6955, -0.5228],\n",
            "        [-1.5331,  1.8843, -0.3861],\n",
            "        [-1.9618,  0.5620,  1.2497],\n",
            "        [ 0.7276, -0.2360, -0.9927],\n",
            "        [-1.4198,  1.5218, -0.7435],\n",
            "        [-1.8211,  0.6153,  1.1392],\n",
            "        [-1.5430,  1.5612, -0.5177],\n",
            "        [-1.6793,  0.3901,  1.3988],\n",
            "        [ 0.5870, -0.2320, -1.1228],\n",
            "        [-1.2182,  1.5348, -0.3866],\n",
            "        [ 0.7051, -0.1133, -0.7675],\n",
            "        [-1.2342,  1.4084, -0.5264],\n",
            "        [-1.5681,  1.9724, -0.3387],\n",
            "        [-1.9018,  1.1384,  0.6627],\n",
            "        [-1.5666,  1.5453, -0.2164],\n",
            "        [-1.1865,  1.6887, -0.7650]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4277,  1.6955, -0.5228],\n",
            "        [-1.5331,  1.8843, -0.3861],\n",
            "        [-1.9618,  0.5620,  1.2497],\n",
            "        [ 0.7276, -0.2360, -0.9927],\n",
            "        [-1.4198,  1.5218, -0.7435],\n",
            "        [-1.8211,  0.6153,  1.1392],\n",
            "        [-1.5430,  1.5612, -0.5177],\n",
            "        [-1.6793,  0.3901,  1.3988],\n",
            "        [ 0.5870, -0.2320, -1.1228],\n",
            "        [-1.2182,  1.5348, -0.3866],\n",
            "        [ 0.7051, -0.1133, -0.7675],\n",
            "        [-1.2342,  1.4084, -0.5264],\n",
            "        [-1.5681,  1.9724, -0.3387],\n",
            "        [-1.9018,  1.1384,  0.6627],\n",
            "        [-1.5666,  1.5453, -0.2164],\n",
            "        [-1.1865,  1.6887, -0.7650]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.6836, -0.0335, -0.9997],\n",
            "        [-0.5459,  0.0864,  0.5291],\n",
            "        [-2.0522,  0.1867,  1.4373],\n",
            "        [-1.7678,  1.5657, -0.2154],\n",
            "        [-1.6855,  1.7425, -0.1267],\n",
            "        [-1.5123,  0.5061,  0.9716],\n",
            "        [-1.5642,  0.8790,  0.7507],\n",
            "        [-1.6581,  1.6855, -0.3167],\n",
            "        [-1.2908,  1.5837, -0.4276],\n",
            "        [-1.5972,  1.7026, -0.3393],\n",
            "        [ 0.6264, -0.0840, -0.8906],\n",
            "        [-2.0370,  0.2391,  1.6274],\n",
            "        [-1.1253,  1.6467, -0.6276],\n",
            "        [-1.5205,  1.9339, -0.7797],\n",
            "        [-1.6727,  1.7969, -0.4651],\n",
            "        [-1.3978,  1.5596, -0.3458]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.6836, -0.0335, -0.9997],\n",
            "        [-0.5459,  0.0864,  0.5291],\n",
            "        [-2.0522,  0.1867,  1.4373],\n",
            "        [-1.7678,  1.5657, -0.2154],\n",
            "        [-1.6855,  1.7425, -0.1267],\n",
            "        [-1.5123,  0.5061,  0.9716],\n",
            "        [-1.5642,  0.8790,  0.7507],\n",
            "        [-1.6581,  1.6855, -0.3167],\n",
            "        [-1.2908,  1.5837, -0.4276],\n",
            "        [-1.5972,  1.7026, -0.3393],\n",
            "        [ 0.6264, -0.0840, -0.8906],\n",
            "        [-2.0370,  0.2391,  1.6274],\n",
            "        [-1.1253,  1.6467, -0.6276],\n",
            "        [-1.5205,  1.9339, -0.7797],\n",
            "        [-1.6727,  1.7969, -0.4651],\n",
            "        [-1.3978,  1.5596, -0.3458]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8460,  0.2698,  1.4141],\n",
            "        [-1.3409,  1.6266, -0.6336],\n",
            "        [-1.7197,  1.2110,  0.3036],\n",
            "        [ 0.5367, -0.1700, -0.6313],\n",
            "        [-1.9630,  0.2902,  1.5499],\n",
            "        [-1.4621,  1.5395, -0.5295],\n",
            "        [-1.5067,  1.7500, -0.3390],\n",
            "        [-1.5406,  1.5841, -0.2806],\n",
            "        [-1.2605,  1.6773, -0.5092],\n",
            "        [-1.3035,  1.6245, -0.5641],\n",
            "        [-1.5280,  1.6336, -0.4062],\n",
            "        [-1.5767,  1.5025, -0.3611],\n",
            "        [-2.0935,  0.5304,  1.0619],\n",
            "        [-1.2439,  1.6771, -0.6385],\n",
            "        [-1.4383,  1.7111, -0.4163],\n",
            "        [-1.5622,  0.9784,  0.4099]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8460,  0.2698,  1.4141],\n",
            "        [-1.3409,  1.6266, -0.6336],\n",
            "        [-1.7197,  1.2110,  0.3036],\n",
            "        [ 0.5367, -0.1700, -0.6313],\n",
            "        [-1.9630,  0.2902,  1.5499],\n",
            "        [-1.4621,  1.5395, -0.5295],\n",
            "        [-1.5067,  1.7500, -0.3390],\n",
            "        [-1.5406,  1.5841, -0.2806],\n",
            "        [-1.2605,  1.6773, -0.5092],\n",
            "        [-1.3035,  1.6245, -0.5641],\n",
            "        [-1.5280,  1.6336, -0.4062],\n",
            "        [-1.5767,  1.5025, -0.3611],\n",
            "        [-2.0935,  0.5304,  1.0619],\n",
            "        [-1.2439,  1.6771, -0.6385],\n",
            "        [-1.4383,  1.7111, -0.4163],\n",
            "        [-1.5622,  0.9784,  0.4099]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7938,  0.5203,  1.0582],\n",
            "        [-1.4707,  1.5231, -0.3321],\n",
            "        [-1.3508,  1.7176, -0.4472],\n",
            "        [ 0.6184, -0.1347, -0.9303],\n",
            "        [-1.5010,  1.4899, -0.3346],\n",
            "        [-1.7599, -0.0168,  1.5377],\n",
            "        [-1.9505,  0.0324,  1.5617],\n",
            "        [-1.3421,  1.5764, -0.4654],\n",
            "        [-1.5057,  1.6440, -0.6031],\n",
            "        [-1.5520,  1.6862, -0.3517],\n",
            "        [-1.4091,  1.7201, -0.3736],\n",
            "        [-1.8819,  0.1395,  1.5575],\n",
            "        [-1.8992,  0.8251,  0.6545],\n",
            "        [-0.8972,  1.2695, -0.4538],\n",
            "        [-1.2789,  1.3435, -0.3662],\n",
            "        [-1.5769,  1.6996, -0.3163]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7938,  0.5203,  1.0582],\n",
            "        [-1.4707,  1.5231, -0.3321],\n",
            "        [-1.3508,  1.7176, -0.4472],\n",
            "        [ 0.6184, -0.1347, -0.9303],\n",
            "        [-1.5010,  1.4899, -0.3346],\n",
            "        [-1.7599, -0.0168,  1.5377],\n",
            "        [-1.9505,  0.0324,  1.5617],\n",
            "        [-1.3421,  1.5764, -0.4654],\n",
            "        [-1.5057,  1.6440, -0.6031],\n",
            "        [-1.5520,  1.6862, -0.3517],\n",
            "        [-1.4091,  1.7201, -0.3736],\n",
            "        [-1.8819,  0.1395,  1.5575],\n",
            "        [-1.8992,  0.8251,  0.6545],\n",
            "        [-0.8972,  1.2695, -0.4538],\n",
            "        [-1.2789,  1.3435, -0.3662],\n",
            "        [-1.5769,  1.6996, -0.3163]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4631,  0.3698,  0.7497],\n",
            "        [-1.2596,  0.8889, -0.2507],\n",
            "        [-1.6230,  1.7153, -0.4997],\n",
            "        [-1.2876,  1.6176, -0.3535],\n",
            "        [-1.7417,  0.3541,  1.1434],\n",
            "        [-1.5828,  1.7548, -0.4249],\n",
            "        [-1.3276,  1.3376, -0.6841],\n",
            "        [-1.4152,  1.4735, -0.3687],\n",
            "        [-1.7391,  0.0995,  1.5912],\n",
            "        [ 0.3726, -0.0978, -0.7852],\n",
            "        [-1.6536,  0.0602,  1.5493],\n",
            "        [-1.9765,  0.0790,  1.5668],\n",
            "        [-1.6214,  1.6637, -0.2430],\n",
            "        [-1.5382,  1.2180, -0.2516],\n",
            "        [-1.4350,  1.0619,  0.0723],\n",
            "        [-1.5040,  1.6532, -0.4395]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4631,  0.3698,  0.7497],\n",
            "        [-1.2596,  0.8889, -0.2507],\n",
            "        [-1.6230,  1.7153, -0.4997],\n",
            "        [-1.2876,  1.6176, -0.3535],\n",
            "        [-1.7417,  0.3541,  1.1434],\n",
            "        [-1.5828,  1.7548, -0.4249],\n",
            "        [-1.3276,  1.3376, -0.6841],\n",
            "        [-1.4152,  1.4735, -0.3687],\n",
            "        [-1.7391,  0.0995,  1.5912],\n",
            "        [ 0.3726, -0.0978, -0.7852],\n",
            "        [-1.6536,  0.0602,  1.5493],\n",
            "        [-1.9765,  0.0790,  1.5668],\n",
            "        [-1.6214,  1.6637, -0.2430],\n",
            "        [-1.5382,  1.2180, -0.2516],\n",
            "        [-1.4350,  1.0619,  0.0723],\n",
            "        [-1.5040,  1.6532, -0.4395]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.2027,  0.0922, -1.0046],\n",
            "        [-1.3861,  1.7909, -0.4858],\n",
            "        [-1.3352,  1.7089, -0.2611],\n",
            "        [-1.4123,  1.5336, -0.4730],\n",
            "        [-1.0647,  1.4455, -0.5111],\n",
            "        [-1.3803,  1.6191, -0.1057],\n",
            "        [-1.7958,  0.4110,  1.2085],\n",
            "        [-1.7018,  1.7287, -0.3204],\n",
            "        [-1.3208,  1.3386, -0.6313],\n",
            "        [-1.8668,  1.0357,  0.6939],\n",
            "        [-1.5077,  1.5127, -0.5303],\n",
            "        [-1.4895,  1.9115, -0.3114],\n",
            "        [-1.3675,  1.7271, -0.4222],\n",
            "        [-1.4343,  1.5498, -0.4200],\n",
            "        [-1.4427,  1.6278, -0.3950],\n",
            "        [-1.5802,  1.4427, -0.3539]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.2027,  0.0922, -1.0046],\n",
            "        [-1.3861,  1.7909, -0.4858],\n",
            "        [-1.3352,  1.7089, -0.2611],\n",
            "        [-1.4123,  1.5336, -0.4730],\n",
            "        [-1.0647,  1.4455, -0.5111],\n",
            "        [-1.3803,  1.6191, -0.1057],\n",
            "        [-1.7958,  0.4110,  1.2085],\n",
            "        [-1.7018,  1.7287, -0.3204],\n",
            "        [-1.3208,  1.3386, -0.6313],\n",
            "        [-1.8668,  1.0357,  0.6939],\n",
            "        [-1.5077,  1.5127, -0.5303],\n",
            "        [-1.4895,  1.9115, -0.3114],\n",
            "        [-1.3675,  1.7271, -0.4222],\n",
            "        [-1.4343,  1.5498, -0.4200],\n",
            "        [-1.4427,  1.6278, -0.3950],\n",
            "        [-1.5802,  1.4427, -0.3539]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5011,  1.7644, -0.4681],\n",
            "        [-1.4366,  1.6425, -0.4171],\n",
            "        [-1.6107,  1.5914, -0.2049],\n",
            "        [-1.3660,  1.5885, -0.3565],\n",
            "        [-1.2221,  1.3517, -0.4149],\n",
            "        [ 0.6198, -0.1453, -1.0200],\n",
            "        [-1.7958,  0.1628,  1.5523],\n",
            "        [-1.0352,  1.2981, -0.5388],\n",
            "        [ 0.5695, -0.2342, -0.9824],\n",
            "        [-1.3867,  1.7647, -0.4827],\n",
            "        [-1.3859,  1.5541, -0.4123],\n",
            "        [-1.4833,  1.7728, -0.4953],\n",
            "        [-1.7991,  1.5650, -0.3153],\n",
            "        [-1.7404,  0.1453,  1.4043],\n",
            "        [-1.6624,  1.3810, -0.3594],\n",
            "        [-1.9378,  0.1614,  1.4533]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5011,  1.7644, -0.4681],\n",
            "        [-1.4366,  1.6425, -0.4171],\n",
            "        [-1.6107,  1.5914, -0.2049],\n",
            "        [-1.3660,  1.5885, -0.3565],\n",
            "        [-1.2221,  1.3517, -0.4149],\n",
            "        [ 0.6198, -0.1453, -1.0200],\n",
            "        [-1.7958,  0.1628,  1.5523],\n",
            "        [-1.0352,  1.2981, -0.5388],\n",
            "        [ 0.5695, -0.2342, -0.9824],\n",
            "        [-1.3867,  1.7647, -0.4827],\n",
            "        [-1.3859,  1.5541, -0.4123],\n",
            "        [-1.4833,  1.7728, -0.4953],\n",
            "        [-1.7991,  1.5650, -0.3153],\n",
            "        [-1.7404,  0.1453,  1.4043],\n",
            "        [-1.6624,  1.3810, -0.3594],\n",
            "        [-1.9378,  0.1614,  1.4533]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.0266,  1.2278, -0.5685],\n",
            "        [-1.2289,  1.2303, -0.2410],\n",
            "        [-1.9696,  0.7536,  0.5961],\n",
            "        [-1.7633,  0.0288,  1.3696],\n",
            "        [-1.6604,  1.4936,  0.1741],\n",
            "        [ 0.5983, -0.0927, -0.8577],\n",
            "        [ 0.6687, -0.3180, -1.0288],\n",
            "        [-1.6461,  1.5647, -0.3293],\n",
            "        [-1.4266,  1.5834, -0.3965],\n",
            "        [-1.6118,  1.5512, -0.4619],\n",
            "        [-1.6664, -0.0600,  1.5299],\n",
            "        [ 0.3889, -0.0400, -0.9475],\n",
            "        [-1.2325,  1.5985, -0.4364],\n",
            "        [-1.6023,  1.2629,  0.0970],\n",
            "        [-1.8984,  0.1106,  1.3693],\n",
            "        [-1.6511,  1.5696, -0.1433]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.0266,  1.2278, -0.5685],\n",
            "        [-1.2289,  1.2303, -0.2410],\n",
            "        [-1.9696,  0.7536,  0.5961],\n",
            "        [-1.7633,  0.0288,  1.3696],\n",
            "        [-1.6604,  1.4936,  0.1741],\n",
            "        [ 0.5983, -0.0927, -0.8577],\n",
            "        [ 0.6687, -0.3180, -1.0288],\n",
            "        [-1.6461,  1.5647, -0.3293],\n",
            "        [-1.4266,  1.5834, -0.3965],\n",
            "        [-1.6118,  1.5512, -0.4619],\n",
            "        [-1.6664, -0.0600,  1.5299],\n",
            "        [ 0.3889, -0.0400, -0.9475],\n",
            "        [-1.2325,  1.5985, -0.4364],\n",
            "        [-1.6023,  1.2629,  0.0970],\n",
            "        [-1.8984,  0.1106,  1.3693],\n",
            "        [-1.6511,  1.5696, -0.1433]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5359,  1.4930, -0.2885],\n",
            "        [-1.7452,  1.2754, -0.0896],\n",
            "        [ 0.4857, -0.0256, -1.0623],\n",
            "        [-1.8966,  0.0337,  1.6270],\n",
            "        [-1.5174,  1.5216, -0.2373],\n",
            "        [-1.6931,  1.4604, -0.1243],\n",
            "        [-1.4577,  1.6078, -0.0807],\n",
            "        [-1.2655,  1.2049, -0.4688],\n",
            "        [-1.5377,  1.0889,  0.1840],\n",
            "        [-1.5028,  1.6695, -0.3068],\n",
            "        [-2.0396,  0.1633,  1.8461],\n",
            "        [-1.8389,  0.1442,  1.4587],\n",
            "        [-1.1731,  1.5212, -0.4052],\n",
            "        [-1.7428,  0.0661,  1.5917],\n",
            "        [-1.6029,  1.7827, -0.3283],\n",
            "        [-1.6521,  1.5976, -0.3155]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5359,  1.4930, -0.2885],\n",
            "        [-1.7452,  1.2754, -0.0896],\n",
            "        [ 0.4857, -0.0256, -1.0623],\n",
            "        [-1.8966,  0.0337,  1.6270],\n",
            "        [-1.5174,  1.5216, -0.2373],\n",
            "        [-1.6931,  1.4604, -0.1243],\n",
            "        [-1.4577,  1.6078, -0.0807],\n",
            "        [-1.2655,  1.2049, -0.4688],\n",
            "        [-1.5377,  1.0889,  0.1840],\n",
            "        [-1.5028,  1.6695, -0.3068],\n",
            "        [-2.0396,  0.1633,  1.8461],\n",
            "        [-1.8389,  0.1442,  1.4587],\n",
            "        [-1.1731,  1.5212, -0.4052],\n",
            "        [-1.7428,  0.0661,  1.5917],\n",
            "        [-1.6029,  1.7827, -0.3283],\n",
            "        [-1.6521,  1.5976, -0.3155]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.9774,  1.1985, -0.3307],\n",
            "        [-1.9082, -0.0305,  1.5502],\n",
            "        [-1.9258,  0.1996,  1.5931],\n",
            "        [-1.6509,  0.8745,  0.7009],\n",
            "        [-1.8073,  1.6377, -0.0614],\n",
            "        [-1.3432,  1.6849, -0.3895],\n",
            "        [-1.3780,  1.2580, -0.2515],\n",
            "        [-1.4896,  1.7920, -0.4362],\n",
            "        [-1.4005,  1.5798, -0.2223],\n",
            "        [-1.8642,  0.0202,  1.5417],\n",
            "        [-1.1802,  1.6094, -0.5512],\n",
            "        [-1.2839,  1.3985, -0.8567],\n",
            "        [-1.4117,  1.6224, -0.3257],\n",
            "        [-1.5844,  1.8185, -0.4506],\n",
            "        [-1.2371,  0.9872, -0.1560],\n",
            "        [-1.6566,  1.3506,  0.1629]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-0.9774,  1.1985, -0.3307],\n",
            "        [-1.9082, -0.0305,  1.5502],\n",
            "        [-1.9258,  0.1996,  1.5931],\n",
            "        [-1.6509,  0.8745,  0.7009],\n",
            "        [-1.8073,  1.6377, -0.0614],\n",
            "        [-1.3432,  1.6849, -0.3895],\n",
            "        [-1.3780,  1.2580, -0.2515],\n",
            "        [-1.4896,  1.7920, -0.4362],\n",
            "        [-1.4005,  1.5798, -0.2223],\n",
            "        [-1.8642,  0.0202,  1.5417],\n",
            "        [-1.1802,  1.6094, -0.5512],\n",
            "        [-1.2839,  1.3985, -0.8567],\n",
            "        [-1.4117,  1.6224, -0.3257],\n",
            "        [-1.5844,  1.8185, -0.4506],\n",
            "        [-1.2371,  0.9872, -0.1560],\n",
            "        [-1.6566,  1.3506,  0.1629]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5984, -0.2042, -0.9114],\n",
            "        [-1.9704, -0.0744,  1.5916],\n",
            "        [-1.6587,  0.1854,  1.5456],\n",
            "        [-2.3908,  0.3783,  1.4024],\n",
            "        [-1.8944,  0.2217,  1.6885],\n",
            "        [-1.2998,  1.6704, -0.6875],\n",
            "        [-1.7855,  1.6289, -0.3826],\n",
            "        [-1.3735,  1.6330, -0.4435],\n",
            "        [-1.7542,  0.3450,  1.4565],\n",
            "        [ 0.5670, -0.1573, -0.8802],\n",
            "        [-1.9298,  0.3248,  1.4286],\n",
            "        [-1.6652,  1.5455,  0.0402],\n",
            "        [-1.5259,  0.3482,  0.8457],\n",
            "        [-1.5956,  1.5147, -0.5915],\n",
            "        [-1.8300,  0.4984,  1.0924],\n",
            "        [-1.7097,  0.2654,  1.3818]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.5984, -0.2042, -0.9114],\n",
            "        [-1.9704, -0.0744,  1.5916],\n",
            "        [-1.6587,  0.1854,  1.5456],\n",
            "        [-2.3908,  0.3783,  1.4024],\n",
            "        [-1.8944,  0.2217,  1.6885],\n",
            "        [-1.2998,  1.6704, -0.6875],\n",
            "        [-1.7855,  1.6289, -0.3826],\n",
            "        [-1.3735,  1.6330, -0.4435],\n",
            "        [-1.7542,  0.3450,  1.4565],\n",
            "        [ 0.5670, -0.1573, -0.8802],\n",
            "        [-1.9298,  0.3248,  1.4286],\n",
            "        [-1.6652,  1.5455,  0.0402],\n",
            "        [-1.5259,  0.3482,  0.8457],\n",
            "        [-1.5956,  1.5147, -0.5915],\n",
            "        [-1.8300,  0.4984,  1.0924],\n",
            "        [-1.7097,  0.2654,  1.3818]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.2718, -0.0917,  0.0131],\n",
            "        [-2.0866,  0.3825,  1.3793],\n",
            "        [-1.6381,  1.5498,  0.2192],\n",
            "        [-1.4212,  1.4908, -0.3300],\n",
            "        [-1.5640,  1.6591, -0.4896],\n",
            "        [-1.6968,  1.6984, -0.2670],\n",
            "        [-1.5070,  1.6089, -0.4354],\n",
            "        [-2.1066,  0.1439,  1.3011],\n",
            "        [-1.5824,  1.4989, -0.1865],\n",
            "        [-1.4263,  1.4758, -0.1077],\n",
            "        [ 0.2541,  0.1852, -0.9216],\n",
            "        [-1.7732,  1.7051, -0.0126],\n",
            "        [-0.1251,  0.6436, -0.8905],\n",
            "        [-1.6186,  0.4789,  1.0381],\n",
            "        [-1.6639,  1.7927, -0.3864],\n",
            "        [-1.8207,  0.1310,  1.3350]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-0.2718, -0.0917,  0.0131],\n",
            "        [-2.0866,  0.3825,  1.3793],\n",
            "        [-1.6381,  1.5498,  0.2192],\n",
            "        [-1.4212,  1.4908, -0.3300],\n",
            "        [-1.5640,  1.6591, -0.4896],\n",
            "        [-1.6968,  1.6984, -0.2670],\n",
            "        [-1.5070,  1.6089, -0.4354],\n",
            "        [-2.1066,  0.1439,  1.3011],\n",
            "        [-1.5824,  1.4989, -0.1865],\n",
            "        [-1.4263,  1.4758, -0.1077],\n",
            "        [ 0.2541,  0.1852, -0.9216],\n",
            "        [-1.7732,  1.7051, -0.0126],\n",
            "        [-0.1251,  0.6436, -0.8905],\n",
            "        [-1.6186,  0.4789,  1.0381],\n",
            "        [-1.6639,  1.7927, -0.3864],\n",
            "        [-1.8207,  0.1310,  1.3350]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6527,  1.8988, -0.3722],\n",
            "        [-1.6108,  1.6965, -0.3344],\n",
            "        [-1.7274,  1.0561,  0.7153],\n",
            "        [-2.1973,  0.7409,  1.2353],\n",
            "        [-1.5991,  1.8405, -0.4064],\n",
            "        [-1.3063,  1.7953, -0.5863],\n",
            "        [-1.5627,  1.6342, -0.2224],\n",
            "        [-1.7027,  0.3472,  1.1719],\n",
            "        [ 0.6142, -0.1686, -1.0016],\n",
            "        [-1.4692,  1.6791, -0.5717],\n",
            "        [-1.9029,  0.4243,  1.2380],\n",
            "        [-1.6661,  1.6761, -0.1058],\n",
            "        [-1.6256,  1.7435, -0.2348],\n",
            "        [-1.9685,  0.2749,  1.5566],\n",
            "        [-0.0995,  0.5842, -0.7112],\n",
            "        [-1.9515,  0.5789,  1.2155]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6527,  1.8988, -0.3722],\n",
            "        [-1.6108,  1.6965, -0.3344],\n",
            "        [-1.7274,  1.0561,  0.7153],\n",
            "        [-2.1973,  0.7409,  1.2353],\n",
            "        [-1.5991,  1.8405, -0.4064],\n",
            "        [-1.3063,  1.7953, -0.5863],\n",
            "        [-1.5627,  1.6342, -0.2224],\n",
            "        [-1.7027,  0.3472,  1.1719],\n",
            "        [ 0.6142, -0.1686, -1.0016],\n",
            "        [-1.4692,  1.6791, -0.5717],\n",
            "        [-1.9029,  0.4243,  1.2380],\n",
            "        [-1.6661,  1.6761, -0.1058],\n",
            "        [-1.6256,  1.7435, -0.2348],\n",
            "        [-1.9685,  0.2749,  1.5566],\n",
            "        [-0.0995,  0.5842, -0.7112],\n",
            "        [-1.9515,  0.5789,  1.2155]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5753,  1.5919, -0.3470],\n",
            "        [-1.9287,  0.2991,  1.5794],\n",
            "        [ 0.7051, -0.0620, -0.9708],\n",
            "        [-1.8993,  0.6992,  1.3054],\n",
            "        [ 0.5905, -0.2382, -1.1695],\n",
            "        [ 0.5321, -0.0342, -1.0210],\n",
            "        [-1.7508,  1.8046, -0.3695],\n",
            "        [-1.8073,  0.3664,  1.5389],\n",
            "        [-1.6107,  0.0889,  1.4752],\n",
            "        [-1.7366,  1.8709, -0.4153],\n",
            "        [-1.6324,  1.6228, -0.2278],\n",
            "        [-1.8421,  0.2941,  1.4548],\n",
            "        [ 0.4606, -0.0716, -1.0681],\n",
            "        [-1.5917,  1.6135, -0.3281],\n",
            "        [-1.3715,  1.6926, -0.1184],\n",
            "        [-1.6574,  1.7950, -0.1488]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5753,  1.5919, -0.3470],\n",
            "        [-1.9287,  0.2991,  1.5794],\n",
            "        [ 0.7051, -0.0620, -0.9708],\n",
            "        [-1.8993,  0.6992,  1.3054],\n",
            "        [ 0.5905, -0.2382, -1.1695],\n",
            "        [ 0.5321, -0.0342, -1.0210],\n",
            "        [-1.7508,  1.8046, -0.3695],\n",
            "        [-1.8073,  0.3664,  1.5389],\n",
            "        [-1.6107,  0.0889,  1.4752],\n",
            "        [-1.7366,  1.8709, -0.4153],\n",
            "        [-1.6324,  1.6228, -0.2278],\n",
            "        [-1.8421,  0.2941,  1.4548],\n",
            "        [ 0.4606, -0.0716, -1.0681],\n",
            "        [-1.5917,  1.6135, -0.3281],\n",
            "        [-1.3715,  1.6926, -0.1184],\n",
            "        [-1.6574,  1.7950, -0.1488]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5904,  1.6026, -0.3453],\n",
            "        [-1.6720,  0.2103,  1.3394],\n",
            "        [-1.5424,  1.7124, -0.4197],\n",
            "        [-1.4412,  1.4953, -0.2314],\n",
            "        [-1.5529,  1.6576, -0.2414],\n",
            "        [-1.9824,  0.4372,  1.4038],\n",
            "        [-1.7128,  1.6640, -0.3327],\n",
            "        [-1.5315,  1.5956,  0.0156],\n",
            "        [-1.7267,  1.6995, -0.3062],\n",
            "        [-1.7847,  1.7900, -0.0903],\n",
            "        [-1.8678,  1.6795, -0.2344],\n",
            "        [ 0.6316, -0.0664, -0.9992],\n",
            "        [-1.7248,  1.8216, -0.4188],\n",
            "        [ 0.4941,  0.1548, -0.9808],\n",
            "        [-1.8783,  1.9020, -0.5593],\n",
            "        [-1.7526,  1.7582, -0.3414]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5904,  1.6026, -0.3453],\n",
            "        [-1.6720,  0.2103,  1.3394],\n",
            "        [-1.5424,  1.7124, -0.4197],\n",
            "        [-1.4412,  1.4953, -0.2314],\n",
            "        [-1.5529,  1.6576, -0.2414],\n",
            "        [-1.9824,  0.4372,  1.4038],\n",
            "        [-1.7128,  1.6640, -0.3327],\n",
            "        [-1.5315,  1.5956,  0.0156],\n",
            "        [-1.7267,  1.6995, -0.3062],\n",
            "        [-1.7847,  1.7900, -0.0903],\n",
            "        [-1.8678,  1.6795, -0.2344],\n",
            "        [ 0.6316, -0.0664, -0.9992],\n",
            "        [-1.7248,  1.8216, -0.4188],\n",
            "        [ 0.4941,  0.1548, -0.9808],\n",
            "        [-1.8783,  1.9020, -0.5593],\n",
            "        [-1.7526,  1.7582, -0.3414]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4705,  1.8632, -0.3427],\n",
            "        [-1.5807,  1.6545, -0.4404],\n",
            "        [-1.7260,  1.7518, -0.3072],\n",
            "        [-0.0900,  0.4747, -0.7164],\n",
            "        [-1.8752,  1.8228, -0.2371],\n",
            "        [-1.7877,  0.3039,  1.3044],\n",
            "        [-1.6640,  0.3890,  1.2999],\n",
            "        [-2.0168,  0.7112,  0.7501],\n",
            "        [-1.5551,  1.5331, -0.4438],\n",
            "        [-1.5536,  1.8043, -0.5052],\n",
            "        [-1.5446,  1.5750, -0.2240],\n",
            "        [-1.9769,  0.1804,  1.5225],\n",
            "        [-1.7943,  0.4715,  1.4298],\n",
            "        [-2.0415,  0.2763,  1.2905],\n",
            "        [ 0.4799, -0.0289, -0.9092],\n",
            "        [-1.5379,  1.6719, -0.3580]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4705,  1.8632, -0.3427],\n",
            "        [-1.5807,  1.6545, -0.4404],\n",
            "        [-1.7260,  1.7518, -0.3072],\n",
            "        [-0.0900,  0.4747, -0.7164],\n",
            "        [-1.8752,  1.8228, -0.2371],\n",
            "        [-1.7877,  0.3039,  1.3044],\n",
            "        [-1.6640,  0.3890,  1.2999],\n",
            "        [-2.0168,  0.7112,  0.7501],\n",
            "        [-1.5551,  1.5331, -0.4438],\n",
            "        [-1.5536,  1.8043, -0.5052],\n",
            "        [-1.5446,  1.5750, -0.2240],\n",
            "        [-1.9769,  0.1804,  1.5225],\n",
            "        [-1.7943,  0.4715,  1.4298],\n",
            "        [-2.0415,  0.2763,  1.2905],\n",
            "        [ 0.4799, -0.0289, -0.9092],\n",
            "        [-1.5379,  1.6719, -0.3580]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5908,  1.8622, -0.3754],\n",
            "        [-1.5765,  1.9586, -0.1905],\n",
            "        [-1.6290,  1.7030, -0.5104],\n",
            "        [-1.2783,  1.2663, -0.1975],\n",
            "        [-1.8536,  0.3330,  1.1624],\n",
            "        [ 0.6610, -0.1702, -1.0067],\n",
            "        [-1.8001,  1.8834, -0.2607],\n",
            "        [-1.6258,  0.0779,  1.0620],\n",
            "        [-1.5284,  1.3909, -0.0609],\n",
            "        [ 0.2122,  0.1825, -0.9090],\n",
            "        [-1.5827,  1.7312, -0.5191],\n",
            "        [-1.8353,  0.5358,  1.2073],\n",
            "        [-1.5530,  1.6898, -0.2679],\n",
            "        [ 0.6225, -0.0670, -0.9569],\n",
            "        [-1.8203,  0.4291,  1.3837],\n",
            "        [-1.9496,  1.2752,  0.0108]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5908,  1.8622, -0.3754],\n",
            "        [-1.5765,  1.9586, -0.1905],\n",
            "        [-1.6290,  1.7030, -0.5104],\n",
            "        [-1.2783,  1.2663, -0.1975],\n",
            "        [-1.8536,  0.3330,  1.1624],\n",
            "        [ 0.6610, -0.1702, -1.0067],\n",
            "        [-1.8001,  1.8834, -0.2607],\n",
            "        [-1.6258,  0.0779,  1.0620],\n",
            "        [-1.5284,  1.3909, -0.0609],\n",
            "        [ 0.2122,  0.1825, -0.9090],\n",
            "        [-1.5827,  1.7312, -0.5191],\n",
            "        [-1.8353,  0.5358,  1.2073],\n",
            "        [-1.5530,  1.6898, -0.2679],\n",
            "        [ 0.6225, -0.0670, -0.9569],\n",
            "        [-1.8203,  0.4291,  1.3837],\n",
            "        [-1.9496,  1.2752,  0.0108]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7652,  1.6823, -0.3007],\n",
            "        [ 0.7295, -0.0304, -0.9476],\n",
            "        [ 0.5511, -0.0242, -0.8950],\n",
            "        [-1.8886,  0.2856,  1.4000],\n",
            "        [-1.7292,  0.2434,  1.4292],\n",
            "        [-1.5560,  1.7354, -0.3468],\n",
            "        [-1.3621,  0.4228,  0.7244],\n",
            "        [-0.3478,  0.6715, -0.8331],\n",
            "        [-1.5982,  1.6701, -0.3963],\n",
            "        [ 0.5913, -0.0551, -0.9789],\n",
            "        [-1.7132,  1.9469, -0.3190],\n",
            "        [-1.4194,  0.9642,  0.0160],\n",
            "        [-1.8236,  0.5445,  1.0881],\n",
            "        [ 0.3002,  0.0724, -1.1330],\n",
            "        [-1.7939,  1.8332, -0.4893],\n",
            "        [-1.7143,  1.8388, -0.2548]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7652,  1.6823, -0.3007],\n",
            "        [ 0.7295, -0.0304, -0.9476],\n",
            "        [ 0.5511, -0.0242, -0.8950],\n",
            "        [-1.8886,  0.2856,  1.4000],\n",
            "        [-1.7292,  0.2434,  1.4292],\n",
            "        [-1.5560,  1.7354, -0.3468],\n",
            "        [-1.3621,  0.4228,  0.7244],\n",
            "        [-0.3478,  0.6715, -0.8331],\n",
            "        [-1.5982,  1.6701, -0.3963],\n",
            "        [ 0.5913, -0.0551, -0.9789],\n",
            "        [-1.7132,  1.9469, -0.3190],\n",
            "        [-1.4194,  0.9642,  0.0160],\n",
            "        [-1.8236,  0.5445,  1.0881],\n",
            "        [ 0.3002,  0.0724, -1.1330],\n",
            "        [-1.7939,  1.8332, -0.4893],\n",
            "        [-1.7143,  1.8388, -0.2548]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.6688, -0.0458, -1.1081],\n",
            "        [-1.4815,  1.7775, -0.3050],\n",
            "        [-1.6768,  1.5791, -0.1425],\n",
            "        [-1.7525,  1.7342, -0.2913],\n",
            "        [ 0.6500, -0.1521, -0.8573],\n",
            "        [-1.8324,  0.4200,  1.1154],\n",
            "        [-1.7712,  1.9482, -0.3266],\n",
            "        [-1.7463,  1.6192, -0.0486],\n",
            "        [-1.6389,  1.8073, -0.4070],\n",
            "        [-1.6331,  0.5900,  0.8006],\n",
            "        [ 0.6017, -0.0661, -0.9134],\n",
            "        [-1.7764,  1.7649, -0.4721],\n",
            "        [-1.6125,  1.8302, -0.4661],\n",
            "        [-1.5867,  1.9661, -0.3646],\n",
            "        [-1.7637,  1.7083, -0.0241],\n",
            "        [-1.8084,  0.6933,  0.9213]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.6688, -0.0458, -1.1081],\n",
            "        [-1.4815,  1.7775, -0.3050],\n",
            "        [-1.6768,  1.5791, -0.1425],\n",
            "        [-1.7525,  1.7342, -0.2913],\n",
            "        [ 0.6500, -0.1521, -0.8573],\n",
            "        [-1.8324,  0.4200,  1.1154],\n",
            "        [-1.7712,  1.9482, -0.3266],\n",
            "        [-1.7463,  1.6192, -0.0486],\n",
            "        [-1.6389,  1.8073, -0.4070],\n",
            "        [-1.6331,  0.5900,  0.8006],\n",
            "        [ 0.6017, -0.0661, -0.9134],\n",
            "        [-1.7764,  1.7649, -0.4721],\n",
            "        [-1.6125,  1.8302, -0.4661],\n",
            "        [-1.5867,  1.9661, -0.3646],\n",
            "        [-1.7637,  1.7083, -0.0241],\n",
            "        [-1.8084,  0.6933,  0.9213]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7269,  1.8875, -0.4091],\n",
            "        [-0.3605,  0.8021, -0.8920],\n",
            "        [ 0.2353,  0.2919, -0.7564],\n",
            "        [-1.9105,  1.9644, -0.3887],\n",
            "        [-1.6476,  1.6330, -0.1919],\n",
            "        [-1.5179,  1.6656, -0.4188],\n",
            "        [-1.6743,  1.8838, -0.2536],\n",
            "        [-1.6183,  1.9832, -0.4043],\n",
            "        [-1.7295,  1.6691, -0.7331],\n",
            "        [-1.7967,  1.9753, -0.5295],\n",
            "        [-1.6461,  0.2220,  1.2743],\n",
            "        [-1.6213,  1.6441, -0.0469],\n",
            "        [-1.5461,  1.6746, -0.3810],\n",
            "        [-1.5851,  0.0422,  1.3658],\n",
            "        [-1.8474,  1.8932, -0.4008],\n",
            "        [-1.4667,  1.7897, -0.2977]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7269,  1.8875, -0.4091],\n",
            "        [-0.3605,  0.8021, -0.8920],\n",
            "        [ 0.2353,  0.2919, -0.7564],\n",
            "        [-1.9105,  1.9644, -0.3887],\n",
            "        [-1.6476,  1.6330, -0.1919],\n",
            "        [-1.5179,  1.6656, -0.4188],\n",
            "        [-1.6743,  1.8838, -0.2536],\n",
            "        [-1.6183,  1.9832, -0.4043],\n",
            "        [-1.7295,  1.6691, -0.7331],\n",
            "        [-1.7967,  1.9753, -0.5295],\n",
            "        [-1.6461,  0.2220,  1.2743],\n",
            "        [-1.6213,  1.6441, -0.0469],\n",
            "        [-1.5461,  1.6746, -0.3810],\n",
            "        [-1.5851,  0.0422,  1.3658],\n",
            "        [-1.8474,  1.8932, -0.4008],\n",
            "        [-1.4667,  1.7897, -0.2977]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7694,  0.3766,  1.3129],\n",
            "        [-1.8961,  1.3396,  0.3743],\n",
            "        [-1.5768,  1.9346, -0.3470],\n",
            "        [-0.4516,  0.4301, -0.1245],\n",
            "        [-1.5034,  1.7692, -0.2533],\n",
            "        [ 0.5266,  0.1466, -0.9684],\n",
            "        [-1.5140,  1.8981, -0.5870],\n",
            "        [-1.5791,  0.1971,  1.0522],\n",
            "        [-1.5455,  0.7659,  0.5889],\n",
            "        [-1.8019,  0.6635,  1.0309],\n",
            "        [-1.6662,  1.6283, -0.3776],\n",
            "        [-1.8076,  1.5971,  0.1623],\n",
            "        [-1.6898,  1.5734, -0.3694],\n",
            "        [-1.5584,  0.1542,  0.9975],\n",
            "        [-1.8541,  1.9661, -0.2706],\n",
            "        [-1.6183,  0.2288,  1.1784]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7694,  0.3766,  1.3129],\n",
            "        [-1.8961,  1.3396,  0.3743],\n",
            "        [-1.5768,  1.9346, -0.3470],\n",
            "        [-0.4516,  0.4301, -0.1245],\n",
            "        [-1.5034,  1.7692, -0.2533],\n",
            "        [ 0.5266,  0.1466, -0.9684],\n",
            "        [-1.5140,  1.8981, -0.5870],\n",
            "        [-1.5791,  0.1971,  1.0522],\n",
            "        [-1.5455,  0.7659,  0.5889],\n",
            "        [-1.8019,  0.6635,  1.0309],\n",
            "        [-1.6662,  1.6283, -0.3776],\n",
            "        [-1.8076,  1.5971,  0.1623],\n",
            "        [-1.6898,  1.5734, -0.3694],\n",
            "        [-1.5584,  0.1542,  0.9975],\n",
            "        [-1.8541,  1.9661, -0.2706],\n",
            "        [-1.6183,  0.2288,  1.1784]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6900,  0.3371,  1.2815],\n",
            "        [-1.9261,  0.8159,  0.7435],\n",
            "        [-1.6045,  0.7663,  0.5138],\n",
            "        [-1.5067,  0.2615,  1.0794],\n",
            "        [-1.5304,  0.3808,  1.2986],\n",
            "        [-1.7000,  1.7639, -0.0310],\n",
            "        [-1.8483,  1.3212,  0.1753],\n",
            "        [-1.6315,  1.5986, -0.1736],\n",
            "        [-1.8157,  1.7521, -0.1005],\n",
            "        [-1.7193,  1.6844, -0.4083],\n",
            "        [-1.5445,  0.1870,  1.3575],\n",
            "        [-2.0432,  1.4816,  0.1328],\n",
            "        [-1.6614,  1.9138, -0.5506],\n",
            "        [-1.5042,  1.6607, -0.3198],\n",
            "        [-1.6838,  1.8228, -0.2694],\n",
            "        [-1.8405,  0.6152,  1.1892]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6900,  0.3371,  1.2815],\n",
            "        [-1.9261,  0.8159,  0.7435],\n",
            "        [-1.6045,  0.7663,  0.5138],\n",
            "        [-1.5067,  0.2615,  1.0794],\n",
            "        [-1.5304,  0.3808,  1.2986],\n",
            "        [-1.7000,  1.7639, -0.0310],\n",
            "        [-1.8483,  1.3212,  0.1753],\n",
            "        [-1.6315,  1.5986, -0.1736],\n",
            "        [-1.8157,  1.7521, -0.1005],\n",
            "        [-1.7193,  1.6844, -0.4083],\n",
            "        [-1.5445,  0.1870,  1.3575],\n",
            "        [-2.0432,  1.4816,  0.1328],\n",
            "        [-1.6614,  1.9138, -0.5506],\n",
            "        [-1.5042,  1.6607, -0.3198],\n",
            "        [-1.6838,  1.8228, -0.2694],\n",
            "        [-1.8405,  0.6152,  1.1892]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5960,  1.8744, -0.2667],\n",
            "        [-1.2183,  1.4037, -0.2962],\n",
            "        [-1.8017,  1.7048, -0.1935],\n",
            "        [-1.4963,  0.2456,  1.0822],\n",
            "        [-1.7256,  1.7706, -0.4663],\n",
            "        [-1.6970,  1.8942, -0.3300],\n",
            "        [-1.6192,  0.1870,  1.1355],\n",
            "        [-1.6949,  1.6736, -0.3787],\n",
            "        [-1.7211,  1.7254, -0.3436],\n",
            "        [-1.7626,  1.7002, -0.1029],\n",
            "        [-1.5900,  1.0375,  0.6037],\n",
            "        [-1.2332,  0.1896,  0.9287],\n",
            "        [-1.6258,  1.5614, -0.5203],\n",
            "        [-1.6720,  1.6674, -0.4245],\n",
            "        [-0.6651,  1.0302, -0.7870],\n",
            "        [ 0.3961,  0.2232, -0.9419]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5960,  1.8744, -0.2667],\n",
            "        [-1.2183,  1.4037, -0.2962],\n",
            "        [-1.8017,  1.7048, -0.1935],\n",
            "        [-1.4963,  0.2456,  1.0822],\n",
            "        [-1.7256,  1.7706, -0.4663],\n",
            "        [-1.6970,  1.8942, -0.3300],\n",
            "        [-1.6192,  0.1870,  1.1355],\n",
            "        [-1.6949,  1.6736, -0.3787],\n",
            "        [-1.7211,  1.7254, -0.3436],\n",
            "        [-1.7626,  1.7002, -0.1029],\n",
            "        [-1.5900,  1.0375,  0.6037],\n",
            "        [-1.2332,  0.1896,  0.9287],\n",
            "        [-1.6258,  1.5614, -0.5203],\n",
            "        [-1.6720,  1.6674, -0.4245],\n",
            "        [-0.6651,  1.0302, -0.7870],\n",
            "        [ 0.3961,  0.2232, -0.9419]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6348,  1.7146, -0.0274],\n",
            "        [-0.6267,  0.3351, -0.0459],\n",
            "        [ 0.4604,  0.2440, -1.1488],\n",
            "        [-1.3685,  0.2006,  1.2154],\n",
            "        [-1.7159,  1.6796, -0.4582],\n",
            "        [-1.8361,  1.8602, -0.1213],\n",
            "        [-1.5057,  1.5421, -0.0298],\n",
            "        [-1.6648,  1.6957, -0.1017],\n",
            "        [-1.7859,  0.5795,  1.0017],\n",
            "        [-1.4215,  1.5844, -0.3613],\n",
            "        [-1.8659,  1.3192,  0.5305],\n",
            "        [-1.6569,  1.6563, -0.3999],\n",
            "        [ 0.6247, -0.0773, -1.1961],\n",
            "        [ 0.5174,  0.0394, -0.8637],\n",
            "        [-1.6941,  0.5058,  1.0828],\n",
            "        [-1.6233,  1.1237,  0.5099]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6348,  1.7146, -0.0274],\n",
            "        [-0.6267,  0.3351, -0.0459],\n",
            "        [ 0.4604,  0.2440, -1.1488],\n",
            "        [-1.3685,  0.2006,  1.2154],\n",
            "        [-1.7159,  1.6796, -0.4582],\n",
            "        [-1.8361,  1.8602, -0.1213],\n",
            "        [-1.5057,  1.5421, -0.0298],\n",
            "        [-1.6648,  1.6957, -0.1017],\n",
            "        [-1.7859,  0.5795,  1.0017],\n",
            "        [-1.4215,  1.5844, -0.3613],\n",
            "        [-1.8659,  1.3192,  0.5305],\n",
            "        [-1.6569,  1.6563, -0.3999],\n",
            "        [ 0.6247, -0.0773, -1.1961],\n",
            "        [ 0.5174,  0.0394, -0.8637],\n",
            "        [-1.6941,  0.5058,  1.0828],\n",
            "        [-1.6233,  1.1237,  0.5099]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4448,  0.1487,  1.1634],\n",
            "        [-1.6787,  0.3040,  0.9905],\n",
            "        [-1.5594,  0.3308,  0.8515],\n",
            "        [-1.6461,  1.5714, -0.3130],\n",
            "        [-1.4789,  1.6253, -0.4473],\n",
            "        [-1.4878,  1.6445, -0.4260],\n",
            "        [-1.5000,  0.9964,  0.2860],\n",
            "        [ 0.5937,  0.0130, -1.0076],\n",
            "        [-1.7316,  1.6905, -0.2864],\n",
            "        [-1.5370,  1.4628,  0.1152],\n",
            "        [ 0.4922, -0.0418, -0.9172],\n",
            "        [-1.4844,  0.3627,  0.9908],\n",
            "        [-1.4602,  1.7543, -0.3979],\n",
            "        [-1.4721,  0.4359,  1.0118],\n",
            "        [-1.6573,  1.5585, -0.1363],\n",
            "        [-1.7792,  1.7464, -0.3287]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4448,  0.1487,  1.1634],\n",
            "        [-1.6787,  0.3040,  0.9905],\n",
            "        [-1.5594,  0.3308,  0.8515],\n",
            "        [-1.6461,  1.5714, -0.3130],\n",
            "        [-1.4789,  1.6253, -0.4473],\n",
            "        [-1.4878,  1.6445, -0.4260],\n",
            "        [-1.5000,  0.9964,  0.2860],\n",
            "        [ 0.5937,  0.0130, -1.0076],\n",
            "        [-1.7316,  1.6905, -0.2864],\n",
            "        [-1.5370,  1.4628,  0.1152],\n",
            "        [ 0.4922, -0.0418, -0.9172],\n",
            "        [-1.4844,  0.3627,  0.9908],\n",
            "        [-1.4602,  1.7543, -0.3979],\n",
            "        [-1.4721,  0.4359,  1.0118],\n",
            "        [-1.6573,  1.5585, -0.1363],\n",
            "        [-1.7792,  1.7464, -0.3287]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3471,  0.1170, -0.9647],\n",
            "        [-1.6264,  0.3735,  1.1964],\n",
            "        [-1.4290,  0.4286,  1.0558],\n",
            "        [ 0.5000,  0.1439, -1.1011],\n",
            "        [-1.6438,  1.8665, -0.3086],\n",
            "        [ 0.1827,  0.3169, -0.8351],\n",
            "        [-1.8890,  0.7749,  0.6123],\n",
            "        [-1.6767,  1.5628, -0.2041],\n",
            "        [-1.4672,  1.7445, -0.3222],\n",
            "        [-1.4328,  1.5076, -0.3981],\n",
            "        [-1.6713,  1.5354, -0.2951],\n",
            "        [-1.5674,  0.4086,  1.0326],\n",
            "        [-1.6388,  0.2560,  1.0937],\n",
            "        [-1.9343,  1.3217,  0.3733],\n",
            "        [-1.6573,  1.9229, -0.3677],\n",
            "        [-1.8724,  1.7934, -0.0407]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.3471,  0.1170, -0.9647],\n",
            "        [-1.6264,  0.3735,  1.1964],\n",
            "        [-1.4290,  0.4286,  1.0558],\n",
            "        [ 0.5000,  0.1439, -1.1011],\n",
            "        [-1.6438,  1.8665, -0.3086],\n",
            "        [ 0.1827,  0.3169, -0.8351],\n",
            "        [-1.8890,  0.7749,  0.6123],\n",
            "        [-1.6767,  1.5628, -0.2041],\n",
            "        [-1.4672,  1.7445, -0.3222],\n",
            "        [-1.4328,  1.5076, -0.3981],\n",
            "        [-1.6713,  1.5354, -0.2951],\n",
            "        [-1.5674,  0.4086,  1.0326],\n",
            "        [-1.6388,  0.2560,  1.0937],\n",
            "        [-1.9343,  1.3217,  0.3733],\n",
            "        [-1.6573,  1.9229, -0.3677],\n",
            "        [-1.8724,  1.7934, -0.0407]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7263,  1.8643, -0.2403],\n",
            "        [-1.7341,  1.6876, -0.3402],\n",
            "        [-1.5843,  1.5029, -0.3794],\n",
            "        [-1.4383,  1.7001, -0.2300],\n",
            "        [-1.4460,  1.6466, -0.3005],\n",
            "        [-1.6582,  1.7930, -0.1590],\n",
            "        [-1.3220,  1.6586, -0.3956],\n",
            "        [-1.5860,  1.9300, -0.2967],\n",
            "        [-1.5526,  1.4357, -0.1229],\n",
            "        [-1.5931,  1.5511, -0.1470],\n",
            "        [-1.4632,  1.8600, -0.4679],\n",
            "        [-1.5536,  1.5602, -0.3404],\n",
            "        [-1.6923,  1.6959, -0.1784],\n",
            "        [-1.5898,  1.4057, -0.2376],\n",
            "        [-1.7930,  1.1820,  0.3083],\n",
            "        [-1.7853,  1.6991,  0.0072]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7263,  1.8643, -0.2403],\n",
            "        [-1.7341,  1.6876, -0.3402],\n",
            "        [-1.5843,  1.5029, -0.3794],\n",
            "        [-1.4383,  1.7001, -0.2300],\n",
            "        [-1.4460,  1.6466, -0.3005],\n",
            "        [-1.6582,  1.7930, -0.1590],\n",
            "        [-1.3220,  1.6586, -0.3956],\n",
            "        [-1.5860,  1.9300, -0.2967],\n",
            "        [-1.5526,  1.4357, -0.1229],\n",
            "        [-1.5931,  1.5511, -0.1470],\n",
            "        [-1.4632,  1.8600, -0.4679],\n",
            "        [-1.5536,  1.5602, -0.3404],\n",
            "        [-1.6923,  1.6959, -0.1784],\n",
            "        [-1.5898,  1.4057, -0.2376],\n",
            "        [-1.7930,  1.1820,  0.3083],\n",
            "        [-1.7853,  1.6991,  0.0072]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7781,  1.6776, -0.3891],\n",
            "        [-1.6848,  0.9007,  0.5949],\n",
            "        [-1.6612,  1.7163, -0.1788],\n",
            "        [-1.6617,  1.7431, -0.2806],\n",
            "        [-1.5978,  1.6266, -0.0033],\n",
            "        [-1.7084,  1.8098, -0.2892],\n",
            "        [ 0.5929,  0.0727, -1.0570],\n",
            "        [-1.6752,  0.4400,  1.2325],\n",
            "        [-1.6331,  1.7308, -0.3018],\n",
            "        [-1.4294,  0.2760,  0.9524],\n",
            "        [-1.5105,  0.4527,  1.0807],\n",
            "        [ 0.8050,  0.0723, -1.0144],\n",
            "        [-1.6712,  0.4501,  0.8262],\n",
            "        [-1.7644,  1.5457, -0.2476],\n",
            "        [-1.5884,  1.2573, -0.3231],\n",
            "        [-1.5774,  1.7106, -0.3524]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7781,  1.6776, -0.3891],\n",
            "        [-1.6848,  0.9007,  0.5949],\n",
            "        [-1.6612,  1.7163, -0.1788],\n",
            "        [-1.6617,  1.7431, -0.2806],\n",
            "        [-1.5978,  1.6266, -0.0033],\n",
            "        [-1.7084,  1.8098, -0.2892],\n",
            "        [ 0.5929,  0.0727, -1.0570],\n",
            "        [-1.6752,  0.4400,  1.2325],\n",
            "        [-1.6331,  1.7308, -0.3018],\n",
            "        [-1.4294,  0.2760,  0.9524],\n",
            "        [-1.5105,  0.4527,  1.0807],\n",
            "        [ 0.8050,  0.0723, -1.0144],\n",
            "        [-1.6712,  0.4501,  0.8262],\n",
            "        [-1.7644,  1.5457, -0.2476],\n",
            "        [-1.5884,  1.2573, -0.3231],\n",
            "        [-1.5774,  1.7106, -0.3524]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3340,  0.2475,  1.0498],\n",
            "        [-1.5015,  1.8946, -0.4029],\n",
            "        [-1.4378,  1.5722, -0.2757],\n",
            "        [-1.7209,  0.2763,  1.2484],\n",
            "        [-1.6681,  1.6548, -0.1526],\n",
            "        [-1.6009,  0.3508,  1.2056],\n",
            "        [-1.5544,  0.4218,  1.0207],\n",
            "        [-1.3410,  0.3680,  1.0890],\n",
            "        [-1.6400,  1.8856, -0.1719],\n",
            "        [-1.5782,  1.6095, -0.5622],\n",
            "        [-1.3865,  1.3211, -0.0649],\n",
            "        [-1.5642,  0.4749,  0.7556],\n",
            "        [-1.3643,  1.5086, -0.3650],\n",
            "        [-1.4130,  1.5314, -0.4230],\n",
            "        [-1.3336,  1.7197, -0.3795],\n",
            "        [ 0.5488,  0.1200, -1.1779]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3340,  0.2475,  1.0498],\n",
            "        [-1.5015,  1.8946, -0.4029],\n",
            "        [-1.4378,  1.5722, -0.2757],\n",
            "        [-1.7209,  0.2763,  1.2484],\n",
            "        [-1.6681,  1.6548, -0.1526],\n",
            "        [-1.6009,  0.3508,  1.2056],\n",
            "        [-1.5544,  0.4218,  1.0207],\n",
            "        [-1.3410,  0.3680,  1.0890],\n",
            "        [-1.6400,  1.8856, -0.1719],\n",
            "        [-1.5782,  1.6095, -0.5622],\n",
            "        [-1.3865,  1.3211, -0.0649],\n",
            "        [-1.5642,  0.4749,  0.7556],\n",
            "        [-1.3643,  1.5086, -0.3650],\n",
            "        [-1.4130,  1.5314, -0.4230],\n",
            "        [-1.3336,  1.7197, -0.3795],\n",
            "        [ 0.5488,  0.1200, -1.1779]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5170,  1.4860, -0.1381],\n",
            "        [-1.5138,  0.4933,  1.0186],\n",
            "        [-1.5544,  1.7353, -0.2917],\n",
            "        [-1.5279,  1.5616, -0.1058],\n",
            "        [ 0.5185,  0.0446, -1.0836],\n",
            "        [-1.4472,  1.7223, -0.2911],\n",
            "        [-1.5247,  1.8692, -0.3429],\n",
            "        [-1.4944,  0.2515,  1.2327],\n",
            "        [-1.5445,  1.5678, -0.0997],\n",
            "        [-1.7331,  0.3365,  1.1597],\n",
            "        [-1.4496,  1.4994, -0.0485],\n",
            "        [-1.6820,  0.3528,  0.8254],\n",
            "        [-1.3130,  1.3185, -0.4286],\n",
            "        [ 0.2018,  0.3863, -0.8537],\n",
            "        [-1.3808,  1.6151, -0.3824],\n",
            "        [-1.5000,  1.7891, -0.3363]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5170,  1.4860, -0.1381],\n",
            "        [-1.5138,  0.4933,  1.0186],\n",
            "        [-1.5544,  1.7353, -0.2917],\n",
            "        [-1.5279,  1.5616, -0.1058],\n",
            "        [ 0.5185,  0.0446, -1.0836],\n",
            "        [-1.4472,  1.7223, -0.2911],\n",
            "        [-1.5247,  1.8692, -0.3429],\n",
            "        [-1.4944,  0.2515,  1.2327],\n",
            "        [-1.5445,  1.5678, -0.0997],\n",
            "        [-1.7331,  0.3365,  1.1597],\n",
            "        [-1.4496,  1.4994, -0.0485],\n",
            "        [-1.6820,  0.3528,  0.8254],\n",
            "        [-1.3130,  1.3185, -0.4286],\n",
            "        [ 0.2018,  0.3863, -0.8537],\n",
            "        [-1.3808,  1.6151, -0.3824],\n",
            "        [-1.5000,  1.7891, -0.3363]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5013,  1.6873, -0.4179],\n",
            "        [ 0.5317, -0.0429, -1.0068],\n",
            "        [-1.4257,  1.4159, -0.4107],\n",
            "        [-1.6991,  0.4957,  0.8584],\n",
            "        [-1.4957,  1.4673, -0.3208],\n",
            "        [-1.5311,  1.7125, -0.5634],\n",
            "        [-1.4768,  0.3422,  1.0785],\n",
            "        [-1.3431,  1.6234, -0.1267],\n",
            "        [-0.0154,  0.0352, -0.3170],\n",
            "        [-1.4979,  1.5009, -0.1536],\n",
            "        [-1.6371,  0.3258,  1.0804],\n",
            "        [-1.6734,  0.8548,  0.7584],\n",
            "        [-1.4166,  1.4332, -0.1956],\n",
            "        [-0.4346,  0.5480, -0.4018],\n",
            "        [-1.6873,  1.7211, -0.2654],\n",
            "        [-1.2692,  1.4011, -0.2785]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5013,  1.6873, -0.4179],\n",
            "        [ 0.5317, -0.0429, -1.0068],\n",
            "        [-1.4257,  1.4159, -0.4107],\n",
            "        [-1.6991,  0.4957,  0.8584],\n",
            "        [-1.4957,  1.4673, -0.3208],\n",
            "        [-1.5311,  1.7125, -0.5634],\n",
            "        [-1.4768,  0.3422,  1.0785],\n",
            "        [-1.3431,  1.6234, -0.1267],\n",
            "        [-0.0154,  0.0352, -0.3170],\n",
            "        [-1.4979,  1.5009, -0.1536],\n",
            "        [-1.6371,  0.3258,  1.0804],\n",
            "        [-1.6734,  0.8548,  0.7584],\n",
            "        [-1.4166,  1.4332, -0.1956],\n",
            "        [-0.4346,  0.5480, -0.4018],\n",
            "        [-1.6873,  1.7211, -0.2654],\n",
            "        [-1.2692,  1.4011, -0.2785]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4040,  1.5268, -0.5456],\n",
            "        [-1.4222,  1.6385, -0.1872],\n",
            "        [-1.4597,  1.6597, -0.2795],\n",
            "        [-1.4870,  0.2310,  1.0737],\n",
            "        [-1.3280,  1.6431, -0.2444],\n",
            "        [-1.6424,  0.2541,  1.0804],\n",
            "        [ 0.1065,  0.3598, -0.9507],\n",
            "        [-1.3947,  0.9821,  0.2667],\n",
            "        [-1.4973,  1.5287, -0.4676],\n",
            "        [-1.6321,  1.5310, -0.2922],\n",
            "        [-1.6678,  1.4418, -0.1084],\n",
            "        [-1.3002,  0.4042,  1.0101],\n",
            "        [-1.4168,  1.5392, -0.1181],\n",
            "        [-1.6414,  1.6850, -0.0916],\n",
            "        [ 0.5678,  0.0065, -0.9925],\n",
            "        [-1.5730,  0.3551,  0.8914]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4040,  1.5268, -0.5456],\n",
            "        [-1.4222,  1.6385, -0.1872],\n",
            "        [-1.4597,  1.6597, -0.2795],\n",
            "        [-1.4870,  0.2310,  1.0737],\n",
            "        [-1.3280,  1.6431, -0.2444],\n",
            "        [-1.6424,  0.2541,  1.0804],\n",
            "        [ 0.1065,  0.3598, -0.9507],\n",
            "        [-1.3947,  0.9821,  0.2667],\n",
            "        [-1.4973,  1.5287, -0.4676],\n",
            "        [-1.6321,  1.5310, -0.2922],\n",
            "        [-1.6678,  1.4418, -0.1084],\n",
            "        [-1.3002,  0.4042,  1.0101],\n",
            "        [-1.4168,  1.5392, -0.1181],\n",
            "        [-1.6414,  1.6850, -0.0916],\n",
            "        [ 0.5678,  0.0065, -0.9925],\n",
            "        [-1.5730,  0.3551,  0.8914]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3492,  0.3854,  1.0430],\n",
            "        [-1.2769,  1.1808, -0.2621],\n",
            "        [-1.5569,  1.4124, -0.1578],\n",
            "        [-1.4628,  0.2512,  1.0403],\n",
            "        [-1.4587,  1.2687, -0.2983],\n",
            "        [-1.5177,  0.3102,  0.9383],\n",
            "        [-1.4066,  0.2493,  0.7468],\n",
            "        [-1.4343,  1.4563, -0.4108],\n",
            "        [-1.3917,  1.4297, -0.2719],\n",
            "        [-1.3603,  0.5734,  0.8681],\n",
            "        [-1.3011,  0.2968,  0.8114],\n",
            "        [-1.6817,  0.3457,  1.0138],\n",
            "        [-1.3601,  1.5290, -0.4923],\n",
            "        [ 0.4808, -0.0446, -0.9527],\n",
            "        [ 0.3850,  0.0056, -1.0371],\n",
            "        [-1.2284,  1.1715, -0.0551]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3492,  0.3854,  1.0430],\n",
            "        [-1.2769,  1.1808, -0.2621],\n",
            "        [-1.5569,  1.4124, -0.1578],\n",
            "        [-1.4628,  0.2512,  1.0403],\n",
            "        [-1.4587,  1.2687, -0.2983],\n",
            "        [-1.5177,  0.3102,  0.9383],\n",
            "        [-1.4066,  0.2493,  0.7468],\n",
            "        [-1.4343,  1.4563, -0.4108],\n",
            "        [-1.3917,  1.4297, -0.2719],\n",
            "        [-1.3603,  0.5734,  0.8681],\n",
            "        [-1.3011,  0.2968,  0.8114],\n",
            "        [-1.6817,  0.3457,  1.0138],\n",
            "        [-1.3601,  1.5290, -0.4923],\n",
            "        [ 0.4808, -0.0446, -0.9527],\n",
            "        [ 0.3850,  0.0056, -1.0371],\n",
            "        [-1.2284,  1.1715, -0.0551]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5685,  0.3051,  1.0314],\n",
            "        [ 0.5795,  0.0766, -0.9267],\n",
            "        [-1.3333,  1.8146, -0.4403],\n",
            "        [-1.2514,  1.0615, -0.0609],\n",
            "        [-1.3476,  1.2567, -0.0174],\n",
            "        [-1.5160,  1.5341, -0.2548],\n",
            "        [-1.3930,  1.2445, -0.2616],\n",
            "        [-1.4860,  0.2568,  0.9675],\n",
            "        [-1.4447,  1.2879, -0.1665],\n",
            "        [-1.3972,  0.3875,  1.0630],\n",
            "        [-1.4406,  0.5085,  0.8037],\n",
            "        [-1.5890,  0.3457,  0.8699],\n",
            "        [-1.1562,  1.4347, -0.4919],\n",
            "        [-1.3505,  1.4066, -0.2282],\n",
            "        [-1.4619,  0.2109,  1.1091],\n",
            "        [-1.9056,  0.5437,  0.9625]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5685,  0.3051,  1.0314],\n",
            "        [ 0.5795,  0.0766, -0.9267],\n",
            "        [-1.3333,  1.8146, -0.4403],\n",
            "        [-1.2514,  1.0615, -0.0609],\n",
            "        [-1.3476,  1.2567, -0.0174],\n",
            "        [-1.5160,  1.5341, -0.2548],\n",
            "        [-1.3930,  1.2445, -0.2616],\n",
            "        [-1.4860,  0.2568,  0.9675],\n",
            "        [-1.4447,  1.2879, -0.1665],\n",
            "        [-1.3972,  0.3875,  1.0630],\n",
            "        [-1.4406,  0.5085,  0.8037],\n",
            "        [-1.5890,  0.3457,  0.8699],\n",
            "        [-1.1562,  1.4347, -0.4919],\n",
            "        [-1.3505,  1.4066, -0.2282],\n",
            "        [-1.4619,  0.2109,  1.1091],\n",
            "        [-1.9056,  0.5437,  0.9625]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3957,  0.3404,  0.9754],\n",
            "        [-1.2289,  1.3999, -0.2691],\n",
            "        [-1.3235,  1.2462, -0.3382],\n",
            "        [-1.5394,  1.5512, -0.1080],\n",
            "        [-1.3764,  1.4105, -0.1028],\n",
            "        [ 0.2267,  0.1374, -1.0262],\n",
            "        [-0.4290,  0.9049, -0.8689],\n",
            "        [-1.6070,  0.8167,  0.5263],\n",
            "        [-1.3826,  1.2735, -0.1764],\n",
            "        [-1.3788,  0.1284,  1.0581],\n",
            "        [-1.4710,  0.2328,  0.9580],\n",
            "        [ 0.1666,  0.2828, -0.9136],\n",
            "        [-1.3440,  1.3285, -0.0941],\n",
            "        [-0.9266,  0.4953,  0.3197],\n",
            "        [-1.1933,  1.3228, -0.2218],\n",
            "        [-1.2973,  1.2484, -0.0901]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3957,  0.3404,  0.9754],\n",
            "        [-1.2289,  1.3999, -0.2691],\n",
            "        [-1.3235,  1.2462, -0.3382],\n",
            "        [-1.5394,  1.5512, -0.1080],\n",
            "        [-1.3764,  1.4105, -0.1028],\n",
            "        [ 0.2267,  0.1374, -1.0262],\n",
            "        [-0.4290,  0.9049, -0.8689],\n",
            "        [-1.6070,  0.8167,  0.5263],\n",
            "        [-1.3826,  1.2735, -0.1764],\n",
            "        [-1.3788,  0.1284,  1.0581],\n",
            "        [-1.4710,  0.2328,  0.9580],\n",
            "        [ 0.1666,  0.2828, -0.9136],\n",
            "        [-1.3440,  1.3285, -0.0941],\n",
            "        [-0.9266,  0.4953,  0.3197],\n",
            "        [-1.1933,  1.3228, -0.2218],\n",
            "        [-1.2973,  1.2484, -0.0901]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3466,  1.4175, -0.3357],\n",
            "        [-1.2287,  1.3166, -0.1256],\n",
            "        [-1.3960,  1.4081, -0.3106],\n",
            "        [-1.3770,  0.1579,  0.9522],\n",
            "        [ 0.2824,  0.0866, -0.8626],\n",
            "        [-1.7690,  1.5137, -0.1101],\n",
            "        [-1.3629,  1.1939, -0.2811],\n",
            "        [-1.3734,  1.3678, -0.1126],\n",
            "        [-1.4241,  1.3607, -0.0994],\n",
            "        [-1.2695,  1.3516, -0.4101],\n",
            "        [-1.6401,  0.3225,  1.0145],\n",
            "        [-1.2180,  1.1245, -0.3592],\n",
            "        [-1.3309,  0.2053,  0.9533],\n",
            "        [-1.3378,  1.1508, -0.1783],\n",
            "        [-1.2947,  1.3188, -0.2506],\n",
            "        [-1.5695,  0.3038,  1.0871]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3466,  1.4175, -0.3357],\n",
            "        [-1.2287,  1.3166, -0.1256],\n",
            "        [-1.3960,  1.4081, -0.3106],\n",
            "        [-1.3770,  0.1579,  0.9522],\n",
            "        [ 0.2824,  0.0866, -0.8626],\n",
            "        [-1.7690,  1.5137, -0.1101],\n",
            "        [-1.3629,  1.1939, -0.2811],\n",
            "        [-1.3734,  1.3678, -0.1126],\n",
            "        [-1.4241,  1.3607, -0.0994],\n",
            "        [-1.2695,  1.3516, -0.4101],\n",
            "        [-1.6401,  0.3225,  1.0145],\n",
            "        [-1.2180,  1.1245, -0.3592],\n",
            "        [-1.3309,  0.2053,  0.9533],\n",
            "        [-1.3378,  1.1508, -0.1783],\n",
            "        [-1.2947,  1.3188, -0.2506],\n",
            "        [-1.5695,  0.3038,  1.0871]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3795,  1.3732,  0.0242],\n",
            "        [-0.9787,  1.1819, -0.4855],\n",
            "        [-1.1587,  1.3849, -0.5612],\n",
            "        [-1.4169,  0.3960,  0.8290],\n",
            "        [-1.5296,  1.3925,  0.1022],\n",
            "        [-1.4573,  1.1148,  0.2004],\n",
            "        [ 0.4709,  0.1489, -1.1488],\n",
            "        [-1.5392,  0.9715,  0.3721],\n",
            "        [-1.3822,  0.4325,  0.7672],\n",
            "        [-1.4373,  1.3130, -0.1127],\n",
            "        [-1.7889,  0.6452,  0.7279],\n",
            "        [-1.4171,  0.4085,  0.9705],\n",
            "        [-1.4233,  0.1478,  0.9794],\n",
            "        [-1.4506,  1.3461, -0.4794],\n",
            "        [-1.3911,  1.3756, -0.2130],\n",
            "        [-1.4667,  0.6717,  0.7668]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3795,  1.3732,  0.0242],\n",
            "        [-0.9787,  1.1819, -0.4855],\n",
            "        [-1.1587,  1.3849, -0.5612],\n",
            "        [-1.4169,  0.3960,  0.8290],\n",
            "        [-1.5296,  1.3925,  0.1022],\n",
            "        [-1.4573,  1.1148,  0.2004],\n",
            "        [ 0.4709,  0.1489, -1.1488],\n",
            "        [-1.5392,  0.9715,  0.3721],\n",
            "        [-1.3822,  0.4325,  0.7672],\n",
            "        [-1.4373,  1.3130, -0.1127],\n",
            "        [-1.7889,  0.6452,  0.7279],\n",
            "        [-1.4171,  0.4085,  0.9705],\n",
            "        [-1.4233,  0.1478,  0.9794],\n",
            "        [-1.4506,  1.3461, -0.4794],\n",
            "        [-1.3911,  1.3756, -0.2130],\n",
            "        [-1.4667,  0.6717,  0.7668]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2650,  1.3903, -0.1470],\n",
            "        [-1.2733,  1.3943, -0.0205],\n",
            "        [-1.6884,  0.1709,  1.1976],\n",
            "        [ 0.5233,  0.1151, -1.0862],\n",
            "        [-1.4755,  1.5673, -0.1216],\n",
            "        [-1.4003,  1.4200, -0.0830],\n",
            "        [ 0.1920,  0.4006, -1.0904],\n",
            "        [-1.3175,  1.4323, -0.2620],\n",
            "        [-1.3598,  1.3721, -0.1932],\n",
            "        [-1.3147,  1.3153, -0.0608],\n",
            "        [-1.4254,  1.5412, -0.2912],\n",
            "        [-1.2796,  1.2944, -0.4216],\n",
            "        [-1.5130,  1.2695, -0.1459],\n",
            "        [-1.4358,  1.1635, -0.1306],\n",
            "        [-1.4238,  1.2684, -0.2205],\n",
            "        [ 0.6317,  0.0194, -1.2710]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2650,  1.3903, -0.1470],\n",
            "        [-1.2733,  1.3943, -0.0205],\n",
            "        [-1.6884,  0.1709,  1.1976],\n",
            "        [ 0.5233,  0.1151, -1.0862],\n",
            "        [-1.4755,  1.5673, -0.1216],\n",
            "        [-1.4003,  1.4200, -0.0830],\n",
            "        [ 0.1920,  0.4006, -1.0904],\n",
            "        [-1.3175,  1.4323, -0.2620],\n",
            "        [-1.3598,  1.3721, -0.1932],\n",
            "        [-1.3147,  1.3153, -0.0608],\n",
            "        [-1.4254,  1.5412, -0.2912],\n",
            "        [-1.2796,  1.2944, -0.4216],\n",
            "        [-1.5130,  1.2695, -0.1459],\n",
            "        [-1.4358,  1.1635, -0.1306],\n",
            "        [-1.4238,  1.2684, -0.2205],\n",
            "        [ 0.6317,  0.0194, -1.2710]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5855,  0.1628,  1.2013],\n",
            "        [-1.1385,  1.5414, -0.2419],\n",
            "        [-1.4008,  1.4636, -0.4019],\n",
            "        [-1.2866,  1.4169, -0.2155],\n",
            "        [-1.2277,  1.4692, -0.4315],\n",
            "        [-1.1951,  1.1825, -0.2904],\n",
            "        [-1.7073,  0.6953,  0.5601],\n",
            "        [ 0.3515,  0.2281, -1.0343],\n",
            "        [-1.3647,  0.4809,  0.9393],\n",
            "        [-1.6215,  0.3888,  0.9679],\n",
            "        [-1.2823,  1.1843, -0.0806],\n",
            "        [-1.2827,  1.3214, -0.3155],\n",
            "        [-0.9298,  0.8576, -0.2620],\n",
            "        [-1.5876,  0.3846,  1.0366],\n",
            "        [ 0.4738,  0.1127, -1.2489],\n",
            "        [-1.3593,  1.3880, -0.3450]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5855,  0.1628,  1.2013],\n",
            "        [-1.1385,  1.5414, -0.2419],\n",
            "        [-1.4008,  1.4636, -0.4019],\n",
            "        [-1.2866,  1.4169, -0.2155],\n",
            "        [-1.2277,  1.4692, -0.4315],\n",
            "        [-1.1951,  1.1825, -0.2904],\n",
            "        [-1.7073,  0.6953,  0.5601],\n",
            "        [ 0.3515,  0.2281, -1.0343],\n",
            "        [-1.3647,  0.4809,  0.9393],\n",
            "        [-1.6215,  0.3888,  0.9679],\n",
            "        [-1.2823,  1.1843, -0.0806],\n",
            "        [-1.2827,  1.3214, -0.3155],\n",
            "        [-0.9298,  0.8576, -0.2620],\n",
            "        [-1.5876,  0.3846,  1.0366],\n",
            "        [ 0.4738,  0.1127, -1.2489],\n",
            "        [-1.3593,  1.3880, -0.3450]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3280,  0.2643,  1.0397],\n",
            "        [-1.3828,  1.3660, -0.2644],\n",
            "        [-1.4650,  1.2303, -0.3299],\n",
            "        [-1.4290,  0.9939,  0.1496],\n",
            "        [-1.4727,  1.0039,  0.3342],\n",
            "        [-1.4573,  0.3789,  0.9871],\n",
            "        [-1.6132,  0.2944,  1.2294],\n",
            "        [-1.3493,  1.3592, -0.1101],\n",
            "        [-1.3368,  1.4265, -0.2145],\n",
            "        [-1.4603,  1.4539, -0.3017],\n",
            "        [-1.4661,  0.3666,  0.9550],\n",
            "        [-1.5135,  0.3873,  0.9126],\n",
            "        [-1.5073,  1.4797, -0.2143],\n",
            "        [-1.5975,  0.3499,  0.9059],\n",
            "        [-1.5099,  1.4472,  0.0490],\n",
            "        [-1.4847,  1.5136, -0.1943]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3280,  0.2643,  1.0397],\n",
            "        [-1.3828,  1.3660, -0.2644],\n",
            "        [-1.4650,  1.2303, -0.3299],\n",
            "        [-1.4290,  0.9939,  0.1496],\n",
            "        [-1.4727,  1.0039,  0.3342],\n",
            "        [-1.4573,  0.3789,  0.9871],\n",
            "        [-1.6132,  0.2944,  1.2294],\n",
            "        [-1.3493,  1.3592, -0.1101],\n",
            "        [-1.3368,  1.4265, -0.2145],\n",
            "        [-1.4603,  1.4539, -0.3017],\n",
            "        [-1.4661,  0.3666,  0.9550],\n",
            "        [-1.5135,  0.3873,  0.9126],\n",
            "        [-1.5073,  1.4797, -0.2143],\n",
            "        [-1.5975,  0.3499,  0.9059],\n",
            "        [-1.5099,  1.4472,  0.0490],\n",
            "        [-1.4847,  1.5136, -0.1943]], grad_fn=<AddmmBackward0>)\n",
            "Epoch 3/3, Loss: 0.5899\n"
          ]
        }
      ],
      "source": [
        "# Now, distill the knowledge into the student model\n",
        "student_model = distillation_train_loop(student_model, teacher_model, train_dataset, val_dataset, tokenizer, epochs=3, batch_size=16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLc5yF0LNxL0"
      },
      "source": [
        "#### After the student model is trained, HuggingFace Trainer is used for evaluation. evaluate() method in Trainer does not perform training again, it only uses the student model in evaluation mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QItGe7pbNxL0",
        "outputId": "77bcba0d-5eab-4f9e-9aca-296a8673b32a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/kv/563b5k8n4xg24_t9kd2d72c40000gn/T/ipykernel_56174/4119820128.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_student = Trainer(\n",
            "100%|██████████| 61/61 [00:07<00:00,  7.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Results: {'eval_loss': 0.5431520938873291, 'eval_model_preparation_time': 0.0042, 'eval_runtime': 8.9747, 'eval_samples_per_second': 108.081, 'eval_steps_per_second': 6.797}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "trainer_student = Trainer(\n",
        "    model=student_model,\n",
        "    args=training_args,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "# Evaluate the student model\n",
        "results = trainer_student.evaluate()\n",
        "print(f\"Evaluation Results: {results}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qps1JiOnNxL0",
        "outputId": "62e593c8-e3d7-4cdd-8d60-267d16ad4ffd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 61/61 [00:07<00:00,  8.04it/s]\n"
          ]
        }
      ],
      "source": [
        "predictions = trainer_student.predict(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_4TEabMNxL0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "predicted_labels = np.argmax(predictions.predictions, axis=-1)\n",
        "\n",
        "true_labels = predictions.label_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tL-48wM2NxL1",
        "outputId": "bbed948d-1c9c-484f-b751-5416f1d58fb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8062\n",
            "Precision: 0.8145\n",
            "Recall: 0.8062\n",
            "F1 Score: 0.7975\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRuGcVRYNxL1"
      },
      "source": [
        "#### Student model as ROBERTA student model as DISTILBERT"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ROBERTA Robustly optimized BERT approach"
      ],
      "metadata": {
        "id": "L54d-8AZXvd7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493,
          "referenced_widgets": [
            "cc796ed43f0943aa87252c0ee28b1b3b",
            "4caa9a6ac69442f9ab0450b139e95eb4",
            "b6e2fd8d96634fb2a534dd6b15698a22",
            "39f2c80e1ab64616b439f7471fb962e2",
            "87c5899cbb49454d916dae5e538d6921",
            "821fe3969ecf4a8fa16fcf41f4b63245",
            "7883f670814a4fc2ab8721f045a546d2",
            "73a815c952694f95a4f24e87e976fe99",
            "3d829106523a44d88f2e601b678afd57",
            "2b047f99e112447293c61a5d18867c6e",
            "39cb6c79f830421c9e06680d7201a622",
            "d81f9632fad842c887e5ebce1392e53b",
            "d5a5293c7aaa49809d0cbccee172c90d",
            "6ad9f4feedad413ca632291d1d895ad4",
            "eca94c24ef4e47c488e2d44591afaece",
            "e45987e26c0f4e19a619290cab11808d",
            "926d2ba251ef4bcb8f50152d9ee19c38",
            "876eaa5fe2c647aa821dcb8062041949",
            "7cd2fe7dc1634194ab987946ae653747",
            "8d630aaa0c8b4ac9bff69fea11fd255d",
            "f660affabaf84b459014f70e73a34b9b",
            "3349b25fbfd4470b956bcb3212860bf6",
            "bbc9867e30d7467a892112c3c2c8e09d",
            "b7dd3edd50534299a182a285d6013b4c",
            "562fc31aeed049eb8340d025a576117a",
            "5c3fe3a6bb2540a29ed1feb34349d2ae",
            "4737cbd82ae04d74884f215ebdfb8ef9",
            "1bff35083e0142f28078382a022497ac",
            "fd9443e8355c4ae1ae01e028e971892c",
            "c434b8b0737f4c2ba5226716160ad782",
            "d4a79af63bd2468689126bbc6f6f6113",
            "f50848b024fc4f1eb0ee542573f43087",
            "29e5a64c98374e85a56b3377fd1d87bc",
            "d79c869da18043c0b8c27085f5a29836",
            "45c9c5010e694b519dc97c3d5b55204d",
            "a70465acb10f404ab2bc9ba8900dfde8",
            "7774a68a9968421aabf3e6d34fa0b768",
            "f68c7b588b4a42688ff5f45474bfdf00",
            "f9f8a9fd69a14fd4a639876e73482aa5",
            "9a6139027be348fbba8b6f64274de1e2",
            "9e6cdad9b4724431b5f7d39790fd8cb9",
            "2353661821054aeba24849371f6985db",
            "e309a6b4f66a4347bb4b59a9738562da",
            "f99da6587a6d40acb9305185fb2b1ec0",
            "e153c3bd81314717a4c02e4a25fdfd60",
            "89de1ef691a34a6c9f55f549770e82ef",
            "28d1fad381bd4e9b9cc5b8a39f8ad255",
            "e596e4c1a48f46f8a59442db31f8710c",
            "4e099c39b232403080aca190a85959f6",
            "4b78131d92594522a303bf353040286f",
            "f96dd57c31994d9fb6a40898413770ce",
            "15dca22ec4a349599849ee4fc12fe033",
            "4ac57e43c32b4dfebdf6b127d54d55c0",
            "f873926761b64924be7b31365092bd7f",
            "8248227f066a41cc92b43ee29b07c5fd",
            "8a99bd5d16594921b88726fabdee3047",
            "a28662be162f487e9e6175680b73c594",
            "e6c92df1dcbe4e62add2b4f04ac13752",
            "505e79841d764987baa5dd3ab00cb42a",
            "a69528d258384126bd9c3cbec914fdf5",
            "274a9f52ca444217ad4379bdfdfb1a97",
            "27fc02adf68c450fa172ebd2ee916740",
            "ec564c5b86104bc79ff1fdfe99e03d2e",
            "ecc9eb27efc4485fb9d84fa24769ed02",
            "65f13d5a86d2477e9c5e9b3aa0b34e23",
            "884c1ca35e164ba5a4e67fa8ebcda63b",
            "62b3fbe25259427e9b674341dcdd80bc",
            "b2b2f55792224161a6738eb145010acc",
            "c552bebb00cc436f9d9278955d030293",
            "a2a617f4fc7b44e3840a925beecda7a6",
            "ad00167ee8594ab98799b1865b216cc9",
            "265d98f0242948329451992c679864b5",
            "058b1b45489b4a85a45a6f319a8a7a84",
            "04ec2d2c4ac74de1acdb7431c80b44c4",
            "98c7049693644a73be336f38cd2f49d5",
            "ee88361a171d4ae38677013b92e2c6a3",
            "2f86dd6ad16d41ac817e9f4b0f70e3fe",
            "cf962cd2832c4275ab9e70e26d8c3b84",
            "1bca41cf53be44ad959c43396c3fef27",
            "03cf4f590ed1429585c6c2f811d200d9",
            "389725306482434d809a23e4213bc8f8",
            "c27ebb7aaa1e4c228d19ca56ec2c19e4",
            "1769cc70a8b54a57a1dccc0769ea3a44",
            "58bb73b9b5dd4a6e87e3c3e34028ac9d",
            "42232a169fd54cd5b5a7ef83314f30fd",
            "217983543e6b4f47a1096eeb931c14db",
            "ae60d05e58ff451aa827f3404deb994e",
            "5dc51965848e4a95b41c46f81cdd9b05",
            "c63b143d48c04736bddec5d4692d183b",
            "af0a1e42cd2b468ab52ac1616e2884dc",
            "b584dc8c36af40918c805f18550c4875",
            "173dd2ddf3d54579b9022035911f22ca",
            "0ec5234cb16f47fbb61d465f6611e765",
            "2ff323a4c3114eb694260f9cb4860cfb",
            "331cd4c22798444488d66f7301ed4326",
            "1e2563da59fb42a6bbf0f8e564c7352c",
            "a9378634621c4d41b857c3d655800e37",
            "8fac7def1d71488cbad4ce368025ce3d",
            "a99e1eec140b406dadbb1729c9ddeb38",
            "9d85b0cc11484bcda21566076a60fa29",
            "278b189d17a94d4c8716baef51231c87",
            "f9236505fbe44772a54f09e513214078",
            "32c5677db4dd40188a33758612ff0a8c",
            "ced1bb07e627446e9d5252dd92a8663b",
            "575e915229e646b6a35b5d00264be8b3",
            "fdbc28683ee6412db019ad2c5038dc81",
            "310256286b164c9b9c1bfffd903c5b80",
            "a64840cdccd049af8369d207e763c509",
            "e132e29eeb2944a6a4d42f741934c625",
            "d99acc8c08154dc283fbb1870b54b932",
            "01d53c5f9598484abcab0a7dd80ffb01",
            "8d6aaa788f8f418ba11df208451f523d",
            "a246421c572b43888dd14eef599b1848",
            "f9ec5142a0894d628f6b0f26956b135c",
            "82aa938087b94aa8831197ed5da1d360",
            "4880d7d55ee54702b1c506bc9536500b",
            "bbdc303c78824e969cdf91e7ab84837c",
            "d88bcedeedd8498cb7dd20a8e20eda6d",
            "679dbae97378472182c801bccc9457eb",
            "52d8f1ccfa7e45b2b1e7ab8988de53d7",
            "6550b6603f954c69900ed76f3943518f"
          ]
        },
        "id": "0DYlzXgENxL1",
        "outputId": "9c22d08b-57b9-4bb6-9c42-b7ffb10245b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc796ed43f0943aa87252c0ee28b1b3b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d81f9632fad842c887e5ebce1392e53b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bbc9867e30d7467a892112c3c2c8e09d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d79c869da18043c0b8c27085f5a29836"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/8.88k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e153c3bd81314717a4c02e4a25fdfd60"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "financial_phrasebank.py:   0%|          | 0.00/6.04k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a99bd5d16594921b88726fabdee3047"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FinancialPhraseBank-v1.0.zip:   0%|          | 0.00/682k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62b3fbe25259427e9b674341dcdd80bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/4846 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf962cd2832c4275ab9e70e26d8c3b84"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3488 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c63b143d48c04736bddec5d4692d183b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/388 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d85b0cc11484bcda21566076a60fa29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/970 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01d53c5f9598484abcab0a7dd80ffb01"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Initialize tokenizer and dataset\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "train_dataset, val_dataset, test_dataset = prepare_datasets(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "teacher_model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=3).to(device)\n",
        "student_model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3).to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234,
          "referenced_widgets": [
            "20f5d028c0474a0ba2e98e25860a1205",
            "fb9272a925454d6c9036b0f3d4353377",
            "b70ab834986b41038fba0ef72162ee7f",
            "89e92096d1c14a7e94beaa1495f67fb1",
            "2cd80a9c588a41c787485c9b50d1ee9b",
            "999600f2818945baa68c0848207ba7bc",
            "c9edfce94baa40c5860b3847b563973a",
            "49b290f52aeb44c686d9ccbbd82760c7",
            "4fb75c2b5e1645e28192942e7c79b221",
            "4a3bd7c145574917a529f93350b88ba5",
            "f07b4f9816ba465d9831442b525f8b06",
            "81b25174d3644dcfac081f38af483cd2",
            "45231c986ad54f8eac9e8228c37a9776",
            "f80c54e62e534506ae549e8c19cc3701",
            "acfb661688eb4efab919ac27e32f0169",
            "80d130db141b4eb8984cec34bd77e8c5",
            "6b26eef2f5c647aab835415befde3a1f",
            "040ba087a9604a8494d1cd16596ddfe0",
            "bc2dabcb3b2646c0b96a9ac1b173d172",
            "be182ae473034bf491987e53eac901ab",
            "05f16056c7f14e1abeae593038b0b47f",
            "591d341703684ddd9e066399e4792631",
            "022576b7c25f4b5a84fea8074889484e",
            "dde60a783f9041099d4fbf482e0e01fb",
            "85ca7b3567bc48b88b0a532ed5515ed0",
            "69a30cf114f946a48ed22ab4641fce2a",
            "cc9fb406f44d4d2aa7f99ce38a786666",
            "8a7a8a907ad44651897541d18369e4ba",
            "36ea293eb9f648deb45ef977f4cb7f4c",
            "0b16be197f1240c38ae8ed0d161b64b6",
            "756edbc5bd7249c3af4886b37de8ad51",
            "d71dbc2a17e94cec9bf62ac655edd997",
            "c30c05619ce8415fb9986e78fcda886c",
            "234bb7d87c0c4b73bf404a6a6dfa4765",
            "8ea25629432643dca574a27c2df44a90",
            "b8233f50a2af422aae48fae3c3690694",
            "9be476d492f74863b04b80f8ea5e0116",
            "5e510af2a5364f7e80c9e871ab594123",
            "9fb6133eafa74502a37fd94cbb680791",
            "f55e1c1e69d64f72bb26de4c5bb882cf",
            "17867e8ec4f444fab52efd318a8c6c7c",
            "f96e9c42190345cb92fbea40570c3c60",
            "788eaa03a52348c1af36d3c4b93e2b97",
            "9ef9949f227a444d8898d500e8c063fd"
          ]
        },
        "id": "p3woTZeaSRFK",
        "outputId": "75f5f735-1d3e-4c10-db75-b8ee02f89b54"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "20f5d028c0474a0ba2e98e25860a1205"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "81b25174d3644dcfac081f38af483cd2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "022576b7c25f4b5a84fea8074889484e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "234bb7d87c0c4b73bf404a6a6dfa4765"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_model = teacher_model.to(device)\n",
        "student_model = student_model.to(device)"
      ],
      "metadata": {
        "id": "wcbGSRFcTRVD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "tXA0JICmNxL1",
        "outputId": "032ebf53-0fbc-421d-c74b-d614ff3ecb2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "<ipython-input-14-f8fe41ae71b8>:20: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_teacher = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='654' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [654/654 02:11, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.938400</td>\n",
              "      <td>0.926514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.911400</td>\n",
              "      <td>0.926700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.909500</td>\n",
              "      <td>0.857801</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "import os\n",
        "\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "training_args_teacher = TrainingArguments(\n",
        "    output_dir=\"/content/results_knowledge_distill/teacher_model_ROBERTA\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"/content/logs_knowledge_distill/teacher_model_ROBERTA\",\n",
        "    logging_steps=10,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=False\n",
        ")\n",
        "\n",
        "trainer_teacher = Trainer(\n",
        "    model=teacher_model,\n",
        "    args=training_args_teacher,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "trainer_teacher.train()\n",
        "\n",
        "teacher_model.save_pretrained(\"/content/checkpoints/teacher_model_ROBERTA\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "DbFcNRK1NxL2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "\n",
        "def distillation_loss(student_logits, teacher_logits, true_labels, temperature, alpha):\n",
        "    device = student_logits.device\n",
        "    true_labels = true_labels.to(device)\n",
        "    teacher_logits = teacher_logits.to(device)\n",
        "\n",
        "    soft_labels = F.softmax(teacher_logits / temperature, dim=-1)\n",
        "\n",
        "    hard_loss = F.cross_entropy(student_logits, true_labels)\n",
        "\n",
        "    soft_loss = F.kl_div(\n",
        "        F.log_softmax(student_logits / temperature, dim=-1),\n",
        "        soft_labels,\n",
        "        reduction=\"batchmean\"\n",
        "    )\n",
        "\n",
        "    return alpha * soft_loss + (1 - alpha) * hard_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=16)\n",
        "\n",
        "optimizer = Adam(student_model.parameters(), lr=2e-5)"
      ],
      "metadata": {
        "id": "sy8GBPv7Vds6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "epochs = 3\n",
        "temperature = 2.0\n",
        "alpha = 0.5\n",
        "\n",
        "teacher_model.to(\"cuda\")\n",
        "teacher_model.eval()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    student_model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        inputs = {k: v.to(\"cuda\") for k, v in batch.items() if k in [\"input_ids\", \"attention_mask\"]}\n",
        "        labels = batch[\"labels\"].to(\"cuda\")\n",
        "\n",
        "        # Get teacher logits (soft labels)\n",
        "        with torch.no_grad():\n",
        "            teacher_logits = teacher_model(**inputs).logits\n",
        "\n",
        "        # Get student logits\n",
        "        student_outputs = student_model(**inputs)\n",
        "        student_logits = student_outputs.logits\n",
        "\n",
        "        # Calculate distillation loss\n",
        "        loss = distillation_loss(student_logits, teacher_logits, labels, temperature, alpha)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_dataloader)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16pvhTohVvnn",
        "outputId": "244a4331-d5e5-4274-b4b5-ba04c2cfca4a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.3367614353058535\n",
            "Epoch 2/3, Loss: 0.21890916695835394\n",
            "Epoch 3/3, Loss: 0.17549574200850016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "student_model.save_pretrained(\"/content/checkpoints/student_model\")"
      ],
      "metadata": {
        "id": "OMuUP4KgW1xw"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iX4GmkO_NxL2",
        "outputId": "24f79f93-c57d-4319-a4c7-5f419b877290"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Metrics: {'accuracy': 0.8530927835051546, 'precision': 0.8533877790196023, 'recall': 0.8530927835051546, 'f1': 0.8488220784681562}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs = {k: v.to(\"cuda\") for k, v in batch.items() if k in [\"input_ids\", \"attention_mask\"]}\n",
        "            labels = batch[\"labels\"].to(\"cuda\")\n",
        "\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits\n",
        "            preds = torch.argmax(logits, axis=-1).cpu().numpy()\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "            predictions.extend(preds)\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    precision = precision_score(true_labels, predictions, average=\"weighted\")\n",
        "    recall = recall_score(true_labels, predictions, average=\"weighted\")\n",
        "    f1 = f1_score(true_labels, predictions, average=\"weighted\")\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "val_metrics = evaluate_model(student_model, val_dataloader)\n",
        "print(f\"Validation Metrics: {val_metrics}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/checkpoints.zip /content/checkpoints"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T22RDXnvagoA",
        "outputId": "c7609876-15ca-449f-f9d0-39a4d6df4bbb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/checkpoints/ (stored 0%)\n",
            "  adding: content/checkpoints/teacher_model_ROBERTA/ (stored 0%)\n",
            "  adding: content/checkpoints/teacher_model_ROBERTA/model.safetensors (deflated 16%)\n",
            "  adding: content/checkpoints/teacher_model_ROBERTA/config.json (deflated 52%)\n",
            "  adding: content/checkpoints/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: content/checkpoints/student_model/ (stored 0%)\n",
            "  adding: content/checkpoints/student_model/model.safetensors (deflated 8%)\n",
            "  adding: content/checkpoints/student_model/config.json (deflated 47%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/logs_knowledge_distill.zip /content/logs_knowledge_distill"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvxaQeqYalJB",
        "outputId": "c7d82b47-0bbc-404f-8eb7-305a37433e3e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/logs_knowledge_distill/ (stored 0%)\n",
            "  adding: content/logs_knowledge_distill/teacher_model_ROBERTA/ (stored 0%)\n",
            "  adding: content/logs_knowledge_distill/teacher_model_ROBERTA/events.out.tfevents.1735121717.9c95ddbc12f4.631.1 (deflated 66%)\n",
            "  adding: content/logs_knowledge_distill/teacher_model_ROBERTA/events.out.tfevents.1735121576.9c95ddbc12f4.631.0 (deflated 62%)\n",
            "  adding: content/logs_knowledge_distill/.ipynb_checkpoints/ (stored 0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/results_knowledge_distill.zip /content/results_knowledge_distill"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlDxneaNaqp-",
        "outputId": "6f51d466-a47f-4c5a-e70f-f13082a79fb3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/results_knowledge_distill/ (stored 0%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/ (stored 0%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-218/ (stored 0%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-218/vocab.txt (deflated 53%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-218/tokenizer.json (deflated 71%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-218/scheduler.pt (deflated 56%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-218/trainer_state.json (deflated 72%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-218/optimizer.pt (deflated 32%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-218/tokenizer_config.json (deflated 75%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-218/model.safetensors (deflated 16%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-218/training_args.bin (deflated 52%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-218/rng_state.pth (deflated 25%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-218/special_tokens_map.json (deflated 42%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-218/config.json (deflated 52%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-654/ (stored 0%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-654/vocab.txt (deflated 53%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-654/tokenizer.json (deflated 71%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-654/scheduler.pt (deflated 56%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-654/trainer_state.json (deflated 78%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-654/optimizer.pt (deflated 32%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-654/tokenizer_config.json (deflated 75%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-654/model.safetensors (deflated 16%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-654/training_args.bin (deflated 52%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-654/rng_state.pth (deflated 25%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-654/special_tokens_map.json (deflated 42%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-654/config.json (deflated 52%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Parameter Search on Knowledge Distillation Model (alpha and temperature) initialization with the huggingface pretrained"
      ],
      "metadata": {
        "id": "hCb5ePWca5M9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=3).to(\"cuda\")\n",
        "teacher_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEyxZ1w5bnD2",
        "outputId": "4ff2341e-e2ff-426c-fc94-96d2dbc1be27"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temperature_values = [1.0, 2.0, 3.0]\n",
        "alpha_values = [0.3, 0.5, 0.7, 0.9]"
      ],
      "metadata": {
        "id": "Rktkmw0ha3un"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = None\n",
        "best_accuracy = float(\"-inf\")\n",
        "best_metrics = None"
      ],
      "metadata": {
        "id": "wb_wjVcqcp71"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grid search on combinations of temperature and alpha\n",
        "for temperature in temperature_values:\n",
        "    for alpha in alpha_values:\n",
        "        print(f\"Training with temperature={temperature}, alpha={alpha}...\")\n",
        "\n",
        "        # reinitialize student model for grid search\n",
        "        student_model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3).to(\"cuda\")\n",
        "        optimizer = Adam(student_model.parameters(), lr=2e-5)\n",
        "\n",
        "        # Using distillation loss, train the student model\n",
        "        epochs = 3 # use same epoch number on student model to comparasion\n",
        "        student_model.train()\n",
        "        for epoch in range(epochs):\n",
        "            total_loss = 0.0\n",
        "            for batch in train_dataloader:\n",
        "                inputs = {k: v.to(\"cuda\") for k, v in batch.items() if k in [\"input_ids\", \"attention_mask\"]}\n",
        "                labels = batch[\"labels\"].to(\"cuda\")\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    teacher_logits = teacher_model(**inputs).logits\n",
        "\n",
        "                student_outputs = student_model(**inputs)\n",
        "                student_logits = student_outputs.logits\n",
        "\n",
        "                loss = distillation_loss(student_logits, teacher_logits, labels, temperature, alpha)\n",
        "                total_loss += loss.item()\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        val_metrics = evaluate_model(student_model, val_dataloader)\n",
        "\n",
        "        print(f\"Validation Metrics: {val_metrics}\")\n",
        "\n",
        "        if val_metrics[\"accuracy\"] > best_accuracy:\n",
        "            best_accuracy = val_metrics[\"accuracy\"]\n",
        "            best_params = {\"temperature\": temperature, \"alpha\": alpha}\n",
        "            best_metrics = val_metrics\n",
        "\n",
        "print(f\"Best Hyperparameters: {best_params}\")\n",
        "print(f\"Best Validation Metrics: {best_metrics}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8ttS_nqcr4f",
        "outputId": "56f5840f-75fa-4c7e-e5a5-f07761aba96f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with temperature=1.0, alpha=0.3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Metrics: {'accuracy': 0.8298969072164949, 'precision': 0.8277090767909066, 'recall': 0.8298969072164949, 'f1': 0.8272837322500177}\n",
            "Training with temperature=1.0, alpha=0.5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Metrics: {'accuracy': 0.8350515463917526, 'precision': 0.8333853096865418, 'recall': 0.8350515463917526, 'f1': 0.8329165832696697}\n",
            "Training with temperature=1.0, alpha=0.7...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Metrics: {'accuracy': 0.8376288659793815, 'precision': 0.83652262516548, 'recall': 0.8376288659793815, 'f1': 0.8341876298292671}\n",
            "Training with temperature=1.0, alpha=0.9...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Metrics: {'accuracy': 0.7268041237113402, 'precision': 0.8252335533592452, 'recall': 0.7268041237113402, 'f1': 0.7438818285221023}\n",
            "Training with temperature=2.0, alpha=0.3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Metrics: {'accuracy': 0.8195876288659794, 'precision': 0.8193024880196635, 'recall': 0.8195876288659794, 'f1': 0.8183060526143721}\n",
            "Training with temperature=2.0, alpha=0.5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Metrics: {'accuracy': 0.8247422680412371, 'precision': 0.8286647536750384, 'recall': 0.8247422680412371, 'f1': 0.8258265651621475}\n",
            "Training with temperature=2.0, alpha=0.7...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Metrics: {'accuracy': 0.8273195876288659, 'precision': 0.8265293717175646, 'recall': 0.8273195876288659, 'f1': 0.8265522501139326}\n",
            "Training with temperature=2.0, alpha=0.9...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Metrics: {'accuracy': 0.8376288659793815, 'precision': 0.8363712992348918, 'recall': 0.8376288659793815, 'f1': 0.83396148679333}\n",
            "Training with temperature=3.0, alpha=0.3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Metrics: {'accuracy': 0.8195876288659794, 'precision': 0.8185384013102601, 'recall': 0.8195876288659794, 'f1': 0.8186497605684431}\n",
            "Training with temperature=3.0, alpha=0.5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Metrics: {'accuracy': 0.8324742268041238, 'precision': 0.8358861601546772, 'recall': 0.8324742268041238, 'f1': 0.8336759006449497}\n",
            "Training with temperature=3.0, alpha=0.7...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Metrics: {'accuracy': 0.8247422680412371, 'precision': 0.8267686221714032, 'recall': 0.8247422680412371, 'f1': 0.8184031965831681}\n",
            "Training with temperature=3.0, alpha=0.9...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Metrics: {'accuracy': 0.8273195876288659, 'precision': 0.8365388168347929, 'recall': 0.8273195876288659, 'f1': 0.8295179670912656}\n",
            "Best Hyperparameters: {'temperature': 1.0, 'alpha': 0.7}\n",
            "Best Validation Metrics: {'accuracy': 0.8376288659793815, 'precision': 0.83652262516548, 'recall': 0.8376288659793815, 'f1': 0.8341876298292671}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "42FeqQOPeiE0"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = {\n",
        "    (1.0, 0.3): {'accuracy': 0.8298969072164949, 'precision': 0.8277090767909066, 'recall': 0.8298969072164949, 'f1': 0.8272837322500177},\n",
        "    (1.0, 0.5): {'accuracy': 0.8350515463917526, 'precision': 0.8333853096865418, 'recall': 0.8350515463917526, 'f1': 0.8329165832696697},\n",
        "    (1.0, 0.7): {'accuracy': 0.8376288659793815, 'precision': 0.83652262516548, 'recall': 0.8376288659793815, 'f1': 0.8341876298292671},\n",
        "    (1.0, 0.9): {'accuracy': 0.7268041237113402, 'precision': 0.8252335533592452, 'recall': 0.7268041237113402, 'f1': 0.7438818285221023},\n",
        "    (2.0, 0.3): {'accuracy': 0.8195876288659794, 'precision': 0.8193024880196635, 'recall': 0.8195876288659794, 'f1': 0.8183060526143721},\n",
        "    (2.0, 0.5): {'accuracy': 0.8247422680412371, 'precision': 0.8286647536750384, 'recall': 0.8247422680412371, 'f1': 0.8258265651621475},\n",
        "    (2.0, 0.7): {'accuracy': 0.8273195876288659, 'precision': 0.8265293717175646, 'recall': 0.8273195876288659, 'f1': 0.8265522501139326},\n",
        "    (2.0, 0.9): {'accuracy': 0.8376288659793815, 'precision': 0.8363712992348918, 'recall': 0.8376288659793815, 'f1': 0.83396148679333},\n",
        "    (3.0, 0.3): {'accuracy': 0.8195876288659794, 'precision': 0.8185384013102601, 'recall': 0.8195876288659794, 'f1': 0.8186497605684431},\n",
        "    (3.0, 0.5): {'accuracy': 0.8324742268041238, 'precision': 0.8358861601546772, 'recall': 0.8324742268041238, 'f1': 0.8336759006449497},\n",
        "    (3.0, 0.7): {'accuracy': 0.8247422680412371, 'precision': 0.8267686221714032, 'recall': 0.8247422680412371, 'f1': 0.8184031965831681},\n",
        "    (3.0, 0.9): {'accuracy': 0.8273195876288659, 'precision': 0.8365388168347929, 'recall': 0.8273195876288659, 'f1': 0.8295179670912656},\n",
        "}\n",
        "\n",
        "data = []\n",
        "\n",
        "for (temperature, alpha), metrics in results.items():\n",
        "    row = {'temperature': temperature, 'alpha': alpha}\n",
        "    row.update(metrics)\n",
        "    data.append(row)\n",
        "\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "JxNwocEalSZP"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the figure\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.subplot(2, 2, 1)\n",
        "sns.heatmap(df.pivot(index=\"alpha\", columns=\"temperature\", values=\"accuracy\"), annot=True, cmap=\"Blues\", fmt=\".3f\", cbar_kws={'label': 'Accuracy'})\n",
        "plt.title(\"Accuracy vs Temperature and Alpha\")\n",
        "plt.xlabel(\"Temperature\")\n",
        "plt.ylabel(\"Alpha\")\n",
        "\n",
        "# Plot Precision\n",
        "plt.subplot(2, 2, 2)\n",
        "sns.heatmap(df.pivot(index=\"alpha\", columns=\"temperature\", values=\"precision\"), annot=True, cmap=\"Blues\", fmt=\".3f\", cbar_kws={'label': 'Precision'})\n",
        "plt.title(\"Precision vs Temperature and Alpha\")\n",
        "plt.xlabel(\"Temperature\")\n",
        "plt.ylabel(\"Alpha\")\n",
        "\n",
        "# Plot Recall\n",
        "plt.subplot(2, 2, 3)\n",
        "sns.heatmap(df.pivot(index=\"alpha\", columns=\"temperature\", values=\"recall\"), annot=True, cmap=\"Blues\", fmt=\".3f\", cbar_kws={'label': 'Recall'})\n",
        "plt.title(\"Recall vs Temperature and Alpha\")\n",
        "plt.xlabel(\"Temperature\")\n",
        "plt.ylabel(\"Alpha\")\n",
        "\n",
        "# Plot F1 Score\n",
        "plt.subplot(2, 2, 4)\n",
        "sns.heatmap(df.pivot(index=\"alpha\", columns=\"temperature\", values=\"f1\"), annot=True, cmap=\"Blues\", fmt=\".3f\", cbar_kws={'label': 'F1 Score'})\n",
        "plt.title(\"F1 Score vs Temperature and Alpha\")\n",
        "plt.xlabel(\"Temperature\")\n",
        "plt.ylabel(\"Alpha\")\n",
        "\n",
        "# Show the plots\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "h_-6ypocn4Gk",
        "outputId": "f56be17d-77dd-4c45-e273-9ffa871e941a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 8 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA9UAAAJOCAYAAAC5nCQrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd1QUVxvA4d/Se5EmCAo2jF1RsXclFiyxYElssddomhpb9Is9ajS2GEtsETVqTOzdqNh7FxuiIkVBpEmZ7w/C6sqiQEAQ3uecPQdm79y5s7M779yZW1SKoigIIYQQQgghhBAiw3RyugBCCCGEEEIIIcSHSirVQgghhBBCCCFEJkmlWgghhBBCCCGEyCSpVAshhBBCCCGEEJkklWohhBBCCCGEECKTpFIthBBCCCGEEEJkklSqhRBCCCGEEEKITJJKtRBCCCGEEEIIkUlSqRZCCCGEEEIIITJJKtVCiDzr4MGDqFQqDh48mKX5qlQqJkyYkOl1Bw8enKXlEULknB49euDq6pqhdbLr3CTEh6B+/frUr18/S/OcMGECKpXqP60bGhqapWUS+YtUqtNhwYIFqFQqPD09c7oo4l8qlSpdr/x8wbJgwQJWrFiR08X44MjvXYjcbcWKFRrneSMjI0qWLMngwYN58uRJThcv30qpmLzrldWVqQ/J1atXmTBhAvfu3cvponxQEhMTcXJyQqVSsWPHjpwujhBa6eV0AT4Ea9aswdXVlZMnT+Lv70/x4sVzukj53qpVqzT+X7lyJXv27Em1/KOPPnqfxcpVFixYgK2tLT169MjponxQ5PcuxIdh4sSJuLm5ERsby5EjR1i4cCHbt2/n8uXLmJiYvLdyLFmyhKSkpAytU7duXWJiYjAwMMimUr1/n3zyicb58sWLFwwYMIC2bdvyySefqJc7ODjkRPFyhatXr/L9999Tv379DLduyM/279/P48ePcXV1Zc2aNTRr1iyniyREKlKpfoe7d+9y7NgxNm3aRL9+/VizZg3jx4/P6WJpFRUVhampaU4X47349NNPNf4/fvw4e/bsSbU8r1AUhdjYWIyNjaUc2ehD+r0Lkd81a9aMKlWqANC7d29sbGyYNWsWf/75J507d9a6TnbESX19/Qyvo6Ojg5GRUZaWI6eVL1+e8uXLq/8PDQ1lwIABlC9fPs/G5txy3ZVbypFdVq9eTeXKlenevTujR4/O8/srPkzS/Psd1qxZg7W1NS1atKB9+/asWbNGa7rw8HCGDx+Oq6srhoaGODs7061bN43+GbGxsUyYMIGSJUtiZGSEo6Mjn3zyCbdv3wbS7mN17949VCqVRlPeHj16YGZmxu3bt2nevDnm5uZ07doVgH/++YcOHTpQuHBhDA0NcXFxYfjw4cTExKQq9/Xr1+nYsSN2dnYYGxvj7u7Od999B8CBAwdQqVRs3rw51Xpr165FpVLh5+en9fM4ffo0KpWK3377LdV7u3btQqVS8ffffwMQGRnJF198of7s7O3tadKkCWfPntWad3olJSUxZ84cypQpg5GREQ4ODvTr149nz55ppHN1daVly5YcPHiQKlWqYGxsTLly5dTHYdOmTZQrVw4jIyM8PDw4d+6cxvopx+LOnTt4eXlhamqKk5MTEydORFGU/1SmXbt2qcu0ePFiAJYvX07Dhg2xt7fH0NCQ0qVLs3DhwlTrX7lyhUOHDqVqcpdWv6OUJpWvN0t7WznCw8P54osvcHFxwdDQkOLFizNt2rR0PbH5888/adGiBU5OThgaGlKsWDEmTZpEYmKiRrr69etTtmxZrl69SoMGDTAxMaFQoUJMnz49VZ6BgYG0adMGU1NT7O3tGT58OHFxce8sy+vS+3t/U8pnmvJ7srCwwMbGhmHDhhEbG6t1nS1btlC2bFkMDQ0pU6YMO3fu1Hj//v37DBw4EHd3d4yNjbGxsaFDhw7SbFCINDRs2BBIvjkGb4+T6T0XA+zYsYN69ephbm6OhYUFVatWZe3ater3tfWpXrduHR4eHup1ypUrx08//aR+P614v2HDBjw8PDA2NsbW1pZPP/2Uhw8faqRJ2a+HDx/Spk0bzMzMsLOz46uvvkp1Dn1Ty5YtKVq0qNb3atSoob5JAbBnzx5q166NlZUVZmZmuLu7M3r06Lfmnx7Xr1+nffv2FChQACMjI6pUqcLWrVs10qTEoyNHjjB06FDs7OywsrKiX79+vHz5kvDwcLp164a1tTXW1tZ88803GvE25bpp5syZzJ49myJFimBsbEy9evW4fPnyfyrToUOHGDhwIPb29jg7OwPpO1+vWLGCDh06ANCgQYNU3dTSGqvD1dVVo8XZ28oByd/XOnXqYGpqirm5OS1atODKlSvvPC5Pnz7lq6++oly5cpiZmWFhYUGzZs24cOGCRrqU7+769ev54YcfcHZ2xsjIiEaNGuHv758q319++YVixYphbGxMtWrV+Oeff95ZltfFxMSwefNmOnXqRMeOHYmJieHPP/9M17opY5isWbMGd3d39XXc4cOHtaYPDw+nR48eWFlZYWlpSc+ePYmOjtZIk55rMJE/yZPqd1izZg2ffPIJBgYGdO7cmYULF3Lq1CmqVq2qTvPixQvq1KnDtWvX6NWrF5UrVyY0NJStW7cSGBiIra0tiYmJtGzZkn379tGpUyeGDRtGZGQke/bs4fLlyxQrVizDZUtISMDLy4vatWszc+ZMdXO3DRs2EB0dzYABA7CxseHkyZPMmzePwMBANmzYoF7/4sWL1KlTB319ffr27Yurqyu3b9/mr7/+4ocffqB+/fq4uLiwZs0a2rZtm+pzKVasGDVq1NBatipVqlC0aFHWr19P9+7dNd7z9fXF2toaLy8vAPr378/GjRsZPHgwpUuXJiwsjCNHjnDt2jUqV66c4c8lRb9+/VixYgU9e/Zk6NCh3L17l59//plz585x9OhRjacL/v7+dOnShX79+vHpp58yc+ZMvL29WbRoEaNHj2bgwIEATJkyhY4dO3Ljxg10dF7dk0pMTOTjjz+mevXqTJ8+nZ07dzJ+/HgSEhKYOHFipsp048YNOnfuTL9+/ejTpw/u7u4ALFy4kDJlytCqVSv09PT466+/GDhwIElJSQwaNAiAOXPmMGTIEMzMzNQ3STLb5E5bOaKjo6lXrx4PHz6kX79+FC5cmGPHjjFq1CgeP37MnDlz3prnihUrMDMzY8SIEZiZmbF//37GjRvH8+fPmTFjhkbaZ8+e8fHHH/PJJ5/QsWNHNm7cyLfffku5cuXUTcBiYmJo1KgRAQEBDB06FCcnJ1atWsX+/fsztK/p+b2/TceOHXF1dWXKlCkcP36cuXPn8uzZM1auXKmR7siRI2zatImBAwdibm7O3LlzadeuHQEBAdjY2ABw6tQpjh07RqdOnXB2dubevXssXLiQ+vXrc/Xq1ffavFWID0HKDeqU3xCkHSfTey5esWIFvXr1okyZMowaNQorKyvOnTvHzp076dKli9Zy7Nmzh86dO9OoUSOmTZsGwLVr1zh69CjDhg1Ls/wp5alatSpTpkzhyZMn/PTTTxw9epRz585hZWWlTpuYmIiXlxeenp7MnDmTvXv38uOPP1KsWDEGDBiQ5jZ8fHzo1q1bqvPa/fv3OX78uPr8e+XKFVq2bEn58uWZOHEihoaG+Pv7c/To0bcdgne6cuUKtWrVolChQowcORJTU1PWr19PmzZt+OOPP1JdawwZMoSCBQvy/fffc/z4cX755ResrKw4duwYhQsXZvLkyWzfvp0ZM2ZQtmxZunXrprH+ypUriYyMZNCgQcTGxvLTTz/RsGFDLl26pI6JGS3TwIEDsbOzY9y4cURFRQHpO1/XrVuXoUOHMnfuXEaPHq3unpbZbmrayrFq1Sq6d++Ol5cX06ZNIzo6moULF1K7dm3OnTv31ibnd+7cYcuWLXTo0AE3NzeePHnC4sWLqVevHlevXsXJyUkj/dSpU9HR0eGrr74iIiKC6dOn07VrV06cOKFOs3TpUvr160fNmjX54osvuHPnDq1ataJAgQK4uLikaz+3bt3Kixcv6NSpEwULFqR+/fqsWbMmzd/fmw4dOoSvry9Dhw7F0NCQBQsW8PHHH3Py5EnKli2rkbZjx464ubkxZcoUzp49y6+//oq9vb36dwzpuwYT+ZQi0nT69GkFUPbs2aMoiqIkJSUpzs7OyrBhwzTSjRs3TgGUTZs2pcojKSlJURRFWbZsmQIos2bNSjPNgQMHFEA5cOCAxvt3795VAGX58uXqZd27d1cAZeTIkanyi46OTrVsypQpikqlUu7fv69eVrduXcXc3Fxj2evlURRFGTVqlGJoaKiEh4erlwUHByt6enrK+PHjU23ndaNGjVL09fWVp0+fqpfFxcUpVlZWSq9evdTLLC0tlUGDBr01r3cZNGiQ8vrX+Z9//lEAZc2aNRrpdu7cmWp5kSJFFEA5duyYetmuXbsUQDE2Ntb4fBYvXpzqGKUciyFDhqiXJSUlKS1atFAMDAyUkJCQTJdp586dqfZV2/H18vJSihYtqrGsTJkySr169VKlHT9+vKLtp798+XIFUO7evfvOckyaNEkxNTVVbt68qbF85MiRiq6urhIQEJAq/3ftQ79+/RQTExMlNjZWvaxevXoKoKxcuVK9LC4uTilYsKDSrl079bI5c+YogLJ+/Xr1sqioKKV48eJaf1PapPf3riiKAmh8/1M+01atWmmkGzhwoAIoFy5c0FjXwMBA8ff3Vy+7cOGCAijz5s1TL9P2Gfn5+aX6PITIb1LOVXv37lVCQkKUBw8eKOvWrVNsbGwUY2NjJTAwUFGUtONkes/F4eHhirm5ueLp6anExMRopH09Tnbv3l0pUqSI+v9hw4YpFhYWSkJCQpr78Ga8f/nypWJvb6+ULVtWY1t///23Aijjxo3T2B6gTJw4USPPSpUqKR4eHmluU1EUJSIiQjE0NFS+/PJLjeXTp0/XuEaYPXu2AqjjV2aEhISkOlc2atRIKVeunMZ5PikpSalZs6ZSokQJ9bKUY+zl5aXxWdeoUUNRqVRK//791csSEhIUZ2dnjXiXct30+vdBURTlxIkTCqAMHz4802WqXbt2qmOb3vP1hg0b0oxJb35WKYoUKaJ07979neWIjIxUrKyslD59+misHxQUpFhaWqZa/qbY2FglMTFRY9ndu3cVQ0NDje9aynf3o48+UuLi4tTLf/rpJwVQLl26pCjKq+90xYoVNdL98ssvCqD1+kSbli1bKrVq1dJYX09PTwkODtZIp+3aBlAA5fTp0+pl9+/fV4yMjJS2bdumWvf1a1NFUZS2bdsqNjY2GsvSew0m8h9p/v0Wa9aswcHBgQYNGgDJzUh8fHxYt26dRhOrP/74gwoVKqS6m5myTkoaW1tbhgwZkmaazNB2R/r1/q5RUVGEhoZSs2ZNFEVRN10OCQnh8OHD9OrVi8KFC6dZnm7duhEXF8fGjRvVy3x9fUlISHhnHykfHx/i4+PZtGmTetnu3bsJDw/Hx8dHvczKyooTJ07w6NGjdO71u23YsAFLS0uaNGlCaGio+uXh4YGZmRkHDhzQSF+6dGmNp+4pIz83bNhQ4/NJWX7nzp1U23x9mqSUJkcvX75k7969mSqTm5ub+mn+614/vhEREYSGhlKvXj3u3LlDREREuj+j9NJWjg0bNlCnTh2sra019qVx48YkJiam2bRK2z5ERkYSGhpKnTp1iI6O5vr16xppzczMNL5rBgYGVKtWTeMYbN++HUdHR9q3b69eZmJiQt++fdO9n+n9vb/Nm3epU37v27dv11jeuHFjjdYp5cuXx8LCQmOfXv+M4uPjCQsLo3jx4lhZWf3nrhFC5AWNGzfGzs4OFxcXOnXqhJmZGZs3b6ZQoUIa6d6Mk+k9F+/Zs4fIyEhGjhyZqv/z2+K2lZUVUVFR7NmzJ937cvr0aYKDgxk4cKDGtlq0aEGpUqXYtm1bqnX69++v8X+dOnW0xqbXpTTpXb9+vUZzaV9fX6pXr66OdylPxf/8888MD8KWlqdPn7J//346duyoPu+HhoYSFhaGl5cXt27dStXU/fPPP9f4rD09PVEUhc8//1y9TFdXlypVqmjd9zZt2mh8H6pVq4anp6f6nJyZMvXp0wddXV2NZTlxvn6zHHv27CE8PJzOnTtrfK91dXXx9PRMdY3xJkNDQ3ULvMTERMLCwtTN/rXtQ8+ePTUG2qtTpw7w6voo5Tvdv39/jXQ9evTA0tIyXfsYFhbGrl27NMZIaNeunbr5eXrUqFEDDw8P9f+FCxemdevW7Nq1K1Vs1/abCgsL4/nz5+pl7/saTHw4pFKdhsTERNatW0eDBg24e/cu/v7++Pv74+npyZMnT9i3b5867e3bt1M1IXnT7du3cXd3R08v61rc6+npafSjSREQEECPHj0oUKCAuq9VvXr1ANQ/+JST3rvKXapUKapWrarRt3TNmjVUr179naMiV6hQgVKlSuHr66te5uvri62trbrvG8D06dO5fPkyLi4uVKtWjQkTJrzzwuBdbt26RUREBPb29tjZ2Wm8Xrx4QXBwsEb6N28spJzw32yelLL8zX53Ojo6qfqplSxZEkDdpyqjZXJzc9O6b0ePHqVx48aYmppiZWWFnZ2dup9bdlWq33Tr1i127tyZaj8aN24MkGpf3nTlyhXatm2LpaUlFhYW2NnZqSvOb+6Ds7NzqgtYa2trjWNw//59ihcvnipdSpP5d8nI7/1tSpQoofF/sWLF0NHRSdUP+s3vm7Z9iomJYdy4ceo+67a2ttjZ2REeHi6BWwhg/vz57NmzhwMHDnD16lX1uBav0xYn03suTmlO/q44+aaBAwdSsmRJmjVrhrOzM7169Uo1ZsKb7t+/D2g/Z5UqVUr9fgojIyPs7Ow0lr15DkmLj48PDx48UI+Jcvv2bc6cOaNxs9vHx4datWrRu3dvHBwc6NSpE+vXr/9PFWx/f38URWHs2LGpPveUASH/S2zWtu9vnpMhOTannJMzUyZtMTEnztdvluPWrVtA8sOAN/dl9+7d74zLSUlJzJ49mxIlSmjsw8WLF7Xuw5vHxtraGnh1fZTynX3zGOjr66fZr/9Nvr6+xMfHU6lSJXVcfvr0KZ6enuke8ySt70B0dDQhISEZ2id4/9dg4sMhfarTkDJ8/7p161i3bl2q99esWUPTpk2zdJtp3flO6ynZ63cVX0/bpEkTnj59yrfffkupUqUwNTXl4cOH9OjRI1MBsVu3bgwbNozAwEDi4uI4fvw4P//8c7rW9fHx4YcffiA0NBRzc3O2bt1K586dNW4udOzYkTp16rB582Z2797NjBkzmDZtGps2bcr0tAlJSUnY29unedJ982LkzbvO71r++h3+7CqTthG2b9++TaNGjShVqhSzZs3CxcUFAwMDtm/fzuzZs9N1fDP6PdNWjqSkJJo0acI333yjdZ2UGwrahIeHU69ePSwsLJg4cSLFihXDyMiIs2fP8u2336bah6w8BmnJrt97Wp91evZpyJAhLF++nC+++IIaNWpgaWmJSqWiU6dOWfbkSIgPWbVq1TQG1tJGW5zM6Lk4o+zt7Tl//jy7du1ix44d7Nixg+XLl9OtWzetg3dmRlrnkPTw9vbGxMSE9evXU7NmTdavX4+Ojo56EC1IPu8fPnyYAwcOsG3bNnbu3Imvry8NGzZk9+7dmdp+ynnrq6++0toKC0h1sz4jsTmzcTmjZdIWE7PzfJ3e2JyynVWrVlGwYMFU6d/1UGfy5MmMHTuWXr16MWnSJAoUKICOjg5ffPGF1n14H7E55Tdaq1Ytre/fuXMn3RX09HjXPmXFNZjIu6RSnYY1a9Zgb2/P/PnzU723adMmNm/ezKJFizA2NqZYsWJaR5N8XbFixThx4gTx8fFpTr+RckcsPDxcY/mbd6jf5tKlS9y8eZPffvtNY8CON5uhpZyE3lVugE6dOjFixAh+//13YmJi0NfX17ij/TY+Pj58//33/PHHHzg4OPD8+XM6deqUKp2joyMDBw5k4MCBBAcHU7lyZX744YdMV6qLFSvG3r17qVWr1nuZ/ikpKYk7d+5oVCZv3rwJoB4YJCvK9NdffxEXF8fWrVs17qhqa9aVVoXu9e/Z6wPfZOR7VqxYMV68eKF+Mp0RBw8eJCwsjE2bNlG3bl318pQRezOjSJEiXL58GUVRNPb7xo0b6Vo/I7/3t7l165bG0wN/f3+SkpIyNR/pxo0b6d69Oz/++KN6WWxsbKrzgxAiY9J7Lk7ponH58uUMz1dvYGCAt7c33t7eJCUlMXDgQBYvXszYsWO15lWkSBEg+Zz1ekuulGUp72cFU1NTWrZsyYYNG5g1axa+vr7UqVMn1UBUOjo6NGrUiEaNGjFr1iwmT57Md999x4EDBzJ17k+57tDX18/U+pmR8vT2dTdv3lSfk7OqTOk9X7+t24C1tXWq9C9fvuTx48fpKkPK99Xe3j5T+7Jx40YaNGjA0qVLNZaHh4dja2ub4fxSvrO3bt3S+E7Hx8dz9+5dKlSo8Nb1U6a4HDx4sLq1ZYqkpCQ+++wz1q5dy5gxY96aT1rfARMTkwzfQMvINZjIf6T5txYxMTFs2rSJli1b0r59+1SvwYMHExkZqZ5uoV27dly4cEHr1FMpd7fatWtHaGio1ie8KWmKFCmCrq5uqv6oCxYsSHfZU+6yvX6nUFEUjak8IPlOfN26dVm2bBkBAQFay5PC1taWZs2asXr1atasWcPHH3+c7hPsRx99RLly5fD19cXX1xdHR0eNilRiYmKq5jL29vY4OTlleDqk13Xs2JHExEQmTZqU6r2EhIRsqZi8fmwVReHnn39GX1+fRo0aZVmZtB3fiIgIli9fniqtqamp1jxTAu/r37OoqKgMPUHp2LEjfn5+7Nq1K9V74eHhJCQkZGgfXr58maHv+ZuaN2/Oo0ePNPr+R0dH88svv7xz3Yz+3t/mzUr5vHnzADJ1c0hXVzfVb3HevHnp7t8thNAuvefipk2bYm5uzpQpU1JNjfe2p3FhYWEa/+vo6Kjnb04rrlWpUgV7e3sWLVqkkWbHjh1cu3aNFi1apGvf0svHx4dHjx7x66+/cuHChVQ3yp8+fZpqnYoVKwJp78O72NvbU79+fRYvXqy1ovhmU9yssGXLFo0+0SdPnuTEiRPqc3JWlSm95+uUuZXTis1vXv/98ssv6T7ne3l5YWFhweTJk4mPj0/1/rv2Rds+bNiwIVWf8vSqUqUKdnZ2LFq0iJcvX6qXr1ixIl3XOylPqb/55ptUcbljx47Uq1cvXU3A/fz8NPqEP3jwgD///JOmTZtmuMVFRq7BRP4jT6q12Lp1K5GRkbRq1Urr+9WrV8fOzo41a9bg4+PD119/zcaNG+nQoQO9evXCw8ODp0+fsnXrVhYtWkSFChXo1q0bK1euZMSIEZw8eZI6deoQFRXF3r17GThwIK1bt8bS0pIOHTowb948VCoVxYoV4++//35nP5jXlSpVimLFivHVV1/x8OFDLCws+OOPP7T2NZo7dy61a9emcuXK9O3bFzc3N+7du8e2bds4f/68Rtpu3bqpB4HSdiHyNj4+PowbNw4jIyM+//xzjaZ4kZGRODs70759eypUqICZmRl79+7l1KlTGnd8M6pevXr069ePKVOmcP78eZo2bYq+vj63bt1iw4YN/PTTTxqDWv1XRkZG7Ny5k+7du+Pp6cmOHTvYtm0bo0ePVt8JzYoyNW3aVP0EpF+/frx48YIlS5Zgb2+f6oLAw8ODhQsX8r///Y/ixYtjb29Pw4YNadq0KYULF+bzzz/n66+/RldXl2XLlmFnZ5fqBktavv76a7Zu3UrLli3p0aMHHh4eREVFcenSJTZu3Mi9e/fSvPFSs2ZNrK2t6d69O0OHDkWlUrFq1ar/1GSsT58+/Pzzz3Tr1o0zZ87g6OjIqlWr0jXtVEZ/729z9+5dWrVqxccff4yfnx+rV6+mS5cu77wjr03Lli1ZtWoVlpaWlC5dGj8/P/bu3asxXZAQIuPSey62sLBg9uzZ9O7dm6pVq9KlSxesra25cOEC0dHRad6I7N27N0+fPqVhw4Y4Oztz//595s2bR8WKFdOcPklfX59p06bRs2dP6tWrR+fOndVTarm6ujJ8+PAs/QxS5u3+6quv0NXVpV27dhrvT5w4kcOHD9OiRQuKFClCcHAwCxYswNnZmdq1a2d6u/Pnz6d27dqUK1eOPn36ULRoUZ48eYKfnx+BgYGp5kT+r4oXL07t2rUZMGAAcXFxzJkzBxsbG42uS1lRpvSerytWrIiuri7Tpk0jIiICQ0ND9ZzHvXv3pn///rRr144mTZpw4cIFdu3ale6HGBYWFixcuJDPPvuMypUr06lTJ3Vc37ZtG7Vq1Xpr172WLVsyceJEevbsSc2aNbl06RJr1qzJdPNqfX19/ve//9GvXz8aNmyIj48Pd+/eZfny5enKc82aNVSsWDHNqbdatWrFkCFDOHv27FunXy1btixeXl4aU2oBfP/99xnep4xcg4l86H0NM/4h8fb2VoyMjJSoqKg00/To0UPR19dXQkNDFUVRlLCwMGXw4MFKoUKFFAMDA8XZ2Vnp3r27+n1FSR6G/7vvvlPc3NwUfX19pWDBgkr79u2V27dvq9OEhIQo7dq1U0xMTBRra2ulX79+yuXLl7VOqWVqaqq1bFevXlUaN26smJmZKba2tkqfPn3UU/a8noeiKMrly5eVtm3bKlZWVoqRkZHi7u6ujB07NlWecXFxirW1tWJpaZlqapF3uXXrlnpagyNHjqTK9+uvv1YqVKigmJubK6ampkqFChWUBQsWZGgbb06pleKXX35RPDw8FGNjY8Xc3FwpV66c8s033yiPHj1SpylSpIjSokWLVOsCqab6SpmmY8aMGeplKcfi9u3bStOmTRUTExPFwcFBGT9+fKrpKf5rmRRFUbZu3aqUL19eMTIyUlxdXZVp06app2x7fTqsoKAgpUWLFoq5uXmq6SvOnDmjeHp6KgYGBkrhwoWVWbNmpTmlVlrliIyMVEaNGqUUL15cMTAwUGxtbZWaNWsqM2fOVF6+fKl1nRRHjx5VqlevrhgbGytOTk7KN998o57G7PWpRurVq6eUKVMm1fpvTmGjKMnTZLRq1UoxMTFRbG1tlWHDhqmnyHnblFqZ+b2TxpRaV69eVdq3b6+Ym5sr1tbWyuDBg1P9XrR9rxQl9bQpz549U3r27KnY2toqZmZmipeXl3L9+vVU6YTIb1LOVadOnXprurfFSUVJ37lYUZLPuTVr1lSMjY0VCwsLpVq1asrvv/+usZ3Xz0cbN25UmjZtqtjb26vPsf369VMeP36sTpPWFJq+vr5KpUqVFENDQ6VAgQJK165dNaaEett+pTVdYlq6du2qAErjxo1Tvbdv3z6ldevWipOTk2JgYKA4OTkpnTt3TjWN4ttom1JLURTl9u3bSrdu3ZSCBQsq+vr6SqFChZSWLVsqGzduVKdJ6xin7OObU329+Zm8Hqt//PFHxcXFRTE0NFTq1KmjMcVhVpRJUTJ2vl6yZIlStGhRRVdXV+M7kJiYqHz77beKra2tYmJionh5eSn+/v5pTqmV1vf/wIEDipeXl2JpaakYGRkpxYoVU3r06KExrZQ2sbGxypdffqk4OjoqxsbGSq1atRQ/Pz+lXr16GtcPKd/dDRs2aKyvbfpXRVGUBQsWKG5uboqhoaFSpUoV5fDhw6nyfNOZM2cUQOv1aIp79+5pTI+W1pRagwYNUlavXq2UKFFCMTQ0VCpVqpTqd5fW90rbdVF6r8FE/qNSlCwcUUDkWQkJCTg5OeHt7Z2qv01+16NHDzZu3MiLFy9yuigih0yYMIHvv/+ekJCQTPU9E0IIkXXu3buHm5sbM2bM4Kuvvsrp4ogcolKpGDRoULoH1xXiv5A+1SJdtmzZQkhIiMbgZ0IIIYQQQgiR30mfavFWJ06c4OLFi0yaNIlKlSqlGoFRCCGEEEIIIfIzeVIt3mrhwoUMGDAAe3t7Vq5cmdPFEUIIIYQQQohcRfpUCyGEEEIIIYQQmSRPqoUQQgghhBBCiEySSrUQQgghhBBCCJFJUqkWQgghhBBCCCEyKU+O/m3caHJOF0FkgmHBwjldBCHyjfA1n2Z5nsaVBqcrXcw5mTM0vxrwx9WcLoLIhCnN3XO6CCITjPR1c7oIIhOMsqF2JvE5++XJSrUQQogcoJLGT0IIIUSuI/E520mlWgghRNZQqXK6BEIIIYR4k8TnbCeVaiGEEFlD7oQLIYQQuY/E52wnlWohhBBZQ0f67wkhhBC5jsTnbCeVaiGEEFlDmpcJIYQQuY/E52wnlWohhBBZQ5qXCSGEELmPxOdsJ5VqIYQQWUPuhAshhBC5j8TnbCeVaiGEEFlD7oQLIYQQuY/E52wnlWohhBBZQwZCEUIIIXIfic/ZTirVQgghsoY0LxNCCCFyH4nP2U4q1UIIIbKGNC8TQgghch+Jz9lOKtVCCCGyhgRtIYQQIveR+JztpFIthBAia+hI8zIhhBAi15H4nO3ktoUQQoisoaObvpcQQggh3p9sjM/z58/H1dUVIyMjPD09OXny5FvTz5kzB3d3d4yNjXFxcWH48OHExsaq31+4cCHly5fHwsICCwsLatSowY4dOzTyqF+/PiqVSuPVv3//TJU/q8iTaiGEEFlDmpcJIYQQuU82xWdfX19GjBjBokWL8PT0ZM6cOXh5eXHjxg3s7e1TpV+7di0jR45k2bJl1KxZk5s3b9KjRw9UKhWzZs0CwNnZmalTp1KiRAkUReG3336jdevWnDt3jjJlyqjz6tOnDxMnTlT/b2Jiki37mF5SqRZCCJE1ZHRRIYQQIvfJpvg8a9Ys+vTpQ8+ePQFYtGgR27ZtY9myZYwcOTJV+mPHjlGrVi26dOkCgKurK507d+bEiRPqNN7e3hrr/PDDDyxcuJDjx49rVKpNTEwoWLBgduxWpshjBSGEEFlDpZO+lxBCCCHen3TG57i4OJ4/f67xiouL05rly5cvOXPmDI0bN1Yv09HRoXHjxvj5+Wldp2bNmpw5c0bdRPzOnTts376d5s2ba02fmJjIunXriIqKokaNGhrvrVmzBltbW8qWLcuoUaOIjo7OzCeTZeRJtRBCiKwhT6qFEEKI3Ced8XnKlCl8//33GsvGjx/PhAkTUqUNDQ0lMTERBwcHjeUODg5cv35da/5dunQhNDSU2rVroygKCQkJ9O/fn9GjR2uku3TpEjVq1CA2NhYzMzM2b95M6dKlNfIpUqQITk5OXLx4kW+//ZYbN26wadOmdO1ndsjRSvWePXs4cuQI9erVo2HDhhw+fJgpU6YQFxfHZ599pm5KIIQQ4gMgg5DlKRKjhRAij0hnfB41ahQjRozQWGZoaJhlxTh48CCTJ09mwYIFeHp64u/vz7Bhw5g0aRJjx45Vp3N3d+f8+fNERESwceNGunfvzqFDh9QV6759+6rTlitXDkdHRxo1asTt27cpVqxYlpU3I3KsHd7q1atp3rw5f//9N61bt2bFihW0bt0aZ2dn3Nzc6N+/Pxs3bsyp4gkhhMgoaf6dZ0iMFkKIPCSd8dnQ0FA96nbKK61Kta2tLbq6ujx58kRj+ZMnT9Ls6zx27Fg+++wzevfuTbly5Wjbti2TJ09mypQpJCUlqdMZGBhQvHhxPDw8mDJlChUqVOCnn35Kc/c8PT0B8Pf3z+gnk2Vy7En1jz/+yI8//sjQoUPZt28f3t7e/PDDDwwfPhyA0qVLM2fOHNq3b59TRcxy/Vp7MLyjJw4FzLh0+wkj5u3m9I3HaaYf/ElV+rSqjIu9BWERMWw+fJ2xvx4gLj4RgD7elenTqjJFHCwBuHY/hMmrjrD75B11Hob6ukwd0JgODT7CUF+PvafuMGzuLoKfRWXvzuYhvZuUZGiL0thbGnM54Bnf/HaKs3fC0kw/4ONS9GpUEmdbE8Ii49h6MoDvfc8RF598shjeqgzeVQpTwsmC2JeJnLwVwvh15/B//Fydh6G+Dv/r6kG76q4Y6Ouw/+Jjvlx+kpDnsWltVrxBjlsOkObfeUZ+i9H1ilrTpKQNFkZ6BEbE4Xv+Mfefpf27bVi8AHWLWmNtos+LuETOPXzOlsvBJCQpAHi521DRyYKC5gbEJyrcfhrNlkvBPHnxUp2HhaEun5RzoJSDGUZ6OjyJjGPn9VDOPYrM9v3NKzasW8ua35YRFhZKiZLufPntd5QpVz7N9L+vXsmmDet4EvQYSytrGjZuysChw9WVhnNnTrP6t2Vcv3aF0JAQps+aS72GjTXyCAsLZf6cWZw4fpTIyEgqVa7Cl9+OpnAR1+zc1Txl3do1/LZ8KaGhIZR0L8XI0WMpVz7t47Z65QrW+/5O0OPHWFlb06SJF0OHf6k+bmdOn2LFsqVcu3qZkJAQZs+dT8NGbxy30FDmzJqJ37EjREZGUtmjCiO/G0uR/HLcsiE+GxgY4OHhwb59+2jTpg0ASUlJ7Nu3j8GDB2tdJzo6Gh0dzZvrurrJT9EVRUlzW0lJSWn27QY4f/48AI6OjhnYg6yVY48Mbt26pR7drVGjRiQkJNCoUSP1+y1atEizPf6HqH39j5jWvxE/rDxCjf7LuHg7mK3TOmFnpX34d5+GpZnUpwGTV/5DxZ6/0H/mNtrX/4iJveur0zwMfc7YJQeoOWAZtQYu5+C5+2yY2IGPitiq00wf2IQW1YvT9fvNNB2+GkdbM9ZN+CS7dzfPaFu9CD909WDapovUG7OdywHP2DSyIbYW2u/ata/pynifSkzbfBHPr/9iyJLjtK1ehHEdK6nT1CrlwK97b9Bk/E7aTt2Lnq4Om0c2xMTwVdOcyZ9W4eNKzvSYe5gWk/ZQ0NqYVcPrZvv+5hVy3HKIPKnOM/JTjPZwtqBdeQe2XQth8r47BEbEMrR2EcwNtTeXrOpiQZuy9my7FsL3u2+z+swjPJwtaF321fQxJWxNOXTnKdMP3OOnI/fRVakYUrswBrqvLmy7Vy2Eg7khC48F8L+9tzn/KJLe1Z1xtjTK9n3OC/bs2sFPP07j834D+e33jRQvWYphA/vy9Kn2m6e7tv/Ngrmz6N1vIOs2/c134yexd/cOFs6bo04TExNNiZLufD1qrNY8FEXhm+FDePjwATNm/8yqdX9Q0NGRIf0/JyYmZwdJ+lDs3LGdmdOn0G/gINZt2Iy7eykG9PucsDDtx23733/x0+wf6T9gMJv/2s6EiT+wa+d25s6ZpU4TExONu7s7o8aM15qHoih8MXQQgYEPmDNvAb4bN+PoVIh+n/fM8cGt3ptsis8jRoxgyZIl/Pbbb1y7do0BAwYQFRWl7h7UrVs3Ro0apU7v7e3NwoULWbduHXfv3mXPnj2MHTsWb29vdeV61KhRHD58mHv37nHp0iVGjRrFwYMH6dq1KwC3b99m0qRJnDlzhnv37rF161a6detG3bp1Kf+WmzPZLceeVOvr6/Py5as7toaGhpiZmWn8HxMTkxNFyxZD21dj+fbzrNp1EYAhc3bQrHpxun9cgZnrUo+QV72MM36XA/HdfxWAgCcRrD9wlaqlnNRptvtpNnGYsOwQfbwrU610Ia7dD8XC1JAezSrQY/KfHDp/H4C+07dxYUU/qn3kxMlrj7Jrd/OMQc0+4rcD/qw5nPz0f/iyEzStWIhP6xVnzl9XUqWvVsKOEzeD2XjsHgABoVH84XcPj2KvbnS0n75fY52Bi49xe1EHKrrZcOx6MBbG+nxWvxi95x/l8NXkJjWDFvtxamYrqhS35bR/aDbtbd4hxy2HSIU5z8hPMbpRCRuO3gvH734EAL+ffUy5gmbUKGLF7pupL/SL2phwOyyGUw+SW6k8jY7n9IPnuBYwVqf5+WiAxjorTz9ihrc7ha2N8Q+NVufz+7lXT8R3XA+lYfECFLE2IjAin7Ru+Q9+X7WC1p90wLtN8oOCkWPGc+yfQ/y1ZRPde/VJlf7ihfOUr1gJr+YtAXAqVIimHzfn8qVL6jQ1a9elZu20b4Q+CLjP5YsX+H3jnxQtXgKAb78bT/NGddm9YzutP8kbLTey06rflvNJ+460adsOgDHjv+fw4YNs2fQHn/fpmyr9+fPnqFipMs1bJt/kK1TImY+bt+TSxQvqNLXr1KN2nXppbvP+/XtcvHCeP/78m+L/Hrcx4ybQsF4tdm7fxiftO2TlLuZO2RSffXx8CAkJYdy4cQQFBVGxYkV27typHrwsICBA48n0mDFjUKlUjBkzhocPH2JnZ6duCZUiODiYbt268fjxYywtLSlfvjy7du2iSZMmQPIT8r179zJnzhyioqJwcXGhXbt2jBkzJlv2Mb1y7AqoePHiGne5Hz58iJubm/r/27dv4+zsnBNFy3L6ejpUKunI/rP31MsUBfafvUu10oW0rnP8SiCVShakintyMwZXRyu8qhVj58nbWtPr6Kjo0KA0pkb6nLj6EIBKJQpioK/L/jN31eluPggj4EkEnmlsV7yir6tDRbcCHLr8qom+osChy4+pVsJW6zonb4VQ0c2GykVtAChiZ0aTCoXYc/5hmtuxMNEH4NmL5GYtFd0KYKCnq7HdW4+f8yD0BdWKa9+ueEWOWw7S0U3fS+R6+SVG66qgsJUR14NfdYlSgOvBURS10d6S7E5YNIWtjChinfxE2dZUnzIFzbgS9CLN7RjrJ19uRb9M1MinirMFJvo6qIAqzhbo6+pwM0S6Z71LfPxLrl+7SjXP6uplOjo6VPWswaWL57WuU75CRa5fvcqVS8kPNx4GPuDYkX+oVbtOurebcqPJ4LU+pjo6OugbGHDh3NlM7En+Ev/yJdeuXqF6jZrqZTo6OlSvXpOLF85pXadixUpcu3qFSxeTj1vggwcc+ecQdeqmXYnWtl0AQwPN42ZgYMC5s2cysysfnmyMz4MHD+b+/fvExcVx4sQJdf9mSB6YbMWKFer/9fT0GD9+PP7+/sTExBAQEMD8+fOxsrJSp1m6dCn37t0jLi6O4OBg9u7dq65QA7i4uHDo0CHCwsKIjY3l1q1bTJ8+HQsLi0yVP6vk2JPq0aNHY21trf7/zQ/i9OnTdOzY8X0XK1vYWpqgp6uTqh9z8LMo3F1stK7ju/8qNpYm7PupGyoV6Ovp8svWs8xYe0wjXRk3Ow7O646RgR4vYl7iM/4Prt9PfiJWsIApcS8TiIjS7IMQ/CwKhwJmiLezMTdMPm5vPDEIfh5LCSdLretsPHYPG3NDdo5vigoV+no6LN17k1lbUz8dheQuLlM+q4LfjWCuBSY/JbG3MiYuPpGI6HjN7UbEYm9lrC0b8Ro5bjlI+lTnGfklRpsZ6qGro+J5bILG8uexCTiYa+8ucurBc8wM9PiqvhsqQFdHxeE7T9l5Q3trFBXQoUJB/EOjefT8VTz+9UQgvT2d+bFVKRKTFF4mJrHY7wEhUfFa8xGvhD8LJzExkQI2mjcsC9jYcP/eHa3reDVvSXj4M/r2/BQFSExI4JMOPvTo3S/d23V1daOgoyML5s5m5NgJGBsb8/vqlQQ/CSI0NOS/7FK+8Cz8GYmJidjYaF772tjYcPeu9uPWvKU3z8Kf0eOzLkDyFEwdfDrRu2//dG/X1a0ojo5OzJ3zI2PHT8TY2JhVK1fwJCiIkJB8ctwkPme7HKtUt23b9q3vjxw5Ml35xMXFpeq4riQloNL5sKfgrlOhMF93qcmwuTs5de0RxZysmTmoCY8/rcXU1UfV6W4+CMOz71IsTQ1pW7cUS771pumI1eqKtXi/an/kwIhWZfly+SnO3A6lqIM5Uz6rwtdtyjFjy6VU6Wf2qEZpZys+nrg7B0orUshxyyLS/DvPyIoYrS0+J8a/RFff4D+VLaeVsDXBq5Qt68495u7TGOzMDOhYoSDNSiWw43rq2NupUkGcLAyZeeiexnLv0vYY6+sy5/B9XrxMoKKTeXIl+9A9jcq3yBpnTp1kxdJf+Gb0OMqUK0/ggwBmTZ/M0l8W8nnfAenKQ09fn6k/zuWHCWNoUrcGurq6VPWsQY1adUhu4yCy2qmTJ1j6y2K+GzuecuXLExAQwPQpP7B44Xz6DRiUrjz09fWZ9dM8Joz9jjo1q6Grq4tn9RrUrlP3rYNj5SkSn7Pdh13zRPsk5bquDdEv2iiNNd6/0IhoEhKTsLc21Vhub21K0FPtzbzG96zH73sus2J7cp+RK3dDMDHWZ/7w5kxbc5SUc0B8QhJ3Hj0D4NytIDzcHRn0SVWGzN5B0NMoDA30sDQ11HhabW9typOnaTdTE8nCIuOSj9sbg8bYWxgRHKG9L+Ho9hXwPXKXVQeT+7tffRCOiaEecz73ZOafl3j93D29e1W8KhWixaTdPHr6aqCM4PAYDPV1sTTR13jqaW9pRHB43ujDmJ3kuOUguRMuXqMtPnt0GEhVn/RdCL8PL+ISSExSsDDSvByyMNJL9fQ6Rasy9pwMCOfovXAAHj2Pw1BXh66VHdl5PVSjauVTsSBlC5oz69A9wmNe5Wdrqk+D4gWYuPs2jyOT4/PDiDiK25pQr5g1v58LytL9zGusrK3Q1dXlaZjmTYynYWEUsNXe3Wbxgrk0a9FK3e+5eImSxMREM2XSBHr27pdqROK0fFS6DKvXb+ZFZCTx8fFYFyhAr099KFW67H/bqXzA2soaXV3dVIOShYWFYZvGcZs/7ydatmql7vdcoqQ7MTHRTJowjj79BqT7uJUuU5b1m/4k8t/jVqBAAbp26kCZMvnkuEl8zna59rbF6NGj6dWr1zvTjRo1ioiICI2Xnmv6+1m8D/EJSZy7+ZgGlVzVy1QqaFDJlZNXtffZNDbUI+mNu2dJicq/66b9w9DRUWGon9wn4tytIF7GJ9Kg8qvtlnAuQGEHS3W/a5G2+MQkzt99Sr0yr+baU6mgbtmCnLylvSWAiaFuquOW+O8UKypeHbfp3avSsooLrX7Yy/03+s+dv/uUlwmJGtst7miBi60ZJ/PDYFf/kRy3nKOjo5Oul/jwpSdGa4vPlT9JPYBUTkpUICA8Fne7Vze9VYC7nSl3wrSPCmygqyLpjYdbb54/ILlCXdHJnDn/3CfsjW4hBrrJvwPljaebScrbY7xIpq9vQKmPSnPq5HH1sqSkJE6dPE658hW1rhMbG5vq/KOj8+6pfNJiZm6OdYECBNy/x7WrV6hbv2GG88hv9A0M+Kh0GU4cfzVAb1JSEidO+FG+QiWt68TGxqJ64ymr7n84bubm5hQoUID79+9x9cpl6jfMPQ/hspPE5+yXa59UBwYGEhgY+M50hoaGqSYlz41Nv+duPMmSb705c/Mxp68/YnC7apgY6bPy39HAf/3Wm0ehkYxbehBIHtl7aPtqXPB/wslrDylWyJpxPeuy3e8WSf9G84mf12fXyds8CH6OuYkBPg3LULdCEbxH/g7A86g4Vuy4wLQBjXkaGUtkVByzhjTl+JVAGfk7nebvuMbCfjU5d/cpZ26HMuDjjzA11GPNoeQB4xb1r8mjZ9FM9D0PwM6zDxnYvBQX7yWnd3Mw57v2Fdh5LlB90TWzR1U61HSjy6yDvIiNVz9RfR4dT2x8Is9j4ll18DY/fOrBs6iXPI+OZ3r3qpy4GZI/RpDOAnLccojUBfKN9MRobfE5Nzb93ncrjO5VnAh4FsO9ZzE0LG6DoZ4OfvfDAehexYnwmAT+vBIMwMXHL2hUogCB4bHq5t/eZey5+DhSXUXuVLEgVV0sWeT3gLj4RCz+nZ4rJj6J+CSFoMg4gl/E0aWSI39cekLUy0QqOJlTyt6UBcce5MCn8OHp/FkPJo4dxUely1K6bDnWrVlJbEwMLVsnd12YMGYkdvb2DBo6AoA6deuzdvVvlCz1EWXLledBQAC/LJhLnbr11VP5REdHERjwauT2Rw8fcvP6NSwsLSnomDz7yr7dO7GyLkBBR0f8b91k9vQp1G3QiOo1a73nT+DD9Fn3nowd/S1lypSlbLnyrF71GzExMbRpmzyK+3ejvsHe3oFhw78EoF79Bqz6bTmlPipNufLJx23+vJ+oW7/Bq+MWFUXAa8ftYWAg169dw9LSEken5OO2e9cOrK0L4OjoxK1bN5g+ZTINGjamZq3a7/kTyCESn7Nd7qt9/mvlypU5XYQstfHgNWwtTRjXoy4O1qZcvP2E1iN91YOXudhbaNzpnrr6CIqiML5nXZxszQkNj2bbcX8m/FvpBrCzNmHpSG8KFjAjIiqOy3eC8R75O/vP3FOn+WbBHpIUhd/Hf4Khvi57T99l2E8739duf/A2H7+Prbkho9uXx97SmEv3n9Fu2n5CnicPguVsY6px3GZsuYSCwpgOFXEsYEzo8zh2ngvkf+vPq9P0buIOwLaxTTW2NXDxMdb+OwXU6NWnSVI8WDmsLgZ6uuy/9Igvl5/M5r3NO+S45YzsfMI2f/58ZsyYQVBQEBUqVGDevHlUq1YtzfRz5sxh4cKFBAQEYGtrS/v27ZkyZQpGRsk3Q6ZMmcKmTZu4fv06xsbG1KxZk2nTpuHu7p5t+5CX5KUYfSbwOWaGurQsbYeFkR6BEXHMOxJAZFzySN0FTPQ1uoDsuB4CKHiXscfKWI8XcYlcehyprnQD1CtWAIAR9Vw1tvXb6Yccvx9BkgI/H31A27L2DKxZGEM9HUJevOS304/eOoq4eKWJVzPCnz3ll4XzCAsNpaR7KeYsWIzNv4OXPXn8GJ3XnnD27NMflUrF4vk/ERIcjJW1NbXrNmDA4GHqNNeuXGFgnx7q/+f8OA2AFt5tGDdpMgChoSHM+XE6T8NCsbWzo1nL1nyegUGz8ruPmzXn2dOnLPh5LqGhIbiX+ogFi3/F5t/m30FvHLc+/QagUqmYP3cOwcFPsLYuQL36DRg8bLg6zZUrl+nds5v6/5nTpwDQqnVbJk2eCkBISAgzp08lLDQMOzs7WrZqTb/+A9/HLucK0gIm+6mUHOyhHxoayrJly/Dz8yMoKLn/UMGCBalZsyY9evTAzs4uU/kaN5qclcUU74lhwcI5XQQh8o3wNZ9meZ7mPr+lK12kb/cM5evr60u3bt1YtGgRnp6ezJkzhw0bNnDjxg3s7e1TpV+7di29evVi2bJl1KxZk5s3b9KjRw86derErFmzAPj444/p1KkTVatWJSEhgdGjR3P58mWuXr2Kqalpqjzzo+yI0QP+uJrVxRTvwZTmcrPpQ2SkL1MYfoiMsuGRZ3bFZ/FKjlWqT506hZeXFyYmJjRu3Fg9SfiTJ0/Yt28f0dHR7Nq1iypVqmQ4b6lUf5ikUi3E+5MdlWqLTul7evl8Xbd3J3qNp6cnVatW5eeffwaS++C5uLgwZMgQraNQDx48mGvXrrFv3z71si+//JITJ05w5MgRrdsICQnB3t6eQ4cOUbdu3QyVLy/KrhgtleoPk1SqP0xSqf4wZUelOrvis3glx5p/DxkyhA4dOrBo0aJUTRIURaF///4MGTIEPz+/NHIQQgiRm6h00te8TNtUS9r63wK8fPmSM2fOMGrUKPUyHR0dGjdunGZ8qFmzJqtXr+bkyZNUq1aNO3fusH37dj777LM0yxQRkTzfeIECBdK1D3mdxGghhMg70hufRebl2DBvFy5cYPjw4Vrb+KtUKoYPH8758+fff8GEEEJkikqlStdrypQpWFpaarymTJmiNc/Q0FASExPVT0pTODg4qJskv6lLly5MnDiR2rVro6+vT7Fixahfvz6jR4/Wmj4pKYkvvviCWrVqUbZsPple5R0kRgshRN6R3vgsMi/HKtUFCxbk5Mm0B/A5efJkqosoIYQQuVd6g7a2qZZefxL9Xx08eJDJkyezYMECzp49y6ZNm9i2bRuTJk3Smn7QoEFcvnyZdevWZVkZPnQSo4UQIu+QSnX2y7Hm31999RV9+/blzJkzNGrUKFV/rSVLljBz5sycKp4QQogMSm9ATquptza2trbo6ury5MkTjeVPnjyhYMGCWtcZO3Ysn332Gb179wagXLlyREVF0bdvX7777juNuTgHDx7M33//zeHDh3F2dk5XmfIDidFCCJF3SIU5++VYpXrQoEHY2toye/ZsFixYQGJi8tQVurq6eHh4sGLFCjp27JhTxRNCCJFB2RG0DQwM8PDwYN++fbRp0wZIbq69b98+Bg8erHWd6OhojYozoJ7PNGVsTkVRGDJkCJs3b+bgwYO4ublledk/ZBKjhRAi75BKdfbL0XmqfXx88PHxIT4+ntDQUCD5qYS+vn5OFksIIUQmZNdAKCNGjKB79+5UqVKFatWqMWfOHKKioujZsycA3bp1o1ChQup+2d7e3syaNYtKlSrh6emJv78/Y8eOxdvbW125HjRoEGvXruXPP//E3Nxc3T/b0tISY2PjbNmPD43EaCGEyBtkoLLsl6OV6hT6+vo4OjrmdDGEEEL8B9l1J9zHx4eQkBDGjRtHUFAQFStWZOfOneomyQEBARpPpseMGYNKpWLMmDE8fPgQOzs7vL29+eGHH9RpFi5cCED9+vU1trV8+XJ69OiRLfvxoZIYLYQQHzZ5Up39ckWlWgghxIcvO4P24MGD02zuffDgQY3/9fT0GD9+POPHj08zv5Rm4EIIIUReJ5Xq7CeVaiGEEFlDYrYQQgiR+0h8znZSqRZCCJEl5E64EEIIkftIfM5+UqkWQgiRJd4ccVsIIYQQOU/ic/aTSrUQQogsIXfChRBCiNxH4nP2k0q1EEKIrCExWwghhMh9JD5nO6lUCyGEyBJyJ1wIIYTIfSQ+Zz+pVAshhMgSErSFEEKI3Efic/aTSrUQQogsodKRoC2EEELkNhKfs59UqoUQQmQJuRMuhBBC5D4Sn7OfVKqFEEJkCQnaQgghRO4j8Tn7SaVaCCFElpCgLYQQQuQ+Ep+zn1SqhRBCZAnpsyWEEELkPhKfs1/erFRHPs3pEohMiDOzyekiiMwIC8zpEohcQu6Ei3dZ/+eFnC6CyISnL+JyuggiE7Yu3pDTRRCZEHNscpbnKfE5++XNSrUQQoj3ToK2EEIIkftIfM5+UqkWQgiRJSRmCyGEELmPxOfsJ5VqIYQQWULuhAshhBC5j8Tn7CeVaiGEEFlCRwZCEUIIIXIdic/ZTyrVQgghsoTcCBdCCCFyH4nP2U8q1UIIIbKE3AkXQgghch+Jz9lPKtVCCCGyhNwJF0IIIXIfic/ZTyrVQgghsoQMhCKEEELkPhKfs59UqoUQQmQJaV4mhBBC5D4Sn7OfVKqFEEJkCbkTLoQQQuQ+Ep+zn1SqhRBCZAmJ2UIIIUTuI/E5+0mlWgghRJaQO+FCCCFE7iPxOftJpVoIIUSWkJgthBBC5D4Sn7OfVKqFEEJkCRkIRQghhMh9JD5nP52cLoAQQoi8QaVSpeuVGfPnz8fV1RUjIyM8PT05efLkW9PPmTMHd3d3jI2NcXFxYfjw4cTGxv6nPIUQQogPUXbGZ5FMKtVCCCGyhEqVvldG+fr6MmLECMaPH8/Zs2epUKECXl5eBAcHa02/du1aRo4cyfjx47l27RpLly7F19eX0aNHZzpPIYQQ4kOVXfFZvCKVaiGEEFkiu+6Ez5o1iz59+tCzZ09Kly7NokWLMDExYdmyZVrTHzt2jFq1atGlSxdcXV1p2rQpnTt31ngSndE8hRBCiA+VPKnOflKpFkIIkSXSeyc8Li6O58+fa7zi4uK05vny5UvOnDlD48aN1ct0dHRo3Lgxfn5+WtepWbMmZ86cUVei79y5w/bt22nevHmm8xRCCCE+VPKkOvvlmoHKHj16xOLFi/H398fR0ZHevXtTqlSpnC6WEEKIdErvQChTpkzh+++/11g2fvx4JkyYkCptaGgoiYmJODg4aCx3cHDg+vXrWvPv0qULoaGh1K5dG0VRSEhIoH///urm35nJM7+TGC2EEB8uGags++XYk2oTExNCQkIAuHr1KqVLl2bt2rXEx8ezbds2PDw8uHjxYk4VTwghRAalt3nZqFGjiIiI0HiNGjUqy8px8OBBJk+ezIIFCzh79iybNm1i27ZtTJo0Kcu2kddJjBZCiLzjQxpIdOHChZQvXx4LCwssLCyoUaMGO3bs0MgjNjaWQYMGYWNjg5mZGe3atePJkyeZKn9WybEn1bGxsSiKAsDo0aOpW7cumzZtQk9Pj6SkJLp27cp3333HX3/9lVNFzHL92tdk+Kf1cbAx59Ktx4yYuZnTVx+kmX5wpzr0aVcDFwdrwiKi2Lz/ImPnbyfuZQIAfdrVoM8nNSjiWACAa3eDmPzrXnb7vXrSsmvhAOp6FNPId8kmP4ZO/SMb9jBv6te8DMPbVMDB2phL98IY8ctRTt8KSTP9YO9y9GlWGhdbM8IiY9l87A5jV54kLj4RgK/aVaRNDTdKOlsRE5fIietBfLfyBLceRqjz2PU/b+qWc9LId8nOqwxd+E/27GQe1O+TagzvXBuHAmZcuh3EiNnbOH3tYZrpB3eoQZ+21XBxsCQsPJrNB68wdvGeV7+3NlXp06YaRRytALh2N5jJKw6y+/gtAKzNjRn7eUMaVSuOi4MloeFR/HX4Gt//uo/nUdqbNuc16Y3HhoaGGBoapiutra0turq6qYLlkydPKFiwoNZ1xo4dy2effUbv3r0BKFeuHFFRUfTt25fvvvsuU3nmN/ktRn/eqASDm5fC3tKYKw+eMXLVGc7eeZpm+n5e7vRqWJxCNiY8jYxj66kHTNpwgbj4JAB6NixOz4YlKGxnCsD1hxHM2HKZfRcfq/P4sUdV6pVxoKC1MVGxCZzyD+V73/PcehyZvTubhzR1t8W7rD1WxvrcfxrD8pOB3A6NTjN984/saOJui62pAc/jEjhxP5zfzzwiPin5u96mrAPViljiZGnEy4QkboZEsebMIx4/f3UOdzA34NMqhShlb4qejg4XHj1n+YlAImITsn1/84p+n1RneNc6yfHZP4gRs/7i9LXANNMP7liTPm09cSloRVh4FJsPXGbsot2v4nNbT/q0rUYRR2vg3/i8bD+7j9/UyMezrAsT+jWlamkXEpOSuHjrMd5fLCf2Zd4/dtnVtDtl0M9Fixbh6enJnDlz8PLy4saNG9jb26dKnzKQ6LJly6hZsyY3b96kR48eqFQqZs2aBYCzszNTp06lRIkSKIrCb7/9RuvWrTl37hxlypQBYPjw4Wzbto0NGzZgaWnJ4MGD+eSTTzh69Gj27Gg65Irm32fPnmXNmjXo6SUXR0dHh2+++YYWLVrkcMmyTvvGFZj2RSuGTP2DU1cCGNypDlvn9qFCh+mEPHuRKr2PVyUmDWpO//+tx+/iPUoUtmPJOB8UReHbOckXMQ+fRDB2/nb8H4SiUsGnLaqwYWYPqn82m2t3Xl0sLt18nEm/7FL/Hx37Mvt3OI9oX7sY03rVYMjCfzh18wmDvcuzdUILKgxcR0hEbKr0PnWLM6lbNfrPO4Tf9SBKOFmxZFh9FAW+XZbcV7NOWScWbb/CmVsh6Omq+P6zavw9oQWVBq8nOu7ViX3prmtMWntK/f/r74m3a9+wLNMGN2PIzK2cuhrI4I412DqrOxU6/0RIeFSq9D5NyjOpfxP6T92C36UASrjYsOS7T5J/bz/vBOBhyHPGLtqNf2AYKpWKT5tVYsOULlTvtZBrd4NxtDXH0dacUfN3cu1uMIULWjHv61Y42lrQZey69/0R5IjsGOTEwMAADw8P9u3bR5s2bQBISkpi3759DB48WOs60dHR6OhoNsTS1dUFQFGUTOWZn+X1GN3GszCTulTiqxWnOHM7jH5e7mz4ugGe3/xNaGTqG2LtahRhXIcKDF16gpO3QilW0Jz5fTxRgLFrzwHw6Gk0E9ef586TSFQqFZ1qu7H6izrUH7uTGw+fA3Dh3lM2+t0jMCwaa1MDvmlblo3fNKDSiL9I+veGhkhbDVcrulUtxK/HH3ArJJrmpe0Y3bgYw7dc47mWCm4tN2s6ezix6GgAN4OjcLQ0ZECtIigKrDqdfMP1o4Jm7Loeyu2waHRVKjpVduS7JsX58s9rxCUkYainw+gmxQl4GsPEXf4A+FRy5JtGRRmz7SZy1N6tfaNyTBvanCEztnDqSiCDfWqydXZPKnSeRcgzbfG5ApMGeNF/8ib8Lt2nRGFblnzXHgX4du52AB4GRzB24S78H4QlXw83r8yGaZ9SvcfPXLubPKODZ1kX/pzVk5mrDjJi1l8kJCZRvrhjvvmtZdcgZK8P+gmwaNEitm3bxrJlyxg5cmSq9K8PJArg6upK586dOXHihDqNt7e3xjo//PADCxcu5Pjx45QpU4aIiAiWLl3K2rVradiwIQDLly/no48+4vjx41SvXj1b9vVdcqz59+vNDHR0dLC0tNR438rKimfPnuVE0bLF0C71WL7lBKv+PsX1u08YMvUPYmLj6e5dVWv66uVc8bt4D99d5wh4/Ix9J26yfvd5qpQurE6z/chVdh27zu0HofgHhDJh4U5eRL+kWtkiGnnFxL7kSVik+hWZT56aZYWhrcuxfPc1Vu27wfUH4QxZeJiYuAS6N9bel7B6KQf8rj3B97A/AcEv2Hc+kPWH/alSwk6dpvX321m9/ybXHjzj0r2n9P3pIIXtzalUzE4jr5i4BJ6Ex6hfkTHx2bqvecnQTjVZ/tdpVm0/x/V7IQyZ8Vfy761lZa3pq5d1we9SAL57LhIQFM6+U7dZv/cSVUo7q9NsP3qDXcdvcTvwKf4Pwpjwy15exLyk2r9prt4NpvOYdWw/eoO7j55x6OxdJvyyl+a13NHVzR9jQuroqNL1yqgRI0awZMkSfvvtN65du8aAAQOIiopSB/Fu3bppNB/39vZm4cKFrFu3jrt377Jnzx7Gjh2Lt7e3unL9rjzzu/wUowd+7M6qg7dZ+89dbjx6zpcrThETl0DXekW1pq9W3JaTt0L4w+8+D0KjOHg5iD+OB1C5qI06za7zj9h78TF3nrzgdlAkP2y8SFRsAlWK2arTrDx4G78bITwIjeLi/WdM/uMSzjam6qfb4u1alLZn360wDvo/5WFELL/6PeBlYhINittoTV/S3pQbwVEcvfuMkKiXXHwUybG7zyhua6JOM2XvbQ7dfkpgeCz3n8Ww4EgAdmYGFLUxBsDd3hR7UwMWHL3Pg/BYHoTHMv/IfYramFDW0fy97PeHbmin2izfeopV285y/V4wQ6b/SUzcS7q39NCavnq5wv/G5wvJ8fmkP+v3XqDKR6/H5+vs8rvJ7cCw5Pi8eE9yfC7jok4zfWgLFmw4xsxVh7l2N5hbAaH8sf8SL/9tRZjXpTc+5/RAom9KTExk3bp1REVFUaNGDQDOnDlDfHy8xnZLlSpF4cKFc3Sw0Ry70lMUhZIlS1KgQAEePXqUqm+Wv79/nmmGp6+nS6VShdh/6lUzFEVR2H/qFtXKFdG6zvFL96hUypkqpZNPCK5OBfCqWYqdx65pTa+jo6JDk4qYGhtw4tJ9jfd8Pq7Mg93fc/r3r5g4sBnGhvpZtGd5m76eDpWK2bH/wqsmw4oC+y8EUs3dQes6x68/oVIxW3Ul2tXBHC+Pwuw8k3YzfwsTAwCevdB88u1TrzgPVnXj9NwOTPysGsYGuaJhSa6nr6dLpZJO7D99R71MURT2n76tEWBfd/zyAyq5O1Hlo0IAuDpZ41W9JDv9bmpNr6OjokOjcpgaGXDiyluOrakRz6PiSExM+g979OHIrj5bPj4+zJw5k3HjxlGxYkXOnz/Pzp071QONBQQE8Pjxq2a1Y8aM4csvv2TMmDGULl2azz//HC8vLxYvXpzuPN/G1dWViRMnEhAQkOF9+VDklxitr6tDBdcCHLoSpF6mKHDo6hOqFrfVus5J/1AquBagctHkrldF7ExpUsGRvRceaU2vo1LR1rMwJoZ6nPYP1ZrGxECXLnXcuBf8godhaTdfFsl0dVQUtTHh0qNXTeUV4NKjSErYmWhd52ZwFEVtjCn2byXa3syASoUsOPdvywFtTAySL5NfxCVXvPR0VChAfOKrp5vxiQqKklzhFm+nr6dLJXcn9p/2Vy9Lvh6+TbWyhbWuc/xSwL/xObkS7epkjVcNd3b63dCaXkdHRYfG5ZPj8+Xk+GxnbUq1soUJeRbFgcX9uPf3aHbP70PN8tqvwfOi9MbnKVOmYGlpqfGaMmWK1jzfNuhnUFCQ1nW6dOnCxIkTqV27Nvr6+hQrVoz69eurBxJNcenSJczMzDA0NKR///5s3ryZ0qVLAxAUFISBgQFWVlbp3u77kGNX6cuXL9f4v3jx4hr/Hz9+nLZt277PImUbWytT9PR0CX6q2cw7+Gkk7kVS9zcA8N11DhtLU/YtGYRKpUJfT5df/jjGjBX7NdKVKVaQg0uHYGSgx4uYl/h8s4Lrd5+8ls9ZAoKe8TjkOeWKO/K/wS0oWcSeTt/+lvU7msfYWhihp6tDcHiMxvLg8Bjcna20ruN72B8bCyP2TWmNSpUcQH7ZcYUZG89pTa9SwYzeNTl29TFXA55p5BMQEsnjp9GUcy3A/7p5UrKQFZ2m7s6y/curbC1N0vi9vcC9iPaLZN89F7GxNGHfgt6vfm+bTzJj1WGNdGWKOnBwUZ9Xv7fRa7l+T3v/ehtLE0b1qM+yv05nzY59ALJzOo7Bgwen2TT74MGDGv/r6ekxfvx4xo8fn+k83+aLL75gxYoVTJw4kQYNGvD555/Ttm3bdPcT/xDklxhtY26YfJ5/rnlTMzgilhJpPHn8w+8+NmaGbBvTGBUq9PV0WL7vFrP/uqqR7iNnS3aOa4KRvi5RsQl0++kfbjzSrMD1alSc8T4VMTPS59aj57SbfoD4fHIT7r+wMNRFV0dFRKxmC66I2AScLI20rnP07jPMDfWY+HEJUKnQ01Gx+0YIWy5pH9xIBXSv6sz1Jy94EJ78/bgVEk1cQhJdPZz4/ewjVCoVXSo7oaujwtpYHli8i63V2+KzndZ1fPdcwMbKhH2L+r6Kz5tOMGPlIY10ZYo6cPCX/q/i86jVXL+X3PTbzSn5Bth3nzdi1M/buXjrMV0/rsT2uZ/j8elP3A4My4a9zV3SG59HjRrFiBEjNJZlZWx7fSBRT09P/P39GTZsGJMmTWLs2LHqdO7u7pw/f56IiAg2btxI9+7dOXTokLpinRvlWKW6e/fub33/9Q/2beLi4lI1S1CSElDpfNhP9epULsbXPRsybPomTl0OoJiLLTNHtOZxr8ZMXbZXne7m/RA8P52FpZkRbRuWZ8n4TjTtv1BdsV625VUfhSu3g3gcFsnOBf1xK2TD3Yd5/yTyvtUp68jX7SsxbPERTt0MppijBTN71+Rxx8pMXX82Vfo5/WpTpnABGo36U2P5st2vWiRcuf+Ux0+j2fk/b9wKWnA3KO276iJz6lRy5evP6jLsx785dTWQYs4FmDmsOY9D6zP1t4PqdDcDQvHsuSD591a/DEu+a0fTIUtTVazNTQzZPONTrt0L5n9L95NfZFefrdzmiy++4IsvvuDs2bOsWLGCIUOGMHDgQLp06UKvXr2oXFl7N4MPSVbEaK3xOTEele6HXfmoVcqeL7xL8/VvpzlzO4yiDuZM/rQyX4aX4cc/r6jT+T+OpP6YnViY6NOqamHm961Oq8n7NCrWG47d5+DlIBysjBnUrBRLB9Wi+f/2qAc8E1mntIMZbcs7sPREILdCoihoYUiPqs48Kx/PpoupK9a9qjvjYm3E+B231Msi4xKYfegun1d34eOP7FCU5Mr6nbBokqRHdbaoU8mNr7vVZ9jMrZy68oBizjbM/KIlj3s0YOqKA+p0NwNC8ew+Lzk+NyjLkjEdaDpoCdfvBaPzb2xauuUkq7YlX4tduPmY+lWK0b2lB+MW5f0HFumNzzk9kGjKeCgGBgbqm7keHh6cOnWKn376icWLF1OwYEFevnxJeHi4xtPqjAw2mpiYyIoVK9i3bx/BwcEkJWmec/fvz/i12wff0U9bM4WEx28fyv19Cw2PIiEhEfsCZhrL7QuYExSmvYI0vr8Xv28/y4o/T3LldhBbD15m3IIdfN2jocYPIz4hkTuBYZy7/pBxC3Zw6dYjBvnUTrMspy4nN1cs5qK9z5F4JfR5LAmJSdhbGWsst7cyJuhZjNZ1xnepyu8Hb7Fiz3Wu3H/K1uP3GLfqFF+3r5jqLuHsvrVoXrUIXmP+4mFY6sE5XnfqZvLd1mKOFpnfoXwiNCI6jd+bGUFhqQcFBBjfuxG/77rAir/PcOXOE7Yevsa4xXv5+rM6qX9vD59y7sYjxi3ew6XbQQzqUEMjLzNjA7b+2I3I6Jf4jP6dhHz01EmlSt8rr6hcuTJz587l0aNHjB8/nl9//ZWqVatSsWJFli1bph49O7/SFp9jLv/57hXfo7DIuOTzvIXm0017SyOCtQxGCTCqXTnWH7vH6kN3uBYYwbYzgfxvw0W+aFla4/sdn5jE3eAXXLj3jEkbLnDlQTh9m7pr5BUZE8+dJy/wuxFCz3lHKeFkQQsP7d1UxCvP4xJJTFKwNNK8QWNppEd4GuOPdKzkyOHbT9l/K4wH4bGcCojg93OPaFOuIG+elnp6OlPZ2ZKJu/x5Gq2Z38VHkQzbdJW+vpfove4S84/cp4CJPsGRMgjsu4SGvyU+P9U+6v34Pk34fec5Vvx1+t/4fJVxi3fzdbd6acfnRbu55P+YQR1rAvA4LDnva/8+uU5x414ILg5WWbiHuVd2xOfXB/1MkTLoZ0r/5ze9ayDRtCQlJalv0np4eKCvr6+x3Rs3bhAQEJDmdt80bNgwhg0bRmJiImXLlqVChQoar8zItY9zR48eTVBQEMuWLXtrOm3NFOwbjsvOomVYfEIi564/pEHVEvx1KPkutkqlokGV4izaoH3od2NDg1QjEqbcRVGpkvt8aaOjo4PhW/reViiZPE1TUKhM2fEu8QlJnLsdQoPyhfjrxD0g+bNvUL4Qi7Zf0bqOsaEeSUlpHTeV+oQxu28tWlV3o+l3W7kf/O5jUcEt+SZI0FPpa/cu8QmJnLv5iAYeRfnrn+Qn/iqVigYeRVm06YTWdYyN9DP3e1OpMNTXVf9vbmLIX7O6ERefSPtv16in+8gvdDMxCNmHLD4+ns2bN7N8+XL27NlD9erV+fzzzwkMDGT06NHs3buXtWvX5nQxs0V6YrS2+Ow6YEs2lyxj4hOTuHDvKXXLFGT72eTxM1QqqFvagV/3ah9TwdhAD+WN83ziv/+rUKGk8cQy+XyR9rMMlSq5ybGh3gf/vCPbJSYp3AmLppyjOacfJE9HqQLKOpqz67r2fuuGejqpzuXqw6iClMPW09OZaoUt+X6nPyEv0q4oR/7bz7pMQTMsjPTU5RBpi09I5NyNRzTwKM5fh1+Lz1WKsegP7QNMZTo+67yKz/cfP+NRSAQlC2t2ASte2JbdaYydktdkV3weMWIE3bt3p0qVKlSrVo05c+akGki0UKFC6n7Z3t7ezJo1i0qVKqmbf785kOioUaNo1qwZhQsXJjIykrVr13Lw4EF27UqeycjS0pLPP/+cESNGUKBAASwsLBgyZAg1atRI98jf69atY/369WkOkJYZubZSHRgYSGBg2nPWpdDWTCE3Nv2eu/YQS8Z34sy1QE7/O6WWibEBK/9OnjLp1wmdeBQcwbgFyZObbz9ylaGd63LhxkNOXgmgmLMN4/p9zPZ/rqorbRMHNmOX3w0eBD3D3MQQH69K1K1cFO+hSwBwK2SDj1cldh27RlhENOWKOzJ9eCv+OXuby/6PtRdUaJj75yWWDKvPGf8QTt8KZrB3OUyM9Fm5N3mAjF+/aMCjsCjGrUpuHbH91H2Gti7PhbuhnLyR3Px7XNeqbD8VoD5uc/rVxqducTpM3sWLmHgc/n0SHhH9ktiXibgVtMCnbnF2nQkgLDKWcq42TO9Vg38uP+Ly/bTnTRWvzF13jCXffcKZ6w85fe0hgzvWSP69/dvs69cx7XgU8pxxi/cAySN7D/WpyYWbjzl59QHFCtkwrncjth+98er31q8Ju47f5MGTiOTfW5Py1K3kiveIlUByhfrv2d0xNtSn58S1WJgaYmGafG4KCY9KdbMlL8ovzb/Pnj3L8uXL+f3339HR0aFbt27Mnj2bUqVezQrQtm1bqlbVPrtDXpCeGK01PufCpt8Ldt5gfp/qnL/7lLN3wujX1B0TQz3WHr6b/H7f6jx+FsOkDRcA2HX+IQM/LsXF+8/Uzb9HtSvHrvMP1Rf/YztUYO/FRwSGRWNmpEf7Gq7UKmVPhxkHgeTBzdp6FuHA5ceERsbhZG3CsJYfERufyJ40BjwTmrZdDWZg7SLcDovmdmgUzT+yx1BPh4P+yV3bBtUuwtPol/x+Nvl658yDCFqUtufe02huhUZT0NwQn4qOnHkQoa6Yfe7pTK2i1szYf5eY+EQsjZKvJ6PjE9WDk9UvXoCH4bE8j0ughJ0pPao6s/1qiMZc1iJtc9cdYcmY9py5Hsjpq4EM9qmFiZEBK//+Nz6PbZ8cn/9tkr396HWGdqqVHJ//bf49rk8Tth+5/io+92+aHJ+DwpPjc9MK1K3khvfwFertzl7zD2N6N+aSfxAXbj7i0+aVcS9iR5fv8uaNzzdlV3z28fEhJCSEcePGERQURMWKFVMNJPr6k+kxY8agUqkYM2YMDx8+xM7ODm9vb3744Qd1muDgYLp168bjx4+xtLSkfPny7Nq1iyZNmqjTzJ49Gx0dHdq1a0dcXBxeXl4sWLAg3eV+vXl5Vsl9tc9/rVy5MqeLkKU27r2ArbUZ4/p64WBjzsWbj2g97Ff1YA0uDtYaF91Tl+1FURTG9/8YJztLQsNfsO2fq0xYuEOdxq6AGUvHd6KgrQURL2K57P8I76FL2H8yuf9PfHwCDauVYHDnOpgaGRD4JJwtBy5p9MkWb7fxyG1sLYwY16UKDtYmXLwbSuvvtxMckdz828XWTPO4rT+LosD4rlVxKmBK6PMYtp0KYMLqV10S+jVPnrh+z+RWGtvq89MBVu+/SXxCIg0rFGKwdzlMjfQIDI1ii99drX2yhXYb91/G1sqUcb0b4VDAjIv+j2n95UqC/50D08XBUqP/zNTfDiUftz6NcLKzIDQ8im1HbzDhl1e/FTtrU5aOaUdBG3MiomK5fPsJ3iNWsv/0bQAqujuqRxe/ul7z6Zx7+x8JCArP5r3OefnlQXXVqlVp0qQJCxcupE2bNujrp64ourm50alTpxwo3fuRl2L0lhMB2JobMvKTcthbGnE54BkdZxwk5N/BywrZmGg8KfvxzysoCoxuXx5Ha2PCIuPYde4h/9v4aoR0WwtDFvStjoOVMc9j4rn6IJwOMw5y8N9RxuPik6jubkc/L3esTPUJiYjl2I0Qmk3co3VubJGa371wLIz06FjREStjPe49jWHK3ttE/DtHtY2p5hPOTReTP3ufSk4UMNHneWwCZwIjWHf21UOGpqWSB8ua8HEJjW0tOHKfQ7eTb2o7WhjRubITZga6BL94yeZLQWy7qn3ASpHaxn2XkuNzn8Y4FDDn4q3HtB6xnOBnKdfDVprXVSsOJF8P922SHJ+fRbHt6HUmLH7VD9rO2oylYzu8is/+QXgPX8H+U69GGf95/TGMDPWYPrQ51hYmXPJ/TMthy7j7MH88rMjO+JzVA4kuXbr0nds0MjJi/vz5zJ8/P0NlTfHll1/y008/8fPPP2fZDQeVkoOdvkJDQ1m2bBl+fn7qIdALFixIzZo16dGjB3Z22kcCfBfjal9lZTHF++JY4t1pRO4T9u4WJSL3iTkyKcvzbL4ofeNZbO9fLcu3/T7dv3+fIkXy/lQs2RGjbbr9ntXFFO9B40al3p1I5DpbF2/I6SKITIg5NjnL88wv8Tm92rZty4EDByhQoABlypRJdXN806ZNGc4zx55Unzp1Ci8vL0xMTGjcuDElS5YEkkdumzt3LlOnTmXXrl1UqVIlp4oohBAiA/JJ62+Cg4MJCgrC09NTY/mJEyfQ1dXNE3FLYrQQQuQd+SU+p5eVlVWWTwuZY5XqIUOG0KFDBxYtWpTqsbuiKPTv358hQ4bg56d94AIhhBC5i24+idqDBg3im2++SVWpfvjwIdOmTePECe0D4n1IJEYLIUTekV/ic3otX748y/PMsUr1hQsXWLFihdZ27CqViuHDh1OpUqUcKJkQQojMyC8DlV29elXrXNSVKlXi6tWrOVCirCcxWggh8o78Ep8zKiQkhBs3kgcfdnd3z3TXY8jBeaoLFizIyZNpt+8/efKkeuQ4IYQQuV9+mafa0NCQJ0+epFr++PFj9PRy7fifGSIxWggh8o78Ep/TKyoqil69euHo6EjdunWpW7cuTk5OfP7550RHZ2762kxH/6tXrxIQEMDLl5pz+LVq1SqNNTR99dVX9O3blzNnztCoUSN1cH7y5An79u1jyZIlzJw5M7PFE0II8Z7p5JOI3LRpU0aNGsWff/6JpaUlAOHh4YwePVpjyo+c8l/jM0iMFkKIvCS/xOf0GjFiBIcOHeKvv/6iVq1aABw5coShQ4fy5ZdfsnDhwgznmeFK9Z07d2jbti2XLl1CpVKRMnh4SrOCxMTEdOUzaNAgbG1tmT17NgsWLFCvp6uri4eHBytWrKBjx44ZLZ4QQogckl9i9syZM6lbty5FihRRN4E+f/48Dg4OrFq1KsfKlVXxGSRGCyFEXpJf4nN6/fHHH2zcuJH69eurlzVv3hxjY2M6duz4firVw4YNw83NjX379uHm5sbJkycJCwvjyy+/zPBdax8fH3x8fIiPjyc0NBQAW1tbrXN+CiGEyN108slE1YUKFeLixYusWbOGCxcuYGxsTM+ePencuXOOxq+sjM8gMVoIIfKK/BKf0ys6OlprFyZ7e/v31/zbz8+P/fv3Y2tri46ODjo6OtSuXZspU6YwdOhQzp07l+FC6Ovr4+jomOH1hBBC5B75qXmZqakpffv2zeliaMiO+AwSo4UQ4kOXn+JzetSoUYPx48ezcuVKjIyMAIiJieH777+nRo0amcozw5XqxMREzM3NgeQ71o8ePcLd3Z0iRYqoR08TQgiR/+S3kJ0VfZezksRnIYQQ2uS3+PwuP/30E15eXjg7O1OhQgUgedYLIyMjdu3alak8M1ypLlu2LBcuXMDNzQ1PT0+mT5+OgYEBv/zyC0WLFs1UIYQQQnz48suUHVnZdzkrSXwWQgihTX6Jz+lVtmxZbt26xZo1a7h+/ToAnTt3pmvXrhgbG2cqzwxXqseMGUNUVBQAEydOpGXLltSpUwcbGxt8fX0zVQghhBAfvvzSZSur+y5nFYnPQgghtMkv8TkjTExM6NOnT5bll+FKtZeXl/rv4sWLc/36dZ4+fYq1tbXcBRFCiHwsvwyEkl19l/8ric9CCCG0yS/x+W22bt1Ks2bN0NfXZ+vWrW9Nm5luXJmep/p1BQoUyIpshBBCfMDyS8XtQ+q7LPFZCCFEfonPb9OmTRuCgoKwt7enTZs2aaZTqVSZ6saV4Up1VFQUU6dOZd++fQQHB5OUlKTx/p07dzJcCCGEEB++/HIjPLf2XZb4LIQQQpv8Ep/f5vWY+GZ8zAoZrlT37t2bQ4cO8dlnn+Ho6Ch3PoQQQgD55054bu27LPFZCCGENhIP3i08PBwrK6tMr5/hSvWOHTvYtm0btWrVyvRGhRBC5D26+SRo59a+yxKfhRBCaJNf4nN6TZs2DVdXV3x8fADo0KEDf/zxB46Ojmzfvl09zVZG6GR0BWtra+mjJYQQIhWVKn2vD1l8fDx6enpcvnxZY3mBAgVy/EmAxGchhBDa5If4nBGLFi3CxcUFgD179rB371527txJs2bN+PrrrzOVZ4Yr1ZMmTWLcuHFER0dnaoNCCCHyJpVKla7Xh0xfX5/ChQvn2FzUbyPxWQghhDb5IT5nRFBQkLpS/ffff9OxY0eaNm3KN998w6lTpzKVZ7qaf1eqVEnjg/b398fBwQFXV1f09fU10p49ezZTBRFCCPFhyy/x+LvvvmP06NGsWrUqx58MS3wWQgjxLvklPqeXtbU1Dx48wMXFhZ07d/K///0PAEVRMn3TPF2V6rcNOy6EEEIA6OSTqP3zzz/j7++Pk5MTRYoUwdTUVOP991l5lfgshBDiXfJLfE6vTz75hC5dulCiRAnCwsJo1qwZAOfOnaN48eKZyjNdlerx48dnKnMhhBD5h04+mbMjN1VkJT4LIYR4l/wSn9Nr9uzZuLq68uDBA6ZPn46ZmRkAjx8/ZuDAgZnKM8Ojf6c4ffo0165dA6B06dJ4eHhkNqusFx+b0yUQmfFS+gF+kGycc7oEIpfI8CAdGTB//nxmzJhBUFAQFSpUYN68eVSrVk1r2vr163Po0KFUy5s3b862bdsAePHiBSNHjmTLli2EhYXh5ubG0KFD6d+//zvLktsrsrk5PkdfOprTRRCZULZb1ZwugsiEkuN65nQRRC6RnfH5Q6Svr89XX32Vavnw4cMznWeGK9WBgYF07tyZo0ePqufyCg8Pp2bNmqxbtw5nZ7nAFkKI/Ci7Bjnx9fVlxIgRLFq0CE9PT+bMmYOXlxc3btzA3t4+VfpNmzbx8uVL9f9hYWFUqFCBDh06qJeNGDGC/fv3s3r1alxdXdm9ezcDBw7EycmJVq1aZct+ZDeJz0IIIbTJT4OQpWXr1q00a9YMfX19tm7d+ta0mbkOyHClunfv3sTHx3Pt2jXc3d0BuHHjBj179qR3797s3Lkzw4UQQgjx4cuu1mWzZs2iT58+9OyZ/NRl0aJFbNu2jWXLljFy5MhU6d8cPGzdunWYmJhoVKqPHTtG9+7dqV+/PgB9+/Zl8eLFnDx58p3BVEdH560XKDk1MrjEZyGEENpI6+/krltBQUHY29u/tRuXSqXKVBzPcKX60KFDHDt2TB2wAdzd3Zk3bx516tTJcAGEEELkDdkRtF++fMmZM2cYNWrUq+3o6NC4cWP8/PzSlcfSpUvp1KmTxoBiNWvWZOvWrfTq1QsnJycOHjzIzZs3mT179jvz27x5s8b/8fHxnDt3jt9++43vv/8+nXuW9SQ+CyGE0EYq1ZCUlKT176yS4Uq1i4sL8fHxqZYnJibi5OSUJYUSQgjx4dFNZ9SOi4sjLi5OY5mhoSGGhoap0oaGhpKYmIiDg4PGcgcHB65fv/7ObZ08eZLLly+zdOlSjeXz5s2jb9++ODs7o6enh46ODkuWLKFu3brvzLN169aplrVv354yZcrg6+vL559//s48soPEZyGEENqkNz6LzMtwv/UZM2YwZMgQTp8+rV52+vRphg0bxsyZM7O0cEIIIT4cKlX6XlOmTMHS0lLjNWXKlGwp09KlSylXrlyqQc3mzZvH8ePH2bp1K2fOnOHHH39k0KBB7N27N9Pbql69Ovv27fuvRc40ic9CCCG0SW98zi+GDh3K3LlzUy3/+eef+eKLLzKVp0pRFCUjK1hbWxMdHU1CQgJ6eskPulP+fnOuzqdPn2aqUP+VcaXBObJd8R8VLJbTJRCZYWCS0yUQmRDzZ78sz3Pk9pvpSvd9oyLpflL98uVLTExM2Lhxo0YfqO7duxMeHs6ff/6Z5naioqJwcnJi4sSJDBs2TL08JiYGS0tLNm/eTIsWLdTLe/fuTWBgYKb6HsfExDBq1Ch27NjBjRs3Mrx+VpD4LLLL6Blf5HQRRCa8TMjQJb7IJSZ9XCLL80xvfJ7avGSWbzs3KlSoEFu3bk01O8bZs2dp1aoVgYGBGc4zw82/58yZk+GNCCGEyPvS2/QprQq0NgYGBnh4eLBv3z51pTopKYl9+/YxePDbK2gbNmwgLi6OTz/9VGN5fHw88fHx6OhollhXVzdd/aysra01BipTFIXIyEhMTExYvXp1uvYrO0h8FkIIoY1MqaUpLCwMS0vLVMstLCwIDQ3NVJ4ZrlR37949UxsSQgiRt2VX07ERI0bQvXt3qlSpQrVq1ZgzZw5RUVHq0cC7detGoUKFUjUhX7p0KW3atMHGxkZjuYWFBfXq1ePrr7/G2NiYIkWKcOjQIVauXMmsWbPeWZ7Zs2drVKp1dHSws7PD09MTa2vrLNjjzJH4LIQQQpv81LQ7PYoXL87OnTtT3ZzfsWMHRYsWzVSe6apUP3/+PN0ZWlhYZKogQgghPmzZNRCKj48PISEhjBs3jqCgICpWrMjOnTvVg5cFBASkeup848YNjhw5wu7du7XmuW7dOkaNGkXXrl15+vQpRYoU4YcffqB///7vLE+PHj3+8z5lFYnPQggh3kUGKtM0YsQIBg8eTEhICA0bNgRg3759/Pjjj5lu9ZWuSrWVldU7Jw1XFCXT83oJIYT48GVnzB48eHCazb0PHjyYapm7uztvGzKkYMGCLF++PFNlWb58OWZmZhrzXkNyc/Po6Oj3+sRY4rMQQoh3kTq1pl69ehEXF8cPP/zApEmTAHB1dWXhwoV069YtU3mmq1J94MCBdGV26dKlTBVCCCHEh08nn7QvmzJlCosXL0613N7enr59+77XSrXEZyGEEO+SX+JzRgwYMIABAwYQEhKCsbExZmZm/ym/dFWq69Wrl+Z7kZGR/P777/z666+cOXPmnQPHCCGEyJvyS8wOCAjAzc0t1fIiRYoQEBDwXssi8VkIIcS75Jf4nBEJCQkcPHiQ27dv06VLFwAePXqEhYVFpirYmR4M7vDhw3Tv3h1HR0dmzpxJw4YNOX78eGazE0II8YHTUaXv9aGzt7fn4sWLqZZfuHAh1aBoOUHisxBCiNfll/icXvfv36dcuXK0bt2aQYMGERISAsC0adP46quvMpVnhkb/DgoKYsWKFSxdupTnz5/TsWNH4uLi2LJlC6VLl85UAYQQQuQNuvnkVnjnzp0ZOnQo5ubm1K1bF4BDhw4xbNgwOnXqlCNlkvgshBAiLfklPqfXsGHDqFKlSqqb4W3btqVPnz6ZyjPdT6q9vb1xd3fn4sWLzJkzh0ePHjFv3rxMbVQIIUTek1/uhE+aNAlPT08aNWqEsbExxsbGNG3alIYNGzJ58uT3Xh6Jz0IIId4mv8Tn9Prnn38YM2YMBgYGGstdXV15+PBhpvJM95PqHTt2MHToUAYMGECJEiUytTEhhBB517tGoc4rDAwM8PX15X//+x/nz5/H2NiYcuXKUaRIkRwpj8RnIYQQb5Nf4nN6JSUlaZ0RIzAwEHNz80zlme4n1UeOHCEyMhIPDw88PT35+eefCQ0NzdRGhRBC5D357U54iRIl6NChAy1btsyxCjVIfBZCCPF2+S0+v0vTpk015qNWqVS8ePGC8ePH07x580zlme5KdfXq1VmyZAmPHz+mX79+rFu3DicnJ5KSktizZw+RkZGZKoAQQoi8QVdHla7Xh65du3ZMmzYt1fLp06enmrv6fZD4LIQQ4m3yS3xOr5kzZ3L06FFKly5NbGwsXbp0UTf91hbf0yPDo3+bmprSq1cvjhw5wqVLl/jyyy+ZOnUq9vb2tGrVKt35eHt7s2rVKmJiYjJaBCGEELlQfrkTfvjwYa13sps1a8bhw4dzoETJsio+g8RoIYTIS/JLfE4vFxcXLly4wHfffcfw4cOpVKkSU6dO5dy5c9jb22cqz0xPqQXg7u7O9OnTCQwM5Pfff8/Qutu2baNXr144OjoyYMAAzpw581+KIoQQIoepVOl7fehevHiRanATAH19fZ4/f54DJUrtv8RnkBgthBB5SX6Jz+kRHx9PsWLFuHXrFl27dmX69OksWLCA3r17Y2xsnOl8MzSlVlp0dXVp06YNbdq0ydB6Fy5cYPfu3SxbtoxffvmFcuXK0bt3b7p27Yq1tXVWFC1X6dexLsO7N8LBxoJLNx8yYtoGTl+5n2b6wV3q06dDHVwKWhMWHsXmvecYO28rcS8TAOjToTZ92tehiFMBAK7dCWLyLzvYffSqOg8HG3Mmf9GWhtVLYW5qyM17wUxfuost+85n677mJf1aVmB4ew8crE25dCeEEQsPcPrmkzTTD25TiT4tyuNiZ0HY8xg2H7nF2OVHiItPHhDhq45VaVOrOCWdCxDzMoETVx/x3bIj3Hr4DIDC9hbc+O1zrXl3/eFvNh25lfU7mQf1a16G4W0q4GBtzKV7YYz45Sinb4WkmX6wdzn6NCuNi60ZYZGxbD52h7ErT746bu0q0qaGGyWdrYiJS+TE9SC+W3mCWw8j1Hns+p83dcs5aeS7ZOdVhi78J3t2MpfRIX9E5HLlyuHr68u4ceM0lq9bty7XTV+V2fgM+StGv+/4XNixADe2T9Sad9evl7Jp77ks3sO86cahv7m69w9inj/DupAbVTv2x9bVPc301/Zv4eY/24l+FoKhqQWFK9WiUuse6Oon3yS7vGs9AeeP8fxJILr6BtgV/YhKbXpi6eAMwIuwJ2wZ10tr3nU+H0mRynWyfifzoFv//M2N/ZuIff4Mq0JuVGrXD5siaR+3mwf/5PbR5ONmYGqBc4ValPfurj5u1/asJ/CCH5HBycfNxu0jynv3wOLf4xYV9oRtE7VfV9XoMRKXSrWzfidzmfwSn9NDX1+f2NjYLM9XpSiKkuW5poOOjg5BQUHqR+wnT55k6dKl+Pr68vLlS9q0aUPv3r1p2LBhhvM2rjQ4q4v7n7VvWplfJ33GkB98OXX5HoO7NOCTJpWo0GYiIc9epErv83EVFk3oSv8Ja/C7cIcSRexZMvEzNuw6w7c/bgKged2yJCYl4R8QggoVn3p7Mrx7I6p3msq1O0EA/LVgEFbmxgyfuoHQ8Bf4NKvC2P4tqNV1OhduBL7Xz+CdChbL6RKk0r5uSX79yosh8/Zx6kYQg9tU5pPaJajQZwUhEambRfrUd2fR8Kb0n70bv6uPKeFsxZIRXmw4dINvlyQ3C/1zUls2HLrBmZtP0NNV8X2PWpQpYkulfr8RHZeAjo4KO0vNO2W9mpVjeLsquHX9hajY+Pey7+lmYJLTJUilfe1i/PpFA4Ys/IdTN58w2Ls8n9QqSoWB6wiJSH0i9albnEVD6tF/3iH8rgdRwsmKJcPqs+Gf23y7zA+AP8c3Z8M//py5FZJ83D6rRpnCBag0eD3RcckX0rv+582tRxFMWntKnXd0XAKRMbnsmAExf/bL8jwXHLuXrnQDa7pm+bbfp7/++otPPvmELl26qGPUvn37WLt2LRs3bsxUBTa3ya4YLfE5OT7r6KiwszbTyLdXu1oM79YYtyajiYp5+V72Pb1Gz/gip4uQyr0zhzm28kc8Ow3GxtWd6we2EHD2CK3G/4KRuVWq9HdPHcRv9RxqfPoFdkU/4nnwQ/xWzaaIR12qtEuel3bfz2Nx9aiLTZGSKEmJnNv6GxGP7uM9dhF6hkYkJSUSFxmhke+tozu5uncT7SavQt8o80+5ssPLhBy5xH+rgLOHObl6Fh4dB1HA1Z1bB//kwfkjNPtusdbjdv/0QU79/hNVOw/D1u0jIkMecnLNHApXrkPFtsnH7fDCcbhUrkuBwiVQkhK59PdKIh7f5+NRC18dtxearYjuHNvJjf2b8J60En3D3HXcJn2c9bM45Jf4nF6TJ0/m5s2b/Prrr+jpZckz5qx5Up0VqlWrRrVq1Zg9ezbr169n6dKlNGnSROtw5x+ioZ82ZPmmY6zaehyAIT+so1mdMnRvU4OZy/ekSl+9ght+5+/gu/M0AAGPn7J+52mqlnVVp9l++LLGOhPm/0WfDrWpVt5NXamuXqEoQyevU99xn/brLoZ0bUil0i65r1KdCw1tW5nlOy6zak/y04Uh8/bSrKob3ZuWZeaGU6nSV//ICb+rj/A9eAOAgODnrD94g6qlCqrTtB67WWOdvrN282BdfyqVcODo5YckJSk8eRatkaZVzeL88c/N3FehzqWGti7H8t3XWLUv+TgMWXiYZlUK071xKWb+cT5V+uqlHPC79gTfw/4ABAS/YP1hf6qWfNWvpvX32zXW6fvTQR6s6k6lYnYcvfpYvTwmLoEn4fmzH6pePumQ5e3tzZYtW5g8eTIbN27E2NiYChUqsH//fgoUKJDTxcsWeTlG50R8TkpSeBKmOYBcqwYV+GPP2VxXoc6tru3bTPGaH1OsRhMAPDsN5uHl0/j77aZs046p0ofcuYZ90dK4Va0PgJmNA64e9Qi9d0OdptHgSRrr1PxsBBtHdiEswB+HEmXR0dHF2FLzN/7ggh9FKtfOdRXq3OrmwS0UremFW/Xk4+bRcRCPr57i7vE9fNQk9UCPYfeuYev2EUWq1AfA1MaBwpXr8vT+TXWaugM0W31U7Tqcrd915dkDf+yK/3vcLDRb1zy86IdLxdq5rkKdXfJLfE6vU6dOsW/fPnbv3k25cuUwNTXVeH/Tpk0ZzvM/9anODiYmJvTo0YN//vmHa9eu5XRxsoS+ni6VPnJh/4lXJ25FUdh/4gbVyrtpXef4hbtUKu1ClTLJ07S4FrLBq1YZdh65ojW9jo6KDl4emBobcOLi3dfyuUP7ph5YW5igUiWnMTLU4/BpaUL8Lvp6OlQq4cD+8wHqZYoC+88HUO0jR63rHL/2iErF7alS0gEA14KWeFV1Zeepu1rTA1iYJDdfehapvSlKpeL2VCxmz2+7Lmt9X2jS19OhUjE79l94qF6mKLD/QiDV3B20rnP8+hMqFbOlSgk7AFwdzPHyKMzOMw/S3I76uL3QPG4+9YrzYFU3Ts/twMTPqmFskGvuXWa7/NRnq0WLFhw9epSoqCju3LlDx44d+eqrr6hQoUJOFy1b5bUYnZPx+XWVPnKhYikXftvi9x/3KH9ITIjn6QN/HEtVVC9T6ejgWKoioXeua13HruhHhD3wV1eiI0Mf8/DKKQqVqZLmduJjogAwNDXT+n5YwC2eBd6heM2mmdyT/CUxIZ5nD/xxKFlRvUylo4N9yYqE3dN+3GxcP+JZ4G3C7icftxehQTy+dpqCpd993AxMtB+3pw/8CX94B7ca+ee45af4nB5WVla0a9cOLy8vnJycsLS01HhlRo5d7dWrV0/rQC+vK1my5HsqTfaytTZDT0+X4Kead6WDw57j7qr9It9352lsrE3Zt3w4KlTo6+vyy4Z/mLFst0a6MsWdOPjblxgZ6PEiJg6fL5dw/d+n1ACffrOMVdN68ejQdOLjE4mOfYnPiCXceSBzmL6LrYUxero6BL/x1Dj4WTTuztr7E/oevIGNhTH7ZvqgUiVfsP2y7QIzfFM/1YbkE9iMfvU5duUhV++HaU3T3ass1wLCOH7tsdb3hSZbC6Pk4/bG0+Lg8Bjcna20ruN72B8bCyP2TWn96rjtuMKMjdr7NapUMKN3TY5dfczVgGca+QSERPL4aTTlXAvwv26elCxkRaepu7Xmk9fo5KeITPIo4EuXLuWPP/7AycmJTz75hPnz5+d0sbJEfonRORmfX9e9TQ2u3XnM8Qtp34AVr8S9eI6SlJSqubCRuRURQdpvhrpVrU/ci+fsnvUNiqKgJCVSonZzyn7sozW9kpTE6T9+wa5oaaycXLWmuX1sN5YFXbArmrvGUsitXkYlHzdDLcctMlh768kiVeoTF/WcAz99qz5uxWo1o7SW1giQfNzOb1qCrVtpLNM4bnf9dmPh4IKt20f/ZXc+KPktPqclKSmJGTNmcPPmTV6+fEnDhg2ZMGHCfxqgLEWOPak+cOAAVlZW/zmfuLg4nj9/rvFSkj785mh1PErwdS8vhk3xpUaXafiM+IVmtcswss/HGulu3nuCZ6cp1O02kyUbjrBk4meUKvqqqfH4QS2xMjemWb+51Pp0OnNX72f19F6UKe705iZFFqhTzpmvfaoxbP5+agxZg8+krTSr6sbIzp5a088Z1JAyrjZ0m7pd6/tGBrr41HeXp9TZrE5ZR75uX4lhi49QY8QmfKbsolmVwozsWFlr+jn9alOmcAG6zdynsXzZ7mvsPRfIlftPWXfIn8/nHKB1DTfcClq8j93IcfnhTnhQUBBTp06lRIkSdOjQAQsLC+Li4tiyZQtTp06latWqOV3ELJEVMVri89vjcwojQ318mlWRp9TZLOjmRS7v8qWqz0Caj5xL3T7f8fDKKS7u0D46/knfhYQ/uk/tXt9qfT/hZRx3Tx+iWD562pkTgm9d5Pqe9VTuMIAmX/9EzV6jeXzlNFd2aT9uZzcuJCLoPtV7fKP1/YSXcQScPaRufp5fZGd8nj9/Pq6urhgZGeHp6cnJkyffmn7OnDm4u7tjbGyMi4sLw4cP1xg4bMqUKVStWhVzc3Ps7e1p06YNN27c0Mijfv36qFQqjVf//v3fWdYffviB0aNHY2ZmRqFChZg7dy6DBg3K3I6/Idc1/86oKVOmpHpkn/Akd039EfrsBQkJidgXMNdYbm9jQVCY9ulXxg9swe/bTrJisx9X/B+x9cBFxv38F1/3bIrqtW99fEIidx6Ecu7aA8bN28qlmw8Z1Lk+AG7OtgzoVI9+E1Zz8ORNLt18yORfdnD2agD9fOpm2/7mFaHPY0hITMLeWnMgLntrE4LeeHqdYny3mvy+/xordl3myr0wth67zbgVR/m6Y9VUJ6vZAxrQvFpRvL7dyMPQ1IPhALStXRITQ33W7Pvwm1m+L6HPY5OPm5XmXUd7K2OCnmnv6zy+S1V+P3iLFXuuc+X+U7Yev8e4Vaf4un3F1Metby2aVy2C15i/eBgW9daynLoZDEAxx/xRqdZJ5+tD5e3tjbu7OxcvXmTOnDk8evSIefPm5XSxci2Jz2nH59e1bVwREyMD1vz99gtR8YqhmQUqHR1iI8M1lsdGhqfqO5viwt+rcavWkBK1vLAu5ErhijWp2KobV3ZtQElK0kh70nchDy+fpMmwKZha22rNL+DcURJfxlHUs1GW7FN+YGCafNzitBw3I3Ptx+3y9tUUqdqQojW8sHJyxblCTcq17Mb1PRtTHbezGxfy6Mop6g+ejImV9uMWeCH5uBWplr+OW3bFZ19fX0aMGMH48eM5e/YsFSpUwMvLi+DgYK3p165dy8iRIxk/fjzXrl1TD4A5evRodZpDhw4xaNAgjh8/zp49e4iPj6dp06ZERWlec/Xp04fHjx+rX9OnT39neVeuXMmCBQvYtWsXW7Zs4a+//mLNmjUkvfFdyoxce30zevRoevXSPm3B60aNGkVERITGS8/B4z2UMP3iExI5d+0BDTxfTRegUqloUK0kJ9PoX2VsZEBSkuaojSkH/G13knRUKgz/7cNpYpTcdC/pjQHeExMVaQaSDvEJSZy79YQGFV3Uy1QqaFDRhZNpNMU2NtRL9XmnHMfXL7ZmD2hAq5rF+XjkRu4/SXte2x5eZdh24g6hWkYaF9rFJyRx7nYIDcoXUi9TqaBB+UKcvKF9KjRjQ723/N5eO259a9Gquhsfj/mL+8GazUW1qeBmA0DQU+03YfIaHZUqXa8P1Y4dO/j888/5/vvvadGiBbq6ujldpByTnhgt8VnT6/H5dT3a1GTboUuEahlpXGinq6dPAZfiBN04r16mJCURdOM8tkVLaV0n8WUsqjcGa1LpJF8GKyQfT0VROOm7kAcX/Gg8bDJmtqlbFqTw99uNczlPjMwz1/8yP9LV08fapThPbl5QL1OSkgi+eQEb17SOW1yqH5a243Z240IeXvSj/qAfMLNJ+7jdPb4bp7LVMDLLX8ctu+LzrFmz6NOnDz179qR06dIsWrQIExMTli1bpjX9sWPHqFWrFl26dMHV1ZWmTZvSuXNnjafbO3fupEePHpQpU4YKFSqwYsUKAgICOHNG86asiYkJBQsWVL8sLN79ACMgIIDmzZur/2/cuDEqlYpHjx5leN/flGsr1YGBgdy7d++d6QwNDbGwsNB4qXRy34XO3NX76dm2Jl29PXF3c2DuaB9MjA1Z+WfyaKO/TvqMiUNaqdNvP3yZPh1q08HLgyJONjT0LMW4AS3ZfviSOphPHNKKWpWLUdixAGWKOzFxSCvqVinBuu3JI5LeuBeEf0AwP4/pTJUyRXBztmXYZw1pVN2dvw5eSF1IkcrczWfp+XE5ujYujbtLAeYOboSJoT4r9yQPSPPrl15M7FFLnX77iTv0aVGeDvVKUsTBgoaVCjOuW022n7ijPm5zBjWkU8NSdJ++nRcxL3GwNsHB2gQjA83vbVFHS2qXdWb5zkvvb4fziLl/XqJn01J0bVASd2cr5vavg4mRPiv3Jjcf+vWLBkz8rJo6/fZT9+nTrDQd6hSjiL05DSsUYlzXqmw/FfDquPWrTad6Jej+4z5exMTjYGWMg5Wx+ri5FbRgZMfKVCpmS2F7M1pUK8KvXzTgn8uPuHz/6fv/EHJAXq9UHzlyhMjISDw8PPD09OTnn38mNDR/jk+Rnhgt8Tnt+JyiqIsttSsXY/nmY+9vh/OIjxq15dbRXdw+vpeIoABOrJtPQlwsxf5t1nv0tx859+cKdfpC5Ty59c927p0+9O9gV+e48NdqnMtVQ+ff7+Up3wXcPXWA2j2/Rt/QmJiIp8REPCXhZZzGtiODHxHsf1kGKMuEkvXbcMdvF/dO7uN50APObFhAwstY3DwbA3Bi9Y9c/GuFOr1j2WrcPrKdgLOHeBEWRND1c1zevhqnsq+O29kNC7l/+iCe3b5Gz8iEmOfPiHn+LPVxC3lEyO0ruNXwem/7m1ukNz5r67YTFxenNc+XL19y5swZGjdu/Go7Ojo0btwYPz/t3Vlq1qzJmTNn1JXoO3fusH37do2K7psiIpKnsXtzdo01a9Zga2tL2bJlGTVqFNHR736AkZCQgJGRkcYyfX194uP/++w6uXZY2pUrV+Z0EbLUxt1nsbU2Y9yAFjjYmHPxxkNaD5qvHhzFpWABjTvfU3/diaIojB/YEid7S0KfvWDb4ctM+PkvdRq7AmYsndSNgrYWRLyI5fKth3gPXMD+E8kjKCYkJNFmyEL+N7Q1G3/qh5mJIbcfhNB73Cp2Hbn6fj+AD9TGwzextTRm3Kc1cChgwsXbIbQeu5ng8OQfrou9ucaT6am/n0BRYHy3WjjZmBEaEc22E3eY8NurC6Z+LZNHB94zXXOQjT4/7mL13lfHpXvTsjwMjWTv2fvZuYt50sYjt7G1MGJclyo4WJtw8W4orb/fTvC/T/xdbM00f2/rzyYft65VcSpgSujzGLadCmDC6ld3Tvs1LwPAnsmtNLbV56cDrN5/k/iERBpWKMRg73KYGukRGBrFFr+7TF1/9j3sce7w4VaX06d69epUr16dOXPm4Ovry7JlyxgxYgRJSUns2bMHFxcXzM3N351RHpCXYnROxOcU3VvX4OGTcPb6aR/5WKTN1aMucZERXPx7NTGRz7AuVJSGgyaqm39HPQvRaGlU7uNOqFBx/q9VxESEYWhmiXO5alT07qZOc/Of5PFN9swZqbGtGp9+oZ66C8Dfbw8mVrY4fqR93A2RtsKV6xL3IoLL21cT+/wZVs5Fqdt/Ikb/HrfoZyGoVK+e+ZVumnzcLm/7P3t3HhfT+scB/DPte9KeIkK2JKnIljUksmYvu0uhLvfiUpZLtkvXmp+lLLmyxLXdQmSNSJaoaBPt0UJpP78/RpNpJiozpuX7vq95XfPMc855zjzN+Z7nnOc8zzF2vckrQ7uTOYxspnLyxN5l11vwzuVc2zKbtJjTWAeA+PtXIaesBi1DE2HuYp1U3fjs4eGBNWvWcKW5u7tj9erVPHkzMzNRWloKTU3uQR01NTURFcX/mDZp0iRkZmaiV69eYBgGJSUlmDdvHlf376+VlZVh8eLF6NmzJzp16sS1nhYtWkBHRwfPnj3D77//jujo6O9OhcUwDBwdHSEtLc1JKygowLx587im1arNlFoshqnUV/UnyszMxKFDhxASEoLUVPaImFpaWrC0tISjoyPU1dVrtV5ZEydBFpP8LFoGoi4BqQ0pue/nIXXO53/nCnydxx/zH721sklddQW+bVGJjo7GwYMHcfToUWRnZ2PQoEE4f/68qIslEMKI0RSf66cVWxaLugikFopKRHaKT37AuiFtBL7O6sbnMR3Vee5MS0tLczVCyyUnJ6NZs2a4d+8eevTowUn/7bffcPPmTTx48IBnmeDgYEyYMAF//vknLCwsEBMTg0WLFmH27NlYtWoVT/5ffvkF//33H+7cuQNd3arPHa5fv44BAwYgJiYGBgZVtyemT59e5Wdf8/b2rla+r4nsTvXDhw9hbW0NOTk5DBw4kDM1R1paGnbs2IGNGzciMDAQ3bpVPQ8dIYSQuoNVj7t215ahoSE2b94MDw8PXLhwocrnyOobitGEENJwVDc+V9WA5kdNTQ3i4uJIS+MeryYtLQ1aWvyfa1+1ahWmTp2KWbNmAQCMjIyQl5eHOXPm4I8//oCYWEUvBScnJ1y8eBG3bt36ZoMaACws2LPsfK9RXZvGcnWJrFHt7OyMcePGwcvLi6eiGYbBvHnz4OzsXGWffEIIIXWLeCNsVJcTFxeHnZ0d7OzsRF0UgaAYTQghDYcw4rOUlBRMTU0RFBTEiX1lZWUICgqCkxP/Xkn5+flcDWcAnEE/yztPMwwDZ2dnnD17FsHBwWjZsuV3y/LkyRMAgLa2di335seJrFH99OlT+Pj48L1ywmKx4OLiAhOTxvfMAyGE1FeNt0nd8FCMJoSQhkNY8dnV1RUODg7o1q0bzM3N4enpiby8PE4362nTpqFZs2bw8PAAwJ6actu2bTAxMeF0/161ahVsbW05jesFCxbg+PHj+Pfff6GoqMh5/EhZWRmysrKIjY3F8ePHMWzYMKiqquLZs2dwcXFBnz590LlzZyHt6feJrFGtpaWF0NBQtGvHfwj90NBQngffCSGE1F2Nsft3Q0UxmhBCGg5hxWd7e3tkZGTAzc0Nqamp6NKlCwICAjjxITExkevO9MqVK8FisbBy5UokJSVBXV0dtra2WL9+PSfP3r17AQBWVlZc2/L29oajoyOkpKRw7do1TgNeT08PY8aMwcqVK4Wyj9Ulskb1kiVLMGfOHISFhWHAgAGcLz8tLQ1BQUHYv38/tm7dKqriEUIIqaE6O0cjqTGK0YQQ0nAIMz47OTlV2d07ODiY672EhATc3d3h7u5e5fq+N4a2np4ebt68WeNyCpvIGtULFiyAmpoatm/fjj179qC0tBQAu1+9qakpfHx8MH78+O+shRBCSF1Bd6obDorRhBDScFB8Fj6R3liwt7fH/fv3kZ+fj6SkJCQlJSE/Px/379+nYE0IIfWMGKt6r9rYvXs39PX1ISMjAwsLC4SGhlaZ18rKCiwWi+dlY2PDlS8yMhIjRoyAsrIy5OXlYWZmhsTExNoVsAGiGE0IIQ2DMOMzYRPZneqvSUpKinS0NkIIIT9OTEhDofj5+cHV1RVeXl6wsLCAp6cnrK2tER0dDQ0NDZ78/v7+KCoq4rx///49jI2NMW7cOE5abGwsevXqhZkzZ2LNmjVQUlLCixcvICMjI5R9qM8oRhNCSP0mrPhMKtSJRjUhhJD6T1i9y7Zt24bZs2dzRhP18vLCpUuXcOjQISxbtownf9OmTbnenzhxAnJyclyN6j/++APDhg3D5s2bOWnfmtuSEEIIqa+o97fw0bgyhBBCBIJVzf9qoqioCGFhYRg4cCAnTUxMDAMHDqz2HMkHDx7EhAkTIC8vD4A9j+alS5fQtm1bWFtbQ0NDAxYWFjh37lyNykYIIYTUB8KIz4QbNaoJIYQIhDiLVa1XYWEhcnNzuV6FhYV815mZmYnS0lKe6Zs0NTU5c1d+S2hoKCIiIjBr1ixOWnp6Oj59+oSNGzdiyJAhuHLlCkaNGoXRo0fXyRFFCSGEkB9R3fhMao8a1YQQQgSCxarey8PDA8rKylwvDw8PoZTp4MGDMDIygrm5OSetrKwMADBy5Ei4uLigS5cuWLZsGYYPHw4vLy+hlIMQQggRlerGZ1J79Ew1IYQQgahuQF6+fDlcXV250qSlpfnmVVNTg7i4ONLS0rjS09LSoKWl9c3t5OXl4cSJE1i7di3POiUkJNChQweu9Pbt2+POnTvV2wlCCCGknqAGs/DRnWpCCCECUd1ntqSlpaGkpMT1qqpRLSUlBVNTUwQFBXHSysrKEBQUhB49enyzPKdOnUJhYSGmTJnCs04zMzNER0dzpb969QotWrSo5d4TQgghdRM9Uy18dKeaEEKIQAhrjktXV1c4ODigW7duMDc3h6enJ/Ly8jijgU+bNg3NmjXj6UJ+8OBB2NnZQVVVlWedS5cuhb29Pfr06YN+/fohICAAFy5cQHBwsHB2ghBCCBERmoNa+KhRTQghRCDEhNS/zN7eHhkZGXBzc0Nqaiq6dOmCgIAAzuBliYmJEBPj7ngVHR2NO3fu4MqVK3zXOWrUKHh5ecHDwwMLFy6EoaEhzpw5g169egllHwghhBBREVZ8JhWoUU0IIUQghNl1zMnJCU5OTnw/43d32dDQEAzDfHOdM2bMwIwZMwRRPEIIIaTOoq7dwkeNakIIIQJB3csIIYSQuofis/BRo5oQQohA0JVwQgghpO6h+Cx81KgmhBAiEPTIFiGEEFL3UHwWPmpUE0IIEQhxitqEEEJInUPxWfgaZKM66+EuUReB1IKKGf9BiEgdp2Ug6hKQOoJCNvmevf/7TdRFILXwy7y/RF0EUhtlpaIuAamFdUME346h+Cx8DbJRTQghRAQoahNCCCF1D8VnoaNGNSGEEIGggVAIIYSQuofis/BRo5oQQohA0CNbhBBCSN1D8Vn4qFFNCCFEIChoE0IIIXUPxWfho0Y1IYQQgaDuZYQQQkjdQ/FZ+KhRTQghRCDoSjghhBBS91B8Fj5qVBNCCBEIitmEEEJI3UPxWfioUU0IIUQwKGoTQgghdQ/FZ6GjRjUhhBCBEKP+ZYQQQkidQ/FZ+KhRTQghRCAoZBNCCCF1D8Vn4aNGNSGEEMGgqE0IIYTUPRSfhY4a1YQQQgSCpuwghBBC6h6Kz8JHjWpCCCECIUYxmxBCCKlzKD4LHzWqCSGECAYFbUIIIaTuofgsdNSoJoQQIhDUvYwQQgipeyg+Cx81qgkhhAgEzdhBCCGE1D0Un4WPGtWEEEIEgmI2IYQQUvdQfBY+alQTQggRCBZdCieEEELqHIrPwicmyo0/ffoU06ZNQ6tWrSArKwt5eXkYGRlh1apVyM3NFWXRCCGE1BCLVb0XqR8oRhNCSMNA8Vn4RNaoDgwMRI8ePZCfn4+ePXtCTEwMM2bMgI2NDU6cOIGuXbsiNTVVVMUjhBBSQ6xqvkjdRzGaEEIaDorPwsdiGIYRxYZNTEwwd+5czJs3DwBw9epVLFy4EJGRkSguLsbQoUOhp6cHb2/vGq+7oETQpRWME8d9cdj7IDIzM9DWsB2WrVgFo86d+ead6TgVjx6G8qT37tMXu/b+D8XFxdi1wxN3bt/Cu3dvoaigAIselljk8is0NDQBAA9DH2DW9Gl81+974hQ6GfHftqiomDmJugh8zR3fBy4OA6CpqoTnr5LguukUHr14U2V+p0lWmD2uN/S0VPA+Ow9nr4Vj1c7zKCxi/2HOHtcLs8f2RgudpgCAyLhUbPjff7hy9yVnHZqqitiweBT6d28HRXlpvEpIx+aDgTgX9ESo+1orWgaiLgFfc4cbw2WsKTRV5PE8LgOue2/g0au0KvM72Zlgtk1n6Kkr4X3uZ5y98xqrvO+gsLgUALBkvBnserZGW92m+FxUggcvk/HHoTt4nZQFAGiuoYTowzP5rnvy+ovwv/Na8Dv5Az7/5yLwdb5Ky69WvraacgLfNhEsYcVon4eJwijuDwu7+i8eXDqFTzkfoNHcAIOnLYCOQbsq84cG+CP82gXkvk+HrKIy2pn3htX4mZCQkgIA3Dv/D6If3sGHlLeQkJJGszYd0M9+FlR19Djr8P3zVyRGPeNar0l/GwyZsVgo+/gjfpn3l6iLwNfccb3gMq0/Oz6/ToLr5jN49KLqvzGniX0xe2zPivgc9BSrdl2oiM9je2L22F5ooV0en1OwYX8grtyL5FqPhZE+Vi+wgVmnFigtZfDs1TvYOnmhoLBYeDtbG2Wloi4BXz/7vKq5dlNEX17Ld92Tlx6E/7VwAe/hj/kcvkvg66T4LHwia1TLysoiMjIS+vr6AACGYSAtLY03b95AW1sbt2/fxpgxY5Cenl7jddfFRnXAf5excvlvWOm+BkZGxvA9ehhXrgTg34sBUFVV5cmfk52N4uKKg3N2TjbGjx4J9zV/YuSo0fj48SOWuCzE6LHjYGjYDrm5udjksR5lZaX456Q/AKC4qAg5OTlc69298288eBCCSwHX6tzzFXWxUT12cFccWDcVzuv98DAiAU6T+mH0IBMY261FRtYnnvz2Q7rBa/VkzFvti5CncWjTQgP7107FqcAw/P4Xu16G9emE0rIyxCRmgAUWpthawMVhALpP2IjIOPadnwt7FqCJoixcNp5CZvYn2A/thlXzbNBz8mY8jX73U7+D76qDjeqxfdriwBJrOO8MwsPoVDjZdcXoXm1gPNsHGTmfefLbWxnCy2Uw5m2/gpCXKWij2wT7Xa1x6mY0ft9/CwDw77pROHUzGmGv0iAhzsIax57o2EINJnMPI7+wBGJiLKgry3Ktd8ZQI7iM6YaWk/+HvIK6dbIljEb16zTe75afNpqy389EREpYMbouNqpf3g/GRa/NGDJ9IXRat8fDAH9EPbiFOVsOQV5ZhSf/i3vXcWn/VtjMXoJmbTrgQ+o7XNq3Be2798PAKeyLECc2LUeHHlbQbmWIstJS3Dx5CBnvEjB70wFIybD//n3//BVNtXXRe4wDZ92SUtKQlpP/OTteA3WxUT12kAkOrJ0C5w0nv8RnK4we2AXGo9dXEZ9N4eU2EfPW/oOQp/Fo00Id+1dPxqnAx/h9+zkAwLDeHVFaxrDjMwuYMtwcLtP6o/ukLZz4bGGkj393zcNW72u4dCsCJaVl6NxWBxeCn6OouI41Yutgo1oU51ViYiyoqyhwrXfGmJ5wmTYQLQetQN7nop+y79UljEY1xWfhE1n372bNmiE6OprzPjY2FmVlZZwGpq6uLj594v1x1VdHD3tj9NjxsBs1BgatW2Ol+xrIyMjgnP8ZvvmVmzSBmro653X/3l3IyMhgkPUQAICioiL2HfCG9ZBh0G/ZCp2Nu2D5H6vw8sULpCQnAwAkpaS41qHcpAlu3AjCSLvRda5BXVctnNIf3v73cPT8fUTFpcJ5/Ql8LiiCg10Pvvm7G7dEyJM4+AU8QmLKBwTdj8LJgEfo1rEFJ8/lWxEIvPMSsYkZiElMx+rdF/ApvxDmnVt+tZ5W2HPiJh69eIOEpPfYdCAQ2R8/w6SDHr/NkkoWjuoK7/8icPTqS0QlfoDzzmv4XFgCh8Gd+Obv3l4HIS+T4RccjcT0XAQ9TsTJ4Gh0M9Ti5Bm56iyOXXuJyMT3eB6fiTnbrqC5phJM2rB7hpSVMUjLyud6jbBsjTO3X9W5BrWwiLGq96qN3bt3Q19fHzIyMrCwsEBoKG9PnnJWVlZgsVg8LxsbG775582bBxaLBU9Pz9oVrgFqTDE69L8zMO43FJ37DoFasxYYMn0RJKSl8exmIN/8716/gG6bjuho2R9N1LXQyqgbOvToh5S4KE6eCb97oHMfa6jr6kOzhQGGz12K3PfpSE3g7rEiISUNhSZNOa+62KCuqxZOsYL32Xs4euEBouLT4LzhJDs+j+zON3/3zvoIeRoPv4CwL/E5GicDH6Nbp6/i8+0XCLz7ErFvMxCTmIHVey6x47ORPifP5l9HYc+JW9jqcw2Rcal4/SYdZ64+qXsN6jpKFOdVZWUM0t5/5HqN6GeMM1cf17kGtbAIMz4TNpE1qqdNm4ZZs2bBy8sL3t7eGDVqFEaMGAGpL12nnjx5gpYtW35nLfVDcVERIl++QPcelpw0MTExdO9uiWdPq9fl5Kz/GQwZagM5uaq7ZXz69AksFguKSkp8P7954zpysrNhN2pMzXagkZKUEIdJez1cf1BxYskwDK4/iOZqAH/t/tN4mHTQ4xzs9ZupwrpnRwTcecE3v5gYC+OsTSEvK4UHz+K/Wk8cxg42hYqSHFgsdh4ZaQncelS3uhDXRZISYjBpo4nrTyruiDEMcP1JIszba/Nd5n5kMkxaa6BbW3YDWV9LGdZm+gh4GM83PwAoybGPVVkfC/h+btJaA10MNHA4MKK2u1L/COmhLT8/P7i6usLd3R2PHz+GsbExrK2tq7xL6u/vj5SUFM4rIiIC4uLiGDduHE/es2fP4v79+9DR0al5wRqwxhKjS0uKkRr/Ci07duWkscTEoN+xK5JiXvJdRrdNR6QmvEZyLLsRnZWegtinoTAwNq9yOwX5eQAAWXlFrvQX967Dc94Y7F82G8F+B1FcyP94QrhJSojDpJ0eroe+4qQxDIProa+4GsBfu/8sASbtddGtY3MA5fG5PQLu8K9nMTEWxg02gbysNCc+q6sowNxIHxkfPuLGocVIuPInrvzPGZZdWgl2BxsoUZ5Xfc2kvR66tNPD4XMhP7hH9Qg9VC10IptSa8WKFcjLy8O6detQWFgIa2tr/P3335zPmzVrhr1794qqeAKVlZ2F0tJSnm7eqqqqiI+P++7yz589Q8zrV1i9dn2VeQoLC+G5bSuGDrOBgoIC3zxn/U/DsmcvaGpp8f2ccFNTUYCEhDjSP3zkSk9/nwtDfU2+y/gFPIKqijyCvF3AAguSkuL436nb2HLoCle+jq11EHz4V8hISeDT50LY/7ofUXEVg/5M+e0Qjm6ageSbm1FcXIr8giLYu+5H3NtMwe9oA6OmJAsJcTGkZ3E/P5SelQ9DXd6unADgFxwNVSVZBG21B4vFDvz/u/QUW/we8s3PYgFb5lrh3oskvHzznm8eB+tOiEx8j/uRKT+2Q/UIS0gRedu2bZg9ezamT58OAPDy8sKlS5dw6NAhLFu2jCd/06ZNud6fOHECcnJyPI3qpKQkODs7IzAwsMq72I1VY4nR+R9zwJSVQa5SN295ZRW8T3nLd5mOlv2R/zEHR9e6AGBQVloKkwHDYTlyEt/8TFkZrh3bC922HaGuV9Fw6GDZH8pqGlBQUUN6YhyCTxzA+5S3GLN4taB2r8FSayLPjs/vK8fnjzDU1+C7jF9AGFSbyCPo4CKwWCz2cf70HWzxvsqVr2NrbQR7u1TE5yUHERXPHo+jZTP2edwfc4Ziuee/ePbqHSbbmOPy3gUwHb8RsW8zhLC3DYcoz6u+5mDXA5FxKbj/tOoL5w2NsOIzqSCyRrWEhAQ2bdqETZs28f3c3LzqK75fKywsRGFhIVcaIy4NaWnpHy5jXXHW/zTatG1b5aBmxcXFWOq6CAzD4A+3NXzzpKWm4t7dO9jyl6cQS0p6m7bB0hnWWOThh4fP38BATw1bl45Fyuwh2Lg/gJPvVUIaLCZ4QFlBFqMGmmD/2qkYPOtvTgBwXzAcTRRlMXTuDrzPzoOtVWcc2zwDA2d44kVMsqh2r8HqbaSLpfbmWLT7Oh5Gp8BApwm2zrVCykQLbPznAU9+zwX90VFfFQOWnOS7PhkpcdhbGfJdtiETxlMlRUVFCAsLw/LlyzlpYmJiGDhwIEJCqneX4eDBg5gwYQLk5Su61paVlWHq1KlYunQpOnbsKPBy13eCiNH84nNxUSEkpep3fH7z8ilCzv8Da0dn6LRuj6zUJFw7tgd3zh5Dr1FTePIHHt6JzHcJmLJqO1e6Sf+KCzkaei2h0KQp/vH4DVlpyVDRpJ4TgtbbtDWWTh+ERRtP4WHEGxjoqWPrktFImZWDjQcqGmivEtJhMXEzlBVkMGpgF+xfMxmDZ+9AVHwaxL70jz3oz+52DgBPo8/CyrwtHEZawG3XRZHsW0MmqPOqcjLSkrAf2o1r2caAnvoUPpHOUy0IHh4eUFZW5npt2eQh6mJxUWmiAnFxcbx/z31H6/3791BTU/vmsvn5+Qj87xJGjR7L9/Pi4mIs/XUxUpKTse/AoSrvUp87ewbKTZqgb7/+tduJRigz6xNKSkqh0ZS7u56GqhJS3/Ofo9V9vg3+uRQKn7MheBGTjPM3nsFt1wUsnT6Y6zn24pJSxL3NRHjkW7jtPI/nr5KwYKIVAKClrhp+mdAXc1cfQ3DoKzx/lYQN//sPj18mYq59H6Htb0ORmfsZJaVl0FDhflRCQ0UOqVn8R790n2aJf65HwicwAi8S3uP8vVi4+dzF0vFmPIFo+y/9MMy8Fax/P42kTP7PlI7q1RZy0pLwDYrk+3lDVd3eZYWFhcjNzeV6VW58lcvMzERpaSk0NbnvYmhqalZrSqfQ0FBERERg1qxZXOmbNm2ChIQEFi5cWNPdJNXELz5f8tkj6mJxkVNUBktMDPk5WVzpeTlZUOAzSBkA3Drtg049B6JLv2HQ0GsJQ7Ne6DtuBkIunABTVsaVN/DwTsSEP8CkFVugpKr+zbKUjzaelZb0A3vUOGRm57Hjs2rl+KyI1MyPfJdx/2UY/rn8ED7n7uNFTMqX+HwRS6cP4o3P7zIRHvUObrsufonPfQEAKZns2B9ZqaEWHZ8KPS3+fy+kgqjOq742amAXyMlIwfdi1eNyNETU+1v46myjesWKFZgxY8Z38y1fvhw5OTlcr6W/L//ucj+TpJQU2nfoiAf3K+6qlJWV4cGDEHQ2NvnmslcDA1BUVAQb2xE8n5U3qBPfvMG+gz5o0oT/AZ1hGPx7zh+2I+wgKSn5YzvTiBSXlCI88i36WRhy0lgsFvqZt0VoFc/pyMpIoayMe0D9si8nWd+6SijGYkFait1xRE6G/cxiWaWB+UtLGYjRpcbvKi4pQ/jrNPTrUjGoG4sF9Ouih9AqumLLSkvwfN/l9fh10N7+Sz+MsGyNIctO400a/xMAAHC07ohLD+KQyWek8YaM3+Bg/F78GlseHsK5GHrw4EEYGRlx3VkNCwvD33//DR8fHxq0sZaqE6P5xWcbx/k/qYTVIy4hCa2WbZHwomJ8E6asDG9ehKNZ6w58lykpKgSr0og+LDH26RQD9nGDYRgEHt6JV4/uYtKKzWiiwX88h6+lJ8YCABSa8M4IQrgVl5QiPOot+pm15aSxWCz0M2uL0OcJfJepdXwWq4jPb5I/IDk9G20rdTFv3VwDiSlZ/BYnXxHVedXXHO0scenmc2TyGWm8IatufCa1J7Lu39/z7t07vHv3/amDpKV5u3rXxSm1pjpMx6oVv6Njx07oZNQZx44exufPn2E3ajQA4I/lv0FDQxOLXH7lWu6s/2n0GzCQp8FcXFyMJS4LERn5Ejt370NZaSkyM9jP8igrK0Pyy2AyABD64D6S3r3D6DH873aTqu04dh37105F2MtEPPoy9YOcrDSO/HsfAHBg3VQkp+fAbed5AOwRKBdO6Yen0e8Q+jwBBnrqcPtlOC7fes4JCmudRyDw7gu8TcmCorwM7Id2Q59ubWA7n30HJzohFTGJ6di1ciKWbzuL9zl5GNGvMwZ0N8ToRV6i+SLqmR1nH2P/r9YIe52OR9GpcLIzgZy0JI5cZQ9scuBXayS//wQ3n7sAgMsP4rBwdFc8jU1HaFQqDHSawG2aJS4/iOPUm+eC/rC3MsS4tefx6XMRNL/cCc/JK0RBUcWor620ldGrky7s3M7+5L0WverG4+XLl8PV1ZUrrapHdtTU1CAuLo60NO45xtPS0qD1nfEh8vLycOLECaxdyz0/6e3bt5Geno7mzZtz0kpLS/Hrr7/C09MTCQkJ1duRRqw6MZpffJaUyhZiqWrHfOgYXNy3GVot20LHwBAPA86iuLAAnftaAwAueG2CoooarOzZ89C3NumO0P/OQLNFa+gYtENWWjJunT6MNibdISYmDgAI9NmJlyHXMdZlDaRk5PAp+wMAQFpOHpJS0shKS8aLe9dh0MUcsgpKyEiMwzVfL+i1M4JGcxr0qjp2HAvG/jWTERaZiEcRiXCa1BdyslI4cp7dLfvAmslIzsjhdMm+fCsCCyd/ic9fun+7/TIMl29FVMRnp+EIvBuJt6lZUJSXhv0QU/QxbQ1bp4rYu/3IdaycNxTPXyXhaXQSptiaw1BfA5N+P/Tzv4R6SBTnVeVa6amhV1cD2DnX//Egaoray8JXZxvVR44cEXURBGrI0GHI+vABe3btQGZmBgzbtceefQeg+qX7d2pKCsRY3B0HEuLjEP44DF77eQ/U6elpCL5xHQAwfsxIrs8OeB+BmbkF5/3ZM6fRpYsJWraqe/MJ13WnrzyGmooC3H6xgaaqIp5FJ2Hkgt2cQTb0tJpyXUHdeCAADMPAff5w6GgoIzPrEy7disDqXRc4edSbKuDgumnQUlNCzqcCRLxOgu38Pbj+gD2SbElJGeyc9+LPhSNx+u+5UJCTRuzbDMxyO4rAKkYpJdxO33oFNWVZuE3pAc2mcngWm4GRq84iPZvd/VtPQ5HrzvTGfx6AYQD3aT2ho6qAzJx8XHoQh9WH73HyzB1uDAC4unk817Zm/xWIY9cq6sVhcCckZX7EtcdvhLmLdVJ1Yza/xlZVpKSkYGpqiqCgINjZ2QFg36UICgqCk9O357Y/deoUCgsLMWUK93OuU6dOxcCBA7nSrK2tMXXqVM5gaOTbGlKM7tDdCvm52bh95jDycrKg0cIA43/bwJmjOjcznesOTk+7yQCLhZunfPApKxNySspobdIdfcdV3LkPD2If833XL+Hals2cJejcxxriEhJIePEYDwP9UVxYAKWm6jA0642eVQx2RnidvhrOjs/zhkFTVQnPXr3DSGevr+KzCvdx/uAV9nF+vg101JWRmZ3Hjs+7L3HyqKso4uDaydBSU0bOp8+IeJ0MWycvrtGqd/1zEzLSktjsOgoqynJ4/ioZwxfsRfw7/oNWEm6iOK8q5zCyB5LSsnEthDu9MaA2tfCxGKZSn8efKDMzE4cOHUJISAjn2TgtLS1YWlrC0dER6urffv6oKnXxTjX5PhWzb58gkzpKiy7W1Eef/3MR+DrfZfF/LroyXZWaDVTl5+cHBwcH7Nu3D+bm5vD09MTJkycRFRUFTU1NTJs2Dc2aNePpQt67d280a9YMJ06c+O429PX1sXjxYixevLhGZWvIhBGjfR4mfj8TqXN+mfeXqItAaqOM5s6ujz6H7xL4OoUVn0kFkT1T/fDhQ7Rt2xY7duyAsrIy+vTpgz59+kBZWRk7duxAu3bt8OjRI1EVjxBCSI0JZygUe3t7bN26FW5ubujSpQuePHmCgIAAzuBliYmJSEnhfl4+Ojoad+7cwcyZM39khxotitGEENKQCG+ost27d0NfXx8yMjKwsLBAaOi3B4Hz9PSEoaEhZGVloaenBxcXFxQUFHA+9/DwgJmZGRQVFaGhoQE7OztER0dzraOgoAALFiyAqqoqFBQUMGbMGJ7HxH42kd2p7t69O4yNjeHl5cXzYDzDMJg3bx6ePXtW7SlTvkZ3qusnulNdT9Gd6npJGHeqk7OLqpVPp4nU9zMRkRJWjKY71fUT3amup+hOdb0kjDvVworPfn5+mDZtGry8vGBhYQFPT0+cOnUK0dHR0NDgnTP++PHjmDFjBg4dOgRLS0u8evUKjo6OmDBhArZt2wYAGDJkCCZMmAAzMzOUlJRgxYoViIiIwMuXLzlTY/7yyy+4dOkSfHx8oKysDCcnJ4iJieHu3bs1Kr8giaxRLSsri/DwcLRr147v51FRUTAxMcHnzzUfPZca1fUTNarrKWpU10vCaFSn5FQvaGsrU6O6rhNWjKZGdf1Ejep6ihrV9ZIwGtXCis8WFhYwMzPDrl3sMpeVlUFPTw/Ozs5YtmwZT34nJydERkYiKCiIk/brr7/iwYMHuHPnDt9tZGRkQENDAzdv3kSfPn2Qk5MDdXV1HD9+HGPHsgdhjoqKQvv27RESEoLu3bvXaB8ERWTdv7W0tL7ZPSA0NJRnXlJCCCF1F6ua/5G6j2I0IYQ0HNWNz4WFhcjNzeV6FRbyfx67qKgIYWFhXAN/iomJYeDAgVX2YrK0tERYWBgnvsTFxeHy5csYNmxYlWXPyckBADRt2hQAe1rM4uJiru22a9cOzZs3r1UPZ0ER2ejfS5YswZw5cxAWFoYBAwZwgnNaWhqCgoKwf/9+bN26VVTFI4QQUlPUXm4wKEYTQkgDUs347OHhgTVr1nClubu7Y/Xq1Tx5MzMzUVpaynOBVVNTE1FR/EdYnzRpEjIzM9GrVy8wDIOSkhLMmzcPK1as4Ju/rKwMixcvRs+ePdGpUycAQGpqKqSkpNCkSROe7ZYPqikKImtUL1iwAGpqati+fTv27NmD0lJ2FxVxcXGYmprCx8cH48eP/85aCCGE1BVi1KhuMChGE0JIw1Hd+Lx8+XK4urpypVV3CszqCA4OxoYNG7Bnzx5YWFggJiYGixYtwrp167Bq1Sqe/AsWLEBERESVXcPrEpHOU21vbw97e3sUFxcjMzMTAKCmpgZJSUlRFosQQkgtUNfuhoViNCGENAzVjc/S0tLVbkSrqalBXFycZ9TttLQ0aGlp8V1m1apVmDp1KmbNmgUAMDIyQl5eHubMmYM//vgDYmIVTyY7OTnh4sWLuHXrFnR1dTnpWlpaKCoqQnZ2Ntfd6m9t92cQ2TPVX5OUlIS2tja0tbUpWBNCSH0lvBk7iAhRjCaEkHpOCPFZSkoKpqamXIOOlZWVISgoCD169OC7TH5+PlfDGWD3gALYM0uU/9/JyQlnz57F9evX0bJlS678pqamkJSU5NpudHQ0EhMTq9zuzyDSO9WEEEIaDmovE0IIIXWPsOKzq6srHBwc0K1bN5ibm8PT0xN5eXmYPn06AGDatGlo1qwZPDw8AAC2trbYtm0bTExMON2/V61aBVtbW07jesGCBTh+/Dj+/fdfKCoqcp6TVlZWhqysLJSVlTFz5ky4urqiadOmUFJSgrOzM3r06CGykb8BalQTQggREBa1qgkhhJA6R1jx2d7eHhkZGXBzc0Nqaiq6dOmCgIAAzuBliYmJXHemV65cCRaLhZUrVyIpKQnq6uqwtbXF+vXrOXn27t0LALCysuLalre3NxwdHQEA27dvh5iYGMaMGYPCwkJYW1tjz549wtnJahLZPNXCRPNU1080T3U9RfNU10vCmKc6K796c6KqyIkLfNukfqB5qusnmqe6nqJ5quslYcxTTfFZ+OrEM9WEEEIIIYQQQkh9RN2/CSGECAR1/yaEEELqHorPwkeNakIIIQJBU2oRQgghdQ/FZ+GjRjUhhBCBoCvhhBBCSN1D8Vn4qFFNCCFEIChoE0IIIXUPxWfho0Y1IYQQgaDuZYQQQkjdQ/FZ+KhRTQghRCDoSjghhBBS91B8Fj5qVBNCCBEIitmEEEJI3UPxWfioUU0IIUQwKGoTQgghdQ/FZ6GjRjUhhBCBEKP+ZYQQQkidQ/FZ+FgMwzCiLgSpnsLCQnh4eGD58uWQlpYWdXFINVG91U9Ub4SQ6qLjRf1E9VY/Ub2Ruoga1fVIbm4ulJWVkZOTAyUlJVEXh1QT1Vv9RPVGCKkuOl7UT1Rv9RPVG6mLxERdAEIIIYQQQgghpL6iRjUhhBBCCCGEEFJL1KgmhBBCCCGEEEJqiRrV9Yi0tDTc3d1pUIZ6huqtfqJ6I4RUFx0v6ieqt/qJ6o3URTRQGSGEEEIIIYQQUkt0p5oQQgghhBBCCKklalQTQgghhBBCCCG1RI1qQgghhBBCCCGklqhRTQghhBBCCCGE1BI1quuQW7duwdbWFjo6OmCxWDh37tx3lwkODkbXrl0hLS2N1q1bw8fHR+jlJBU8PDxgZmYGRUVFaGhowM7ODtHR0d9d7tSpU2jXrh1kZGRgZGSEy5cv/4TSknJ79+5F586doaSkBCUlJfTo0QP//fffN5ehOiOk8aL4XP9QfK6fKD6T+ooa1XVIXl4ejI2NsXv37mrlj4+Ph42NDfr164cnT55g8eLFmDVrFgIDA4VcUlLu5s2bWLBgAe7fv4+rV6+iuLgYgwcPRl5eXpXL3Lt3DxMnTsTMmTMRHh4OOzs72NnZISIi4ieWvHHT1dXFxo0bERYWhkePHqF///4YOXIkXrx4wTc/1RkhjRvF5/qH4nP9RPGZ1Fc0pVYdxWKxcPbsWdjZ2VWZ5/fff8elS5e4DhwTJkxAdnY2AgICfkIpSWUZGRnQ0NDAzZs30adPH7557O3tkZeXh4sXL3LSunfvji5dusDLy+tnFZVU0rRpU2zZsgUzZ87k+YzqjBBSjuJz/UTxuf6i+EzqA7pTXY+FhIRg4MCBXGnW1tYICQkRUYlITk4OAHYAqArVW91SWlqKEydOIC8vDz169OCbh+qMEFITdMyoeyg+1z8Un0l9IiHqApDaS01NhaamJleapqYmcnNz8fnzZ8jKyoqoZI1TWVkZFi9ejJ49e6JTp05V5quq3lJTU4VdRPKV58+fo0ePHigoKICCggLOnj2LDh068M1LdUYIqQmKz3ULxef6heIzqY+oUU2IgCxYsAARERG4c+eOqItCqsHQ0BBPnjxBTk4OTp8+DQcHB9y8ebPKwE0IIaR+ovhcv1B8JvURNarrMS0tLaSlpXGlpaWlQUlJia6C/2ROTk64ePEibt26BV1d3W/mraretLS0hFlEUomUlBRat24NADA1NcXDhw/x999/Y9++fTx5qc4IITVB8bnuoPhc/1B8JvURPVNdj/Xo0QNBQUFcaVevXq3yuRMieAzDwMnJCWfPnsX169fRsmXL7y5D9VY3lZWVobCwkO9nVGeEkJqgY4boUXxuOCg+k3qBIXXGx48fmfDwcCY8PJwBwGzbto0JDw9n3rx5wzAMwyxbtoyZOnUqJ39cXBwjJyfHLF26lImMjGR2797NiIuLMwEBAaLahUbnl19+YZSVlZng4GAmJSWF88rPz+fkmTp1KrNs2TLO+7t37zISEhLM1q1bmcjISMbd3Z2RlJRknj9/LopdaJSWLVvG3Lx5k4mPj2eePXvGLFu2jGGxWMyVK1cYhqE6I4Rwo/hc/1B8rp8oPpP6ihrVdciNGzcYADwvBwcHhmEYxsHBgenbty/PMl26dGGkpKSYVq1aMd7e3j+93I0Zv/oCwFUPffv25dRhuZMnTzJt27ZlpKSkmI4dOzKXLl36uQVv5GbMmMG0aNGCkZKSYtTV1ZkBAwZwAjbDUJ0RQrhRfK5/KD7XTxSfSX1F81QTQgghhBBCCCG1RM9UE0IIIYQQQgghtUSNakIIIYQQQgghpJaoUU0IIYQQQgghhNQSNaoJIYQQQgghhJBaokY1IYQQQgghhBBSS9SoJoQQQgghhBBCaoka1YQQQgghhBBCSC1Ro5oQQgghhBBCCKklalQTQgghhBBCCCG1RI1qUi+xWKxvvlavXi3qIgqcvr4+PD09RV0MQgghpEoUnwkhjZGEqAtASG2kpKRw/u3n5wc3NzdER0dz0hQUFERRrBpjGAalpaWQkPh5P8WioiJISUn9tO0RQghpPCg+1x7FZ0LqL7pTTeolLS0tzktZWRksFosr7cSJE2jfvj1kZGTQrl077Nmzh7NsQkICWCwWTp48id69e0NWVhZmZmZ49eoVHj58iG7dukFBQQFDhw5FRkYGZzlHR0fY2dlhzZo1UFdXh5KSEubNm4eioiJOnrKyMnh4eKBly5aQlZWFsbExTp8+zfk8ODgYLBYL//33H0xNTSEtLY07d+4gNjYWI0eOhKamJhQUFGBmZoZr165xlrOyssKbN2/g4uLCudoPAKtXr0aXLl24vhtPT0/o6+vzlHv9+vXQ0dGBoaEhAODt27cYP348mjRpgqZNm2LkyJFISEgQRPUQQghppCg+U3wmpDGiRjVpcHx9feHm5ob169cjMjISGzZswKpVq3D48GGufO7u7li5ciUeP34MCQkJTJo0Cb/99hv+/vtv3L59GzExMXBzc+NaJigoCJGRkQgODsY///wDf39/rFmzhvO5h4cHjhw5Ai8vL7x48QIuLi6YMmUKbt68ybWeZcuWYePGjYiMjETnzp3x6dMnDBs2DEFBQQgPD8eQIUNga2uLxMREAIC/vz90dXWxdu1apKSkcN0JqI6goCBER0fj6tWruHjxIoqLi2FtbQ1FRUXcvn0bd+/ehYKCAoYMGcJ1EkIIIYQICsVnXhSfCWkgGELqOW9vb0ZZWZnz3sDAgDl+/DhXnnXr1jE9evRgGIZh4uPjGQDMgQMHOJ//888/DAAmKCiIk+bh4cEYGhpy3js4ODBNmzZl8vLyOGl79+5lFBQUmNLSUqagoICRk5Nj7t27x7XtmTNnMhMnTmQYhmFu3LjBAGDOnTv33f3q2LEjs3PnTs77Fi1aMNu3b+fK4+7uzhgbG3Olbd++nWnRogVXuTU1NZnCwkJO2tGjRxlDQ0OmrKyMk1ZYWMjIysoygYGB3y0bIYQQ8j0Un4250ig+E9Jw0TPVpEHJy8tDbGwsZs6cidmzZ3PSS0pKoKyszJW3c+fOnH9ramoCAIyMjLjS0tPTuZYxNjaGnJwc532PHj3w6dMnvH37Fp8+fUJ+fj4GDRrEtUxRURFMTEy40rp168b1/tOnT1i9ejUuXbqElJQUlJSU4PPnz5wr4T/KyMiI6zmtp0+fIiYmBoqKilz5CgoKEBsbK5BtEkIIIeUoPvNH8ZmQhoEa1aRB+fTpEwBg//79sLCw4PpMXFyc672kpCTn3+XPQFVOKysrq/G2L126hGbNmnF9Ji0tzfVeXl6e6/2SJUtw9epVbN26Fa1bt4asrCzGjh373a5eYmJiYBiGK624uJgnX+Xtffr0CaampvD19eXJq66u/s1tEkIIITVF8ZniMyENGTWqSYOiqakJHR0dxMXFYfLkyQJf/9OnT/H582fIysoCAO7fvw8FBQXo6emhadOmkJaWRmJiIvr27Vuj9d69exeOjo4YNWoUAHZQrTwoiZSUFEpLS7nS1NXVkZqaCoZhOCceT548+e72unbtCj8/P2hoaEBJSalGZSWEEEJqiuIzxWdCGjIaqIw0OGvWrIGHhwd27NiBV69e4fnz5/D29sa2bdt+eN1FRUWYOXMmXr58icuXL8Pd3R1OTk4QExODoqIilixZAhcXFxw+fBixsbF4/Pgxdu7cyTMIS2Vt2rSBv78/njx5gqdPn2LSpEk8V+H19fVx69YtJCUlITMzEwB71NGMjAxs3rwZsbGx2L17N/7777/v7sfkyZOhpqaGkSNH4vbt24iPj0dwcDAWLlyId+/e1f4LIoQQQqpA8ZniMyENFTWqSYMza9YsHDhwAN7e3jAyMkLfvn3h4+ODli1b/vC6BwwYgDZt2qBPnz6wt7fHiBEjsHr1as7n69atw6pVq+Dh4YH27dtjyJAhuHTp0ne3vW3bNqioqMDS0hK2trawtrZG165dufKsXbsWCQkJMDAw4HQBa9++Pfbs2YPdu3fD2NgYoaGhWLJkyXf3Q05ODrdu3ULz5s0xevRotG/fHjNnzkRBQQFdGSeEECIUFJ8pPhPSULGYyg98EEL4cnR0RHZ2Ns6dOyfqohBCCCHkC4rPhBBRozvVhBBCCCGEEEJILVGjmhBCCCGEEEIIqSXq/k0IIYQQQgghhNQS3akmhBBCCCGEEEJqiRrVhBBCCCGEEEJILVGjmhBCCCGEEEIIqSVqVBNCCCGEEEIIIbVEjWpCCCGEEEIIIaSWqFFNCCGEEEIIIYTUEjWqCSGEEEIIIYSQWqJGNSGEEEIIIYQQUkvUqCaEEEIIIYQQQmqJGtWEEEIIIYQQQkgtUaOaEEIIIYQQQgipJWpUE0IIIYQQQgghtUSNakIIIYQQQgghpJaoUd3IsFgsrF69mvPex8cHLBYLCQkJIisTIdWxevVqsFgsga4zODgYLBYLwcHBtV729OnTAi0TIYQQ0lD9SNz9lsrntzVd1snJSaDlIY0PNaoFqLyBWv6SkJBAs2bN4OjoiKSkJFEXr04qP7hW59VY5efnY/Xq1QIPQI3B+PHjwWKx8Pvvv4u6KIQQAascc79+LVu2jJPvypUrmDlzJjp16gRxcXHo6+vXaDufPn2Cu7s7OnXqBHl5eaiqqqJLly5YtGgRkpOTBbxX9Vd1Y3ljjmV79uyBj4+PqItR7+zZswcsFgsWFhaiLgohVZIQdQEaorVr16Jly5YoKCjA/fv34ePjgzt37iAiIgIyMjKiLl6d0r59exw9epQrbfny5VBQUMAff/wholLVLfn5+VizZg0AwMrKSrSFqUdyc3Nx4cIF6Ovr459//sHGjRsb9cUZQhqq8pj7tU6dOnH+ffz4cfj5+aFr167Q0dGp0bqLi4vRp08fREVFwcHBAc7Ozvj06RNevHiB48ePY9SoUTVeZ0NVOZYfOXIEV69e5Ulv3779zyxWnbJnzx6oqanB0dFR1EWpV3x9faGvr4/Q0FDExMSgdevWoi4SITyoUS0EQ4cORbdu3QAAs2bNgpqaGjZt2oTz589j/PjxIi5d3aKpqYkpU6ZwpW3cuBFqamo86Q1FSUkJysrKICUlReUQojNnzqC0tBSHDh1C//79cevWLfTt21fUxSKECNjXMZefDRs2YP/+/ZCUlMTw4cMRERFR7XWfO3cO4eHh8PX1xaRJk7g+KygoQFFRUa3LXVN5eXmQl5f/adurqcox+/79+7h69WqDjeUMw6CgoACysrJUDiGKj4/HvXv34O/vj7lz58LX1xfu7u6iLhYhPKj790/Qu3dvAEBsbCxXelRUFMaOHYumTZtCRkYG3bp1w/nz53mWz87OhouLC/T19SEtLQ1dXV1MmzYNmZmZAICioiK4ubnB1NQUysrKkJeXR+/evXHjxg2BlH/r1q1gsVh48+YNz2fLly+HlJQUsrKyAACvX7/GmDFjoKWlBRkZGejq6mLChAnIycn5oTJkZ2dj8eLF0NPTg7S0NFq3bo1NmzahrKyMkychIQEsFgtbt27F7t270apVK8jJyWHw4MF4+/YtGIbBunXroKurC1lZWYwcORIfPnzg2o6+vj6GDx+OK1euoEuXLpCRkUGHDh3g7+//w2Xy9PSEgYEBpKWl8fLly2rVW0JCAtTV1QEAa9as4XSfK39uyMrKiu/da0dHR64ujt8qB1D9v0V+tm7dCktLS6iqqkJWVhampqZ8nzMuf2bp3Llz6NSpE6SlpdGxY0cEBATw5L1z5w7MzMwgIyMDAwMD7Nu3r1pl+Zqvry8GDRqEfv36oX379vD19a3WclZWVujUqRPCwsJgaWkJWVlZtGzZEl5eXnzzl5WVYf369dDV1YWMjAwGDBiAmJgYrjy3b9/GuHHj0Lx5c0hLS0NPTw8uLi74/PlzjfeLEFIzOjo6kJSUrNWy5XG7Z8+ePJ/JyMhASUmJKy0qKgrjx4+Huro6ZGVlYWhoyNPrKjw8HEOHDoWSkhIUFBQwYMAA3L9/nytPedf2mzdvYv78+dDQ0ICuri7n8//++w+9e/eGvLw8FBUVYWNjgxcvXnxzXx49egQWi4XDhw/zfBYYGAgWi4WLFy8CAD5+/IjFixdzzjs0NDQwaNAgPH78+Jvb+J6ysjJ4enqiY8eOkJGRgaamJubOncs5hyhXHouDg4PRrVs3yMrKwsjIiNN13N/fH0ZGRpCRkYGpqSnCw8O5lnd0dISCggLi4uJgbW0NeXl56OjoYO3atWAY5ofKFBgYyClTeWzy9vZG//79oaGhAWlpaXTo0AF79+7lWf7Fixe4efMmJ5aXx++qxgzhN+7Nt8pRnfOSqvz777+wsbGBjo4OpKWlYWBggHXr1qG0tJQrX3mMfPnyJfr16wc5OTk0a9YMmzdv5lnnu3fvYGdnB3l5eWhoaMDFxQWFhYXfLcvXfH19oaKiAhsbG4wdO7basbz8Oy3/TSopKUFVVRWLFi1CQUEB32W+d37y5s0bzJ8/H4aGhpCVlYWqqirGjRtH4xIRAHSn+qco/7GpqKhw0l68eIGePXuiWbNmWLZsGeTl5XHy5EnY2dnhzJkzGDVqFAD2s1y9e/dGZGQkZsyYga5duyIzMxPnz5/Hu3fvoKamhtzcXBw4cAATJ07E7Nmz8fHjRxw8eBDW1tYIDQ1Fly5dfqj848ePx2+//YaTJ09i6dKlXJ+dPHkSgwcPhoqKCoqKimBtbY3CwkI4OztDS0sLSUlJuHjxIrKzs6GsrFyr7efn56Nv375ISkrC3Llz0bx5c9y7dw/Lly9HSkoKPD09ufL7+vqiqKgIzs7O+PDhAzZv3ozx48ejf//+CA4Oxu+//46YmBjs3LkTS5YswaFDh7iWf/36Nezt7TFv3jw4ODjA29sb48aNQ0BAAAYNGlSrMnl7e6OgoABz5syBtLQ0mjZtWq16U1dXx969e/HLL79g1KhRGD16NACgc+fOtfou+ZWjun+LVfn7778xYsQITJ48GUVFRThx4gTGjRuHixcvwsbGhivvnTt34O/vj/nz50NRURE7duzAmDFjkJiYCFVVVQDA8+fPMXjwYKirq2P16tUoKSmBu7s7NDU1q72fycnJuHHjBufkceLEidi+fTt27dpVrTvzWVlZGDZsGMaPH4+JEyfi5MmT+OWXXyAlJYUZM2Zw5d24cSPExMSwZMkS5OTkYPPmzZg8eTIePHjAyXPq1Cnk5+fjl19+gaqqKkJDQ7Fz5068e/cOp06dqvZ+EUJ45eTkcC4yl1NTUxPIulu0aAGA3ZV55cqV33yE5NmzZ+jduzckJSUxZ84c6OvrIzY2FhcuXMD69esBsGN/7969oaSkhN9++w2SkpLYt28frKyscPPmTZ5nRufPnw91dXW4ubkhLy8PALubtYODA6ytrbFp0ybk5+dj79696NWrF8LDw6t8Zrxbt25o1aoVTp48CQcHB67P/Pz8oKKiAmtrawDAvHnzcPr0aTg5OaFDhw54//497ty5g8jISHTt2rVW3yUAzJ07Fz4+Ppg+fToWLlyI+Ph47Nq1C+Hh4bh79y7XxY+YmBhMmjQJc+fOxZQpU7B161bY2trCy8sLK1aswPz58wEAHh4eGD9+PKKjoyEmVnGvqLS0FEOGDEH37t2xefNmBAQEwN3dHSUlJVi7dm2tyhQdHY2JEydi7ty5mD17NgwNDQEAe/fuRceOHTFixAhISEjgwoULmD9/PsrKyrBgwQIAgKenJ5ydnbkeb6tJXPsav3LU9LykMh8fHygoKMDV1RUKCgq4fv063NzckJubiy1btnDlzcrKwpAhQzB69GiMHz8ep0+fxu+//w4jIyMMHToUAPD582cMGDAAiYmJWLhwIXR0dHD06FFcv369Rvvq6+uL0aNHQ0pKChMnTsTevXvx8OFDmJmZVWv58ePHQ19fHx4eHrh//z527NiBrKwsHDlyhCtfdc5PHj58iHv37mHChAnQ1dVFQkIC9u7dCysrK7x8+RJycnI12jfSwDBEYLy9vRkAzLVr15iMjAzm7du3zOnTpxl1dXVGWlqaefv2LSfvgAEDGCMjI6agoICTVlZWxlhaWjJt2rThpLm5uTEAGH9/f57tlZWVMQzDMCUlJUxhYSHXZ1lZWYympiYzY8YMrnQAjLu7O0+Z4+Pjv7lvPXr0YExNTbnSQkNDGQDMkSNHGIZhmPDwcAYAc+rUqW+u63s6duzI9O3bl/N+3bp1jLy8PPPq1SuufMuWLWPExcWZxMREhmEYJj4+ngHAqKurM9nZ2Zx8y5cvZwAwxsbGTHFxMSd94sSJjJSUFFcdtGjRggHAnDlzhpOWk5PDaGtrMyYmJrUuk5KSEpOens6Vt7r1lpGRwVNv5fr27cv1XZVzcHBgWrRowXn/rXJU92+xKvn5+Vzvi4qKmE6dOjH9+/fnSgfASElJMTExMZy0p0+fMgCYnTt3ctLs7OwYGRkZ5s2bN5y0ly9fMuLi4kx1D1lbt25lZGVlmdzcXIZhGObVq1cMAObs2bNc+W7cuMEAYG7cuMFJ69u3LwOA+euvvzhphYWFTJcuXRgNDQ2mqKiIa9n27dtz1ePff//NAGCeP39e5XfEMAzj4eHBsFgsrv0khFRfefzi96qKjY0N17Hxe/Lz8xlDQ0MGANOiRQvG0dGROXjwIJOWlsaTt0+fPoyioiLPb7o8VjMM+/gmJSXFxMbGctKSk5MZRUVFpk+fPjz71qtXL6akpIST/vHjR6ZJkybM7NmzubaRmprKKCsr86RXtnz5ckZSUpL58OEDJ62wsJBp0qQJV9xRVlZmFixY8M11fc+CBQu46uL27dsMAMbX15crX0BAAE96eSy+d+8eJy0wMJABwMjKynJ9x/v27eM5jjs4ODAAGGdnZ05aWVkZY2Njw0hJSTEZGRm1LlNAQADPvvI7xltbWzOtWrXiSqt8flPO3d2d798tv3O0qspR3fOSqvDbh7lz5zJycnJc5wflMbL83I9h2H9DWlpazJgxYzhpnp6eDADm5MmTnLS8vDymdevWPPVVlUePHjEAmKtXrzIMw65DXV1dZtGiRTx5K58nlX+nI0aM4Mo3f/58BgDz9OlTrmWrc37C7zsKCQnh+T5I40Tdv4Vg4MCBUFdXh56eHsaOHQt5eXmcP3+e03Xrw4cPuH79OsaPH4+PHz8iMzMTmZmZeP/+PaytrfH69WvOaOFnzpyBsbEx37uF5VfMxcXFOXffysrK8OHDB5SUlKBbt24/3FWrnL29PcLCwri6sPv5+UFaWhojR44EAM6d6MDAQOTn5wtkuwD7Ll/v3r2hoqLC+a4yMzMxcOBAlJaW4tatW1z5x40bx3VXvPzK/5QpUyAhIcGVXlRUxDMyu46ODtf3raSkhGnTpiE8PBypqam1KtOYMWM43bjL/Yx6q6xyOWryt1iVr5/jysrKQk5ODnr37s13HwYOHAgDAwPO+86dO0NJSQlxcXEA2HcWAgMDYWdnh+bNm3PytW/fnnMHpTp8fX1hY2MDRUVFAECbNm1gampa7W5jEhISmDt3Lue9lJQU5s6di/T0dISFhXHlnT59Otfd7/LHPcr3CeD+jvLy8pCZmQlLS0swDMPTbZEQUjO7d+/G1atXuV6CIisriwcPHnB6afn4+GDmzJnQ1taGs7MzpytrRkYGbt26hRkzZnAdu4CKWF1aWoorV67Azs4OrVq14nyura2NSZMm4c6dO8jNzeVadvbs2RAXF+e8v3r1KrKzszFx4kSu2CMuLg4LC4vvPvZlb2+P4uJirkearly5guzsbNjb23PSmjRpggcPHgh0dPNTp05BWVkZgwYN4iq7qakpFBQUeMreoUMH9OjRg/O+PJb379+f6zsuT//6mFvu62mSyh9BKioqwrVr12pVppYtW/KNRV8f48t7TvTt2xdxcXE//PgbP/zKUdPzkm/tQ/n5QO/evZGfn4+oqCiuvAoKClzPyktJScHc3JyrDi5fvgxtbW2MHTuWkyYnJ4c5c+ZUez99fX2hqamJfv36AWDXob29PU6cOMHTLb0q5T0Fyjk7O3PK97XvnZ8A3N9RcXEx3r9/j9atW6NJkyZCO28j9Qd1/xaC3bt3o23btsjJycGhQ4dw69YtSEtLcz6PiYkBwzBYtWoVVq1axXcd6enpaNasGWJjYzFmzJjvbvPw4cP466+/EBUVheLiYk565RFRa2vcuHFwdXWFn58fVqxYAYZhcOrUKc5zYeXbcnV1xbZt2+Dr64vevXtjxIgRmDJlSq27fgPs7tjPnj3jaZSWS09P53pf+YSmfNt6enp80ys/N9W6dWueLn5t27YFwO7Kr6WlVeMyVVUPwq63yiqvtyZ/i1W5ePEi/vzzTzx58oTrWSl+3SQr1w3AfiyivA4yMjLw+fNntGnThiefoaEhTxDkJzIyEuHh4Zg2bRrXs81WVlbYvXs3cnNzeZ6DrExHR4dnQKCv/wa6d+9e5T6VP+bx9d9VYmIi3NzccP78eZ6/N2GccBHSmJibm39zoLIfpaysjM2bN2Pz5s148+YNgoKCsHXrVuzatQvKysr4888/OSfeX486XllGRgby8/M5XYa/1r59e5SVleHt27fo2LEjJ73yMfv169cA2A1Lfr53bDM2Nka7du3g5+eHmTNnAmBfIFdTU+Na5+bNm+Hg4AA9PT2Ymppi2LBhmDZtGtfFgJp6/fo1cnJyoKGhwfdzQcdyMTExnvJ+fRyvTZmqis13796Fu7s7QkJCeG4q5OTk/NA5ED/8ylHT85LKXrx4gZUrV+L69es8F3cqxyldXV2eGK+iooJnz55x3r9584bv+RS/v39+SktLceLECfTr1w/x8fGcdAsLC/z1118ICgrC4MGDv7ueyucTBgYGEBMT43kO+nvnJwC7S7uHhwe8vb2RlJTE9Xw+xXJCjWoh+DrA29nZoVevXpg0aRKio6OhoKDAGTBiyZIlVd59q8l0AceOHYOjoyPs7OywdOlSaGhoQFxcHB4eHjyDo9WWjo4OevfujZMnT2LFihW4f/8+EhMTsWnTJq58f/31FxwdHfHvv//iypUrWLhwIec5lq8HWamJsrIyDBo0CL/99hvfz8uDZLmvr+pXJ52pNGiJMMrEb1ROQdQbi8XiW/6qruBWLseP/i3evn0bI0aMQJ8+fbBnzx5oa2tDUlIS3t7eOH78OE9+QdZBVY4dOwYAcHFxgYuLC8/nZ86cwfTp0wW2ve/tU2lpKQYNGoQPHz7g999/R7t27SAvL4+kpCQ4OjpWawAZQkjd0KJFC8yYMQOjRo1Cq1at4Ovriz///FNo26vqmH306FFoaWnx5P+6N1ZV7O3tsX79emRmZkJRURHnz5/HxIkTuZYdP348evfujbNnz+LKlSvYsmULNm3aBH9/f84zszVVVlYGDQ2NKnsM8evNxY+gY3lNysQvlsfGxmLAgAFo164dtm3bBj09PUhJSeHy5cvYvn17tY7xVT2rX91YDtT8vORr2dnZ6Nu3L5SUlLB27VoYGBhARkYGjx8/xu+//86zDz8jll+/fh0pKSk4ceIETpw4wfO5r69vtRrVlVX1XVdnn5ydneHt7Y3FixejR48eUFZWBovFwoQJEyiWE2pUC1t5I6lfv37YtWsXli1bxrlyKikpiYEDB35zeQMDg+9O/3H69Gm0atUK/v7+XAcLQU85YG9vj/nz5yM6Ohp+fn6Qk5ODra0tTz4jIyMYGRlh5cqVuHfvHnr27AkvL69an3gYGBjg06dP3/2uBKX87u3X3+WrV68AgDMAjCDKVN16+9bAOCoqKny7vPEbqZ2fmvwt8nPmzBnIyMggMDCQqzeGt7d3jdcFgDNibvndmK9FR0d/d3mGYXD8+HH069ePM4jN19atWwdfX9/vNqqTk5N5pq+p/DdQXc+fP8erV69w+PBhTJs2jZMuyC6qhJCfS0VFhSs+lx9LvxWv1dXVIScnx/dYFhUVBTExMZ67sJWVd0/V0NCodfyxt7fHmjVrcObMGWhqaiI3NxcTJkzgyaetrY358+dj/vz5SE9PR9euXbF+/fpaN6oNDAxw7do19OzZ86dM/1RWVoa4uDiuxiS/WP6jZbpw4QIKCwtx/vx5rrud/LriVxXPy3s4ZWdno0mTJpz06sZy4MfOS4KDg/H+/Xv4+/ujT58+nPSv7xDXVIsWLRAREcFzPlWdWA6wG80aGhrYvXs3z2f+/v44e/YsvLy8vltvr1+/5rqzHxMTg7KyshrHcoB93ubg4IC//vqLk1ZQUIDs7Owar4s0PPRM9U9gZWUFc3NzeHp6oqCgABoaGrCyssK+ffuQkpLCkz8jI4Pz7zFjxuDp06c4e/YsT77yq2flV9e+vpr24MEDhISECHQ/xowZA3Fxcfzzzz84deoUhg8fztXoyM3NRUlJCdcyRkZGEBMTq/EUCl8bP348QkJCEBgYyPNZdnY2zzZ/VHJyMtf3nZubiyNHjqBLly6cOwOCKFN16618NEl+B20DAwNERUVx/c08ffoUd+/e/e72AdTob7GqfWCxWFxX0xMSEnDu3LlqbZ/f+qytrXHu3DkkJiZy0iMjI/l+15XdvXsXCQkJmD59OsaOHcvzsre3x40bN777nGBJSQnXNF5FRUXYt28f1NXVYWpqWuN9ArjrmWEY/P333zVaDyHk53v69CnPyOIAu7Hz8uVLTldWdXV19OnTB4cOHeI6dgHcsXrw4MH4999/ubqepqWl4fjx4+jVq9d3u29bW1tDSUkJGzZs4HpkqNz3jtkAu6u5kZER/Pz84OfnB21tba6GVGlpKU9XVg0NDejo6PxwLC8tLcW6det4PispKRFKw2TXrl2cfzMMg127dkFSUhIDBgwQWJn4HeNzcnL4XlyWl5evMpYD4HruOS8vj+/0Z1X5kfMSfvtQVFSEPXv2VHv7lQ0bNgzJyclcU2zm5+fjf//733eX/fz5M/z9/TF8+HC+sdzJyQkfP36s1tSflRvlO3fuBIBaXRwSFxfnuRu/c+fOaj/fTRo2ulP9kyxduhTjxo2Dj48P5s2bh927d6NXr14wMjLC7Nmz0apVK6SlpSEkJATv3r3D06dPOcudPn0a48aNw4wZM2BqaooPHz7g/Pnz8PLygrGxMYYPHw5/f3+MGjUKNjY2iI+Ph5eXFzp06IBPnz4JbB80NDTQr18/bNu2DR8/fuQa1ARgd9VxcnLCuHHj0LZtW5SUlODo0aMQFxev1nPhVVm6dCnOnz+P4cOHw9HREaampsjLy8Pz589x+vRpJCQkCGz6FIDdRWrmzJl4+PAhNDU1cejQIaSlpXEFSEGUqbr1Jisriw4dOsDPzw9t27ZF06ZN0alTJ3Tq1AkzZszAtm3bYG1tjZkzZyI9PR1eXl7o2LEjzzNRVanu3yI/NjY22LZtG4YMGYJJkyYhPT0du3fvRuvWrbmeraqJNWvWICAgAL1798b8+fNRUlKCnTt3omPHjt9dp6+vL8TFxXmm8io3YsQI/PHHHzhx4gRcXV2rXI+Ojg42bdqEhIQEtG3bFn5+fnjy5An+97//1Xi+23bt2sHAwABLlixBUlISlJSUcObMGZ7n/wghwvHs2TPOyXdMTAxycnI4PaeMjY359rgqd/XqVbi7u2PEiBHo3r07Z+7jQ4cOobCwEKtXr+bk3bFjB3r16oWuXbtizpw5aNmyJRISEnDp0iU8efIEAPDnn3/i6tWr6NWrF+bPnw8JCQns27cPhYWFfOf5rUxJSQl79+7F1KlT0bVrV0yYMAHq6upITEzEpUuX0LNnT66GZFXs7e3h5uYGGRkZzJw5k2sqqo8fP0JXVxdjx46FsbExFBQUcO3aNTx8+JDrDl1N9e3bF3PnzoWHhweePHmCwYMHQ1JSEq9fv8apU6fw999/cw1q9aNkZGQQEBAABwcHWFhY4L///sOlS5ewYsUKTrduQZRp8ODBkJKSgq2tLebOnYtPnz5h//790NDQ4LlYbWpqir179+LPP/9E69atoaGhgf79+2Pw4MFo3rw5Zs6ciaVLl0JcXByHDh3i1G11/Mh5iaWlJVRUVODg4ICFCxeCxWLh6NGjP9Sde/bs2di1axemTZuGsLAwaGtr4+jRo9Wadur8+fP4+PEjRowYwffz7t27Q11dHb6+vjznopXFx8djxIgRGDJkCEJCQnDs2DFMmjQJxsbGNd6n4cOH4+jRo1BWVkaHDh0QEhKCa9eucabcIo3czxpmvDEon/rg4cOHPJ+VlpYyBgYGjIGBAWd6jNjYWGbatGmMlpYWIykpyTRr1owZPnw4c/r0aa5l379/zzg5OTHNmjVjpKSkGF1dXcbBwYHJzMxkGIY9xcCGDRuYFi1aMNLS0oyJiQlz8eJFnmmVGKb2U2qV279/PwOAUVRUZD5//sz1WVxcHDNjxgzGwMCAkZGRYZo2bcr069ePuXbtWrXWXY7flBMfP35kli9fzrRu3ZqRkpJi1NTUGEtLS2br1q2cKY7Kp43asmUL17LlUx9VnuqLX321aNGCsbGxYQIDA5nOnTsz0tLSTLt27fhOE/YjZWKYmtXbvXv3GFNTU0ZKSoqnDo8dO8a0atWKkZKSYrp06cIEBgZWOaUWv3IwTPX/Fvk5ePAg06ZNG8535e3tzXd6EAB8p2hp0aIF4+DgwJV28+ZNzv62atWK8fLyqnLKkXJFRUWMqqoq07t372+Wt2XLlpzp0aqaUqtjx47Mo0ePmB49ejAyMjJMixYtmF27dnGtp6q/q/Lv2tvbm5P28uVLZuDAgYyCggKjpqbGzJ49mzNdx9f5CCHV962Yyy8fv1flY09lcXFxjJubG9O9e3dGQ0ODkZCQYNTV1RkbGxvm+vXrPPkjIiKYUaNGMU2aNGFkZGQYQ0NDZtWqVVx5Hj9+zFhbWzMKCgqMnJwc069fP66po6qzbzdu3GCsra0ZZWVlRkZGhjEwMGAcHR2ZR48efXN/yr1+/ZrzHdy5c4frs8LCQmbp0qWMsbExo6ioyMjLyzPGxsbMnj17qrXucpWn1Cr3v//9jzE1NWVkZWUZRUVFxsjIiPntt9+Y5ORkTp7yWFwZvzjCL745ODgw8vLyTGxsLDN48GBGTk6O0dTUZNzd3ZnS0lKBlolhGOb8+fNM586dGRkZGUZfX5/ZtGkTc+jQIZ7zq9TUVMbGxoZRVFRkAHCd64SFhTEWFhaMlJQU07x5c2bbtm1VTqlVVTmqc15Slbt37zLdu3dnZGVlGR0dHea3337jTGPGL0ZWxu/c5c2bN8yIESMYOTk5Rk1NjVm0aBFnurJvTalla2vLyMjIMHl5eVXmcXR0ZCQlJTnnwpXPjcrPGV6+fMmMHTuWUVRUZFRUVBgnJyee89fqnp9kZWUx06dPZ9TU1BgFBQXG2tqaiYqK4nseQxofFsMIcFQBQuo5fX19dOrUCRcvXhR1UYiIWFlZITMz87tjGRBCCKmbHB0dcfr0aYH21iP1y+rVq7FmzRpkZGQItDcjIVWhZ6oJIYQQQgghhJBaokY1IYQQQgghhBBSS9SoJoQQQgghhBBCaomeqSaEEEIIIYQQQmqJ7lQTQgghhBBCCCG1RI1qQgghhBBCCCGklqhRTQghhBBCCCGE1BI1qgkhhBBCCCGEkFqSEHUBhEF2wAZRF4HUgrRWc1EXgZBGI9t3isDXKWviVK18n8N3CXzbpH6QHbRJ1EUgtSCnQ/G5XqKhiOul90cmCnydFJ+Fr0E2qgkhhIiAmLioS0AIIYSQyig+Cx01qgkhhAgGi54oIoQQQuocis9CR41qQgghgsFiiboEhBBCCKmM4rPQUaOaEEKIYNCVcEIIIaTuofgsdNSoJoQQIhh0JZwQQgipeyg+Cx01qgkhhAgGDYRCCCGE1D0Un4WOGtWEEEIEg7qXEUIIIXUPxWeho0Y1IYQQwaDuZYQQQkjdQ/FZ6KhRTQghRDDoSjghhBBS91B8FjpqVBNCCBEMuhJOCCGE1D0Un4WOGtWEEEIEQ4xCCiGEEFLnUHwWOvqGCSGECIYYXQknhBBC6hyKz0JHjWpCCCGCQc9sEUIIIXUPxWeho0Y1IYQQwaBntgghhJC6h+Kz0FGjmhBCiGDQlXBCCCGk7qH4LHTUqCaEECIYYuKiLgEhhBBCKqP4LHTUqCaEECIY1L2MEEIIqXsoPgudSPsCXL16Fe7u7rh+/ToA4NatWxg6dCj69+8Pb29vURaNEEJITbHEqvci9QLFaEIIaSAoPgudyL69Y8eOYdiwYbh48SJGjhwJHx8fjBw5Erq6umjZsiXmzZuH06dPi6p4hBBCaorFqt6L1HkUowkhpAGh+Cx0Iuv+/ddff+Gvv/7CwoULERQUBFtbW6xfvx4uLi4AgA4dOsDT0xNjx44VVREFbu5IU7iMt4BmUwU8j02D684reBSdUmV+p9FmmD2iK/Q0lPA+5zPO3orCqgM3UFhcCgCYbdsVs0d0RQtNZQBA5JsMbDh6B1dC4zjrkJYUx8ZfBmJcv/aQlpTAtYdxWLQjEOlZecLd2QZk1qC2WGjTARrKsohIzMJvhx/icdz7KvP/MqQdZgxoC101Obz/WIjzoYlY4xeOwuIyAIDLiI6w7dYcbXSUUFBUitDXGXA/EY6YlFzOOqQlxfDnZFOM6a4PKUkxXH+Wgl+9Q5GRWyD0/W0oqN5EgK5yNxiNLUbPHWECl3EW0Gwqj+ex6XDdfe3b8XlUN8y27VIRn29HY9XBm5z4vGRCd9j1aou2ek3xubAED14m4Y8DN/H63QcAQHNNJUQf+4XvuievOwf/W9GC38kGaOaANnAa2g4ayrJ48TYLy46F4XHchyrzzx1siBn9W6OZqhw+fCzE+Udvse7UU85xvoehOpyGtkcXfRVoqchh6t+3cPlxEtc65KUl4DbeGMO66kJFQQqJGXn439VX8LkRI9R9bUhmDmgDp2Ff1dvR79SbdaV6e8in3oZ9VW+evPWmriQDd3tj9OukBSU5KYREZ2DZ0UeIS/sk1H2tMyg+C53IvuHXr1/D1tYWADBgwACUlJRgwIABnM9tbGwQFRUlquIJ3Fir9tg0bwDWH7mDHvMO4VlsOs5vmgD1JnJ889v374B1s/thw5Hb6DL9f5i39RLGWrXH2llWnDxJmblYtf8GLH85hJ7zvREc/gan1o5D+xZqnDyb5w+CTffWmLzmLAa7HIO2mgJOrB4t7N1tMEZ1b4H1k02xyf8Z+q68jIjELPgv6w81JWm++cda6sPd3gSbzj6DxdILcN5/H6O6t4DbeBNOnp7tNHHgWjQGuQdg1MZrkBAXw9ll/SEnXTGIxIYp3TDERBeOO27BZt1VaKnI4qhLH6Hvb0NB9SYiYuLVe5E6rzHF6LF922HT3P5Yf+wuevzig2dx6TjvMb7q+NyvPdbN6osNR++iy8wDmLftP4y1aoe1M/py8vTurAev84/Rd+ExDF/mBwkJcVzcOB5yMpIAgHcZH6E/fhfXa+3h2/iYX4jAry6Mk6rZmTfHuokm2PJvBPq7ByDibTZOLekHNUX+x/kx3VvAbZwxNp+LQI/ll7HwUChGmTfHyrHGnDxy0hJ48TYLvx0Nq3K76yaZoL+RNubtC0GP5ZfhdSUam6aaYohJM4HvY0NkZ9Ec6yaZYMu5CPR3C0BEYjZOLf1GvfX4qt6WXcbCg6EYZdEcK8dVqrfELPx2pOp6O7q4N1qoK2CK5230WxWAt5l58P+9P+SkGklMovgsdCJrVEtKSqKoqIjzXlpaGgoKClzvP3/+LIqiCcXCsebwvvwERwOfIepNJpw9/8PnwhI4DDHmm797R12ERLyD3/WXSEzLQVBYPE7eeIluhjqcPJdDYhAYGovYpCzEvPuA1Ydu4tPnIph3YB/YleSl4TjUGL97BeHmkzcIf52KOZsvoUcnPZi31+G7XcJtwdD2OHwjBr634hCdlAOXQw+QX1iKKX1b881v3kYdD16l4/S9BCRm5uHG8xScCUlAVwNVTp6xm6/j+K04RCXlICIxG/P33YOemgK6tGTnUZKVxFQrA/zhG4ZbL9PwNOEDFuwLQfe2GujWWo3vdgk3qjcRoWe2GozGFKMXjjGD939PcTTwOaIS38P570B8LiyGg7UR3/zdOzZDyIt38LsRicS0XASFJeDkjUh0a6fNyTNyxSkcuxKByDeZeB6XgTlbLqG5pjJM2mgCAMrKGKRl5XG9RvRsizM3o5FXUPxT9ru+mz/EEEdvxuL47XhEJ+fiV5+H+FxUgsl9WvHNb95GDaGvM3Dm/hu8zcxDcEQqztxPRNdWFcf5oGcp2HDmOS6Fvatyu+at1XDiTjzuRqXjbWYejgTHIuJtNrq2airwfWyI5g8xxNHgSvVWWILJfauot9Zf6i2k9vVmoKUIs9ZqWHL4IcLjPyAm9SOWHH4IGSlxjO7RQij7WedQfBY6kX17rVu35rrKnZSUhJYtW3Lex8bGQldXVxRFEzhJCTGYtNXG9ccJnDSGAa4/juc0gCu7/+IdTNpqoZshO0jrazeBtbkBAkJj+eYXE2NhXL8OkJeRxIOX7C4vJm20ICUpjuth8Zx8r96+R2JaDiyq2C6pICkuhi4tm+JmREUXQIYBbkakwLwN/0ZS6OsMdGmpyjnYt1BXwCDjZrj6JIlvfgBQkmPfucj6VAgA6NKyKaQkxLm2+zolF28zP8G8sTTOfgDVmwjRM1sNRmOJ0ez4rIXrj99w0tjxOeEb8TkJJm2+is9ayt+MzwD7IjcAZH3k/yiISRtNdGmticMBz2q7K42KpLgYjPWb4uaLVE4awwA3X6TBrIrjbejrTBjrN+U0fluoy2OQsTauPU2u0bZDYzIx1KQZtFVkAQC92mmgtaYibkSkfmdJUmW9vfxGvcX8eL1JSbCbO+Xdxcu3W1Rciu5t1WuzK/UPxWehE9kz1StWrICKigrnvZKSEtfnjx49wvjx4392sYRCTVkOEuJiPM8xp2flwVBPle8yftdfQlVZDkF/TwOLBUhKiON/5x9jy/F7XPk6tlRH8E4HyEhJ4NPnIti7n0HUm0wAgFZTeRQWlSAnr5Bnu5pNFUC+TVVRml1vOdwnQem5BWijo8x3mdP3EqCqKI0A98FggQVJCTEcvPYK286/4JufxQI8pnZDSHQ6It/lAAA0msiisLgUOfncdyvScwqg0URWAHvWsFG9iRBd5W4wGkuMrjo+51cdn29EsuPz9skV8flCOLb8c59vfhYL2PLLANyLeIeXCZl88zgM6YzIN5m4/7LqC3mkQpXH+ZwCtNFW5LvMmftvoKoojUt/DOQc572vv8b2iy9rtO1lR8Owfbo5IjztUFxShjKGgYt3KEKiM2q9P40Fp95ya1BvIW+gqiCNSyu/qreg19h+ofr1xr7AnYdV44zh6h2K/MJS/DLEEM1U5aFJ8ZkIiMga1aNGjfrm58uWLavWegoLC1FYyN1oZMpKwBKr31Nw9zZujqWTLLFoRwAeRibDQEcFWxcMQsqUnth47C4n36u372Ex5yCU5aUxqk877P/dFoNdj3Ea1uTn6tVeE64jOuFX74cIi81EK01FeEzthqV2Rthy7jlP/q2O5uig2wRD1l4RQWlJOao3AaHnsRoMQcToBhufO+th6cTuWLTzCjs+N1PB1vkDkTLZEht97/Hk93QejI766hjg4st3fTJSErDv34HvskRwerbTwOLhHbD0yCOExb5HK01FbJjcFb+O6Ii/qriAys/sQW3RzUAVk7bfxNv3+bA0VMfmqd2QmvUZN1+mCXEPGqee7TSw2LYDlh7+qt6mdMWv2R3x17/Vq7eSUgYOO27j75kWiPMai5LSMtx8kYarT5PRaO7NUnwWuvod2QB4eHhgzZo1XGni+v0h2WpAFUv8fJk5+SgpLYOGijxXuoaKPFI/8B+F2316X/xzNQI+l58CAF7EZ0BOVhK7XYZhk+9dMAw7X3FJGeKSswAA4a9TYWqojQWjzeC8/T+kfsiDtJQElOWlue5Wa6jII+1DIxnt8Ae8/1jIrjdlGa50DSUZpOfwf5ZwxVhj+N2Jx9Fg9iigL99mQ05aAp4zLbD13+ecegOAzQ5msDZpBpt1V5D8IZ+Tnp79GdKS4lCWk+S666mhLIP07IbxDKMwUb2JEHUdI1/hG59bDoCkwSARlYhX1fFZDqlVzJLh7tgb/1x7AZ//2F21XyRkQk5GErsXD8Gm4/e4jhfbnQZimIUBBv56HEmZH/mub1QfQ8hJS8L3aoRgdqoRqPI4ryzDc/e63PLRRjh5LwHHbrIHgot8lwM5aQlsczTDtgsvuOqtKjKS4lg5tjOm7biDq1+6H798m41OzVWwYGh7alR/B6felGpQb2OqqLfpZth2vnr1BgBPE7JgtSoAirKSkJIQw/uPhbjiPghP4qsedbxBofgsdHW2L8CKFSswY8aM7+Zbvnw5cnJyuF4S+n2/u9zPVFxShvBXKehnos9JY7GAfib6CK2iq5estATKKh0pykqZL8tW/cMQE2NBWpJ9NSr8dSqKikvRr2vFdtvoNkVzTWXOc9ekasWlZXgS/wF9O2px0lgsoE8nLYS+5t8TQE5anKfeSsu+1NtX10M3O5hheDc9jFh/DW8yuE/cnsR/QFFJKdd2W2srQU9NAaEx1APhe6jeRIfFYlXrReq/6sRovvG5Zb+fVMLqYcfnVPQzqRis6PvxWZI3PpfxxuftTgMxomdbDPntBN6k5lRZBschnXEpJAaZVVz0I7yKS8vwNOED+nSodJzvoImHVRxvZaUlwFTjOP8tkuIsSEnwjxdidfaMuu7g1Fvl+PytepOSAFP2Y/X2tY+fi/H+YyFaaSqgS8umPFNvNVQUn4Wvzt6pfvfuHd69q3r0xXLS0tKQluYehr8udi3bcToU+3+3RdirFDyKSobTGHPIyUjiSCD7SveB322RnPkRbgeDAbBH9l441hxPY9IQGpkEg2YqcJveB5dDXnOC99qZVggMjcXb9FwoyknBvn9H9DFuAdtl/wAAcvMK4fPfU2z6ZSA+fCzAx7xCbHMejPsv3iE0smYDczRWu/+LxN65lgiP/4Cw2Ez8MqQ95KUl4HuTPSCN1zxLJGflY63fEwBAwOMkzB/WDs8S2Plbairij7HGCAh/xwnCWx3NMM6yJSZtC8angmLOlfbc/GIUFJci93MxjgbHYv0UU2TlFSE3vxibHczw4FUGHjWSxtmPonoTDQrIjUd1YnS9ic9nHmL/bzYIe5WKR9EpcBrV7Ut8Zj/6ceA3G3Z8PnQLAHD5fgwWjjHD05h0hEaxH89yc+iNy/djOPHZ03kQ7Pt3wDh3f3zKL4LmlzvhOXmFKCgq4Wy7lU4T9DLSg90fp37yXtd/ewKisXt2dzyJ/4DHce8x19oQctISOH6bPTjrnjndkZL1GetOsXv8BYYnYf6Qdnj2JovTjXj5aCMEPkniHOflpSXQUrNizJnm6gro1LwJsj4VIelDPj4WlOBOZBrW2HdBQVEp3mbmoWc7Ddj31Meqf8J//pdQD/HU2+Av9Xarinp7wqfexlSz3vKKkPSe3aNshJke3n8sxLv3eeig1wQbJnfF5bAkBDeSAeYoPgtf3YtuXxw5ckTURRCo08GRUFOWg5tjH2iqyONZbBpGLvPjDI6ip6HEdeVz47E7YBgG7tP7QEdNEZnZ+bh0PwarvzS6AUBdRQ4Hl9lCq6kCcvIKERGXDttl/+B6WAInz297rqKMYfCP+2hIS4rj2qN4LPo74Gftdr139v4bqClKY8XYztBQlsXzN1kYs+k6Mr4MsqGrKs9Vb1vOPQcDBivHdYF2U1lk5hYiIPwd/jz5hJNn1iBDAMClVYO5tjV/3z0cv8Xu3rTi2COUMaY4sqgPpCTEcf15Mn71DhXy3jYcVG8iIsSYvXv3bmzZsgWpqakwNjbGzp07YW5uXmV+T09P7N27F4mJiVBTU8PYsWPh4eEBGRn2xRAPDw/4+/sjKioKsrKysLS0xKZNm2BoaCi8nWhAGlKMPn0zCmpN5ODm0OtLfE7HyBUnkZ7NPhnnic++7C7e7o69oaOmgMycz+z4/KXRDQBzR3QFAFz9axLXtmZvuYRjVyq6eTsM6YykzI+49tUsHaR6zoUmQk1JGstGG0FDWQYRiVkYvzWYc5xv1lSOc5EDAP46/wIMgBVjOkNbRRbvPxYiMDwJf56pGHG9S8umOL+84vHB9ZPY9fjP7Tg4HXgAAJi99x5WjTPGvnk90EReCu8y87H+9DN4X4/5CXtd/517kAg1xUr1tuWrelOV4/q9/fUvu4v3irGV6u10pXpb8VW9Tf6q3vaz602riSz+nGQCdWUZpGUXwO9uPLaeq/6z9PUexWehYzGV+8L8RJmZmTh06BBCQkKQmsq+UqSlpQVLS0s4OjpCXb12w9zLDtggyGKSn0Raq7moi0BIo5HtO0Xg61S0P1ytfB/9HGq0Xj8/P0ybNg1eXl6wsLCAp6cnTp06hejoaGhoaPDkP378OGbMmIFDhw7B0tISr169gqOjIyZMmIBt27YBAIYMGYIJEybAzMwMJSUlWLFiBSIiIvDy5UvIy8vzrLMxEkaMlh20SdDFJD+BnA7F53pJZGf45Ee8PzJR4Ouk+Cx8ImtUP3z4ENbW1pCTk8PAgQOhqakJAEhLS0NQUBDy8/MRGBiIbt261Xjd1Kiun6hRTcjPI4xGtdKE6t29zD0xrUbrtbCwgJmZGXbt2gUAKCsrg56eHpydnfmOQu3k5ITIyEgEBQVx0n799Vc8ePAAd+7c4buNjIwMaGho4ObNm+jTp0+NytcQCStGU6O6fqJGdT1Fjep6SRiNaorPwiey7t/Ozs4YN24cvLy8ePr5MwyDefPmwdnZGSEhISIqISGEkJoQxjNbRUVFCAsLw/LlyzlpYmJiGDhwYJXxwdLSEseOHUNoaCjMzc0RFxeHy5cvY+rUqVVuJyeHPZBU06ZNBbsD9RTFaEIIaTiqG5/5TYXIb3wMgOJzZSJrVD99+hQ+Pj58K5nFYsHFxQUmJiYiKBkhhJBaqWabuiZBOzMzE6WlpZw7peU0NTURFRXFd/2TJk1CZmYmevXqBYZhUFJSgnnz5mHFihV885eVlWHx4sXo2bMnOnXqVL2daOAoRhNCSANSzfjMbypEd3d3rF69micvxWduIpsAQEtLC6GhVQ/gExoaylNJhBBC6q7qTtnh4eEBZWVlrpeHh4fAyhEcHIwNGzZgz549ePz4Mfz9/XHp0iWsW7eOb/4FCxYgIiICJ06cEFgZ6juK0YQQ0nBUNz7zmwrx6zvRP6ohx2eR3alesmQJ5syZg7CwMAwYMIDnea39+/dj69atoioeIYSQGhKr5kSty5cvh6urK1cav7vUAKCmpgZxcXGkpaVxpaelpUFLS4vvMqtWrcLUqVMxa9YsAICRkRHy8vIwZ84c/PHHH1zldHJywsWLF3Hr1i3o6upWq/yNAcVoQghpOKobn6vqNcYPxWduImtUL1iwAGpqati+fTv27NmD0tJSAIC4uDhMTU3h4+OD8ePHi6p4hBBCaqi6z2zVJGhLSUnB1NQUQUFBsLOzA8DuDhYUFAQnJye+y+Tn5/OcQIiLiwNgPw9c/n9nZ2ecPXsWwcHBaNmyZbXK01hQjCaEkIZDGGOeUHzmJtJ5qu3t7WFvb4/i4mJkZmYCYF/1kJSUFGWxCCGE1IaQ5sF0dXWFg4MDunXrBnNzc3h6eiIvLw/Tp08HAEybNg3NmjXjdCG3tbXFtm3bYGJiAgsLC8TExGDVqlWwtbXlBO8FCxbg+PHj+Pfff6GoqMiZMkpZWRmysrLC2ZF6hmI0IYQ0EBSfhU6kjepykpKS0NbWFnUxCCGE/ABhXAkH2I27jIwMuLm5ITU1FV26dEFAQACnS3JiYiLXle+VK1eCxWJh5cqVSEpKgrq6OmxtbbF+/XpOnr179wIArKysuLbl7e0NR0dHoexHfUUxmhBC6jeKz8InsnmqhYnmqa6faJ5qQn4eYcxTrT7dr1r5MrztBb5tUj/QPNX1E81TXU81uDP8xkEY81RTfBa+OnGnmhBCSP3HEhNS/zJCCCGE1BrFZ+GjRjUhhBCBEFb3MkIIIYTUHsVn4aNGNSGEEIGgoE0IIYTUPRSfhY8a1YQQQgSCgjYhhBBS91B8Fj5qVBNCCBEICtqEEEJI3UPxWfioUU0IIUQgaCAUQgghpO6h+Cx81KgmhBAiEHQlnBBCCKl7KD4LHzWqCSGECAQFbUIIIaTuofgsfNSoJoQQIhgUswkhhJC6h+Kz0FGjmhBCiECIiYmJugiEEEIIqYTis/BRo5oQQohAUPcyQgghpO6h+Cx81KgmhBAiEBS0CSGEkLqH4rPwUaOaEEKIYFDMJoQQQuoeis9C1zAb1R8/iLoEpBYKFVRFXQRSG+/fiboEpI6gK+Hku7JSRV0CUgv5ElKiLgKpjbR4UZeA1MpEga+R4rPwNcxGNSGEkJ9OTIyCNiGEEFLXUHwWPmpUE0IIEQi6Ek4IIYTUPRSfhY8a1YQQQgSCYjYhhBBS91B8Fj5qVBNCCBEIuhJOCCGE1D0Un4WPGtWEEEIEgmI2IYQQUvdQfBY+alQTQggRCHFxitqEEEJIXUPxWfioUU0IIUQgqHsZIYQQUvdQfBY+alQTQggRCIrZhBBCSN1D8Vn4qFFNCCFEIOhKOCGEEFL3UHwWPmpUE0IIEQgK2oQQQkjdQ/FZ+KhRTQghRCDExChoE0IIIXUNxWfho0Y1IYQQgaAL4YQQQkjdQ/FZ+KhRTQghRCCoexkhhBBS91B8Fj4xUReAEEJIw8BiVe9VG7t374a+vj5kZGRgYWGB0NDQb+b39PSEoaEhZGVloaenBxcXFxQUFPzQOgkhhJD6SJjxmbBRo5oQQohAsFisar1qys/PD66urnB3d8fjx49hbGwMa2trpKen881//PhxLFu2DO7u7oiMjMTBgwfh5+eHFStW1HqdhBBCSH0lrPhMKlCjmhBCiECIibGq9aqpbdu2Yfbs2Zg+fTo6dOgALy8vyMnJ4dChQ3zz37t3Dz179sSkSZOgr6+PwYMHY+LEiVx3omu6TkIIIaS+ElZ8JhWoUU0IIUQghNG9rKioCGFhYRg4cCAnTUxMDAMHDkRISAjfZSwtLREWFsZpRMfFxeHy5csYNmxYrddJCCGE1FfU/Vv46sxAZcnJydi3bx9iYmKgra2NWbNmoV27dqIuFiGEkGqqbtexwsJCFBYWcqVJS0tDWlqaJ29mZiZKS0uhqanJla6pqYmoqCi+6580aRIyMzPRq1cvMAyDkpISzJs3j9P9uzbrbOwoRhNCSP1FXbuFT2R3quXk5JCRkQEAePnyJTp06IDjx4+juLgYly5dgqmpKZ49eyaq4hFCCKmh6l4J9/DwgLKyMtfLw8NDYOUIDg7Ghg0bsGfPHjx+/Bj+/v64dOkS1q1bJ7BtNHQUowkhpOGgO9XCJ7I71QUFBWAYBgCwYsUK9OnTB/7+/pCQkEBZWRkmT56MP/74AxcuXBBVEQVu7lhLuEyxgqaqIp6/ToHr1rN49PJtlfmdJvTG7DE9oKepgvc5eTh7/RlW7b6MwqISAMDsMT0we3QPtNBuCgCIjE/FhgPXcCWk4k5L4N5f0MfUgGu9+/1DsHDjGSHsYcM0d1hHuNgZQ1NFFs8T3sP1f3fx6HVGlfmdbI0we2gH6Kkp4P3HApy9F4dVR0JRWFwKAFgypgvserREW90m+FxYigdRqfjjyAO8TsrhrCPwT1v0MdLhWu/+gJdYuPe2cHayAZo72hwuE3tBs6kCnsemwnX7JTyKTKoyv9O4Hpg9yhx6msp4n52Ps8EvsGrf1Yrfm50ZZtuZo4V2EwBAZHw6NvgE48r91wAAFUVZrJrZHwPMW0NPUxmZ2Xm4cCsSaw4EITevsKrNNijVfR5r+fLlcHV15Urjd5caANTU1CAuLo60tDSu9LS0NGhpafFdZtWqVZg6dSpmzZoFADAyMkJeXh7mzJmDP/74o1brbGwaW4yeO64nXKb2/xKfk+G6xR+PXiRWmd9pYh/MHtsTeppN8D77S3zedfGr+GyJ2WN7VsTnuFRsOBCIK/cq4vPOFePQ37wttNWU8OlzEe4/i8fKHRfx6g0Nllddc4cbw2WsKTRV5PE8LgOue2/g0au0KvM72Zlgtk1n6Kkr4X3uZ5y98xqrvO9UxOfxZrDr2RptdZvic1EJHrxMxh+H7uB1UhbXeizaaWO1gyXM2mmjtKwMz2IzYLvSHwVFpULd34Zi7vjecJnWH5qqSnj+Kgmum09/+/c2yYr9e9NSYf/egp5g1c4LFb+3sb0we1xPtNBWBQBExqVgw/8CcOVeJN/1nds5D9Y9O2C8635cCH4u+B2sg+h5aeGrE92/Hz9+DF9fnoz42wAAblFJREFUX0hIsIsjJiaG3377DTY2NiIumeCMHWiMTYtHwHnjGTx8kQinCb1xfsdsGI/bjIysTzz57a1NsG7BMMz78yRCniWgTXN17HezB8Mw+N2TfRKTlJaDVbsvI+ZtJlgsYIpNN5za6ojuU7cjMq4iqBw8ex/r/hfIeZ9fUCT8HW4gxvYywKYZPeC89zYevkqDk21nnF9tA+P5J5CRU8CT375Pa6ybZo55O28iJCoVbXSaYP8iKzAM8Psh9rOavTvpwOvyC4S9zoCEOAtrpprj4mobmDidRH5hCWddBwMjse74Q877rz8j3za2fydschoK563n8fDlOziN74Hz2xxgPPFvZGTn8eS3H9QZ6+YNwryN5xDyPBFt9FSx/4/R7N/brgAAQFJGLlZ5XUHMu/dgsViYMtQEpzwmofuMvYiMT4e2miK01RSxfHcAIuPT0VyrCXYuHQFtNSVMWnXiZ38FIlHd7mVVdfXmR0pKCqampggKCoKdnR0AoKysDEFBQXBycuK7TH5+PsTEuDtiiYuLAwAYhqnVOhuzhh6jxw7qgk0udnD2OIWHEW/gNLEvzu+cC+MxHlXE565Y5zQc89aeQMizeLRproH9qyeyjxfb/wUAJKXnYNWui4hJzGAfL4ab4dRfM9F98l+IjEsFAIRHvsOJ/8LwNjULTZXk8cdca1zcPQ/tRqxDWRnzU7+D+mhsn7bYNKcPnHcG4WF0KpzsuuL8n6NhPNsHGTmfefLbWxli3fRemLf9CkJepqCNbhPsd7Vm19v+WwCA3ka68LrwFGGv0tjx2bEnLq4fDZO5hzkx2KKdNv79cxS2+j2E695glJSWoXMrdVCVVc/YwSbY5DoKzhv88PD5GzhN7ovzu+fDeNSf/H9vQ0yxztkW89YcR8jTeLRpoYH9ayazz6u2nQUAJKVnY9WOC19+b8AUW3Oc2j4b3Sdu5vzeyjlPtuJcMGxMqPu38ImsUf310O1iYmJQVlbm+rxJkybIysrit2i9tHBSX3ife4CjF9mNJOeNZzC0Z3s42Jph65EbPPm7G+kj5FkC/ALDAQCJKVk4eeUJzDo25+S5fOcl1zKr9wZg9mhLmHdqwdWo/lxQhLT3H4WxWw3ewpFG8L4SiaNB0QAA5723MLRbczgMbIetZ57w5O/eThMhkWnwuxUDAEhM/4STt2Jg1laDk2fkmstcy8z5OxhvjzrAxEAdd1+mcNI/F5YgLZv3xIB838IJlvC+8AhHL7N/P85bLmBoD0M4DO+Krcd47/Z376SHkOeJ8LvK7s6amJqNk9eew6yDLifP5bvRXMus/t81zLYzg3kHXUTGp+NlfDomrqxoPMcnZ2H1/67h0KqxEBcXQ2lpmTB2tU4RVtB2dXWFg4MDunXrBnNzc3h6eiIvLw/Tp08HAEybNg3NmjXjdCG3tbXFtm3bYGJiAgsLC8TExGDVqlWwtbXlNK6/t87GrjHF6IWTreB9LgRHL7AHtnP2OIWhvdrDYYQFth4O4snf3VgfIU/j4Rf4GMCX+Bz4GGadWnDyXL79gmuZ1XsuY/YYS5gbteCc5B86WzEoXmJKFtbsuYyHJ35DC+2miE96L/D9bGgWjuoK7/8icPQq+1zIeec1DDVrCYfBnbD11EOe/N3b6yDkZTL8gtnH8sT0XJwMjoZZu4reKSNXneVaZs62K3h7Yh5M2mjibgS7p9PmuX2x599wrm1UvpNNqrZwcj94n72Ho+cfAACc15/E0F4d4TCyO7b6XOPJ3924JUKexsEvIAwAkJjyAScDwrh/b7ciuJZZvfsSZo/tBXMjfa5Gdee2zbBoSn/0nLIFCVfXC2P36ixqVAufyJ6pZhgGbdu2RdOmTZGcnMzzbFZMTEyD6YYnKSEOk3bNcP3hK04awzC4/vA1zI1a8F3m/vMEmLTTRbcOegAAfZ2msLZsh4AqurKIibEwblAXyMtK4cHzN1yf2Q/pirdX1uDRP0uwdv5QyEpLCmjPGjZJCTGYGKjj+tOKLsMMA1x/+g7mhpp8l7kflQYTAzV0a6MOANDXVIS1aXMEhFXdzV9JTgoAkPWJ+863fd/WeHt0Gh7tGIe1U80hK1UnOpbUeZIS4jBpq4Prj+I4aQzD4PqjWJh31OO7zP2ItzAx1EG39s0AAPo6KrDu3hYBIa/45hcTY2HcACPIy0jhwYtv1K28DHLzChtFgxoQ3jNb9vb22Lp1K9zc3NClSxc8efIEAQEBnIHGEhMTkZJScUFq5cqV+PXXX7Fy5Up06NABM2fOhLW1Nfbt21ftdTZ2jSVGs+OzLq4/qBSfQ1/DvHMV8flpAkza66Hbl4vc+s1UYd2zAwLufiM+DzaBvKw0HjxL4JtHTkYK00ZYIP7de7xLy/6hfWoMJCXEYNJGE9efVHQZZhjg+pNEmLfX5rvM/chkmLTWQLe27N+4vpYyrM30EfAwvsrtcOLzR3Z8VleWhXk7bWTkfMaNv+yRcHwOrmweB8uOOlWug1SQlBCHSXs9XH9QcZGaYRhcfxAN884t+S5z/2k87++tVwcE3H3JNz/799aV5/cmKyMJnw0OWLzxVKO80STMZ6p3794NfX19yMjIwMLCgmv6Sn48PT1haGgIWVlZ6OnpwcXFBQUF3OfANV1nXSCys3Rvb2+u961bt+Z6f//+fYwaNepnFklo1JrIQ0JCHOkfuLu1pH/4CMMWGnyX8QsMh6qyPIL2LwCLxYKkhDj+d+Yetvhc58rX0UALwQedISMlgU+fi2D/mw+i4tO+Ws9jJKZmISUjF0attfGnkw3attDAhN8PC35HGxg1JRlIiIshvdLd4vTszzDUbcJ3Gb9bMVBVkkGQx0iwWOwA8r//XmDL6XC++VksYMssS9x7mYKXiVlc60nM+IiUD/kw0m+KP6dZoG2zJpiw8YrA9q+hUlOWq+L39gmGLdT4LuN39RlUleUQtGdWxe/tbCi2HL3Fla9jK00Ee82u+L2tOI6oBP7P16sqy2G5oxUOXXgkmB2rB4R5JdzJyanKrtnBwcFc7yUkJODu7g53d/dar7OxaywxuiI+c59kp3/4CEP9quLzY6g2kUfQAeeK48Xpu9jizX2XraOBNoK9F1UcL5Ye4orPADBnbE+sX2gLBTlpRCekwWbBXhSX0HO536OmJMuOz1n5XOnpWfkw1FXhu4xfcDRUlWQRtNW+Ij5feootfrx3tYEv8XmuFe69SMLLN+yeAy212T02/pjcHcsP3MKzuAxMHtABlz3GwHTeUcQmZwtuJxugb//e+F/Q9AsIY//eDi0GCyxISorjf6fuYMuhq1z5OrbWRrCP65ffWyHsfz2AqPiKu9Sbfx2N+0/jcfFm43iGujJhxWc/Pz+4urrCy8sLFhYW8PT0hLW1NaKjo6GhwXsMPX78OJYtW4ZDhw7B0tISr169gqOjI1gsFrZt21ardVZWUlKC4OBgxMbGYtKkSVBUVERycjKUlJSgoKAg8O+gnMga1Q4ODt/8fNWqVdVaD7+pWZiyErDE6vddvd5dDbB0en8s2uyPhxGJMNBTw1bXkUiZMRAbD1UE7ldvMmAxZRuUFWQwqn9n7HefgMHz9nIC96FzDzh5X8SmIuX9RwTsmYeWzVSpe5kQ9O6kjaVjTbBo3x08fJUOA20lbJ1liZTxXbHx5GOe/J5ze6Fj86YYsPxfrvRDVyrueLx48wEpH/IR8KctWmopIT41V+j70dj0NtHH0ql9sOivi3j48h0MdJti66JhSMm0wsbDwZx8rxIzYTF9D/v3ZtUR+/8Yg8HOB3ka1opy0ji7ZQoiE9Lx58HraCxoIJSGQxAxusHGZ1MDLJ0+EIs2nq6Iz0tGIWXmIGw8WHGi/+pNOiwmbWUfLwYYY//qSRg8ZxdXw/rEf2EIehANLTUlLJ7aD8c2OqD/zB2cAZiI4PQ20sVSe3Ms2n0dD6NTYKDTBFvnWiFlogU2/vOAJ7/ngv7oqK+KAUtOctLEvjRMDl5+zul2/jT2Jqy66MFhcEe4+dz9OTvTiPQ2bY2lMwZjkccpPIxIgIGeOrYuGY2UWdbYeKBivKBXCemwmLgJygqyGDWgC/avnYLBs3YgKj4VNn06wcqsDbpP3CzCPREtYcXnbdu2Yfbs2ZxHp7y8vHDp0iUcOnQIy5Yt48l/79499OzZE5MmTQIA6OvrY+LEiXjw4EGt1/m1N2/eYMiQIUhMTERhYSEGDRoERUVFbNq0CYWFhfDy8hLUrvMQWfdvQeE3NUtJSt3qIpCZnYeSklJoNOW+OqLRVBGp7/k3kNznWeOfy4/h828oXsSm4nxwBNz2/Ieljv25rjYVl5Qi7t17hEclwW3Pf3j+OhkL7HtVWZaHEeyuUgZ6qgLYs4YtM7cAJaVl0Ggiy5Wu0UQWqVn8n3V2n2SGf4Jfw+dqFF68+YDz9xPgdvQhlo7twtOtZvucnhhm1gLWKy8g6T3v4Flfe/iKPRqsgbZS7XeokcjMya/i96aA1Pe8g6AAgPusAfgn8Cl8LobhRVwazt+KhNu+a1g6tTfv7y3pA8Kjk+G27yqex6ZiwbgeXOtSkJXC+b+m4WN+EexX/IOSRtL1G6ApOwg3vvE5lf9dQVGpiM+KXOnfjs/D8M/lR/D59wFexKbgfPBzuO2+hKXTB/KJz5kIj3oHt92X8PxVMhZM7MO1rty8AsS+zcTd8DhM+s0HhvoaGNnPSPA72sBk5n5mx2cVOa50DRU5pFa6e13OfZol/rkeCZ/ACLxIeI/z92Lh5nMXS8eb8cbnX/phmHkrWP9+GkmZFXEj5QM7Vkcmct+UiE78AD0N7r8hwuvbvzf+XbLd59vgn8sP4XMuBC9iUnD+xjO47b6IpdMH8f7e3mYiPPIt3HZdwPNXSVgwqS8AwMq8LVrpqiH15iZ8DN2Oj6HbAQD/bJmJwP85C2lv65bqxufCwkLk5uZyvSpfHC1XVFSEsLAwDBw4kJMmJiaGgQMHIiQkhO8ylpaWCAsL43TnjouLw+XLlzFs2LBar/NrixYtQrdu3ZCVlQVZ2Yrz91GjRiEoiHeMDEGqs43qFStWYMaMGd/Nt3z5cuTk5HC9JLTNf0IJq6+4pBThUUnoZ9aGk8ZisdCvW2uEVnr+uZystBTKKo1OWFZW9mXZqrclJiYG6W88e2vclv3cT2pm43uepKaKS8oQHpuBfp2bcdJYLKBf52YIjeY/ZYestATPqK0V9VZRcdvn9MSI7i0xZOUFvEn/fl0Yt2RfBEn9wP9kgVQoLilF+Ktk9DNtxUljsVjoZ9oKoVU8/ywrI1m73xuLBWlJcc57RTlpXNzugKKSUoz93bfR3W0SY7Gq9SL1X3ViNN/4rGX2k0pYPez4/A79zNty0lgsFvqZtUHosyric22PF2IsSEtWHZ/ZJ7UsSH0jD2ErLilD+Os09OtSMU4GiwX066KH0MgUvsvISkvwqTfmy7Jfxedf+mGEZWsMWXYab9K4L6y8SctFcuYntK3Uxby1rgoS0+i86nuKS0oRHvmW9/dmbojQZ/yfbZeVkeI9ryqt2e9tq/dVmNlvgsXEzZwXAPz2lz/mrPb9kV2qN6obn/ldDC0fBLSyzMxMlJaW8oxFoqmpidTUVL7LTJo0CWvXrkWvXr0gKSkJAwMDWFlZYcWKFbVe59du376NlStXQkpKiitdX18fSUlVT6sqCHX2yP3u3Tu8e/fuu/n4Tc1SF7uW7Th+E/vdJyAs8h0efZlSS05WCke+jAZ+YPUEJKfnwG3PfwDYI3svnNgHT6OTEPoiEQa6qnCbOwSXb7/kHFzWzh+KwJBovE3NgqKcNOytTdCnayvYLtwPAGjZTBX21iYIvBeJ9zn5MGqtjc0uI3D7cSwiYvgHHcJtx7/PsX+RFcJiMvDodTqcbI0gJyOJI9fYg2wcWNwPye/z4HaUfcXt8sM3WDiyM57GZyI0mt39222yGS4/TOTUm+fcXrDv0xrjNgTi0+diaH65E56TX4SColK01FKCfZ/WCAxLxPuPBTDSV8XmGT1wOyIZEW8+iOaLqGd2nLiH/X+MRlhUEh5FJsFpfA/27+0Suwv+gZVjkJyRC7d97K6al+9GY6G9JZ6+SkHoy7cwaKYKt1kDcPludMXvbe4gBN5/hbdpOezf26DO6GOiD1vXIwAqGtSy0pKYvvY4lOSloSTPPjZlZOc1iilyqL3ceFQnRteb+OwbjP2rJyHs5Vs8evEGTpP6so8XF9jdEQ+smcSOz7svAWCP7L1wkhU7Pke8gYGeGtzmDcXlWy8qjhcLbBB4L/JLfJaB/ZCu6GNqAFtn9mB5+s1UMXZQFwTdj0Zm1ic002yCXx0H4HNBMQKrGPCMcNtx9jH2/2qNsNfpeBSdCic7E8hJS+LIVfbI6wd+tUby+0+cLtmXH8Rh4eiueBqbjtCoVBjoNIHbNEtcfhBXEZ8X9Ie9lSHGrT2PT5+LoPnlTnhOXiFnDurtZx5h5ZQeeB6fiaex6ZgysAMMdZti0vqLIvgW6p8dvjewf82Ur35vVuzf25fRwA+sncL+ve1iTx97+VYEFk7uh6dR7xD6pfu323wbXL4dUfF7c7JF4L2XeJuSBUV5adgP6YY+pq1hu2AvACDt/Ue+g5O9Tc3Cm+TGcV5V3fi8fPlyuLq6cqVVdwrM6ggODsaGDRuwZ88ezuwcixYtwrp166r96O+3lJWVobSUd1yKd+/eQVFRuL1J6l50++LIkSOiLoJAnb72FGoqCnCbYw1NVUU8e5WMkYsOcAZT0tNU4Trp3njoGhiGgfu8IdBRV0Zm9idcuv0Sq/f+x8mj3lQBB90nQEtNCTmfChARkwzbhftxPfQ1AKC4uAT9zdvAaWJvyMtI4V1aNs7deM71TDb5ttN3YqGmJAO3Sd2gqSKHZ/GZGLnmMtK/zIGpp6bAXW8nH4NhAPfJZtBpKo/M3M+49DARq49VPJIwd1hHAMDVDSO4tjX77xs4dv0ViktK0d+4Gf7f3p3HxZw/fgB/TfelSJc7Z65USsl99JVjEYvsOrJuK6ywy+7KtYS1hGVz5Nz9KffajRw5IyJEJEeIdDtLKjW/P4axo0lTZppmej338Xk8dt7zns/n/emjXvP+fN6f98e7ty0M9bTwOD0L+yPuS70nm6TbfTwGZpUN4Tu6KyxNjXDtbhL6TtuG1GeioXu1LE3EV5YAYPHWU6LjNqYrqpsbI/15FkLOxmHu+g+/K+ZVDBH485ewqloJL7LeIOZeCnr7bMPxS/cAAPY21cSzi9/cKRlINgN+Q0LycwXvtfLxkR0Vhzpl9O6jV0X5PL47LKsa49rtRPSdtO5DPlt9lM+BR0V/Lyb0eJfPWQg5fQNz14aI65ibGiFw3pB3+ZyNmDtJ6D1pnXiW8ZycPLR1qAfvrzqiirE+UjNeIfxKPDqPWin1Wb1U2O7Tt2Fmog/foa6wNDXAtXtp6Dt7H1Kfi0Z01bKoJHFlevGOC6LjNrwtqlc1QvqL1wi5EI+5W8+J64z7wg4AcHTpIIltjfntMP48JrqH+vf9V6CnrYWlYzuiSiU9XI9Pwxc/7cH9pBeK3mW1sPvIFdHv24Seot+3uMfo6/2HePKyQr9vGw+Lvg9P7CX6fXuWiZAzNzD39w8nMcxNjRA4fyiszEze/b49Qe+Jf0jMMl7RyZrP0k6GFsXMzAyamppISZEcvZmSklLk0yFmz56NYcOGYfTo0QAAW1tbZGVlYezYsfjpp59Ktc7/6tatG/z9/bF+/XoAov3OzMzEnDlzxEPMFUUgVOIT0NPT07Fp0yZERESIL+lbWVmhTZs2GDFiBMzNzUu1Xn3n6fJsJpWVag2Lr0PlT0bxI0qo/MkOXyD3dfYMkG0+i4Pjy9ctOiSdIjJa32mqvJtJZcG8trJbQKWRUvTjwqj8yr68Su7rVFQ+u7i4wNnZGatXrwYgulJcu3ZteHt7S51UzNHREW5ubliyZIm4bMeOHRg1ahRevXoFTU3NEq/zvx49eoTu3btDKBTizp07cHJywp07d2BmZobTp0/LNHt4aSntSvXFixfh7u4OAwMDuLm5oVEj0f0VKSkpWLVqFRYvXozDhw/DyclJWU0kIqIS4IVq9cGMJiJSH4rKZx8fH3h5ecHJyQnOzs7w9/dHVlaWeObu4cOHo0aNGuL7snv37o3ly5fDwcFBPPx79uzZ6N27NzQ1NWVa56fUqlUL0dHRCA4ORnR0NDIzMzFq1CgMGTJEYuIyRVBap3rSpEkYOHAgAgICCg1JEAqFGD9+PCZNmiTTTG9ERKR8ArBXrS6Y0URE6kNR+ezp6Ym0tDT4+voiOTkZ9vb2CA0NFU80lpCQAA2ND/Ni//zzzxAIBPj555+RmJgIc3Nz9O7dGwsXLpR5nUXJy8tD48aN8e+//2LIkCEYMmSIQva5KEob/q2vr48rV66gcePGUt+/desWHBwckJ0t/dFFn1w3h3+rJg7/Vk0c/q2SFDH8u8962R6XdGBs+ZoBmgpTVEZz+LeK4vBv1cTh3ypJEcO/K0o+16hRA8eOHUOTJk3KfNtKe6SWlZWV+Bll0kRGRhZ7RoKIiMoPgUAg00LlHzOaiEh9VJR8njhxIpYsWYK3b8v+kaZKG/49ffp0jB07FlFRUejatas4nFNSUhAWFoYNGzZg2bJlymoeERGVkKaG6gcyiTCjiYjUR0XJ54sXLyIsLAxHjhyBra0tDA0NJd7fu3evwrZd6k71zZs3kZCQgNzcXInyPn36FPEJSRMnToSZmRlWrFiBtWvXip8ppqmpCUdHR2zZsgWDBg0qZi1ERFReqMFJ7mJdu3ZN5rotWrRQYEuK9rn5DDCjiYjUSUXIZwCoXLkyvvzyS6Vsu8Sd6vj4ePTr1w/Xr1+HQCDA+1uy3w8ZkPbA7aJ4enrC09MTeXl5SE9PByB65pm2tnZJm0VEREqmDkPHimNvby+RfR97/55AIChRHsqDPPMZYEYTEamLipDPALB582albbvEneopU6agbt26CAsLQ926dREZGYmMjAxMmzat1EPBtLW1Ua1atVJ9loiIyoeKkNn375ffiX8Ukc8AM5qISNVVhHz+r7S0NMTFxQEAbGxsYG5urvBtlrhTHRERgePHj8PMzAwaGhrQ0NBAu3bt4Ofnh8mTJ+PKlSuKaCcREZVzGhUgtevUqaPsJhSJ+UxERNJUhHwGgKysLEyaNAnbtm1DQUEBANFtS8OHD8fq1athYGCgsG2XuFOdn5+PSpUqARANA3vy5AlsbGxQp04d8RkBIiKqeCpCaB84cEDmuiW5h1kemM9ERCRNRchnAPDx8cGpU6fwzz//oG3btgCA8PBwTJ48GdOmTcMff/yhsG2XuFPdvHlzREdHo27dunBxccHSpUuho6OD9evXo169eopoIxERqYCKMLmoh4eHTPWUcU8185mIiKSpCPkMAHv27MHu3bvRqVMncVnPnj2hr6+PQYMGla9O9c8//4ysrCwAwPz58/HFF1+gffv2qFq1KoKDg+XeQCIiUg0VYSKU98PJyiPmMxERSVMR8hkAXr9+LX4E5H9ZWFjg9evXCt12iTvV7u7u4v9v0KABbt26hadPn6JKlSoV5oAREVFhjADlYj4TEZE0FSUCXF1dMWfOHGzbtg16enoAgOzsbMybNw+urq4K3Xapn1P9X6ampvJYDRERqbCK2HHLysrCqVOnpD4XevLkyUpq1QfMZyIiqij5vHLlSri7u6NmzZqws7MDAERHR0NPTw+HDx9W6LZL3KnOysrC4sWLERYWhtTU1EJD4eLj4+XWOCIiUh2aFeWmrXeuXLmCnj174vXr18jKyoKpqSnS09NhYGAACwuLMu9UM5+JiEiaipLPzZs3x507d/DXX3/h1q1bAICvvvoKQ4YMgb6+vkK3XeJO9ejRo3Hq1CkMGzYM1apVqzBnPoiI6NMqWhpMnToVvXv3RkBAAExMTHD+/Hloa2tj6NChmDJlSpm3h/lMRETSVKQ0MDAwwJgxY8p8uyXuVB86dAghISHiacqJiIiAivPIjveuXr2KdevWQUNDA5qamsjJyUG9evWwdOlSeHl5oX///mXaHuYzERFJU1Hy2c/PD5aWlhg5cqRE+aZNm5CWloYffvhBYdvWKOkHqlSpwnu0iIioEIFAtkVdaGtrQ0NDFKMWFhZISEgAAJiYmODRo0dl3h7mMxERSVNR8nndunVo3LhxofJmzZohICBAodsucad6wYIF8PX1Vfi05EREpFo0NAQyLerCwcEBFy9eBAB07NgRvr6++Ouvv/Ddd9+hefPmZd4e5jMREUlTUfI5OTkZ1apVK1Rubm6OpKQkhW5bpuHfDg4OEvdm3b17F5aWlrC2toa2trZE3cuXL8u3hUREpBIqyvCy9xYtWoRXr14BABYuXIjhw4djwoQJaNiwIQIDA8ukDcxnIiIqTkXJ51q1auHs2bOoW7euRPnZs2dRvXp1hW5bpk61h4eHQhtBRESqr4JktpiTk5P4/y0sLBAaGlrmbWA+ExFRcSpKPo8ZMwbfffcd8vLy0KVLFwBAWFgYvv/+e0ybNk2h25apUz1nzhyFNoKIiFRfRZtt+v79+3j79i0aNmwoUX7nzh1oa2vD2tpa4W1gPhMRUXEqSj7PmDEDGRkZ+Pbbb5GbmwsA0NPTww8//IBZs2YpdNslnv37vUuXLiE2NhYA0LRpUzg6OsqtUZ8t742yW0Clkcv7AFVS1ZrKbgGVEyWepKME1qxZg19//RXJycmws7PD6tWr4ezsLLVup06dcOrUqULlPXv2REhICAAgMzMTM2fOxP79+5GRkYG6deti8uTJGD9+vMxtGjFiBEaOHFmoU33hwgVs3LgRJ0+elH0H5ahc53N+nrJbQKVRkK/sFlApGDR3VXYTqJxQZD6XJwKBAEuWLMHs2bMRGxsLfX19NGzYELq6ugrfdok71Y8fP8ZXX32Fs2fPonLlygCA58+fo02bNggKCkLNmvyCTURUEWkqaJKT4OBg+Pj4ICAgAC4uLvD394e7uzvi4uJgYWFRqP7evXvFZ6gBICMjA3Z2dhg4cKC4zMfHB8ePH8eff/4Ja2trHDlyBN9++y2qV6+OPn36yNSuK1euSH18VevWreHt7V2KPf08zGciIpJGUflcXhkZGaFVq1Z4+PAh7t27h8aNG4uf1qEoJV776NGjkZeXh9jYWDx9+hRPnz5FbGwsCgoKMHr0aEW0kYiIVICGQLalpJYvX44xY8bgm2++QdOmTREQEAADAwNs2rRJan1TU1NYWVmJl6NHj8LAwECiU33u3Dl4eXmhU6dOsLa2xtixY2FnZ4fIyEiZ2yUQCMQTlf3XixcvkJ9f9lf2mM9ERCSNovK5vNi0aROWL18uUTZ27FjUq1cPtra2aN68ucIfdVniTvWpU6fwxx9/wMbGRlxmY2OD1atX4/Tp03JtHBERqQ6BQCDTkpOTg5cvX0osOTk5UteZm5uLqKgouLm5ics0NDTg5uaGiIgImdoVGBiIwYMHw9DQUFzWpk0bHDhwAImJiRAKhThx4gRu376Nbt26yby/HTp0gJ+fn0QHOj8/H35+fmjXrp3M65EX5jMREUkjaz6rqvXr16NKlSri16Ghodi8eTO2bduGixcvonLlypg3b55C21Di4d+1atVCXl7he6Ly8/MVPlU5ERGVX7Ke5fbz8ysUbnPmzMHcuXML1U1PT0d+fj4sLS0lyi0tLXHr1q1itxUZGYmYmJhCj7havXo1xo4di5o1a0JLSwsaGhrYsGEDOnToINtOAFiyZAk6dOgAGxsbtG/fHgBw5swZvHz5EsePH5d5PfLCfCYiImlU+Sq0LO7cuSPxRI6///4bffv2xZAhQwCIHoH5zTffKLQNJb5S/euvv2LSpEm4dOmSuOzSpUuYMmUKli1bJtfGERGR6hAIZFtmzZqFFy9eSCyKmpUzMDAQtra2hSY1W716Nc6fP48DBw4gKioKv/32GyZOnIhjx47JvO6mTZvi2rVrGDRoEFJTU/Hq1SsMHz4ct27dQvPmzeW9K8ViPhMRkTSy5rOqys7OhrGxsfj1uXPnJE6S16tXD8nJyQptQ4mvVI8YMQKvX7+Gi4sLtLREH3/79i20tLQwcuRIjBw5Ulz36dOn8mspERGVa1oyJrKurq7MM3GamZlBU1MTKSkpEuUpKSmwsrL65GezsrIQFBSE+fPnS5RnZ2fjxx9/xL59+9CrVy8AQIsWLXD16lUsW7ZMYqh5capXr45FixbJXF+RmM9ERCSNrPmsqurUqYOoqCjUqVMH6enpuHHjhsREosnJyTAxMVFoG0rcqfb391dAM4iISNUpIrN1dHTg6OiIsLAweHh4AAAKCgoQFhZW7Azbu3btQk5ODoYOHSpRnpeXh7y8vEIzgWpqaqKgoKBE7Ttz5gzWrVuH+Ph47Nq1CzVq1MD27dtRt27dMr+vmvlMRETSqHmfGl5eXpg4cSJu3LiB48ePo3HjxhKPkzx37pzCR5CVuFPt5eWliHYQEZGK01BQavv4+MDLywtOTk5wdnaGv78/srKyxPdHDR8+HDVq1ICfn5/E5wIDA+Hh4YGqVatKlBsbG6Njx46YMWMG9PX1UadOHZw6dQrbtm0rNHvop+zZswfDhg3DkCFDcPnyZfFkay9evMCiRYtw8ODBz9zzkmE+ExGRNIrK5/Li+++/x+vXr7F3715YWVlh165dEu+fPXsWX331lULbIFOn+uXLlzKv8L/j2YmIqOJQVGZ7enoiLS0Nvr6+SE5Ohr29PUJDQ8WTlyUkJBS66hwXF4fw8HAcOXJE6jqDgoIwa9YsDBkyBE+fPkWdOnWwcOFCjB8/XuZ2/fLLLwgICMDw4cMRFBQkLm/bti1++eWXUuxpyTGfiYioOGrep4aGhgbmz59f6Hav9z7uZCuCTJ3qypUrFzvNulAohEAgUMqzOYmISPkUObuot7d3kcO9T548WajMxsYGQqGwyPVZWVlh8+bNn9WmuLg4qbOFm5iY4Pnz55+1blkxn4mIqDjqPvt3eSBTp/rEiRMyrez69euf1RgiIlJdmhUsta2srHD37l1YW1tLlIeHh6NevXpl0gbmMxERFaei5bMyyNSp7tixY5HvvXr1Cjt27MDGjRsRFRVV7MQxRESknipaZo8ZMwZTpkzBpk2bIBAI8OTJE0RERGDatGnw9fUtkzYwn4mIqDgVLZ+VocQTlb13+vRpBAYGYs+ePahevTr69++PNWvWyLNtRESkQgSoWKk9c+ZMFBQUoGvXrnj9+jU6dOgAXV1dzJgxA6NHj1Zau5jPRET0XxUtn5WhRJ3q5ORkbNmyBYGBgXj58iUGDRqEnJwc7N+/H02bNlVUG4mISAVUtDPhAoEAP/30E2bMmIG7d+8iMzMTTZs2xbp161C3bl0kJyeXWVuYz0REVJSKls/KoFF8FZHevXvDxsYG165dg7+/P548eYLVq1crsm1ERKRCNASyLaouJycHs2bNgpOTE9q2bYuDBw+iadOmuHHjBmxsbLBy5UpMnTq1zNrDfCYiok+pKPlclEePHmHkyJEK3YbMnepDhw5h1KhRmDdvHnr16gVNTU1FtouIiFSMpoZApkXV+fr64o8//oC1tTXu37+PgQMHYuzYsVixYgV+++033L9/Hz/88EOZtYf5TEREn6LIfF6zZg2sra2hp6cHFxcXREZGFlm3U6dOEAgEhZZevXqJ62RmZsLb2xs1a9aEvr4+mjZtioCAgFK17b2nT59i69atn7WO4sg8/Ds8PByBgYFwdHREkyZNMGzYMAwePFiRbSMiIhWi7s/BfG/Xrl3Ytm0b+vTpg5iYGLRo0QJv375FdHR0sY+3UgTmMxERfYqioik4OBg+Pj4ICAiAi4sL/P394e7ujri4OFhYWBSqv3fvXuTm5opfZ2RkwM7ODgMHDhSX+fj44Pjx4/jzzz9hbW2NI0eO4Ntvv0X16tXRp08fqe04cODAJ9sZHx9fyj2UnUD4qQd5SpGVlYXg4GBs2rQJkZGRyM/Px/LlyzFy5EhUqlRJ5vX07t0bgwYNwoABA6Cvr1/ihn+KvgNnOFVJVvWV3QIqDR0DZbeASiH773FyX6f/mfsy1fuufV25b7ss6ejo4P79+6hRowYAQF9fH5GRkbC1tVVqu+SVz4DiMpr5rKIsrJXdAioFA8saym4ClULGtq/kvk5F5bOLiwtatWqF33//HQBQUFCAWrVqYdKkSZg5c2bx7fL3h6+vL5KSkmBoaAgAaN68OTw9PTF79mxxPUdHR/To0QO//PKL1PVoaGhAIBDgU91agUCA/Pz8kuxeicg8/Ps9Q0NDjBw5EuHh4bh+/TqmTZuGxYsXw8LCosizB9KEhIRg5MiRqFatGiZMmICoqKiSNoWIiMqRinLPVn5+PnR0dMSvtbS0YGRkpMQWicgrnwFmNBGROlFEPufm5iIqKgpubm4ftqOhATc3N0RERMi0jsDAQAwePFjcoQaANm3a4MCBA0hMTIRQKMSJEydw+/ZtdOvWrcj1VKtWDXv37kVBQYHU5fLlyyXbuVIo9SO1AMDGxgZLly6Fn58f/vnnH2zatKlEn4+OjsaRI0ewadMmrF+/Hra2thg9ejSGDBmCKlWqfE7TyqVxgzpgqldXWFY1xvXbifBZsguXbjwssr73150wZmB71LKqgoznWdh37Apmrz6AnNy3AIAxA9thzID2qFPdFAAQG5+MResP4cjZm+J1WFathEXf9UOX1o1RyVAXtx+kYmngYewPu6rQfVUn476ww9QBjrCsYojr8Wnw+eMELt1OKbK+t4cDxvRqgVrmxsh4mY194Xcwe3M4cvJEZ8emD2oFj7YN0KimKbJz3+LCzSf4aVM47iQ+AwDUtjBG3NZRUtc9ZOG/2Bt+R/47qYbG9WyGqR52sKyij+sPMuCz/iwu3Ukrsr53b1uM6dEUtcyMkPHqDfadi8fsbZEfjtuX9vBwrYtGNSsjOycfF24l46dtF3An8YV4HYd/6Y0OttUl1rsh9CYm/3FGMTtZzmhWkPHfQqEQI0aMgK6uLgDgzZs3GD9+vMSXAkA0zE1ZPjefgYqV0crI5//a//sEuLdthkFT1+Ofk9fkv4Nqalxve0wd0AqWpu/yeW0YLsUVPeu+d7+WGNPLHrUsKony+cxtzN505sPfeU9neLRthEa13udzIn4KPI07j9/ls6Ux4raNlbruIb8cwN4zt+W/k2poVNeG8O7ZGBYm+rjx6Blmbo/C5finRdYf526DkV0aoEZVAzx9lYMDFx9hwa5o5OQVAABcbczh3bMJ7K2rwKqKAYb5n8bBy4kS6zDU1YLvIDv0dKyJKkY6SEjLwvojt7HlxF2F7mt5IWs+5+TkICcnR6JMV1dXnHf/lZ6ejvz8fFhaWkqUW1pa4tatW8VuKzIyEjExMQgMDJQoX716NcaOHYuaNWtCS0sLGhoa2LBhAzp06FDkuhwdHREVFYW+fftKfb+4q9jyUOIr1dJoamrCw8Oj2PHsHzMzM8N3332Ha9euISIiAi4uLvj5559Ro0YNfP311zh+/Lg8mlcuDOjWEkum9cPCdYfg+vUSXLudiANrJ8K8ivSrG57dnbBgcl8sWncI9v1/wfh5f2GAuyPmT/pwtSEx5Tlmr/4bbYYsRdshv+Jk5G3sWjEWTepZietsXDAcjawtMPC7dXAauAh/H7+KP5eMhJ1NTYXvszoY0KERloztgIV/nYfrpL9w7X46DvzSH+Ym0odDenaywYJv2mHRX+dhP3YrxvsfwYAOjTB/RFtxnfa2NRHwTzQ6Tg3CFz/ugZaWBv5d2B8GuqJzXI/TX8H663USy/zt5/DqdS4OX3pQFrut8ga0q48lI12xMDgKrj57cO3+UxyY2wvmJnpS63t2aIAFw52xKCgK9t7BGL/6FAa0q4/5w5zFddo3r46AgzfQccZ+fDHnX9Fxm9tLfNzeCzwcC2uvbeLlpy3nFbqv5YlAINui6ry8vGBhYQETExOYmJhg6NChqF69uvj1+6U8KG0+AxUno5WVz+9NGtIZCv6up5YGdLTBkrGdsPCvCLhO3I5r8ak4sHAAzE2k35Lk2bkxFozsgEV/nYP9mM0Yv/wwBnRsjPnftBfXad+iFgL+uYKO3/2FL2btgpamJv5dNBAGutoAgMdpr2A9eK3EMn/bWVE+X5RteG1F5+FSGwu+dsCv+2PQxTcUMQnPsWtGZ5hVKtxpA4AvXevAd6Adlu6PgevMg5gcGIl+LrXx80A7cR0DXS3cSHiG77cVPaJmwdcO6NKiGsYHRMB15kEEHI7DkuGO6O5QMYbIy5rPfn5+hbLMz89PIW0KDAyEra0tnJ2dJcpXr16N8+fP48CBA4iKisJvv/2GiRMn4tixY0Wua8aMGWjTpk2R7zdo0AAnTpyQW9ul+awr1fLk7OwMZ2dnrFixAjt37kRgYCD+97//KXTse1maPLQLNu89h+0HRF+wJy0MQo/2zeDl4Yplm48Wqt/ari4irsYjOPQSACAh6Sl2hl5Cq+bW4joHT8dIfGbumn8wZmA7OLeoi9j45HfrqYfJi4LEZ9yXbDyMSUO6wKFpLUTHPVbErqqVyf1aYvOhGGw/Krq6MGn1MfRoVRde3Zpj2a6Lheq3blIdETefIPhkHAAgIfUldp6MQ6vGH75I9Z29T+IzY5cfwaOg8XBoaImzMYkoKBAi5dlriTp92jTAnjO3kfUmT967qJYm97XF5iOx2B4mOg6T/jiNHk614eXWGMv2XC1Uv3VjS0TEpiD4tOiMdUJqJnaevotWjT5MstF33kGJz4xdeRKPtnvBob45zt5MEpdn57xFyvNsBexV+acOQ7tlsXnzZmU3ocypc0YrK58BoEWjGpgyrAvaDlmKB8cU88VVXU3u74TNodex/YjoZz1p1VH0cK4HL/fmWLaz8OzDrZvWQMSNRASfEF1BS0h5iZ0nb6GVzX/y+ac9Ep8Z+9shPNo58V0+Py46n0/HMZ9l9G13G2w/eQ//9+4e32lbLqKbXXUM6VgPK/+NLVTfuYEZIu+kYU+E6Hvso/Qs7DmfAMf6VcV1wq4lIexaUqHPSqynoRmCwu/j7K1UAMC2k/fg1bkBWtYzReiVxE9+Vh3Ims+zZs2Cj4+PRJm0q9SA6MSrpqYmUlIkR2+mpKTAyqrwCcT/ysrKQlBQEObPny9Rnp2djR9//BH79u0TzwjeokULXL16FcuWLZMYav5f7du3l1r+nqGhITp27PjJOp9LLleq5cnAwAAjRozAmTNnEBtb+JdLFWlracKhSS0cvxAnLhMKhTh+IQ7OLaRPCHA++j4cmtaCU7M6AADrGlXh3rYZQsNvSK2voSHAQHdHGOrr4MK1+/9ZTzwGdHNEFWMDCASiOnq6Wjh9iUOIi6OtpQGHhpY4fjVBXCYUAsevJsC5STWpnzkf+wQODSzg1Eg0FMbaygTurawR+okz2MYGonszn716I/V9hwYWsK9vga2HY6S+T5K0tTTgUN8cx6M/hKRQCByPfgxnG0upnzl/KwUO9c3g1NAcAGBtWQnujrURGvWoyO2Ij1um5HHz7NgAj7YPx6VVAzF/mDP0dcrNuUuF0xAIZFpIdalbRiszn/X1tLHFbwS+W7wTKRmv5LhX6k+cz5c/DNEXCoHjVxLg3LS61M+cv5kIh4aWcHrXiRblc91P57OhqDNRdD5bwr6BJbYevl7aXalQtDU1YGdtilM3PpxYEgqBUzdT0KqBmdTPRN5Nh521KVrWE91KUcfcEP+zq4Zj0U9KtO3IO+no4VAD1aqIRhq2a2KBBlaVcCKm6NsF1Ims+ayrqwtjY2OJpahOtY6ODhwdHREWFiYuKygoQFhYGFxdXT/Znl27diEnJwdDhw6VKM/Ly0NeXh40NCS7qJqamigoKChyffHx8Qof3l0cpX3b69ixo8REL9I0atSojFqjWGZVjKClpYnUp5KhmZrxEjbW0r/kB4deQtUqhgjbPBUCCKCtrYn1u87g101HJOo1a1AdJ7dOg56OFjKzc+A5bQNu/ecs+NDvN2H7kpF4cmop8vLy8fpNLjx9NiD+Ubr8d1TNmBnrQ0tTA6kfnZVOffYaNjWl308YfDIOVY31EbbMEwKB6Avb+pBo/Bpc+Ko2IBpq8+u4Tjh3IxE3H2ZIrePl3hyxCRk4H/vps7AkYmasJzpuH10tTn2eDZualaV+Jvj0XVQ11kOYX98Px+3QDfy6+4rU+gIB8OvoNjh3Mwk3E55JrCch7RWSnr6GrbUpfhnugkY1KmPw4iNS16Nu2F9WHxUlo5WZz0unfYnz0ffx70l2yEpKnM/PsyTKU59lwaaWqdTPBJ+4Jcrn37768Hf+36v4NeiC1PoCAfDr+M44F/MYNx9K/87k1d0WsQ8zcP5myTp4FVXVSrqi4/ZS8iRF6os3aFhN+hMK9kQ8RFUjXYT87Cb6fdPSwOawO1jxj/T5CYoyc3sUVox0RsxKD+S9LUCBUIipmyIREVf0XCvqRFH57OPjAy8vLzg5OcHZ2Rn+/v7IysrCN998AwAYPnw4atSoUWgIeWBgIDw8PFC1alWJcmNjY3Ts2BEzZsyAvr4+6tSpg1OnTmHbtm1Yvnx5ke1o2LAhkpKSxI/x8vT0xKpVqwrd761ISutUy2tcu7Qb6oUF+RBoaMpl/crS3rEhZox0xxS/YFy8/hD1a5lh2YwBSBrTHYs3hIrr3X6QApfBfjAx0kc/NwdsmD8M3UavFAf3nIlfoHIlffQYtwoZz7PQu1ML/Ll0JNxG+uPGXYaAvLW3rYkZns6YsuY4LsYloX71ylg2rhOSvnLB4h2Fg9t/Yhc0s66KrtN3Sl2fno4mPDvZSP0syU/75tUwY4ADpqwLx8XbqahfzRjLRrdB0qCWWLyz8IyR/uPaoVltU3Sd9bdE+aYjH67c3Xj4FElPXyP0l96oa2WM+8kvFb4fyqZZUcZ/VwDyyGjmc9H53KujLTo5N0LrwYuVuCcVS/sWtTBjcGtM+f0YLt56l88TuiDp69ZY/H+F577w93ZDszpm6Dpth9T16elowbNzY6mfJflp29gC3/VuihlbLyHqXgbqWVbCoqEtMe15M/z2t/TRIdKM+V8jONWviq+Xn8KjjNdoY2OOpcOdkPw8G6duFD35rLpQVD57enoiLS0Nvr6+SE5Ohr29PUJDQ8Wd2YSEhEJXnePi4hAeHo4jR6RfcAgKCsKsWbMwZMgQPH36FHXq1MHChQsxfvz4Itvx8VXqgwcPKuxe8KKo/LhEPz8/zJs3T6JM07IVtKs5F/GJspf+LBNv3+bDwlTyLJxFVWMkZ0j/oj3n217YERKJLftEU9LfuPsEBvq6WPPzV1iy8bD4H0/e23zxVecrsY/g2Kw2Jn7VCZMWBqFuTTNMGNwRLb/8RXwP1/XbiWjbsj7GeXbA5IVBitpltZD+Mhtv8wtgUUVy0hOLKgZI/ujq9XtzhrfBjuOx2PJuqPaNBxkw0NXGmsluWBJ0QWIymhUTOqOncz24zdiJxPRMqevr164RDHS18VeY6g+zLCvpL9+IjltlycnkLCrrI/mZ9Hud53zdCjtO3sGWo6J77W48fCo6bhPbY8muy5LHbWxb9GxVB26zDiAxI0vq+t67eFt071b9ahWjU13u7icipWI+F53PnVo1Qr2aZkg+/avEuncsG42zV+7BfcxKee+qWhHnc2XJGfctqhgi+Zn0v8tzvNpiR9hNbAkVjQy48SAdBnraWDOlG5bsOC/5d35iV/R0qQe3acFF53P7d/l8TPaOXUWX8SpHdNyMJScNtTDRQ+oL6UPsZ31pi53nHuDPU/EAgNjHL2Cgq4Xl37TC8gM3ZJrkT09bEz8PbIHhK8Nx9N2w8ZuPnqN57SqY2KNJhehUKzKfvb294e3tLfW9kydPFiqzsbH55FBtKysrlZy7pNx+B/rxxx8xcuTIYuvNmjULL168kFi0LB3LoIWyy3ubjyuxj9DZxUZcJhAI0Nm5ESKvSb+XR19PBwUFkv/g3t9L8KkhHBoCAXTf3cNpoCcaulfw0T/c/Hwh72uUQd7bAly5k4LO9rXEZQIB0Nm+FiKLGIqtr6tV6Of9/jgK/vMzXzGhM/q0aYDuM3fjYUrRna0R7s0QciEe6S8q5sRXpZH3tgBX7qWhc4sPM3oKBEDnFjUQGSc9OPV1tT7x+/af4za2Lfq0rovuP/+Dh6nF3wNpV1c0rCn5qfSTMOpGIBDItJDqkyWjmc+S/pvPyzYfQatBfnAZvFi8AMD3v+3B2Dl/fs4uVQjifHaoLS4T5XNtRBYxFFvmfJ7YVZTP3+/Ew5QXKMoId1uEnL/HfC6BvPwCRD94ig7NPkxiJRAAHZpa4uJd6UPs9XW0IPzo9y3//XGDbHmirSmAjpZm4e/DBcIKM8GmuueztPaX9f6U2yvVjx8/xuPHxc9OLe3ZaeVxaNmqP49jw/xhiLqZgEsxD+D9dWcY6Oti29+iYUMbFwzDk9QX8F0teuzJwdMxmDy0M6LjHiPy+gPUr2UO3wlf4ODp6+IQmD+pDw6fvYFHSc9QyVAPnj2c0MGpIXp/uxYAEPcgGXcTUvH7z19h1vJ9yHiRhT6dW6Braxv0nxKgnB+Eilm17zI2THNH1J1UXIpLhreHAwx0tbHtqOjM9MZp7niSkQnfLWcBAAcvxGNy/5aIvpeKyFvJqF+9MnyHt8HBC/Hi4+Y/sQs8O9lg4PwDyMzOheW7K+EvsnLwJvfDTLr1qpmgXfOa8PDdByqZVX9fx4YpnRB1Nw2X7qTCu7ctDPS0se2YaDKijd91xpOMLPhuF80Qe/DiQ0zu2wLR99MRGSca/u07pBUOXkz4cNzGtYNnhwYYuOgwMrPzYPnuSviL17l4k5uPulbG8OzQAIejEpDx6g1srati6UhXnIl5gpiHRT9/U52obhxTScmS0cznovM5JeOV1MnJHiU9w8Mn0ufXIEmr9l7Chuk9EHU7BZfikuDdz1H0d/7dbOAbZ/TAk/RM+G4+AwA4eD4ek/s7Ivpuiiifa1SGr1dbHLxw78PfeW83eHZujIFz93+Uz7l48+4Z5ABQr3pltLOtCY/Ze0AlszY0DmvGtMbV+09xOT4D47rZwEBXC/93WnQSa+3Y1kh6lo0Fu6IBAIevJuLb7o1x7eEz8fDvWV/a4vDVRHEn2VBXC3UtPzwCr7a5EZrXroxnWblIzHiNV2/eIjw2BfMG2+NNbj4epWehbWMLeLazxuz/kz53irpR93wWCoUYMWKEOHPevHmD8ePHw9BQcjTL3r17FdaGctup3rZtm7KbIFe7j1yGWRUj+E7oBcuqlXAtLhF9J64RT45Sy8pU4sz34o2hEAqFmPPtF6huYYL0Z5kIOR2Dub//I65jbmqEwAXDYWVmjBeZbxBzJxG9v12L4xdEQ1jfvi2Ax6Q/8Mvkvti9chyMDHRx71EaRvtux+Hwkk3wUFHtPn0bZib68B3qCktTA1y7l4a+s/ch9bnoymMti0oSZz4X7xAN8Z4zvC2qVzVC+ovXCLkQj7lbz4nrjPtC9GzFo0sHSWxrzG+H8eexD8fFq1tzJKa/wrH/zG5Kstkdfg9mxnrw/doJllUMcO1+OvrOO4jUd1cUapkZSf6+7RQN8Z4zpBWqmxoi/WU2Qi4mYO6fHx7LMq5nMwDA0UV9JLY1ZuUJ/Hn8NvLe5qOLXQ1497aFoZ4WHqdnYX/Efan3ZKsrjoCpONQpo5WRz/T5dp+Kg5mJAXyHtxX9nY9PQ9+fdn/IZ3NjyeP2fxGi4zai3bt8zkbI+XuYuyVcXGdcb3sAwNFlgyW2NWbZIfx59MMwby/3d/kc9UBxO6im9l9IgFklXczsbwsLEz3EJDzDoF9PIu3d5GU1qhpIfK/67W/REO8fB7RAtSr6yHiVg8NXEvHL7mviOvZ1TXHgx67i1wuHtAQA7DgTD+8Nojlpxqw9h9kD7bBuvCsqG+ngcfprLNx9DZuP3y2L3VY6dc9nLy8vidcfzypeFgRCJc4/np6ejk2bNiEiIgLJyaJ7fq2srNCmTRuMGDEC5ubmpVqvvoP0cf1UzlnVV3YLqDR0DIqvQ+VO9t/j5L7O/7tc/OgiAPi6ZU25b5vkTxEZzXxWURbWym4BlYKBZY3iK1G5k7HtK7mvk/mseEq7p/rixYto1KgRVq1aBRMTE3To0AEdOnSAiYkJVq1ahcaNG+PSpUvKah4REZWQut+zVZEwo4mI1AfzWfGUNvx70qRJGDhwIAICAgodRKFQiPHjx2PSpEmIiIhQUguJiKgkyu3Ml1RizGgiIvXBfFY8pXWqo6OjsWXLFqlnRQQCAaZOnQoHBwcltIyIiEqDZ7nVBzOaiEh9MJ8VT2knLqysrBAZGVnk+5GRkeIHhxMRUfknkHGh8o8ZTUSkPpjPiqe0K9XTp0/H2LFjERUVha5du4rDOSUlBWFhYdiwYQOWLVumrOYREVEJafJMuNpgRhMRqQ/ms+IprVM9ceJEmJmZYcWKFVi7di3y80XP59XU1ISjoyO2bNmCQYMGFbMWIiIqLzi8TH0wo4mI1AfzWfGU+pxqT09PeHp6Ii8vD+np6QAAMzMzaGtrK7NZRERUCoxs9cKMJiJSD8xnxSsXk8Fpa2ujWrVqqFatGsOaiEhFCQSyLaWxZs0aWFtbQ09PDy4uLp+837dTp05SHxXSq1cviXqxsbHo06cPTExMYGhoiFatWiEhIaF0DVRjzGgiItWmyHwmkXLRqSYiItWnAYFMS0kFBwfDx8cHc+bMweXLl2FnZwd3d3ekpqZKrb93714kJSWJl5iYGGhqamLgwIHiOvfu3UO7du3QuHFjnDx5EteuXcPs2bOhp6dX6v0nIiIqjxSVz/SBUod/ExGR+tBQ0Gnu5cuXY8yYMfjmm28AAAEBAQgJCcGmTZswc+bMQvVNTU0lXgcFBcHAwECiU/3TTz+hZ8+eWLp0qbisfv36Cmk/ERGRMikqn+kDXqkmIiK5kHV4WU5ODl6+fCmx5OTkSF1nbm4uoqKi4ObmJi7T0NCAm5sbIiIiZGpXYGAgBg8eDENDQwBAQUEBQkJC0KhRI7i7u8PCwgIuLi7Yv3//Z/8MiIiIyhsO/1Y8dqqJiEguZB1e5ufnBxMTE4nFz89P6jrT09ORn59f6JnIlpaWSE5OLrZNkZGRiImJwejRo8VlqampyMzMxOLFi9G9e3ccOXIE/fr1Q//+/XHq1KnP+yEQERGVMxz+rXgc/k1ERHIh61nuWbNmwcfHR6JMV1dXAS0SXaW2tbWFs7OzuKygoAAA0LdvX0ydOhUAYG9vj3PnziEgIAAdO3ZUSFuIiIiUgVehFY+daiIikgtZ79nS1dWVuRNtZmYGTU1NpKSkSJSnpKTAysrqk5/NyspCUFAQ5s+fX2idWlpaaNq0qUR5kyZNEB4eLlO7iIiIVAXvqVY8Dv8mIiK50BDItpSEjo4OHB0dERYWJi4rKChAWFgYXF1dP/nZXbt2IScnB0OHDi20zlatWiEuLk6i/Pbt26hTp07JGkhERFTOKSKfSRKvVBMRkVwIFHQ/lo+PD7y8vODk5ARnZ2f4+/sjKytLPBv48OHDUaNGjUL3ZQcGBsLDwwNVq1YttM4ZM2bA09MTHTp0QOfOnREaGop//vkHJ0+eVMg+EBERKYui8pk+YKeaiIjkQlGjyzw9PZGWlgZfX18kJyfD3t4eoaGh4snLEhISoKEhOfAqLi4O4eHhOHLkiNR19uvXDwEBAfDz88PkyZNhY2ODPXv2oF27dorZCSIiIiXh6G/FEwiFQqGyGyFv+g7eym4ClYYVnxGrknQMlN0CKoXsv8fJfZ0n457KVK+TjWnxlUgtMZ9VlIW1sltApWBgWUPZTaBSyNj2ldzXyXxWPF6pJiIiudDkqXAiIqJyh/mseOxUExGRXDCziYiIyh/ms+KxU01ERHLBzCYiIip/mM+Kx041ERHJBZ+DSUREVP4wnxVPLTvVzy7+ruwmUClUacUJbFQSJ5ijdxjZVBzms2piPqum19mZym4ClRPMZ8VTy041ERGVPQHPhBMREZU7zGfFY6eaiIjkgplNRERU/jCfFY+daiIikgtmNhERUfnDfFY8dqqJiEg+mNpERETlD/NZ4dipJiIiuRAwtYmIiMod5rPisVNNRERyocHMJiIiKneYz4rHTjUREckHQ5uIiKj8YT4rHDvVREQkFxxeRkREVP4wnxWPnWoiIpILPrKDiIio/GE+K56GshtARETqQSDjQkRERGVHkfm8Zs0aWFtbQ09PDy4uLoiMjCyybqdOnSAQCAotvXr1kqgXGxuLPn36wMTEBIaGhmjVqhUSEhJK2cKywU41ERHJhbSglLYQERFR2VFUPgcHB8PHxwdz5szB5cuXYWdnB3d3d6Smpkqtv3fvXiQlJYmXmJgYaGpqYuDAgeI69+7dQ7t27dC4cWOcPHkS165dw+zZs6Gnp1fq/S8LHP5NRERywf4yERFR+aOofF6+fDnGjBmDb775BgAQEBCAkJAQbNq0CTNnzixU39TUVOJ1UFAQDAwMJDrVP/30E3r27ImlS5eKy+rXr6+YHZAjXqkmIiK54PBvIiKi8kcR+Zybm4uoqCi4ubmJyzQ0NODm5oaIiAiZ1hEYGIjBgwfD0NAQAFBQUICQkBA0atQI7u7usLCwgIuLC/bv31/C1pU9dqqJiEg+2KsmIiIqf2TM55ycHLx8+VJiycnJkbrK9PR05Ofnw9LSUqLc0tISycnJxTYpMjISMTExGD16tLgsNTUVmZmZWLx4Mbp3744jR46gX79+6N+/P06dOlWqXS8r7FQTEZFcaAgEMi1ERERUdmTNZz8/P5iYmEgsfn5+CmlTYGAgbG1t4ezsLC4rKCgAAPTt2xdTp06Fvb09Zs6ciS+++AIBAQEKaYe88J5qIiKSC3aXiYiIyh9Z83nWrFnw8fGRKNPV1ZVa18zMDJqamkhJSZEoT0lJgZWV1Se3k5WVhaCgIMyfP7/QOrW0tNC0aVOJ8iZNmiA8PFzGvVAOXqkmIiL54PBvIiKi8kfGfNbV1YWxsbHEUlSnWkdHB46OjggLCxOXFRQUICwsDK6urp9szq5du5CTk4OhQ4cWWmerVq0QFxcnUX779m3UqVOnZPtcxpTaqY6Ojsbw4cNRr1496Ovrw9DQELa2tpg9ezZevnypzKYREVEJCWT8j1QDM5qISD0oKp99fHywYcMGbN26FbGxsZgwYQKysrLEs4EPHz4cs2bNKvS5wMBAeHh4oGrVqoXemzFjBoKDg7FhwwbcvXsXv//+O/755x98++23Jd/xMqS0TvXhw4fh6uqK169fo23bttDQ0MDIkSPRq1cvBAUFoWXLljLd5E5EROWDQCDbQuUfM5qISH0oKp89PT2xbNky+Pr6wt7eHlevXkVoaKh48rKEhAQkJSVJfCYuLg7h4eEYNWqU1HX269cPAQEBWLp0KWxtbbFx40bs2bMH7dq1K3kDy5BAKBQKlbFhBwcHjBs3DuPHjwcAHD16FJMnT0ZsbCzy8vLQo0cP1KpVC5s3by7xut+8lXdr5SPo//7C1s2BSE9PQyObxpj542zYtmghte6oEcNw6WJkofL2HTri9z/WIy8vD7+v8kf4mdN4/PgRKhkZwcW1DaZMnQYLC9E/5IuRFzD6m+FS1/9X0C40t5W+bWWp0spb2U2QatygDpjq1RWWVY1x/XYifJbswqUbD4us7/11J4wZ2B61rKog43kW9h27gtmrDyAnV/QPc8zAdhgzoD3qVBc9qy82PhmL1h/CkbM3xeuwrFoJi77rhy6tG6OSoS5uP0jF0sDD2B92VaH7WipW5fPZgeO+sMPUAY6wrGKI6/Fp8PnjBC7dTimyvreHA8b0aoFa5sbIeJmNfeF3MHtzOHLy8gEA0we1gkfbBmhU0xTZuW9x4eYT/LQpHHcSnwEAalsYI26r9IAYsvBf7A2/I/+d/AzZh6bKfZ23U17LVK+RpYHct03ypaiMLq/5DMg3oz+2YJ4vdu8MxowfZmHo8BGF3s/NzcXQwQMRF3cLwbv3o3GTJp+9P/LEfL4pdX37f58A97bNMGjqevxz8pr8d/BzVTJTdgukGtevFaYObgtLUyNcv5cMn5WHcCk2scj63gNbY0xfJ9SyNEHGi9fYd/ImZq8P+3Dc+jphjEcr1LGqDACIvZ+KRVtP4ciFu+J16OpoYfHEbhjYpTl0tbVw7OJdTFkegtRnWQrd19LIPj1X7utkPiue0iYqu3XrFrp37y5+7ebmhnv37iEpKQnVqlXDnDlz8OWXXyqreXIXeuggli31w89z5sHW1g5/bd+KCeNG4e9/Q6UOfVjuvxp5eXni189fPMeg/n3xv26in9mbN29wK/Ymxo6fABubxnj58iWW+C3EFO8J2LFzLwDA3t4BYSclb+pfs3olLlyIQLPmtgrcW/UxoFtLLJnWD5MWBuNizAN4f90ZB9ZOhJ3HfKQ9yyxU37O7ExZM7ovxc/9CRHQ8GtaxwIb5wyAE8MNvouOSmPIcs1f/jbsJaRBAgKG9XbBrxVi0HrwYsfGiKz8bFwxH5Ur6GPjdOqQ/z4RnDyf8uWQk2g5Ziui4x2X5I1BJAzo0wpKxHTBpdRguxiXD26MlDvzSH3ZjtiDtRXah+p6dbLDgm3YYv+IIIm4moWHNytjg4w6hUIgfNpwGALS3rYmAf6IRdTsFWpoCzBvRFv8u7A+HcVvxOuctHqe/gvXX6yTWO7KHLaZ+6YTDlx6UxW4rHYd2qw9m9Odl9H+FHTuK69HRMLewKHL7K35bCnMLC8TF3ZLPDlUAysrn9yYN6QzlXJZSbQO6NMOSie6Y9Nu/uHgzEd4DW+PAsqGwG/I70p4X7uB6utliwVg3jF/yNyJiHqFhrarYMMsDQiHww5rDAIDEtJeYve4Y7j7OEB237nbYtegrtB4VgNgHaQCApd7u6OHaCEPm7MLLzDdY8V1PBP3iiS4TN5Xp/isL81nxlDb8u0aNGhI3od+7dw8FBQXi8KpZsyYyMwv/UVRV27duRv8Bg+DR70vUb9AAP8+ZBz09Pezfu0dqfZPKlWFmbi5ezp87Cz09PfzPXRTYlSpVwrqNm+HevSes69ZDCzt7zPppNm7euIGkJ08AANo6OhLrMKlcGSdOhKGvR38IOAZTJpOHdsHmveew/cB53IpPxqSFQch+kwsvD+kTMLS2q4uIq/EIDr2EhKSnCDt/CztDL8Gp2YfJFQ6ejsHh8Ju4l5CGuwmpmLvmH2S+zoFzi7r/WU89rA06hUs3HuJBYgaWbDyM56+y4dC0lsL3WR1M7tcSmw/FYPvRm7iV8BSTVh9Dds5beHVrLrV+6ybVEXHzCYJPxiEh9SXCLidg58k4ONl8mL2y7+x9+PPYTcQmZOD6/XSMXX4EtS2N4dBQNDKkoECIlGevJZY+bRpgz5nbyHqTJ3W76obDv9UHM/rzMvq9lJQULF60AIuWLoO2lrbUdYWfOYWIc2fhM/0Hue+XOlNWPgNAi0Y1MGVYF4yf+6dC91EdTR7kis3/Xsb2Q1dx62EaJv32L7Lf5MGrl4PU+q2b10JETAKCj11HQvJzhF28h51h1+HUpIa4zsFzt3H4/B3ce/wUdx9nYO7G48jMzoVzs5oAAGNDXYzo1RI//H4Ypy7fx5XbSRi7+G+42taGc9OaZbLfysZ8VjyldaqHDx+O0aNHIyAgAJs3b0a/fv3Qp08f6OjoAACuXr2KunXrFrMW1ZCXm4vYmzfQ2rWNuExDQwOtW7fBtegrMq1j39496N6jFwwMih6WkZmZCYFAgErGxlLfP3XiOF48fw6PfupzdUGRtLU04dCkFo5f+PDFUigU4viFuEIB+9756PtwaFpLHNLWNarCvW0zhIbfkFpfQ0OAge6OMNTXwYVr9/+znngM6OaIKsYGEAhEdfR0tXD6UvkaQlweaWtpwKGhJY5fTRCXCYXA8asJcG5STepnzsc+gUMDCzg1EnWQra1M4N7KGqEX70utDwDGBqK/Vc9evZH6vkMDC9jXt8DWwzGl3RWVo8jJv9esWQNra2vo6enBxcUFkZGFh96+16lTJwgEgkJLr169pNYfP348BAIB/P39S9k69cOM/vyMLigowE8zZ2DEN6PQoEFDqZ/LSE/HvDmzsdBvKfT09T5vRyoQZeazvp42tviNwHeLdyIl45Uc90r9aWtpwqFRdRy/FC8uEwqFOB4VL+4Af+x8zCM4NKou7kRbV6sC99YNEXpe+vchDQ0BBnZpDkM9bVyIEY3sc7CpDh1tTRyP+rDd2wnpSEh+Dpcitqtu+HAOxVPa8O8ff/wRWVlZWLBgAXJycuDu7o6VK1eK369Rowb++OMPZTVPrp49f4b8/PxCQ8iqVq2K+/fji/jUB9evXcPdO7cxd/7CIuvk5OTAf/ky9OjZC0ZGRlLr7Nu7G23atoNlMc+OIxGzKkbQ0tJE6lPJ0EzNeAkba0upnwkOvYSqVQwRtnkqBBBAW1sT63edwa+bjkjUa9agOk5unQY9HS1kZufAc9oG3PrP0LKh32/C9iUj8eTUUuTl5eP1m1x4+mxA/KN0+e+omjEz1oeWpgZSn0neP5T67DVsalaR+pngk3GoaqyPsGWeEAhEwb8+JBq/Bl+UWl8gAH4d1wnnbiTi5sMMqXW83JsjNiED52OTpL6vlhSUyMHBwfDx8UFAQABcXFzg7+8Pd3d3xMXFwULKkNq9e/ciNzdX/DojIwN2dnYYOHBgobr79u3D+fPnUb16dcU0XkUxoz8/ozcHboCmlha+Hip9bhOhUIjZP83EwEGD0ay5LRITeWuPrJSZz0unfYnz0ffx78nr8t8xNWdmYgAtLQ2kfjQ8P/VpFmxqS7//O/jYdVQ1MUDY7yM/5PP+i/j1zzMS9ZrVs8DJtaPfHbdceP4cjFsPRUO/rUyNkJP7Fi8yJU+Cpz7LgmVV6d+Z1Q57zAqntE61lpYWlixZgiVLlkh939nZWab15OTkICcnR6JMqKlb5DPVVNG+vbvRsFGjIidMycvLwwyfKRAKhfjJd57UOinJyTh3Nhy//uavwJZSe8eGmDHSHVP8gnHx+kPUr2WGZTMGIGlMdyzeECqud/tBClwG+8HESB/93BywYf4wdBu9UhzccyZ+gcqV9NFj3CpkPM9C704t8OfSkXAb6Y8bd58oa/fUVnvbmpjh6Ywpa47jYlwS6levjGXjOiHpKxcs3nGhUH3/iV3QzLoquk7fKXV9ejqa8OxkI/Wz6kxDQWPHli9fjjFjxogf0REQEICQkBBs2rQJM2fOLFTf1NRU4nVQUBAMDAwKdaoTExMxadIkHD58uMir2BWVPDK6IuQzID2jb96IwV/btyFo994ib7f6v7+2IysrC6PGjCurplZo8sjnXh1t0cm5EVoPXqzEPalY2ttbY8bQ9piyPAQXYx+jfg1TLJvcA0nDX2HxttPiercTMuAyKgAmhrro16kpNvzogW6Ttog71hWdovKZPlDqc6rlwc/PDyYmJhLLr0v8lN0sCVUqV4GmpiYyMiSvaGVkZMDM7NMzM75+/RqHD4WgX/8BUt/Py8vDjGnfIenJE6zbuKnIq9T79+2BSeXK6Ni5S+l2ogJKf5aJt2/zYWFaSaLcoqoxkjOkP6N1zre9sCMkElv2ReDG3Sc4cOIafH//BzO+6SbxxSrvbT7iH6XjSuwj+K4+gOu3EzHxq04AgLo1zTBhcEeMm/snTkbexvXbiVi0/hAu30zAOM8OCttfdZH+Mhtv8wtgUUXyVgmLKgZIfiZ99ss5w9tgx/FYbDkcgxsPMnDg3D34bjmLGYNaFbrHaMWEzujpXA/uP+xGYrr0e0r7tWsEA11t/BUWK5d9UhWyDi/LycnBy5cvJZaPO1/v5ebmIioqCm5ubuIyDQ0NuLm5ISIiQqZ2BQYGYvDgwTA0NBSXFRQUYNiwYZgxYwaaNWtWmt2lYqhCPgOKyejLUZfw9GkGurt1RssWTdGyRVM8eZKI335dgh7/E+XwxQvncS36Klo52KJli6bo3aMbAOBrzy/x8yzeX/0pysrnTq0aoV5NMySf/hWvLq7Eq4ui0Rs7lo3G4Q1TFLOzaiT9xWu8fVsAiyqS31UtTA2R/FR6ns4Z1Rk7jkRjS8hl3IhPxYEzt+C7PgwzhrYvfNwSn+LK7ST4rg/D9bspmDjQBQCQ/DQTujpaMDGSvMXCooohUjLUZ26IT+Hwb8Urt53qH3/8ESNHjiy23qxZs/DixQuJZcYPhR8yrkzaOjpo0rQZLpz/8AWwoKAAFy5EoIWd9IkZ3jt6OBS5ubno1btPoffed6gTHj7EusAtqFxZ+tBWoVCIv/fvRe8+HtDWlj5RChWW9zYfV2IfobOLjbhMIBCgs3MjRF6Tfq+tvp4OCgokpwMtKCh499mit6UhEEBXRzRwxEBPdM9iwUfTiubnC3mmUQZ5bwtw5U4KOtt/mNRNIAA629dCZBFDsfV1tQr9vN8fx/+G9ooJndGnTQN0n7kbD1Okf3EDgBHuzRByIR7pUmYaV2sypra0zpafn/TOVnp6OvLz88XPvHzP0tJSpuckR0ZGIiYmBqNHj5YoX7JkCbS0tDB58uQS7ybJltGqkM+AYjL6iz59sWvfAQTv2S9ezC0s4PXNKPyxfiMA4IdZP2Pn3r/F779/FNfSZSswaYr8H3mnTpSVz8s2H0GrQX5wGbxYvADA97/twdg5nLSsOHlv83Hl9hN0dvxw37tAIEDnlvUQeUP67Q/6etpS8lmG46YhgK626LhdiXuC3Lx8ie02rFUVta0q40IR21U77FUrnNKGfxfn8ePHePy4+H/ourqFh5KVx+dgDvP6BrN//AHNmjVHc9sW+HP7VmRnZ8OjX38AwE+zvoeFhSWmTJ0m8bl9e3ejc1e3Qh3mvLw8TJ86GbGxN7F6zToU5OcjPU00xMXExATa7yaTAYDIC+eR+Pgx+n8p/Wo3FW3Vn8exYf4wRN1MwKV3j+ww0NfFtr/PAwA2LhiGJ6kv4Lv6AADRzKGTh3ZGdNxjRF5/gPq1zOE74QscPH1dHObzJ/XB4bM38CjpGSoZ6sGzhxM6ODVE72/XAgDiHiTjbkIqfv/5K8xavg8ZL7LQp3MLdG1tg/5TApTzg1Axq/ZdxoZp7oi6k4pLccnw9nCAga42th0VTUizcZo7nmRkwnfLWQDAwQvxmNy/JaLvpSLyVjLqV68M3+FtcPBCvPi4+U/sAs9ONhg4/wAys3Nh+e5K+IusHLzJzRdvu141E7RrXhMevvvKeK+VT9ZHdsyaNQs+Pj4SZYoaEhwYGAhbW1uJ4cpRUVFYuXIlLl++zCchlJIsGa0q+QzIP6MrV65SqExbSxtmZmawrlsPAFDto/v4309yVrNWbc59IgNl5HNKxiupk5M9SnqGh0+kz69BklbtjMCGWf0QFfcEl2JFj9Qy0NfGtoOiSQE3/tgPT9Jfwnd9GADRzN6TB7ki+nYyIt8N//Yd1QUHz8V9OG5ju+Lwhbt4lPIClQx04Olmiw721ug9fTsA4GVWDraEXMaSie54+jIbr7JysPy7njgf8wiRNytGp5qP1FK8ctup3rZtm7KbIFfde/TEs6dPsfb3VUhPT4NN4yZYu24jqr4bWpaclAQNgeTAgQf343HlchQCNhR+hl5qagpOnjgOABj0ZV+J9zZu3oZWzi7i1/v27Ia9vQPq1qsv791Se7uPXIZZFSP4TugFy6qVcC0uEX0nrhFPjlLLylTizPfijaEQCoWY8+0XqG5hgvRnmQg5HYO5v/8jrmNuaoTABcNhZWaMF5lvEHMnEb2/XYvjF0TPJ337tgAek/7AL5P7YvfKcTAy0MW9R2kY7bsdh8Nvlu0PQEXtPn0bZib68B3qCktTA1y7l4a+s/ch9blo+Hcti0oSZ74X77gAoRCYM7wtqlc1QvqL1wi5EI+5W8+J64z7wg4AcHTpIIltjfntMP489uG4eHVrjsT0Vzh2+aEid7FckrV/Kq2zVRQzMzNoamoiJSVFojwlJQVWxXQ8srKyEBQUhPnz50uUnzlzBqmpqahdu7a4LD8/H9OmTYO/vz8ePHgg245UYMzoT2c0KZ4y8pk+3+7jN2BW2RC+IzvD0tQI1+4mo+/0P5H6TPSM6lqWJpL5vO206LiN7oLq5pWQ/vw1Qs7FYe6G4+I65lUMEfhjP1hVNcKLrBzE3EtB7+nbJWYZ//73wygQCrFjgSd0tTVx7OI9TFkeUnY7rmQ8f6x4AqFQeY+uT09Px6ZNmxARESEexmdlZYU2bdpgxIgRMDc3L9V6y+uZcPq0Kq28ld0EKg0rnqxRRdmH5D+89PEz6fdFf6xmlZJdlXZxcYGzszNWr14NQDT0r3bt2vD29pY6Udl7W7Zswfjx45GYmCgxs3NGRgaSkiRvBXB3d8ewYcPwzTffwMbG5uNVVUiKyGjms2piPquoSp+eE4DKp+zTc+W+TkXlM32gtCvVFy9ehLu7OwwMDODm5oZGjRoBEF19WLVqFRYvXozDhw/DyclJWU0kIqISUcypcB8fH3h5ecHJyQnOzs7w9/dHVlaWeDbw4cOHo0aNGoXuyw4MDISHh4fURyV9XKatrQ0rKyt2qN9hRhMRqRNeqlY0pXWqJ02ahIEDByIgIKDQPW1CoRDjx4/HpEmTZJ7dlYiIlEtRw8s8PT2RlpYGX19fJCcnw97eHqGhoeLJyxISEqChITk0Ny4uDuHh4Thy5Ii0VVIxmNFEROqDw78VT2nDv/X19XHlyhU0btxY6vu3bt2Cg4MDsrNLPnsuh5epJg4vU1Ec/q2SFDH8+8nzXJnqVa+sU3wlUipFZTTzWTUxn1UUh3+rJEUM/2Y+K57SHqllZWWFyMjIIt+PjIws9AgVIiIqvwQC2RYq/5jRRETqg/mseEob/j19+nSMHTsWUVFR6Nq1qzicU1JSEBYWhg0bNmDZsmXKah4REZUQH0+lPpjRRETqg/mseErrVE+cOBFmZmZYsWIF1q5di/x80XNeNTU14ejoiC1btmDQoEHFrIWIiMoLRrb6YEYTEakP5rPiKfWRWu/l5eUhPT0dgOiZpNra2p+1Pt6zpZp4z5aK4j3VKkkR91SnvsqTqZ5Fpc/7G09lS54ZzXxWTcxnFcV7qlWSIu6pZj4rntKuVP+XtrY2qlWrpuxmEBHRZxDwXLhaYkYTEak25rPilYtONRERqT7eskVERFT+MJ8Vj51qIiKSC4Y2ERFR+cN8Vjx2qomISC44vIyIiKj8YT4rHjvVREQkFzwTTkREVP4wnxVPQ9kNICIiIiIiIlJVvFJNRERyocFT4UREROUO81nx2KkmIiK5YGYTERGVP8xnxWOnmoiI5IKZTUREVP4wnxWPnWoiIpIPpjYREVH5w3xWOHaqiYhILvjIDiIiovKH+ax47FQTEZFcaDCziYiIyh3ms+KxU01ERPLB0CYiIip/mM8Kx041ERHJBYeXERERlT/MZ8Vjp5qIiOSCj+wgIiIqf5jPiicQCoVCZTeCZJOTkwM/Pz/MmjULurq6ym4OyYjHTTXxuBGRrPj3QjXxuKkmHjcqj9ipViEvX76EiYkJXrx4AWNjY2U3h2TE46aaeNyISFb8e6GaeNxUE48blUcaym4AERERERERkapip5qIiIiIiIiolNipJiIiIiIiIioldqpViK6uLubMmcNJGVQMj5tq4nEjIlnx74Vq4nFTTTxuVB5xojIiIiIiIiKiUuKVaiIiIiIiIqJSYqeaiIiIiIiIqJTYqSYiIiIiIiIqJXaqy5HTp0+jd+/eqF69OgQCAfbv31/sZ06ePImWLVtCV1cXDRo0wJYtWxTeTvrAz88PrVq1QqVKlWBhYQEPDw/ExcUV+7ldu3ahcePG0NPTg62tLQ4ePFgGraX3/vjjD7Ro0QLGxsYwNjaGq6srDh069MnP8JgRVVzMZ9XDfFZNzGdSVexUlyNZWVmws7PDmjVrZKp///599OrVC507d8bVq1fx3XffYfTo0Th8+LCCW0rvnTp1ChMnTsT58+dx9OhR5OXloVu3bsjKyiryM+fOncNXX32FUaNG4cqVK/Dw8ICHhwdiYmLKsOUVW82aNbF48WJERUXh0qVL6NKlC/r27YsbN25Irc9jRlSxMZ9VD/NZNTGfSVVx9u9ySiAQYN++ffDw8Ciyzg8//ICQkBCJPxyDBw/G8+fPERoaWgatpI+lpaXBwsICp06dQocOHaTW8fT0RFZWFv79919xWevWrWFvb4+AgICyaip9xNTUFL/++itGjRpV6D0eMyJ6j/msmpjPqov5TKqAV6pVWEREBNzc3CTK3N3dERERoaQW0YsXLwCIAqAoPG7lS35+PoKCgpCVlQVXV1epdXjMiKgk+Dej/GE+qx7mM6kSLWU3gEovOTkZlpaWEmWWlpZ4+fIlsrOzoa+vr6SWVUwFBQX47rvv0LZtWzRv3rzIekUdt+TkZEU3kf7j+vXrcHV1xZs3b2BkZIR9+/ahadOmUuvymBFRSTCfyxfms2phPpMqYqeaSE4mTpyImJgYhIeHK7spJAMbGxtcvXoVL168wO7du+Hl5YVTp04VGdxERKSamM+qhflMqoidahVmZWWFlJQUibKUlBQYGxvzLHgZ8/b2xr///ovTp0+jZs2an6xb1HGzsrJSZBPpIzo6OmjQoAEAwNHRERcvXsTKlSuxbt26QnV5zIioJJjP5QfzWfUwn0kV8Z5qFebq6oqwsDCJsqNHjxZ53wnJn1AohLe3N/bt24fjx4+jbt26xX6Gx618KigoQE5OjtT3eMyIqCT4N0P5mM/qg/lMKkFI5carV6+EV65cEV65ckUIQLh8+XLhlStXhA8fPhQKhULhzJkzhcOGDRPXj4+PFxoYGAhnzJghjI2NFa5Zs0aoqakpDA0NVdYuVDgTJkwQmpiYCE+ePClMSkoSL69fvxbXGTZsmHDmzJni12fPnhVqaWkJly1bJoyNjRXOmTNHqK2tLbx+/boydqFCmjlzpvDUqVPC+/fvC69duyacOXOmUCAQCI8cOSIUCnnMiEgS81n1MJ9VE/OZVBU71eXIiRMnhAAKLV5eXkKhUCj08vISduzYsdBn7O3thTo6OsJ69eoJN2/eXObtrsikHS8AEsehY8eO4mP43s6dO4WNGjUS6ujoCJs1ayYMCQkp24ZXcCNHjhTWqVNHqKOjIzQ3Nxd27dpVHNhCIY8ZEUliPqse5rNqYj6TquJzqomIiIiIiIhKifdUExEREREREZUSO9VEREREREREpcRONREREREREVEpsVNNREREREREVErsVBMRERERERGVEjvVRERERERERKXETjURERERERFRKbFTTURERERERFRK7FQTERERERERlRI71aSSBALBJ5e5c+cqu4lyZ21tDX9/f2U3g4iIqEjMZyKqiLSU3QCi0khKShL/f3BwMHx9fREXFycuMzIyUkazSkwoFCI/Px9aWmX3q5ibmwsdHZ0y2x4REVUczOfSYz4TqS5eqSaVZGVlJV5MTEwgEAgkyoKCgtCkSRPo6emhcePGWLt2rfizDx48gEAgwM6dO9G+fXvo6+ujVatWuH37Ni5evAgnJycYGRmhR48eSEtLE39uxIgR8PDwwLx582Bubg5jY2OMHz8eubm54joFBQXw8/ND3bp1oa+vDzs7O+zevVv8/smTJyEQCHDo0CE4OjpCV1cX4eHhuHfvHvr27QtLS0sYGRmhVatWOHbsmPhznTp1wsOHDzF16lTx2X4AmDt3Luzt7SV+Nv7+/rC2ti7U7oULF6J69eqwsbEBADx69AiDBg1C5cqVYWpqir59++LBgwfyODxERFRBMZ+Zz0QVETvVpHb++usv+Pr6YuHChYiNjcWiRYswe/ZsbN26VaLenDlz8PPPP+Py5cvQ0tLC119/je+//x4rV67EmTNncPfuXfj6+kp8JiwsDLGxsTh58iR27NiBvXv3Yt68eeL3/fz8sG3bNgQEBODGjRuYOnUqhg4dilOnTkmsZ+bMmVi8eDFiY2PRokULZGZmomfPnggLC8OVK1fQvXt39O7dGwkJCQCAvXv3ombNmpg/fz6SkpIkrgTIIiwsDHFxcTh69Cj+/fdf5OXlwd3dHZUqVcKZM2dw9uxZGBkZoXv37hJfQoiIiOSF+VwY85lITQiJVNzmzZuFJiYm4tf169cX/t///Z9EnQULFghdXV2FQqFQeP/+fSEA4caNG8Xv79ixQwhAGBYWJi7z8/MT2tjYiF97eXkJTU1NhVlZWeKyP/74Q2hkZCTMz88XvnnzRmhgYCA8d+6cxLZHjRol/Oqrr4RCoVB44sQJIQDh/v37i92vZs2aCVevXi1+XadOHeGKFSsk6syZM0doZ2cnUbZixQphnTp1JNptaWkpzMnJEZdt375daGNjIywoKBCX5eTkCPX19YWHDx8utm1ERETFYT7bSZQxn4nUF++pJrWSlZWFe/fuYdSoURgzZoy4/O3btzAxMZGo26JFC/H/W1paAgBsbW0lylJTUyU+Y2dnBwMDA/FrV1dXZGZm4tGjR8jMzMTr16/xv//9T+Izubm5cHBwkChzcnKSeJ2ZmYm5c+ciJCQESUlJePv2LbKzs8Vnwj+Xra2txH1a0dHRuHv3LipVqiRR782bN7h3755ctklERPQe81k65jORemCnmtRKZmYmAGDDhg1wcXGReE9TU1Pitba2tvj/398D9XFZQUFBibcdEhKCGjVqSLynq6sr8drQ0FDi9fTp03H06FEsW7YMDRo0gL6+PgYMGFDsUC8NDQ0IhUKJsry8vEL1Pt5eZmYmHB0d8ddffxWqa25u/sltEhERlRTzmflMpM7YqSa1YmlpierVqyM+Ph5DhgyR+/qjo6ORnZ0NfX19AMD58+dhZGSEWrVqwdTUFLq6ukhISEDHjh1LtN6zZ89ixIgR6NevHwBRqH48KYmOjg7y8/MlyszNzZGcnAyhUCj+4nH16tVit9eyZUsEBwfDwsICxsbGJWorERFRSTGfmc9E6owTlZHamTdvHvz8/LBq1Srcvn0b169fx+bNm7F8+fLPXndubi5GjRqFmzdv4uDBg5gzZw68vb2hoaGBSpUqYfr06Zg6dSq2bt2Ke/fu4fLly1i9enWhSVg+1rBhQ+zduxdXr15FdHQ0vv7660Jn4a2trXH69GkkJiYiPT0dgGjW0bS0NCxduhT37t3DmjVrcOjQoWL3Y8iQITAzM0Pfvn1x5swZ3L9/HydPnsTkyZPx+PHj0v+AiIiIisB8Zj4TqSt2qkntjB49Ghs3bsTmzZtha2uLjh07YsuWLahbt+5nr7tr165o2LAhOnToAE9PT/Tp0wdz584Vv79gwQLMnj0bfn5+aNKkCbp3746QkJBit718+XJUqVIFbdq0Qe/eveHu7o6WLVtK1Jk/fz4ePHiA+vXri4eANWnSBGvXrsWaNWtgZ2eHyMhITJ8+vdj9MDAwwOnTp1G7dm30798fTZo0wahRo/DmzRueGSciIoVgPjOfidSVQPjxDR9EJNWIESPw/Plz7N+/X9lNISIioneYz0SkbLxSTURERERERFRK7FQTERERERERlRKHfxMRERERERGVEq9UExEREREREZUSO9VEREREREREpcRONREREREREVEpsVNNREREREREVErsVBMRERERERGVEjvVRERERERERKXETjURERERERFRKbFTTURERERERFRK7FQTERERERERldL/A0Ez1cltvnY1AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    {'temperature': 1.0, 'alpha': 0.3, 'accuracy': 0.8298969072164949, 'precision': 0.8277090767909066, 'recall': 0.8298969072164949, 'f1': 0.8272837322500177},\n",
        "    {'temperature': 1.0, 'alpha': 0.5, 'accuracy': 0.8350515463917526, 'precision': 0.8333853096865418, 'recall': 0.8350515463917526, 'f1': 0.8329165832696697},\n",
        "    {'temperature': 1.0, 'alpha': 0.7, 'accuracy': 0.8376288659793815, 'precision': 0.83652262516548, 'recall': 0.8376288659793815, 'f1': 0.8341876298292671},\n",
        "    {'temperature': 1.0, 'alpha': 0.9, 'accuracy': 0.7268041237113402, 'precision': 0.8252335533592452, 'recall': 0.7268041237113402, 'f1': 0.7438818285221023},\n",
        "    {'temperature': 2.0, 'alpha': 0.3, 'accuracy': 0.8195876288659794, 'precision': 0.8193024880196635, 'recall': 0.8195876288659794, 'f1': 0.8183060526143721},\n",
        "    {'temperature': 2.0, 'alpha': 0.5, 'accuracy': 0.825, 'precision': 0.829, 'recall': 0.825, 'f1': 0.826},\n",
        "    {'temperature': 2.0, 'alpha': 0.7, 'accuracy': 0.827, 'precision': 0.827, 'recall': 0.827, 'f1': 0.827},\n",
        "    {'temperature': 2.0, 'alpha': 0.9, 'accuracy': 0.838, 'precision': 0.836, 'recall': 0.838, 'f1': 0.834},\n",
        "    {'temperature': 3.0, 'alpha': 0.3, 'accuracy': 0.820, 'precision': 0.819, 'recall': 0.820, 'f1': 0.819},\n",
        "    {'temperature': 3.0, 'alpha': 0.5, 'accuracy': 0.832, 'precision': 0.836, 'recall': 0.832, 'f1': 0.834},\n",
        "    {'temperature': 3.0, 'alpha': 0.7, 'accuracy': 0.825, 'precision': 0.827, 'recall': 0.825, 'f1': 0.818},\n",
        "    {'temperature': 3.0, 'alpha': 0.9, 'accuracy': 0.827, 'precision': 0.837, 'recall': 0.827, 'f1': 0.830},\n",
        "]\n",
        "\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "-buvG1EPoRVB"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the figure\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.subplot(2, 2, 1)\n",
        "sns.barplot(x=\"temperature\", y=\"accuracy\", hue=\"alpha\", data=df,palette=\"Set1\")\n",
        "plt.title(\"Accuracy vs Temperature and Alpha\")\n",
        "plt.xlabel(\"Temperature\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "\n",
        "# Plot Precision\n",
        "plt.subplot(2, 2, 2)\n",
        "sns.barplot(x=\"temperature\", y=\"precision\", hue=\"alpha\", data=df,palette=\"Set1\")\n",
        "plt.title(\"Precision vs Temperature and Alpha\")\n",
        "plt.xlabel(\"Temperature\")\n",
        "plt.ylabel(\"Precision\")\n",
        "\n",
        "# Plot Recall\n",
        "plt.subplot(2, 2, 3)\n",
        "sns.barplot(x=\"temperature\", y=\"recall\", hue=\"alpha\", data=df,palette=\"Set1\")\n",
        "plt.title(\"Recall vs Temperature and Alpha\")\n",
        "plt.xlabel(\"Temperature\")\n",
        "plt.ylabel(\"Recall\")\n",
        "\n",
        "# Plot F1 Score\n",
        "plt.subplot(2, 2, 4)\n",
        "sns.barplot(x=\"temperature\", y=\"f1\", hue=\"alpha\", data=df,palette=\"Set1\")\n",
        "plt.title(\"F1 Score vs Temperature and Alpha\")\n",
        "plt.xlabel(\"Temperature\")\n",
        "plt.ylabel(\"F1 Score\")\n",
        "\n",
        "# Show the plots\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "Dc2LyPu9ob0G",
        "outputId": "229d18da-aebd-4026-cddf-1df4dbfe1597"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For gird search, train from strach for consistency"
      ],
      "metadata": {
        "id": "kwvDKamZplGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "train_dataset, val_dataset, test_dataset = prepare_datasets(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "294c99943cab4105bc8a5ade3389d09c",
            "66a116dee8d44d178eb4358d6f9333cf",
            "103662d5926849e9928d41f69229c04d",
            "99ebd88c07264ffead77a8f50e61146d",
            "865ef4d76507474eb339acda1e55b887",
            "64b889fd48c5413e95a310c3512f57e2",
            "baee1b71d81a4e99b392a21b25d2fef9",
            "d985874c44ad4ab49a2ab1f129bd1ed9",
            "5f5d7921c43949b88acd7f3c825baf24",
            "abf15fdde69041929a3a7a87f985717e",
            "423065e3030348a88d7915722956fa58",
            "2b38bb367b5e431d8a6940eca9c6acc9",
            "0d4ca7b2650f456aa0ffadbc9ad003dc",
            "6b5f145a4e8044b883d49d160b870a3b",
            "e7a70e69173d4e59b295686b118792b7",
            "95c9323911954e5e991ccd8100776b67",
            "0ad55f7095af4aa8883b4dac12ebbf5a",
            "59ae9eeb9b6049669c4c1283d2685587",
            "4ea8b9abeeb841519a902e9340be8204",
            "61a55d4bfdf8478fa6231ceb4b8a0a9f",
            "b020010c15c1497e8efa22228f664462",
            "a2e8b0cb0b794f0fa287a43cc9499693",
            "d57268467ef84fa29faecf1e0c5d0bc4",
            "c803c231c9ae42879e8c38f1e10f1e02",
            "d47e28a16f4f4934b5043d2da49cd131",
            "47eb3a97ceee4dcdb30c90f9b36e2b93",
            "25c78e76003f4ea0909117ed4328f7fb",
            "cdff912ba66d496db14eabbb454839d0",
            "c323c880909b4db1bd748634f0be8b4e",
            "0a5d0d786b4545b1995c367f36d5c556",
            "ed967468b2314992ab6da4383e9d4e5a",
            "ec36fb810f2045f7b2d1ded34b00b33b",
            "9f222d2ae8ea42728e20c41b73f04fe2"
          ]
        },
        "id": "MNqdMw-kjkqE",
        "outputId": "12182294-71f3-41df-eba8-6518a7ca9f74"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3488 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "294c99943cab4105bc8a5ade3389d09c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/388 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b38bb367b5e431d8a6940eca9c6acc9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/970 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d57268467ef84fa29faecf1e0c5d0bc4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args_teacher = TrainingArguments(\n",
        "    output_dir=\"/content/results_knowledge_distill/teacher_model_ROBERTA_grid_seach\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"/content/logs_knowledge_distill/teacher_model_ROBERTA_grid_search\",\n",
        "    logging_steps=10,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzFAU-EFptJx",
        "outputId": "c0106693-f466-44f2-d00f-213600e0ad15"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def distillation_loss(student_logits, teacher_logits, true_labels, temperature, alpha):\n",
        "    device = student_logits.device\n",
        "    true_labels = true_labels.to(device)\n",
        "    teacher_logits = teacher_logits.to(device)\n",
        "\n",
        "    soft_labels = F.softmax(teacher_logits / temperature, dim=-1)\n",
        "\n",
        "    hard_loss = F.cross_entropy(student_logits, true_labels)\n",
        "\n",
        "    soft_loss = F.kl_div(\n",
        "        F.log_softmax(student_logits / temperature, dim=-1),\n",
        "        soft_labels,\n",
        "        reduction=\"batchmean\"\n",
        "    )\n",
        "\n",
        "    return alpha * soft_loss + (1 - alpha) * hard_loss"
      ],
      "metadata": {
        "id": "qvBFXdORp0MZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation function\n",
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs = {k: v.to(\"cuda\") for k, v in batch.items() if k in [\"input_ids\", \"attention_mask\"]}\n",
        "            labels = batch[\"labels\"].to(\"cuda\")\n",
        "\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits\n",
        "            preds = torch.argmax(logits, axis=-1).cpu().numpy()\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "            predictions.extend(preds)\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    precision = precision_score(true_labels, predictions, average=\"weighted\")\n",
        "    recall = recall_score(true_labels, predictions, average=\"weighted\")\n",
        "    f1 = f1_score(true_labels, predictions, average=\"weighted\")\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n"
      ],
      "metadata": {
        "id": "SRAKrmfap4ZR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform grid search\n",
        "temperatures = [1.0, 2.0, 3.0]\n",
        "alphas = [0.3, 0.5, 0.7, 0.9]"
      ],
      "metadata": {
        "id": "B42BVjGWp6u5"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_metrics = {}\n",
        "best_params = {}"
      ],
      "metadata": {
        "id": "fVa_UV1Kp9TV"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start grid search\n",
        "for temperature in temperatures:\n",
        "    for alpha in alphas:\n",
        "        print(f\"Training with temperature={temperature}, alpha={alpha}...\")\n",
        "\n",
        "        teacher_model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=3).to(\"cuda\")\n",
        "        student_model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3).to(\"cuda\")\n",
        "\n",
        "        trainer_teacher = Trainer(\n",
        "            model=teacher_model,\n",
        "            args=training_args_teacher,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=val_dataset,\n",
        "            tokenizer=tokenizer\n",
        "        )\n",
        "        trainer_teacher.train()\n",
        "\n",
        "        teacher_model.save_pretrained(f\"/content/checkpoints/teacher_model_ROBERTA_{temperature}_{alpha}\")\n",
        "\n",
        "        train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "        val_dataloader = DataLoader(val_dataset, batch_size=16)\n",
        "\n",
        "        optimizer = Adam(student_model.parameters(), lr=2e-5)\n",
        "\n",
        "        student_model.train()\n",
        "        for epoch in range(3):  # training for 3 epochs\n",
        "            total_loss = 0.0\n",
        "            for batch in train_dataloader:\n",
        "                inputs = {k: v.to(\"cuda\") for k, v in batch.items() if k in [\"input_ids\", \"attention_mask\"]}\n",
        "                labels = batch[\"labels\"].to(\"cuda\")\n",
        "\n",
        "                # Get teacher logits (soft labels)\n",
        "                with torch.no_grad():\n",
        "                    teacher_logits = teacher_model(**inputs).logits\n",
        "\n",
        "                # Get student logits\n",
        "                student_outputs = student_model(**inputs)\n",
        "                student_logits = student_outputs.logits\n",
        "\n",
        "                # Calculate distillation loss\n",
        "                loss = distillation_loss(student_logits, teacher_logits, labels, temperature, alpha)\n",
        "                total_loss += loss.item()\n",
        "\n",
        "                # Backpropagation\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            print(f\"Epoch {epoch + 1}/3, Loss: {total_loss / len(train_dataloader)}\")\n",
        "\n",
        "        val_metrics = evaluate_model(student_model, val_dataloader)\n",
        "        print(f\"Validation Metrics: {val_metrics}\")\n",
        "\n",
        "        if best_metrics.get(\"f1\", 0) < val_metrics[\"f1\"]:\n",
        "            best_metrics = val_metrics\n",
        "            best_params = {\"temperature\": temperature, \"alpha\": alpha}\n",
        "\n",
        "print(f\"Best Hyperparameters: {best_params}\")\n",
        "print(f\"Best Metrics: {best_metrics}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3ZoxUVubp_R2",
        "outputId": "275de74a-0596-4f8e-f3ba-51300f773da5"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with temperature=1.0, alpha=0.3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-51-5219ad9dabdf>:9: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_teacher = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='654' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [654/654 02:15, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.844600</td>\n",
              "      <td>0.900884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.823600</td>\n",
              "      <td>0.825296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.808400</td>\n",
              "      <td>0.788450</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.46957809122603966\n",
            "Epoch 2/3, Loss: 0.3139647369127755\n",
            "Epoch 3/3, Loss: 0.26214407780848514\n",
            "Validation Metrics: {'accuracy': 0.8376288659793815, 'precision': 0.8398862824463537, 'recall': 0.8376288659793815, 'f1': 0.8310263073315738}\n",
            "Training with temperature=1.0, alpha=0.5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-51-5219ad9dabdf>:9: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_teacher = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='654' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [654/654 02:11, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.841100</td>\n",
              "      <td>0.879826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.793100</td>\n",
              "      <td>0.803001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.765800</td>\n",
              "      <td>0.790243</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.38276030704242375\n",
            "Epoch 2/3, Loss: 0.27664949922660076\n",
            "Epoch 3/3, Loss: 0.2400041089965663\n",
            "Validation Metrics: {'accuracy': 0.8170103092783505, 'precision': 0.837305730113012, 'recall': 0.8170103092783505, 'f1': 0.8050978025712996}\n",
            "Training with temperature=1.0, alpha=0.7...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-51-5219ad9dabdf>:9: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_teacher = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='654' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [654/654 02:14, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.841100</td>\n",
              "      <td>0.879826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.793100</td>\n",
              "      <td>0.803001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.765800</td>\n",
              "      <td>0.790243</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.2780301862763702\n",
            "Epoch 2/3, Loss: 0.20553818348487582\n",
            "Epoch 3/3, Loss: 0.1834566878547909\n",
            "Validation Metrics: {'accuracy': 0.7731958762886598, 'precision': 0.8038614148685745, 'recall': 0.7731958762886598, 'f1': 0.7499013506711274}\n",
            "Training with temperature=1.0, alpha=0.9...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-51-5219ad9dabdf>:9: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_teacher = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='654' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [654/654 02:12, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.841100</td>\n",
              "      <td>0.879826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.793100</td>\n",
              "      <td>0.803001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.765800</td>\n",
              "      <td>0.790243</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.15711717574148004\n",
            "Epoch 2/3, Loss: 0.10079986070615983\n",
            "Epoch 3/3, Loss: 0.08658158755220405\n",
            "Validation Metrics: {'accuracy': 0.7268041237113402, 'precision': 0.7564079141529226, 'recall': 0.7268041237113402, 'f1': 0.679571193818801}\n",
            "Training with temperature=2.0, alpha=0.3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-51-5219ad9dabdf>:9: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_teacher = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='654' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [654/654 02:14, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.841100</td>\n",
              "      <td>0.879826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.793100</td>\n",
              "      <td>0.803001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.765800</td>\n",
              "      <td>0.790243</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.43246159299251136\n",
            "Epoch 2/3, Loss: 0.2407882811347826\n",
            "Epoch 3/3, Loss: 0.17087770762656807\n",
            "Validation Metrics: {'accuracy': 0.8402061855670103, 'precision': 0.8446246537928913, 'recall': 0.8402061855670103, 'f1': 0.8337970427200434}\n",
            "Training with temperature=2.0, alpha=0.5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-51-5219ad9dabdf>:9: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_teacher = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='654' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [654/654 02:12, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.841100</td>\n",
              "      <td>0.879826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.793100</td>\n",
              "      <td>0.803001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.765800</td>\n",
              "      <td>0.790243</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.32840735608831456\n",
            "Epoch 2/3, Loss: 0.20358471411767357\n",
            "Epoch 3/3, Loss: 0.15899113712644358\n",
            "Validation Metrics: {'accuracy': 0.8479381443298969, 'precision': 0.8537685309654318, 'recall': 0.8479381443298969, 'f1': 0.8415580370495922}\n",
            "Training with temperature=2.0, alpha=0.7...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-51-5219ad9dabdf>:9: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_teacher = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='654' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [654/654 02:11, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.841100</td>\n",
              "      <td>0.879826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.793100</td>\n",
              "      <td>0.803001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.765800</td>\n",
              "      <td>0.790243</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.21858785745747591\n",
            "Epoch 2/3, Loss: 0.15075211585798395\n",
            "Epoch 3/3, Loss: 0.12697655259879356\n",
            "Validation Metrics: {'accuracy': 0.8427835051546392, 'precision': 0.8565280707269036, 'recall': 0.8427835051546392, 'f1': 0.8344957649991004}\n",
            "Training with temperature=2.0, alpha=0.9...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-51-5219ad9dabdf>:9: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_teacher = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='654' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [654/654 02:11, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.841100</td>\n",
              "      <td>0.879826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.793100</td>\n",
              "      <td>0.803001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.765800</td>\n",
              "      <td>0.790243</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.09844845671787722\n",
            "Epoch 2/3, Loss: 0.07122124693946007\n",
            "Epoch 3/3, Loss: 0.06378683687076656\n",
            "Validation Metrics: {'accuracy': 0.770618556701031, 'precision': 0.79751215618348, 'recall': 0.770618556701031, 'f1': 0.7470662566380434}\n",
            "Training with temperature=3.0, alpha=0.3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-51-5219ad9dabdf>:9: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_teacher = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='654' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [654/654 02:12, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.841100</td>\n",
              "      <td>0.879826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.793100</td>\n",
              "      <td>0.803001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.765800</td>\n",
              "      <td>0.790243</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.41921555661006804\n",
            "Epoch 2/3, Loss: 0.21598331165423088\n",
            "Epoch 3/3, Loss: 0.13979856992875217\n",
            "Validation Metrics: {'accuracy': 0.8350515463917526, 'precision': 0.839932334589111, 'recall': 0.8350515463917526, 'f1': 0.8276403683666697}\n",
            "Training with temperature=3.0, alpha=0.5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-51-5219ad9dabdf>:9: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_teacher = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='654' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [654/654 02:12, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.841100</td>\n",
              "      <td>0.879826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.793100</td>\n",
              "      <td>0.803001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.765800</td>\n",
              "      <td>0.790243</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.3105423928605854\n",
            "Epoch 2/3, Loss: 0.1741138709657783\n",
            "Epoch 3/3, Loss: 0.12415652197503715\n",
            "Validation Metrics: {'accuracy': 0.8376288659793815, 'precision': 0.8422299593421195, 'recall': 0.8376288659793815, 'f1': 0.830817962471834}\n",
            "Training with temperature=3.0, alpha=0.7...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-51-5219ad9dabdf>:9: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_teacher = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='654' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [654/654 02:13, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.841100</td>\n",
              "      <td>0.879826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.793100</td>\n",
              "      <td>0.803001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.765800</td>\n",
              "      <td>0.790243</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.19870037500054463\n",
            "Epoch 2/3, Loss: 0.12368139388774513\n",
            "Epoch 3/3, Loss: 0.09687098079796778\n",
            "Validation Metrics: {'accuracy': 0.8530927835051546, 'precision': 0.8584148108106562, 'recall': 0.8530927835051546, 'f1': 0.8474563176496248}\n",
            "Training with temperature=3.0, alpha=0.9...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-51-5219ad9dabdf>:9: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_teacher = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='654' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [654/654 02:12, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.841100</td>\n",
              "      <td>0.879826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.793100</td>\n",
              "      <td>0.803001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.765800</td>\n",
              "      <td>0.790243</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.08095941760944664\n",
            "Epoch 2/3, Loss: 0.05820950544481977\n",
            "Epoch 3/3, Loss: 0.0506890488771397\n",
            "Validation Metrics: {'accuracy': 0.8118556701030928, 'precision': 0.8387543611377265, 'recall': 0.8118556701030928, 'f1': 0.797773794031129}\n",
            "Best Hyperparameters: {'temperature': 3.0, 'alpha': 0.7}\n",
            "Best Metrics: {'accuracy': 0.8530927835051546, 'precision': 0.8584148108106562, 'recall': 0.8530927835051546, 'f1': 0.8474563176496248}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q0AUZKtjqOPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_from_new_training = [\n",
        "    {'temperature': 1.0, 'alpha': 0.3, 'accuracy': 0.8376288659793815, 'precision': 0.8398862824463537, 'recall': 0.8376288659793815, 'f1': 0.8310263073315738},\n",
        "    {'temperature': 1.0, 'alpha': 0.5, 'accuracy': 0.8170103092783, 'precision':0.83730573, 'recall':0.8170103, 'f1':0.805097 },\n",
        "    {'temperature': 1.0, 'alpha': 0.7, 'accuracy': 0.7731958762, 'precision': 0.8038614, 'recall': 0.7731958, 'f1': 0.7499013},\n",
        "    {'temperature': 1.0, 'alpha': 0.9, 'accuracy': 0.726804123, 'precision': 0.75640791, 'recall': 0.7268041, 'f1': 0.679571193},\n",
        "    {'temperature': 2.0, 'alpha': 0.3, 'accuracy': 0.84020618, 'precision': 0.84462465, 'recall': 0.84020618, 'f1': 0.833797},\n",
        "    {'temperature': 2.0, 'alpha': 0.5, 'accuracy': 0.84793814, 'precision': 0.8537685, 'recall': 0.8479381, 'f1': 0.84155},\n",
        "    {'temperature': 2.0, 'alpha': 0.7, 'accuracy': 0.8427835, 'precision': 0.856528, 'recall': 0.842783, 'f1': 0.834495},\n",
        "    {'temperature': 2.0, 'alpha': 0.9, 'accuracy': 0.7706185, 'precision': 0.797512, 'recall': 0.770618, 'f1': 0.7470662},\n",
        "    {'temperature': 3.0, 'alpha': 0.3, 'accuracy': 0.835051, 'precision': 0.8399, 'recall': 0.835051, 'f1': 0.82764},\n",
        "    {'temperature': 3.0, 'alpha': 0.5, 'accuracy': 0.8376288, 'precision': 0.84222, 'recall': 0.83762, 'f1': 0.830817},\n",
        "    {'temperature': 3.0, 'alpha': 0.7, 'accuracy': 0.853092, 'precision': 0.858414, 'recall': 0.8530927, 'f1': 0.847456},\n",
        "    {'temperature': 3.0, 'alpha': 0.9, 'accuracy': 0.8118556, 'precision': 0.838754, 'recall': 0.81185, 'f1': 0.79777},\n",
        "]\n",
        "\n",
        "df = pd.DataFrame(data_from_new_training)"
      ],
      "metadata": {
        "id": "mxipnYTxrgLQ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the figure\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.subplot(2, 2, 1)\n",
        "sns.barplot(x=\"temperature\", y=\"accuracy\", hue=\"alpha\", data=df,palette=\"Set1\")\n",
        "plt.title(\"Accuracy vs Temperature and Alpha\")\n",
        "plt.xlabel(\"Temperature\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "\n",
        "# Plot Precision\n",
        "plt.subplot(2, 2, 2)\n",
        "sns.barplot(x=\"temperature\", y=\"precision\", hue=\"alpha\", data=df,palette=\"Set1\")\n",
        "plt.title(\"Precision vs Temperature and Alpha\")\n",
        "plt.xlabel(\"Temperature\")\n",
        "plt.ylabel(\"Precision\")\n",
        "\n",
        "# Plot Recall\n",
        "plt.subplot(2, 2, 3)\n",
        "sns.barplot(x=\"temperature\", y=\"recall\", hue=\"alpha\", data=df,palette=\"Set1\")\n",
        "plt.title(\"Recall vs Temperature and Alpha\")\n",
        "plt.xlabel(\"Temperature\")\n",
        "plt.ylabel(\"Recall\")\n",
        "\n",
        "# Plot F1 Score\n",
        "plt.subplot(2, 2, 4)\n",
        "sns.barplot(x=\"temperature\", y=\"f1\", hue=\"alpha\", data=df,palette=\"Set1\")\n",
        "plt.title(\"F1 Score vs Temperature and Alpha\")\n",
        "plt.xlabel(\"Temperature\")\n",
        "plt.ylabel(\"F1 Score\")\n",
        "\n",
        "# Show the plots\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "89cXwG792CZl",
        "outputId": "1cb2eac4-ad0f-4a36-f7e4-d12467e08f65"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training knowledge distillation model with AdamW instead of Adam vis using best hyperparameters from grid search."
      ],
      "metadata": {
        "id": "Ri3DiBOKxiHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import AdamW\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "YAexGl11x5SW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "train_dataset, val_dataset, test_dataset = prepare_datasets(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493,
          "referenced_widgets": [
            "3ea94f93be2c47c3b327efeac6d63f46",
            "d251ef5062a04bb7be5bd692eec06537",
            "a50add41e3ba46c28422c841d84bc17f",
            "ae391878469d4cbca62735a3c9e3593a",
            "847a54bfba374d378db4f1433735b33a",
            "5493798603a84237ac575217159ee510",
            "dce04ac9f4ef4d4fbbea6626de54d595",
            "a620dc94421942c181ba2787e9b2116f",
            "045ad72477f94e818248f2213a0b9af0",
            "6ffaf54a38c745f5b458d84faf0a7d19",
            "3265b21e3ee24d3c8f3bb72722457805",
            "0cf46776d9fa45fd90eab28abed5dba9",
            "71adfc022bad4e518159bb16dc7f37a9",
            "6d5718ce15294efe9ac0f8202712fc67",
            "697467891e3c42d8b9f5a8b344d087c7",
            "f65fa75d374c444fa711f80a60781d74",
            "1c9dd3edc0204093b93865e1c953403d",
            "76a9bff016264784b57adf0ef30645d3",
            "321b024a316a4704b766a5c32d68c331",
            "d8210acd437c4ceaae1b0955991e462e",
            "5f4ec26e966841a68dcfd89872b8cc14",
            "9eb380d1a6d349679723d30f27624423",
            "35e79b41cf0b40a881c1d57be34187db",
            "d54c19c940a04f4eaeeda807e666ddf8",
            "33f9af79073f44259c6047009f38dad9",
            "b32a4e3f46c040fda479fe8529f7cdb7",
            "4631fa655457411eb7a0079d4e11b8a8",
            "c606831e2302431bac132233c793384d",
            "24ac7df9555a43ceb7f6260beab0e53e",
            "b01a7222d9944c2b96a6259bb212323a",
            "fe7fa85e337143829833404cd8ea7f3d",
            "69f82d11fa2e42ceb68769b70c261b23",
            "d852ad7b01364d418ae320eb4cf665b1",
            "5ce2455d893c47ae9d6f9554875395b2",
            "eebdced070f24a6da579ba5b68f8e1cc",
            "c221ae700bc24f17864790cd7ae65ca7",
            "e0d264c0dd634a50b34e07d5d07656cc",
            "93d3a53f1b1c425189357b10471ce9b5",
            "d2a367f85f424a91a2e5439d5b5f30fb",
            "f6483b02c1ef40e0be4d293255fda36c",
            "3b29616046914588b60e5ef2261cc57c",
            "b5ff000441834eb7b8f93ad5ad20c053",
            "4562b6000e5043cc9bd73d17dea84bfb",
            "f07f664ba51d454788761647e7e74dc2",
            "1d870f134ac244d29cc41ca0174a4151",
            "c6478ff659674af7b09dc6f11aee55fa",
            "fd6d62285dcd4412b00904ac833547ef",
            "82b5ea39072a4650a3bf3f3789f78804",
            "50575a756d3349748630a52089d471ed",
            "d9446adb28394b979e56dc5a670ad1c5",
            "9d829383f23f4418afecdbef6274defc",
            "cef517f1cae74f5d886ac7a732c8df11",
            "f2b4c65e7a63481a9ae7cca6cb29f5da",
            "7a6bffeda969445a9d83b8fe5d316814",
            "d48161278bc1401da52510783636fca4",
            "ef7650a97873452f91d39890435a98ad",
            "c66e2d9eaf814eeba86570f63c7af27c",
            "7088b7797d5a4a89b064260d168b6613",
            "8cbfd630ab7a45d2b6b022ac11809cde",
            "7af6e332f6bc4c6ea77650da1e7b1e64",
            "182ac60eac024a98975ccec3a757c881",
            "e41ea1032ad441439ba408988a28b1c1",
            "28a58a777917448c8fffbea11f3cce13",
            "5b746737162d4667979f59078922c133",
            "38eca8f68883437aac3709eb102b2985",
            "7c478921dd8648929223f3114a4148a4",
            "1cdc185ddb7a465da56816ae45f1cf7b",
            "c53be57a31004ecb9a85844f6d830e7d",
            "18962701146e48969d85fb2e527d9e3b",
            "79441464bf644c9587859709ba7b0e4c",
            "441bf149b2d441ce8f29b1f0c326a260",
            "00b4010ef7454da897ac9817ef82995d",
            "a7d03e3ea02447c89f317eca0bf95410",
            "c42e9c3b17d34b638051819e1be9d1f6",
            "0dfc9209147a4a73a25d7e631a164670",
            "bf9ebf70c7e8481a9905cec9e9b96cbd",
            "b03884a9939c4216a298b4667e842362",
            "9cbb25d7b591417ea41587c8e5abcf6d",
            "a8054768334544ae88bedab1fd845f81",
            "208912e528784fc290069c8825f63689",
            "be6f733b4b454462a94a16721b23375c",
            "2799434cdeca4deea94ba55d90cb0c02",
            "3d0e7e567c69492db343e871f79e209e",
            "8c05cffe4b71446c9f5da76cbe26e9c0",
            "eb3337a6fb6d4faaa27086cff730f25a",
            "f388c6f42b974a17b3b71d62640bc07c",
            "2aa7c80e422f4b0489f8182c1e8fb174",
            "940b5c639e0340b1a22f8f2c415c6521",
            "8303c0f9983a4dc8824b13c5fd848a47",
            "bb9e2147edba4440b317ae5ef367633e",
            "e1a71e2ebfb84795a312ce69ec7952c1",
            "f6995bf8da5143a9b910e8e7ab5802d1",
            "d76087cf48c84132a217d6b9c49f81f4",
            "7a033f75cb1f4c3ca68e4b42f81e7e46",
            "96e71d0f93a84271a70d9d1fbefb93dd",
            "c09e80640b764822aa2c7619b5b51ff5",
            "0cfb6b4b7de64b69a057de732f570da0",
            "802962e0bb9c45eaa01ab45ca8a44e4b",
            "129b3bff1fe4476c8cd1c60658eb5db2",
            "54d90c60be5b444090640bb64f92e1b8",
            "918ff5ed1e154bd0a1dfae717202cb1f",
            "a44dd9186dc64df5bc5c733e768de16e",
            "14d34f9037cf4752af7a4d15e58dc3e2",
            "7e64d77b302147d189f7734444b8f528",
            "7973da519d244ebe8b454db0e83cc782",
            "7035433411134808add473ceaf3e9042",
            "c2e7113e410a44769be9fa3525acbb6f",
            "cc15d8e664a0466ebb999a041363799c",
            "0b056c63972b4147b6970d532a118ee4",
            "0fe4340bab814c59ba546bfd88629b78",
            "30fc8368fe114f3d926b8b678ea83134",
            "f4a79859b5d1463593af1be3136ea600",
            "292e5d84fbc743de974a7e23b69c1924",
            "c25718c6a56643e1a68974e739b86d79",
            "dc91cf645ad745b68bfc0ec20f1eaf34",
            "01e415e354084d8a911f83fcee186fbb",
            "2c1c4c0699a24bfe8b772f7102714d98",
            "375d1ed18766409f8c5d6068b009fac8",
            "4967fdc80dcf437494fa0398475c8c75",
            "a92578d806174717b1c6c72751ff70a3",
            "b6ffced1184c4ac9bc6fbff42fe764b0"
          ]
        },
        "id": "4PCOJkwn2PUX",
        "outputId": "fbd4fb74-4635-47be-9a20-274ae93f2285"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ea94f93be2c47c3b327efeac6d63f46"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0cf46776d9fa45fd90eab28abed5dba9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35e79b41cf0b40a881c1d57be34187db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ce2455d893c47ae9d6f9554875395b2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/8.88k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d870f134ac244d29cc41ca0174a4151"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "financial_phrasebank.py:   0%|          | 0.00/6.04k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef7650a97873452f91d39890435a98ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FinancialPhraseBank-v1.0.zip:   0%|          | 0.00/682k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1cdc185ddb7a465da56816ae45f1cf7b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/4846 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9cbb25d7b591417ea41587c8e5abcf6d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3488 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8303c0f9983a4dc8824b13c5fd848a47"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/388 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54d90c60be5b444090640bb64f92e1b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/970 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30fc8368fe114f3d926b8b678ea83134"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=3).to(\"cuda\")\n",
        "student_model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3).to(\"cuda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234,
          "referenced_widgets": [
            "60d3a594358b466db95388d2f4a8dff7",
            "1aee4f3317414e299f7fa16840084eb0",
            "ff52808c6f604e24ae3bf22b4a0ac1a1",
            "a2dfccc8aed7479a8e1528604c6a3928",
            "8d653f5fe9694dad8d944183c85ed049",
            "db89d8754d784f70a2d8b07032c78059",
            "da2eec3efa734ce0963894f12ac19cd3",
            "649dfb9e88a245a78f69389504d02aa9",
            "af40086a735b4c92b28e189217ae0924",
            "bf4fae3e0b7f4f368cdf4fa73018b3f5",
            "3f3908468d6945c28baf0b3f9513bb83",
            "d8fd87db63084027bb9e9400cb054f2c",
            "f9bc1b1167b64a7e98950f5b3a58858b",
            "668cb65bce494fb2978fda9944f9b0c5",
            "9f100e4e254f4cc4ac263276e25e5039",
            "1c8000d24b5f411dad234c9939cd853f",
            "62627d28a87b4ae8a54363c7f218d993",
            "41d2b118411d4e388f5742ccfb6c5d37",
            "60b68694694b431c9a3b33419b24a51a",
            "51402aefc5ae44f0aaff296522588b3a",
            "a2fcf238f2a34603935f5f59c86c8de6",
            "5a481181d95b4267b108ec097c08665a",
            "af32c1ca1a9b4ea49cce948190b289db",
            "01afd12bd01f48acaa83232755262378",
            "30c63fd1711148c9ac1ba71ffcd0a31b",
            "fe779f86209c46d897e957963d427fb8",
            "5364f8537d184223898d702633d7366a",
            "217c64f050c7420da78849e65dc9adab",
            "c8b2668160b34bd5a1f3e39475749d69",
            "cf563f4cb3b843039a647111fa384aa7",
            "ab1f469244724fddb4a3e50374647f88",
            "09c1c7241a434aadace4c74ba51d522f",
            "bc859d3841ea48d98663dc2fae197317",
            "6621c65327df4f43a61d5342d9b9b5f5",
            "75c977beee554d2cbec5ef2feb911ed7",
            "85b848c3139b43ca87a07fac9f6c970c",
            "43a3731694d84095b4c9080ef65a80ef",
            "041c5c476e4f40578e4d7bb2b03b46c1",
            "ec7b5bf2fb0041a4ab2ac03ac9417cf8",
            "c77d14a9d6b64389834039a2e9315bb7",
            "f212c7f48083499b8538629a10329b28",
            "4fcad4750734436b99bfc4aed4ce63d2",
            "c21ffed75e66498a80422599bceefa2c",
            "d0ca6d3cf8ce437f88db40c144cf98af"
          ]
        },
        "id": "VPHFRguwxs24",
        "outputId": "65e64792-8588-4462-b388-90180a32fd2e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "60d3a594358b466db95388d2f4a8dff7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8fd87db63084027bb9e9400cb054f2c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af32c1ca1a9b4ea49cce948190b289db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6621c65327df4f43a61d5342d9b9b5f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args_teacher = TrainingArguments(\n",
        "    output_dir=\"/content/teacher_model\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"/content/logs_teacher\",\n",
        "    logging_steps=10,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=False,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlXzYp-szUSc",
        "outputId": "c3f8c0d0-06fd-4bc9-d081-714f078704aa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "trainer_teacher = Trainer(\n",
        "    model=teacher_model,\n",
        "    args=training_args_teacher,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "trainer_teacher.train()\n",
        "\n",
        "teacher_model.save_pretrained(\"./teacher_model\")\n",
        "print(\"Teacher model training completed and saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "6Ha1wnTnztxf",
        "outputId": "9109d092-ef13-4778-9807-57b8601e3450"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-4ce791a62616>:5: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_teacher = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='654' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [654/654 02:11, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.819600</td>\n",
              "      <td>0.863598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.817700</td>\n",
              "      <td>0.887446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.824100</td>\n",
              "      <td>0.823151</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher model training completed and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=16)"
      ],
      "metadata": {
        "id": "5Bb_PkvxxxNA"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(student_model.parameters(), lr=2e-5)"
      ],
      "metadata": {
        "id": "QySdiQHfxz21"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temperature = 3.0\n",
        "alpha = 0.7\n",
        "epochs = 3"
      ],
      "metadata": {
        "id": "z3x5EUSO0qJE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_model.eval()\n",
        "for epoch in range(epochs):\n",
        "    student_model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        inputs = {k: v.to(\"cuda\") for k, v in batch.items() if k in [\"input_ids\", \"attention_mask\"]}\n",
        "        labels = batch[\"labels\"].to(\"cuda\")\n",
        "\n",
        "        # Get teacher logits (soft labels)\n",
        "        with torch.no_grad():\n",
        "            teacher_logits = teacher_model(**inputs).logits\n",
        "\n",
        "        # Get student logits\n",
        "        student_outputs = student_model(**inputs)\n",
        "        student_logits = student_outputs.logits\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = distillation_loss(student_logits, teacher_logits, labels, temperature, alpha)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_dataloader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oq3QAGKoyGYD",
        "outputId": "f1eff1da-fe0a-4625-95fd-550ddf45b7c2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.20505645566987335\n",
            "Epoch 2/3, Loss: 0.12929951218426775\n",
            "Epoch 3/3, Loss: 0.10490229590838655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "val_metrics = evaluate_model(student_model, val_dataloader)\n",
        "print(f\"Validation Metrics with AdamW: {val_metrics}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yd_va3VKyLBH",
        "outputId": "24b0112c-512f-4394-fd80-22343fd1a08a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Metrics with AdamW: {'accuracy': 0.8402061855670103, 'precision': 0.8423849425605004, 'recall': 0.8402061855670103, 'f1': 0.8354557587007766}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "student_model.save_pretrained(\"/content/student_model\")\n",
        "print(\"Student model training completed and saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOyF4Su601SW",
        "outputId": "0f401d84-0e96-4a35-917d-1dfd9d0b9967"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student model training completed and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training with RMSProp"
      ],
      "metadata": {
        "id": "Dz1i-1s92c_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_model = AutoModelForSequenceClassification.from_pretrained(\"./teacher_model\").to(\"cuda\")\n",
        "teacher_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UyfQlOZ2lHD",
        "outputId": "79507aa1-2aba-4211-a3da-08dceb657c6d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=16)"
      ],
      "metadata": {
        "id": "DRzxVHkS3ZY9"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3).to(\"cuda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuZVbtun3Zv8",
        "outputId": "d296ff3e-0fe3-4f75-c3c1-8bb5481dca2d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import RMSprop\n",
        "\n",
        "lr = 2e-5\n",
        "weight_decay = 1e-2\n",
        "optimizer = RMSprop(student_model.parameters(), lr=lr, weight_decay=weight_decay)"
      ],
      "metadata": {
        "id": "kfEmI_KE3cgj"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 3\n",
        "temperature = 3.0\n",
        "alpha = 0.7"
      ],
      "metadata": {
        "id": "xS8LW6Zm3jSd"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    student_model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        inputs = {k: v.to(\"cuda\") for k, v in batch.items() if k in [\"input_ids\", \"attention_mask\"]}\n",
        "        labels = batch[\"labels\"].to(\"cuda\")\n",
        "\n",
        "        # Get teacher logits\n",
        "        with torch.no_grad():\n",
        "            teacher_logits = teacher_model(**inputs).logits\n",
        "\n",
        "        # Get student logits\n",
        "        student_outputs = student_model(**inputs)\n",
        "        student_logits = student_outputs.logits\n",
        "\n",
        "        # Calculate distillation loss\n",
        "        loss = distillation_loss(student_logits, teacher_logits, labels, temperature, alpha)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_dataloader)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqrsTtVp3sV7",
        "outputId": "b144abed-eca4-4071-e293-7d5287a7ba35"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.20615704227751547\n",
            "Epoch 2/3, Loss: 0.15681191127097935\n",
            "Epoch 3/3, Loss: 0.14590958153846068\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_metrics = evaluate_model(student_model, val_dataloader)\n",
        "print(f\"Validation Metrics with RMSProp: {val_metrics}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALRlla3j3vPy",
        "outputId": "0b6ba5af-bd82-4315-cb4f-8c5075822535"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Metrics with RMSProp: {'accuracy': 0.8170103092783505, 'precision': 0.8250155837928553, 'recall': 0.8170103092783505, 'f1': 0.8194498555951912}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "adam_metrics = {'accuracy': 0.8530927835051546, 'precision': 0.8584148108106562, 'recall': 0.8530927835051546, 'f1': 0.8474563176496248}\n",
        "adamw_metrics = {'accuracy': 0.8402061855670103, 'precision': 0.8423849425605004, 'recall': 0.8402061855670103, 'f1': 0.8354557587007766}\n",
        "rmsprop_metrics = {'accuracy': 0.8170103092783505, 'precision': 0.8250155837928553, 'recall': 0.8170103092783505, 'f1': 0.8194498555951912}\n",
        "\n",
        "labels = list(adam_metrics.keys())\n",
        "adam_values = list(adam_metrics.values())\n",
        "adamw_values = list(adamw_metrics.values())\n",
        "rmsprop_values = list(rmsprop_metrics.values())\n",
        "\n",
        "x = np.arange(len(labels))\n",
        "width = 0.25\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Adam\n",
        "plt.bar(x - width, adam_values, width, label='Adam', color='skyblue')\n",
        "\n",
        "# AdamW\n",
        "plt.bar(x, adamw_values, width, label='AdamW', color='orange')\n",
        "\n",
        "# RMSProp\n",
        "plt.bar(x + width, rmsprop_values, width, label='RMSProp', color='green')\n",
        "\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Values')\n",
        "plt.title('Comparison of Metrics for Adam, AdamW, and RMSProp')\n",
        "plt.xticks(x, labels)\n",
        "plt.ylim(0.8, 0.9)\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "VUyblb3s1yME",
        "outputId": "769826a8-61d1-48b3-ee6f-14f006d99452"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xnrLo1cl2Liq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cc796ed43f0943aa87252c0ee28b1b3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4caa9a6ac69442f9ab0450b139e95eb4",
              "IPY_MODEL_b6e2fd8d96634fb2a534dd6b15698a22",
              "IPY_MODEL_39f2c80e1ab64616b439f7471fb962e2"
            ],
            "layout": "IPY_MODEL_87c5899cbb49454d916dae5e538d6921"
          }
        },
        "4caa9a6ac69442f9ab0450b139e95eb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_821fe3969ecf4a8fa16fcf41f4b63245",
            "placeholder": "​",
            "style": "IPY_MODEL_7883f670814a4fc2ab8721f045a546d2",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "b6e2fd8d96634fb2a534dd6b15698a22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73a815c952694f95a4f24e87e976fe99",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d829106523a44d88f2e601b678afd57",
            "value": 48
          }
        },
        "39f2c80e1ab64616b439f7471fb962e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b047f99e112447293c61a5d18867c6e",
            "placeholder": "​",
            "style": "IPY_MODEL_39cb6c79f830421c9e06680d7201a622",
            "value": " 48.0/48.0 [00:00&lt;00:00, 3.59kB/s]"
          }
        },
        "87c5899cbb49454d916dae5e538d6921": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "821fe3969ecf4a8fa16fcf41f4b63245": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7883f670814a4fc2ab8721f045a546d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73a815c952694f95a4f24e87e976fe99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d829106523a44d88f2e601b678afd57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b047f99e112447293c61a5d18867c6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39cb6c79f830421c9e06680d7201a622": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d81f9632fad842c887e5ebce1392e53b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5a5293c7aaa49809d0cbccee172c90d",
              "IPY_MODEL_6ad9f4feedad413ca632291d1d895ad4",
              "IPY_MODEL_eca94c24ef4e47c488e2d44591afaece"
            ],
            "layout": "IPY_MODEL_e45987e26c0f4e19a619290cab11808d"
          }
        },
        "d5a5293c7aaa49809d0cbccee172c90d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_926d2ba251ef4bcb8f50152d9ee19c38",
            "placeholder": "​",
            "style": "IPY_MODEL_876eaa5fe2c647aa821dcb8062041949",
            "value": "config.json: 100%"
          }
        },
        "6ad9f4feedad413ca632291d1d895ad4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cd2fe7dc1634194ab987946ae653747",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d630aaa0c8b4ac9bff69fea11fd255d",
            "value": 570
          }
        },
        "eca94c24ef4e47c488e2d44591afaece": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f660affabaf84b459014f70e73a34b9b",
            "placeholder": "​",
            "style": "IPY_MODEL_3349b25fbfd4470b956bcb3212860bf6",
            "value": " 570/570 [00:00&lt;00:00, 35.7kB/s]"
          }
        },
        "e45987e26c0f4e19a619290cab11808d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "926d2ba251ef4bcb8f50152d9ee19c38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "876eaa5fe2c647aa821dcb8062041949": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7cd2fe7dc1634194ab987946ae653747": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d630aaa0c8b4ac9bff69fea11fd255d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f660affabaf84b459014f70e73a34b9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3349b25fbfd4470b956bcb3212860bf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbc9867e30d7467a892112c3c2c8e09d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b7dd3edd50534299a182a285d6013b4c",
              "IPY_MODEL_562fc31aeed049eb8340d025a576117a",
              "IPY_MODEL_5c3fe3a6bb2540a29ed1feb34349d2ae"
            ],
            "layout": "IPY_MODEL_4737cbd82ae04d74884f215ebdfb8ef9"
          }
        },
        "b7dd3edd50534299a182a285d6013b4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bff35083e0142f28078382a022497ac",
            "placeholder": "​",
            "style": "IPY_MODEL_fd9443e8355c4ae1ae01e028e971892c",
            "value": "vocab.txt: 100%"
          }
        },
        "562fc31aeed049eb8340d025a576117a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c434b8b0737f4c2ba5226716160ad782",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d4a79af63bd2468689126bbc6f6f6113",
            "value": 231508
          }
        },
        "5c3fe3a6bb2540a29ed1feb34349d2ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f50848b024fc4f1eb0ee542573f43087",
            "placeholder": "​",
            "style": "IPY_MODEL_29e5a64c98374e85a56b3377fd1d87bc",
            "value": " 232k/232k [00:00&lt;00:00, 7.70MB/s]"
          }
        },
        "4737cbd82ae04d74884f215ebdfb8ef9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bff35083e0142f28078382a022497ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd9443e8355c4ae1ae01e028e971892c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c434b8b0737f4c2ba5226716160ad782": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4a79af63bd2468689126bbc6f6f6113": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f50848b024fc4f1eb0ee542573f43087": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29e5a64c98374e85a56b3377fd1d87bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d79c869da18043c0b8c27085f5a29836": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_45c9c5010e694b519dc97c3d5b55204d",
              "IPY_MODEL_a70465acb10f404ab2bc9ba8900dfde8",
              "IPY_MODEL_7774a68a9968421aabf3e6d34fa0b768"
            ],
            "layout": "IPY_MODEL_f68c7b588b4a42688ff5f45474bfdf00"
          }
        },
        "45c9c5010e694b519dc97c3d5b55204d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9f8a9fd69a14fd4a639876e73482aa5",
            "placeholder": "​",
            "style": "IPY_MODEL_9a6139027be348fbba8b6f64274de1e2",
            "value": "tokenizer.json: 100%"
          }
        },
        "a70465acb10f404ab2bc9ba8900dfde8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e6cdad9b4724431b5f7d39790fd8cb9",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2353661821054aeba24849371f6985db",
            "value": 466062
          }
        },
        "7774a68a9968421aabf3e6d34fa0b768": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e309a6b4f66a4347bb4b59a9738562da",
            "placeholder": "​",
            "style": "IPY_MODEL_f99da6587a6d40acb9305185fb2b1ec0",
            "value": " 466k/466k [00:00&lt;00:00, 29.2MB/s]"
          }
        },
        "f68c7b588b4a42688ff5f45474bfdf00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9f8a9fd69a14fd4a639876e73482aa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a6139027be348fbba8b6f64274de1e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e6cdad9b4724431b5f7d39790fd8cb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2353661821054aeba24849371f6985db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e309a6b4f66a4347bb4b59a9738562da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f99da6587a6d40acb9305185fb2b1ec0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e153c3bd81314717a4c02e4a25fdfd60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89de1ef691a34a6c9f55f549770e82ef",
              "IPY_MODEL_28d1fad381bd4e9b9cc5b8a39f8ad255",
              "IPY_MODEL_e596e4c1a48f46f8a59442db31f8710c"
            ],
            "layout": "IPY_MODEL_4e099c39b232403080aca190a85959f6"
          }
        },
        "89de1ef691a34a6c9f55f549770e82ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b78131d92594522a303bf353040286f",
            "placeholder": "​",
            "style": "IPY_MODEL_f96dd57c31994d9fb6a40898413770ce",
            "value": "README.md: 100%"
          }
        },
        "28d1fad381bd4e9b9cc5b8a39f8ad255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15dca22ec4a349599849ee4fc12fe033",
            "max": 8878,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ac57e43c32b4dfebdf6b127d54d55c0",
            "value": 8878
          }
        },
        "e596e4c1a48f46f8a59442db31f8710c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f873926761b64924be7b31365092bd7f",
            "placeholder": "​",
            "style": "IPY_MODEL_8248227f066a41cc92b43ee29b07c5fd",
            "value": " 8.88k/8.88k [00:00&lt;00:00, 737kB/s]"
          }
        },
        "4e099c39b232403080aca190a85959f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b78131d92594522a303bf353040286f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f96dd57c31994d9fb6a40898413770ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15dca22ec4a349599849ee4fc12fe033": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ac57e43c32b4dfebdf6b127d54d55c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f873926761b64924be7b31365092bd7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8248227f066a41cc92b43ee29b07c5fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a99bd5d16594921b88726fabdee3047": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a28662be162f487e9e6175680b73c594",
              "IPY_MODEL_e6c92df1dcbe4e62add2b4f04ac13752",
              "IPY_MODEL_505e79841d764987baa5dd3ab00cb42a"
            ],
            "layout": "IPY_MODEL_a69528d258384126bd9c3cbec914fdf5"
          }
        },
        "a28662be162f487e9e6175680b73c594": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_274a9f52ca444217ad4379bdfdfb1a97",
            "placeholder": "​",
            "style": "IPY_MODEL_27fc02adf68c450fa172ebd2ee916740",
            "value": "financial_phrasebank.py: 100%"
          }
        },
        "e6c92df1dcbe4e62add2b4f04ac13752": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec564c5b86104bc79ff1fdfe99e03d2e",
            "max": 6036,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ecc9eb27efc4485fb9d84fa24769ed02",
            "value": 6036
          }
        },
        "505e79841d764987baa5dd3ab00cb42a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65f13d5a86d2477e9c5e9b3aa0b34e23",
            "placeholder": "​",
            "style": "IPY_MODEL_884c1ca35e164ba5a4e67fa8ebcda63b",
            "value": " 6.04k/6.04k [00:00&lt;00:00, 520kB/s]"
          }
        },
        "a69528d258384126bd9c3cbec914fdf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "274a9f52ca444217ad4379bdfdfb1a97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27fc02adf68c450fa172ebd2ee916740": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec564c5b86104bc79ff1fdfe99e03d2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecc9eb27efc4485fb9d84fa24769ed02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "65f13d5a86d2477e9c5e9b3aa0b34e23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "884c1ca35e164ba5a4e67fa8ebcda63b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62b3fbe25259427e9b674341dcdd80bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2b2f55792224161a6738eb145010acc",
              "IPY_MODEL_c552bebb00cc436f9d9278955d030293",
              "IPY_MODEL_a2a617f4fc7b44e3840a925beecda7a6"
            ],
            "layout": "IPY_MODEL_ad00167ee8594ab98799b1865b216cc9"
          }
        },
        "b2b2f55792224161a6738eb145010acc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_265d98f0242948329451992c679864b5",
            "placeholder": "​",
            "style": "IPY_MODEL_058b1b45489b4a85a45a6f319a8a7a84",
            "value": "FinancialPhraseBank-v1.0.zip: 100%"
          }
        },
        "c552bebb00cc436f9d9278955d030293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04ec2d2c4ac74de1acdb7431c80b44c4",
            "max": 681890,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_98c7049693644a73be336f38cd2f49d5",
            "value": 681890
          }
        },
        "a2a617f4fc7b44e3840a925beecda7a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee88361a171d4ae38677013b92e2c6a3",
            "placeholder": "​",
            "style": "IPY_MODEL_2f86dd6ad16d41ac817e9f4b0f70e3fe",
            "value": " 682k/682k [00:00&lt;00:00, 28.0MB/s]"
          }
        },
        "ad00167ee8594ab98799b1865b216cc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "265d98f0242948329451992c679864b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "058b1b45489b4a85a45a6f319a8a7a84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04ec2d2c4ac74de1acdb7431c80b44c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98c7049693644a73be336f38cd2f49d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee88361a171d4ae38677013b92e2c6a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f86dd6ad16d41ac817e9f4b0f70e3fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf962cd2832c4275ab9e70e26d8c3b84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1bca41cf53be44ad959c43396c3fef27",
              "IPY_MODEL_03cf4f590ed1429585c6c2f811d200d9",
              "IPY_MODEL_389725306482434d809a23e4213bc8f8"
            ],
            "layout": "IPY_MODEL_c27ebb7aaa1e4c228d19ca56ec2c19e4"
          }
        },
        "1bca41cf53be44ad959c43396c3fef27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1769cc70a8b54a57a1dccc0769ea3a44",
            "placeholder": "​",
            "style": "IPY_MODEL_58bb73b9b5dd4a6e87e3c3e34028ac9d",
            "value": "Generating train split: 100%"
          }
        },
        "03cf4f590ed1429585c6c2f811d200d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42232a169fd54cd5b5a7ef83314f30fd",
            "max": 4846,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_217983543e6b4f47a1096eeb931c14db",
            "value": 4846
          }
        },
        "389725306482434d809a23e4213bc8f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae60d05e58ff451aa827f3404deb994e",
            "placeholder": "​",
            "style": "IPY_MODEL_5dc51965848e4a95b41c46f81cdd9b05",
            "value": " 4846/4846 [00:00&lt;00:00, 30454.83 examples/s]"
          }
        },
        "c27ebb7aaa1e4c228d19ca56ec2c19e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1769cc70a8b54a57a1dccc0769ea3a44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58bb73b9b5dd4a6e87e3c3e34028ac9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42232a169fd54cd5b5a7ef83314f30fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "217983543e6b4f47a1096eeb931c14db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae60d05e58ff451aa827f3404deb994e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dc51965848e4a95b41c46f81cdd9b05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c63b143d48c04736bddec5d4692d183b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_af0a1e42cd2b468ab52ac1616e2884dc",
              "IPY_MODEL_b584dc8c36af40918c805f18550c4875",
              "IPY_MODEL_173dd2ddf3d54579b9022035911f22ca"
            ],
            "layout": "IPY_MODEL_0ec5234cb16f47fbb61d465f6611e765"
          }
        },
        "af0a1e42cd2b468ab52ac1616e2884dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ff323a4c3114eb694260f9cb4860cfb",
            "placeholder": "​",
            "style": "IPY_MODEL_331cd4c22798444488d66f7301ed4326",
            "value": "Map: 100%"
          }
        },
        "b584dc8c36af40918c805f18550c4875": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e2563da59fb42a6bbf0f8e564c7352c",
            "max": 3488,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a9378634621c4d41b857c3d655800e37",
            "value": 3488
          }
        },
        "173dd2ddf3d54579b9022035911f22ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fac7def1d71488cbad4ce368025ce3d",
            "placeholder": "​",
            "style": "IPY_MODEL_a99e1eec140b406dadbb1729c9ddeb38",
            "value": " 3488/3488 [00:00&lt;00:00, 10250.78 examples/s]"
          }
        },
        "0ec5234cb16f47fbb61d465f6611e765": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ff323a4c3114eb694260f9cb4860cfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "331cd4c22798444488d66f7301ed4326": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e2563da59fb42a6bbf0f8e564c7352c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9378634621c4d41b857c3d655800e37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8fac7def1d71488cbad4ce368025ce3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a99e1eec140b406dadbb1729c9ddeb38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d85b0cc11484bcda21566076a60fa29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_278b189d17a94d4c8716baef51231c87",
              "IPY_MODEL_f9236505fbe44772a54f09e513214078",
              "IPY_MODEL_32c5677db4dd40188a33758612ff0a8c"
            ],
            "layout": "IPY_MODEL_ced1bb07e627446e9d5252dd92a8663b"
          }
        },
        "278b189d17a94d4c8716baef51231c87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_575e915229e646b6a35b5d00264be8b3",
            "placeholder": "​",
            "style": "IPY_MODEL_fdbc28683ee6412db019ad2c5038dc81",
            "value": "Map: 100%"
          }
        },
        "f9236505fbe44772a54f09e513214078": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_310256286b164c9b9c1bfffd903c5b80",
            "max": 388,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a64840cdccd049af8369d207e763c509",
            "value": 388
          }
        },
        "32c5677db4dd40188a33758612ff0a8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e132e29eeb2944a6a4d42f741934c625",
            "placeholder": "​",
            "style": "IPY_MODEL_d99acc8c08154dc283fbb1870b54b932",
            "value": " 388/388 [00:00&lt;00:00, 7172.37 examples/s]"
          }
        },
        "ced1bb07e627446e9d5252dd92a8663b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "575e915229e646b6a35b5d00264be8b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdbc28683ee6412db019ad2c5038dc81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "310256286b164c9b9c1bfffd903c5b80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a64840cdccd049af8369d207e763c509": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e132e29eeb2944a6a4d42f741934c625": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d99acc8c08154dc283fbb1870b54b932": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01d53c5f9598484abcab0a7dd80ffb01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d6aaa788f8f418ba11df208451f523d",
              "IPY_MODEL_a246421c572b43888dd14eef599b1848",
              "IPY_MODEL_f9ec5142a0894d628f6b0f26956b135c"
            ],
            "layout": "IPY_MODEL_82aa938087b94aa8831197ed5da1d360"
          }
        },
        "8d6aaa788f8f418ba11df208451f523d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4880d7d55ee54702b1c506bc9536500b",
            "placeholder": "​",
            "style": "IPY_MODEL_bbdc303c78824e969cdf91e7ab84837c",
            "value": "Map: 100%"
          }
        },
        "a246421c572b43888dd14eef599b1848": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d88bcedeedd8498cb7dd20a8e20eda6d",
            "max": 970,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_679dbae97378472182c801bccc9457eb",
            "value": 970
          }
        },
        "f9ec5142a0894d628f6b0f26956b135c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52d8f1ccfa7e45b2b1e7ab8988de53d7",
            "placeholder": "​",
            "style": "IPY_MODEL_6550b6603f954c69900ed76f3943518f",
            "value": " 970/970 [00:00&lt;00:00, 9511.20 examples/s]"
          }
        },
        "82aa938087b94aa8831197ed5da1d360": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4880d7d55ee54702b1c506bc9536500b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbdc303c78824e969cdf91e7ab84837c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d88bcedeedd8498cb7dd20a8e20eda6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "679dbae97378472182c801bccc9457eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "52d8f1ccfa7e45b2b1e7ab8988de53d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6550b6603f954c69900ed76f3943518f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20f5d028c0474a0ba2e98e25860a1205": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb9272a925454d6c9036b0f3d4353377",
              "IPY_MODEL_b70ab834986b41038fba0ef72162ee7f",
              "IPY_MODEL_89e92096d1c14a7e94beaa1495f67fb1"
            ],
            "layout": "IPY_MODEL_2cd80a9c588a41c787485c9b50d1ee9b"
          }
        },
        "fb9272a925454d6c9036b0f3d4353377": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_999600f2818945baa68c0848207ba7bc",
            "placeholder": "​",
            "style": "IPY_MODEL_c9edfce94baa40c5860b3847b563973a",
            "value": "config.json: 100%"
          }
        },
        "b70ab834986b41038fba0ef72162ee7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49b290f52aeb44c686d9ccbbd82760c7",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4fb75c2b5e1645e28192942e7c79b221",
            "value": 481
          }
        },
        "89e92096d1c14a7e94beaa1495f67fb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a3bd7c145574917a529f93350b88ba5",
            "placeholder": "​",
            "style": "IPY_MODEL_f07b4f9816ba465d9831442b525f8b06",
            "value": " 481/481 [00:00&lt;00:00, 39.6kB/s]"
          }
        },
        "2cd80a9c588a41c787485c9b50d1ee9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "999600f2818945baa68c0848207ba7bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9edfce94baa40c5860b3847b563973a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49b290f52aeb44c686d9ccbbd82760c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fb75c2b5e1645e28192942e7c79b221": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a3bd7c145574917a529f93350b88ba5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f07b4f9816ba465d9831442b525f8b06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81b25174d3644dcfac081f38af483cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_45231c986ad54f8eac9e8228c37a9776",
              "IPY_MODEL_f80c54e62e534506ae549e8c19cc3701",
              "IPY_MODEL_acfb661688eb4efab919ac27e32f0169"
            ],
            "layout": "IPY_MODEL_80d130db141b4eb8984cec34bd77e8c5"
          }
        },
        "45231c986ad54f8eac9e8228c37a9776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b26eef2f5c647aab835415befde3a1f",
            "placeholder": "​",
            "style": "IPY_MODEL_040ba087a9604a8494d1cd16596ddfe0",
            "value": "model.safetensors: 100%"
          }
        },
        "f80c54e62e534506ae549e8c19cc3701": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc2dabcb3b2646c0b96a9ac1b173d172",
            "max": 498818054,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be182ae473034bf491987e53eac901ab",
            "value": 498818054
          }
        },
        "acfb661688eb4efab919ac27e32f0169": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05f16056c7f14e1abeae593038b0b47f",
            "placeholder": "​",
            "style": "IPY_MODEL_591d341703684ddd9e066399e4792631",
            "value": " 499M/499M [00:02&lt;00:00, 214MB/s]"
          }
        },
        "80d130db141b4eb8984cec34bd77e8c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b26eef2f5c647aab835415befde3a1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "040ba087a9604a8494d1cd16596ddfe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc2dabcb3b2646c0b96a9ac1b173d172": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be182ae473034bf491987e53eac901ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "05f16056c7f14e1abeae593038b0b47f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "591d341703684ddd9e066399e4792631": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "022576b7c25f4b5a84fea8074889484e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dde60a783f9041099d4fbf482e0e01fb",
              "IPY_MODEL_85ca7b3567bc48b88b0a532ed5515ed0",
              "IPY_MODEL_69a30cf114f946a48ed22ab4641fce2a"
            ],
            "layout": "IPY_MODEL_cc9fb406f44d4d2aa7f99ce38a786666"
          }
        },
        "dde60a783f9041099d4fbf482e0e01fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a7a8a907ad44651897541d18369e4ba",
            "placeholder": "​",
            "style": "IPY_MODEL_36ea293eb9f648deb45ef977f4cb7f4c",
            "value": "config.json: 100%"
          }
        },
        "85ca7b3567bc48b88b0a532ed5515ed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b16be197f1240c38ae8ed0d161b64b6",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_756edbc5bd7249c3af4886b37de8ad51",
            "value": 483
          }
        },
        "69a30cf114f946a48ed22ab4641fce2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d71dbc2a17e94cec9bf62ac655edd997",
            "placeholder": "​",
            "style": "IPY_MODEL_c30c05619ce8415fb9986e78fcda886c",
            "value": " 483/483 [00:00&lt;00:00, 41.5kB/s]"
          }
        },
        "cc9fb406f44d4d2aa7f99ce38a786666": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a7a8a907ad44651897541d18369e4ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36ea293eb9f648deb45ef977f4cb7f4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b16be197f1240c38ae8ed0d161b64b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "756edbc5bd7249c3af4886b37de8ad51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d71dbc2a17e94cec9bf62ac655edd997": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c30c05619ce8415fb9986e78fcda886c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "234bb7d87c0c4b73bf404a6a6dfa4765": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ea25629432643dca574a27c2df44a90",
              "IPY_MODEL_b8233f50a2af422aae48fae3c3690694",
              "IPY_MODEL_9be476d492f74863b04b80f8ea5e0116"
            ],
            "layout": "IPY_MODEL_5e510af2a5364f7e80c9e871ab594123"
          }
        },
        "8ea25629432643dca574a27c2df44a90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fb6133eafa74502a37fd94cbb680791",
            "placeholder": "​",
            "style": "IPY_MODEL_f55e1c1e69d64f72bb26de4c5bb882cf",
            "value": "model.safetensors: 100%"
          }
        },
        "b8233f50a2af422aae48fae3c3690694": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17867e8ec4f444fab52efd318a8c6c7c",
            "max": 267954768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f96e9c42190345cb92fbea40570c3c60",
            "value": 267954768
          }
        },
        "9be476d492f74863b04b80f8ea5e0116": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_788eaa03a52348c1af36d3c4b93e2b97",
            "placeholder": "​",
            "style": "IPY_MODEL_9ef9949f227a444d8898d500e8c063fd",
            "value": " 268M/268M [00:01&lt;00:00, 213MB/s]"
          }
        },
        "5e510af2a5364f7e80c9e871ab594123": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fb6133eafa74502a37fd94cbb680791": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f55e1c1e69d64f72bb26de4c5bb882cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17867e8ec4f444fab52efd318a8c6c7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f96e9c42190345cb92fbea40570c3c60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "788eaa03a52348c1af36d3c4b93e2b97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ef9949f227a444d8898d500e8c063fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "294c99943cab4105bc8a5ade3389d09c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66a116dee8d44d178eb4358d6f9333cf",
              "IPY_MODEL_103662d5926849e9928d41f69229c04d",
              "IPY_MODEL_99ebd88c07264ffead77a8f50e61146d"
            ],
            "layout": "IPY_MODEL_865ef4d76507474eb339acda1e55b887"
          }
        },
        "66a116dee8d44d178eb4358d6f9333cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64b889fd48c5413e95a310c3512f57e2",
            "placeholder": "​",
            "style": "IPY_MODEL_baee1b71d81a4e99b392a21b25d2fef9",
            "value": "Map: 100%"
          }
        },
        "103662d5926849e9928d41f69229c04d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d985874c44ad4ab49a2ab1f129bd1ed9",
            "max": 3488,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f5d7921c43949b88acd7f3c825baf24",
            "value": 3488
          }
        },
        "99ebd88c07264ffead77a8f50e61146d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abf15fdde69041929a3a7a87f985717e",
            "placeholder": "​",
            "style": "IPY_MODEL_423065e3030348a88d7915722956fa58",
            "value": " 3488/3488 [00:00&lt;00:00, 5104.49 examples/s]"
          }
        },
        "865ef4d76507474eb339acda1e55b887": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64b889fd48c5413e95a310c3512f57e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baee1b71d81a4e99b392a21b25d2fef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d985874c44ad4ab49a2ab1f129bd1ed9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f5d7921c43949b88acd7f3c825baf24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "abf15fdde69041929a3a7a87f985717e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "423065e3030348a88d7915722956fa58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b38bb367b5e431d8a6940eca9c6acc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d4ca7b2650f456aa0ffadbc9ad003dc",
              "IPY_MODEL_6b5f145a4e8044b883d49d160b870a3b",
              "IPY_MODEL_e7a70e69173d4e59b295686b118792b7"
            ],
            "layout": "IPY_MODEL_95c9323911954e5e991ccd8100776b67"
          }
        },
        "0d4ca7b2650f456aa0ffadbc9ad003dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ad55f7095af4aa8883b4dac12ebbf5a",
            "placeholder": "​",
            "style": "IPY_MODEL_59ae9eeb9b6049669c4c1283d2685587",
            "value": "Map: 100%"
          }
        },
        "6b5f145a4e8044b883d49d160b870a3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ea8b9abeeb841519a902e9340be8204",
            "max": 388,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61a55d4bfdf8478fa6231ceb4b8a0a9f",
            "value": 388
          }
        },
        "e7a70e69173d4e59b295686b118792b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b020010c15c1497e8efa22228f664462",
            "placeholder": "​",
            "style": "IPY_MODEL_a2e8b0cb0b794f0fa287a43cc9499693",
            "value": " 388/388 [00:00&lt;00:00, 7519.21 examples/s]"
          }
        },
        "95c9323911954e5e991ccd8100776b67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ad55f7095af4aa8883b4dac12ebbf5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59ae9eeb9b6049669c4c1283d2685587": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ea8b9abeeb841519a902e9340be8204": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61a55d4bfdf8478fa6231ceb4b8a0a9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b020010c15c1497e8efa22228f664462": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2e8b0cb0b794f0fa287a43cc9499693": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d57268467ef84fa29faecf1e0c5d0bc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c803c231c9ae42879e8c38f1e10f1e02",
              "IPY_MODEL_d47e28a16f4f4934b5043d2da49cd131",
              "IPY_MODEL_47eb3a97ceee4dcdb30c90f9b36e2b93"
            ],
            "layout": "IPY_MODEL_25c78e76003f4ea0909117ed4328f7fb"
          }
        },
        "c803c231c9ae42879e8c38f1e10f1e02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdff912ba66d496db14eabbb454839d0",
            "placeholder": "​",
            "style": "IPY_MODEL_c323c880909b4db1bd748634f0be8b4e",
            "value": "Map: 100%"
          }
        },
        "d47e28a16f4f4934b5043d2da49cd131": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a5d0d786b4545b1995c367f36d5c556",
            "max": 970,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed967468b2314992ab6da4383e9d4e5a",
            "value": 970
          }
        },
        "47eb3a97ceee4dcdb30c90f9b36e2b93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec36fb810f2045f7b2d1ded34b00b33b",
            "placeholder": "​",
            "style": "IPY_MODEL_9f222d2ae8ea42728e20c41b73f04fe2",
            "value": " 970/970 [00:00&lt;00:00, 9750.97 examples/s]"
          }
        },
        "25c78e76003f4ea0909117ed4328f7fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdff912ba66d496db14eabbb454839d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c323c880909b4db1bd748634f0be8b4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a5d0d786b4545b1995c367f36d5c556": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed967468b2314992ab6da4383e9d4e5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec36fb810f2045f7b2d1ded34b00b33b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f222d2ae8ea42728e20c41b73f04fe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ea94f93be2c47c3b327efeac6d63f46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d251ef5062a04bb7be5bd692eec06537",
              "IPY_MODEL_a50add41e3ba46c28422c841d84bc17f",
              "IPY_MODEL_ae391878469d4cbca62735a3c9e3593a"
            ],
            "layout": "IPY_MODEL_847a54bfba374d378db4f1433735b33a"
          }
        },
        "d251ef5062a04bb7be5bd692eec06537": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5493798603a84237ac575217159ee510",
            "placeholder": "​",
            "style": "IPY_MODEL_dce04ac9f4ef4d4fbbea6626de54d595",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "a50add41e3ba46c28422c841d84bc17f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a620dc94421942c181ba2787e9b2116f",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_045ad72477f94e818248f2213a0b9af0",
            "value": 48
          }
        },
        "ae391878469d4cbca62735a3c9e3593a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ffaf54a38c745f5b458d84faf0a7d19",
            "placeholder": "​",
            "style": "IPY_MODEL_3265b21e3ee24d3c8f3bb72722457805",
            "value": " 48.0/48.0 [00:00&lt;00:00, 2.84kB/s]"
          }
        },
        "847a54bfba374d378db4f1433735b33a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5493798603a84237ac575217159ee510": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dce04ac9f4ef4d4fbbea6626de54d595": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a620dc94421942c181ba2787e9b2116f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "045ad72477f94e818248f2213a0b9af0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ffaf54a38c745f5b458d84faf0a7d19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3265b21e3ee24d3c8f3bb72722457805": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0cf46776d9fa45fd90eab28abed5dba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_71adfc022bad4e518159bb16dc7f37a9",
              "IPY_MODEL_6d5718ce15294efe9ac0f8202712fc67",
              "IPY_MODEL_697467891e3c42d8b9f5a8b344d087c7"
            ],
            "layout": "IPY_MODEL_f65fa75d374c444fa711f80a60781d74"
          }
        },
        "71adfc022bad4e518159bb16dc7f37a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c9dd3edc0204093b93865e1c953403d",
            "placeholder": "​",
            "style": "IPY_MODEL_76a9bff016264784b57adf0ef30645d3",
            "value": "config.json: 100%"
          }
        },
        "6d5718ce15294efe9ac0f8202712fc67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_321b024a316a4704b766a5c32d68c331",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8210acd437c4ceaae1b0955991e462e",
            "value": 570
          }
        },
        "697467891e3c42d8b9f5a8b344d087c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f4ec26e966841a68dcfd89872b8cc14",
            "placeholder": "​",
            "style": "IPY_MODEL_9eb380d1a6d349679723d30f27624423",
            "value": " 570/570 [00:00&lt;00:00, 38.3kB/s]"
          }
        },
        "f65fa75d374c444fa711f80a60781d74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c9dd3edc0204093b93865e1c953403d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76a9bff016264784b57adf0ef30645d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "321b024a316a4704b766a5c32d68c331": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8210acd437c4ceaae1b0955991e462e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f4ec26e966841a68dcfd89872b8cc14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9eb380d1a6d349679723d30f27624423": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35e79b41cf0b40a881c1d57be34187db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d54c19c940a04f4eaeeda807e666ddf8",
              "IPY_MODEL_33f9af79073f44259c6047009f38dad9",
              "IPY_MODEL_b32a4e3f46c040fda479fe8529f7cdb7"
            ],
            "layout": "IPY_MODEL_4631fa655457411eb7a0079d4e11b8a8"
          }
        },
        "d54c19c940a04f4eaeeda807e666ddf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c606831e2302431bac132233c793384d",
            "placeholder": "​",
            "style": "IPY_MODEL_24ac7df9555a43ceb7f6260beab0e53e",
            "value": "vocab.txt: 100%"
          }
        },
        "33f9af79073f44259c6047009f38dad9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b01a7222d9944c2b96a6259bb212323a",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe7fa85e337143829833404cd8ea7f3d",
            "value": 231508
          }
        },
        "b32a4e3f46c040fda479fe8529f7cdb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69f82d11fa2e42ceb68769b70c261b23",
            "placeholder": "​",
            "style": "IPY_MODEL_d852ad7b01364d418ae320eb4cf665b1",
            "value": " 232k/232k [00:00&lt;00:00, 1.09MB/s]"
          }
        },
        "4631fa655457411eb7a0079d4e11b8a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c606831e2302431bac132233c793384d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24ac7df9555a43ceb7f6260beab0e53e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b01a7222d9944c2b96a6259bb212323a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe7fa85e337143829833404cd8ea7f3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "69f82d11fa2e42ceb68769b70c261b23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d852ad7b01364d418ae320eb4cf665b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ce2455d893c47ae9d6f9554875395b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eebdced070f24a6da579ba5b68f8e1cc",
              "IPY_MODEL_c221ae700bc24f17864790cd7ae65ca7",
              "IPY_MODEL_e0d264c0dd634a50b34e07d5d07656cc"
            ],
            "layout": "IPY_MODEL_93d3a53f1b1c425189357b10471ce9b5"
          }
        },
        "eebdced070f24a6da579ba5b68f8e1cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2a367f85f424a91a2e5439d5b5f30fb",
            "placeholder": "​",
            "style": "IPY_MODEL_f6483b02c1ef40e0be4d293255fda36c",
            "value": "tokenizer.json: 100%"
          }
        },
        "c221ae700bc24f17864790cd7ae65ca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b29616046914588b60e5ef2261cc57c",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5ff000441834eb7b8f93ad5ad20c053",
            "value": 466062
          }
        },
        "e0d264c0dd634a50b34e07d5d07656cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4562b6000e5043cc9bd73d17dea84bfb",
            "placeholder": "​",
            "style": "IPY_MODEL_f07f664ba51d454788761647e7e74dc2",
            "value": " 466k/466k [00:00&lt;00:00, 1.08MB/s]"
          }
        },
        "93d3a53f1b1c425189357b10471ce9b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2a367f85f424a91a2e5439d5b5f30fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6483b02c1ef40e0be4d293255fda36c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b29616046914588b60e5ef2261cc57c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5ff000441834eb7b8f93ad5ad20c053": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4562b6000e5043cc9bd73d17dea84bfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f07f664ba51d454788761647e7e74dc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d870f134ac244d29cc41ca0174a4151": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6478ff659674af7b09dc6f11aee55fa",
              "IPY_MODEL_fd6d62285dcd4412b00904ac833547ef",
              "IPY_MODEL_82b5ea39072a4650a3bf3f3789f78804"
            ],
            "layout": "IPY_MODEL_50575a756d3349748630a52089d471ed"
          }
        },
        "c6478ff659674af7b09dc6f11aee55fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9446adb28394b979e56dc5a670ad1c5",
            "placeholder": "​",
            "style": "IPY_MODEL_9d829383f23f4418afecdbef6274defc",
            "value": "README.md: 100%"
          }
        },
        "fd6d62285dcd4412b00904ac833547ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cef517f1cae74f5d886ac7a732c8df11",
            "max": 8878,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2b4c65e7a63481a9ae7cca6cb29f5da",
            "value": 8878
          }
        },
        "82b5ea39072a4650a3bf3f3789f78804": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a6bffeda969445a9d83b8fe5d316814",
            "placeholder": "​",
            "style": "IPY_MODEL_d48161278bc1401da52510783636fca4",
            "value": " 8.88k/8.88k [00:00&lt;00:00, 700kB/s]"
          }
        },
        "50575a756d3349748630a52089d471ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9446adb28394b979e56dc5a670ad1c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d829383f23f4418afecdbef6274defc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cef517f1cae74f5d886ac7a732c8df11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2b4c65e7a63481a9ae7cca6cb29f5da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a6bffeda969445a9d83b8fe5d316814": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d48161278bc1401da52510783636fca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef7650a97873452f91d39890435a98ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c66e2d9eaf814eeba86570f63c7af27c",
              "IPY_MODEL_7088b7797d5a4a89b064260d168b6613",
              "IPY_MODEL_8cbfd630ab7a45d2b6b022ac11809cde"
            ],
            "layout": "IPY_MODEL_7af6e332f6bc4c6ea77650da1e7b1e64"
          }
        },
        "c66e2d9eaf814eeba86570f63c7af27c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_182ac60eac024a98975ccec3a757c881",
            "placeholder": "​",
            "style": "IPY_MODEL_e41ea1032ad441439ba408988a28b1c1",
            "value": "financial_phrasebank.py: 100%"
          }
        },
        "7088b7797d5a4a89b064260d168b6613": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28a58a777917448c8fffbea11f3cce13",
            "max": 6036,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b746737162d4667979f59078922c133",
            "value": 6036
          }
        },
        "8cbfd630ab7a45d2b6b022ac11809cde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38eca8f68883437aac3709eb102b2985",
            "placeholder": "​",
            "style": "IPY_MODEL_7c478921dd8648929223f3114a4148a4",
            "value": " 6.04k/6.04k [00:00&lt;00:00, 531kB/s]"
          }
        },
        "7af6e332f6bc4c6ea77650da1e7b1e64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "182ac60eac024a98975ccec3a757c881": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e41ea1032ad441439ba408988a28b1c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28a58a777917448c8fffbea11f3cce13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b746737162d4667979f59078922c133": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "38eca8f68883437aac3709eb102b2985": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c478921dd8648929223f3114a4148a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1cdc185ddb7a465da56816ae45f1cf7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c53be57a31004ecb9a85844f6d830e7d",
              "IPY_MODEL_18962701146e48969d85fb2e527d9e3b",
              "IPY_MODEL_79441464bf644c9587859709ba7b0e4c"
            ],
            "layout": "IPY_MODEL_441bf149b2d441ce8f29b1f0c326a260"
          }
        },
        "c53be57a31004ecb9a85844f6d830e7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00b4010ef7454da897ac9817ef82995d",
            "placeholder": "​",
            "style": "IPY_MODEL_a7d03e3ea02447c89f317eca0bf95410",
            "value": "FinancialPhraseBank-v1.0.zip: 100%"
          }
        },
        "18962701146e48969d85fb2e527d9e3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c42e9c3b17d34b638051819e1be9d1f6",
            "max": 681890,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0dfc9209147a4a73a25d7e631a164670",
            "value": 681890
          }
        },
        "79441464bf644c9587859709ba7b0e4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf9ebf70c7e8481a9905cec9e9b96cbd",
            "placeholder": "​",
            "style": "IPY_MODEL_b03884a9939c4216a298b4667e842362",
            "value": " 682k/682k [00:00&lt;00:00, 19.1MB/s]"
          }
        },
        "441bf149b2d441ce8f29b1f0c326a260": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00b4010ef7454da897ac9817ef82995d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7d03e3ea02447c89f317eca0bf95410": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c42e9c3b17d34b638051819e1be9d1f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dfc9209147a4a73a25d7e631a164670": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf9ebf70c7e8481a9905cec9e9b96cbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b03884a9939c4216a298b4667e842362": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9cbb25d7b591417ea41587c8e5abcf6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8054768334544ae88bedab1fd845f81",
              "IPY_MODEL_208912e528784fc290069c8825f63689",
              "IPY_MODEL_be6f733b4b454462a94a16721b23375c"
            ],
            "layout": "IPY_MODEL_2799434cdeca4deea94ba55d90cb0c02"
          }
        },
        "a8054768334544ae88bedab1fd845f81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d0e7e567c69492db343e871f79e209e",
            "placeholder": "​",
            "style": "IPY_MODEL_8c05cffe4b71446c9f5da76cbe26e9c0",
            "value": "Generating train split: 100%"
          }
        },
        "208912e528784fc290069c8825f63689": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb3337a6fb6d4faaa27086cff730f25a",
            "max": 4846,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f388c6f42b974a17b3b71d62640bc07c",
            "value": 4846
          }
        },
        "be6f733b4b454462a94a16721b23375c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2aa7c80e422f4b0489f8182c1e8fb174",
            "placeholder": "​",
            "style": "IPY_MODEL_940b5c639e0340b1a22f8f2c415c6521",
            "value": " 4846/4846 [00:00&lt;00:00, 31264.43 examples/s]"
          }
        },
        "2799434cdeca4deea94ba55d90cb0c02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d0e7e567c69492db343e871f79e209e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c05cffe4b71446c9f5da76cbe26e9c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb3337a6fb6d4faaa27086cff730f25a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f388c6f42b974a17b3b71d62640bc07c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2aa7c80e422f4b0489f8182c1e8fb174": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "940b5c639e0340b1a22f8f2c415c6521": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8303c0f9983a4dc8824b13c5fd848a47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb9e2147edba4440b317ae5ef367633e",
              "IPY_MODEL_e1a71e2ebfb84795a312ce69ec7952c1",
              "IPY_MODEL_f6995bf8da5143a9b910e8e7ab5802d1"
            ],
            "layout": "IPY_MODEL_d76087cf48c84132a217d6b9c49f81f4"
          }
        },
        "bb9e2147edba4440b317ae5ef367633e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a033f75cb1f4c3ca68e4b42f81e7e46",
            "placeholder": "​",
            "style": "IPY_MODEL_96e71d0f93a84271a70d9d1fbefb93dd",
            "value": "Map: 100%"
          }
        },
        "e1a71e2ebfb84795a312ce69ec7952c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c09e80640b764822aa2c7619b5b51ff5",
            "max": 3488,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0cfb6b4b7de64b69a057de732f570da0",
            "value": 3488
          }
        },
        "f6995bf8da5143a9b910e8e7ab5802d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_802962e0bb9c45eaa01ab45ca8a44e4b",
            "placeholder": "​",
            "style": "IPY_MODEL_129b3bff1fe4476c8cd1c60658eb5db2",
            "value": " 3488/3488 [00:00&lt;00:00, 10381.64 examples/s]"
          }
        },
        "d76087cf48c84132a217d6b9c49f81f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a033f75cb1f4c3ca68e4b42f81e7e46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96e71d0f93a84271a70d9d1fbefb93dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c09e80640b764822aa2c7619b5b51ff5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cfb6b4b7de64b69a057de732f570da0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "802962e0bb9c45eaa01ab45ca8a44e4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "129b3bff1fe4476c8cd1c60658eb5db2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54d90c60be5b444090640bb64f92e1b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_918ff5ed1e154bd0a1dfae717202cb1f",
              "IPY_MODEL_a44dd9186dc64df5bc5c733e768de16e",
              "IPY_MODEL_14d34f9037cf4752af7a4d15e58dc3e2"
            ],
            "layout": "IPY_MODEL_7e64d77b302147d189f7734444b8f528"
          }
        },
        "918ff5ed1e154bd0a1dfae717202cb1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7973da519d244ebe8b454db0e83cc782",
            "placeholder": "​",
            "style": "IPY_MODEL_7035433411134808add473ceaf3e9042",
            "value": "Map: 100%"
          }
        },
        "a44dd9186dc64df5bc5c733e768de16e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2e7113e410a44769be9fa3525acbb6f",
            "max": 388,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc15d8e664a0466ebb999a041363799c",
            "value": 388
          }
        },
        "14d34f9037cf4752af7a4d15e58dc3e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b056c63972b4147b6970d532a118ee4",
            "placeholder": "​",
            "style": "IPY_MODEL_0fe4340bab814c59ba546bfd88629b78",
            "value": " 388/388 [00:00&lt;00:00, 7321.09 examples/s]"
          }
        },
        "7e64d77b302147d189f7734444b8f528": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7973da519d244ebe8b454db0e83cc782": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7035433411134808add473ceaf3e9042": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2e7113e410a44769be9fa3525acbb6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc15d8e664a0466ebb999a041363799c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b056c63972b4147b6970d532a118ee4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fe4340bab814c59ba546bfd88629b78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30fc8368fe114f3d926b8b678ea83134": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4a79859b5d1463593af1be3136ea600",
              "IPY_MODEL_292e5d84fbc743de974a7e23b69c1924",
              "IPY_MODEL_c25718c6a56643e1a68974e739b86d79"
            ],
            "layout": "IPY_MODEL_dc91cf645ad745b68bfc0ec20f1eaf34"
          }
        },
        "f4a79859b5d1463593af1be3136ea600": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01e415e354084d8a911f83fcee186fbb",
            "placeholder": "​",
            "style": "IPY_MODEL_2c1c4c0699a24bfe8b772f7102714d98",
            "value": "Map: 100%"
          }
        },
        "292e5d84fbc743de974a7e23b69c1924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_375d1ed18766409f8c5d6068b009fac8",
            "max": 970,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4967fdc80dcf437494fa0398475c8c75",
            "value": 970
          }
        },
        "c25718c6a56643e1a68974e739b86d79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a92578d806174717b1c6c72751ff70a3",
            "placeholder": "​",
            "style": "IPY_MODEL_b6ffced1184c4ac9bc6fbff42fe764b0",
            "value": " 970/970 [00:00&lt;00:00, 9729.89 examples/s]"
          }
        },
        "dc91cf645ad745b68bfc0ec20f1eaf34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01e415e354084d8a911f83fcee186fbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c1c4c0699a24bfe8b772f7102714d98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "375d1ed18766409f8c5d6068b009fac8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4967fdc80dcf437494fa0398475c8c75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a92578d806174717b1c6c72751ff70a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6ffced1184c4ac9bc6fbff42fe764b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60d3a594358b466db95388d2f4a8dff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1aee4f3317414e299f7fa16840084eb0",
              "IPY_MODEL_ff52808c6f604e24ae3bf22b4a0ac1a1",
              "IPY_MODEL_a2dfccc8aed7479a8e1528604c6a3928"
            ],
            "layout": "IPY_MODEL_8d653f5fe9694dad8d944183c85ed049"
          }
        },
        "1aee4f3317414e299f7fa16840084eb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db89d8754d784f70a2d8b07032c78059",
            "placeholder": "​",
            "style": "IPY_MODEL_da2eec3efa734ce0963894f12ac19cd3",
            "value": "config.json: 100%"
          }
        },
        "ff52808c6f604e24ae3bf22b4a0ac1a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_649dfb9e88a245a78f69389504d02aa9",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af40086a735b4c92b28e189217ae0924",
            "value": 481
          }
        },
        "a2dfccc8aed7479a8e1528604c6a3928": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf4fae3e0b7f4f368cdf4fa73018b3f5",
            "placeholder": "​",
            "style": "IPY_MODEL_3f3908468d6945c28baf0b3f9513bb83",
            "value": " 481/481 [00:00&lt;00:00, 40.9kB/s]"
          }
        },
        "8d653f5fe9694dad8d944183c85ed049": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db89d8754d784f70a2d8b07032c78059": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da2eec3efa734ce0963894f12ac19cd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "649dfb9e88a245a78f69389504d02aa9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af40086a735b4c92b28e189217ae0924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf4fae3e0b7f4f368cdf4fa73018b3f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f3908468d6945c28baf0b3f9513bb83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8fd87db63084027bb9e9400cb054f2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9bc1b1167b64a7e98950f5b3a58858b",
              "IPY_MODEL_668cb65bce494fb2978fda9944f9b0c5",
              "IPY_MODEL_9f100e4e254f4cc4ac263276e25e5039"
            ],
            "layout": "IPY_MODEL_1c8000d24b5f411dad234c9939cd853f"
          }
        },
        "f9bc1b1167b64a7e98950f5b3a58858b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62627d28a87b4ae8a54363c7f218d993",
            "placeholder": "​",
            "style": "IPY_MODEL_41d2b118411d4e388f5742ccfb6c5d37",
            "value": "model.safetensors: 100%"
          }
        },
        "668cb65bce494fb2978fda9944f9b0c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60b68694694b431c9a3b33419b24a51a",
            "max": 498818054,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51402aefc5ae44f0aaff296522588b3a",
            "value": 498818054
          }
        },
        "9f100e4e254f4cc4ac263276e25e5039": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2fcf238f2a34603935f5f59c86c8de6",
            "placeholder": "​",
            "style": "IPY_MODEL_5a481181d95b4267b108ec097c08665a",
            "value": " 499M/499M [00:02&lt;00:00, 236MB/s]"
          }
        },
        "1c8000d24b5f411dad234c9939cd853f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62627d28a87b4ae8a54363c7f218d993": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41d2b118411d4e388f5742ccfb6c5d37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60b68694694b431c9a3b33419b24a51a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51402aefc5ae44f0aaff296522588b3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2fcf238f2a34603935f5f59c86c8de6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a481181d95b4267b108ec097c08665a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af32c1ca1a9b4ea49cce948190b289db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_01afd12bd01f48acaa83232755262378",
              "IPY_MODEL_30c63fd1711148c9ac1ba71ffcd0a31b",
              "IPY_MODEL_fe779f86209c46d897e957963d427fb8"
            ],
            "layout": "IPY_MODEL_5364f8537d184223898d702633d7366a"
          }
        },
        "01afd12bd01f48acaa83232755262378": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_217c64f050c7420da78849e65dc9adab",
            "placeholder": "​",
            "style": "IPY_MODEL_c8b2668160b34bd5a1f3e39475749d69",
            "value": "config.json: 100%"
          }
        },
        "30c63fd1711148c9ac1ba71ffcd0a31b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf563f4cb3b843039a647111fa384aa7",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab1f469244724fddb4a3e50374647f88",
            "value": 483
          }
        },
        "fe779f86209c46d897e957963d427fb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09c1c7241a434aadace4c74ba51d522f",
            "placeholder": "​",
            "style": "IPY_MODEL_bc859d3841ea48d98663dc2fae197317",
            "value": " 483/483 [00:00&lt;00:00, 45.5kB/s]"
          }
        },
        "5364f8537d184223898d702633d7366a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "217c64f050c7420da78849e65dc9adab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8b2668160b34bd5a1f3e39475749d69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf563f4cb3b843039a647111fa384aa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab1f469244724fddb4a3e50374647f88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09c1c7241a434aadace4c74ba51d522f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc859d3841ea48d98663dc2fae197317": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6621c65327df4f43a61d5342d9b9b5f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75c977beee554d2cbec5ef2feb911ed7",
              "IPY_MODEL_85b848c3139b43ca87a07fac9f6c970c",
              "IPY_MODEL_43a3731694d84095b4c9080ef65a80ef"
            ],
            "layout": "IPY_MODEL_041c5c476e4f40578e4d7bb2b03b46c1"
          }
        },
        "75c977beee554d2cbec5ef2feb911ed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec7b5bf2fb0041a4ab2ac03ac9417cf8",
            "placeholder": "​",
            "style": "IPY_MODEL_c77d14a9d6b64389834039a2e9315bb7",
            "value": "model.safetensors: 100%"
          }
        },
        "85b848c3139b43ca87a07fac9f6c970c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f212c7f48083499b8538629a10329b28",
            "max": 267954768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4fcad4750734436b99bfc4aed4ce63d2",
            "value": 267954768
          }
        },
        "43a3731694d84095b4c9080ef65a80ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c21ffed75e66498a80422599bceefa2c",
            "placeholder": "​",
            "style": "IPY_MODEL_d0ca6d3cf8ce437f88db40c144cf98af",
            "value": " 268M/268M [00:01&lt;00:00, 239MB/s]"
          }
        },
        "041c5c476e4f40578e4d7bb2b03b46c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec7b5bf2fb0041a4ab2ac03ac9417cf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c77d14a9d6b64389834039a2e9315bb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f212c7f48083499b8538629a10329b28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fcad4750734436b99bfc4aed4ce63d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c21ffed75e66498a80422599bceefa2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0ca6d3cf8ce437f88db40c144cf98af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}