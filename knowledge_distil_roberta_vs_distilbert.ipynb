{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emrekuruu/Fine-Tune/blob/main/knowledge_distil_roberta_vs_distilbert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUox-IuVRGDD",
        "outputId": "ade86fc9-a6d2-4515-b5f4-658609283c90"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets peft"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TYL77usRinq",
        "outputId": "3cd19868-db89-4244-a137-7b0e4dbb932d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.5.1+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (1.2.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8TcVpvVRoGI",
        "outputId": "39d18927-f3b2-4f3f-f386-3f2dee135017"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CRQ27Dl_NxLv"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mMvfUb5wNxLw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datasets import load_dataset, Dataset\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3upgzzwdNxLx"
      },
      "outputs": [],
      "source": [
        "def prepare_datasets(tokenizer, dataset_name=\"financial_phrasebank\", subset_name=\"sentences_50agree\", max_length=128, random_state=42):\n",
        "    dataset = load_dataset(dataset_name, subset_name, trust_remote_code=True)\n",
        "\n",
        "    df = pd.DataFrame(dataset['train'])\n",
        "\n",
        "    # Stratify split into train, validation, and test\n",
        "    train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "        df['sentence'], df['label'], test_size=0.2, stratify=df['label'], random_state=random_state\n",
        "    )\n",
        "    train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "        train_texts, train_labels, test_size=0.1, stratify=train_labels, random_state=random_state\n",
        "    )\n",
        "\n",
        "    # Create DataFrames for each split\n",
        "    train_df = pd.DataFrame({'sentence': train_texts, 'label': train_labels})\n",
        "    val_df = pd.DataFrame({'sentence': val_texts, 'label': val_labels})\n",
        "    test_df = pd.DataFrame({'sentence': test_texts, 'label': test_labels})\n",
        "\n",
        "    # Convert DataFrames to Hugging Face Dataset format\n",
        "    train_dataset = Dataset.from_pandas(train_df)\n",
        "    val_dataset = Dataset.from_pandas(val_df)\n",
        "    test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "    # Define tokenization function\n",
        "    def tokenize_function(example):\n",
        "        return tokenizer(\n",
        "            example[\"sentence\"],\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=max_length\n",
        "        )\n",
        "     # Tokenize datasets\n",
        "    train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "    val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
        "    test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "    # Remove raw text and prepare for Hugging Face Trainer\n",
        "    train_dataset = train_dataset.remove_columns([\"sentence\"])\n",
        "    val_dataset = val_dataset.remove_columns([\"sentence\"])\n",
        "    test_dataset = test_dataset.remove_columns([\"sentence\"])\n",
        "\n",
        "    train_dataset = train_dataset.rename_column(\"label\", \"labels\")\n",
        "    val_dataset = val_dataset.rename_column(\"label\", \"labels\")\n",
        "    test_dataset = test_dataset.rename_column(\"label\", \"labels\")\n",
        "\n",
        "    train_dataset.set_format(\"torch\")\n",
        "    val_dataset.set_format(\"torch\")\n",
        "    test_dataset.set_format(\"torch\")\n",
        "\n",
        "    return train_dataset, val_dataset, test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXBAho7oNxLx",
        "outputId": "db123b0f-64ee-497e-82b4-aa77956a9b24"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "# Load the tokenizer for BERT\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Load the Teacher model (BERT)\n",
        "teacher_model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
        "\n",
        "# Load the Student model (DistilBERT)\n",
        "student_model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgnlSDGNNxLy",
        "outputId": "76ece52a-e63b-4f5c-818b-180dbfdcea57"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 3488/3488 [00:00<00:00, 24431.47 examples/s]\n",
            "Map: 100%|██████████| 388/388 [00:00<00:00, 22940.69 examples/s]\n",
            "Map: 100%|██████████| 970/970 [00:00<00:00, 22919.05 examples/s]\n"
          ]
        }
      ],
      "source": [
        "train_dataset, val_dataset, test_dataset = prepare_datasets(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFgT4lzuNxLy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def distillation_loss(student_logits, teacher_logits, true_labels, temperature=2.0, alpha=0.7):\n",
        "    # Soft labels from teacher model\n",
        "    soft_labels = F.softmax(teacher_logits / temperature, dim=-1)\n",
        "\n",
        "    # Hard loss using true labels\n",
        "    hard_loss = F.cross_entropy(student_logits, true_labels)\n",
        "\n",
        "    # Soft loss between teacher and student logits\n",
        "    soft_loss = F.kl_div(\n",
        "        F.log_softmax(student_logits / temperature, dim=-1),\n",
        "        soft_labels,\n",
        "        reduction='batchmean'\n",
        "    )\n",
        "\n",
        "    # Weighted combination of soft and hard loss\n",
        "    return alpha * soft_loss + (1.0 - alpha) * hard_loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naCuJuErNxLy"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def get_teacher_logits(model, dataset, batch_size=16, device='cpu'):\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
        "    logits = []\n",
        "\n",
        "    model.eval()  # Set teacher model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs = {k: v.to(device) for k, v in batch.items() if k in ['input_ids', 'attention_mask']}\n",
        "            outputs = model(**inputs)\n",
        "            logits.append(outputs.logits.cpu())\n",
        "\n",
        "    return torch.cat(logits, dim=0)  # Concatenate all logits into one tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEtIwdjcNxLy"
      },
      "outputs": [],
      "source": [
        "def distillation_train_loop(student_model, teacher_model, train_dataset, val_dataset, tokenizer, epochs=3, batch_size=16, learning_rate=5e-5, device='cpu'):\n",
        "    student_model = student_model.to(device)\n",
        "    teacher_model = teacher_model.to(device)\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(student_model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Teacher logits for the entire training dataset\n",
        "    teacher_logits = get_teacher_logits(teacher_model, train_dataset, batch_size=batch_size, device=device)\n",
        "    print(f\"Teacher logits: {teacher_logits}\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        student_model.train()\n",
        "        total_loss = 0.0\n",
        "\n",
        "        for i, batch in enumerate(train_dataloader):\n",
        "            inputs = {k: v.to(device) for k, v in batch.items() if k in ['input_ids', 'attention_mask']}\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            # Select corresponding teacher logits for this batch\n",
        "            batch_teacher_logits = teacher_logits[i * batch_size:(i + 1) * batch_size].to(device)\n",
        "\n",
        "            # Forward pass of student model\n",
        "            student_outputs = student_model(**inputs)\n",
        "            print(f\"Student outputs: {student_outputs}\")\n",
        "            student_logits = student_outputs.logits\n",
        "            print(f\"Student logits: {student_logits}\")\n",
        "\n",
        "            # Compute loss\n",
        "            loss = distillation_loss(student_logits, batch_teacher_logits, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_dataloader):.4f}\")\n",
        "\n",
        "    return student_model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6qtLLXINxLz",
        "outputId": "4fdf3fc4-ba3a-45a6-dc26-21e22fb8f9b8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/beyzakaya/miniforge3/envs/DLprojectenv/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/var/folders/kv/563b5k8n4xg24_t9kd2d72c40000gn/T/ipykernel_56174/2655727639.py:14: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_teacher = Trainer(\n",
            "  2%|▏         | 10/654 [00:22<15:48,  1.47s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8957, 'grad_norm': 4.335817337036133, 'learning_rate': 4.923547400611621e-05, 'epoch': 0.05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 20/654 [00:35<11:03,  1.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7797, 'grad_norm': 3.726905584335327, 'learning_rate': 4.847094801223242e-05, 'epoch': 0.09}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▍         | 30/654 [00:55<19:18,  1.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7911, 'grad_norm': 3.6768481731414795, 'learning_rate': 4.7706422018348626e-05, 'epoch': 0.14}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 40/654 [01:14<20:44,  2.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7659, 'grad_norm': 6.559085845947266, 'learning_rate': 4.694189602446483e-05, 'epoch': 0.18}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 50/654 [01:34<14:28,  1.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.6494, 'grad_norm': 5.637365341186523, 'learning_rate': 4.617737003058104e-05, 'epoch': 0.23}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▉         | 60/654 [02:01<34:59,  3.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.5958, 'grad_norm': 7.2245049476623535, 'learning_rate': 4.541284403669725e-05, 'epoch': 0.28}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 70/654 [02:44<33:00,  3.39s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.5212, 'grad_norm': 9.817317008972168, 'learning_rate': 4.4648318042813456e-05, 'epoch': 0.32}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 80/654 [03:20<37:59,  3.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.5809, 'grad_norm': 14.302302360534668, 'learning_rate': 4.3883792048929664e-05, 'epoch': 0.37}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 90/654 [03:51<25:06,  2.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4667, 'grad_norm': 4.403275012969971, 'learning_rate': 4.311926605504588e-05, 'epoch': 0.41}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 100/654 [04:09<13:33,  1.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4744, 'grad_norm': 2.98917293548584, 'learning_rate': 4.235474006116208e-05, 'epoch': 0.46}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 110/654 [04:27<14:55,  1.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4692, 'grad_norm': 13.180750846862793, 'learning_rate': 4.159021406727829e-05, 'epoch': 0.5}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 120/654 [04:39<08:44,  1.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.451, 'grad_norm': 4.209173679351807, 'learning_rate': 4.0825688073394495e-05, 'epoch': 0.55}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|█▉        | 130/654 [04:47<07:08,  1.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.3658, 'grad_norm': 13.522235870361328, 'learning_rate': 4.00611620795107e-05, 'epoch': 0.6}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██▏       | 140/654 [04:56<08:09,  1.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4707, 'grad_norm': 6.981060981750488, 'learning_rate': 3.929663608562692e-05, 'epoch': 0.64}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 150/654 [05:05<07:03,  1.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.394, 'grad_norm': 3.078388214111328, 'learning_rate': 3.8532110091743125e-05, 'epoch': 0.69}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▍       | 160/654 [05:15<08:03,  1.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4116, 'grad_norm': 11.815357208251953, 'learning_rate': 3.7767584097859326e-05, 'epoch': 0.73}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 170/654 [05:26<07:30,  1.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4293, 'grad_norm': 8.353646278381348, 'learning_rate': 3.7003058103975534e-05, 'epoch': 0.78}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 180/654 [05:34<06:24,  1.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4091, 'grad_norm': 3.852647542953491, 'learning_rate': 3.623853211009174e-05, 'epoch': 0.83}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 29%|██▉       | 190/654 [05:47<11:29,  1.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.3439, 'grad_norm': 8.242115020751953, 'learning_rate': 3.5474006116207956e-05, 'epoch': 0.87}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 31%|███       | 200/654 [05:57<07:18,  1.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4478, 'grad_norm': 11.006133079528809, 'learning_rate': 3.4709480122324164e-05, 'epoch': 0.92}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 210/654 [06:07<07:36,  1.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4146, 'grad_norm': 3.8564493656158447, 'learning_rate': 3.394495412844037e-05, 'epoch': 0.96}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                 \n",
            " 33%|███▎      | 218/654 [06:22<06:04,  1.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.39951249957084656, 'eval_runtime': 7.9863, 'eval_samples_per_second': 48.583, 'eval_steps_per_second': 3.13, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▎      | 220/654 [06:25<20:41,  2.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4293, 'grad_norm': 5.919196605682373, 'learning_rate': 3.318042813455658e-05, 'epoch': 1.01}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 230/654 [06:35<06:36,  1.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2745, 'grad_norm': 12.205646514892578, 'learning_rate': 3.241590214067278e-05, 'epoch': 1.06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 240/654 [06:44<05:46,  1.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2492, 'grad_norm': 19.635948181152344, 'learning_rate': 3.1651376146788995e-05, 'epoch': 1.1}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 250/654 [06:52<05:59,  1.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2927, 'grad_norm': 13.9088716506958, 'learning_rate': 3.08868501529052e-05, 'epoch': 1.15}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|███▉      | 260/654 [07:01<05:22,  1.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2574, 'grad_norm': 12.238587379455566, 'learning_rate': 3.012232415902141e-05, 'epoch': 1.19}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 41%|████▏     | 270/654 [07:09<05:22,  1.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2473, 'grad_norm': 4.494692802429199, 'learning_rate': 2.9357798165137618e-05, 'epoch': 1.24}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 280/654 [07:18<05:12,  1.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2933, 'grad_norm': 5.556410789489746, 'learning_rate': 2.8593272171253826e-05, 'epoch': 1.28}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 290/654 [07:26<05:01,  1.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2478, 'grad_norm': 15.016253471374512, 'learning_rate': 2.782874617737003e-05, 'epoch': 1.33}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 46%|████▌     | 300/654 [07:35<04:48,  1.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2413, 'grad_norm': 10.48573112487793, 'learning_rate': 2.7064220183486238e-05, 'epoch': 1.38}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 47%|████▋     | 310/654 [07:43<04:30,  1.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2933, 'grad_norm': 8.468277931213379, 'learning_rate': 2.629969418960245e-05, 'epoch': 1.42}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 49%|████▉     | 320/654 [07:51<04:33,  1.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2082, 'grad_norm': 11.91784954071045, 'learning_rate': 2.5535168195718656e-05, 'epoch': 1.47}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 330/654 [08:00<04:21,  1.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1717, 'grad_norm': 6.597239017486572, 'learning_rate': 2.4770642201834864e-05, 'epoch': 1.51}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 340/654 [08:08<04:10,  1.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2109, 'grad_norm': 6.263698577880859, 'learning_rate': 2.4006116207951072e-05, 'epoch': 1.56}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|█████▎    | 350/654 [08:16<04:01,  1.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2668, 'grad_norm': 3.51605486869812, 'learning_rate': 2.324159021406728e-05, 'epoch': 1.61}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 55%|█████▌    | 360/654 [08:25<03:58,  1.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2358, 'grad_norm': 6.929905891418457, 'learning_rate': 2.2477064220183487e-05, 'epoch': 1.65}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 370/654 [08:32<03:38,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1737, 'grad_norm': 13.150646209716797, 'learning_rate': 2.1712538226299695e-05, 'epoch': 1.7}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 58%|█████▊    | 380/654 [08:59<08:46,  1.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1887, 'grad_norm': 2.7542884349823, 'learning_rate': 2.0948012232415903e-05, 'epoch': 1.74}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|█████▉    | 390/654 [09:17<08:21,  1.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2438, 'grad_norm': 7.993503093719482, 'learning_rate': 2.018348623853211e-05, 'epoch': 1.79}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 61%|██████    | 400/654 [09:43<07:55,  1.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2273, 'grad_norm': 1.731151819229126, 'learning_rate': 1.9418960244648318e-05, 'epoch': 1.83}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 63%|██████▎   | 410/654 [09:51<03:25,  1.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.189, 'grad_norm': 10.786277770996094, 'learning_rate': 1.8654434250764526e-05, 'epoch': 1.88}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 420/654 [10:00<03:27,  1.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2369, 'grad_norm': 24.436796188354492, 'learning_rate': 1.7889908256880737e-05, 'epoch': 1.93}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 66%|██████▌   | 430/654 [10:09<03:13,  1.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2379, 'grad_norm': 10.953409194946289, 'learning_rate': 1.712538226299694e-05, 'epoch': 1.97}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                 \n",
            " 67%|██████▋   | 436/654 [10:20<03:09,  1.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.42221856117248535, 'eval_runtime': 5.1733, 'eval_samples_per_second': 75.001, 'eval_steps_per_second': 4.833, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 440/654 [10:25<05:57,  1.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1247, 'grad_norm': 0.48542287945747375, 'learning_rate': 1.636085626911315e-05, 'epoch': 2.02}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 69%|██████▉   | 450/654 [10:35<03:32,  1.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1219, 'grad_norm': 4.878985404968262, 'learning_rate': 1.559633027522936e-05, 'epoch': 2.06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 460/654 [10:44<02:38,  1.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0529, 'grad_norm': 0.5471055507659912, 'learning_rate': 1.4831804281345565e-05, 'epoch': 2.11}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 72%|███████▏  | 470/654 [10:56<04:36,  1.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.094, 'grad_norm': 2.234342336654663, 'learning_rate': 1.4067278287461774e-05, 'epoch': 2.16}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 73%|███████▎  | 480/654 [11:10<03:11,  1.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0941, 'grad_norm': 2.1173996925354004, 'learning_rate': 1.3302752293577984e-05, 'epoch': 2.2}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▍  | 490/654 [11:23<03:31,  1.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1095, 'grad_norm': 8.039071083068848, 'learning_rate': 1.253822629969419e-05, 'epoch': 2.25}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▋  | 500/654 [11:50<09:03,  3.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0603, 'grad_norm': 0.2917783856391907, 'learning_rate': 1.1773700305810397e-05, 'epoch': 2.29}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 510/654 [12:28<06:34,  2.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.058, 'grad_norm': 3.5893125534057617, 'learning_rate': 1.1009174311926607e-05, 'epoch': 2.34}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|███████▉  | 520/654 [12:48<04:15,  1.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0454, 'grad_norm': 0.35865363478660583, 'learning_rate': 1.0244648318042814e-05, 'epoch': 2.39}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 81%|████████  | 530/654 [12:58<01:46,  1.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0929, 'grad_norm': 1.6767597198486328, 'learning_rate': 9.480122324159022e-06, 'epoch': 2.43}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 83%|████████▎ | 540/654 [13:06<01:33,  1.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.065, 'grad_norm': 0.4124130606651306, 'learning_rate': 8.71559633027523e-06, 'epoch': 2.48}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 84%|████████▍ | 550/654 [13:59<06:46,  3.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1427, 'grad_norm': 7.561567783355713, 'learning_rate': 7.951070336391438e-06, 'epoch': 2.52}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 560/654 [14:19<03:21,  2.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1231, 'grad_norm': 0.09226620942354202, 'learning_rate': 7.186544342507645e-06, 'epoch': 2.57}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 87%|████████▋ | 570/654 [14:48<03:34,  2.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0902, 'grad_norm': 2.3611152172088623, 'learning_rate': 6.422018348623854e-06, 'epoch': 2.61}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 89%|████████▊ | 580/654 [15:07<02:04,  1.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1019, 'grad_norm': 0.11030992120504379, 'learning_rate': 5.657492354740062e-06, 'epoch': 2.66}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 590/654 [15:25<01:34,  1.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0148, 'grad_norm': 0.17759627103805542, 'learning_rate': 4.892966360856269e-06, 'epoch': 2.71}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 92%|█████████▏| 600/654 [15:37<00:56,  1.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.127, 'grad_norm': 0.4788254201412201, 'learning_rate': 4.128440366972477e-06, 'epoch': 2.75}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 610/654 [16:06<01:00,  1.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1061, 'grad_norm': 13.228991508483887, 'learning_rate': 3.363914373088685e-06, 'epoch': 2.8}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 95%|█████████▍| 620/654 [16:22<00:40,  1.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1632, 'grad_norm': 16.87421417236328, 'learning_rate': 2.599388379204893e-06, 'epoch': 2.84}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96%|█████████▋| 630/654 [16:33<00:28,  1.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1102, 'grad_norm': 2.434553861618042, 'learning_rate': 1.8348623853211011e-06, 'epoch': 2.89}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 640/654 [16:47<00:24,  1.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0989, 'grad_norm': 0.21832436323165894, 'learning_rate': 1.0703363914373088e-06, 'epoch': 2.94}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 99%|█████████▉| 650/654 [16:58<00:04,  1.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1114, 'grad_norm': 0.08660129457712173, 'learning_rate': 3.0581039755351683e-07, 'epoch': 2.98}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                 \n",
            "100%|██████████| 654/654 [17:20<00:00,  1.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.6311530470848083, 'eval_runtime': 7.7797, 'eval_samples_per_second': 49.873, 'eval_steps_per_second': 3.213, 'epoch': 3.0}\n",
            "{'train_runtime': 1040.5886, 'train_samples_per_second': 10.056, 'train_steps_per_second': 0.628, 'train_loss': 0.2857098263611487, 'epoch': 3.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=654, training_loss=0.2857098263611487, metrics={'train_runtime': 1040.5886, 'train_samples_per_second': 10.056, 'train_steps_per_second': 0.628, 'total_flos': 688304700776448.0, 'train_loss': 0.2857098263611487, 'epoch': 3.0})"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set up the training arguments for the teacher model\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results_knowledge_distill/teacher_model\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    logging_dir=\"./logs_knowledge_distill/teacher_model\",\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "# Trainer for the teacher model\n",
        "trainer_teacher = Trainer(\n",
        "    model=teacher_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "# Fine-tune the teacher model\n",
        "trainer_teacher.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjVi3ZhONxLz"
      },
      "source": [
        "#### This function ensures the student model is trained using the logits from the teacher model in addition to the ground truth labels, combining hard and soft losses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwFCHcBfNxLz",
        "outputId": "2aa59a57-39f5-4fdc-c9a3-8c6f5a4ae343"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teacher logits: tensor([[-2.6213,  4.1635, -2.3194],\n",
            "        [-1.5190, -1.7753,  4.8557],\n",
            "        [-2.5256,  4.1303, -2.2848],\n",
            "        ...,\n",
            "        [-1.7173,  3.6361, -2.9695],\n",
            "        [-1.8634, -1.4155,  4.7208],\n",
            "        [-2.6480,  4.1266, -2.2814]])\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4568,  1.6938, -0.6216],\n",
            "        [-1.4918,  1.5309, -0.0303],\n",
            "        [-1.6417,  1.1014,  0.4621],\n",
            "        [-1.2778,  1.1750, -0.1223],\n",
            "        [-1.7693,  0.3149,  1.4295],\n",
            "        [-1.8186,  1.1852,  0.1105],\n",
            "        [ 0.1959,  0.1122, -0.8044],\n",
            "        [-2.2644,  0.2283,  1.6057],\n",
            "        [-1.8654,  0.4816,  0.9782],\n",
            "        [-0.0396,  0.2007, -0.8431],\n",
            "        [-1.1631,  1.3751, -0.3029],\n",
            "        [-1.7715,  1.5458,  0.2369],\n",
            "        [-1.1664,  1.3201, -0.6355],\n",
            "        [-1.6168, -0.0067,  1.1921],\n",
            "        [-1.7620,  0.3772,  1.1147],\n",
            "        [-1.8191,  1.2931,  0.3181]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4568,  1.6938, -0.6216],\n",
            "        [-1.4918,  1.5309, -0.0303],\n",
            "        [-1.6417,  1.1014,  0.4621],\n",
            "        [-1.2778,  1.1750, -0.1223],\n",
            "        [-1.7693,  0.3149,  1.4295],\n",
            "        [-1.8186,  1.1852,  0.1105],\n",
            "        [ 0.1959,  0.1122, -0.8044],\n",
            "        [-2.2644,  0.2283,  1.6057],\n",
            "        [-1.8654,  0.4816,  0.9782],\n",
            "        [-0.0396,  0.2007, -0.8431],\n",
            "        [-1.1631,  1.3751, -0.3029],\n",
            "        [-1.7715,  1.5458,  0.2369],\n",
            "        [-1.1664,  1.3201, -0.6355],\n",
            "        [-1.6168, -0.0067,  1.1921],\n",
            "        [-1.7620,  0.3772,  1.1147],\n",
            "        [-1.8191,  1.2931,  0.3181]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5808,  1.6886, -0.0567],\n",
            "        [-1.5757,  1.7930, -0.4598],\n",
            "        [-1.2112,  1.0803, -0.2517],\n",
            "        [-1.9942,  1.0192,  0.6077],\n",
            "        [-1.4595,  1.4458, -0.1002],\n",
            "        [-1.7656,  0.1432,  1.3050],\n",
            "        [-1.6312,  1.5670, -0.0466],\n",
            "        [-1.6714,  1.6358, -0.0982],\n",
            "        [-1.9927,  0.2996,  1.4402],\n",
            "        [-1.3640,  1.4469, -0.2880],\n",
            "        [-1.6073,  1.7372, -0.1742],\n",
            "        [-1.8234,  1.4073,  0.0721],\n",
            "        [-1.8748,  1.2589,  0.2262],\n",
            "        [-1.5140,  1.9485, -0.1832],\n",
            "        [-1.8572,  1.1929,  0.5277],\n",
            "        [-1.9547,  1.0560,  0.4281]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5808,  1.6886, -0.0567],\n",
            "        [-1.5757,  1.7930, -0.4598],\n",
            "        [-1.2112,  1.0803, -0.2517],\n",
            "        [-1.9942,  1.0192,  0.6077],\n",
            "        [-1.4595,  1.4458, -0.1002],\n",
            "        [-1.7656,  0.1432,  1.3050],\n",
            "        [-1.6312,  1.5670, -0.0466],\n",
            "        [-1.6714,  1.6358, -0.0982],\n",
            "        [-1.9927,  0.2996,  1.4402],\n",
            "        [-1.3640,  1.4469, -0.2880],\n",
            "        [-1.6073,  1.7372, -0.1742],\n",
            "        [-1.8234,  1.4073,  0.0721],\n",
            "        [-1.8748,  1.2589,  0.2262],\n",
            "        [-1.5140,  1.9485, -0.1832],\n",
            "        [-1.8572,  1.1929,  0.5277],\n",
            "        [-1.9547,  1.0560,  0.4281]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8969,  0.2397,  1.0902],\n",
            "        [-0.1880,  0.9118, -0.9832],\n",
            "        [-2.0599,  0.2623,  1.3519],\n",
            "        [-1.4655,  1.8053, -0.4308],\n",
            "        [-2.0229,  0.8996,  0.8102],\n",
            "        [-1.5829,  1.8561, -0.2814],\n",
            "        [-1.2304,  1.8818, -0.4453],\n",
            "        [-1.7999,  1.6950, -0.2052],\n",
            "        [ 0.2999,  0.1976, -0.7324],\n",
            "        [-1.2648,  1.6260, -0.4516],\n",
            "        [-1.7086,  0.7986,  0.5704],\n",
            "        [-1.4620,  1.8107, -0.3460],\n",
            "        [-1.9785,  0.1820,  1.0779],\n",
            "        [-1.7401,  0.5852,  0.8561],\n",
            "        [-1.3896,  1.4953, -0.5455],\n",
            "        [-1.9561,  1.2152,  0.2842]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8969,  0.2397,  1.0902],\n",
            "        [-0.1880,  0.9118, -0.9832],\n",
            "        [-2.0599,  0.2623,  1.3519],\n",
            "        [-1.4655,  1.8053, -0.4308],\n",
            "        [-2.0229,  0.8996,  0.8102],\n",
            "        [-1.5829,  1.8561, -0.2814],\n",
            "        [-1.2304,  1.8818, -0.4453],\n",
            "        [-1.7999,  1.6950, -0.2052],\n",
            "        [ 0.2999,  0.1976, -0.7324],\n",
            "        [-1.2648,  1.6260, -0.4516],\n",
            "        [-1.7086,  0.7986,  0.5704],\n",
            "        [-1.4620,  1.8107, -0.3460],\n",
            "        [-1.9785,  0.1820,  1.0779],\n",
            "        [-1.7401,  0.5852,  0.8561],\n",
            "        [-1.3896,  1.4953, -0.5455],\n",
            "        [-1.9561,  1.2152,  0.2842]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7141,  1.8761, -0.5925],\n",
            "        [-1.5706,  1.1415,  0.3156],\n",
            "        [-1.4402,  1.4088, -0.3472],\n",
            "        [-1.4057,  1.0404,  0.1290],\n",
            "        [-1.6380,  1.5460, -0.1893],\n",
            "        [-1.9334,  1.8076, -0.1668],\n",
            "        [-1.9521,  0.3418,  1.0511],\n",
            "        [-1.4147,  1.7655, -0.3826],\n",
            "        [-1.5983,  1.2245,  0.1235],\n",
            "        [-1.2994,  1.5697, -0.5744],\n",
            "        [-1.6341,  1.9706, -0.4236],\n",
            "        [-1.3460,  1.7099, -0.7192],\n",
            "        [-1.8432, -0.0081,  1.1590],\n",
            "        [-1.0330, -0.1063,  0.4977],\n",
            "        [-1.2093,  1.5753, -0.7494],\n",
            "        [-1.7473,  0.0451,  1.3275]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7141,  1.8761, -0.5925],\n",
            "        [-1.5706,  1.1415,  0.3156],\n",
            "        [-1.4402,  1.4088, -0.3472],\n",
            "        [-1.4057,  1.0404,  0.1290],\n",
            "        [-1.6380,  1.5460, -0.1893],\n",
            "        [-1.9334,  1.8076, -0.1668],\n",
            "        [-1.9521,  0.3418,  1.0511],\n",
            "        [-1.4147,  1.7655, -0.3826],\n",
            "        [-1.5983,  1.2245,  0.1235],\n",
            "        [-1.2994,  1.5697, -0.5744],\n",
            "        [-1.6341,  1.9706, -0.4236],\n",
            "        [-1.3460,  1.7099, -0.7192],\n",
            "        [-1.8432, -0.0081,  1.1590],\n",
            "        [-1.0330, -0.1063,  0.4977],\n",
            "        [-1.2093,  1.5753, -0.7494],\n",
            "        [-1.7473,  0.0451,  1.3275]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8880,  0.5797,  1.0462],\n",
            "        [-1.1565,  1.7072, -0.6239],\n",
            "        [-0.4670,  0.3878, -0.2553],\n",
            "        [-1.1267,  0.0882,  0.5977],\n",
            "        [-1.4539,  1.6303, -0.2260],\n",
            "        [-1.4307,  1.8323, -0.6772],\n",
            "        [-1.6197,  1.7431, -0.5176],\n",
            "        [ 0.3151,  0.0745, -0.8056],\n",
            "        [-1.7548,  1.7354, -0.3265],\n",
            "        [-1.6265,  1.9403, -0.5851],\n",
            "        [-1.3482,  1.4719, -0.4669],\n",
            "        [-1.6000,  1.8708, -0.3454],\n",
            "        [-1.2566,  1.5660, -0.6674],\n",
            "        [-1.5996,  1.3574,  0.0147],\n",
            "        [-1.4978,  0.5757,  0.3773],\n",
            "        [-1.7697,  0.0973,  1.1830]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8880,  0.5797,  1.0462],\n",
            "        [-1.1565,  1.7072, -0.6239],\n",
            "        [-0.4670,  0.3878, -0.2553],\n",
            "        [-1.1267,  0.0882,  0.5977],\n",
            "        [-1.4539,  1.6303, -0.2260],\n",
            "        [-1.4307,  1.8323, -0.6772],\n",
            "        [-1.6197,  1.7431, -0.5176],\n",
            "        [ 0.3151,  0.0745, -0.8056],\n",
            "        [-1.7548,  1.7354, -0.3265],\n",
            "        [-1.6265,  1.9403, -0.5851],\n",
            "        [-1.3482,  1.4719, -0.4669],\n",
            "        [-1.6000,  1.8708, -0.3454],\n",
            "        [-1.2566,  1.5660, -0.6674],\n",
            "        [-1.5996,  1.3574,  0.0147],\n",
            "        [-1.4978,  0.5757,  0.3773],\n",
            "        [-1.7697,  0.0973,  1.1830]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2173,  1.6854, -0.7218],\n",
            "        [-1.4920,  1.7671, -0.6350],\n",
            "        [ 0.3513,  0.0959, -1.0022],\n",
            "        [-1.3255,  1.8228, -0.3550],\n",
            "        [ 0.2836,  0.1714, -0.8218],\n",
            "        [-0.1668,  0.5345, -0.8727],\n",
            "        [-1.8353,  2.0175, -0.5865],\n",
            "        [ 0.2520,  0.0674, -0.7655],\n",
            "        [-1.4565,  1.9292, -0.4260],\n",
            "        [-1.6304,  0.4388,  1.0338],\n",
            "        [-1.3879,  0.9916, -0.0966],\n",
            "        [-0.1588,  0.6567, -0.7677],\n",
            "        [-1.2565,  1.5755, -0.5490],\n",
            "        [-1.2649,  1.6284, -0.5473],\n",
            "        [-1.4908,  1.8048, -0.7164],\n",
            "        [-1.7832,  2.1890, -0.4949]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2173,  1.6854, -0.7218],\n",
            "        [-1.4920,  1.7671, -0.6350],\n",
            "        [ 0.3513,  0.0959, -1.0022],\n",
            "        [-1.3255,  1.8228, -0.3550],\n",
            "        [ 0.2836,  0.1714, -0.8218],\n",
            "        [-0.1668,  0.5345, -0.8727],\n",
            "        [-1.8353,  2.0175, -0.5865],\n",
            "        [ 0.2520,  0.0674, -0.7655],\n",
            "        [-1.4565,  1.9292, -0.4260],\n",
            "        [-1.6304,  0.4388,  1.0338],\n",
            "        [-1.3879,  0.9916, -0.0966],\n",
            "        [-0.1588,  0.6567, -0.7677],\n",
            "        [-1.2565,  1.5755, -0.5490],\n",
            "        [-1.2649,  1.6284, -0.5473],\n",
            "        [-1.4908,  1.8048, -0.7164],\n",
            "        [-1.7832,  2.1890, -0.4949]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4473, -0.0038,  0.9192],\n",
            "        [-0.5547,  0.6509, -0.4672],\n",
            "        [-0.9378,  1.2056, -0.4954],\n",
            "        [-1.2899,  0.1189,  0.8748],\n",
            "        [-1.6029,  2.0654, -0.5146],\n",
            "        [-1.5999,  1.8809, -0.5239],\n",
            "        [-1.4438,  1.9209, -0.3122],\n",
            "        [-1.0144,  1.3347, -0.6797],\n",
            "        [-1.8773,  2.1005, -0.4372],\n",
            "        [-1.6271,  0.4022,  0.7778],\n",
            "        [-2.0181,  1.4072,  0.1399],\n",
            "        [-1.7730,  1.0972, -0.0378],\n",
            "        [ 0.0349,  0.2952, -0.8624],\n",
            "        [-1.3738,  1.7125, -0.5301],\n",
            "        [-1.4603,  1.9760, -0.3511],\n",
            "        [-0.9744,  1.4929, -0.7590]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4473, -0.0038,  0.9192],\n",
            "        [-0.5547,  0.6509, -0.4672],\n",
            "        [-0.9378,  1.2056, -0.4954],\n",
            "        [-1.2899,  0.1189,  0.8748],\n",
            "        [-1.6029,  2.0654, -0.5146],\n",
            "        [-1.5999,  1.8809, -0.5239],\n",
            "        [-1.4438,  1.9209, -0.3122],\n",
            "        [-1.0144,  1.3347, -0.6797],\n",
            "        [-1.8773,  2.1005, -0.4372],\n",
            "        [-1.6271,  0.4022,  0.7778],\n",
            "        [-2.0181,  1.4072,  0.1399],\n",
            "        [-1.7730,  1.0972, -0.0378],\n",
            "        [ 0.0349,  0.2952, -0.8624],\n",
            "        [-1.3738,  1.7125, -0.5301],\n",
            "        [-1.4603,  1.9760, -0.3511],\n",
            "        [-0.9744,  1.4929, -0.7590]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.5201,  0.3785, -0.4718],\n",
            "        [-1.2962,  1.5986, -0.4343],\n",
            "        [ 0.1818,  0.0055, -0.8860],\n",
            "        [-1.7050,  1.6695, -0.2703],\n",
            "        [-1.4208, -0.1215,  0.9247],\n",
            "        [ 0.4385, -0.0335, -0.8810],\n",
            "        [-1.5586,  1.7617, -0.3256],\n",
            "        [-1.7066,  1.6914, -0.5316],\n",
            "        [-2.0845,  1.0420,  0.6715],\n",
            "        [-1.4831,  1.0806,  0.2099],\n",
            "        [-1.4429,  1.7936, -0.5431],\n",
            "        [-1.8366,  0.5299,  0.7811],\n",
            "        [-1.4471,  1.6804, -0.4279],\n",
            "        [-1.3845,  0.1014,  0.7955],\n",
            "        [ 0.0970,  0.3794, -0.7938],\n",
            "        [-1.9072,  0.6539,  0.8181]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-0.5201,  0.3785, -0.4718],\n",
            "        [-1.2962,  1.5986, -0.4343],\n",
            "        [ 0.1818,  0.0055, -0.8860],\n",
            "        [-1.7050,  1.6695, -0.2703],\n",
            "        [-1.4208, -0.1215,  0.9247],\n",
            "        [ 0.4385, -0.0335, -0.8810],\n",
            "        [-1.5586,  1.7617, -0.3256],\n",
            "        [-1.7066,  1.6914, -0.5316],\n",
            "        [-2.0845,  1.0420,  0.6715],\n",
            "        [-1.4831,  1.0806,  0.2099],\n",
            "        [-1.4429,  1.7936, -0.5431],\n",
            "        [-1.8366,  0.5299,  0.7811],\n",
            "        [-1.4471,  1.6804, -0.4279],\n",
            "        [-1.3845,  0.1014,  0.7955],\n",
            "        [ 0.0970,  0.3794, -0.7938],\n",
            "        [-1.9072,  0.6539,  0.8181]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5584,  1.7904, -0.3210],\n",
            "        [-1.4272,  1.7838, -0.5500],\n",
            "        [-1.5076,  1.7006, -0.5693],\n",
            "        [-1.3787,  0.1077,  0.8029],\n",
            "        [-1.9888,  0.7693,  1.0535],\n",
            "        [-1.3906,  1.8703, -0.3374],\n",
            "        [-1.3968, -0.0687,  0.7893],\n",
            "        [-1.1569,  1.5628, -0.7887],\n",
            "        [-1.4318,  0.1253,  0.9321],\n",
            "        [-1.2737,  1.6697, -0.6392],\n",
            "        [-1.7873,  0.2935,  0.9819],\n",
            "        [-1.4592,  0.1470,  0.8396],\n",
            "        [-1.4940,  1.8155, -0.5937],\n",
            "        [-1.0518,  0.8756, -0.1353],\n",
            "        [-1.8676,  0.1120,  1.1754],\n",
            "        [-1.4071,  0.0181,  0.8922]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5584,  1.7904, -0.3210],\n",
            "        [-1.4272,  1.7838, -0.5500],\n",
            "        [-1.5076,  1.7006, -0.5693],\n",
            "        [-1.3787,  0.1077,  0.8029],\n",
            "        [-1.9888,  0.7693,  1.0535],\n",
            "        [-1.3906,  1.8703, -0.3374],\n",
            "        [-1.3968, -0.0687,  0.7893],\n",
            "        [-1.1569,  1.5628, -0.7887],\n",
            "        [-1.4318,  0.1253,  0.9321],\n",
            "        [-1.2737,  1.6697, -0.6392],\n",
            "        [-1.7873,  0.2935,  0.9819],\n",
            "        [-1.4592,  0.1470,  0.8396],\n",
            "        [-1.4940,  1.8155, -0.5937],\n",
            "        [-1.0518,  0.8756, -0.1353],\n",
            "        [-1.8676,  0.1120,  1.1754],\n",
            "        [-1.4071,  0.0181,  0.8922]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4765,  1.8344, -0.4541],\n",
            "        [ 0.3183, -0.0887, -0.8284],\n",
            "        [-1.8266,  1.2304,  0.1374],\n",
            "        [-1.7662,  1.7618, -0.3422],\n",
            "        [-1.7449,  1.4021, -0.0907],\n",
            "        [-1.5072,  1.8590, -0.5322],\n",
            "        [-1.1289,  1.5206, -0.5161],\n",
            "        [-1.6403,  1.6249, -0.2184],\n",
            "        [-1.9604,  1.4893,  0.2569],\n",
            "        [-1.4178,  1.5459, -0.4688],\n",
            "        [-1.8111,  0.9545,  0.6346],\n",
            "        [-1.7611,  1.3625, -0.0725],\n",
            "        [-2.0322,  0.4491,  0.9949],\n",
            "        [-2.1114,  1.0166,  0.5607],\n",
            "        [-1.8647,  0.4941,  0.8324],\n",
            "        [-1.8858,  1.6332, -0.0103]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4765,  1.8344, -0.4541],\n",
            "        [ 0.3183, -0.0887, -0.8284],\n",
            "        [-1.8266,  1.2304,  0.1374],\n",
            "        [-1.7662,  1.7618, -0.3422],\n",
            "        [-1.7449,  1.4021, -0.0907],\n",
            "        [-1.5072,  1.8590, -0.5322],\n",
            "        [-1.1289,  1.5206, -0.5161],\n",
            "        [-1.6403,  1.6249, -0.2184],\n",
            "        [-1.9604,  1.4893,  0.2569],\n",
            "        [-1.4178,  1.5459, -0.4688],\n",
            "        [-1.8111,  0.9545,  0.6346],\n",
            "        [-1.7611,  1.3625, -0.0725],\n",
            "        [-2.0322,  0.4491,  0.9949],\n",
            "        [-2.1114,  1.0166,  0.5607],\n",
            "        [-1.8647,  0.4941,  0.8324],\n",
            "        [-1.8858,  1.6332, -0.0103]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1501,  0.8308,  0.9894],\n",
            "        [ 0.0816,  0.1146, -0.6804],\n",
            "        [-1.6468,  1.6523, -0.3956],\n",
            "        [-0.4358,  0.7952, -0.9513],\n",
            "        [-2.0343,  1.9148, -0.0294],\n",
            "        [ 0.3067,  0.1947, -0.8112],\n",
            "        [-1.4048,  0.1876,  1.1138],\n",
            "        [ 0.1607,  0.0883, -0.8433],\n",
            "        [-1.3767,  1.6757, -0.4643],\n",
            "        [-0.8140,  0.0965,  0.2266],\n",
            "        [-1.9513,  1.8642, -0.2587],\n",
            "        [-1.9456,  2.1230, -0.2895],\n",
            "        [-0.9125,  0.7586, -0.1862],\n",
            "        [ 0.4059, -0.1091, -0.9392],\n",
            "        [-1.7820,  1.4136, -0.0967],\n",
            "        [-1.4014,  1.6458, -0.4302]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1501,  0.8308,  0.9894],\n",
            "        [ 0.0816,  0.1146, -0.6804],\n",
            "        [-1.6468,  1.6523, -0.3956],\n",
            "        [-0.4358,  0.7952, -0.9513],\n",
            "        [-2.0343,  1.9148, -0.0294],\n",
            "        [ 0.3067,  0.1947, -0.8112],\n",
            "        [-1.4048,  0.1876,  1.1138],\n",
            "        [ 0.1607,  0.0883, -0.8433],\n",
            "        [-1.3767,  1.6757, -0.4643],\n",
            "        [-0.8140,  0.0965,  0.2266],\n",
            "        [-1.9513,  1.8642, -0.2587],\n",
            "        [-1.9456,  2.1230, -0.2895],\n",
            "        [-0.9125,  0.7586, -0.1862],\n",
            "        [ 0.4059, -0.1091, -0.9392],\n",
            "        [-1.7820,  1.4136, -0.0967],\n",
            "        [-1.4014,  1.6458, -0.4302]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1397e+00,  1.5334e+00,  3.6656e-01],\n",
            "        [-1.5806e+00,  9.4443e-02,  9.5022e-01],\n",
            "        [-1.7965e+00,  8.3183e-02,  1.2819e+00],\n",
            "        [-2.0434e+00,  7.9573e-01,  5.5927e-01],\n",
            "        [-1.5749e+00,  3.6432e-01,  8.8442e-01],\n",
            "        [ 1.9667e-01,  7.3335e-02, -9.4493e-01],\n",
            "        [-1.5946e+00,  1.5603e+00, -2.0114e-01],\n",
            "        [-1.0464e+00,  1.0204e+00, -4.5841e-01],\n",
            "        [-1.4966e+00,  1.7984e+00, -5.4026e-01],\n",
            "        [-1.3123e+00,  1.1718e+00, -3.4633e-01],\n",
            "        [-1.2636e+00,  2.3403e-01,  7.2084e-01],\n",
            "        [-1.6755e+00,  1.4961e+00, -1.3193e-01],\n",
            "        [-1.7290e+00,  1.1583e+00,  2.9804e-01],\n",
            "        [-2.0875e+00,  1.6509e+00, -1.1191e-03],\n",
            "        [-1.8971e+00,  1.7920e+00, -1.5188e-01],\n",
            "        [-1.7845e+00,  1.8361e+00, -1.5329e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1397e+00,  1.5334e+00,  3.6656e-01],\n",
            "        [-1.5806e+00,  9.4443e-02,  9.5022e-01],\n",
            "        [-1.7965e+00,  8.3183e-02,  1.2819e+00],\n",
            "        [-2.0434e+00,  7.9573e-01,  5.5927e-01],\n",
            "        [-1.5749e+00,  3.6432e-01,  8.8442e-01],\n",
            "        [ 1.9667e-01,  7.3335e-02, -9.4493e-01],\n",
            "        [-1.5946e+00,  1.5603e+00, -2.0114e-01],\n",
            "        [-1.0464e+00,  1.0204e+00, -4.5841e-01],\n",
            "        [-1.4966e+00,  1.7984e+00, -5.4026e-01],\n",
            "        [-1.3123e+00,  1.1718e+00, -3.4633e-01],\n",
            "        [-1.2636e+00,  2.3403e-01,  7.2084e-01],\n",
            "        [-1.6755e+00,  1.4961e+00, -1.3193e-01],\n",
            "        [-1.7290e+00,  1.1583e+00,  2.9804e-01],\n",
            "        [-2.0875e+00,  1.6509e+00, -1.1191e-03],\n",
            "        [-1.8971e+00,  1.7920e+00, -1.5188e-01],\n",
            "        [-1.7845e+00,  1.8361e+00, -1.5329e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2680,  1.2873, -0.0575],\n",
            "        [-1.6775,  0.3889,  1.0493],\n",
            "        [-1.8963,  0.4460,  0.9678],\n",
            "        [-1.9677,  1.5980,  0.0842],\n",
            "        [-2.0162,  0.4283,  1.1752],\n",
            "        [-1.4565,  0.0893,  0.9317],\n",
            "        [ 0.3339,  0.0505, -0.7772],\n",
            "        [-1.6001,  1.7563, -0.3555],\n",
            "        [-1.7633,  0.2872,  1.1554],\n",
            "        [-1.5450,  1.7104, -0.0072],\n",
            "        [-0.0197,  0.4424, -0.9216],\n",
            "        [-2.0893,  1.3294,  0.4043],\n",
            "        [-2.1290,  1.9618, -0.2788],\n",
            "        [-1.8640,  1.6078, -0.0457],\n",
            "        [-2.0188,  0.9139,  0.6380],\n",
            "        [-1.7744,  0.3510,  0.9486]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2680,  1.2873, -0.0575],\n",
            "        [-1.6775,  0.3889,  1.0493],\n",
            "        [-1.8963,  0.4460,  0.9678],\n",
            "        [-1.9677,  1.5980,  0.0842],\n",
            "        [-2.0162,  0.4283,  1.1752],\n",
            "        [-1.4565,  0.0893,  0.9317],\n",
            "        [ 0.3339,  0.0505, -0.7772],\n",
            "        [-1.6001,  1.7563, -0.3555],\n",
            "        [-1.7633,  0.2872,  1.1554],\n",
            "        [-1.5450,  1.7104, -0.0072],\n",
            "        [-0.0197,  0.4424, -0.9216],\n",
            "        [-2.0893,  1.3294,  0.4043],\n",
            "        [-2.1290,  1.9618, -0.2788],\n",
            "        [-1.8640,  1.6078, -0.0457],\n",
            "        [-2.0188,  0.9139,  0.6380],\n",
            "        [-1.7744,  0.3510,  0.9486]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.0282,  1.3471, -0.5169],\n",
            "        [-1.8294,  1.8399, -0.2557],\n",
            "        [-1.5882,  0.1801,  0.9642],\n",
            "        [-1.8569,  1.8524, -0.2316],\n",
            "        [-1.9657,  1.8344, -0.2300],\n",
            "        [-2.4348,  0.9898,  1.0129],\n",
            "        [-1.9226,  1.7134,  0.1648],\n",
            "        [-1.9125,  2.0559, -0.4284],\n",
            "        [-0.2810,  0.6755, -0.7247],\n",
            "        [-1.8789,  0.3384,  1.1373],\n",
            "        [-1.7875,  0.3358,  1.2439],\n",
            "        [-1.9016,  1.8626,  0.0937],\n",
            "        [-1.0248,  1.2165, -0.5676],\n",
            "        [-1.7765,  1.6915, -0.3748],\n",
            "        [-1.7048,  1.9291, -0.3737],\n",
            "        [-1.5646,  1.2691, -0.1334]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.0282,  1.3471, -0.5169],\n",
            "        [-1.8294,  1.8399, -0.2557],\n",
            "        [-1.5882,  0.1801,  0.9642],\n",
            "        [-1.8569,  1.8524, -0.2316],\n",
            "        [-1.9657,  1.8344, -0.2300],\n",
            "        [-2.4348,  0.9898,  1.0129],\n",
            "        [-1.9226,  1.7134,  0.1648],\n",
            "        [-1.9125,  2.0559, -0.4284],\n",
            "        [-0.2810,  0.6755, -0.7247],\n",
            "        [-1.8789,  0.3384,  1.1373],\n",
            "        [-1.7875,  0.3358,  1.2439],\n",
            "        [-1.9016,  1.8626,  0.0937],\n",
            "        [-1.0248,  1.2165, -0.5676],\n",
            "        [-1.7765,  1.6915, -0.3748],\n",
            "        [-1.7048,  1.9291, -0.3737],\n",
            "        [-1.5646,  1.2691, -0.1334]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0195,  0.6617,  0.9426],\n",
            "        [-1.7519,  1.6056, -0.0421],\n",
            "        [-1.6624,  1.0689,  0.0477],\n",
            "        [-1.9956,  1.4005,  0.0821],\n",
            "        [-1.9263,  0.2883,  1.0516],\n",
            "        [ 0.2455,  0.0966, -0.9458],\n",
            "        [-1.8336,  1.8750, -0.0494],\n",
            "        [-1.9564,  0.5724,  1.0470],\n",
            "        [-2.1272,  1.2094,  0.3707],\n",
            "        [-2.1567,  1.7640, -0.0174],\n",
            "        [-1.3445,  1.4774, -0.5061],\n",
            "        [-1.7895,  1.7644, -0.0460],\n",
            "        [-1.3003,  1.2155, -0.3857],\n",
            "        [ 0.0726,  0.4491, -1.0450],\n",
            "        [-1.5117,  1.4972, -0.1928],\n",
            "        [ 0.0702,  0.4610, -0.8497]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0195,  0.6617,  0.9426],\n",
            "        [-1.7519,  1.6056, -0.0421],\n",
            "        [-1.6624,  1.0689,  0.0477],\n",
            "        [-1.9956,  1.4005,  0.0821],\n",
            "        [-1.9263,  0.2883,  1.0516],\n",
            "        [ 0.2455,  0.0966, -0.9458],\n",
            "        [-1.8336,  1.8750, -0.0494],\n",
            "        [-1.9564,  0.5724,  1.0470],\n",
            "        [-2.1272,  1.2094,  0.3707],\n",
            "        [-2.1567,  1.7640, -0.0174],\n",
            "        [-1.3445,  1.4774, -0.5061],\n",
            "        [-1.7895,  1.7644, -0.0460],\n",
            "        [-1.3003,  1.2155, -0.3857],\n",
            "        [ 0.0726,  0.4491, -1.0450],\n",
            "        [-1.5117,  1.4972, -0.1928],\n",
            "        [ 0.0702,  0.4610, -0.8497]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9680,  1.0076,  0.7110],\n",
            "        [-2.0108,  1.7003,  0.1266],\n",
            "        [-2.1008,  0.5764,  1.2419],\n",
            "        [-0.1937,  0.4258, -0.6580],\n",
            "        [-1.4765,  1.4540, -0.2391],\n",
            "        [-1.6448,  1.4945, -0.0344],\n",
            "        [-2.0368,  0.3880,  0.9560],\n",
            "        [-1.8123,  1.7368,  0.0339],\n",
            "        [-2.0459,  1.7589, -0.0740],\n",
            "        [-1.8791,  1.6231, -0.0909],\n",
            "        [-1.6988,  1.9049, -0.2524],\n",
            "        [-1.7572,  1.3740,  0.0399],\n",
            "        [-1.8872,  1.6421, -0.0355],\n",
            "        [-2.2634,  1.2957,  0.3201],\n",
            "        [-1.9051,  1.9290,  0.0443],\n",
            "        [-1.9209,  0.5007,  1.1036]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9680,  1.0076,  0.7110],\n",
            "        [-2.0108,  1.7003,  0.1266],\n",
            "        [-2.1008,  0.5764,  1.2419],\n",
            "        [-0.1937,  0.4258, -0.6580],\n",
            "        [-1.4765,  1.4540, -0.2391],\n",
            "        [-1.6448,  1.4945, -0.0344],\n",
            "        [-2.0368,  0.3880,  0.9560],\n",
            "        [-1.8123,  1.7368,  0.0339],\n",
            "        [-2.0459,  1.7589, -0.0740],\n",
            "        [-1.8791,  1.6231, -0.0909],\n",
            "        [-1.6988,  1.9049, -0.2524],\n",
            "        [-1.7572,  1.3740,  0.0399],\n",
            "        [-1.8872,  1.6421, -0.0355],\n",
            "        [-2.2634,  1.2957,  0.3201],\n",
            "        [-1.9051,  1.9290,  0.0443],\n",
            "        [-1.9209,  0.5007,  1.1036]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6825,  1.5395, -0.0678],\n",
            "        [-2.2996,  1.4369,  0.2242],\n",
            "        [-1.8487,  1.2347,  0.5672],\n",
            "        [ 0.3789, -0.0330, -0.9931],\n",
            "        [-1.6918,  1.8080, -0.1860],\n",
            "        [-1.8046,  1.5112, -0.2935],\n",
            "        [-1.6130,  1.0512,  0.3293],\n",
            "        [-2.1008,  1.3963,  0.3071],\n",
            "        [ 0.2869,  0.1972, -0.8933],\n",
            "        [-2.0431,  1.1523,  0.5678],\n",
            "        [-2.1712,  1.0084,  0.9933],\n",
            "        [-1.9742,  0.5090,  0.9714],\n",
            "        [-2.0596,  1.2941,  0.5765],\n",
            "        [-1.5263,  1.0797,  0.0525],\n",
            "        [-1.8429,  1.3291,  0.0243],\n",
            "        [-0.8968,  1.0144, -0.6456]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6825,  1.5395, -0.0678],\n",
            "        [-2.2996,  1.4369,  0.2242],\n",
            "        [-1.8487,  1.2347,  0.5672],\n",
            "        [ 0.3789, -0.0330, -0.9931],\n",
            "        [-1.6918,  1.8080, -0.1860],\n",
            "        [-1.8046,  1.5112, -0.2935],\n",
            "        [-1.6130,  1.0512,  0.3293],\n",
            "        [-2.1008,  1.3963,  0.3071],\n",
            "        [ 0.2869,  0.1972, -0.8933],\n",
            "        [-2.0431,  1.1523,  0.5678],\n",
            "        [-2.1712,  1.0084,  0.9933],\n",
            "        [-1.9742,  0.5090,  0.9714],\n",
            "        [-2.0596,  1.2941,  0.5765],\n",
            "        [-1.5263,  1.0797,  0.0525],\n",
            "        [-1.8429,  1.3291,  0.0243],\n",
            "        [-0.8968,  1.0144, -0.6456]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2506,  1.3120,  0.4991],\n",
            "        [-1.9895,  1.1160,  0.2085],\n",
            "        [-1.6726,  0.4690,  0.8600],\n",
            "        [-2.0388,  1.2898,  0.5152],\n",
            "        [-1.9939,  1.3771,  0.2646],\n",
            "        [-1.5869,  1.5342, -0.3130],\n",
            "        [-1.8967,  0.1897,  1.1269],\n",
            "        [-1.7729,  0.2877,  1.0380],\n",
            "        [-1.7016,  0.3462,  1.0169],\n",
            "        [-1.7091,  1.6189,  0.0821],\n",
            "        [ 0.4552,  0.2810, -1.1331],\n",
            "        [-2.1216,  1.3714,  0.1336],\n",
            "        [-1.4630,  1.4112, -0.1254],\n",
            "        [ 0.4686, -0.0261, -0.8961],\n",
            "        [-1.8095,  1.6762, -0.0553],\n",
            "        [-2.0339,  0.8945,  0.9589]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.2506,  1.3120,  0.4991],\n",
            "        [-1.9895,  1.1160,  0.2085],\n",
            "        [-1.6726,  0.4690,  0.8600],\n",
            "        [-2.0388,  1.2898,  0.5152],\n",
            "        [-1.9939,  1.3771,  0.2646],\n",
            "        [-1.5869,  1.5342, -0.3130],\n",
            "        [-1.8967,  0.1897,  1.1269],\n",
            "        [-1.7729,  0.2877,  1.0380],\n",
            "        [-1.7016,  0.3462,  1.0169],\n",
            "        [-1.7091,  1.6189,  0.0821],\n",
            "        [ 0.4552,  0.2810, -1.1331],\n",
            "        [-2.1216,  1.3714,  0.1336],\n",
            "        [-1.4630,  1.4112, -0.1254],\n",
            "        [ 0.4686, -0.0261, -0.8961],\n",
            "        [-1.8095,  1.6762, -0.0553],\n",
            "        [-2.0339,  0.8945,  0.9589]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5531,  1.7348, -0.3591],\n",
            "        [ 0.3054, -0.0077, -0.9494],\n",
            "        [-0.2666,  0.6412, -0.8432],\n",
            "        [-1.7674,  1.4206, -0.1860],\n",
            "        [-2.0025,  1.1007,  0.6408],\n",
            "        [-2.0228,  0.4424,  1.0205],\n",
            "        [-1.7104,  1.7505, -0.1631],\n",
            "        [-1.8808,  1.6186, -0.0944],\n",
            "        [ 0.3867, -0.1134, -0.9485],\n",
            "        [-2.1851,  1.0836,  0.6771],\n",
            "        [-1.9213,  0.5509,  0.9053],\n",
            "        [-0.0534,  0.3766, -0.8946],\n",
            "        [-1.8776,  1.5840, -0.1584],\n",
            "        [ 0.0284,  0.2467, -0.9474],\n",
            "        [ 0.3481,  0.0124, -0.7146],\n",
            "        [-1.8992,  0.9368,  0.4645]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5531,  1.7348, -0.3591],\n",
            "        [ 0.3054, -0.0077, -0.9494],\n",
            "        [-0.2666,  0.6412, -0.8432],\n",
            "        [-1.7674,  1.4206, -0.1860],\n",
            "        [-2.0025,  1.1007,  0.6408],\n",
            "        [-2.0228,  0.4424,  1.0205],\n",
            "        [-1.7104,  1.7505, -0.1631],\n",
            "        [-1.8808,  1.6186, -0.0944],\n",
            "        [ 0.3867, -0.1134, -0.9485],\n",
            "        [-2.1851,  1.0836,  0.6771],\n",
            "        [-1.9213,  0.5509,  0.9053],\n",
            "        [-0.0534,  0.3766, -0.8946],\n",
            "        [-1.8776,  1.5840, -0.1584],\n",
            "        [ 0.0284,  0.2467, -0.9474],\n",
            "        [ 0.3481,  0.0124, -0.7146],\n",
            "        [-1.8992,  0.9368,  0.4645]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6481,  1.6352, -0.2957],\n",
            "        [-1.9631,  1.4994,  0.2981],\n",
            "        [-1.5491,  1.1086,  0.2300],\n",
            "        [-1.8973,  1.5566, -0.0588],\n",
            "        [-1.7790,  1.5539,  0.1366],\n",
            "        [-0.9257,  1.0216, -0.4392],\n",
            "        [-1.9018,  1.4440,  0.2721],\n",
            "        [-1.6586,  0.3714,  1.0444],\n",
            "        [-1.6601,  1.7457, -0.2582],\n",
            "        [ 0.4393, -0.0611, -0.9682],\n",
            "        [-1.9924,  1.4067,  0.1905],\n",
            "        [-1.5189,  1.5694, -0.3049],\n",
            "        [-1.8023,  1.5746, -0.2943],\n",
            "        [-1.8835,  1.3636, -0.0769],\n",
            "        [-2.1459,  1.1378,  0.4839],\n",
            "        [-2.1272,  1.4915,  0.2959]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6481,  1.6352, -0.2957],\n",
            "        [-1.9631,  1.4994,  0.2981],\n",
            "        [-1.5491,  1.1086,  0.2300],\n",
            "        [-1.8973,  1.5566, -0.0588],\n",
            "        [-1.7790,  1.5539,  0.1366],\n",
            "        [-0.9257,  1.0216, -0.4392],\n",
            "        [-1.9018,  1.4440,  0.2721],\n",
            "        [-1.6586,  0.3714,  1.0444],\n",
            "        [-1.6601,  1.7457, -0.2582],\n",
            "        [ 0.4393, -0.0611, -0.9682],\n",
            "        [-1.9924,  1.4067,  0.1905],\n",
            "        [-1.5189,  1.5694, -0.3049],\n",
            "        [-1.8023,  1.5746, -0.2943],\n",
            "        [-1.8835,  1.3636, -0.0769],\n",
            "        [-2.1459,  1.1378,  0.4839],\n",
            "        [-2.1272,  1.4915,  0.2959]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7030,  1.5949, -0.2490],\n",
            "        [-1.7295,  1.8265, -0.1417],\n",
            "        [-1.9773,  1.2351,  0.4184],\n",
            "        [-1.5281,  0.5793,  0.5152],\n",
            "        [-2.2141,  0.9186,  0.8656],\n",
            "        [ 0.3650,  0.0457, -1.0428],\n",
            "        [-1.4780,  1.2289, -0.1320],\n",
            "        [-1.4170,  1.7169, -0.2941],\n",
            "        [-1.6790,  1.5279, -0.1742],\n",
            "        [ 0.4215,  0.1363, -0.8381],\n",
            "        [ 0.5759, -0.0372, -1.1097],\n",
            "        [-2.1263,  0.6578,  0.7944],\n",
            "        [-2.3422,  1.6028,  0.2962],\n",
            "        [ 0.3367, -0.0103, -0.8541],\n",
            "        [-0.8324,  0.4251, -0.0777],\n",
            "        [-2.1144,  0.6001,  1.0192]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7030,  1.5949, -0.2490],\n",
            "        [-1.7295,  1.8265, -0.1417],\n",
            "        [-1.9773,  1.2351,  0.4184],\n",
            "        [-1.5281,  0.5793,  0.5152],\n",
            "        [-2.2141,  0.9186,  0.8656],\n",
            "        [ 0.3650,  0.0457, -1.0428],\n",
            "        [-1.4780,  1.2289, -0.1320],\n",
            "        [-1.4170,  1.7169, -0.2941],\n",
            "        [-1.6790,  1.5279, -0.1742],\n",
            "        [ 0.4215,  0.1363, -0.8381],\n",
            "        [ 0.5759, -0.0372, -1.1097],\n",
            "        [-2.1263,  0.6578,  0.7944],\n",
            "        [-2.3422,  1.6028,  0.2962],\n",
            "        [ 0.3367, -0.0103, -0.8541],\n",
            "        [-0.8324,  0.4251, -0.0777],\n",
            "        [-2.1144,  0.6001,  1.0192]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2026e+00,  7.8478e-01,  9.4017e-01],\n",
            "        [-1.9702e+00,  1.3964e+00,  2.3825e-01],\n",
            "        [ 1.3158e-01,  3.5358e-01, -9.5030e-01],\n",
            "        [-1.2767e-01,  4.6840e-01, -9.0016e-01],\n",
            "        [-2.2358e+00,  1.0165e+00,  7.1087e-01],\n",
            "        [ 3.4404e-01,  3.1044e-01, -1.0395e+00],\n",
            "        [-2.1681e+00,  1.6850e+00,  3.1116e-01],\n",
            "        [-1.8588e+00,  1.6093e+00,  2.8002e-02],\n",
            "        [-1.8152e+00,  1.4223e+00,  1.1178e-02],\n",
            "        [-1.8930e+00,  1.4321e+00,  2.2762e-03],\n",
            "        [-2.0251e+00,  1.2643e+00,  2.5583e-01],\n",
            "        [-1.9793e+00,  1.2001e+00,  6.0797e-01],\n",
            "        [-2.0379e+00,  1.4379e+00,  4.1150e-01],\n",
            "        [-1.8087e+00,  1.5697e+00,  8.6610e-02],\n",
            "        [-2.3313e+00,  1.6212e+00,  4.6631e-02],\n",
            "        [-1.8249e+00,  4.5793e-01,  9.8432e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.2026e+00,  7.8478e-01,  9.4017e-01],\n",
            "        [-1.9702e+00,  1.3964e+00,  2.3825e-01],\n",
            "        [ 1.3158e-01,  3.5358e-01, -9.5030e-01],\n",
            "        [-1.2767e-01,  4.6840e-01, -9.0016e-01],\n",
            "        [-2.2358e+00,  1.0165e+00,  7.1087e-01],\n",
            "        [ 3.4404e-01,  3.1044e-01, -1.0395e+00],\n",
            "        [-2.1681e+00,  1.6850e+00,  3.1116e-01],\n",
            "        [-1.8588e+00,  1.6093e+00,  2.8002e-02],\n",
            "        [-1.8152e+00,  1.4223e+00,  1.1178e-02],\n",
            "        [-1.8930e+00,  1.4321e+00,  2.2762e-03],\n",
            "        [-2.0251e+00,  1.2643e+00,  2.5583e-01],\n",
            "        [-1.9793e+00,  1.2001e+00,  6.0797e-01],\n",
            "        [-2.0379e+00,  1.4379e+00,  4.1150e-01],\n",
            "        [-1.8087e+00,  1.5697e+00,  8.6610e-02],\n",
            "        [-2.3313e+00,  1.6212e+00,  4.6631e-02],\n",
            "        [-1.8249e+00,  4.5793e-01,  9.8432e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.4124,  1.2846,  0.6857],\n",
            "        [-1.8028,  1.3500, -0.0758],\n",
            "        [-2.1848,  1.0047,  0.6597],\n",
            "        [-1.6880,  1.4142,  0.2404],\n",
            "        [-2.1074,  1.3313,  0.4990],\n",
            "        [-1.9188,  1.5059,  0.4770],\n",
            "        [-2.0976,  1.6097,  0.4881],\n",
            "        [-1.6169,  1.6240,  0.1039],\n",
            "        [-1.8440,  1.2097,  0.3961],\n",
            "        [-2.2177,  0.7754,  0.8486],\n",
            "        [-2.0818,  1.1875,  0.6408],\n",
            "        [-1.6801,  1.5328, -0.0654],\n",
            "        [-1.2698,  1.4023, -0.4753],\n",
            "        [-1.7524,  1.3702,  0.0542],\n",
            "        [-1.7128,  1.3559, -0.0474],\n",
            "        [-1.4300,  1.2955, -0.0620]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.4124,  1.2846,  0.6857],\n",
            "        [-1.8028,  1.3500, -0.0758],\n",
            "        [-2.1848,  1.0047,  0.6597],\n",
            "        [-1.6880,  1.4142,  0.2404],\n",
            "        [-2.1074,  1.3313,  0.4990],\n",
            "        [-1.9188,  1.5059,  0.4770],\n",
            "        [-2.0976,  1.6097,  0.4881],\n",
            "        [-1.6169,  1.6240,  0.1039],\n",
            "        [-1.8440,  1.2097,  0.3961],\n",
            "        [-2.2177,  0.7754,  0.8486],\n",
            "        [-2.0818,  1.1875,  0.6408],\n",
            "        [-1.6801,  1.5328, -0.0654],\n",
            "        [-1.2698,  1.4023, -0.4753],\n",
            "        [-1.7524,  1.3702,  0.0542],\n",
            "        [-1.7128,  1.3559, -0.0474],\n",
            "        [-1.4300,  1.2955, -0.0620]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7993,  1.4972,  0.0309],\n",
            "        [-2.2965,  1.1838,  0.6829],\n",
            "        [-0.4948,  0.8397, -0.6195],\n",
            "        [-2.0422,  0.7085,  1.0508],\n",
            "        [-0.3262,  0.4632, -0.4354],\n",
            "        [-2.4930,  1.3647,  0.6164],\n",
            "        [ 0.4091, -0.0455, -0.8811],\n",
            "        [-1.9165,  1.5976, -0.2146],\n",
            "        [-1.9766,  1.2294,  0.4164],\n",
            "        [ 0.0040,  0.4809, -0.7295],\n",
            "        [-2.0419,  1.2230,  0.5695],\n",
            "        [-1.8514,  1.3950, -0.1196],\n",
            "        [ 0.5184,  0.0813, -0.9102],\n",
            "        [-1.9056,  0.7753,  0.9141],\n",
            "        [-1.8222,  0.7731,  0.9787],\n",
            "        [-1.6657,  1.5609,  0.0198]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7993,  1.4972,  0.0309],\n",
            "        [-2.2965,  1.1838,  0.6829],\n",
            "        [-0.4948,  0.8397, -0.6195],\n",
            "        [-2.0422,  0.7085,  1.0508],\n",
            "        [-0.3262,  0.4632, -0.4354],\n",
            "        [-2.4930,  1.3647,  0.6164],\n",
            "        [ 0.4091, -0.0455, -0.8811],\n",
            "        [-1.9165,  1.5976, -0.2146],\n",
            "        [-1.9766,  1.2294,  0.4164],\n",
            "        [ 0.0040,  0.4809, -0.7295],\n",
            "        [-2.0419,  1.2230,  0.5695],\n",
            "        [-1.8514,  1.3950, -0.1196],\n",
            "        [ 0.5184,  0.0813, -0.9102],\n",
            "        [-1.9056,  0.7753,  0.9141],\n",
            "        [-1.8222,  0.7731,  0.9787],\n",
            "        [-1.6657,  1.5609,  0.0198]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3968,  1.2937, -0.1311],\n",
            "        [-2.0710,  1.0570,  0.4677],\n",
            "        [-1.4146,  1.3578, -0.1908],\n",
            "        [-1.8834,  0.6231,  0.8630],\n",
            "        [-1.5718,  1.1395, -0.1479],\n",
            "        [-2.0315,  1.6150,  0.2095],\n",
            "        [-1.7276,  0.2971,  0.9305],\n",
            "        [-1.8157,  1.5717,  0.0592],\n",
            "        [-1.2067,  1.6200, -0.2811],\n",
            "        [-1.2935,  0.7521,  0.2244],\n",
            "        [-1.5258,  1.3332, -0.1748],\n",
            "        [-1.6795,  1.2923,  0.2303],\n",
            "        [-2.2193,  0.9275,  1.0426],\n",
            "        [-0.8913,  1.1886, -0.8016],\n",
            "        [-1.7305,  1.3322,  0.1728],\n",
            "        [-1.5796,  0.7858,  0.2914]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3968,  1.2937, -0.1311],\n",
            "        [-2.0710,  1.0570,  0.4677],\n",
            "        [-1.4146,  1.3578, -0.1908],\n",
            "        [-1.8834,  0.6231,  0.8630],\n",
            "        [-1.5718,  1.1395, -0.1479],\n",
            "        [-2.0315,  1.6150,  0.2095],\n",
            "        [-1.7276,  0.2971,  0.9305],\n",
            "        [-1.8157,  1.5717,  0.0592],\n",
            "        [-1.2067,  1.6200, -0.2811],\n",
            "        [-1.2935,  0.7521,  0.2244],\n",
            "        [-1.5258,  1.3332, -0.1748],\n",
            "        [-1.6795,  1.2923,  0.2303],\n",
            "        [-2.2193,  0.9275,  1.0426],\n",
            "        [-0.8913,  1.1886, -0.8016],\n",
            "        [-1.7305,  1.3322,  0.1728],\n",
            "        [-1.5796,  0.7858,  0.2914]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.2949, -0.0353, -0.9060],\n",
            "        [-1.4809,  1.2609,  0.0080],\n",
            "        [-2.1235,  1.5603,  0.3231],\n",
            "        [-1.9352,  1.5274,  0.0348],\n",
            "        [-1.8600,  1.5229,  0.1648],\n",
            "        [-1.9876,  1.3464,  0.2469],\n",
            "        [-1.8078,  0.9841,  0.5350],\n",
            "        [-1.6115,  1.2840, -0.0586],\n",
            "        [-1.8178,  1.3468,  0.3814],\n",
            "        [ 0.2792,  0.1360, -0.9413],\n",
            "        [-1.9685,  0.5677,  1.1617],\n",
            "        [-2.0464,  0.9119,  0.7198],\n",
            "        [ 0.2926,  0.1165, -0.9106],\n",
            "        [-1.5272,  1.2775, -0.1740],\n",
            "        [-1.7108,  1.2761,  0.1806],\n",
            "        [-1.9620,  1.4867,  0.0507]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.2949, -0.0353, -0.9060],\n",
            "        [-1.4809,  1.2609,  0.0080],\n",
            "        [-2.1235,  1.5603,  0.3231],\n",
            "        [-1.9352,  1.5274,  0.0348],\n",
            "        [-1.8600,  1.5229,  0.1648],\n",
            "        [-1.9876,  1.3464,  0.2469],\n",
            "        [-1.8078,  0.9841,  0.5350],\n",
            "        [-1.6115,  1.2840, -0.0586],\n",
            "        [-1.8178,  1.3468,  0.3814],\n",
            "        [ 0.2792,  0.1360, -0.9413],\n",
            "        [-1.9685,  0.5677,  1.1617],\n",
            "        [-2.0464,  0.9119,  0.7198],\n",
            "        [ 0.2926,  0.1165, -0.9106],\n",
            "        [-1.5272,  1.2775, -0.1740],\n",
            "        [-1.7108,  1.2761,  0.1806],\n",
            "        [-1.9620,  1.4867,  0.0507]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.1328,  0.1523, -0.6214],\n",
            "        [-1.7005,  1.3099,  0.2880],\n",
            "        [-1.8501,  0.5710,  0.9457],\n",
            "        [-2.0052,  0.5493,  1.0234],\n",
            "        [-1.8300,  0.7927,  0.8858],\n",
            "        [-1.3701,  0.7549,  0.3592],\n",
            "        [-2.0148,  1.2070,  0.2099],\n",
            "        [-1.2903,  1.2003, -0.0716],\n",
            "        [-2.0446,  0.5562,  0.8467],\n",
            "        [-1.7712,  1.9766, -0.0951],\n",
            "        [ 0.2980,  0.2074, -0.9178],\n",
            "        [-2.0644,  1.5834,  0.1297],\n",
            "        [-2.0355,  1.5966,  0.1695],\n",
            "        [-2.0816,  1.1746,  0.3903],\n",
            "        [-1.7721,  1.3085,  0.0588],\n",
            "        [ 0.3750,  0.0516, -0.8968]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.1328,  0.1523, -0.6214],\n",
            "        [-1.7005,  1.3099,  0.2880],\n",
            "        [-1.8501,  0.5710,  0.9457],\n",
            "        [-2.0052,  0.5493,  1.0234],\n",
            "        [-1.8300,  0.7927,  0.8858],\n",
            "        [-1.3701,  0.7549,  0.3592],\n",
            "        [-2.0148,  1.2070,  0.2099],\n",
            "        [-1.2903,  1.2003, -0.0716],\n",
            "        [-2.0446,  0.5562,  0.8467],\n",
            "        [-1.7712,  1.9766, -0.0951],\n",
            "        [ 0.2980,  0.2074, -0.9178],\n",
            "        [-2.0644,  1.5834,  0.1297],\n",
            "        [-2.0355,  1.5966,  0.1695],\n",
            "        [-2.0816,  1.1746,  0.3903],\n",
            "        [-1.7721,  1.3085,  0.0588],\n",
            "        [ 0.3750,  0.0516, -0.8968]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1491e+00,  1.6023e+00,  1.3924e-01],\n",
            "        [-1.9703e+00,  1.2094e+00,  6.4100e-01],\n",
            "        [-1.4648e+00,  1.4833e+00, -9.2048e-03],\n",
            "        [-1.5037e+00,  1.4628e+00, -1.0687e-01],\n",
            "        [-1.7461e+00,  1.6036e+00,  3.2691e-01],\n",
            "        [-1.4136e+00,  1.4119e+00, -3.1461e-01],\n",
            "        [-1.8982e+00,  4.0869e-01,  9.6476e-01],\n",
            "        [-1.4748e+00,  1.4360e+00,  9.4396e-04],\n",
            "        [-1.8026e+00,  6.3234e-01,  1.1372e+00],\n",
            "        [-2.0506e+00,  9.6225e-01,  5.4069e-01],\n",
            "        [-1.2849e+00,  1.2566e+00, -2.4742e-01],\n",
            "        [-1.5317e+00,  1.7782e+00, -4.2399e-01],\n",
            "        [-1.4349e+00,  1.1619e+00, -6.1875e-02],\n",
            "        [-1.8628e+00,  1.4725e+00,  1.2070e-01],\n",
            "        [-1.9454e+00,  3.2478e-01,  9.1072e-01],\n",
            "        [-2.0558e+00,  1.3191e+00,  3.5409e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1491e+00,  1.6023e+00,  1.3924e-01],\n",
            "        [-1.9703e+00,  1.2094e+00,  6.4100e-01],\n",
            "        [-1.4648e+00,  1.4833e+00, -9.2048e-03],\n",
            "        [-1.5037e+00,  1.4628e+00, -1.0687e-01],\n",
            "        [-1.7461e+00,  1.6036e+00,  3.2691e-01],\n",
            "        [-1.4136e+00,  1.4119e+00, -3.1461e-01],\n",
            "        [-1.8982e+00,  4.0869e-01,  9.6476e-01],\n",
            "        [-1.4748e+00,  1.4360e+00,  9.4396e-04],\n",
            "        [-1.8026e+00,  6.3234e-01,  1.1372e+00],\n",
            "        [-2.0506e+00,  9.6225e-01,  5.4069e-01],\n",
            "        [-1.2849e+00,  1.2566e+00, -2.4742e-01],\n",
            "        [-1.5317e+00,  1.7782e+00, -4.2399e-01],\n",
            "        [-1.4349e+00,  1.1619e+00, -6.1875e-02],\n",
            "        [-1.8628e+00,  1.4725e+00,  1.2070e-01],\n",
            "        [-1.9454e+00,  3.2478e-01,  9.1072e-01],\n",
            "        [-2.0558e+00,  1.3191e+00,  3.5409e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5407,  1.0414,  0.1383],\n",
            "        [-2.0983,  1.4852,  0.2083],\n",
            "        [-1.9726,  1.5567,  0.1756],\n",
            "        [-1.5318,  1.2376, -0.0421],\n",
            "        [-1.7535,  1.3428,  0.2127],\n",
            "        [-1.7863,  1.5544,  0.0601],\n",
            "        [-2.0149,  0.7828,  0.7990],\n",
            "        [-1.8073,  1.5522, -0.0114],\n",
            "        [-1.6612,  1.4085,  0.1592],\n",
            "        [-1.7907,  1.3830,  0.0553],\n",
            "        [-1.4371,  1.2280, -0.1564],\n",
            "        [-1.7240,  0.7384,  0.7239],\n",
            "        [-1.6621,  1.4913, -0.2311],\n",
            "        [-1.4830,  1.2453, -0.2940],\n",
            "        [ 0.4539, -0.1449, -0.7420],\n",
            "        [-1.4559,  1.1877,  0.1413]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5407,  1.0414,  0.1383],\n",
            "        [-2.0983,  1.4852,  0.2083],\n",
            "        [-1.9726,  1.5567,  0.1756],\n",
            "        [-1.5318,  1.2376, -0.0421],\n",
            "        [-1.7535,  1.3428,  0.2127],\n",
            "        [-1.7863,  1.5544,  0.0601],\n",
            "        [-2.0149,  0.7828,  0.7990],\n",
            "        [-1.8073,  1.5522, -0.0114],\n",
            "        [-1.6612,  1.4085,  0.1592],\n",
            "        [-1.7907,  1.3830,  0.0553],\n",
            "        [-1.4371,  1.2280, -0.1564],\n",
            "        [-1.7240,  0.7384,  0.7239],\n",
            "        [-1.6621,  1.4913, -0.2311],\n",
            "        [-1.4830,  1.2453, -0.2940],\n",
            "        [ 0.4539, -0.1449, -0.7420],\n",
            "        [-1.4559,  1.1877,  0.1413]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9768,  0.4685,  1.0646],\n",
            "        [-1.8344,  1.3127,  0.0957],\n",
            "        [-1.7173,  1.3740, -0.0447],\n",
            "        [-1.0946,  1.2646, -0.2473],\n",
            "        [ 0.2397, -0.0587, -0.8147],\n",
            "        [-1.7795,  0.8479,  0.7190],\n",
            "        [-1.9804,  0.6084,  1.2400],\n",
            "        [-1.7694,  1.3991, -0.0653],\n",
            "        [-1.7685,  0.4952,  0.8929],\n",
            "        [-1.8329,  0.4614,  1.1261],\n",
            "        [-1.3426,  1.2483, -0.0406],\n",
            "        [-1.8782,  1.4180,  0.0205],\n",
            "        [-1.7436,  1.4271, -0.0123],\n",
            "        [-1.9834,  0.9168,  0.7730],\n",
            "        [-2.0323,  0.5325,  1.0357],\n",
            "        [-1.6242,  1.7057, -0.0417]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9768,  0.4685,  1.0646],\n",
            "        [-1.8344,  1.3127,  0.0957],\n",
            "        [-1.7173,  1.3740, -0.0447],\n",
            "        [-1.0946,  1.2646, -0.2473],\n",
            "        [ 0.2397, -0.0587, -0.8147],\n",
            "        [-1.7795,  0.8479,  0.7190],\n",
            "        [-1.9804,  0.6084,  1.2400],\n",
            "        [-1.7694,  1.3991, -0.0653],\n",
            "        [-1.7685,  0.4952,  0.8929],\n",
            "        [-1.8329,  0.4614,  1.1261],\n",
            "        [-1.3426,  1.2483, -0.0406],\n",
            "        [-1.8782,  1.4180,  0.0205],\n",
            "        [-1.7436,  1.4271, -0.0123],\n",
            "        [-1.9834,  0.9168,  0.7730],\n",
            "        [-2.0323,  0.5325,  1.0357],\n",
            "        [-1.6242,  1.7057, -0.0417]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1737,  0.5648,  1.1256],\n",
            "        [ 0.1421,  0.4352, -0.7538],\n",
            "        [-0.3496,  0.8832, -0.9682],\n",
            "        [-1.7526,  0.8965,  0.6240],\n",
            "        [-1.5874,  1.0301,  0.0455],\n",
            "        [-1.6969,  0.6895,  0.8503],\n",
            "        [-1.0139,  0.9557,  0.0159],\n",
            "        [-1.4640,  1.6553, -0.2845],\n",
            "        [ 0.3993,  0.0773, -0.7615],\n",
            "        [ 0.4883, -0.0489, -0.8049],\n",
            "        [-1.9863,  1.1868,  0.4008],\n",
            "        [-1.5445,  1.4678, -0.0084],\n",
            "        [-1.7052,  0.5622,  0.9239],\n",
            "        [-2.3387,  0.8512,  1.0229],\n",
            "        [-1.8207,  1.0305,  0.3225],\n",
            "        [-1.6242,  1.1162, -0.0694]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1737,  0.5648,  1.1256],\n",
            "        [ 0.1421,  0.4352, -0.7538],\n",
            "        [-0.3496,  0.8832, -0.9682],\n",
            "        [-1.7526,  0.8965,  0.6240],\n",
            "        [-1.5874,  1.0301,  0.0455],\n",
            "        [-1.6969,  0.6895,  0.8503],\n",
            "        [-1.0139,  0.9557,  0.0159],\n",
            "        [-1.4640,  1.6553, -0.2845],\n",
            "        [ 0.3993,  0.0773, -0.7615],\n",
            "        [ 0.4883, -0.0489, -0.8049],\n",
            "        [-1.9863,  1.1868,  0.4008],\n",
            "        [-1.5445,  1.4678, -0.0084],\n",
            "        [-1.7052,  0.5622,  0.9239],\n",
            "        [-2.3387,  0.8512,  1.0229],\n",
            "        [-1.8207,  1.0305,  0.3225],\n",
            "        [-1.6242,  1.1162, -0.0694]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.0788,  1.3498, -0.4431],\n",
            "        [-1.7284,  1.6353, -0.3045],\n",
            "        [-1.5816,  1.5156, -0.1686],\n",
            "        [-1.6171,  1.1364,  0.3574],\n",
            "        [-1.5271,  1.4904,  0.0419],\n",
            "        [-1.8009,  0.3849,  0.9977],\n",
            "        [-1.5553,  1.4328, -0.1645],\n",
            "        [ 0.6359, -0.0747, -0.8079],\n",
            "        [-1.3873,  1.2456, -0.2708],\n",
            "        [-1.5880,  1.2441, -0.1748],\n",
            "        [-1.5231,  0.3273,  1.1142],\n",
            "        [-1.3785,  1.1645, -0.3824],\n",
            "        [-1.8323,  0.5910,  0.7492],\n",
            "        [-1.5661,  1.4215, -0.0129],\n",
            "        [-1.5611,  0.3172,  0.8050],\n",
            "        [-1.8986,  0.7828,  0.7348]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.0788,  1.3498, -0.4431],\n",
            "        [-1.7284,  1.6353, -0.3045],\n",
            "        [-1.5816,  1.5156, -0.1686],\n",
            "        [-1.6171,  1.1364,  0.3574],\n",
            "        [-1.5271,  1.4904,  0.0419],\n",
            "        [-1.8009,  0.3849,  0.9977],\n",
            "        [-1.5553,  1.4328, -0.1645],\n",
            "        [ 0.6359, -0.0747, -0.8079],\n",
            "        [-1.3873,  1.2456, -0.2708],\n",
            "        [-1.5880,  1.2441, -0.1748],\n",
            "        [-1.5231,  0.3273,  1.1142],\n",
            "        [-1.3785,  1.1645, -0.3824],\n",
            "        [-1.8323,  0.5910,  0.7492],\n",
            "        [-1.5661,  1.4215, -0.0129],\n",
            "        [-1.5611,  0.3172,  0.8050],\n",
            "        [-1.8986,  0.7828,  0.7348]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5079e+00,  1.3078e+00, -2.3452e-01],\n",
            "        [-1.8150e+00,  9.5841e-01,  6.3561e-01],\n",
            "        [-1.7785e+00,  1.5858e+00, -4.6734e-01],\n",
            "        [-1.8000e-03,  4.4577e-01, -1.0783e+00],\n",
            "        [-2.0593e+00,  1.0961e+00,  3.7491e-01],\n",
            "        [-1.7226e+00,  1.4564e+00, -3.3064e-02],\n",
            "        [-1.9063e+00,  3.9351e-01,  1.0155e+00],\n",
            "        [-1.6079e+00,  1.3672e+00, -1.0490e-01],\n",
            "        [-1.1492e+00,  5.7279e-01,  4.8708e-01],\n",
            "        [-1.4987e+00,  1.4578e+00, -2.3348e-01],\n",
            "        [ 3.5714e-01,  3.6234e-02, -7.6356e-01],\n",
            "        [-1.1463e+00,  1.3023e+00, -3.0967e-01],\n",
            "        [-1.7336e+00,  1.5910e+00, -9.6977e-02],\n",
            "        [-1.5392e+00,  1.2648e+00, -2.6235e-01],\n",
            "        [-1.5006e+00,  1.3090e+00, -8.5506e-02],\n",
            "        [-1.6735e+00,  1.5506e+00,  5.2781e-02]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5079e+00,  1.3078e+00, -2.3452e-01],\n",
            "        [-1.8150e+00,  9.5841e-01,  6.3561e-01],\n",
            "        [-1.7785e+00,  1.5858e+00, -4.6734e-01],\n",
            "        [-1.8000e-03,  4.4577e-01, -1.0783e+00],\n",
            "        [-2.0593e+00,  1.0961e+00,  3.7491e-01],\n",
            "        [-1.7226e+00,  1.4564e+00, -3.3064e-02],\n",
            "        [-1.9063e+00,  3.9351e-01,  1.0155e+00],\n",
            "        [-1.6079e+00,  1.3672e+00, -1.0490e-01],\n",
            "        [-1.1492e+00,  5.7279e-01,  4.8708e-01],\n",
            "        [-1.4987e+00,  1.4578e+00, -2.3348e-01],\n",
            "        [ 3.5714e-01,  3.6234e-02, -7.6356e-01],\n",
            "        [-1.1463e+00,  1.3023e+00, -3.0967e-01],\n",
            "        [-1.7336e+00,  1.5910e+00, -9.6977e-02],\n",
            "        [-1.5392e+00,  1.2648e+00, -2.6235e-01],\n",
            "        [-1.5006e+00,  1.3090e+00, -8.5506e-02],\n",
            "        [-1.6735e+00,  1.5506e+00,  5.2781e-02]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9921,  0.6428,  1.0531],\n",
            "        [-1.5763,  0.7289,  0.5339],\n",
            "        [-1.7620,  1.4955, -0.1881],\n",
            "        [-1.0096,  0.5677,  0.4178],\n",
            "        [-1.8416,  1.1750,  0.3888],\n",
            "        [-1.4494,  1.6961, -0.1015],\n",
            "        [ 0.3821,  0.1131, -0.9870],\n",
            "        [-1.7396,  0.9662,  0.7546],\n",
            "        [-1.9888,  0.7874,  1.0579],\n",
            "        [-2.0298,  0.6453,  1.0247],\n",
            "        [-0.1842,  0.3841, -0.5891],\n",
            "        [-0.2711,  0.4382, -0.6806],\n",
            "        [-1.7888,  0.9493,  0.3755],\n",
            "        [-2.0058,  1.3055,  0.4174],\n",
            "        [-1.9908,  1.7281, -0.2262],\n",
            "        [-0.2562,  0.8534, -0.9246]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9921,  0.6428,  1.0531],\n",
            "        [-1.5763,  0.7289,  0.5339],\n",
            "        [-1.7620,  1.4955, -0.1881],\n",
            "        [-1.0096,  0.5677,  0.4178],\n",
            "        [-1.8416,  1.1750,  0.3888],\n",
            "        [-1.4494,  1.6961, -0.1015],\n",
            "        [ 0.3821,  0.1131, -0.9870],\n",
            "        [-1.7396,  0.9662,  0.7546],\n",
            "        [-1.9888,  0.7874,  1.0579],\n",
            "        [-2.0298,  0.6453,  1.0247],\n",
            "        [-0.1842,  0.3841, -0.5891],\n",
            "        [-0.2711,  0.4382, -0.6806],\n",
            "        [-1.7888,  0.9493,  0.3755],\n",
            "        [-2.0058,  1.3055,  0.4174],\n",
            "        [-1.9908,  1.7281, -0.2262],\n",
            "        [-0.2562,  0.8534, -0.9246]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1137,  0.8680,  0.7887],\n",
            "        [-1.2522,  1.7719, -0.5970],\n",
            "        [-0.9590,  1.1587, -0.5103],\n",
            "        [ 0.4810,  0.0121, -0.9518],\n",
            "        [-2.0209,  0.8255,  0.9415],\n",
            "        [-2.2026,  0.8294,  0.7599],\n",
            "        [-1.4433,  1.4290, -0.2851],\n",
            "        [-1.5034,  1.5639, -0.3057],\n",
            "        [-1.7964,  0.5156,  0.7872],\n",
            "        [-1.9176,  1.1608,  0.3990],\n",
            "        [-0.9095,  0.4037,  0.0771],\n",
            "        [-1.3564,  1.6000, -0.5386],\n",
            "        [-1.2227,  1.4191, -0.4720],\n",
            "        [-2.2992,  0.8093,  0.9689],\n",
            "        [-1.5961,  1.5755, -0.0728],\n",
            "        [-1.5428,  1.7438, -0.4588]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1137,  0.8680,  0.7887],\n",
            "        [-1.2522,  1.7719, -0.5970],\n",
            "        [-0.9590,  1.1587, -0.5103],\n",
            "        [ 0.4810,  0.0121, -0.9518],\n",
            "        [-2.0209,  0.8255,  0.9415],\n",
            "        [-2.2026,  0.8294,  0.7599],\n",
            "        [-1.4433,  1.4290, -0.2851],\n",
            "        [-1.5034,  1.5639, -0.3057],\n",
            "        [-1.7964,  0.5156,  0.7872],\n",
            "        [-1.9176,  1.1608,  0.3990],\n",
            "        [-0.9095,  0.4037,  0.0771],\n",
            "        [-1.3564,  1.6000, -0.5386],\n",
            "        [-1.2227,  1.4191, -0.4720],\n",
            "        [-2.2992,  0.8093,  0.9689],\n",
            "        [-1.5961,  1.5755, -0.0728],\n",
            "        [-1.5428,  1.7438, -0.4588]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3182,  1.4718, -0.4840],\n",
            "        [-1.6578,  0.4504,  1.0398],\n",
            "        [-0.3365,  0.9701, -0.9505],\n",
            "        [-1.4502,  1.4528, -0.4804],\n",
            "        [-1.7047,  1.7349, -0.1063],\n",
            "        [-1.8092,  1.5350, -0.0317],\n",
            "        [-1.6429,  1.5502, -0.2956],\n",
            "        [-1.6288,  1.6832, -0.3330],\n",
            "        [-1.5050,  1.4516, -0.4750],\n",
            "        [-1.8896,  1.6108,  0.1082],\n",
            "        [ 0.4013, -0.1751, -0.8057],\n",
            "        [ 0.5431, -0.1449, -0.8332],\n",
            "        [-1.4239,  1.8479, -0.6227],\n",
            "        [-1.9517,  1.3757,  0.4420],\n",
            "        [-2.2041,  1.2647,  0.6167],\n",
            "        [-1.5313,  1.7563, -0.4046]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3182,  1.4718, -0.4840],\n",
            "        [-1.6578,  0.4504,  1.0398],\n",
            "        [-0.3365,  0.9701, -0.9505],\n",
            "        [-1.4502,  1.4528, -0.4804],\n",
            "        [-1.7047,  1.7349, -0.1063],\n",
            "        [-1.8092,  1.5350, -0.0317],\n",
            "        [-1.6429,  1.5502, -0.2956],\n",
            "        [-1.6288,  1.6832, -0.3330],\n",
            "        [-1.5050,  1.4516, -0.4750],\n",
            "        [-1.8896,  1.6108,  0.1082],\n",
            "        [ 0.4013, -0.1751, -0.8057],\n",
            "        [ 0.5431, -0.1449, -0.8332],\n",
            "        [-1.4239,  1.8479, -0.6227],\n",
            "        [-1.9517,  1.3757,  0.4420],\n",
            "        [-2.2041,  1.2647,  0.6167],\n",
            "        [-1.5313,  1.7563, -0.4046]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1388,  0.5726,  0.8874],\n",
            "        [-2.0844,  1.2122,  0.6429],\n",
            "        [-1.7374,  1.8250, -0.3420],\n",
            "        [-1.7339,  1.4185, -0.2247],\n",
            "        [-1.3862,  1.3636, -0.1346],\n",
            "        [-2.0508,  0.9189,  0.9852],\n",
            "        [-1.6760,  1.8324, -0.3263],\n",
            "        [-1.4415,  0.9347,  0.2968],\n",
            "        [-1.3623,  1.7185, -0.3968],\n",
            "        [-1.9083,  0.4426,  0.9361],\n",
            "        [-1.3277,  1.4158, -0.5804],\n",
            "        [ 0.3070,  0.1045, -0.7338],\n",
            "        [-2.1357,  0.8213,  0.7372],\n",
            "        [-2.1458,  0.7162,  1.1041],\n",
            "        [-1.5214,  1.9138, -0.7235],\n",
            "        [-1.9563,  0.7940,  0.7403]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1388,  0.5726,  0.8874],\n",
            "        [-2.0844,  1.2122,  0.6429],\n",
            "        [-1.7374,  1.8250, -0.3420],\n",
            "        [-1.7339,  1.4185, -0.2247],\n",
            "        [-1.3862,  1.3636, -0.1346],\n",
            "        [-2.0508,  0.9189,  0.9852],\n",
            "        [-1.6760,  1.8324, -0.3263],\n",
            "        [-1.4415,  0.9347,  0.2968],\n",
            "        [-1.3623,  1.7185, -0.3968],\n",
            "        [-1.9083,  0.4426,  0.9361],\n",
            "        [-1.3277,  1.4158, -0.5804],\n",
            "        [ 0.3070,  0.1045, -0.7338],\n",
            "        [-2.1357,  0.8213,  0.7372],\n",
            "        [-2.1458,  0.7162,  1.1041],\n",
            "        [-1.5214,  1.9138, -0.7235],\n",
            "        [-1.9563,  0.7940,  0.7403]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-8.6856e-01,  1.1573e+00, -5.6783e-01],\n",
            "        [-1.5464e+00,  2.0306e+00, -6.6507e-01],\n",
            "        [-1.9758e+00,  6.8754e-01,  8.9163e-01],\n",
            "        [-1.6067e+00,  1.7873e+00, -4.2124e-01],\n",
            "        [-1.5996e+00,  1.9108e+00, -4.2811e-01],\n",
            "        [-1.3531e+00,  1.3971e+00, -2.7992e-01],\n",
            "        [-1.4715e+00,  1.6595e+00, -3.8446e-01],\n",
            "        [-1.5467e+00,  1.8954e+00, -5.1558e-01],\n",
            "        [-1.5699e+00,  1.8837e+00, -5.0411e-01],\n",
            "        [-1.8503e+00,  4.2376e-01,  8.7642e-01],\n",
            "        [-1.7031e+00,  1.6881e+00, -4.4424e-01],\n",
            "        [-1.2198e+00,  1.5837e+00, -5.8833e-01],\n",
            "        [ 4.5165e-01, -2.6162e-01, -8.4401e-01],\n",
            "        [-1.8483e+00,  8.3531e-01,  9.1635e-01],\n",
            "        [-2.0430e+00,  1.8047e+00, -7.5335e-04],\n",
            "        [ 3.6482e-01, -1.6390e-02, -8.5745e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-8.6856e-01,  1.1573e+00, -5.6783e-01],\n",
            "        [-1.5464e+00,  2.0306e+00, -6.6507e-01],\n",
            "        [-1.9758e+00,  6.8754e-01,  8.9163e-01],\n",
            "        [-1.6067e+00,  1.7873e+00, -4.2124e-01],\n",
            "        [-1.5996e+00,  1.9108e+00, -4.2811e-01],\n",
            "        [-1.3531e+00,  1.3971e+00, -2.7992e-01],\n",
            "        [-1.4715e+00,  1.6595e+00, -3.8446e-01],\n",
            "        [-1.5467e+00,  1.8954e+00, -5.1558e-01],\n",
            "        [-1.5699e+00,  1.8837e+00, -5.0411e-01],\n",
            "        [-1.8503e+00,  4.2376e-01,  8.7642e-01],\n",
            "        [-1.7031e+00,  1.6881e+00, -4.4424e-01],\n",
            "        [-1.2198e+00,  1.5837e+00, -5.8833e-01],\n",
            "        [ 4.5165e-01, -2.6162e-01, -8.4401e-01],\n",
            "        [-1.8483e+00,  8.3531e-01,  9.1635e-01],\n",
            "        [-2.0430e+00,  1.8047e+00, -7.5335e-04],\n",
            "        [ 3.6482e-01, -1.6390e-02, -8.5745e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6544,  1.8535, -0.4945],\n",
            "        [-1.1878,  1.6785, -0.6321],\n",
            "        [-1.1818,  1.6488, -0.7015],\n",
            "        [-1.4733,  1.6549, -0.5889],\n",
            "        [-2.0264,  0.6995,  1.2920],\n",
            "        [-1.4492,  1.6586, -0.5599],\n",
            "        [-2.0001,  1.9980, -0.1133],\n",
            "        [-1.8767,  1.0885,  0.4290],\n",
            "        [-2.3973,  0.8504,  0.8332],\n",
            "        [ 0.0591,  0.3409, -1.1022],\n",
            "        [-1.6742,  1.4985, -0.3419],\n",
            "        [ 0.4581,  0.0165, -0.8839],\n",
            "        [-1.6270,  1.8441, -0.3937],\n",
            "        [-1.7463,  2.1133, -0.3617],\n",
            "        [-1.6944,  1.9498, -0.5383],\n",
            "        [-1.9741,  0.5385,  1.1724]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6544,  1.8535, -0.4945],\n",
            "        [-1.1878,  1.6785, -0.6321],\n",
            "        [-1.1818,  1.6488, -0.7015],\n",
            "        [-1.4733,  1.6549, -0.5889],\n",
            "        [-2.0264,  0.6995,  1.2920],\n",
            "        [-1.4492,  1.6586, -0.5599],\n",
            "        [-2.0001,  1.9980, -0.1133],\n",
            "        [-1.8767,  1.0885,  0.4290],\n",
            "        [-2.3973,  0.8504,  0.8332],\n",
            "        [ 0.0591,  0.3409, -1.1022],\n",
            "        [-1.6742,  1.4985, -0.3419],\n",
            "        [ 0.4581,  0.0165, -0.8839],\n",
            "        [-1.6270,  1.8441, -0.3937],\n",
            "        [-1.7463,  2.1133, -0.3617],\n",
            "        [-1.6944,  1.9498, -0.5383],\n",
            "        [-1.9741,  0.5385,  1.1724]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5862,  1.8999, -0.6431],\n",
            "        [-1.5350,  1.8016, -0.6835],\n",
            "        [-1.7012,  2.0044, -0.5496],\n",
            "        [-1.6136,  0.6939,  0.7041],\n",
            "        [-1.5693,  1.9624, -0.6860],\n",
            "        [-0.9912,  1.4020, -0.5953],\n",
            "        [-2.0727,  0.8789,  0.8825],\n",
            "        [-0.1632,  0.8487, -0.9523],\n",
            "        [-1.9803,  1.1531,  0.5635],\n",
            "        [-1.9623,  1.5840,  0.2248],\n",
            "        [-1.5543,  1.6778, -0.4196],\n",
            "        [-1.2098,  1.9101, -0.5590],\n",
            "        [-1.6546,  2.0642, -0.5407],\n",
            "        [-1.5954,  1.8011, -0.4328],\n",
            "        [-2.3328,  1.2203,  0.8169],\n",
            "        [-1.6797,  1.7047, -0.4260]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5862,  1.8999, -0.6431],\n",
            "        [-1.5350,  1.8016, -0.6835],\n",
            "        [-1.7012,  2.0044, -0.5496],\n",
            "        [-1.6136,  0.6939,  0.7041],\n",
            "        [-1.5693,  1.9624, -0.6860],\n",
            "        [-0.9912,  1.4020, -0.5953],\n",
            "        [-2.0727,  0.8789,  0.8825],\n",
            "        [-0.1632,  0.8487, -0.9523],\n",
            "        [-1.9803,  1.1531,  0.5635],\n",
            "        [-1.9623,  1.5840,  0.2248],\n",
            "        [-1.5543,  1.6778, -0.4196],\n",
            "        [-1.2098,  1.9101, -0.5590],\n",
            "        [-1.6546,  2.0642, -0.5407],\n",
            "        [-1.5954,  1.8011, -0.4328],\n",
            "        [-2.3328,  1.2203,  0.8169],\n",
            "        [-1.6797,  1.7047, -0.4260]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7755,  2.0310, -0.6466],\n",
            "        [-2.0988,  0.6301,  0.9343],\n",
            "        [-2.0365,  0.7374,  1.0580],\n",
            "        [-2.2198,  1.2184,  0.7729],\n",
            "        [-1.3825,  2.0417, -0.6671],\n",
            "        [-1.5647,  1.9811, -0.6021],\n",
            "        [-1.3604,  1.9081, -0.7679],\n",
            "        [-1.1728,  1.7514, -0.9326],\n",
            "        [-1.8329,  0.5159,  1.0923],\n",
            "        [-1.2808,  2.0404, -0.7449],\n",
            "        [-1.7497,  1.9864, -0.6145],\n",
            "        [-1.9820,  1.2693,  0.3616],\n",
            "        [-1.4953,  1.8943, -0.7714],\n",
            "        [-2.2029,  1.2347,  0.6266],\n",
            "        [-1.8559,  1.9657, -0.0700],\n",
            "        [-1.8506,  1.9975, -0.4090]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7755,  2.0310, -0.6466],\n",
            "        [-2.0988,  0.6301,  0.9343],\n",
            "        [-2.0365,  0.7374,  1.0580],\n",
            "        [-2.2198,  1.2184,  0.7729],\n",
            "        [-1.3825,  2.0417, -0.6671],\n",
            "        [-1.5647,  1.9811, -0.6021],\n",
            "        [-1.3604,  1.9081, -0.7679],\n",
            "        [-1.1728,  1.7514, -0.9326],\n",
            "        [-1.8329,  0.5159,  1.0923],\n",
            "        [-1.2808,  2.0404, -0.7449],\n",
            "        [-1.7497,  1.9864, -0.6145],\n",
            "        [-1.9820,  1.2693,  0.3616],\n",
            "        [-1.4953,  1.8943, -0.7714],\n",
            "        [-2.2029,  1.2347,  0.6266],\n",
            "        [-1.8559,  1.9657, -0.0700],\n",
            "        [-1.8506,  1.9975, -0.4090]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1662,  0.9194,  0.8387],\n",
            "        [-1.7225,  1.8710, -0.5269],\n",
            "        [-1.6236,  1.6734, -0.6691],\n",
            "        [-1.5683,  2.1694, -0.4509],\n",
            "        [ 0.5450, -0.1945, -0.9762],\n",
            "        [-1.9859,  1.8286, -0.4169],\n",
            "        [-2.0226,  0.7053,  1.0684],\n",
            "        [-2.2198,  1.2584,  0.6168],\n",
            "        [-1.7630,  2.1677, -0.6252],\n",
            "        [-1.9490,  0.4648,  0.9805],\n",
            "        [-1.6742,  2.0480, -0.5868],\n",
            "        [-1.5876,  1.9920, -0.5716],\n",
            "        [-1.8987,  0.4519,  1.2004],\n",
            "        [-1.2649,  2.0241, -0.5878],\n",
            "        [-2.2745,  0.9281,  0.9107],\n",
            "        [-1.9323,  1.9410, -0.1991]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1662,  0.9194,  0.8387],\n",
            "        [-1.7225,  1.8710, -0.5269],\n",
            "        [-1.6236,  1.6734, -0.6691],\n",
            "        [-1.5683,  2.1694, -0.4509],\n",
            "        [ 0.5450, -0.1945, -0.9762],\n",
            "        [-1.9859,  1.8286, -0.4169],\n",
            "        [-2.0226,  0.7053,  1.0684],\n",
            "        [-2.2198,  1.2584,  0.6168],\n",
            "        [-1.7630,  2.1677, -0.6252],\n",
            "        [-1.9490,  0.4648,  0.9805],\n",
            "        [-1.6742,  2.0480, -0.5868],\n",
            "        [-1.5876,  1.9920, -0.5716],\n",
            "        [-1.8987,  0.4519,  1.2004],\n",
            "        [-1.2649,  2.0241, -0.5878],\n",
            "        [-2.2745,  0.9281,  0.9107],\n",
            "        [-1.9323,  1.9410, -0.1991]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6660,  1.9245, -0.2870],\n",
            "        [ 0.3027,  0.1950, -0.8994],\n",
            "        [-1.5399,  2.1750, -0.8427],\n",
            "        [-2.0631,  0.5190,  1.2097],\n",
            "        [-1.4907,  2.1244, -0.8799],\n",
            "        [-1.7207,  1.6628, -0.4684],\n",
            "        [-1.6293,  2.1331, -0.6555],\n",
            "        [-2.1247,  2.0411, -0.3763],\n",
            "        [-1.7266,  0.3879,  1.2186],\n",
            "        [-1.7286,  1.8080, -0.2915],\n",
            "        [-2.0474,  0.9127,  0.5560],\n",
            "        [-1.7352,  2.1617, -0.8467],\n",
            "        [-1.5168,  1.9416, -0.6569],\n",
            "        [-1.8183,  1.9425, -0.7058],\n",
            "        [-2.0026,  1.5214,  0.3370],\n",
            "        [-1.8420,  2.0589, -0.7991]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6660,  1.9245, -0.2870],\n",
            "        [ 0.3027,  0.1950, -0.8994],\n",
            "        [-1.5399,  2.1750, -0.8427],\n",
            "        [-2.0631,  0.5190,  1.2097],\n",
            "        [-1.4907,  2.1244, -0.8799],\n",
            "        [-1.7207,  1.6628, -0.4684],\n",
            "        [-1.6293,  2.1331, -0.6555],\n",
            "        [-2.1247,  2.0411, -0.3763],\n",
            "        [-1.7266,  0.3879,  1.2186],\n",
            "        [-1.7286,  1.8080, -0.2915],\n",
            "        [-2.0474,  0.9127,  0.5560],\n",
            "        [-1.7352,  2.1617, -0.8467],\n",
            "        [-1.5168,  1.9416, -0.6569],\n",
            "        [-1.8183,  1.9425, -0.7058],\n",
            "        [-2.0026,  1.5214,  0.3370],\n",
            "        [-1.8420,  2.0589, -0.7991]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9153,  2.3404, -0.7273],\n",
            "        [-1.0373,  1.1848, -0.2490],\n",
            "        [-2.0324,  0.3404,  1.0937],\n",
            "        [-2.1150,  0.6945,  1.2505],\n",
            "        [-2.1214,  1.3041,  0.5106],\n",
            "        [ 0.4268,  0.1983, -0.8264],\n",
            "        [-1.5855,  2.0427, -0.7791],\n",
            "        [-2.2930,  1.0809,  0.6842],\n",
            "        [-1.6662,  2.2741, -0.4012],\n",
            "        [-2.1034,  1.5466,  0.4654],\n",
            "        [-1.5721,  2.1279, -0.5727],\n",
            "        [-1.6134,  2.0054, -0.5914],\n",
            "        [ 0.1168,  0.0760, -0.8486],\n",
            "        [-2.0309,  2.3420, -0.3549],\n",
            "        [-1.7609,  2.1599, -0.5959],\n",
            "        [ 0.6329,  0.0630, -1.0754]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9153,  2.3404, -0.7273],\n",
            "        [-1.0373,  1.1848, -0.2490],\n",
            "        [-2.0324,  0.3404,  1.0937],\n",
            "        [-2.1150,  0.6945,  1.2505],\n",
            "        [-2.1214,  1.3041,  0.5106],\n",
            "        [ 0.4268,  0.1983, -0.8264],\n",
            "        [-1.5855,  2.0427, -0.7791],\n",
            "        [-2.2930,  1.0809,  0.6842],\n",
            "        [-1.6662,  2.2741, -0.4012],\n",
            "        [-2.1034,  1.5466,  0.4654],\n",
            "        [-1.5721,  2.1279, -0.5727],\n",
            "        [-1.6134,  2.0054, -0.5914],\n",
            "        [ 0.1168,  0.0760, -0.8486],\n",
            "        [-2.0309,  2.3420, -0.3549],\n",
            "        [-1.7609,  2.1599, -0.5959],\n",
            "        [ 0.6329,  0.0630, -1.0754]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7369,  2.2006, -0.5638],\n",
            "        [-1.5825,  2.2225, -0.7997],\n",
            "        [-1.8406,  0.2685,  1.3754],\n",
            "        [-2.0716,  0.3122,  1.1927],\n",
            "        [-2.2060,  1.3326,  0.3272],\n",
            "        [-1.8205,  1.9720, -0.6133],\n",
            "        [-2.0689,  0.2799,  1.2989],\n",
            "        [-1.2963,  1.0412,  0.0626],\n",
            "        [-1.8471,  1.8001, -0.0923],\n",
            "        [-1.9830,  0.3317,  1.3978],\n",
            "        [-2.2451,  0.6248,  1.2195],\n",
            "        [-1.7428,  0.3233,  1.0899],\n",
            "        [-2.1035,  0.7839,  0.8624],\n",
            "        [-1.9738,  0.4983,  1.2070],\n",
            "        [-2.0980,  0.6733,  0.9699],\n",
            "        [-1.4409,  2.0261, -0.5690]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7369,  2.2006, -0.5638],\n",
            "        [-1.5825,  2.2225, -0.7997],\n",
            "        [-1.8406,  0.2685,  1.3754],\n",
            "        [-2.0716,  0.3122,  1.1927],\n",
            "        [-2.2060,  1.3326,  0.3272],\n",
            "        [-1.8205,  1.9720, -0.6133],\n",
            "        [-2.0689,  0.2799,  1.2989],\n",
            "        [-1.2963,  1.0412,  0.0626],\n",
            "        [-1.8471,  1.8001, -0.0923],\n",
            "        [-1.9830,  0.3317,  1.3978],\n",
            "        [-2.2451,  0.6248,  1.2195],\n",
            "        [-1.7428,  0.3233,  1.0899],\n",
            "        [-2.1035,  0.7839,  0.8624],\n",
            "        [-1.9738,  0.4983,  1.2070],\n",
            "        [-2.0980,  0.6733,  0.9699],\n",
            "        [-1.4409,  2.0261, -0.5690]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.1223,  0.5683, -1.0191],\n",
            "        [-1.6029,  1.6778, -0.2673],\n",
            "        [-2.0551,  1.0688,  0.3842],\n",
            "        [-1.6303,  1.7900, -0.1914],\n",
            "        [-1.9791,  2.0777, -0.5152],\n",
            "        [-2.3577,  1.3992,  0.4042],\n",
            "        [-1.8974,  2.1705, -0.5407],\n",
            "        [-1.9797,  1.8944, -0.2769],\n",
            "        [-1.1220,  1.4037, -0.6978],\n",
            "        [-1.8001,  0.2987,  1.3190],\n",
            "        [-1.6734,  0.1110,  1.2209],\n",
            "        [-2.1968,  1.7395, -0.1194],\n",
            "        [-1.6319,  2.1620, -0.3784],\n",
            "        [-1.9393,  1.6826, -0.1922],\n",
            "        [-1.8142,  0.1991,  1.0765],\n",
            "        [-1.7608,  1.8276, -0.3861]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.1223,  0.5683, -1.0191],\n",
            "        [-1.6029,  1.6778, -0.2673],\n",
            "        [-2.0551,  1.0688,  0.3842],\n",
            "        [-1.6303,  1.7900, -0.1914],\n",
            "        [-1.9791,  2.0777, -0.5152],\n",
            "        [-2.3577,  1.3992,  0.4042],\n",
            "        [-1.8974,  2.1705, -0.5407],\n",
            "        [-1.9797,  1.8944, -0.2769],\n",
            "        [-1.1220,  1.4037, -0.6978],\n",
            "        [-1.8001,  0.2987,  1.3190],\n",
            "        [-1.6734,  0.1110,  1.2209],\n",
            "        [-2.1968,  1.7395, -0.1194],\n",
            "        [-1.6319,  2.1620, -0.3784],\n",
            "        [-1.9393,  1.6826, -0.1922],\n",
            "        [-1.8142,  0.1991,  1.0765],\n",
            "        [-1.7608,  1.8276, -0.3861]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2525,  1.9500,  0.0824],\n",
            "        [-1.6989,  0.4080,  1.2108],\n",
            "        [ 0.5228, -0.2431, -0.9392],\n",
            "        [-1.8328,  2.0757, -0.5917],\n",
            "        [-2.2976,  1.7440,  0.0702],\n",
            "        [-2.1479,  1.0634,  0.8373],\n",
            "        [-2.0143,  0.3833,  1.1867],\n",
            "        [-1.9085,  2.2390, -0.4592],\n",
            "        [-2.1629,  0.9920,  0.9476],\n",
            "        [ 0.5349,  0.0084, -0.9636],\n",
            "        [-2.3796,  0.8823,  1.1376],\n",
            "        [-1.6900,  1.9783, -0.3745],\n",
            "        [-1.8757,  1.9406, -0.4491],\n",
            "        [-2.3405,  0.5084,  1.3274],\n",
            "        [-2.2817,  1.2406,  0.9789],\n",
            "        [-2.2834,  0.9956,  0.9098]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.2525,  1.9500,  0.0824],\n",
            "        [-1.6989,  0.4080,  1.2108],\n",
            "        [ 0.5228, -0.2431, -0.9392],\n",
            "        [-1.8328,  2.0757, -0.5917],\n",
            "        [-2.2976,  1.7440,  0.0702],\n",
            "        [-2.1479,  1.0634,  0.8373],\n",
            "        [-2.0143,  0.3833,  1.1867],\n",
            "        [-1.9085,  2.2390, -0.4592],\n",
            "        [-2.1629,  0.9920,  0.9476],\n",
            "        [ 0.5349,  0.0084, -0.9636],\n",
            "        [-2.3796,  0.8823,  1.1376],\n",
            "        [-1.6900,  1.9783, -0.3745],\n",
            "        [-1.8757,  1.9406, -0.4491],\n",
            "        [-2.3405,  0.5084,  1.3274],\n",
            "        [-2.2817,  1.2406,  0.9789],\n",
            "        [-2.2834,  0.9956,  0.9098]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5253,  0.5618,  0.7947],\n",
            "        [-2.2295,  0.5518,  1.4206],\n",
            "        [-2.1186,  0.2676,  1.4295],\n",
            "        [-1.3245,  1.6347, -0.7258],\n",
            "        [-2.2525,  1.7112,  0.1575],\n",
            "        [-1.6948,  2.2432, -0.6416],\n",
            "        [-0.7971,  1.1851, -0.9072],\n",
            "        [-2.3721,  0.8525,  1.0021],\n",
            "        [-1.9712,  2.2175, -0.6035],\n",
            "        [-1.7150,  2.0025, -0.7394],\n",
            "        [-2.3260,  0.6015,  1.1574],\n",
            "        [-1.7588,  2.2631, -0.5367],\n",
            "        [-2.0057,  2.3644, -0.4458],\n",
            "        [-1.9616,  1.8111,  0.1105],\n",
            "        [-1.9496,  0.1856,  1.2768],\n",
            "        [-1.9022,  1.9529, -0.0898]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5253,  0.5618,  0.7947],\n",
            "        [-2.2295,  0.5518,  1.4206],\n",
            "        [-2.1186,  0.2676,  1.4295],\n",
            "        [-1.3245,  1.6347, -0.7258],\n",
            "        [-2.2525,  1.7112,  0.1575],\n",
            "        [-1.6948,  2.2432, -0.6416],\n",
            "        [-0.7971,  1.1851, -0.9072],\n",
            "        [-2.3721,  0.8525,  1.0021],\n",
            "        [-1.9712,  2.2175, -0.6035],\n",
            "        [-1.7150,  2.0025, -0.7394],\n",
            "        [-2.3260,  0.6015,  1.1574],\n",
            "        [-1.7588,  2.2631, -0.5367],\n",
            "        [-2.0057,  2.3644, -0.4458],\n",
            "        [-1.9616,  1.8111,  0.1105],\n",
            "        [-1.9496,  0.1856,  1.2768],\n",
            "        [-1.9022,  1.9529, -0.0898]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8676,  1.9529, -0.1475],\n",
            "        [-1.6613,  0.1987,  1.0555],\n",
            "        [-1.8047,  1.6372,  0.1244],\n",
            "        [-1.9042,  0.2724,  1.3831],\n",
            "        [-2.0103,  1.9302, -0.1319],\n",
            "        [-1.6428,  1.4459, -0.0180],\n",
            "        [-1.7079,  0.0141,  1.2755],\n",
            "        [-2.0335,  0.3477,  1.3355],\n",
            "        [-1.9208,  2.1933, -0.5873],\n",
            "        [ 0.5205, -0.1913, -0.9759],\n",
            "        [-1.7763,  2.3422, -0.5123],\n",
            "        [-1.8692,  1.8066,  0.1020],\n",
            "        [-2.0480,  0.5096,  1.0585],\n",
            "        [-1.9275,  0.4160,  1.1797],\n",
            "        [-2.4385,  1.8729,  0.4027],\n",
            "        [-2.2728,  0.5007,  1.4193]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8676,  1.9529, -0.1475],\n",
            "        [-1.6613,  0.1987,  1.0555],\n",
            "        [-1.8047,  1.6372,  0.1244],\n",
            "        [-1.9042,  0.2724,  1.3831],\n",
            "        [-2.0103,  1.9302, -0.1319],\n",
            "        [-1.6428,  1.4459, -0.0180],\n",
            "        [-1.7079,  0.0141,  1.2755],\n",
            "        [-2.0335,  0.3477,  1.3355],\n",
            "        [-1.9208,  2.1933, -0.5873],\n",
            "        [ 0.5205, -0.1913, -0.9759],\n",
            "        [-1.7763,  2.3422, -0.5123],\n",
            "        [-1.8692,  1.8066,  0.1020],\n",
            "        [-2.0480,  0.5096,  1.0585],\n",
            "        [-1.9275,  0.4160,  1.1797],\n",
            "        [-2.4385,  1.8729,  0.4027],\n",
            "        [-2.2728,  0.5007,  1.4193]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8778,  2.2860, -0.4169],\n",
            "        [-2.0548,  2.2815, -0.4640],\n",
            "        [-2.1752,  0.8711,  0.9894],\n",
            "        [-2.1274,  0.3094,  1.3499],\n",
            "        [-2.2890,  0.6823,  1.1910],\n",
            "        [-1.5895,  1.6163, -0.1845],\n",
            "        [-1.7780,  2.3018, -0.7165],\n",
            "        [-2.0898,  0.4224,  1.2891],\n",
            "        [-2.0216,  0.2802,  1.2917],\n",
            "        [-2.2054,  2.5114, -0.2217],\n",
            "        [-1.8244,  2.1878, -0.3488],\n",
            "        [-2.0877,  0.4151,  1.1912],\n",
            "        [-1.7406,  2.1675, -0.6204],\n",
            "        [-1.9907,  0.3064,  1.2703],\n",
            "        [ 0.6071, -0.1726, -0.9964],\n",
            "        [-1.9411,  2.0415, -0.3128]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8778,  2.2860, -0.4169],\n",
            "        [-2.0548,  2.2815, -0.4640],\n",
            "        [-2.1752,  0.8711,  0.9894],\n",
            "        [-2.1274,  0.3094,  1.3499],\n",
            "        [-2.2890,  0.6823,  1.1910],\n",
            "        [-1.5895,  1.6163, -0.1845],\n",
            "        [-1.7780,  2.3018, -0.7165],\n",
            "        [-2.0898,  0.4224,  1.2891],\n",
            "        [-2.0216,  0.2802,  1.2917],\n",
            "        [-2.2054,  2.5114, -0.2217],\n",
            "        [-1.8244,  2.1878, -0.3488],\n",
            "        [-2.0877,  0.4151,  1.1912],\n",
            "        [-1.7406,  2.1675, -0.6204],\n",
            "        [-1.9907,  0.3064,  1.2703],\n",
            "        [ 0.6071, -0.1726, -0.9964],\n",
            "        [-1.9411,  2.0415, -0.3128]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0370,  1.9576, -0.3056],\n",
            "        [-1.8742,  0.3842,  1.2252],\n",
            "        [-1.4038,  0.3187,  0.7774],\n",
            "        [-2.1762,  0.9430,  0.8320],\n",
            "        [-2.2167,  2.2510, -0.1254],\n",
            "        [-2.1491,  1.1951,  0.8714],\n",
            "        [-2.1014,  0.3226,  1.3522],\n",
            "        [-2.0009,  2.2011, -0.5154],\n",
            "        [-1.8728,  1.8697, -0.2672],\n",
            "        [-2.0096,  0.1367,  1.3543],\n",
            "        [-1.8539,  0.1911,  1.2057],\n",
            "        [ 0.7104, -0.2528, -0.9451],\n",
            "        [-2.4961,  1.4386,  0.5706],\n",
            "        [ 0.5873,  0.0473, -1.0303],\n",
            "        [ 0.4056,  0.1446, -0.9520],\n",
            "        [-2.3111,  0.9894,  0.8609]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0370,  1.9576, -0.3056],\n",
            "        [-1.8742,  0.3842,  1.2252],\n",
            "        [-1.4038,  0.3187,  0.7774],\n",
            "        [-2.1762,  0.9430,  0.8320],\n",
            "        [-2.2167,  2.2510, -0.1254],\n",
            "        [-2.1491,  1.1951,  0.8714],\n",
            "        [-2.1014,  0.3226,  1.3522],\n",
            "        [-2.0009,  2.2011, -0.5154],\n",
            "        [-1.8728,  1.8697, -0.2672],\n",
            "        [-2.0096,  0.1367,  1.3543],\n",
            "        [-1.8539,  0.1911,  1.2057],\n",
            "        [ 0.7104, -0.2528, -0.9451],\n",
            "        [-2.4961,  1.4386,  0.5706],\n",
            "        [ 0.5873,  0.0473, -1.0303],\n",
            "        [ 0.4056,  0.1446, -0.9520],\n",
            "        [-2.3111,  0.9894,  0.8609]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1247,  1.7233,  0.0082],\n",
            "        [-2.3489,  1.8177,  0.1136],\n",
            "        [-2.0526,  2.2546, -0.5546],\n",
            "        [-2.2089,  1.9934, -0.2681],\n",
            "        [-1.8615,  2.2031, -0.2762],\n",
            "        [-1.7446,  2.1666, -0.4608],\n",
            "        [-2.2977,  0.4530,  1.1303],\n",
            "        [-1.6877,  2.3248, -0.4361],\n",
            "        [ 0.5963, -0.2995, -1.0348],\n",
            "        [-1.5677,  1.9768, -0.2830],\n",
            "        [-1.3264,  0.2892,  0.6400],\n",
            "        [-2.1485,  2.3368, -0.5983],\n",
            "        [-2.0022,  0.4396,  1.4755],\n",
            "        [-1.6459,  1.8564, -0.3874],\n",
            "        [ 0.5530,  0.0443, -1.0194],\n",
            "        [-2.0031,  1.0935,  0.6980]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1247,  1.7233,  0.0082],\n",
            "        [-2.3489,  1.8177,  0.1136],\n",
            "        [-2.0526,  2.2546, -0.5546],\n",
            "        [-2.2089,  1.9934, -0.2681],\n",
            "        [-1.8615,  2.2031, -0.2762],\n",
            "        [-1.7446,  2.1666, -0.4608],\n",
            "        [-2.2977,  0.4530,  1.1303],\n",
            "        [-1.6877,  2.3248, -0.4361],\n",
            "        [ 0.5963, -0.2995, -1.0348],\n",
            "        [-1.5677,  1.9768, -0.2830],\n",
            "        [-1.3264,  0.2892,  0.6400],\n",
            "        [-2.1485,  2.3368, -0.5983],\n",
            "        [-2.0022,  0.4396,  1.4755],\n",
            "        [-1.6459,  1.8564, -0.3874],\n",
            "        [ 0.5530,  0.0443, -1.0194],\n",
            "        [-2.0031,  1.0935,  0.6980]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3807,  1.7459, -0.5688],\n",
            "        [-1.9588,  1.3197,  0.2659],\n",
            "        [-2.1717,  2.3606, -0.4918],\n",
            "        [-1.4262,  1.1566,  0.0571],\n",
            "        [-2.3322,  0.8721,  1.1606],\n",
            "        [-2.2288,  2.1650, -0.1323],\n",
            "        [-2.1696,  1.0961,  0.6521],\n",
            "        [ 0.4018, -0.1310, -0.9386],\n",
            "        [-2.3438,  0.4825,  1.1914],\n",
            "        [-1.9487,  1.8441, -0.3330],\n",
            "        [ 0.3784, -0.1120, -0.7507],\n",
            "        [-2.0751,  2.1009, -0.3518],\n",
            "        [-2.3126,  1.7006,  0.2943],\n",
            "        [-2.2299,  0.7801,  1.2193],\n",
            "        [-2.3840,  1.5762,  0.4706],\n",
            "        [-1.7307,  2.2997, -0.7216]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3807,  1.7459, -0.5688],\n",
            "        [-1.9588,  1.3197,  0.2659],\n",
            "        [-2.1717,  2.3606, -0.4918],\n",
            "        [-1.4262,  1.1566,  0.0571],\n",
            "        [-2.3322,  0.8721,  1.1606],\n",
            "        [-2.2288,  2.1650, -0.1323],\n",
            "        [-2.1696,  1.0961,  0.6521],\n",
            "        [ 0.4018, -0.1310, -0.9386],\n",
            "        [-2.3438,  0.4825,  1.1914],\n",
            "        [-1.9487,  1.8441, -0.3330],\n",
            "        [ 0.3784, -0.1120, -0.7507],\n",
            "        [-2.0751,  2.1009, -0.3518],\n",
            "        [-2.3126,  1.7006,  0.2943],\n",
            "        [-2.2299,  0.7801,  1.2193],\n",
            "        [-2.3840,  1.5762,  0.4706],\n",
            "        [-1.7307,  2.2997, -0.7216]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2932,  0.4728,  1.2756],\n",
            "        [-1.9379,  2.2648, -0.7773],\n",
            "        [-1.6730,  2.3139, -0.7165],\n",
            "        [-1.9698,  2.0153, -0.2826],\n",
            "        [-2.3570,  1.3640,  0.5176],\n",
            "        [-1.7267,  1.9315, -0.2695],\n",
            "        [-2.0262,  0.7408,  1.1259],\n",
            "        [-2.0531,  1.8564, -0.0873],\n",
            "        [ 0.3132,  0.5197, -1.2896],\n",
            "        [-1.8807,  2.1038, -0.5023],\n",
            "        [ 0.2179, -0.0949, -0.8188],\n",
            "        [-2.1342,  2.2941, -0.4094],\n",
            "        [-0.8234,  1.4096, -0.7687],\n",
            "        [ 0.6757, -0.2132, -1.0098],\n",
            "        [-1.6749,  2.1626, -0.5886],\n",
            "        [-1.1521,  0.5855,  0.2175]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.2932,  0.4728,  1.2756],\n",
            "        [-1.9379,  2.2648, -0.7773],\n",
            "        [-1.6730,  2.3139, -0.7165],\n",
            "        [-1.9698,  2.0153, -0.2826],\n",
            "        [-2.3570,  1.3640,  0.5176],\n",
            "        [-1.7267,  1.9315, -0.2695],\n",
            "        [-2.0262,  0.7408,  1.1259],\n",
            "        [-2.0531,  1.8564, -0.0873],\n",
            "        [ 0.3132,  0.5197, -1.2896],\n",
            "        [-1.8807,  2.1038, -0.5023],\n",
            "        [ 0.2179, -0.0949, -0.8188],\n",
            "        [-2.1342,  2.2941, -0.4094],\n",
            "        [-0.8234,  1.4096, -0.7687],\n",
            "        [ 0.6757, -0.2132, -1.0098],\n",
            "        [-1.6749,  2.1626, -0.5886],\n",
            "        [-1.1521,  0.5855,  0.2175]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0337,  0.7201,  1.1708],\n",
            "        [-2.0802,  1.0186,  0.8903],\n",
            "        [-2.1007,  0.4318,  1.2325],\n",
            "        [ 0.4314,  0.2996, -1.0781],\n",
            "        [ 0.1483,  0.3314, -0.9179],\n",
            "        [ 0.5713,  0.0407, -1.1200],\n",
            "        [-2.0291,  2.4402, -0.6878],\n",
            "        [-1.9600,  2.0901, -0.5506],\n",
            "        [-2.0956,  0.6116,  1.0419],\n",
            "        [-1.5847,  1.7514, -0.2898],\n",
            "        [-1.7794,  2.0660, -0.6036],\n",
            "        [ 0.3921,  0.2698, -1.1496],\n",
            "        [-2.2842,  1.1252,  0.8403],\n",
            "        [-1.6681,  2.0367, -0.3749],\n",
            "        [-1.8352,  1.9309, -0.3806],\n",
            "        [-2.0917,  0.7532,  1.2962]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0337,  0.7201,  1.1708],\n",
            "        [-2.0802,  1.0186,  0.8903],\n",
            "        [-2.1007,  0.4318,  1.2325],\n",
            "        [ 0.4314,  0.2996, -1.0781],\n",
            "        [ 0.1483,  0.3314, -0.9179],\n",
            "        [ 0.5713,  0.0407, -1.1200],\n",
            "        [-2.0291,  2.4402, -0.6878],\n",
            "        [-1.9600,  2.0901, -0.5506],\n",
            "        [-2.0956,  0.6116,  1.0419],\n",
            "        [-1.5847,  1.7514, -0.2898],\n",
            "        [-1.7794,  2.0660, -0.6036],\n",
            "        [ 0.3921,  0.2698, -1.1496],\n",
            "        [-2.2842,  1.1252,  0.8403],\n",
            "        [-1.6681,  2.0367, -0.3749],\n",
            "        [-1.8352,  1.9309, -0.3806],\n",
            "        [-2.0917,  0.7532,  1.2962]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9156,  1.9520, -0.3333],\n",
            "        [-2.1588,  0.5290,  1.2744],\n",
            "        [ 0.4699, -0.0405, -0.9844],\n",
            "        [-0.2081,  0.4921, -0.6961],\n",
            "        [-1.9810,  1.9637, -0.1603],\n",
            "        [-1.7487,  2.0842, -0.6899],\n",
            "        [-1.4195,  1.7164, -0.7770],\n",
            "        [-1.8582,  2.0959, -0.5565],\n",
            "        [-2.0391,  2.2353, -0.6855],\n",
            "        [-1.8471,  0.3376,  1.1192],\n",
            "        [-2.2494,  2.1388, -0.3662],\n",
            "        [-1.5777,  1.8001, -0.2130],\n",
            "        [-1.5277,  1.8290, -0.5189],\n",
            "        [-1.9824,  1.9019, -0.4019],\n",
            "        [ 0.6269,  0.0320, -0.9990],\n",
            "        [ 0.6158, -0.0530, -1.1728]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9156,  1.9520, -0.3333],\n",
            "        [-2.1588,  0.5290,  1.2744],\n",
            "        [ 0.4699, -0.0405, -0.9844],\n",
            "        [-0.2081,  0.4921, -0.6961],\n",
            "        [-1.9810,  1.9637, -0.1603],\n",
            "        [-1.7487,  2.0842, -0.6899],\n",
            "        [-1.4195,  1.7164, -0.7770],\n",
            "        [-1.8582,  2.0959, -0.5565],\n",
            "        [-2.0391,  2.2353, -0.6855],\n",
            "        [-1.8471,  0.3376,  1.1192],\n",
            "        [-2.2494,  2.1388, -0.3662],\n",
            "        [-1.5777,  1.8001, -0.2130],\n",
            "        [-1.5277,  1.8290, -0.5189],\n",
            "        [-1.9824,  1.9019, -0.4019],\n",
            "        [ 0.6269,  0.0320, -0.9990],\n",
            "        [ 0.6158, -0.0530, -1.1728]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.2758,  0.1873, -1.0931],\n",
            "        [-2.2274,  1.4172,  0.5350],\n",
            "        [-1.9576,  2.3064, -0.3033],\n",
            "        [-1.1681,  1.3442, -0.2895],\n",
            "        [-0.9023,  0.2634,  0.2010],\n",
            "        [-1.8993,  1.9725, -0.3066],\n",
            "        [-1.8364,  2.4515, -0.4875],\n",
            "        [-2.2272,  1.5067,  0.4055],\n",
            "        [-2.2454,  1.9462,  0.0153],\n",
            "        [-2.1117,  1.0282,  0.8962],\n",
            "        [-1.8027,  0.3709,  1.0282],\n",
            "        [-2.0286,  2.1685, -0.6134],\n",
            "        [ 0.2517,  0.1120, -0.6491],\n",
            "        [-1.9989,  1.0317,  0.5940],\n",
            "        [-1.6002,  0.9799,  0.4823],\n",
            "        [-1.8973,  0.3233,  1.0471]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.2758,  0.1873, -1.0931],\n",
            "        [-2.2274,  1.4172,  0.5350],\n",
            "        [-1.9576,  2.3064, -0.3033],\n",
            "        [-1.1681,  1.3442, -0.2895],\n",
            "        [-0.9023,  0.2634,  0.2010],\n",
            "        [-1.8993,  1.9725, -0.3066],\n",
            "        [-1.8364,  2.4515, -0.4875],\n",
            "        [-2.2272,  1.5067,  0.4055],\n",
            "        [-2.2454,  1.9462,  0.0153],\n",
            "        [-2.1117,  1.0282,  0.8962],\n",
            "        [-1.8027,  0.3709,  1.0282],\n",
            "        [-2.0286,  2.1685, -0.6134],\n",
            "        [ 0.2517,  0.1120, -0.6491],\n",
            "        [-1.9989,  1.0317,  0.5940],\n",
            "        [-1.6002,  0.9799,  0.4823],\n",
            "        [-1.8973,  0.3233,  1.0471]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.4107,  0.9573, -1.1225],\n",
            "        [-1.1334,  1.3471, -0.2969],\n",
            "        [-1.8782,  2.0754, -0.5374],\n",
            "        [-1.0999,  0.5239,  0.3744],\n",
            "        [-0.4735,  1.2303, -0.9421],\n",
            "        [-2.2140,  0.8608,  0.9840],\n",
            "        [-1.2274,  1.6844, -0.7232],\n",
            "        [-1.7698,  1.7778, -0.4047],\n",
            "        [-1.6949,  2.1172, -0.7067],\n",
            "        [-1.5887,  1.7460, -0.5146],\n",
            "        [-1.9194,  0.2554,  1.1654],\n",
            "        [-1.7477,  1.7814, -0.3133],\n",
            "        [-1.8817,  2.0714, -0.2072],\n",
            "        [-1.4606,  1.9289, -0.5333],\n",
            "        [-1.7999,  1.9390, -0.6958],\n",
            "        [-1.5641,  1.5621, -0.2824]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-0.4107,  0.9573, -1.1225],\n",
            "        [-1.1334,  1.3471, -0.2969],\n",
            "        [-1.8782,  2.0754, -0.5374],\n",
            "        [-1.0999,  0.5239,  0.3744],\n",
            "        [-0.4735,  1.2303, -0.9421],\n",
            "        [-2.2140,  0.8608,  0.9840],\n",
            "        [-1.2274,  1.6844, -0.7232],\n",
            "        [-1.7698,  1.7778, -0.4047],\n",
            "        [-1.6949,  2.1172, -0.7067],\n",
            "        [-1.5887,  1.7460, -0.5146],\n",
            "        [-1.9194,  0.2554,  1.1654],\n",
            "        [-1.7477,  1.7814, -0.3133],\n",
            "        [-1.8817,  2.0714, -0.2072],\n",
            "        [-1.4606,  1.9289, -0.5333],\n",
            "        [-1.7999,  1.9390, -0.6958],\n",
            "        [-1.5641,  1.5621, -0.2824]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.4449,  1.2686,  0.8654],\n",
            "        [-2.1086,  0.4957,  1.2709],\n",
            "        [-1.5289,  1.7675, -0.3240],\n",
            "        [-1.7826, -0.0945,  1.2702],\n",
            "        [-1.7972,  2.1157, -0.7791],\n",
            "        [-1.7709,  1.9054, -0.4767],\n",
            "        [-1.8738,  1.2694,  0.1496],\n",
            "        [-1.5585,  1.6767, -0.3210],\n",
            "        [-1.5536,  1.8334, -0.6134],\n",
            "        [ 0.2301,  0.1491, -1.1126],\n",
            "        [-2.1886,  0.6593,  1.3691],\n",
            "        [-1.9280,  1.9087, -0.1202],\n",
            "        [ 0.2596,  0.4734, -1.1369],\n",
            "        [-2.2897,  0.9404,  0.7341],\n",
            "        [-1.7902,  2.0677, -0.5372],\n",
            "        [-1.1492,  1.3622, -0.5506]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.4449,  1.2686,  0.8654],\n",
            "        [-2.1086,  0.4957,  1.2709],\n",
            "        [-1.5289,  1.7675, -0.3240],\n",
            "        [-1.7826, -0.0945,  1.2702],\n",
            "        [-1.7972,  2.1157, -0.7791],\n",
            "        [-1.7709,  1.9054, -0.4767],\n",
            "        [-1.8738,  1.2694,  0.1496],\n",
            "        [-1.5585,  1.6767, -0.3210],\n",
            "        [-1.5536,  1.8334, -0.6134],\n",
            "        [ 0.2301,  0.1491, -1.1126],\n",
            "        [-2.1886,  0.6593,  1.3691],\n",
            "        [-1.9280,  1.9087, -0.1202],\n",
            "        [ 0.2596,  0.4734, -1.1369],\n",
            "        [-2.2897,  0.9404,  0.7341],\n",
            "        [-1.7902,  2.0677, -0.5372],\n",
            "        [-1.1492,  1.3622, -0.5506]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.4799,  0.2892, -1.1492],\n",
            "        [-2.2237,  2.0589, -0.0459],\n",
            "        [-2.3820,  0.7107,  0.9790],\n",
            "        [-1.8342,  0.1991,  0.9474],\n",
            "        [-1.7373,  2.3869, -0.6624],\n",
            "        [ 0.2356,  0.2195, -1.3631],\n",
            "        [-2.0080,  2.1275, -0.3985],\n",
            "        [-1.7695,  1.7237, -0.3590],\n",
            "        [-2.2180,  1.7415,  0.2435],\n",
            "        [-1.8189,  1.7274, -0.0719],\n",
            "        [-2.2071,  0.6215,  1.0939],\n",
            "        [ 0.1871,  0.3779, -1.1758],\n",
            "        [-2.0775,  2.2289, -0.5950],\n",
            "        [ 0.4362,  0.3700, -1.1112],\n",
            "        [-2.0661,  2.1217, -0.3220],\n",
            "        [-1.7647,  2.0419, -0.6654]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.4799,  0.2892, -1.1492],\n",
            "        [-2.2237,  2.0589, -0.0459],\n",
            "        [-2.3820,  0.7107,  0.9790],\n",
            "        [-1.8342,  0.1991,  0.9474],\n",
            "        [-1.7373,  2.3869, -0.6624],\n",
            "        [ 0.2356,  0.2195, -1.3631],\n",
            "        [-2.0080,  2.1275, -0.3985],\n",
            "        [-1.7695,  1.7237, -0.3590],\n",
            "        [-2.2180,  1.7415,  0.2435],\n",
            "        [-1.8189,  1.7274, -0.0719],\n",
            "        [-2.2071,  0.6215,  1.0939],\n",
            "        [ 0.1871,  0.3779, -1.1758],\n",
            "        [-2.0775,  2.2289, -0.5950],\n",
            "        [ 0.4362,  0.3700, -1.1112],\n",
            "        [-2.0661,  2.1217, -0.3220],\n",
            "        [-1.7647,  2.0419, -0.6654]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.0185,  1.3213, -0.8420],\n",
            "        [-1.6594,  2.0219, -0.7760],\n",
            "        [-2.0092,  0.6553,  0.6891],\n",
            "        [-1.7074,  1.8999, -0.6147],\n",
            "        [-2.2854,  0.6830,  1.1462],\n",
            "        [-1.7906,  2.1817, -0.4442],\n",
            "        [-1.6203,  1.7743, -0.1964],\n",
            "        [ 0.4488,  0.1494, -1.1745],\n",
            "        [-0.9221,  0.6117, -0.2252],\n",
            "        [-2.1568,  2.1644, -0.0616],\n",
            "        [-0.3232,  0.9356, -0.9970],\n",
            "        [-1.8995,  0.5315,  1.0706],\n",
            "        [-1.7702,  1.8158, -0.1892],\n",
            "        [-1.8795,  1.8538, -0.3122],\n",
            "        [-0.5521,  0.6664, -0.5491],\n",
            "        [ 0.4360,  0.3480, -1.0701]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.0185,  1.3213, -0.8420],\n",
            "        [-1.6594,  2.0219, -0.7760],\n",
            "        [-2.0092,  0.6553,  0.6891],\n",
            "        [-1.7074,  1.8999, -0.6147],\n",
            "        [-2.2854,  0.6830,  1.1462],\n",
            "        [-1.7906,  2.1817, -0.4442],\n",
            "        [-1.6203,  1.7743, -0.1964],\n",
            "        [ 0.4488,  0.1494, -1.1745],\n",
            "        [-0.9221,  0.6117, -0.2252],\n",
            "        [-2.1568,  2.1644, -0.0616],\n",
            "        [-0.3232,  0.9356, -0.9970],\n",
            "        [-1.8995,  0.5315,  1.0706],\n",
            "        [-1.7702,  1.8158, -0.1892],\n",
            "        [-1.8795,  1.8538, -0.3122],\n",
            "        [-0.5521,  0.6664, -0.5491],\n",
            "        [ 0.4360,  0.3480, -1.0701]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8118,  1.9310, -0.3915],\n",
            "        [-1.6526,  2.1228, -0.6527],\n",
            "        [-1.7864,  1.9776, -0.3650],\n",
            "        [-1.8963,  2.1380, -0.3395],\n",
            "        [-1.9922,  0.4159,  1.1879],\n",
            "        [-2.1661,  0.5602,  0.9087],\n",
            "        [-1.9191,  1.8751, -0.2693],\n",
            "        [-1.2557,  1.7213, -0.8752],\n",
            "        [-1.7813,  2.0737, -0.5721],\n",
            "        [-2.4254,  1.4626,  0.4691],\n",
            "        [-1.9895,  2.1081, -0.3780],\n",
            "        [-1.8486,  2.1058, -0.6139],\n",
            "        [-2.2854,  1.0663,  1.0544],\n",
            "        [-1.8383,  0.5156,  1.1022],\n",
            "        [-2.0525,  1.5114,  0.2403],\n",
            "        [-1.9164,  1.8949, -0.5644]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8118,  1.9310, -0.3915],\n",
            "        [-1.6526,  2.1228, -0.6527],\n",
            "        [-1.7864,  1.9776, -0.3650],\n",
            "        [-1.8963,  2.1380, -0.3395],\n",
            "        [-1.9922,  0.4159,  1.1879],\n",
            "        [-2.1661,  0.5602,  0.9087],\n",
            "        [-1.9191,  1.8751, -0.2693],\n",
            "        [-1.2557,  1.7213, -0.8752],\n",
            "        [-1.7813,  2.0737, -0.5721],\n",
            "        [-2.4254,  1.4626,  0.4691],\n",
            "        [-1.9895,  2.1081, -0.3780],\n",
            "        [-1.8486,  2.1058, -0.6139],\n",
            "        [-2.2854,  1.0663,  1.0544],\n",
            "        [-1.8383,  0.5156,  1.1022],\n",
            "        [-2.0525,  1.5114,  0.2403],\n",
            "        [-1.9164,  1.8949, -0.5644]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0341,  1.7545, -0.0036],\n",
            "        [-1.8460,  2.0373, -0.2578],\n",
            "        [-2.1833,  2.0158,  0.0074],\n",
            "        [-1.8453,  2.0147, -0.3379],\n",
            "        [-1.9446,  1.8098, -0.4341],\n",
            "        [-0.2186,  0.4432, -0.8169],\n",
            "        [-2.1130,  0.6738,  1.0344],\n",
            "        [-1.9123,  1.9689, -0.3420],\n",
            "        [-2.1751,  1.7441,  0.1518],\n",
            "        [-2.0994,  0.6119,  1.2945],\n",
            "        [-2.2183,  0.6018,  1.2209],\n",
            "        [-1.9531,  1.9839, -0.3356],\n",
            "        [-1.8221,  2.0073, -0.2288],\n",
            "        [-1.8380,  1.9041, -0.7863],\n",
            "        [-0.1279,  0.7262, -1.1870],\n",
            "        [-1.7865,  1.4052,  0.2550]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0341,  1.7545, -0.0036],\n",
            "        [-1.8460,  2.0373, -0.2578],\n",
            "        [-2.1833,  2.0158,  0.0074],\n",
            "        [-1.8453,  2.0147, -0.3379],\n",
            "        [-1.9446,  1.8098, -0.4341],\n",
            "        [-0.2186,  0.4432, -0.8169],\n",
            "        [-2.1130,  0.6738,  1.0344],\n",
            "        [-1.9123,  1.9689, -0.3420],\n",
            "        [-2.1751,  1.7441,  0.1518],\n",
            "        [-2.0994,  0.6119,  1.2945],\n",
            "        [-2.2183,  0.6018,  1.2209],\n",
            "        [-1.9531,  1.9839, -0.3356],\n",
            "        [-1.8221,  2.0073, -0.2288],\n",
            "        [-1.8380,  1.9041, -0.7863],\n",
            "        [-0.1279,  0.7262, -1.1870],\n",
            "        [-1.7865,  1.4052,  0.2550]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4773,  1.5984, -0.3667],\n",
            "        [-1.7148,  2.1453, -0.3721],\n",
            "        [-1.7103,  1.9287, -0.2929],\n",
            "        [-1.5016,  1.7924, -0.2424],\n",
            "        [-1.6929,  2.0682, -0.6684],\n",
            "        [-1.7770,  2.0668, -0.4957],\n",
            "        [-1.5483,  1.7772, -0.3482],\n",
            "        [-1.6409,  1.7548, -0.1950],\n",
            "        [-1.8863,  1.8961, -0.2186],\n",
            "        [-1.8484,  1.8261, -0.3246],\n",
            "        [-2.0500,  1.6497, -0.0153],\n",
            "        [-2.0643,  1.3688,  0.4328],\n",
            "        [-2.2727,  0.6671,  1.2011],\n",
            "        [ 0.2883,  0.3539, -1.1528],\n",
            "        [-1.9716,  1.9444, -0.2384],\n",
            "        [-2.0492,  0.5004,  0.9771]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4773,  1.5984, -0.3667],\n",
            "        [-1.7148,  2.1453, -0.3721],\n",
            "        [-1.7103,  1.9287, -0.2929],\n",
            "        [-1.5016,  1.7924, -0.2424],\n",
            "        [-1.6929,  2.0682, -0.6684],\n",
            "        [-1.7770,  2.0668, -0.4957],\n",
            "        [-1.5483,  1.7772, -0.3482],\n",
            "        [-1.6409,  1.7548, -0.1950],\n",
            "        [-1.8863,  1.8961, -0.2186],\n",
            "        [-1.8484,  1.8261, -0.3246],\n",
            "        [-2.0500,  1.6497, -0.0153],\n",
            "        [-2.0643,  1.3688,  0.4328],\n",
            "        [-2.2727,  0.6671,  1.2011],\n",
            "        [ 0.2883,  0.3539, -1.1528],\n",
            "        [-1.9716,  1.9444, -0.2384],\n",
            "        [-2.0492,  0.5004,  0.9771]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2516,  1.0247,  0.9752],\n",
            "        [ 0.3480,  0.1906, -1.1403],\n",
            "        [-1.1441,  1.3259, -0.3963],\n",
            "        [-2.2542,  0.7582,  1.2746],\n",
            "        [-1.9675,  0.4780,  1.1213],\n",
            "        [-2.1385,  0.4744,  1.0801],\n",
            "        [-0.6777,  0.9381, -0.6290],\n",
            "        [-1.5654,  1.5431, -0.2812],\n",
            "        [-1.5060,  1.7169, -0.0848],\n",
            "        [-1.8592,  1.9548, -0.2038],\n",
            "        [-1.7821,  1.9575, -0.2284],\n",
            "        [-2.0038,  1.8937, -0.2102],\n",
            "        [-0.0097,  0.4448, -0.9904],\n",
            "        [-1.7617,  1.7723, -0.2013],\n",
            "        [-1.8449,  1.9107, -0.1376],\n",
            "        [-2.0926,  1.8033,  0.0371]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.2516,  1.0247,  0.9752],\n",
            "        [ 0.3480,  0.1906, -1.1403],\n",
            "        [-1.1441,  1.3259, -0.3963],\n",
            "        [-2.2542,  0.7582,  1.2746],\n",
            "        [-1.9675,  0.4780,  1.1213],\n",
            "        [-2.1385,  0.4744,  1.0801],\n",
            "        [-0.6777,  0.9381, -0.6290],\n",
            "        [-1.5654,  1.5431, -0.2812],\n",
            "        [-1.5060,  1.7169, -0.0848],\n",
            "        [-1.8592,  1.9548, -0.2038],\n",
            "        [-1.7821,  1.9575, -0.2284],\n",
            "        [-2.0038,  1.8937, -0.2102],\n",
            "        [-0.0097,  0.4448, -0.9904],\n",
            "        [-1.7617,  1.7723, -0.2013],\n",
            "        [-1.8449,  1.9107, -0.1376],\n",
            "        [-2.0926,  1.8033,  0.0371]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8186,  1.6237, -0.0672],\n",
            "        [-1.9771,  0.4328,  0.9904],\n",
            "        [-2.1478,  1.7057,  0.0386],\n",
            "        [-2.0338,  1.8162,  0.0553],\n",
            "        [-2.1958,  1.3132,  0.5219],\n",
            "        [ 0.3291,  0.4065, -1.1321],\n",
            "        [-1.8126,  2.0663, -0.3616],\n",
            "        [-1.8822,  1.9341, -0.0830],\n",
            "        [-0.6533,  1.2255, -0.9161],\n",
            "        [-1.8321,  1.9578, -0.2253],\n",
            "        [-2.0201,  1.3016,  0.8272],\n",
            "        [-0.4860,  0.8289, -0.6967],\n",
            "        [-0.9119,  0.7482, -0.1111],\n",
            "        [-1.9062,  1.8315, -0.1195],\n",
            "        [ 0.4116,  0.3554, -1.2147],\n",
            "        [-2.0032,  1.8279, -0.1572]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8186,  1.6237, -0.0672],\n",
            "        [-1.9771,  0.4328,  0.9904],\n",
            "        [-2.1478,  1.7057,  0.0386],\n",
            "        [-2.0338,  1.8162,  0.0553],\n",
            "        [-2.1958,  1.3132,  0.5219],\n",
            "        [ 0.3291,  0.4065, -1.1321],\n",
            "        [-1.8126,  2.0663, -0.3616],\n",
            "        [-1.8822,  1.9341, -0.0830],\n",
            "        [-0.6533,  1.2255, -0.9161],\n",
            "        [-1.8321,  1.9578, -0.2253],\n",
            "        [-2.0201,  1.3016,  0.8272],\n",
            "        [-0.4860,  0.8289, -0.6967],\n",
            "        [-0.9119,  0.7482, -0.1111],\n",
            "        [-1.9062,  1.8315, -0.1195],\n",
            "        [ 0.4116,  0.3554, -1.2147],\n",
            "        [-2.0032,  1.8279, -0.1572]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3942,  1.4365, -0.2846],\n",
            "        [-2.3024,  0.6559,  0.9639],\n",
            "        [-1.9700,  1.2777,  0.1116],\n",
            "        [-2.1009,  0.3958,  1.0580],\n",
            "        [-1.7732,  1.5358,  0.1508],\n",
            "        [-2.0422,  1.7364,  0.2936],\n",
            "        [ 0.1374,  0.3797, -1.0744],\n",
            "        [-1.8636,  1.5694,  0.1285],\n",
            "        [-1.9690,  1.6755, -0.1196],\n",
            "        [-1.4010,  0.2783,  0.7342],\n",
            "        [-0.0689,  0.5132, -0.8392],\n",
            "        [-2.2057,  0.6440,  1.0791],\n",
            "        [-1.9954,  0.9441,  0.5211],\n",
            "        [-1.9411,  1.3829,  0.2149],\n",
            "        [ 0.0265,  0.3014, -0.9875],\n",
            "        [-1.5187,  1.5104, -0.5095]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3942,  1.4365, -0.2846],\n",
            "        [-2.3024,  0.6559,  0.9639],\n",
            "        [-1.9700,  1.2777,  0.1116],\n",
            "        [-2.1009,  0.3958,  1.0580],\n",
            "        [-1.7732,  1.5358,  0.1508],\n",
            "        [-2.0422,  1.7364,  0.2936],\n",
            "        [ 0.1374,  0.3797, -1.0744],\n",
            "        [-1.8636,  1.5694,  0.1285],\n",
            "        [-1.9690,  1.6755, -0.1196],\n",
            "        [-1.4010,  0.2783,  0.7342],\n",
            "        [-0.0689,  0.5132, -0.8392],\n",
            "        [-2.2057,  0.6440,  1.0791],\n",
            "        [-1.9954,  0.9441,  0.5211],\n",
            "        [-1.9411,  1.3829,  0.2149],\n",
            "        [ 0.0265,  0.3014, -0.9875],\n",
            "        [-1.5187,  1.5104, -0.5095]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1814,  1.1039,  0.5281],\n",
            "        [-2.2716,  0.6650,  1.0321],\n",
            "        [-2.0168,  0.6287,  1.2965],\n",
            "        [-1.7847,  1.6774, -0.1163],\n",
            "        [ 0.4775,  0.1156, -1.3164],\n",
            "        [-1.8640,  1.7390, -0.0232],\n",
            "        [ 0.5127,  0.2613, -1.2639],\n",
            "        [-2.4501,  0.8241,  0.9557],\n",
            "        [-1.6527,  1.7635,  0.0640],\n",
            "        [-1.3692,  1.4170, -0.3853],\n",
            "        [-2.0888,  0.4631,  1.1111],\n",
            "        [ 0.5636,  0.2481, -1.2057],\n",
            "        [-0.1139,  0.6179, -0.8561],\n",
            "        [ 0.3483,  0.2238, -0.9831],\n",
            "        [-1.8322,  1.7391, -0.0961],\n",
            "        [-1.8058,  0.4834,  0.9766]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1814,  1.1039,  0.5281],\n",
            "        [-2.2716,  0.6650,  1.0321],\n",
            "        [-2.0168,  0.6287,  1.2965],\n",
            "        [-1.7847,  1.6774, -0.1163],\n",
            "        [ 0.4775,  0.1156, -1.3164],\n",
            "        [-1.8640,  1.7390, -0.0232],\n",
            "        [ 0.5127,  0.2613, -1.2639],\n",
            "        [-2.4501,  0.8241,  0.9557],\n",
            "        [-1.6527,  1.7635,  0.0640],\n",
            "        [-1.3692,  1.4170, -0.3853],\n",
            "        [-2.0888,  0.4631,  1.1111],\n",
            "        [ 0.5636,  0.2481, -1.2057],\n",
            "        [-0.1139,  0.6179, -0.8561],\n",
            "        [ 0.3483,  0.2238, -0.9831],\n",
            "        [-1.8322,  1.7391, -0.0961],\n",
            "        [-1.8058,  0.4834,  0.9766]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6759,  1.6716, -0.2213],\n",
            "        [-1.0731,  1.4011, -0.4666],\n",
            "        [-1.9086,  1.6802, -0.0567],\n",
            "        [-1.9591,  1.2062,  0.2760],\n",
            "        [ 0.0521,  0.3491, -0.9278],\n",
            "        [-1.7448,  1.5687, -0.1287],\n",
            "        [-1.3753,  1.4690, -0.5342],\n",
            "        [-1.5631,  1.4995, -0.1556],\n",
            "        [-1.8241,  1.1768,  0.4509],\n",
            "        [-1.6172,  1.5463, -0.2080],\n",
            "        [-1.6253,  1.6422, -0.2363],\n",
            "        [-0.2914,  0.3758, -0.4152],\n",
            "        [-2.0907,  1.5181,  0.4858],\n",
            "        [-2.1157,  0.6642,  1.0349],\n",
            "        [-1.3109,  1.4059, -0.2993],\n",
            "        [-1.4545,  1.2947, -0.1371]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6759,  1.6716, -0.2213],\n",
            "        [-1.0731,  1.4011, -0.4666],\n",
            "        [-1.9086,  1.6802, -0.0567],\n",
            "        [-1.9591,  1.2062,  0.2760],\n",
            "        [ 0.0521,  0.3491, -0.9278],\n",
            "        [-1.7448,  1.5687, -0.1287],\n",
            "        [-1.3753,  1.4690, -0.5342],\n",
            "        [-1.5631,  1.4995, -0.1556],\n",
            "        [-1.8241,  1.1768,  0.4509],\n",
            "        [-1.6172,  1.5463, -0.2080],\n",
            "        [-1.6253,  1.6422, -0.2363],\n",
            "        [-0.2914,  0.3758, -0.4152],\n",
            "        [-2.0907,  1.5181,  0.4858],\n",
            "        [-2.1157,  0.6642,  1.0349],\n",
            "        [-1.3109,  1.4059, -0.2993],\n",
            "        [-1.4545,  1.2947, -0.1371]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6140,  1.5033, -0.2607],\n",
            "        [ 0.1503,  0.4033, -1.0496],\n",
            "        [-1.5940,  1.2337,  0.0703],\n",
            "        [-2.0055,  0.4589,  1.2230],\n",
            "        [-1.3236,  1.4461, -0.2700],\n",
            "        [-1.9710,  0.8080,  0.9093],\n",
            "        [-1.4481,  1.6240, -0.3440],\n",
            "        [-1.5684,  1.4916, -0.3932],\n",
            "        [-2.1728,  1.1187,  0.8299],\n",
            "        [-1.7910,  1.5849, -0.2145],\n",
            "        [ 0.2528,  0.1881, -0.7717],\n",
            "        [-0.0252,  0.6912, -0.9828],\n",
            "        [-1.4525,  1.5486, -0.2833],\n",
            "        [-0.4542,  0.1219, -0.1150],\n",
            "        [-1.4667,  1.4827, -0.1354],\n",
            "        [-1.8101,  0.4678,  0.9431]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6140,  1.5033, -0.2607],\n",
            "        [ 0.1503,  0.4033, -1.0496],\n",
            "        [-1.5940,  1.2337,  0.0703],\n",
            "        [-2.0055,  0.4589,  1.2230],\n",
            "        [-1.3236,  1.4461, -0.2700],\n",
            "        [-1.9710,  0.8080,  0.9093],\n",
            "        [-1.4481,  1.6240, -0.3440],\n",
            "        [-1.5684,  1.4916, -0.3932],\n",
            "        [-2.1728,  1.1187,  0.8299],\n",
            "        [-1.7910,  1.5849, -0.2145],\n",
            "        [ 0.2528,  0.1881, -0.7717],\n",
            "        [-0.0252,  0.6912, -0.9828],\n",
            "        [-1.4525,  1.5486, -0.2833],\n",
            "        [-0.4542,  0.1219, -0.1150],\n",
            "        [-1.4667,  1.4827, -0.1354],\n",
            "        [-1.8101,  0.4678,  0.9431]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3753,  1.6768, -0.4969],\n",
            "        [ 0.3957,  0.1830, -1.0354],\n",
            "        [-1.9360,  0.7125,  1.0642],\n",
            "        [-1.5902,  1.6409, -0.2251],\n",
            "        [-2.0004,  0.3990,  1.1998],\n",
            "        [-1.7467,  0.2143,  1.1406],\n",
            "        [-1.6047,  1.5968,  0.0389],\n",
            "        [-1.2888,  0.7063,  0.1743],\n",
            "        [-1.8903,  0.5564,  0.8095],\n",
            "        [-2.0570,  0.7214,  0.8618],\n",
            "        [-1.9412,  0.3163,  1.2128],\n",
            "        [-1.9587,  0.3222,  1.0600],\n",
            "        [-1.6474,  1.8844, -0.0548],\n",
            "        [-1.6329,  1.8560, -0.4924],\n",
            "        [-1.7570,  1.0013,  0.4124],\n",
            "        [-1.9182,  0.5818,  1.1856]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3753,  1.6768, -0.4969],\n",
            "        [ 0.3957,  0.1830, -1.0354],\n",
            "        [-1.9360,  0.7125,  1.0642],\n",
            "        [-1.5902,  1.6409, -0.2251],\n",
            "        [-2.0004,  0.3990,  1.1998],\n",
            "        [-1.7467,  0.2143,  1.1406],\n",
            "        [-1.6047,  1.5968,  0.0389],\n",
            "        [-1.2888,  0.7063,  0.1743],\n",
            "        [-1.8903,  0.5564,  0.8095],\n",
            "        [-2.0570,  0.7214,  0.8618],\n",
            "        [-1.9412,  0.3163,  1.2128],\n",
            "        [-1.9587,  0.3222,  1.0600],\n",
            "        [-1.6474,  1.8844, -0.0548],\n",
            "        [-1.6329,  1.8560, -0.4924],\n",
            "        [-1.7570,  1.0013,  0.4124],\n",
            "        [-1.9182,  0.5818,  1.1856]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5973,  0.2230, -1.1858],\n",
            "        [-0.8074,  0.6609, -0.1021],\n",
            "        [-1.1486,  1.0715, -0.1448],\n",
            "        [-1.8977,  0.1990,  1.0693],\n",
            "        [-1.3293,  1.5357, -0.3347],\n",
            "        [-1.4613,  1.6599, -0.4178],\n",
            "        [ 0.6110,  0.2210, -1.2199],\n",
            "        [-1.6408,  1.4961, -0.0210],\n",
            "        [-2.2004,  0.5120,  1.1313],\n",
            "        [-1.1272,  0.6656,  0.1048],\n",
            "        [-1.4778,  1.5010, -0.1517],\n",
            "        [-0.9022,  1.2354, -0.5189],\n",
            "        [-1.7323,  1.2608,  0.0296],\n",
            "        [-2.1106,  0.4833,  1.3013],\n",
            "        [-1.1755,  1.5724, -0.5026],\n",
            "        [-1.8445,  0.3859,  1.0886]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.5973,  0.2230, -1.1858],\n",
            "        [-0.8074,  0.6609, -0.1021],\n",
            "        [-1.1486,  1.0715, -0.1448],\n",
            "        [-1.8977,  0.1990,  1.0693],\n",
            "        [-1.3293,  1.5357, -0.3347],\n",
            "        [-1.4613,  1.6599, -0.4178],\n",
            "        [ 0.6110,  0.2210, -1.2199],\n",
            "        [-1.6408,  1.4961, -0.0210],\n",
            "        [-2.2004,  0.5120,  1.1313],\n",
            "        [-1.1272,  0.6656,  0.1048],\n",
            "        [-1.4778,  1.5010, -0.1517],\n",
            "        [-0.9022,  1.2354, -0.5189],\n",
            "        [-1.7323,  1.2608,  0.0296],\n",
            "        [-2.1106,  0.4833,  1.3013],\n",
            "        [-1.1755,  1.5724, -0.5026],\n",
            "        [-1.8445,  0.3859,  1.0886]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.8006,  0.1838, -1.1799],\n",
            "        [-1.1851,  1.3206, -0.3892],\n",
            "        [-0.1068,  0.5842, -0.6880],\n",
            "        [-1.2313,  1.5963, -0.4567],\n",
            "        [-1.6982,  0.2484,  0.9321],\n",
            "        [-1.5416,  1.4136, -0.3174],\n",
            "        [-0.1535,  0.5851, -0.6179],\n",
            "        [-1.3486,  1.4698, -0.2745],\n",
            "        [ 0.5987,  0.1131, -1.1652],\n",
            "        [-1.9203,  1.5752,  0.0357],\n",
            "        [ 0.4674,  0.3024, -1.3094],\n",
            "        [ 0.5296,  0.2798, -1.1643],\n",
            "        [-2.2177,  0.4585,  1.2456],\n",
            "        [-1.2355,  1.5529, -0.6887],\n",
            "        [-1.6824,  1.6023, -0.1322],\n",
            "        [ 0.5538,  0.2873, -1.1733]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.8006,  0.1838, -1.1799],\n",
            "        [-1.1851,  1.3206, -0.3892],\n",
            "        [-0.1068,  0.5842, -0.6880],\n",
            "        [-1.2313,  1.5963, -0.4567],\n",
            "        [-1.6982,  0.2484,  0.9321],\n",
            "        [-1.5416,  1.4136, -0.3174],\n",
            "        [-0.1535,  0.5851, -0.6179],\n",
            "        [-1.3486,  1.4698, -0.2745],\n",
            "        [ 0.5987,  0.1131, -1.1652],\n",
            "        [-1.9203,  1.5752,  0.0357],\n",
            "        [ 0.4674,  0.3024, -1.3094],\n",
            "        [ 0.5296,  0.2798, -1.1643],\n",
            "        [-2.2177,  0.4585,  1.2456],\n",
            "        [-1.2355,  1.5529, -0.6887],\n",
            "        [-1.6824,  1.6023, -0.1322],\n",
            "        [ 0.5538,  0.2873, -1.1733]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.3697,  0.9920, -0.7754],\n",
            "        [-1.2106,  1.4391, -0.4400],\n",
            "        [-1.4155,  0.2457,  0.7984],\n",
            "        [-0.9193,  1.1170, -0.5218],\n",
            "        [-1.2319,  1.4657, -0.3222],\n",
            "        [-0.9815,  1.2991, -0.6557],\n",
            "        [-1.1828,  0.9487,  0.2290],\n",
            "        [-1.7366,  1.1216,  0.2688],\n",
            "        [ 0.4994,  0.2167, -1.0871],\n",
            "        [-1.7177,  0.4087,  0.9409],\n",
            "        [-1.1130,  1.4891, -0.8582],\n",
            "        [ 0.4919,  0.3423, -1.1642],\n",
            "        [-2.0515,  0.7341,  1.0213],\n",
            "        [-1.6007,  1.6348, -0.2447],\n",
            "        [-1.1571,  1.4991, -0.5738],\n",
            "        [-1.1562,  0.9049, -0.0372]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-0.3697,  0.9920, -0.7754],\n",
            "        [-1.2106,  1.4391, -0.4400],\n",
            "        [-1.4155,  0.2457,  0.7984],\n",
            "        [-0.9193,  1.1170, -0.5218],\n",
            "        [-1.2319,  1.4657, -0.3222],\n",
            "        [-0.9815,  1.2991, -0.6557],\n",
            "        [-1.1828,  0.9487,  0.2290],\n",
            "        [-1.7366,  1.1216,  0.2688],\n",
            "        [ 0.4994,  0.2167, -1.0871],\n",
            "        [-1.7177,  0.4087,  0.9409],\n",
            "        [-1.1130,  1.4891, -0.8582],\n",
            "        [ 0.4919,  0.3423, -1.1642],\n",
            "        [-2.0515,  0.7341,  1.0213],\n",
            "        [-1.6007,  1.6348, -0.2447],\n",
            "        [-1.1571,  1.4991, -0.5738],\n",
            "        [-1.1562,  0.9049, -0.0372]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.1913,  0.7271,  0.0420],\n",
            "        [-0.4413,  0.1819, -0.3850],\n",
            "        [-0.0075,  0.7480, -0.9310],\n",
            "        [-1.0926,  1.2736, -0.3589],\n",
            "        [-1.3461,  1.6901, -0.3696],\n",
            "        [-0.5823,  1.1109, -0.5999],\n",
            "        [-1.2162,  1.2883, -0.3075],\n",
            "        [-1.3809,  1.4710, -0.5487],\n",
            "        [-1.7000,  0.5077,  0.9162],\n",
            "        [-0.2357,  0.7510, -1.0525],\n",
            "        [-1.5574,  1.0203,  0.2140],\n",
            "        [-1.4350,  1.6889, -0.4240],\n",
            "        [ 0.0673,  0.4106, -0.6758],\n",
            "        [-1.1210,  1.5366, -0.4299],\n",
            "        [-1.1359,  1.2612, -0.3724],\n",
            "        [-1.5389,  1.6430, -0.1619]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.1913,  0.7271,  0.0420],\n",
            "        [-0.4413,  0.1819, -0.3850],\n",
            "        [-0.0075,  0.7480, -0.9310],\n",
            "        [-1.0926,  1.2736, -0.3589],\n",
            "        [-1.3461,  1.6901, -0.3696],\n",
            "        [-0.5823,  1.1109, -0.5999],\n",
            "        [-1.2162,  1.2883, -0.3075],\n",
            "        [-1.3809,  1.4710, -0.5487],\n",
            "        [-1.7000,  0.5077,  0.9162],\n",
            "        [-0.2357,  0.7510, -1.0525],\n",
            "        [-1.5574,  1.0203,  0.2140],\n",
            "        [-1.4350,  1.6889, -0.4240],\n",
            "        [ 0.0673,  0.4106, -0.6758],\n",
            "        [-1.1210,  1.5366, -0.4299],\n",
            "        [-1.1359,  1.2612, -0.3724],\n",
            "        [-1.5389,  1.6430, -0.1619]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7706,  1.5548,  0.0273],\n",
            "        [-1.1204,  1.8101, -0.7279],\n",
            "        [-1.8705,  0.7083,  0.7870],\n",
            "        [-1.5511,  1.5350, -0.3603],\n",
            "        [ 0.7227,  0.1734, -1.1677],\n",
            "        [-1.1657,  1.7444, -0.6626],\n",
            "        [-0.9880,  1.4909, -0.3294],\n",
            "        [-1.3949,  1.4992, -0.5978],\n",
            "        [-0.6275,  1.1607, -0.8052],\n",
            "        [-1.4345,  1.4840, -0.1883],\n",
            "        [-2.0596,  0.4227,  1.0981],\n",
            "        [-1.8638,  1.4927,  0.2669],\n",
            "        [-1.3438,  1.1725, -0.1904],\n",
            "        [ 0.7404,  0.0961, -1.2912],\n",
            "        [ 0.0532,  0.2158, -0.8871],\n",
            "        [-1.6465,  2.0016, -0.3326]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7706,  1.5548,  0.0273],\n",
            "        [-1.1204,  1.8101, -0.7279],\n",
            "        [-1.8705,  0.7083,  0.7870],\n",
            "        [-1.5511,  1.5350, -0.3603],\n",
            "        [ 0.7227,  0.1734, -1.1677],\n",
            "        [-1.1657,  1.7444, -0.6626],\n",
            "        [-0.9880,  1.4909, -0.3294],\n",
            "        [-1.3949,  1.4992, -0.5978],\n",
            "        [-0.6275,  1.1607, -0.8052],\n",
            "        [-1.4345,  1.4840, -0.1883],\n",
            "        [-2.0596,  0.4227,  1.0981],\n",
            "        [-1.8638,  1.4927,  0.2669],\n",
            "        [-1.3438,  1.1725, -0.1904],\n",
            "        [ 0.7404,  0.0961, -1.2912],\n",
            "        [ 0.0532,  0.2158, -0.8871],\n",
            "        [-1.6465,  2.0016, -0.3326]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.8484,  0.6708, -0.1337],\n",
            "        [-1.5146,  1.5082, -0.0853],\n",
            "        [-1.7440,  1.4008,  0.1099],\n",
            "        [-1.6357,  0.2873,  0.9916],\n",
            "        [-0.7330,  1.1726, -0.8706],\n",
            "        [-0.1389,  0.2524, -0.4708],\n",
            "        [ 0.4411,  0.3131, -0.9739],\n",
            "        [-0.6437,  0.7536, -0.5119],\n",
            "        [ 0.1782,  0.4933, -1.2898],\n",
            "        [-1.4993,  1.5275, -0.4923],\n",
            "        [-1.6522,  0.8363,  0.3254],\n",
            "        [-1.2304,  1.2960, -0.4524],\n",
            "        [-0.2675,  0.5801, -0.7008],\n",
            "        [-1.7011,  0.3275,  0.9615],\n",
            "        [-1.5170,  1.7728, -0.4745],\n",
            "        [-1.5750,  1.5930, -0.2669]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-0.8484,  0.6708, -0.1337],\n",
            "        [-1.5146,  1.5082, -0.0853],\n",
            "        [-1.7440,  1.4008,  0.1099],\n",
            "        [-1.6357,  0.2873,  0.9916],\n",
            "        [-0.7330,  1.1726, -0.8706],\n",
            "        [-0.1389,  0.2524, -0.4708],\n",
            "        [ 0.4411,  0.3131, -0.9739],\n",
            "        [-0.6437,  0.7536, -0.5119],\n",
            "        [ 0.1782,  0.4933, -1.2898],\n",
            "        [-1.4993,  1.5275, -0.4923],\n",
            "        [-1.6522,  0.8363,  0.3254],\n",
            "        [-1.2304,  1.2960, -0.4524],\n",
            "        [-0.2675,  0.5801, -0.7008],\n",
            "        [-1.7011,  0.3275,  0.9615],\n",
            "        [-1.5170,  1.7728, -0.4745],\n",
            "        [-1.5750,  1.5930, -0.2669]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7220,  0.7358,  0.7211],\n",
            "        [-1.8245,  0.2591,  1.0525],\n",
            "        [-1.2307,  1.4376, -0.6816],\n",
            "        [-1.6311,  0.8505,  0.4506],\n",
            "        [-2.1516,  0.4717,  1.0135],\n",
            "        [-1.3775,  1.8513, -0.6397],\n",
            "        [ 0.2993,  0.4065, -1.1149],\n",
            "        [-1.8796,  0.9210,  0.7396],\n",
            "        [-2.1009,  0.7707,  0.9550],\n",
            "        [ 0.3884,  0.2012, -1.1451],\n",
            "        [-1.7811,  1.1746,  0.3255],\n",
            "        [-1.3305,  1.7198, -0.5546],\n",
            "        [-1.0005,  1.2715, -0.6175],\n",
            "        [-0.4301,  1.1162, -1.0808],\n",
            "        [-0.9869,  1.4502, -0.6751],\n",
            "        [-1.2403,  1.4495, -0.5661]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7220,  0.7358,  0.7211],\n",
            "        [-1.8245,  0.2591,  1.0525],\n",
            "        [-1.2307,  1.4376, -0.6816],\n",
            "        [-1.6311,  0.8505,  0.4506],\n",
            "        [-2.1516,  0.4717,  1.0135],\n",
            "        [-1.3775,  1.8513, -0.6397],\n",
            "        [ 0.2993,  0.4065, -1.1149],\n",
            "        [-1.8796,  0.9210,  0.7396],\n",
            "        [-2.1009,  0.7707,  0.9550],\n",
            "        [ 0.3884,  0.2012, -1.1451],\n",
            "        [-1.7811,  1.1746,  0.3255],\n",
            "        [-1.3305,  1.7198, -0.5546],\n",
            "        [-1.0005,  1.2715, -0.6175],\n",
            "        [-0.4301,  1.1162, -1.0808],\n",
            "        [-0.9869,  1.4502, -0.6751],\n",
            "        [-1.2403,  1.4495, -0.5661]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2150,  1.7462, -0.5996],\n",
            "        [-1.3728,  1.9337, -0.3615],\n",
            "        [-1.4172,  0.4024,  0.7580],\n",
            "        [-1.2918,  1.7338, -0.6560],\n",
            "        [-1.1495,  1.5671, -0.5117],\n",
            "        [ 0.6474,  0.2765, -1.3047],\n",
            "        [-1.3607,  0.7682,  0.1445],\n",
            "        [-1.4177,  1.5407, -0.4057],\n",
            "        [ 0.5847,  0.0949, -1.2355],\n",
            "        [-1.0655,  0.1655,  0.4295],\n",
            "        [-0.8396,  1.0906, -0.3057],\n",
            "        [-1.7432,  1.5971, -0.0654],\n",
            "        [-0.4045,  1.0868, -0.8353],\n",
            "        [-1.5601,  1.6384, -0.3806],\n",
            "        [-0.0383,  0.8220, -0.9960],\n",
            "        [-1.3809,  1.9747, -0.4554]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2150,  1.7462, -0.5996],\n",
            "        [-1.3728,  1.9337, -0.3615],\n",
            "        [-1.4172,  0.4024,  0.7580],\n",
            "        [-1.2918,  1.7338, -0.6560],\n",
            "        [-1.1495,  1.5671, -0.5117],\n",
            "        [ 0.6474,  0.2765, -1.3047],\n",
            "        [-1.3607,  0.7682,  0.1445],\n",
            "        [-1.4177,  1.5407, -0.4057],\n",
            "        [ 0.5847,  0.0949, -1.2355],\n",
            "        [-1.0655,  0.1655,  0.4295],\n",
            "        [-0.8396,  1.0906, -0.3057],\n",
            "        [-1.7432,  1.5971, -0.0654],\n",
            "        [-0.4045,  1.0868, -0.8353],\n",
            "        [-1.5601,  1.6384, -0.3806],\n",
            "        [-0.0383,  0.8220, -0.9960],\n",
            "        [-1.3809,  1.9747, -0.4554]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5575,  1.8216, -0.5019],\n",
            "        [-1.5537,  1.6238, -0.3129],\n",
            "        [-1.3453,  1.6854, -0.5172],\n",
            "        [-1.9373,  0.7114,  0.9558],\n",
            "        [ 0.8308,  0.1064, -1.1417],\n",
            "        [-1.4649,  1.7960, -0.5593],\n",
            "        [-1.4233,  1.7772, -0.4258],\n",
            "        [-1.2703,  1.7407, -0.5835],\n",
            "        [-1.7634,  1.9395, -0.4068],\n",
            "        [-1.4961,  1.9062, -0.2903],\n",
            "        [-1.9202,  1.1424,  0.1760],\n",
            "        [-1.0870,  1.1381, -0.4247],\n",
            "        [ 0.5013,  0.4652, -1.1734],\n",
            "        [-1.6980,  1.5936, -0.0030],\n",
            "        [-0.3107,  0.3449, -0.4086],\n",
            "        [-0.7531,  1.2893, -0.6184]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5575,  1.8216, -0.5019],\n",
            "        [-1.5537,  1.6238, -0.3129],\n",
            "        [-1.3453,  1.6854, -0.5172],\n",
            "        [-1.9373,  0.7114,  0.9558],\n",
            "        [ 0.8308,  0.1064, -1.1417],\n",
            "        [-1.4649,  1.7960, -0.5593],\n",
            "        [-1.4233,  1.7772, -0.4258],\n",
            "        [-1.2703,  1.7407, -0.5835],\n",
            "        [-1.7634,  1.9395, -0.4068],\n",
            "        [-1.4961,  1.9062, -0.2903],\n",
            "        [-1.9202,  1.1424,  0.1760],\n",
            "        [-1.0870,  1.1381, -0.4247],\n",
            "        [ 0.5013,  0.4652, -1.1734],\n",
            "        [-1.6980,  1.5936, -0.0030],\n",
            "        [-0.3107,  0.3449, -0.4086],\n",
            "        [-0.7531,  1.2893, -0.6184]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.2296,  0.3842, -1.0622],\n",
            "        [-1.5998,  1.6553, -0.4885],\n",
            "        [-1.0807,  1.1339, -0.3214],\n",
            "        [-2.0213,  0.3211,  1.0273],\n",
            "        [-1.6417,  1.8457, -0.3277],\n",
            "        [-1.7832,  1.7823, -0.3341],\n",
            "        [-1.7114,  1.1416,  0.5137],\n",
            "        [-1.2058,  1.6167, -0.5470],\n",
            "        [-1.7519,  1.2756,  0.4459],\n",
            "        [-1.4309,  1.8602, -0.5583],\n",
            "        [-1.5374,  1.7372, -0.4784],\n",
            "        [-1.8441,  0.1623,  1.1801],\n",
            "        [-0.1786,  0.2892, -0.4428],\n",
            "        [-2.0425,  0.9833,  0.6288],\n",
            "        [-1.4564,  1.6962, -0.4482],\n",
            "        [-1.7440,  2.1448, -0.5848]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.2296,  0.3842, -1.0622],\n",
            "        [-1.5998,  1.6553, -0.4885],\n",
            "        [-1.0807,  1.1339, -0.3214],\n",
            "        [-2.0213,  0.3211,  1.0273],\n",
            "        [-1.6417,  1.8457, -0.3277],\n",
            "        [-1.7832,  1.7823, -0.3341],\n",
            "        [-1.7114,  1.1416,  0.5137],\n",
            "        [-1.2058,  1.6167, -0.5470],\n",
            "        [-1.7519,  1.2756,  0.4459],\n",
            "        [-1.4309,  1.8602, -0.5583],\n",
            "        [-1.5374,  1.7372, -0.4784],\n",
            "        [-1.8441,  0.1623,  1.1801],\n",
            "        [-0.1786,  0.2892, -0.4428],\n",
            "        [-2.0425,  0.9833,  0.6288],\n",
            "        [-1.4564,  1.6962, -0.4482],\n",
            "        [-1.7440,  2.1448, -0.5848]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.3660,  0.2152, -0.0902],\n",
            "        [-1.9293,  1.1718,  0.3303],\n",
            "        [-1.7369,  1.8085, -0.3807],\n",
            "        [-1.6699,  1.8534, -0.3675],\n",
            "        [-1.6346,  1.8749, -0.2816],\n",
            "        [ 0.0414,  0.7619, -0.8653],\n",
            "        [ 0.2629,  0.5767, -1.1333],\n",
            "        [-0.3879,  0.2082, -0.1836],\n",
            "        [-1.3112,  1.5863, -0.3532],\n",
            "        [-1.5473,  1.7702, -0.3588],\n",
            "        [-1.0985,  0.3036,  0.4518],\n",
            "        [-1.4766,  1.6774, -0.4064],\n",
            "        [-1.5570,  1.6420, -0.4294],\n",
            "        [-1.7719,  1.1852,  0.2764],\n",
            "        [-1.9386,  1.9506, -0.1950],\n",
            "        [ 0.6963,  0.1875, -1.2469]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-0.3660,  0.2152, -0.0902],\n",
            "        [-1.9293,  1.1718,  0.3303],\n",
            "        [-1.7369,  1.8085, -0.3807],\n",
            "        [-1.6699,  1.8534, -0.3675],\n",
            "        [-1.6346,  1.8749, -0.2816],\n",
            "        [ 0.0414,  0.7619, -0.8653],\n",
            "        [ 0.2629,  0.5767, -1.1333],\n",
            "        [-0.3879,  0.2082, -0.1836],\n",
            "        [-1.3112,  1.5863, -0.3532],\n",
            "        [-1.5473,  1.7702, -0.3588],\n",
            "        [-1.0985,  0.3036,  0.4518],\n",
            "        [-1.4766,  1.6774, -0.4064],\n",
            "        [-1.5570,  1.6420, -0.4294],\n",
            "        [-1.7719,  1.1852,  0.2764],\n",
            "        [-1.9386,  1.9506, -0.1950],\n",
            "        [ 0.6963,  0.1875, -1.2469]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6680,  1.8943, -0.4425],\n",
            "        [-1.6076,  1.5040, -0.2145],\n",
            "        [-1.5170,  1.6459, -0.3154],\n",
            "        [-1.3811,  1.7844, -0.4989],\n",
            "        [-1.2859,  1.8791, -0.6064],\n",
            "        [-1.8538,  1.8863, -0.2506],\n",
            "        [-1.2787,  1.1921, -0.0719],\n",
            "        [ 0.3482,  0.2356, -0.9715],\n",
            "        [-1.8154,  0.5290,  1.1479],\n",
            "        [-2.0830,  0.2697,  1.1770],\n",
            "        [ 0.0257,  0.7619, -0.9509],\n",
            "        [-1.6492,  1.9018, -0.1053],\n",
            "        [-2.0920,  0.6405,  0.9879],\n",
            "        [-1.5188,  1.6063, -0.3840],\n",
            "        [-1.6852,  1.8250, -0.5523],\n",
            "        [-1.3999,  1.7053, -0.4829]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6680,  1.8943, -0.4425],\n",
            "        [-1.6076,  1.5040, -0.2145],\n",
            "        [-1.5170,  1.6459, -0.3154],\n",
            "        [-1.3811,  1.7844, -0.4989],\n",
            "        [-1.2859,  1.8791, -0.6064],\n",
            "        [-1.8538,  1.8863, -0.2506],\n",
            "        [-1.2787,  1.1921, -0.0719],\n",
            "        [ 0.3482,  0.2356, -0.9715],\n",
            "        [-1.8154,  0.5290,  1.1479],\n",
            "        [-2.0830,  0.2697,  1.1770],\n",
            "        [ 0.0257,  0.7619, -0.9509],\n",
            "        [-1.6492,  1.9018, -0.1053],\n",
            "        [-2.0920,  0.6405,  0.9879],\n",
            "        [-1.5188,  1.6063, -0.3840],\n",
            "        [-1.6852,  1.8250, -0.5523],\n",
            "        [-1.3999,  1.7053, -0.4829]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3178,  1.7021, -0.3209],\n",
            "        [-1.7084,  1.6022, -0.0505],\n",
            "        [-1.6900,  1.7193, -0.4076],\n",
            "        [-1.6111,  1.7707, -0.2561],\n",
            "        [-1.8703,  1.7311, -0.1936],\n",
            "        [ 0.5176,  0.3047, -1.1362],\n",
            "        [-1.6507,  1.8585, -0.4621],\n",
            "        [-1.4197,  1.6192, -0.6777],\n",
            "        [ 0.3691,  0.4136, -1.1752],\n",
            "        [-0.9271,  1.6728, -0.7101],\n",
            "        [-1.8957,  1.3729,  0.1883],\n",
            "        [-1.0012,  1.4496, -0.6520],\n",
            "        [-0.8108,  1.2970, -0.4018],\n",
            "        [-1.6078,  1.8273, -0.4876],\n",
            "        [-1.8773,  1.6140, -0.0773],\n",
            "        [-1.9958,  0.9896,  0.5378]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3178,  1.7021, -0.3209],\n",
            "        [-1.7084,  1.6022, -0.0505],\n",
            "        [-1.6900,  1.7193, -0.4076],\n",
            "        [-1.6111,  1.7707, -0.2561],\n",
            "        [-1.8703,  1.7311, -0.1936],\n",
            "        [ 0.5176,  0.3047, -1.1362],\n",
            "        [-1.6507,  1.8585, -0.4621],\n",
            "        [-1.4197,  1.6192, -0.6777],\n",
            "        [ 0.3691,  0.4136, -1.1752],\n",
            "        [-0.9271,  1.6728, -0.7101],\n",
            "        [-1.8957,  1.3729,  0.1883],\n",
            "        [-1.0012,  1.4496, -0.6520],\n",
            "        [-0.8108,  1.2970, -0.4018],\n",
            "        [-1.6078,  1.8273, -0.4876],\n",
            "        [-1.8773,  1.6140, -0.0773],\n",
            "        [-1.9958,  0.9896,  0.5378]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5234,  0.5419, -1.2099],\n",
            "        [-1.6177,  1.9447, -0.3205],\n",
            "        [-0.9918,  0.2494,  0.2910],\n",
            "        [-1.5204,  1.7287, -0.2758],\n",
            "        [-1.4441,  1.6588, -0.0457],\n",
            "        [-1.1474,  1.5402, -0.5231],\n",
            "        [-1.9453,  0.4978,  1.1515],\n",
            "        [-1.8884,  1.7680, -0.3039],\n",
            "        [-1.9785,  1.7036,  0.4697],\n",
            "        [-2.1451,  0.4319,  1.2681],\n",
            "        [-2.0069,  0.3729,  1.1088],\n",
            "        [-1.6763,  1.5877, -0.2881],\n",
            "        [-0.3762,  1.0447, -0.8469],\n",
            "        [ 0.4518,  0.3701, -1.1998],\n",
            "        [-2.4083,  1.2536,  0.3555],\n",
            "        [-1.5824,  0.3606,  1.0748]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.5234,  0.5419, -1.2099],\n",
            "        [-1.6177,  1.9447, -0.3205],\n",
            "        [-0.9918,  0.2494,  0.2910],\n",
            "        [-1.5204,  1.7287, -0.2758],\n",
            "        [-1.4441,  1.6588, -0.0457],\n",
            "        [-1.1474,  1.5402, -0.5231],\n",
            "        [-1.9453,  0.4978,  1.1515],\n",
            "        [-1.8884,  1.7680, -0.3039],\n",
            "        [-1.9785,  1.7036,  0.4697],\n",
            "        [-2.1451,  0.4319,  1.2681],\n",
            "        [-2.0069,  0.3729,  1.1088],\n",
            "        [-1.6763,  1.5877, -0.2881],\n",
            "        [-0.3762,  1.0447, -0.8469],\n",
            "        [ 0.4518,  0.3701, -1.1998],\n",
            "        [-2.4083,  1.2536,  0.3555],\n",
            "        [-1.5824,  0.3606,  1.0748]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5364,  1.7833, -0.3162],\n",
            "        [-1.5357,  1.7130, -0.3813],\n",
            "        [-1.8087,  1.8362, -0.1479],\n",
            "        [ 0.2578,  0.3840, -1.2029],\n",
            "        [-1.7731,  1.6891, -0.2608],\n",
            "        [-2.0343,  0.9308,  0.9065],\n",
            "        [-1.6460,  2.0082, -0.3024],\n",
            "        [-2.1672,  0.5042,  1.3399],\n",
            "        [-1.7187,  1.4884, -0.1290],\n",
            "        [-0.4438,  0.2978, -0.2193],\n",
            "        [-1.5703,  1.9288, -0.4716],\n",
            "        [-1.7384,  0.4309,  0.9795],\n",
            "        [-1.6622,  2.0966, -0.5079],\n",
            "        [-2.0734,  0.5270,  1.0462],\n",
            "        [-1.4884,  1.7898, -0.4800],\n",
            "        [-1.5671,  2.0410, -0.6064]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5364,  1.7833, -0.3162],\n",
            "        [-1.5357,  1.7130, -0.3813],\n",
            "        [-1.8087,  1.8362, -0.1479],\n",
            "        [ 0.2578,  0.3840, -1.2029],\n",
            "        [-1.7731,  1.6891, -0.2608],\n",
            "        [-2.0343,  0.9308,  0.9065],\n",
            "        [-1.6460,  2.0082, -0.3024],\n",
            "        [-2.1672,  0.5042,  1.3399],\n",
            "        [-1.7187,  1.4884, -0.1290],\n",
            "        [-0.4438,  0.2978, -0.2193],\n",
            "        [-1.5703,  1.9288, -0.4716],\n",
            "        [-1.7384,  0.4309,  0.9795],\n",
            "        [-1.6622,  2.0966, -0.5079],\n",
            "        [-2.0734,  0.5270,  1.0462],\n",
            "        [-1.4884,  1.7898, -0.4800],\n",
            "        [-1.5671,  2.0410, -0.6064]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.3870,  0.7302, -0.6633],\n",
            "        [-1.0473,  1.7291, -0.5552],\n",
            "        [-1.5161,  1.6221, -0.2656],\n",
            "        [-1.6716,  1.6950, -0.2783],\n",
            "        [-1.3567,  1.7236, -0.4035],\n",
            "        [-1.8428,  0.4565,  0.9462],\n",
            "        [-1.5781,  1.7617, -0.3984],\n",
            "        [-1.8955,  1.6885, -0.2908],\n",
            "        [-1.5063,  1.5907, -0.2137],\n",
            "        [ 0.3030,  0.6342, -0.9724],\n",
            "        [-1.7094,  1.9018, -0.3598],\n",
            "        [-1.6893,  1.6522, -0.0491],\n",
            "        [-1.6632,  1.7266, -0.4439],\n",
            "        [-1.7538,  1.6987, -0.2620],\n",
            "        [-2.1156,  0.4729,  0.8837],\n",
            "        [-1.4241,  1.9635, -0.5820]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-0.3870,  0.7302, -0.6633],\n",
            "        [-1.0473,  1.7291, -0.5552],\n",
            "        [-1.5161,  1.6221, -0.2656],\n",
            "        [-1.6716,  1.6950, -0.2783],\n",
            "        [-1.3567,  1.7236, -0.4035],\n",
            "        [-1.8428,  0.4565,  0.9462],\n",
            "        [-1.5781,  1.7617, -0.3984],\n",
            "        [-1.8955,  1.6885, -0.2908],\n",
            "        [-1.5063,  1.5907, -0.2137],\n",
            "        [ 0.3030,  0.6342, -0.9724],\n",
            "        [-1.7094,  1.9018, -0.3598],\n",
            "        [-1.6893,  1.6522, -0.0491],\n",
            "        [-1.6632,  1.7266, -0.4439],\n",
            "        [-1.7538,  1.6987, -0.2620],\n",
            "        [-2.1156,  0.4729,  0.8837],\n",
            "        [-1.4241,  1.9635, -0.5820]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.8682,  1.2301, -0.6830],\n",
            "        [-1.7328,  1.8076, -0.3258],\n",
            "        [-1.6954,  1.7991, -0.4088],\n",
            "        [-2.0723,  0.9818,  0.8392],\n",
            "        [-1.7571,  1.6441, -0.1834],\n",
            "        [-2.0621,  0.3723,  1.1957],\n",
            "        [-1.7601,  1.9191, -0.3923],\n",
            "        [-1.3508,  1.7472, -0.4569],\n",
            "        [-1.7694,  1.8965, -0.1290],\n",
            "        [-1.8406,  0.6586,  0.7912],\n",
            "        [-1.6160,  0.3435,  0.9541],\n",
            "        [-1.5791,  1.5556, -0.2814],\n",
            "        [-1.8795,  0.2958,  1.2399],\n",
            "        [-1.8980,  1.7882, -0.0753],\n",
            "        [-1.9138,  0.3857,  1.1330],\n",
            "        [-1.7374,  0.4367,  1.0293]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-0.8682,  1.2301, -0.6830],\n",
            "        [-1.7328,  1.8076, -0.3258],\n",
            "        [-1.6954,  1.7991, -0.4088],\n",
            "        [-2.0723,  0.9818,  0.8392],\n",
            "        [-1.7571,  1.6441, -0.1834],\n",
            "        [-2.0621,  0.3723,  1.1957],\n",
            "        [-1.7601,  1.9191, -0.3923],\n",
            "        [-1.3508,  1.7472, -0.4569],\n",
            "        [-1.7694,  1.8965, -0.1290],\n",
            "        [-1.8406,  0.6586,  0.7912],\n",
            "        [-1.6160,  0.3435,  0.9541],\n",
            "        [-1.5791,  1.5556, -0.2814],\n",
            "        [-1.8795,  0.2958,  1.2399],\n",
            "        [-1.8980,  1.7882, -0.0753],\n",
            "        [-1.9138,  0.3857,  1.1330],\n",
            "        [-1.7374,  0.4367,  1.0293]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4263,  1.3913, -0.1417],\n",
            "        [-0.7640,  0.0834,  0.0807],\n",
            "        [-1.6018,  1.7291, -0.4561],\n",
            "        [-1.5258,  1.8251, -0.3872],\n",
            "        [ 0.1680,  0.2522, -0.7748],\n",
            "        [-1.4780,  1.7410, -0.2770],\n",
            "        [-1.6416,  0.6936,  0.7465],\n",
            "        [-1.3851,  1.4639, -0.2896],\n",
            "        [-1.5832,  1.7730, -0.2794],\n",
            "        [-1.8677,  1.3803,  0.1536],\n",
            "        [-1.2487,  1.9524, -0.6876],\n",
            "        [-1.9615,  0.4573,  0.9468],\n",
            "        [-1.4492,  1.7715, -0.4111],\n",
            "        [-1.2733,  1.5765, -0.4797],\n",
            "        [-1.6122,  1.6866, -0.3304],\n",
            "        [-1.5974,  1.7783, -0.2518]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4263,  1.3913, -0.1417],\n",
            "        [-0.7640,  0.0834,  0.0807],\n",
            "        [-1.6018,  1.7291, -0.4561],\n",
            "        [-1.5258,  1.8251, -0.3872],\n",
            "        [ 0.1680,  0.2522, -0.7748],\n",
            "        [-1.4780,  1.7410, -0.2770],\n",
            "        [-1.6416,  0.6936,  0.7465],\n",
            "        [-1.3851,  1.4639, -0.2896],\n",
            "        [-1.5832,  1.7730, -0.2794],\n",
            "        [-1.8677,  1.3803,  0.1536],\n",
            "        [-1.2487,  1.9524, -0.6876],\n",
            "        [-1.9615,  0.4573,  0.9468],\n",
            "        [-1.4492,  1.7715, -0.4111],\n",
            "        [-1.2733,  1.5765, -0.4797],\n",
            "        [-1.6122,  1.6866, -0.3304],\n",
            "        [-1.5974,  1.7783, -0.2518]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4133,  1.6596, -0.3949],\n",
            "        [-1.7839,  0.2629,  0.8893],\n",
            "        [-1.4300,  1.3274, -0.0810],\n",
            "        [-1.0885,  1.6198, -0.6863],\n",
            "        [-1.6900,  1.7356, -0.1722],\n",
            "        [-1.5387,  1.4476, -0.1241],\n",
            "        [-1.4387,  1.6813, -0.5690],\n",
            "        [-1.7160,  1.8273, -0.2933],\n",
            "        [-1.4425,  1.9205, -0.2908],\n",
            "        [-1.4021,  1.5670, -0.5284],\n",
            "        [-1.6343,  1.6712, -0.1905],\n",
            "        [-2.1158,  0.5497,  0.9505],\n",
            "        [-1.5938,  1.7321, -0.3354],\n",
            "        [-0.1845,  0.8865, -1.0623],\n",
            "        [-1.6176,  0.8472,  0.3905],\n",
            "        [-1.3583,  0.5092,  0.8023]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4133,  1.6596, -0.3949],\n",
            "        [-1.7839,  0.2629,  0.8893],\n",
            "        [-1.4300,  1.3274, -0.0810],\n",
            "        [-1.0885,  1.6198, -0.6863],\n",
            "        [-1.6900,  1.7356, -0.1722],\n",
            "        [-1.5387,  1.4476, -0.1241],\n",
            "        [-1.4387,  1.6813, -0.5690],\n",
            "        [-1.7160,  1.8273, -0.2933],\n",
            "        [-1.4425,  1.9205, -0.2908],\n",
            "        [-1.4021,  1.5670, -0.5284],\n",
            "        [-1.6343,  1.6712, -0.1905],\n",
            "        [-2.1158,  0.5497,  0.9505],\n",
            "        [-1.5938,  1.7321, -0.3354],\n",
            "        [-0.1845,  0.8865, -1.0623],\n",
            "        [-1.6176,  0.8472,  0.3905],\n",
            "        [-1.3583,  0.5092,  0.8023]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7749,  0.6178,  0.9603],\n",
            "        [-1.4125,  1.6145, -0.3236],\n",
            "        [-1.5919,  1.5500, -0.2596],\n",
            "        [-1.6676,  1.7913, -0.2402],\n",
            "        [-1.5689,  2.0776, -0.1194],\n",
            "        [-1.7089,  1.4854, -0.0551],\n",
            "        [ 0.1599,  0.1824, -1.0766],\n",
            "        [-1.6490,  1.6475, -0.2629],\n",
            "        [ 0.4608,  0.2168, -1.1088],\n",
            "        [-1.6369,  1.6123, -0.0284],\n",
            "        [-1.6368,  1.5819, -0.1612],\n",
            "        [-1.8217,  1.8684, -0.3520],\n",
            "        [-1.7617,  1.5577, -0.2171],\n",
            "        [ 0.2156,  0.4056, -0.7950],\n",
            "        [-2.0747,  0.6308,  0.9408],\n",
            "        [-1.4831,  1.5908, -0.1754]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7749,  0.6178,  0.9603],\n",
            "        [-1.4125,  1.6145, -0.3236],\n",
            "        [-1.5919,  1.5500, -0.2596],\n",
            "        [-1.6676,  1.7913, -0.2402],\n",
            "        [-1.5689,  2.0776, -0.1194],\n",
            "        [-1.7089,  1.4854, -0.0551],\n",
            "        [ 0.1599,  0.1824, -1.0766],\n",
            "        [-1.6490,  1.6475, -0.2629],\n",
            "        [ 0.4608,  0.2168, -1.1088],\n",
            "        [-1.6369,  1.6123, -0.0284],\n",
            "        [-1.6368,  1.5819, -0.1612],\n",
            "        [-1.8217,  1.8684, -0.3520],\n",
            "        [-1.7617,  1.5577, -0.2171],\n",
            "        [ 0.2156,  0.4056, -0.7950],\n",
            "        [-2.0747,  0.6308,  0.9408],\n",
            "        [-1.4831,  1.5908, -0.1754]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6584,  1.6088, -0.3080],\n",
            "        [-1.3297,  0.5092,  0.4804],\n",
            "        [-1.7826,  0.4541,  1.0320],\n",
            "        [-1.4458,  0.8597,  0.3731],\n",
            "        [-2.0616,  0.7937,  1.0061],\n",
            "        [-1.5363,  1.4422, -0.2716],\n",
            "        [ 0.1895,  0.2996, -0.9130],\n",
            "        [-1.6231,  1.6624, -0.1033],\n",
            "        [ 0.3128,  0.3744, -1.1827],\n",
            "        [-2.1233,  0.5639,  1.2083],\n",
            "        [-2.1755,  0.6941,  1.2578],\n",
            "        [-1.8867,  0.9439,  0.5380],\n",
            "        [-1.7193,  1.7154, -0.0065],\n",
            "        [-2.1761,  0.6584,  1.1071],\n",
            "        [-1.5858,  1.1711,  0.1404],\n",
            "        [ 0.3667,  0.3173, -1.0987]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6584,  1.6088, -0.3080],\n",
            "        [-1.3297,  0.5092,  0.4804],\n",
            "        [-1.7826,  0.4541,  1.0320],\n",
            "        [-1.4458,  0.8597,  0.3731],\n",
            "        [-2.0616,  0.7937,  1.0061],\n",
            "        [-1.5363,  1.4422, -0.2716],\n",
            "        [ 0.1895,  0.2996, -0.9130],\n",
            "        [-1.6231,  1.6624, -0.1033],\n",
            "        [ 0.3128,  0.3744, -1.1827],\n",
            "        [-2.1233,  0.5639,  1.2083],\n",
            "        [-2.1755,  0.6941,  1.2578],\n",
            "        [-1.8867,  0.9439,  0.5380],\n",
            "        [-1.7193,  1.7154, -0.0065],\n",
            "        [-2.1761,  0.6584,  1.1071],\n",
            "        [-1.5858,  1.1711,  0.1404],\n",
            "        [ 0.3667,  0.3173, -1.0987]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5226,  1.6990, -0.3131],\n",
            "        [-1.7737,  1.2594,  0.0294],\n",
            "        [-1.8912,  0.8030,  0.9040],\n",
            "        [-1.9960,  0.5979,  1.0523],\n",
            "        [-1.5328,  1.6819, -0.2168],\n",
            "        [-1.3318,  1.5911, -0.1872],\n",
            "        [ 0.5139,  0.1784, -1.0318],\n",
            "        [ 0.6523,  0.2571, -1.3126],\n",
            "        [-1.9336,  0.8134,  0.7839],\n",
            "        [-1.6781,  1.4387, -0.1081],\n",
            "        [-1.3243,  1.4392, -0.1401],\n",
            "        [ 0.3812,  0.3659, -1.0786],\n",
            "        [-1.8845,  1.3166,  0.3422],\n",
            "        [-1.8796,  1.7777, -0.0873],\n",
            "        [-0.8028,  0.6444, -0.0352],\n",
            "        [-0.7620,  1.0302, -0.4303]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5226,  1.6990, -0.3131],\n",
            "        [-1.7737,  1.2594,  0.0294],\n",
            "        [-1.8912,  0.8030,  0.9040],\n",
            "        [-1.9960,  0.5979,  1.0523],\n",
            "        [-1.5328,  1.6819, -0.2168],\n",
            "        [-1.3318,  1.5911, -0.1872],\n",
            "        [ 0.5139,  0.1784, -1.0318],\n",
            "        [ 0.6523,  0.2571, -1.3126],\n",
            "        [-1.9336,  0.8134,  0.7839],\n",
            "        [-1.6781,  1.4387, -0.1081],\n",
            "        [-1.3243,  1.4392, -0.1401],\n",
            "        [ 0.3812,  0.3659, -1.0786],\n",
            "        [-1.8845,  1.3166,  0.3422],\n",
            "        [-1.8796,  1.7777, -0.0873],\n",
            "        [-0.8028,  0.6444, -0.0352],\n",
            "        [-0.7620,  1.0302, -0.4303]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6409,  1.0932,  0.2554],\n",
            "        [-2.0153,  1.1669,  0.3659],\n",
            "        [-1.6440,  1.3127,  0.2534],\n",
            "        [-1.4243,  1.5782, -0.2296],\n",
            "        [-1.8886,  1.0381,  0.4651],\n",
            "        [-1.1674,  1.3933, -0.3435],\n",
            "        [-0.9817,  1.2305, -0.3496],\n",
            "        [-2.1864,  1.0754,  0.8946],\n",
            "        [ 0.4759,  0.1817, -1.1806],\n",
            "        [-1.4702,  1.3763, -0.2450],\n",
            "        [-0.5322,  0.7050, -0.3702],\n",
            "        [-1.5595,  1.0329,  0.2866],\n",
            "        [-1.8563,  0.7529,  0.8484],\n",
            "        [-1.3768,  1.4191, -0.1556],\n",
            "        [-1.4915,  1.5852, -0.3943],\n",
            "        [-1.7741,  0.5573,  0.9495]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6409,  1.0932,  0.2554],\n",
            "        [-2.0153,  1.1669,  0.3659],\n",
            "        [-1.6440,  1.3127,  0.2534],\n",
            "        [-1.4243,  1.5782, -0.2296],\n",
            "        [-1.8886,  1.0381,  0.4651],\n",
            "        [-1.1674,  1.3933, -0.3435],\n",
            "        [-0.9817,  1.2305, -0.3496],\n",
            "        [-2.1864,  1.0754,  0.8946],\n",
            "        [ 0.4759,  0.1817, -1.1806],\n",
            "        [-1.4702,  1.3763, -0.2450],\n",
            "        [-0.5322,  0.7050, -0.3702],\n",
            "        [-1.5595,  1.0329,  0.2866],\n",
            "        [-1.8563,  0.7529,  0.8484],\n",
            "        [-1.3768,  1.4191, -0.1556],\n",
            "        [-1.4915,  1.5852, -0.3943],\n",
            "        [-1.7741,  0.5573,  0.9495]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5057,  1.6222, -0.1549],\n",
            "        [-1.5962,  1.6810, -0.2519],\n",
            "        [-1.5641,  1.7952, -0.1669],\n",
            "        [-1.4897,  1.3846, -0.3204],\n",
            "        [-1.9342,  0.5346,  0.9028],\n",
            "        [-1.4156,  1.6692, -0.3037],\n",
            "        [-1.2680,  1.2407, -0.0906],\n",
            "        [-0.3201,  0.8583, -0.8263],\n",
            "        [-1.4351,  1.4439, -0.1499],\n",
            "        [-1.7572,  1.5817, -0.0120],\n",
            "        [-1.9156,  1.5157,  0.2482],\n",
            "        [-1.4668,  1.5758, -0.1564],\n",
            "        [-1.3528,  0.2445,  0.7474],\n",
            "        [-1.6977,  0.3648,  0.8458],\n",
            "        [-1.7918,  0.6333,  0.8127],\n",
            "        [-1.4010,  1.6408, -0.0925]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5057,  1.6222, -0.1549],\n",
            "        [-1.5962,  1.6810, -0.2519],\n",
            "        [-1.5641,  1.7952, -0.1669],\n",
            "        [-1.4897,  1.3846, -0.3204],\n",
            "        [-1.9342,  0.5346,  0.9028],\n",
            "        [-1.4156,  1.6692, -0.3037],\n",
            "        [-1.2680,  1.2407, -0.0906],\n",
            "        [-0.3201,  0.8583, -0.8263],\n",
            "        [-1.4351,  1.4439, -0.1499],\n",
            "        [-1.7572,  1.5817, -0.0120],\n",
            "        [-1.9156,  1.5157,  0.2482],\n",
            "        [-1.4668,  1.5758, -0.1564],\n",
            "        [-1.3528,  0.2445,  0.7474],\n",
            "        [-1.6977,  0.3648,  0.8458],\n",
            "        [-1.7918,  0.6333,  0.8127],\n",
            "        [-1.4010,  1.6408, -0.0925]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6392,  0.4923,  0.6883],\n",
            "        [-1.2847,  1.3454, -0.3098],\n",
            "        [-1.3093,  1.7064, -0.1973],\n",
            "        [-1.6462,  1.2605, -0.3020],\n",
            "        [-1.4103,  1.3081, -0.2198],\n",
            "        [ 0.5344,  0.0832, -1.2216],\n",
            "        [-1.9061,  0.6107,  1.0281],\n",
            "        [-1.3160,  1.4229, -0.2406],\n",
            "        [-1.1587,  1.1506, -0.2376],\n",
            "        [-1.7846,  1.8712, -0.0434],\n",
            "        [-1.9332,  0.4153,  0.8904],\n",
            "        [-1.8246,  1.1633,  0.5156],\n",
            "        [-1.2716,  1.2253, -0.1367],\n",
            "        [-1.5934,  1.1279,  0.3845],\n",
            "        [-1.7594,  0.7434,  0.8337],\n",
            "        [-0.5274,  0.1708, -0.0901]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6392,  0.4923,  0.6883],\n",
            "        [-1.2847,  1.3454, -0.3098],\n",
            "        [-1.3093,  1.7064, -0.1973],\n",
            "        [-1.6462,  1.2605, -0.3020],\n",
            "        [-1.4103,  1.3081, -0.2198],\n",
            "        [ 0.5344,  0.0832, -1.2216],\n",
            "        [-1.9061,  0.6107,  1.0281],\n",
            "        [-1.3160,  1.4229, -0.2406],\n",
            "        [-1.1587,  1.1506, -0.2376],\n",
            "        [-1.7846,  1.8712, -0.0434],\n",
            "        [-1.9332,  0.4153,  0.8904],\n",
            "        [-1.8246,  1.1633,  0.5156],\n",
            "        [-1.2716,  1.2253, -0.1367],\n",
            "        [-1.5934,  1.1279,  0.3845],\n",
            "        [-1.7594,  0.7434,  0.8337],\n",
            "        [-0.5274,  0.1708, -0.0901]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4437,  1.3560, -0.2489],\n",
            "        [-1.8065,  0.6198,  0.5733],\n",
            "        [-1.5098,  1.3405, -0.0547],\n",
            "        [-0.2800,  0.1237, -0.2569],\n",
            "        [-1.8633,  0.5239,  0.8925],\n",
            "        [-1.4925,  1.5025, -0.2089],\n",
            "        [-1.0478,  1.3333, -0.2023],\n",
            "        [-1.8968,  0.5139,  0.8684],\n",
            "        [-1.8727,  0.5127,  0.7088],\n",
            "        [-1.2139,  1.3372, -0.1683],\n",
            "        [-1.8029,  0.8054,  0.7557],\n",
            "        [-1.5923,  1.6061, -0.2191],\n",
            "        [-1.3063,  1.6559, -0.3063],\n",
            "        [-1.1835,  1.4440, -0.4024],\n",
            "        [-1.7999,  0.5407,  0.9703],\n",
            "        [-1.3522,  1.0807, -0.0294]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4437,  1.3560, -0.2489],\n",
            "        [-1.8065,  0.6198,  0.5733],\n",
            "        [-1.5098,  1.3405, -0.0547],\n",
            "        [-0.2800,  0.1237, -0.2569],\n",
            "        [-1.8633,  0.5239,  0.8925],\n",
            "        [-1.4925,  1.5025, -0.2089],\n",
            "        [-1.0478,  1.3333, -0.2023],\n",
            "        [-1.8968,  0.5139,  0.8684],\n",
            "        [-1.8727,  0.5127,  0.7088],\n",
            "        [-1.2139,  1.3372, -0.1683],\n",
            "        [-1.8029,  0.8054,  0.7557],\n",
            "        [-1.5923,  1.6061, -0.2191],\n",
            "        [-1.3063,  1.6559, -0.3063],\n",
            "        [-1.1835,  1.4440, -0.4024],\n",
            "        [-1.7999,  0.5407,  0.9703],\n",
            "        [-1.3522,  1.0807, -0.0294]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3384,  1.4453, -0.2525],\n",
            "        [-1.3669,  1.5851, -0.2582],\n",
            "        [-1.7421,  0.8264,  0.6126],\n",
            "        [-1.0954,  1.4725, -0.5560],\n",
            "        [-1.5078,  1.5734, -0.2983],\n",
            "        [ 0.3398,  0.3861, -1.0986],\n",
            "        [-0.8062,  0.8740, -0.4773],\n",
            "        [-1.2971,  1.4899, -0.2609],\n",
            "        [-1.8674,  0.8729,  0.8869],\n",
            "        [-1.2240,  1.3726, -0.2147],\n",
            "        [-1.7369,  0.4644,  0.7078],\n",
            "        [-1.9703,  0.6510,  0.9024],\n",
            "        [-1.7371,  0.6390,  0.7418],\n",
            "        [-1.2622,  1.4670, -0.2209],\n",
            "        [-0.8750,  1.2593, -0.3883],\n",
            "        [-1.6387,  0.6264,  0.6031]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3384,  1.4453, -0.2525],\n",
            "        [-1.3669,  1.5851, -0.2582],\n",
            "        [-1.7421,  0.8264,  0.6126],\n",
            "        [-1.0954,  1.4725, -0.5560],\n",
            "        [-1.5078,  1.5734, -0.2983],\n",
            "        [ 0.3398,  0.3861, -1.0986],\n",
            "        [-0.8062,  0.8740, -0.4773],\n",
            "        [-1.2971,  1.4899, -0.2609],\n",
            "        [-1.8674,  0.8729,  0.8869],\n",
            "        [-1.2240,  1.3726, -0.2147],\n",
            "        [-1.7369,  0.4644,  0.7078],\n",
            "        [-1.9703,  0.6510,  0.9024],\n",
            "        [-1.7371,  0.6390,  0.7418],\n",
            "        [-1.2622,  1.4670, -0.2209],\n",
            "        [-0.8750,  1.2593, -0.3883],\n",
            "        [-1.6387,  0.6264,  0.6031]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7165,  0.4669,  0.8685],\n",
            "        [-1.2870,  1.5353, -0.3801],\n",
            "        [-1.2202,  1.5077, -0.2578],\n",
            "        [-0.7676,  1.3726, -0.4437],\n",
            "        [-1.4582,  0.3875,  0.7671],\n",
            "        [ 0.5775,  0.1207, -1.0362],\n",
            "        [-1.3550,  1.3933, -0.4495],\n",
            "        [-1.7378,  0.6090,  0.9236],\n",
            "        [-1.6153,  1.6303, -0.1672],\n",
            "        [-2.0641,  0.6592,  0.9689],\n",
            "        [-1.3117,  1.4334, -0.0810],\n",
            "        [-1.7375,  0.6079,  0.7219],\n",
            "        [-1.5524,  1.5711, -0.1761],\n",
            "        [-1.9808,  0.6645,  0.8695],\n",
            "        [-1.6618,  1.1715,  0.1338],\n",
            "        [-1.2592,  1.3824, -0.0662]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7165,  0.4669,  0.8685],\n",
            "        [-1.2870,  1.5353, -0.3801],\n",
            "        [-1.2202,  1.5077, -0.2578],\n",
            "        [-0.7676,  1.3726, -0.4437],\n",
            "        [-1.4582,  0.3875,  0.7671],\n",
            "        [ 0.5775,  0.1207, -1.0362],\n",
            "        [-1.3550,  1.3933, -0.4495],\n",
            "        [-1.7378,  0.6090,  0.9236],\n",
            "        [-1.6153,  1.6303, -0.1672],\n",
            "        [-2.0641,  0.6592,  0.9689],\n",
            "        [-1.3117,  1.4334, -0.0810],\n",
            "        [-1.7375,  0.6079,  0.7219],\n",
            "        [-1.5524,  1.5711, -0.1761],\n",
            "        [-1.9808,  0.6645,  0.8695],\n",
            "        [-1.6618,  1.1715,  0.1338],\n",
            "        [-1.2592,  1.3824, -0.0662]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3252,  1.1344,  0.1296],\n",
            "        [-1.0690,  1.4454, -0.3808],\n",
            "        [-1.2709,  1.4083, -0.3625],\n",
            "        [-1.4194,  1.4355, -0.0227],\n",
            "        [-1.1385,  0.2402,  0.5316],\n",
            "        [-1.3813,  1.6067, -0.2593],\n",
            "        [-1.4763,  1.3743, -0.0709],\n",
            "        [-1.8086,  0.5308,  0.8966],\n",
            "        [-1.3914,  1.3302, -0.0464],\n",
            "        [-1.3756,  0.5768,  0.6808],\n",
            "        [-1.8366,  0.6705,  0.9570],\n",
            "        [ 0.3381,  0.0789, -0.8669],\n",
            "        [-1.6833,  0.9733,  0.4992],\n",
            "        [-1.2784,  1.4184, -0.4255],\n",
            "        [-1.2867,  1.4889, -0.3008],\n",
            "        [-1.2164,  1.1570, -0.2877]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3252,  1.1344,  0.1296],\n",
            "        [-1.0690,  1.4454, -0.3808],\n",
            "        [-1.2709,  1.4083, -0.3625],\n",
            "        [-1.4194,  1.4355, -0.0227],\n",
            "        [-1.1385,  0.2402,  0.5316],\n",
            "        [-1.3813,  1.6067, -0.2593],\n",
            "        [-1.4763,  1.3743, -0.0709],\n",
            "        [-1.8086,  0.5308,  0.8966],\n",
            "        [-1.3914,  1.3302, -0.0464],\n",
            "        [-1.3756,  0.5768,  0.6808],\n",
            "        [-1.8366,  0.6705,  0.9570],\n",
            "        [ 0.3381,  0.0789, -0.8669],\n",
            "        [-1.6833,  0.9733,  0.4992],\n",
            "        [-1.2784,  1.4184, -0.4255],\n",
            "        [-1.2867,  1.4889, -0.3008],\n",
            "        [-1.2164,  1.1570, -0.2877]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6553,  0.5600,  0.9343],\n",
            "        [-1.2129,  1.3475, -0.3237],\n",
            "        [-1.2666,  1.4012, -0.2809],\n",
            "        [-1.6561,  0.4751,  0.8970],\n",
            "        [-1.6707,  0.6403,  0.6158],\n",
            "        [-1.2045,  1.3794,  0.0498],\n",
            "        [ 0.2163,  0.2187, -0.8174],\n",
            "        [-1.6787,  0.4643,  0.9444],\n",
            "        [ 0.3211,  0.1292, -0.7211],\n",
            "        [-1.1591,  1.2641, -0.3136],\n",
            "        [ 0.1868,  0.4068, -0.8974],\n",
            "        [-1.5392,  1.3336, -0.1661],\n",
            "        [-1.6522,  0.3747,  0.8333],\n",
            "        [-1.0099,  1.1073, -0.3873],\n",
            "        [-1.2987,  1.4057, -0.2878],\n",
            "        [-1.5299,  1.0563,  0.0686]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6553,  0.5600,  0.9343],\n",
            "        [-1.2129,  1.3475, -0.3237],\n",
            "        [-1.2666,  1.4012, -0.2809],\n",
            "        [-1.6561,  0.4751,  0.8970],\n",
            "        [-1.6707,  0.6403,  0.6158],\n",
            "        [-1.2045,  1.3794,  0.0498],\n",
            "        [ 0.2163,  0.2187, -0.8174],\n",
            "        [-1.6787,  0.4643,  0.9444],\n",
            "        [ 0.3211,  0.1292, -0.7211],\n",
            "        [-1.1591,  1.2641, -0.3136],\n",
            "        [ 0.1868,  0.4068, -0.8974],\n",
            "        [-1.5392,  1.3336, -0.1661],\n",
            "        [-1.6522,  0.3747,  0.8333],\n",
            "        [-1.0099,  1.1073, -0.3873],\n",
            "        [-1.2987,  1.4057, -0.2878],\n",
            "        [-1.5299,  1.0563,  0.0686]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4162,  0.8245,  0.3071],\n",
            "        [-1.4522,  1.4889, -0.3801],\n",
            "        [-1.2054,  1.1950, -0.2006],\n",
            "        [-1.4070,  1.3100, -0.3265],\n",
            "        [-1.3087,  1.5889, -0.6150],\n",
            "        [-1.6639,  0.4200,  0.8646],\n",
            "        [-1.1911,  1.5679, -0.4181],\n",
            "        [-1.5966,  0.5384,  0.6229],\n",
            "        [-1.2914,  1.3960, -0.2165],\n",
            "        [-1.6777,  1.5752,  0.0263],\n",
            "        [-1.0578,  1.1712, -0.4673],\n",
            "        [-1.0145,  1.4913, -0.4457],\n",
            "        [-1.6682,  0.3592,  0.9296],\n",
            "        [-1.7549,  0.5469,  0.6255],\n",
            "        [-0.6349,  0.9815, -0.6660],\n",
            "        [-1.1604,  1.3152, -0.3413]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4162,  0.8245,  0.3071],\n",
            "        [-1.4522,  1.4889, -0.3801],\n",
            "        [-1.2054,  1.1950, -0.2006],\n",
            "        [-1.4070,  1.3100, -0.3265],\n",
            "        [-1.3087,  1.5889, -0.6150],\n",
            "        [-1.6639,  0.4200,  0.8646],\n",
            "        [-1.1911,  1.5679, -0.4181],\n",
            "        [-1.5966,  0.5384,  0.6229],\n",
            "        [-1.2914,  1.3960, -0.2165],\n",
            "        [-1.6777,  1.5752,  0.0263],\n",
            "        [-1.0578,  1.1712, -0.4673],\n",
            "        [-1.0145,  1.4913, -0.4457],\n",
            "        [-1.6682,  0.3592,  0.9296],\n",
            "        [-1.7549,  0.5469,  0.6255],\n",
            "        [-0.6349,  0.9815, -0.6660],\n",
            "        [-1.1604,  1.3152, -0.3413]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7338,  1.0017,  0.2777],\n",
            "        [-1.2687,  1.4505, -0.3509],\n",
            "        [-1.2222,  1.3598, -0.1214],\n",
            "        [-1.9011,  0.7310,  0.8012],\n",
            "        [-1.9262,  0.4412,  1.0473],\n",
            "        [-1.1267,  1.3283, -0.3704],\n",
            "        [-1.5651,  0.3690,  0.8685],\n",
            "        [-1.4412,  0.9942,  0.3080],\n",
            "        [-1.7684,  1.1913,  0.4152],\n",
            "        [-1.3384,  1.5863, -0.4633],\n",
            "        [-1.2022,  1.5680, -0.4444],\n",
            "        [-1.1150,  1.6209, -0.3880],\n",
            "        [-1.4438,  1.5482, -0.3233],\n",
            "        [-0.9089,  0.4422,  0.2168],\n",
            "        [-1.1470,  1.6085, -0.4459],\n",
            "        [-0.7288,  0.3214, -0.0047]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7338,  1.0017,  0.2777],\n",
            "        [-1.2687,  1.4505, -0.3509],\n",
            "        [-1.2222,  1.3598, -0.1214],\n",
            "        [-1.9011,  0.7310,  0.8012],\n",
            "        [-1.9262,  0.4412,  1.0473],\n",
            "        [-1.1267,  1.3283, -0.3704],\n",
            "        [-1.5651,  0.3690,  0.8685],\n",
            "        [-1.4412,  0.9942,  0.3080],\n",
            "        [-1.7684,  1.1913,  0.4152],\n",
            "        [-1.3384,  1.5863, -0.4633],\n",
            "        [-1.2022,  1.5680, -0.4444],\n",
            "        [-1.1150,  1.6209, -0.3880],\n",
            "        [-1.4438,  1.5482, -0.3233],\n",
            "        [-0.9089,  0.4422,  0.2168],\n",
            "        [-1.1470,  1.6085, -0.4459],\n",
            "        [-0.7288,  0.3214, -0.0047]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2777,  1.5666, -0.5149],\n",
            "        [-1.6756,  0.4372,  0.8902],\n",
            "        [-0.1354,  0.0816, -0.1787],\n",
            "        [-2.0697,  0.8405,  0.9237],\n",
            "        [-1.3809,  1.7105, -0.5614],\n",
            "        [-1.3589,  1.6115, -0.2560],\n",
            "        [ 0.6774,  0.1162, -1.0700],\n",
            "        [-1.6213,  0.5704,  0.8143],\n",
            "        [-1.5441,  1.5724, -0.2635],\n",
            "        [-1.4391,  1.3884, -0.2778],\n",
            "        [-0.9926,  1.3918, -0.4085],\n",
            "        [-0.5224,  0.1735,  0.1598],\n",
            "        [-1.7275,  0.7343,  0.8724],\n",
            "        [-1.2689,  1.2698, -0.5527],\n",
            "        [-1.4468,  0.8530,  0.3440],\n",
            "        [-1.2855,  1.6418, -0.4661]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2777,  1.5666, -0.5149],\n",
            "        [-1.6756,  0.4372,  0.8902],\n",
            "        [-0.1354,  0.0816, -0.1787],\n",
            "        [-2.0697,  0.8405,  0.9237],\n",
            "        [-1.3809,  1.7105, -0.5614],\n",
            "        [-1.3589,  1.6115, -0.2560],\n",
            "        [ 0.6774,  0.1162, -1.0700],\n",
            "        [-1.6213,  0.5704,  0.8143],\n",
            "        [-1.5441,  1.5724, -0.2635],\n",
            "        [-1.4391,  1.3884, -0.2778],\n",
            "        [-0.9926,  1.3918, -0.4085],\n",
            "        [-0.5224,  0.1735,  0.1598],\n",
            "        [-1.7275,  0.7343,  0.8724],\n",
            "        [-1.2689,  1.2698, -0.5527],\n",
            "        [-1.4468,  0.8530,  0.3440],\n",
            "        [-1.2855,  1.6418, -0.4661]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3010,  0.9237,  0.1583],\n",
            "        [-1.6058,  0.4519,  0.9583],\n",
            "        [-1.4956,  1.3421,  0.0587],\n",
            "        [ 0.5144,  0.1394, -1.1256],\n",
            "        [-1.6494,  0.4116,  1.0284],\n",
            "        [ 0.2656,  0.0427, -0.7772],\n",
            "        [ 0.5810,  0.1777, -1.0311],\n",
            "        [-0.6948,  1.5690, -0.5836],\n",
            "        [-1.3742,  1.1404, -0.2193],\n",
            "        [-1.4609,  1.6326, -0.3043],\n",
            "        [-1.5178,  1.8934, -0.2118],\n",
            "        [-1.1849,  1.5467, -0.5277],\n",
            "        [-1.1470,  1.5686, -0.3780],\n",
            "        [-1.8153,  0.5976,  0.8733],\n",
            "        [-1.0243,  0.1612,  0.5777],\n",
            "        [-1.7996,  0.4581,  1.0171]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3010,  0.9237,  0.1583],\n",
            "        [-1.6058,  0.4519,  0.9583],\n",
            "        [-1.4956,  1.3421,  0.0587],\n",
            "        [ 0.5144,  0.1394, -1.1256],\n",
            "        [-1.6494,  0.4116,  1.0284],\n",
            "        [ 0.2656,  0.0427, -0.7772],\n",
            "        [ 0.5810,  0.1777, -1.0311],\n",
            "        [-0.6948,  1.5690, -0.5836],\n",
            "        [-1.3742,  1.1404, -0.2193],\n",
            "        [-1.4609,  1.6326, -0.3043],\n",
            "        [-1.5178,  1.8934, -0.2118],\n",
            "        [-1.1849,  1.5467, -0.5277],\n",
            "        [-1.1470,  1.5686, -0.3780],\n",
            "        [-1.8153,  0.5976,  0.8733],\n",
            "        [-1.0243,  0.1612,  0.5777],\n",
            "        [-1.7996,  0.4581,  1.0171]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5865,  0.0173, -0.9571],\n",
            "        [-1.6557,  0.9550,  0.4989],\n",
            "        [-1.3769,  1.6764, -0.5493],\n",
            "        [-1.4437,  0.1680,  0.7862],\n",
            "        [-0.9985,  1.5833, -0.5735],\n",
            "        [-1.2326,  1.6610, -0.6965],\n",
            "        [-1.6006,  0.3991,  0.8745],\n",
            "        [-1.3611,  1.3848, -0.0407],\n",
            "        [-1.4884,  1.4120, -0.4105],\n",
            "        [ 0.6514,  0.0659, -1.0071],\n",
            "        [-1.7688,  0.4451,  0.8208],\n",
            "        [-0.5247,  0.2670, -0.0879],\n",
            "        [-0.0573,  0.2299, -0.5329],\n",
            "        [-1.2356,  1.5928, -0.4616],\n",
            "        [ 0.4621, -0.0424, -1.0814],\n",
            "        [-1.2508,  1.6145, -0.4643]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.5865,  0.0173, -0.9571],\n",
            "        [-1.6557,  0.9550,  0.4989],\n",
            "        [-1.3769,  1.6764, -0.5493],\n",
            "        [-1.4437,  0.1680,  0.7862],\n",
            "        [-0.9985,  1.5833, -0.5735],\n",
            "        [-1.2326,  1.6610, -0.6965],\n",
            "        [-1.6006,  0.3991,  0.8745],\n",
            "        [-1.3611,  1.3848, -0.0407],\n",
            "        [-1.4884,  1.4120, -0.4105],\n",
            "        [ 0.6514,  0.0659, -1.0071],\n",
            "        [-1.7688,  0.4451,  0.8208],\n",
            "        [-0.5247,  0.2670, -0.0879],\n",
            "        [-0.0573,  0.2299, -0.5329],\n",
            "        [-1.2356,  1.5928, -0.4616],\n",
            "        [ 0.4621, -0.0424, -1.0814],\n",
            "        [-1.2508,  1.6145, -0.4643]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2063,  1.5420, -0.5989],\n",
            "        [ 0.2043,  0.3591, -1.0806],\n",
            "        [-1.1856,  1.5653, -0.4957],\n",
            "        [-1.2126,  1.5946, -0.3564],\n",
            "        [-1.5954,  0.5039,  0.8925],\n",
            "        [-1.3961,  1.5694, -0.5244],\n",
            "        [ 0.4304,  0.3210, -0.9666],\n",
            "        [-1.2945,  1.4977, -0.5712],\n",
            "        [-1.9245,  0.7195,  0.9623],\n",
            "        [-1.2788,  1.6565, -0.6031],\n",
            "        [ 0.6287,  0.1748, -0.9595],\n",
            "        [-1.1988,  1.7105, -0.5364],\n",
            "        [-1.2543,  1.7071, -0.3481],\n",
            "        [-1.2150,  1.6379, -0.3651],\n",
            "        [-1.7811,  0.5559,  0.8047],\n",
            "        [ 0.5585,  0.1636, -1.0655]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2063,  1.5420, -0.5989],\n",
            "        [ 0.2043,  0.3591, -1.0806],\n",
            "        [-1.1856,  1.5653, -0.4957],\n",
            "        [-1.2126,  1.5946, -0.3564],\n",
            "        [-1.5954,  0.5039,  0.8925],\n",
            "        [-1.3961,  1.5694, -0.5244],\n",
            "        [ 0.4304,  0.3210, -0.9666],\n",
            "        [-1.2945,  1.4977, -0.5712],\n",
            "        [-1.9245,  0.7195,  0.9623],\n",
            "        [-1.2788,  1.6565, -0.6031],\n",
            "        [ 0.6287,  0.1748, -0.9595],\n",
            "        [-1.1988,  1.7105, -0.5364],\n",
            "        [-1.2543,  1.7071, -0.3481],\n",
            "        [-1.2150,  1.6379, -0.3651],\n",
            "        [-1.7811,  0.5559,  0.8047],\n",
            "        [ 0.5585,  0.1636, -1.0655]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6682,  0.7060,  0.7074],\n",
            "        [-1.6583,  0.4277,  0.8658],\n",
            "        [-1.2912,  1.9062, -0.6273],\n",
            "        [ 0.1211, -0.0057, -0.5869],\n",
            "        [-1.2931,  1.6365, -0.6784],\n",
            "        [ 0.3018,  0.5056, -1.0874],\n",
            "        [-1.0451,  1.4526, -0.5594],\n",
            "        [-1.1258,  1.6976, -0.6921],\n",
            "        [-1.3876,  0.3697,  0.8752],\n",
            "        [-0.6324,  1.2599, -0.9372],\n",
            "        [-0.6289,  1.2685, -0.9734],\n",
            "        [-1.2832,  1.6339, -0.3284],\n",
            "        [-1.4236,  1.9067, -0.4098],\n",
            "        [-1.5055,  0.4412,  0.9168],\n",
            "        [-1.0687,  1.7557, -0.7018],\n",
            "        [-1.4991,  1.1816, -0.1834]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6682,  0.7060,  0.7074],\n",
            "        [-1.6583,  0.4277,  0.8658],\n",
            "        [-1.2912,  1.9062, -0.6273],\n",
            "        [ 0.1211, -0.0057, -0.5869],\n",
            "        [-1.2931,  1.6365, -0.6784],\n",
            "        [ 0.3018,  0.5056, -1.0874],\n",
            "        [-1.0451,  1.4526, -0.5594],\n",
            "        [-1.1258,  1.6976, -0.6921],\n",
            "        [-1.3876,  0.3697,  0.8752],\n",
            "        [-0.6324,  1.2599, -0.9372],\n",
            "        [-0.6289,  1.2685, -0.9734],\n",
            "        [-1.2832,  1.6339, -0.3284],\n",
            "        [-1.4236,  1.9067, -0.4098],\n",
            "        [-1.5055,  0.4412,  0.9168],\n",
            "        [-1.0687,  1.7557, -0.7018],\n",
            "        [-1.4991,  1.1816, -0.1834]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.1184,  1.4366, -0.5725],\n",
            "        [-1.6252,  0.8228,  0.4149],\n",
            "        [-0.9605,  1.3866, -0.8052],\n",
            "        [-1.0323,  1.5955, -0.7175],\n",
            "        [-1.3169,  1.7162, -0.6618],\n",
            "        [-1.3698,  1.5812, -0.5145],\n",
            "        [-1.0911,  1.6999, -0.6087],\n",
            "        [-1.6903,  1.0873,  0.2165],\n",
            "        [ 0.6557,  0.0639, -1.2224],\n",
            "        [-1.8630,  0.8018,  0.6773],\n",
            "        [-1.1502,  1.6838, -0.4790],\n",
            "        [-1.8053,  1.9412, -0.1781],\n",
            "        [ 0.6628, -0.0054, -1.0280],\n",
            "        [-1.2142,  1.7892, -0.5477],\n",
            "        [-1.2567,  1.8931, -0.7826],\n",
            "        [-1.4032,  0.4738,  0.5284]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.1184,  1.4366, -0.5725],\n",
            "        [-1.6252,  0.8228,  0.4149],\n",
            "        [-0.9605,  1.3866, -0.8052],\n",
            "        [-1.0323,  1.5955, -0.7175],\n",
            "        [-1.3169,  1.7162, -0.6618],\n",
            "        [-1.3698,  1.5812, -0.5145],\n",
            "        [-1.0911,  1.6999, -0.6087],\n",
            "        [-1.6903,  1.0873,  0.2165],\n",
            "        [ 0.6557,  0.0639, -1.2224],\n",
            "        [-1.8630,  0.8018,  0.6773],\n",
            "        [-1.1502,  1.6838, -0.4790],\n",
            "        [-1.8053,  1.9412, -0.1781],\n",
            "        [ 0.6628, -0.0054, -1.0280],\n",
            "        [-1.2142,  1.7892, -0.5477],\n",
            "        [-1.2567,  1.8931, -0.7826],\n",
            "        [-1.4032,  0.4738,  0.5284]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4829e+00,  1.3837e+00,  9.2623e-02],\n",
            "        [-1.1813e+00,  1.7342e+00, -3.6067e-01],\n",
            "        [-1.1541e+00,  1.7156e+00, -6.1222e-01],\n",
            "        [-5.5024e-05,  7.0478e-02, -3.4514e-01],\n",
            "        [-1.4998e+00,  5.3871e-01,  6.9909e-01],\n",
            "        [-1.1841e+00,  1.6214e+00, -7.3670e-01],\n",
            "        [-9.7702e-01,  1.5412e+00, -6.5792e-01],\n",
            "        [-1.8170e+00,  6.7715e-01,  6.6417e-01],\n",
            "        [-1.8467e+00,  9.0383e-01,  3.5099e-01],\n",
            "        [-1.1838e+00,  1.4736e+00, -4.5544e-01],\n",
            "        [-1.4058e+00,  1.7171e+00, -5.0132e-01],\n",
            "        [ 5.8421e-01,  5.8477e-02, -1.1578e+00],\n",
            "        [-1.2953e+00,  1.7878e+00, -6.7615e-01],\n",
            "        [-1.4467e+00,  3.7961e-01,  7.7286e-01],\n",
            "        [-1.1181e+00,  1.5535e+00, -6.7502e-01],\n",
            "        [-1.5508e+00,  2.6167e-01,  9.3949e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4829e+00,  1.3837e+00,  9.2623e-02],\n",
            "        [-1.1813e+00,  1.7342e+00, -3.6067e-01],\n",
            "        [-1.1541e+00,  1.7156e+00, -6.1222e-01],\n",
            "        [-5.5024e-05,  7.0478e-02, -3.4514e-01],\n",
            "        [-1.4998e+00,  5.3871e-01,  6.9909e-01],\n",
            "        [-1.1841e+00,  1.6214e+00, -7.3670e-01],\n",
            "        [-9.7702e-01,  1.5412e+00, -6.5792e-01],\n",
            "        [-1.8170e+00,  6.7715e-01,  6.6417e-01],\n",
            "        [-1.8467e+00,  9.0383e-01,  3.5099e-01],\n",
            "        [-1.1838e+00,  1.4736e+00, -4.5544e-01],\n",
            "        [-1.4058e+00,  1.7171e+00, -5.0132e-01],\n",
            "        [ 5.8421e-01,  5.8477e-02, -1.1578e+00],\n",
            "        [-1.2953e+00,  1.7878e+00, -6.7615e-01],\n",
            "        [-1.4467e+00,  3.7961e-01,  7.7286e-01],\n",
            "        [-1.1181e+00,  1.5535e+00, -6.7502e-01],\n",
            "        [-1.5508e+00,  2.6167e-01,  9.3949e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.1829,  2.0652, -0.7652],\n",
            "        [-1.7004,  0.7567,  0.5977],\n",
            "        [-1.2492,  1.7770, -0.5560],\n",
            "        [-1.0210,  1.6470, -0.7751],\n",
            "        [-0.4064,  0.1964,  0.0066],\n",
            "        [-1.0398,  1.2992, -0.7337],\n",
            "        [ 0.5706,  0.2618, -1.0155],\n",
            "        [-1.1878,  1.6657, -0.5378],\n",
            "        [ 0.4243,  0.2689, -0.9712],\n",
            "        [-1.4050,  0.3534,  0.9169],\n",
            "        [-0.5823,  0.1251,  0.0118],\n",
            "        [-1.1862,  1.8853, -0.8158],\n",
            "        [-1.7349,  0.3718,  0.8943],\n",
            "        [-1.3791,  1.7757, -0.6337],\n",
            "        [-1.2653,  1.7221, -0.6424],\n",
            "        [-1.0777,  1.6373, -0.8314]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.1829,  2.0652, -0.7652],\n",
            "        [-1.7004,  0.7567,  0.5977],\n",
            "        [-1.2492,  1.7770, -0.5560],\n",
            "        [-1.0210,  1.6470, -0.7751],\n",
            "        [-0.4064,  0.1964,  0.0066],\n",
            "        [-1.0398,  1.2992, -0.7337],\n",
            "        [ 0.5706,  0.2618, -1.0155],\n",
            "        [-1.1878,  1.6657, -0.5378],\n",
            "        [ 0.4243,  0.2689, -0.9712],\n",
            "        [-1.4050,  0.3534,  0.9169],\n",
            "        [-0.5823,  0.1251,  0.0118],\n",
            "        [-1.1862,  1.8853, -0.8158],\n",
            "        [-1.7349,  0.3718,  0.8943],\n",
            "        [-1.3791,  1.7757, -0.6337],\n",
            "        [-1.2653,  1.7221, -0.6424],\n",
            "        [-1.0777,  1.6373, -0.8314]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3963,  1.6937, -0.4786],\n",
            "        [-1.2720,  1.6972, -0.8072],\n",
            "        [ 0.5889,  0.1620, -1.1160],\n",
            "        [ 0.7003,  0.0531, -1.0811],\n",
            "        [-1.3386,  1.9066, -0.4617],\n",
            "        [-0.7710,  1.3426, -0.7534],\n",
            "        [-0.9155,  0.1608,  0.6358],\n",
            "        [-1.0939,  1.4675, -0.4261],\n",
            "        [-1.5049,  1.8916, -0.7414],\n",
            "        [-0.1352,  0.6390, -0.8277],\n",
            "        [-1.0792,  1.5769, -0.6328],\n",
            "        [-0.9432,  1.7735, -0.8190],\n",
            "        [-1.0967,  1.8134, -0.7727],\n",
            "        [-1.6324,  0.9693,  0.4655],\n",
            "        [-1.0463,  1.4376, -0.7265],\n",
            "        [-1.1887,  1.6480, -0.6281]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3963,  1.6937, -0.4786],\n",
            "        [-1.2720,  1.6972, -0.8072],\n",
            "        [ 0.5889,  0.1620, -1.1160],\n",
            "        [ 0.7003,  0.0531, -1.0811],\n",
            "        [-1.3386,  1.9066, -0.4617],\n",
            "        [-0.7710,  1.3426, -0.7534],\n",
            "        [-0.9155,  0.1608,  0.6358],\n",
            "        [-1.0939,  1.4675, -0.4261],\n",
            "        [-1.5049,  1.8916, -0.7414],\n",
            "        [-0.1352,  0.6390, -0.8277],\n",
            "        [-1.0792,  1.5769, -0.6328],\n",
            "        [-0.9432,  1.7735, -0.8190],\n",
            "        [-1.0967,  1.8134, -0.7727],\n",
            "        [-1.6324,  0.9693,  0.4655],\n",
            "        [-1.0463,  1.4376, -0.7265],\n",
            "        [-1.1887,  1.6480, -0.6281]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.1040,  1.7815, -0.9178],\n",
            "        [-1.1370,  1.7505, -0.7701],\n",
            "        [-1.4488,  1.8623, -0.6352],\n",
            "        [-1.3521,  1.7729, -0.6374],\n",
            "        [-1.2255,  1.3650, -0.2342],\n",
            "        [-0.3538,  0.8954, -0.8368],\n",
            "        [-1.3406,  1.9200, -0.6610],\n",
            "        [-1.3014,  1.6122, -0.2861],\n",
            "        [-1.1559,  1.7659, -0.7762],\n",
            "        [-1.0683,  1.3086, -0.6208],\n",
            "        [-1.2982,  1.4995, -0.4151],\n",
            "        [-1.6683,  0.5448,  0.7751],\n",
            "        [-0.2771,  0.8158, -1.1241],\n",
            "        [-1.7701,  0.2957,  0.9552],\n",
            "        [-1.3372,  1.7932, -0.6258],\n",
            "        [-0.5225,  1.0750, -0.4636]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.1040,  1.7815, -0.9178],\n",
            "        [-1.1370,  1.7505, -0.7701],\n",
            "        [-1.4488,  1.8623, -0.6352],\n",
            "        [-1.3521,  1.7729, -0.6374],\n",
            "        [-1.2255,  1.3650, -0.2342],\n",
            "        [-0.3538,  0.8954, -0.8368],\n",
            "        [-1.3406,  1.9200, -0.6610],\n",
            "        [-1.3014,  1.6122, -0.2861],\n",
            "        [-1.1559,  1.7659, -0.7762],\n",
            "        [-1.0683,  1.3086, -0.6208],\n",
            "        [-1.2982,  1.4995, -0.4151],\n",
            "        [-1.6683,  0.5448,  0.7751],\n",
            "        [-0.2771,  0.8158, -1.1241],\n",
            "        [-1.7701,  0.2957,  0.9552],\n",
            "        [-1.3372,  1.7932, -0.6258],\n",
            "        [-0.5225,  1.0750, -0.4636]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4197,  1.6995, -0.7205],\n",
            "        [-1.5412,  0.2465,  0.9100],\n",
            "        [-1.4946,  1.8691, -0.6567],\n",
            "        [ 0.7461,  0.0139, -1.1915],\n",
            "        [-0.9846,  1.6620, -0.7297],\n",
            "        [-1.1372,  1.7576, -0.6601],\n",
            "        [-1.3863,  1.9451, -0.6520],\n",
            "        [-1.3680,  0.6978,  0.2598],\n",
            "        [-1.3870,  1.8603, -0.7231],\n",
            "        [-1.2802,  1.6238, -0.4697],\n",
            "        [-1.3185, -0.0108,  1.0924],\n",
            "        [-1.1466,  1.9015, -0.7414],\n",
            "        [-1.6601,  0.6567,  0.6507],\n",
            "        [-1.2854,  1.5554, -0.4853],\n",
            "        [-1.5139,  0.1993,  0.9920],\n",
            "        [-1.6356,  0.4161,  0.9525]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4197,  1.6995, -0.7205],\n",
            "        [-1.5412,  0.2465,  0.9100],\n",
            "        [-1.4946,  1.8691, -0.6567],\n",
            "        [ 0.7461,  0.0139, -1.1915],\n",
            "        [-0.9846,  1.6620, -0.7297],\n",
            "        [-1.1372,  1.7576, -0.6601],\n",
            "        [-1.3863,  1.9451, -0.6520],\n",
            "        [-1.3680,  0.6978,  0.2598],\n",
            "        [-1.3870,  1.8603, -0.7231],\n",
            "        [-1.2802,  1.6238, -0.4697],\n",
            "        [-1.3185, -0.0108,  1.0924],\n",
            "        [-1.1466,  1.9015, -0.7414],\n",
            "        [-1.6601,  0.6567,  0.6507],\n",
            "        [-1.2854,  1.5554, -0.4853],\n",
            "        [-1.5139,  0.1993,  0.9920],\n",
            "        [-1.6356,  0.4161,  0.9525]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.0821,  1.7648, -0.6472],\n",
            "        [-1.7319,  0.2912,  1.1081],\n",
            "        [-1.2371,  1.7870, -0.8052],\n",
            "        [-1.2444,  1.8543, -0.3605],\n",
            "        [-0.8246,  1.7386, -0.5907],\n",
            "        [-1.2375,  1.6149, -0.2249],\n",
            "        [-1.7816,  0.5708,  0.8969],\n",
            "        [ 0.2632,  0.0784, -0.7399],\n",
            "        [-1.6520,  0.2283,  1.1385],\n",
            "        [-1.2593,  2.0137, -0.7254],\n",
            "        [-1.7676,  1.3370,  0.2173],\n",
            "        [-1.3809,  1.9181, -0.4661],\n",
            "        [-1.2931,  1.6250, -0.1639],\n",
            "        [-1.2422,  1.3411, -0.3836],\n",
            "        [-1.5257,  1.8530, -0.6771],\n",
            "        [-1.7091,  0.2674,  0.9723]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.0821,  1.7648, -0.6472],\n",
            "        [-1.7319,  0.2912,  1.1081],\n",
            "        [-1.2371,  1.7870, -0.8052],\n",
            "        [-1.2444,  1.8543, -0.3605],\n",
            "        [-0.8246,  1.7386, -0.5907],\n",
            "        [-1.2375,  1.6149, -0.2249],\n",
            "        [-1.7816,  0.5708,  0.8969],\n",
            "        [ 0.2632,  0.0784, -0.7399],\n",
            "        [-1.6520,  0.2283,  1.1385],\n",
            "        [-1.2593,  2.0137, -0.7254],\n",
            "        [-1.7676,  1.3370,  0.2173],\n",
            "        [-1.3809,  1.9181, -0.4661],\n",
            "        [-1.2931,  1.6250, -0.1639],\n",
            "        [-1.2422,  1.3411, -0.3836],\n",
            "        [-1.5257,  1.8530, -0.6771],\n",
            "        [-1.7091,  0.2674,  0.9723]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5255,  0.1166, -0.8160],\n",
            "        [-1.6735,  1.3551, -0.0516],\n",
            "        [-1.3214,  1.7702, -0.4983],\n",
            "        [-1.0212,  1.4224, -0.6585],\n",
            "        [-1.5200,  1.3293, -0.0516],\n",
            "        [-2.0124,  0.4838,  1.1289],\n",
            "        [-1.3512,  1.8545, -0.7062],\n",
            "        [-0.8659,  1.6707, -0.5836],\n",
            "        [-1.6338,  1.0187,  0.3713],\n",
            "        [-0.9101,  1.5096, -0.2792],\n",
            "        [ 0.2031, -0.0506, -0.5014],\n",
            "        [-1.1694,  1.7197, -0.7184],\n",
            "        [-1.4578,  0.0255,  1.0361],\n",
            "        [-1.3143,  1.6313, -0.5368],\n",
            "        [ 0.7223,  0.1016, -0.9507],\n",
            "        [-1.4729,  1.7734, -0.4096]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.5255,  0.1166, -0.8160],\n",
            "        [-1.6735,  1.3551, -0.0516],\n",
            "        [-1.3214,  1.7702, -0.4983],\n",
            "        [-1.0212,  1.4224, -0.6585],\n",
            "        [-1.5200,  1.3293, -0.0516],\n",
            "        [-2.0124,  0.4838,  1.1289],\n",
            "        [-1.3512,  1.8545, -0.7062],\n",
            "        [-0.8659,  1.6707, -0.5836],\n",
            "        [-1.6338,  1.0187,  0.3713],\n",
            "        [-0.9101,  1.5096, -0.2792],\n",
            "        [ 0.2031, -0.0506, -0.5014],\n",
            "        [-1.1694,  1.7197, -0.7184],\n",
            "        [-1.4578,  0.0255,  1.0361],\n",
            "        [-1.3143,  1.6313, -0.5368],\n",
            "        [ 0.7223,  0.1016, -0.9507],\n",
            "        [-1.4729,  1.7734, -0.4096]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3635,  0.4710,  1.1305],\n",
            "        [ 0.4720, -0.0353, -1.0844],\n",
            "        [-2.0076,  1.1181,  0.4492],\n",
            "        [-1.5661,  1.8401, -0.4462],\n",
            "        [-1.2846,  1.6455, -0.5859],\n",
            "        [-1.3760,  0.1467,  1.0058],\n",
            "        [-1.7391,  0.1021,  1.0195],\n",
            "        [-1.8590,  0.0386,  1.1714],\n",
            "        [-0.6849,  1.1446, -0.7012],\n",
            "        [-1.5077,  0.0825,  0.8979],\n",
            "        [-1.1984,  1.7667, -0.6896],\n",
            "        [-1.0165,  1.5619, -0.5715],\n",
            "        [-1.4516,  1.9457, -0.5288],\n",
            "        [-1.6323,  0.1336,  1.0451],\n",
            "        [ 0.7700,  0.0092, -0.9275],\n",
            "        [-1.3483,  2.0346, -0.6052]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3635,  0.4710,  1.1305],\n",
            "        [ 0.4720, -0.0353, -1.0844],\n",
            "        [-2.0076,  1.1181,  0.4492],\n",
            "        [-1.5661,  1.8401, -0.4462],\n",
            "        [-1.2846,  1.6455, -0.5859],\n",
            "        [-1.3760,  0.1467,  1.0058],\n",
            "        [-1.7391,  0.1021,  1.0195],\n",
            "        [-1.8590,  0.0386,  1.1714],\n",
            "        [-0.6849,  1.1446, -0.7012],\n",
            "        [-1.5077,  0.0825,  0.8979],\n",
            "        [-1.1984,  1.7667, -0.6896],\n",
            "        [-1.0165,  1.5619, -0.5715],\n",
            "        [-1.4516,  1.9457, -0.5288],\n",
            "        [-1.6323,  0.1336,  1.0451],\n",
            "        [ 0.7700,  0.0092, -0.9275],\n",
            "        [-1.3483,  2.0346, -0.6052]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3018,  1.4446, -0.6256],\n",
            "        [-1.3014,  1.7990, -0.6022],\n",
            "        [-1.2999,  1.5785, -0.3557],\n",
            "        [-1.5589,  1.5859, -0.3437],\n",
            "        [-1.3633,  0.0557,  1.1184],\n",
            "        [-1.3029,  1.1748, -0.1112],\n",
            "        [-1.5471,  1.1451,  0.4636],\n",
            "        [ 0.5711, -0.1088, -0.9191],\n",
            "        [-0.6244,  1.3223, -0.8214],\n",
            "        [-1.4766,  0.1802,  1.0309],\n",
            "        [-1.2100,  1.4272, -0.3248],\n",
            "        [-1.1664,  1.7871, -0.7437],\n",
            "        [-1.9227,  0.7889,  0.6356],\n",
            "        [-1.0360,  1.6558, -0.5294],\n",
            "        [-1.0029,  1.5384, -0.7012],\n",
            "        [-1.3498,  1.8228, -0.8205]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3018,  1.4446, -0.6256],\n",
            "        [-1.3014,  1.7990, -0.6022],\n",
            "        [-1.2999,  1.5785, -0.3557],\n",
            "        [-1.5589,  1.5859, -0.3437],\n",
            "        [-1.3633,  0.0557,  1.1184],\n",
            "        [-1.3029,  1.1748, -0.1112],\n",
            "        [-1.5471,  1.1451,  0.4636],\n",
            "        [ 0.5711, -0.1088, -0.9191],\n",
            "        [-0.6244,  1.3223, -0.8214],\n",
            "        [-1.4766,  0.1802,  1.0309],\n",
            "        [-1.2100,  1.4272, -0.3248],\n",
            "        [-1.1664,  1.7871, -0.7437],\n",
            "        [-1.9227,  0.7889,  0.6356],\n",
            "        [-1.0360,  1.6558, -0.5294],\n",
            "        [-1.0029,  1.5384, -0.7012],\n",
            "        [-1.3498,  1.8228, -0.8205]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8578,  0.2468,  1.1745],\n",
            "        [-1.8234,  0.8009,  0.6265],\n",
            "        [-1.4914,  0.6081,  0.4201],\n",
            "        [-0.7676,  1.2485, -0.6864],\n",
            "        [-1.3854,  1.4835, -0.3738],\n",
            "        [-1.0113,  1.5816, -0.7154],\n",
            "        [-0.7645,  0.0758,  0.4424],\n",
            "        [-1.5604,  1.7035, -0.5668],\n",
            "        [-1.1859,  1.7785, -0.4097],\n",
            "        [-1.1144,  1.4853, -0.5058],\n",
            "        [-1.4658,  1.7079, -0.3914],\n",
            "        [-1.5811,  0.2768,  1.0361],\n",
            "        [-1.6894,  0.2627,  1.1414],\n",
            "        [-1.1972,  1.0926, -0.2768],\n",
            "        [-1.1899,  1.7670, -0.4386],\n",
            "        [-1.4482,  0.0717,  1.2160]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8578,  0.2468,  1.1745],\n",
            "        [-1.8234,  0.8009,  0.6265],\n",
            "        [-1.4914,  0.6081,  0.4201],\n",
            "        [-0.7676,  1.2485, -0.6864],\n",
            "        [-1.3854,  1.4835, -0.3738],\n",
            "        [-1.0113,  1.5816, -0.7154],\n",
            "        [-0.7645,  0.0758,  0.4424],\n",
            "        [-1.5604,  1.7035, -0.5668],\n",
            "        [-1.1859,  1.7785, -0.4097],\n",
            "        [-1.1144,  1.4853, -0.5058],\n",
            "        [-1.4658,  1.7079, -0.3914],\n",
            "        [-1.5811,  0.2768,  1.0361],\n",
            "        [-1.6894,  0.2627,  1.1414],\n",
            "        [-1.1972,  1.0926, -0.2768],\n",
            "        [-1.1899,  1.7670, -0.4386],\n",
            "        [-1.4482,  0.0717,  1.2160]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.1094,  1.6734, -0.8167],\n",
            "        [-1.1679,  1.5788, -0.5515],\n",
            "        [-1.7564,  0.2122,  1.2817],\n",
            "        [-1.5900,  1.6504, -0.1970],\n",
            "        [-1.6180,  0.0892,  1.2403],\n",
            "        [-1.8187,  0.1317,  1.0645],\n",
            "        [-1.2788,  1.9798, -0.5618],\n",
            "        [-1.5080,  1.7827, -0.1023],\n",
            "        [ 0.6154, -0.0306, -0.8671],\n",
            "        [-1.3332,  1.7121, -0.5655],\n",
            "        [-1.5034, -0.0323,  1.3414],\n",
            "        [-1.6612,  0.0387,  1.2107],\n",
            "        [-1.8563,  0.2290,  1.2955],\n",
            "        [-1.7917,  1.6266, -0.2292],\n",
            "        [-1.2449,  1.6472, -0.5700],\n",
            "        [-1.7357,  0.2550,  1.1002]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.1094,  1.6734, -0.8167],\n",
            "        [-1.1679,  1.5788, -0.5515],\n",
            "        [-1.7564,  0.2122,  1.2817],\n",
            "        [-1.5900,  1.6504, -0.1970],\n",
            "        [-1.6180,  0.0892,  1.2403],\n",
            "        [-1.8187,  0.1317,  1.0645],\n",
            "        [-1.2788,  1.9798, -0.5618],\n",
            "        [-1.5080,  1.7827, -0.1023],\n",
            "        [ 0.6154, -0.0306, -0.8671],\n",
            "        [-1.3332,  1.7121, -0.5655],\n",
            "        [-1.5034, -0.0323,  1.3414],\n",
            "        [-1.6612,  0.0387,  1.2107],\n",
            "        [-1.8563,  0.2290,  1.2955],\n",
            "        [-1.7917,  1.6266, -0.2292],\n",
            "        [-1.2449,  1.6472, -0.5700],\n",
            "        [-1.7357,  0.2550,  1.1002]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6212,  1.6614, -0.2808],\n",
            "        [-1.6859,  0.8689,  0.4109],\n",
            "        [-1.8145,  0.5396,  1.0842],\n",
            "        [-0.7309,  0.1523,  0.4819],\n",
            "        [-0.9630,  1.4290, -0.5998],\n",
            "        [-1.3093,  1.2586, -0.4148],\n",
            "        [-1.8071, -0.0708,  1.1587],\n",
            "        [ 0.4748, -0.2390, -0.4868],\n",
            "        [-1.0477,  1.8117, -0.5847],\n",
            "        [-1.8493,  0.1982,  1.1631],\n",
            "        [-1.6288,  0.5236,  0.8887],\n",
            "        [-1.4821,  1.5274, -0.1952],\n",
            "        [-1.6915,  0.9759,  0.3277],\n",
            "        [-1.8108,  0.4238,  1.2259],\n",
            "        [-1.9910,  0.4815,  1.2782],\n",
            "        [-1.5941,  0.2453,  1.3673]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6212,  1.6614, -0.2808],\n",
            "        [-1.6859,  0.8689,  0.4109],\n",
            "        [-1.8145,  0.5396,  1.0842],\n",
            "        [-0.7309,  0.1523,  0.4819],\n",
            "        [-0.9630,  1.4290, -0.5998],\n",
            "        [-1.3093,  1.2586, -0.4148],\n",
            "        [-1.8071, -0.0708,  1.1587],\n",
            "        [ 0.4748, -0.2390, -0.4868],\n",
            "        [-1.0477,  1.8117, -0.5847],\n",
            "        [-1.8493,  0.1982,  1.1631],\n",
            "        [-1.6288,  0.5236,  0.8887],\n",
            "        [-1.4821,  1.5274, -0.1952],\n",
            "        [-1.6915,  0.9759,  0.3277],\n",
            "        [-1.8108,  0.4238,  1.2259],\n",
            "        [-1.9910,  0.4815,  1.2782],\n",
            "        [-1.5941,  0.2453,  1.3673]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6917,  0.2718,  1.2528],\n",
            "        [ 0.4957, -0.1571, -0.7796],\n",
            "        [-1.8351,  0.1672,  1.1581],\n",
            "        [ 0.1544,  0.2687, -0.7888],\n",
            "        [-0.9586,  1.1735, -0.1711],\n",
            "        [-1.4105,  1.8016, -0.6443],\n",
            "        [-1.6738,  0.4821,  0.8851],\n",
            "        [-1.8207, -0.0513,  1.1771],\n",
            "        [-1.6213,  1.4818, -0.1658],\n",
            "        [-1.1578,  1.9115, -0.3772],\n",
            "        [-1.7110,  0.4389,  0.9634],\n",
            "        [-0.9527,  1.4069, -0.7129],\n",
            "        [ 0.5711,  0.1315, -1.0651],\n",
            "        [-1.7641, -0.0653,  1.3383],\n",
            "        [-1.6009,  0.2665,  1.0649],\n",
            "        [-1.6459,  0.3963,  0.9604]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6917,  0.2718,  1.2528],\n",
            "        [ 0.4957, -0.1571, -0.7796],\n",
            "        [-1.8351,  0.1672,  1.1581],\n",
            "        [ 0.1544,  0.2687, -0.7888],\n",
            "        [-0.9586,  1.1735, -0.1711],\n",
            "        [-1.4105,  1.8016, -0.6443],\n",
            "        [-1.6738,  0.4821,  0.8851],\n",
            "        [-1.8207, -0.0513,  1.1771],\n",
            "        [-1.6213,  1.4818, -0.1658],\n",
            "        [-1.1578,  1.9115, -0.3772],\n",
            "        [-1.7110,  0.4389,  0.9634],\n",
            "        [-0.9527,  1.4069, -0.7129],\n",
            "        [ 0.5711,  0.1315, -1.0651],\n",
            "        [-1.7641, -0.0653,  1.3383],\n",
            "        [-1.6009,  0.2665,  1.0649],\n",
            "        [-1.6459,  0.3963,  0.9604]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2588,  1.9372, -0.5755],\n",
            "        [-1.7183,  0.5639,  0.6778],\n",
            "        [-1.4689,  1.8356, -0.6351],\n",
            "        [-1.3782, -0.0145,  1.1723],\n",
            "        [-1.7201,  1.0479,  0.4056],\n",
            "        [-0.0163, -0.2495, -0.0903],\n",
            "        [-2.1382,  0.7178,  0.7863],\n",
            "        [-2.0694,  0.7179,  1.0213],\n",
            "        [-1.1396,  1.7056, -0.7907],\n",
            "        [-0.5461, -0.0588,  0.4007],\n",
            "        [-0.4869,  0.7744, -0.5224],\n",
            "        [-1.5221,  1.6947, -0.4759],\n",
            "        [-1.8784,  0.2912,  1.2625],\n",
            "        [-1.7287,  0.2491,  1.2600],\n",
            "        [-1.8173,  0.4504,  1.0564],\n",
            "        [-1.5737,  0.6786,  0.7319]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2588,  1.9372, -0.5755],\n",
            "        [-1.7183,  0.5639,  0.6778],\n",
            "        [-1.4689,  1.8356, -0.6351],\n",
            "        [-1.3782, -0.0145,  1.1723],\n",
            "        [-1.7201,  1.0479,  0.4056],\n",
            "        [-0.0163, -0.2495, -0.0903],\n",
            "        [-2.1382,  0.7178,  0.7863],\n",
            "        [-2.0694,  0.7179,  1.0213],\n",
            "        [-1.1396,  1.7056, -0.7907],\n",
            "        [-0.5461, -0.0588,  0.4007],\n",
            "        [-0.4869,  0.7744, -0.5224],\n",
            "        [-1.5221,  1.6947, -0.4759],\n",
            "        [-1.8784,  0.2912,  1.2625],\n",
            "        [-1.7287,  0.2491,  1.2600],\n",
            "        [-1.8173,  0.4504,  1.0564],\n",
            "        [-1.5737,  0.6786,  0.7319]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.7783, -0.1906, -0.9851],\n",
            "        [ 0.6377, -0.1688, -0.8286],\n",
            "        [-0.8351,  1.2377, -0.8038],\n",
            "        [-0.3281,  0.8385, -0.8592],\n",
            "        [-1.5836, -0.0551,  1.0817],\n",
            "        [-1.1630,  1.9201, -0.5398],\n",
            "        [-1.1082,  1.4569, -0.5302],\n",
            "        [-1.5606,  1.7990, -0.5567],\n",
            "        [-1.6426,  1.8543, -0.2529],\n",
            "        [-0.8846,  1.4810, -0.5161],\n",
            "        [-2.0175,  1.3903,  0.5301],\n",
            "        [-1.3079,  1.4824, -0.6201],\n",
            "        [-1.7043, -0.0528,  1.2179],\n",
            "        [-1.8506,  0.4830,  1.0265],\n",
            "        [ 0.8443, -0.2345, -0.7961],\n",
            "        [-1.3142,  1.6167, -0.5519]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.7783, -0.1906, -0.9851],\n",
            "        [ 0.6377, -0.1688, -0.8286],\n",
            "        [-0.8351,  1.2377, -0.8038],\n",
            "        [-0.3281,  0.8385, -0.8592],\n",
            "        [-1.5836, -0.0551,  1.0817],\n",
            "        [-1.1630,  1.9201, -0.5398],\n",
            "        [-1.1082,  1.4569, -0.5302],\n",
            "        [-1.5606,  1.7990, -0.5567],\n",
            "        [-1.6426,  1.8543, -0.2529],\n",
            "        [-0.8846,  1.4810, -0.5161],\n",
            "        [-2.0175,  1.3903,  0.5301],\n",
            "        [-1.3079,  1.4824, -0.6201],\n",
            "        [-1.7043, -0.0528,  1.2179],\n",
            "        [-1.8506,  0.4830,  1.0265],\n",
            "        [ 0.8443, -0.2345, -0.7961],\n",
            "        [-1.3142,  1.6167, -0.5519]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2356,  1.2679, -0.3040],\n",
            "        [-1.4079,  1.6726, -0.5897],\n",
            "        [-1.2999,  1.4985, -0.3664],\n",
            "        [-1.2685,  1.6145, -0.2531],\n",
            "        [-1.6932, -0.1191,  1.1590],\n",
            "        [-1.3480,  1.7783, -0.4185],\n",
            "        [-1.7924,  1.3821,  0.0769],\n",
            "        [-1.6334,  1.7958, -0.0959],\n",
            "        [-1.7497,  0.1768,  1.3280],\n",
            "        [-1.9811,  0.4824,  1.2098],\n",
            "        [-1.6005,  1.9682, -0.4616],\n",
            "        [-1.2869,  1.6579, -0.4443],\n",
            "        [-0.7979,  1.3335, -0.8443],\n",
            "        [-1.4990,  1.5118, -0.2615],\n",
            "        [-2.1431,  0.2508,  1.4751],\n",
            "        [ 0.5581, -0.0890, -0.6692]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2356,  1.2679, -0.3040],\n",
            "        [-1.4079,  1.6726, -0.5897],\n",
            "        [-1.2999,  1.4985, -0.3664],\n",
            "        [-1.2685,  1.6145, -0.2531],\n",
            "        [-1.6932, -0.1191,  1.1590],\n",
            "        [-1.3480,  1.7783, -0.4185],\n",
            "        [-1.7924,  1.3821,  0.0769],\n",
            "        [-1.6334,  1.7958, -0.0959],\n",
            "        [-1.7497,  0.1768,  1.3280],\n",
            "        [-1.9811,  0.4824,  1.2098],\n",
            "        [-1.6005,  1.9682, -0.4616],\n",
            "        [-1.2869,  1.6579, -0.4443],\n",
            "        [-0.7979,  1.3335, -0.8443],\n",
            "        [-1.4990,  1.5118, -0.2615],\n",
            "        [-2.1431,  0.2508,  1.4751],\n",
            "        [ 0.5581, -0.0890, -0.6692]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9332,  0.9724,  0.8265],\n",
            "        [-1.7380,  0.3141,  1.1101],\n",
            "        [-2.0389,  0.4166,  1.1886],\n",
            "        [ 0.4043, -0.0802, -0.5821],\n",
            "        [-1.6681,  1.8298, -0.3581],\n",
            "        [ 0.3910, -0.0148, -0.7565],\n",
            "        [-2.0732,  0.9514,  0.7468],\n",
            "        [-1.2075,  1.4354, -0.6021],\n",
            "        [-1.4402,  1.8724, -0.5189],\n",
            "        [-1.3283,  1.7744, -0.3173],\n",
            "        [-1.6841,  1.5225,  0.1007],\n",
            "        [-1.6957,  0.1828,  1.3629],\n",
            "        [-0.0313, -0.1326, -0.0596],\n",
            "        [-1.2768,  1.6627, -0.3875],\n",
            "        [-1.1855,  0.4901,  0.4361],\n",
            "        [-1.0896,  0.5261,  0.2966]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9332,  0.9724,  0.8265],\n",
            "        [-1.7380,  0.3141,  1.1101],\n",
            "        [-2.0389,  0.4166,  1.1886],\n",
            "        [ 0.4043, -0.0802, -0.5821],\n",
            "        [-1.6681,  1.8298, -0.3581],\n",
            "        [ 0.3910, -0.0148, -0.7565],\n",
            "        [-2.0732,  0.9514,  0.7468],\n",
            "        [-1.2075,  1.4354, -0.6021],\n",
            "        [-1.4402,  1.8724, -0.5189],\n",
            "        [-1.3283,  1.7744, -0.3173],\n",
            "        [-1.6841,  1.5225,  0.1007],\n",
            "        [-1.6957,  0.1828,  1.3629],\n",
            "        [-0.0313, -0.1326, -0.0596],\n",
            "        [-1.2768,  1.6627, -0.3875],\n",
            "        [-1.1855,  0.4901,  0.4361],\n",
            "        [-1.0896,  0.5261,  0.2966]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.3212,  0.4096,  1.0402],\n",
            "        [-1.6298,  0.0154,  1.1231],\n",
            "        [-1.1405,  1.6105, -0.4139],\n",
            "        [-1.6011,  2.1088, -0.2477],\n",
            "        [-1.3272,  1.6468, -0.8081],\n",
            "        [-1.4086,  1.6582, -0.4054],\n",
            "        [ 0.0420,  0.2749, -0.5436],\n",
            "        [ 0.6561, -0.1801, -0.7742],\n",
            "        [-1.3303,  1.7262, -0.4790],\n",
            "        [ 0.3348,  0.2067, -0.7074],\n",
            "        [-2.0870,  0.3089,  1.3991],\n",
            "        [-1.4085,  1.7786, -0.3494],\n",
            "        [-1.1970,  1.5407, -0.8100],\n",
            "        [ 0.0113,  0.3315, -0.6566],\n",
            "        [-0.7860,  1.6039, -0.8308],\n",
            "        [-1.2695,  1.7395, -0.5918]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.3212,  0.4096,  1.0402],\n",
            "        [-1.6298,  0.0154,  1.1231],\n",
            "        [-1.1405,  1.6105, -0.4139],\n",
            "        [-1.6011,  2.1088, -0.2477],\n",
            "        [-1.3272,  1.6468, -0.8081],\n",
            "        [-1.4086,  1.6582, -0.4054],\n",
            "        [ 0.0420,  0.2749, -0.5436],\n",
            "        [ 0.6561, -0.1801, -0.7742],\n",
            "        [-1.3303,  1.7262, -0.4790],\n",
            "        [ 0.3348,  0.2067, -0.7074],\n",
            "        [-2.0870,  0.3089,  1.3991],\n",
            "        [-1.4085,  1.7786, -0.3494],\n",
            "        [-1.1970,  1.5407, -0.8100],\n",
            "        [ 0.0113,  0.3315, -0.6566],\n",
            "        [-0.7860,  1.6039, -0.8308],\n",
            "        [-1.2695,  1.7395, -0.5918]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9599,  1.2297,  0.5135],\n",
            "        [-1.3094,  1.8398, -0.5243],\n",
            "        [-1.8277,  0.1859,  1.2791],\n",
            "        [-2.0634,  0.5140,  1.1969],\n",
            "        [-1.4175,  1.7700, -0.6032],\n",
            "        [ 0.2998, -0.1923, -0.5294],\n",
            "        [-1.4600,  1.8012, -0.3987],\n",
            "        [-1.1956,  1.7524, -0.6168],\n",
            "        [-1.3223,  1.6675, -0.4367],\n",
            "        [-1.8382,  0.6345,  0.8768],\n",
            "        [-1.4524,  2.0403, -0.5378],\n",
            "        [-1.4735,  1.7702, -0.5796],\n",
            "        [-1.9469,  1.4882,  0.1952],\n",
            "        [-1.2404,  1.6839, -0.4374],\n",
            "        [-0.5655,  1.2038, -0.6384],\n",
            "        [-1.4862,  1.7801, -0.3068]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9599,  1.2297,  0.5135],\n",
            "        [-1.3094,  1.8398, -0.5243],\n",
            "        [-1.8277,  0.1859,  1.2791],\n",
            "        [-2.0634,  0.5140,  1.1969],\n",
            "        [-1.4175,  1.7700, -0.6032],\n",
            "        [ 0.2998, -0.1923, -0.5294],\n",
            "        [-1.4600,  1.8012, -0.3987],\n",
            "        [-1.1956,  1.7524, -0.6168],\n",
            "        [-1.3223,  1.6675, -0.4367],\n",
            "        [-1.8382,  0.6345,  0.8768],\n",
            "        [-1.4524,  2.0403, -0.5378],\n",
            "        [-1.4735,  1.7702, -0.5796],\n",
            "        [-1.9469,  1.4882,  0.1952],\n",
            "        [-1.2404,  1.6839, -0.4374],\n",
            "        [-0.5655,  1.2038, -0.6384],\n",
            "        [-1.4862,  1.7801, -0.3068]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0900,  1.1634,  0.4443],\n",
            "        [ 0.2648, -0.0438, -0.6904],\n",
            "        [ 0.5842, -0.0363, -0.8356],\n",
            "        [-1.3366,  2.1410, -0.6584],\n",
            "        [-1.9008,  0.3999,  1.2661],\n",
            "        [-1.6814,  1.8590, -0.3172],\n",
            "        [-1.7539,  2.0141, -0.1392],\n",
            "        [-1.5506,  1.7691, -0.3913],\n",
            "        [-1.8514,  0.1696,  1.1499],\n",
            "        [-1.3246,  2.0107, -0.7740],\n",
            "        [-1.3521,  1.6101, -0.6620],\n",
            "        [-0.6066,  1.1688, -0.9010],\n",
            "        [-1.4530,  1.8531, -0.5220],\n",
            "        [ 0.3702,  0.3922, -0.9482],\n",
            "        [-1.2950,  1.6457, -0.6270],\n",
            "        [-1.6420,  2.0038, -0.4079]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0900,  1.1634,  0.4443],\n",
            "        [ 0.2648, -0.0438, -0.6904],\n",
            "        [ 0.5842, -0.0363, -0.8356],\n",
            "        [-1.3366,  2.1410, -0.6584],\n",
            "        [-1.9008,  0.3999,  1.2661],\n",
            "        [-1.6814,  1.8590, -0.3172],\n",
            "        [-1.7539,  2.0141, -0.1392],\n",
            "        [-1.5506,  1.7691, -0.3913],\n",
            "        [-1.8514,  0.1696,  1.1499],\n",
            "        [-1.3246,  2.0107, -0.7740],\n",
            "        [-1.3521,  1.6101, -0.6620],\n",
            "        [-0.6066,  1.1688, -0.9010],\n",
            "        [-1.4530,  1.8531, -0.5220],\n",
            "        [ 0.3702,  0.3922, -0.9482],\n",
            "        [-1.2950,  1.6457, -0.6270],\n",
            "        [-1.6420,  2.0038, -0.4079]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1438,  0.3974,  1.2203],\n",
            "        [-1.9557,  0.6797,  0.8921],\n",
            "        [-1.6063,  1.7090, -0.4532],\n",
            "        [-1.0967,  1.5000, -0.4659],\n",
            "        [-1.8148,  0.0701,  1.1597],\n",
            "        [-1.7026,  1.6183, -0.2363],\n",
            "        [-1.6322,  1.9610, -0.5893],\n",
            "        [-2.0304,  0.6579,  0.8714],\n",
            "        [-1.6787,  2.0790, -0.2976],\n",
            "        [-1.2815,  1.8638, -0.5439],\n",
            "        [-1.8931,  0.5110,  1.0329],\n",
            "        [-1.5198,  1.9792, -0.6155],\n",
            "        [-1.8732,  1.8248, -0.2999],\n",
            "        [-1.9092,  1.7148, -0.3256],\n",
            "        [-1.6026,  2.0051, -0.5434],\n",
            "        [-1.3229,  1.8544, -0.4867]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1438,  0.3974,  1.2203],\n",
            "        [-1.9557,  0.6797,  0.8921],\n",
            "        [-1.6063,  1.7090, -0.4532],\n",
            "        [-1.0967,  1.5000, -0.4659],\n",
            "        [-1.8148,  0.0701,  1.1597],\n",
            "        [-1.7026,  1.6183, -0.2363],\n",
            "        [-1.6322,  1.9610, -0.5893],\n",
            "        [-2.0304,  0.6579,  0.8714],\n",
            "        [-1.6787,  2.0790, -0.2976],\n",
            "        [-1.2815,  1.8638, -0.5439],\n",
            "        [-1.8931,  0.5110,  1.0329],\n",
            "        [-1.5198,  1.9792, -0.6155],\n",
            "        [-1.8732,  1.8248, -0.2999],\n",
            "        [-1.9092,  1.7148, -0.3256],\n",
            "        [-1.6026,  2.0051, -0.5434],\n",
            "        [-1.3229,  1.8544, -0.4867]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9677,  1.0890,  0.4164],\n",
            "        [-1.7157,  1.6872,  0.0028],\n",
            "        [-2.1156,  1.0456,  0.8007],\n",
            "        [-2.4226,  0.5915,  1.3972],\n",
            "        [-1.4835,  1.8244, -0.3640],\n",
            "        [-1.5185,  1.9588, -0.5272],\n",
            "        [-1.8555,  1.7001, -0.0028],\n",
            "        [-1.6217,  1.8537, -0.3512],\n",
            "        [-1.7274,  1.7479, -0.0592],\n",
            "        [-1.7050,  1.9091, -0.4366],\n",
            "        [-1.9659,  1.0229,  0.7634],\n",
            "        [-1.7865,  0.2741,  1.1821],\n",
            "        [-1.5947,  1.8875, -0.6645],\n",
            "        [-1.6333,  0.3717,  1.1178],\n",
            "        [-1.8879,  1.6557, -0.4223],\n",
            "        [ 0.4114, -0.0563, -0.7571]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9677,  1.0890,  0.4164],\n",
            "        [-1.7157,  1.6872,  0.0028],\n",
            "        [-2.1156,  1.0456,  0.8007],\n",
            "        [-2.4226,  0.5915,  1.3972],\n",
            "        [-1.4835,  1.8244, -0.3640],\n",
            "        [-1.5185,  1.9588, -0.5272],\n",
            "        [-1.8555,  1.7001, -0.0028],\n",
            "        [-1.6217,  1.8537, -0.3512],\n",
            "        [-1.7274,  1.7479, -0.0592],\n",
            "        [-1.7050,  1.9091, -0.4366],\n",
            "        [-1.9659,  1.0229,  0.7634],\n",
            "        [-1.7865,  0.2741,  1.1821],\n",
            "        [-1.5947,  1.8875, -0.6645],\n",
            "        [-1.6333,  0.3717,  1.1178],\n",
            "        [-1.8879,  1.6557, -0.4223],\n",
            "        [ 0.4114, -0.0563, -0.7571]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6908,  1.7773, -0.3534],\n",
            "        [-1.6351,  2.0891, -0.3636],\n",
            "        [-1.7102,  1.7350, -0.3458],\n",
            "        [-1.5360,  1.9997, -0.7154],\n",
            "        [-1.7110,  2.1971, -0.6079],\n",
            "        [-1.6377,  2.0493, -0.2008],\n",
            "        [-1.5347,  0.8928,  0.5230],\n",
            "        [-0.5538,  1.2011, -0.8268],\n",
            "        [-1.9729,  0.5362,  0.9216],\n",
            "        [-1.7300,  2.1823, -0.4716],\n",
            "        [-1.6235,  2.0031, -0.4073],\n",
            "        [-1.6188,  1.9749, -0.4792],\n",
            "        [-1.3440,  2.1416, -0.7366],\n",
            "        [-1.8814,  0.5300,  1.0462],\n",
            "        [-2.2143,  0.5555,  1.1495],\n",
            "        [-1.7217,  2.2298, -0.4074]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6908,  1.7773, -0.3534],\n",
            "        [-1.6351,  2.0891, -0.3636],\n",
            "        [-1.7102,  1.7350, -0.3458],\n",
            "        [-1.5360,  1.9997, -0.7154],\n",
            "        [-1.7110,  2.1971, -0.6079],\n",
            "        [-1.6377,  2.0493, -0.2008],\n",
            "        [-1.5347,  0.8928,  0.5230],\n",
            "        [-0.5538,  1.2011, -0.8268],\n",
            "        [-1.9729,  0.5362,  0.9216],\n",
            "        [-1.7300,  2.1823, -0.4716],\n",
            "        [-1.6235,  2.0031, -0.4073],\n",
            "        [-1.6188,  1.9749, -0.4792],\n",
            "        [-1.3440,  2.1416, -0.7366],\n",
            "        [-1.8814,  0.5300,  1.0462],\n",
            "        [-2.2143,  0.5555,  1.1495],\n",
            "        [-1.7217,  2.2298, -0.4074]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.4053,  0.3148, -1.0955],\n",
            "        [-1.5915,  1.9636, -0.3565],\n",
            "        [-2.1327,  0.6928,  1.0536],\n",
            "        [-1.5844,  2.0813, -0.5912],\n",
            "        [ 0.3818,  0.1061, -0.9206],\n",
            "        [-1.8180,  1.9127, -0.4315],\n",
            "        [-2.1171,  0.8056,  0.8728],\n",
            "        [-1.6127,  0.6470,  0.4877],\n",
            "        [-1.7156,  2.2044, -0.5525],\n",
            "        [-1.5132,  2.0672, -0.5551],\n",
            "        [-1.4362,  1.9077, -0.3334],\n",
            "        [-1.8126,  0.2863,  1.2882],\n",
            "        [-1.8234,  1.8538, -0.2953],\n",
            "        [-2.1432,  1.0941,  0.6135],\n",
            "        [-2.0549,  0.7609,  1.0317],\n",
            "        [-1.5557,  1.9032, -0.3445]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.4053,  0.3148, -1.0955],\n",
            "        [-1.5915,  1.9636, -0.3565],\n",
            "        [-2.1327,  0.6928,  1.0536],\n",
            "        [-1.5844,  2.0813, -0.5912],\n",
            "        [ 0.3818,  0.1061, -0.9206],\n",
            "        [-1.8180,  1.9127, -0.4315],\n",
            "        [-2.1171,  0.8056,  0.8728],\n",
            "        [-1.6127,  0.6470,  0.4877],\n",
            "        [-1.7156,  2.2044, -0.5525],\n",
            "        [-1.5132,  2.0672, -0.5551],\n",
            "        [-1.4362,  1.9077, -0.3334],\n",
            "        [-1.8126,  0.2863,  1.2882],\n",
            "        [-1.8234,  1.8538, -0.2953],\n",
            "        [-2.1432,  1.0941,  0.6135],\n",
            "        [-2.0549,  0.7609,  1.0317],\n",
            "        [-1.5557,  1.9032, -0.3445]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7917e+00,  2.3284e-01,  1.0344e+00],\n",
            "        [-1.7784e+00,  3.7567e-01,  1.2530e+00],\n",
            "        [ 6.7674e-01, -1.0496e-01, -9.6751e-01],\n",
            "        [-2.0590e+00,  1.8779e+00, -5.3598e-02],\n",
            "        [-1.6626e+00,  1.9756e+00, -4.0503e-01],\n",
            "        [-1.9525e+00,  2.2789e+00, -5.2064e-01],\n",
            "        [-1.8051e+00,  4.2873e-01,  1.0528e+00],\n",
            "        [-1.6370e+00,  2.2463e+00, -5.6880e-01],\n",
            "        [-1.7741e+00,  1.8010e+00, -7.3129e-04],\n",
            "        [-1.6181e+00,  1.9518e+00, -4.2724e-01],\n",
            "        [-2.4483e+00,  1.6618e+00,  3.4239e-01],\n",
            "        [-1.7575e+00,  1.9183e+00, -4.3116e-01],\n",
            "        [-2.0288e+00,  9.1199e-01,  7.9772e-01],\n",
            "        [-2.2631e+00,  1.1736e+00,  7.6387e-01],\n",
            "        [-1.8190e+00,  1.8768e+00, -5.7511e-01],\n",
            "        [-1.4353e+00,  2.0340e+00, -6.2388e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7917e+00,  2.3284e-01,  1.0344e+00],\n",
            "        [-1.7784e+00,  3.7567e-01,  1.2530e+00],\n",
            "        [ 6.7674e-01, -1.0496e-01, -9.6751e-01],\n",
            "        [-2.0590e+00,  1.8779e+00, -5.3598e-02],\n",
            "        [-1.6626e+00,  1.9756e+00, -4.0503e-01],\n",
            "        [-1.9525e+00,  2.2789e+00, -5.2064e-01],\n",
            "        [-1.8051e+00,  4.2873e-01,  1.0528e+00],\n",
            "        [-1.6370e+00,  2.2463e+00, -5.6880e-01],\n",
            "        [-1.7741e+00,  1.8010e+00, -7.3129e-04],\n",
            "        [-1.6181e+00,  1.9518e+00, -4.2724e-01],\n",
            "        [-2.4483e+00,  1.6618e+00,  3.4239e-01],\n",
            "        [-1.7575e+00,  1.9183e+00, -4.3116e-01],\n",
            "        [-2.0288e+00,  9.1199e-01,  7.9772e-01],\n",
            "        [-2.2631e+00,  1.1736e+00,  7.6387e-01],\n",
            "        [-1.8190e+00,  1.8768e+00, -5.7511e-01],\n",
            "        [-1.4353e+00,  2.0340e+00, -6.2388e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7679,  2.1359, -0.3493],\n",
            "        [-1.8135,  2.2142, -0.4329],\n",
            "        [-1.6420,  2.0343, -0.2353],\n",
            "        [-1.7025,  1.8590, -0.4345],\n",
            "        [ 0.4854, -0.0661, -1.0141],\n",
            "        [-1.9911,  2.1332, -0.2885],\n",
            "        [-0.0036,  0.3544, -0.5381],\n",
            "        [-1.7941,  1.4189, -0.2811],\n",
            "        [-2.4170,  1.8154,  0.3219],\n",
            "        [-1.5626,  1.7821, -0.4360],\n",
            "        [-1.2793,  1.5425, -0.5997],\n",
            "        [-1.7527,  2.0271, -0.6312],\n",
            "        [-2.0134,  1.7975,  0.1207],\n",
            "        [-1.3732,  1.6321, -0.4413],\n",
            "        [-2.0889,  1.7723,  0.0794],\n",
            "        [-1.8953,  1.9825, -0.3443]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7679,  2.1359, -0.3493],\n",
            "        [-1.8135,  2.2142, -0.4329],\n",
            "        [-1.6420,  2.0343, -0.2353],\n",
            "        [-1.7025,  1.8590, -0.4345],\n",
            "        [ 0.4854, -0.0661, -1.0141],\n",
            "        [-1.9911,  2.1332, -0.2885],\n",
            "        [-0.0036,  0.3544, -0.5381],\n",
            "        [-1.7941,  1.4189, -0.2811],\n",
            "        [-2.4170,  1.8154,  0.3219],\n",
            "        [-1.5626,  1.7821, -0.4360],\n",
            "        [-1.2793,  1.5425, -0.5997],\n",
            "        [-1.7527,  2.0271, -0.6312],\n",
            "        [-2.0134,  1.7975,  0.1207],\n",
            "        [-1.3732,  1.6321, -0.4413],\n",
            "        [-2.0889,  1.7723,  0.0794],\n",
            "        [-1.8953,  1.9825, -0.3443]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5824,  0.2020, -0.9547],\n",
            "        [-1.6759,  2.1564, -0.1438],\n",
            "        [-2.0570,  0.8636,  0.9925],\n",
            "        [-1.9621,  0.5454,  1.1464],\n",
            "        [-2.4482,  2.0785,  0.0497],\n",
            "        [-1.6559,  2.1020, -0.4884],\n",
            "        [-1.6286,  2.1955, -0.4307],\n",
            "        [-2.0061,  1.8307, -0.4473],\n",
            "        [ 0.7036, -0.0214, -0.9513],\n",
            "        [ 0.6085, -0.0167, -1.0085],\n",
            "        [-1.5254,  1.8474, -0.2458],\n",
            "        [-1.7883,  2.0556, -0.3316],\n",
            "        [-1.8554,  1.8201,  0.1281],\n",
            "        [-1.9870,  1.9580, -0.0904],\n",
            "        [-1.9451,  2.0919, -0.2922],\n",
            "        [-1.9431,  1.9926, -0.1145]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.5824,  0.2020, -0.9547],\n",
            "        [-1.6759,  2.1564, -0.1438],\n",
            "        [-2.0570,  0.8636,  0.9925],\n",
            "        [-1.9621,  0.5454,  1.1464],\n",
            "        [-2.4482,  2.0785,  0.0497],\n",
            "        [-1.6559,  2.1020, -0.4884],\n",
            "        [-1.6286,  2.1955, -0.4307],\n",
            "        [-2.0061,  1.8307, -0.4473],\n",
            "        [ 0.7036, -0.0214, -0.9513],\n",
            "        [ 0.6085, -0.0167, -1.0085],\n",
            "        [-1.5254,  1.8474, -0.2458],\n",
            "        [-1.7883,  2.0556, -0.3316],\n",
            "        [-1.8554,  1.8201,  0.1281],\n",
            "        [-1.9870,  1.9580, -0.0904],\n",
            "        [-1.9451,  2.0919, -0.2922],\n",
            "        [-1.9431,  1.9926, -0.1145]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1020,  1.9496, -0.3218],\n",
            "        [-1.6033,  1.9349, -0.3926],\n",
            "        [-1.7152,  2.1485, -0.5893],\n",
            "        [-1.5543,  1.9917, -0.4640],\n",
            "        [-1.4698,  1.7138, -0.4454],\n",
            "        [-2.0475,  2.0410, -0.1787],\n",
            "        [-2.1791,  0.5950,  0.9211],\n",
            "        [-1.5006,  1.7337, -0.4556],\n",
            "        [-2.0778,  1.4929,  0.4591],\n",
            "        [-2.1144,  0.7224,  0.9434],\n",
            "        [-1.7933,  2.0094, -0.3490],\n",
            "        [-1.8311,  1.7549, -0.2168],\n",
            "        [-1.7860,  2.1134, -0.4194],\n",
            "        [-1.9692,  2.0919, -0.2115],\n",
            "        [-1.6874,  1.9233, -0.3188],\n",
            "        [-1.2386,  1.4028, -0.2955]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1020,  1.9496, -0.3218],\n",
            "        [-1.6033,  1.9349, -0.3926],\n",
            "        [-1.7152,  2.1485, -0.5893],\n",
            "        [-1.5543,  1.9917, -0.4640],\n",
            "        [-1.4698,  1.7138, -0.4454],\n",
            "        [-2.0475,  2.0410, -0.1787],\n",
            "        [-2.1791,  0.5950,  0.9211],\n",
            "        [-1.5006,  1.7337, -0.4556],\n",
            "        [-2.0778,  1.4929,  0.4591],\n",
            "        [-2.1144,  0.7224,  0.9434],\n",
            "        [-1.7933,  2.0094, -0.3490],\n",
            "        [-1.8311,  1.7549, -0.2168],\n",
            "        [-1.7860,  2.1134, -0.4194],\n",
            "        [-1.9692,  2.0919, -0.2115],\n",
            "        [-1.6874,  1.9233, -0.3188],\n",
            "        [-1.2386,  1.4028, -0.2955]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9460,  1.7087, -0.5237],\n",
            "        [-1.9995,  1.0583,  0.5302],\n",
            "        [-1.8472,  2.0217, -0.3616],\n",
            "        [-2.3147,  1.0399,  1.0837],\n",
            "        [-1.7801,  1.7824, -0.0419],\n",
            "        [-1.8404,  0.4681,  1.0259],\n",
            "        [-1.9804,  2.2716, -0.3475],\n",
            "        [-1.5917,  1.7186, -0.3396],\n",
            "        [-1.5554,  1.9726, -0.5792],\n",
            "        [ 0.6586,  0.1921, -1.0866],\n",
            "        [-1.5892,  1.8809, -0.3995],\n",
            "        [-1.6574,  1.8735, -0.4443],\n",
            "        [-1.6362,  2.0157, -0.1405],\n",
            "        [-1.8787,  2.0117, -0.4219],\n",
            "        [ 0.8586, -0.0688, -1.0211],\n",
            "        [-2.0375,  0.5612,  0.6719]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9460,  1.7087, -0.5237],\n",
            "        [-1.9995,  1.0583,  0.5302],\n",
            "        [-1.8472,  2.0217, -0.3616],\n",
            "        [-2.3147,  1.0399,  1.0837],\n",
            "        [-1.7801,  1.7824, -0.0419],\n",
            "        [-1.8404,  0.4681,  1.0259],\n",
            "        [-1.9804,  2.2716, -0.3475],\n",
            "        [-1.5917,  1.7186, -0.3396],\n",
            "        [-1.5554,  1.9726, -0.5792],\n",
            "        [ 0.6586,  0.1921, -1.0866],\n",
            "        [-1.5892,  1.8809, -0.3995],\n",
            "        [-1.6574,  1.8735, -0.4443],\n",
            "        [-1.6362,  2.0157, -0.1405],\n",
            "        [-1.8787,  2.0117, -0.4219],\n",
            "        [ 0.8586, -0.0688, -1.0211],\n",
            "        [-2.0375,  0.5612,  0.6719]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1247e+00,  1.9272e+00,  1.4634e-01],\n",
            "        [-2.0161e+00,  2.0042e+00,  4.4966e-04],\n",
            "        [-2.1776e+00,  1.2359e+00,  5.0065e-01],\n",
            "        [-1.9849e+00,  1.4254e+00,  4.7441e-01],\n",
            "        [-2.3230e+00,  8.3024e-01,  1.1249e+00],\n",
            "        [-1.9446e+00,  5.8587e-01,  8.5805e-01],\n",
            "        [-1.7612e+00,  2.0485e+00, -3.5346e-01],\n",
            "        [-1.7949e+00,  2.0420e+00, -3.2816e-01],\n",
            "        [-2.0154e+00,  7.3728e-01,  7.7266e-01],\n",
            "        [-1.8484e+00,  2.0247e+00, -2.0875e-01],\n",
            "        [-6.9890e-01,  4.9615e-01, -1.9342e-02],\n",
            "        [ 3.9519e-01,  1.5071e-01, -7.7649e-01],\n",
            "        [-2.2969e+00,  1.9680e+00, -4.6888e-02],\n",
            "        [-2.1902e+00,  7.9755e-01,  8.7494e-01],\n",
            "        [-1.8657e+00,  1.9144e+00, -1.8724e-01],\n",
            "        [-1.7464e+00,  1.9700e+00, -2.8957e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1247e+00,  1.9272e+00,  1.4634e-01],\n",
            "        [-2.0161e+00,  2.0042e+00,  4.4966e-04],\n",
            "        [-2.1776e+00,  1.2359e+00,  5.0065e-01],\n",
            "        [-1.9849e+00,  1.4254e+00,  4.7441e-01],\n",
            "        [-2.3230e+00,  8.3024e-01,  1.1249e+00],\n",
            "        [-1.9446e+00,  5.8587e-01,  8.5805e-01],\n",
            "        [-1.7612e+00,  2.0485e+00, -3.5346e-01],\n",
            "        [-1.7949e+00,  2.0420e+00, -3.2816e-01],\n",
            "        [-2.0154e+00,  7.3728e-01,  7.7266e-01],\n",
            "        [-1.8484e+00,  2.0247e+00, -2.0875e-01],\n",
            "        [-6.9890e-01,  4.9615e-01, -1.9342e-02],\n",
            "        [ 3.9519e-01,  1.5071e-01, -7.7649e-01],\n",
            "        [-2.2969e+00,  1.9680e+00, -4.6888e-02],\n",
            "        [-2.1902e+00,  7.9755e-01,  8.7494e-01],\n",
            "        [-1.8657e+00,  1.9144e+00, -1.8724e-01],\n",
            "        [-1.7464e+00,  1.9700e+00, -2.8957e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9736,  1.8908, -0.1743],\n",
            "        [-2.1029,  2.1890, -0.2979],\n",
            "        [ 0.8311, -0.0605, -1.1241],\n",
            "        [-2.3003,  1.3613,  0.7382],\n",
            "        [-1.8130,  0.8381,  0.5511],\n",
            "        [-0.7022,  1.2809, -0.6841],\n",
            "        [-1.7146,  0.1062,  1.3618],\n",
            "        [-1.7536,  1.9360, -0.1955],\n",
            "        [-1.7430,  2.0000, -0.3408],\n",
            "        [-1.6749,  1.6973, -0.3013],\n",
            "        [-1.8399,  2.0022, -0.2094],\n",
            "        [-1.1854,  1.6903, -0.4891],\n",
            "        [-1.7322,  1.9194, -0.3406],\n",
            "        [-1.6586,  0.5810,  1.0126],\n",
            "        [-1.9064,  1.9872, -0.0801],\n",
            "        [-1.7511,  1.7010, -0.3547]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9736,  1.8908, -0.1743],\n",
            "        [-2.1029,  2.1890, -0.2979],\n",
            "        [ 0.8311, -0.0605, -1.1241],\n",
            "        [-2.3003,  1.3613,  0.7382],\n",
            "        [-1.8130,  0.8381,  0.5511],\n",
            "        [-0.7022,  1.2809, -0.6841],\n",
            "        [-1.7146,  0.1062,  1.3618],\n",
            "        [-1.7536,  1.9360, -0.1955],\n",
            "        [-1.7430,  2.0000, -0.3408],\n",
            "        [-1.6749,  1.6973, -0.3013],\n",
            "        [-1.8399,  2.0022, -0.2094],\n",
            "        [-1.1854,  1.6903, -0.4891],\n",
            "        [-1.7322,  1.9194, -0.3406],\n",
            "        [-1.6586,  0.5810,  1.0126],\n",
            "        [-1.9064,  1.9872, -0.0801],\n",
            "        [-1.7511,  1.7010, -0.3547]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8279,  1.9857, -0.2974],\n",
            "        [-2.0801,  1.9076, -0.1380],\n",
            "        [-1.0927,  1.6291, -0.5943],\n",
            "        [-1.8365,  1.9915, -0.1607],\n",
            "        [-1.8487,  1.9624, -0.2091],\n",
            "        [-1.8986,  0.2878,  1.1534],\n",
            "        [-1.7578,  2.0044, -0.1555],\n",
            "        [-1.6784,  0.9127,  0.6119],\n",
            "        [-0.6701,  0.4714,  0.0276],\n",
            "        [ 0.3275,  0.3538, -1.0149],\n",
            "        [ 0.4775, -0.0735, -0.9274],\n",
            "        [-1.8205,  0.4103,  1.1676],\n",
            "        [-1.7463,  1.9320, -0.3098],\n",
            "        [-2.1946,  0.8208,  0.9407],\n",
            "        [-1.9103,  2.0507, -0.1014],\n",
            "        [-1.6268,  1.8597, -0.2414]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8279,  1.9857, -0.2974],\n",
            "        [-2.0801,  1.9076, -0.1380],\n",
            "        [-1.0927,  1.6291, -0.5943],\n",
            "        [-1.8365,  1.9915, -0.1607],\n",
            "        [-1.8487,  1.9624, -0.2091],\n",
            "        [-1.8986,  0.2878,  1.1534],\n",
            "        [-1.7578,  2.0044, -0.1555],\n",
            "        [-1.6784,  0.9127,  0.6119],\n",
            "        [-0.6701,  0.4714,  0.0276],\n",
            "        [ 0.3275,  0.3538, -1.0149],\n",
            "        [ 0.4775, -0.0735, -0.9274],\n",
            "        [-1.8205,  0.4103,  1.1676],\n",
            "        [-1.7463,  1.9320, -0.3098],\n",
            "        [-2.1946,  0.8208,  0.9407],\n",
            "        [-1.9103,  2.0507, -0.1014],\n",
            "        [-1.6268,  1.8597, -0.2414]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0388e+00,  1.0728e+00,  7.9340e-01],\n",
            "        [-1.4539e+00,  1.0004e-02,  1.1918e+00],\n",
            "        [-1.9009e+00,  4.7413e-01,  1.1358e+00],\n",
            "        [-2.2065e+00,  2.1130e+00, -7.7575e-02],\n",
            "        [-1.7585e+00,  5.0874e-01,  9.7516e-01],\n",
            "        [-1.6437e+00, -1.1966e-05,  1.1165e+00],\n",
            "        [ 7.1616e-01, -1.2322e-01, -7.5012e-01],\n",
            "        [-1.7946e+00,  4.0875e-01,  1.1555e+00],\n",
            "        [-1.7019e+00,  1.9019e+00, -1.6133e-01],\n",
            "        [-2.1422e+00,  1.9547e+00,  1.1015e-01],\n",
            "        [-1.7902e+00,  1.9501e+00, -5.0211e-01],\n",
            "        [ 3.7349e-01,  1.4800e-01, -8.6248e-01],\n",
            "        [-2.0096e+00,  1.5265e+00,  3.2996e-01],\n",
            "        [-1.7811e+00,  4.8739e-01,  1.0496e+00],\n",
            "        [-2.0588e+00,  2.0116e+00, -3.5530e-01],\n",
            "        [-2.0061e+00,  2.1467e+00, -8.3223e-02]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0388e+00,  1.0728e+00,  7.9340e-01],\n",
            "        [-1.4539e+00,  1.0004e-02,  1.1918e+00],\n",
            "        [-1.9009e+00,  4.7413e-01,  1.1358e+00],\n",
            "        [-2.2065e+00,  2.1130e+00, -7.7575e-02],\n",
            "        [-1.7585e+00,  5.0874e-01,  9.7516e-01],\n",
            "        [-1.6437e+00, -1.1966e-05,  1.1165e+00],\n",
            "        [ 7.1616e-01, -1.2322e-01, -7.5012e-01],\n",
            "        [-1.7946e+00,  4.0875e-01,  1.1555e+00],\n",
            "        [-1.7019e+00,  1.9019e+00, -1.6133e-01],\n",
            "        [-2.1422e+00,  1.9547e+00,  1.1015e-01],\n",
            "        [-1.7902e+00,  1.9501e+00, -5.0211e-01],\n",
            "        [ 3.7349e-01,  1.4800e-01, -8.6248e-01],\n",
            "        [-2.0096e+00,  1.5265e+00,  3.2996e-01],\n",
            "        [-1.7811e+00,  4.8739e-01,  1.0496e+00],\n",
            "        [-2.0588e+00,  2.0116e+00, -3.5530e-01],\n",
            "        [-2.0061e+00,  2.1467e+00, -8.3223e-02]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5806,  0.0221, -0.9597],\n",
            "        [ 0.4003,  0.0712, -0.9199],\n",
            "        [-2.0314,  0.2000,  1.1166],\n",
            "        [-2.2018,  0.6254,  1.1223],\n",
            "        [-1.6982,  0.2416,  1.0703],\n",
            "        [-1.9643,  2.1376, -0.3440],\n",
            "        [-1.5122,  1.7228, -0.4589],\n",
            "        [-1.9314,  1.9469,  0.0346],\n",
            "        [ 0.1911,  0.3618, -0.8753],\n",
            "        [-1.7308,  1.9075, -0.3242],\n",
            "        [-1.8062,  1.7791, -0.0131],\n",
            "        [-1.7874,  1.7601, -0.2427],\n",
            "        [-2.3728,  1.4065,  0.6269],\n",
            "        [-1.8851,  1.7462, -0.0983],\n",
            "        [-2.1310,  0.2729,  1.2602],\n",
            "        [-1.6905,  1.8812, -0.1379]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.5806,  0.0221, -0.9597],\n",
            "        [ 0.4003,  0.0712, -0.9199],\n",
            "        [-2.0314,  0.2000,  1.1166],\n",
            "        [-2.2018,  0.6254,  1.1223],\n",
            "        [-1.6982,  0.2416,  1.0703],\n",
            "        [-1.9643,  2.1376, -0.3440],\n",
            "        [-1.5122,  1.7228, -0.4589],\n",
            "        [-1.9314,  1.9469,  0.0346],\n",
            "        [ 0.1911,  0.3618, -0.8753],\n",
            "        [-1.7308,  1.9075, -0.3242],\n",
            "        [-1.8062,  1.7791, -0.0131],\n",
            "        [-1.7874,  1.7601, -0.2427],\n",
            "        [-2.3728,  1.4065,  0.6269],\n",
            "        [-1.8851,  1.7462, -0.0983],\n",
            "        [-2.1310,  0.2729,  1.2602],\n",
            "        [-1.6905,  1.8812, -0.1379]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1033,  2.1409,  0.0359],\n",
            "        [-0.7506,  0.9531, -0.4982],\n",
            "        [-1.9322,  1.8228, -0.0079],\n",
            "        [-2.3090,  0.7984,  1.4036],\n",
            "        [ 0.6599, -0.1417, -0.7787],\n",
            "        [-1.3674,  1.4400, -0.3603],\n",
            "        [-1.8710,  0.4578,  1.3015],\n",
            "        [-2.0478,  1.9460,  0.0642],\n",
            "        [-1.8070,  1.8811, -0.1702],\n",
            "        [-0.7849,  0.5451, -0.0476],\n",
            "        [-2.0877,  2.0487,  0.1280],\n",
            "        [ 0.5784,  0.1368, -0.6619],\n",
            "        [-2.0919,  1.8102,  0.1177],\n",
            "        [-1.8314,  1.7714, -0.1927],\n",
            "        [ 0.5368,  0.0398, -1.0978],\n",
            "        [-1.4090,  1.8171, -0.0725]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1033,  2.1409,  0.0359],\n",
            "        [-0.7506,  0.9531, -0.4982],\n",
            "        [-1.9322,  1.8228, -0.0079],\n",
            "        [-2.3090,  0.7984,  1.4036],\n",
            "        [ 0.6599, -0.1417, -0.7787],\n",
            "        [-1.3674,  1.4400, -0.3603],\n",
            "        [-1.8710,  0.4578,  1.3015],\n",
            "        [-2.0478,  1.9460,  0.0642],\n",
            "        [-1.8070,  1.8811, -0.1702],\n",
            "        [-0.7849,  0.5451, -0.0476],\n",
            "        [-2.0877,  2.0487,  0.1280],\n",
            "        [ 0.5784,  0.1368, -0.6619],\n",
            "        [-2.0919,  1.8102,  0.1177],\n",
            "        [-1.8314,  1.7714, -0.1927],\n",
            "        [ 0.5368,  0.0398, -1.0978],\n",
            "        [-1.4090,  1.8171, -0.0725]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6939,  0.1158,  1.1838],\n",
            "        [-1.8216,  1.9027, -0.2193],\n",
            "        [-1.6249, -0.0549,  1.2068],\n",
            "        [-1.9235,  1.9204, -0.0116],\n",
            "        [-2.0690,  1.5191,  0.1612],\n",
            "        [-2.1277,  1.8087,  0.3343],\n",
            "        [-1.8385,  0.5172,  0.7381],\n",
            "        [-2.0105,  0.1977,  1.2735],\n",
            "        [ 0.5281, -0.0678, -0.9905],\n",
            "        [-1.6922,  1.8607, -0.3567],\n",
            "        [-1.5217, -0.1141,  1.3411],\n",
            "        [-2.0466,  1.9453,  0.0757],\n",
            "        [-1.8716,  1.8692,  0.0061],\n",
            "        [ 0.2473,  0.3033, -0.8771],\n",
            "        [-1.6401,  1.7091, -0.1087],\n",
            "        [ 0.5816,  0.0304, -0.7649]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6939,  0.1158,  1.1838],\n",
            "        [-1.8216,  1.9027, -0.2193],\n",
            "        [-1.6249, -0.0549,  1.2068],\n",
            "        [-1.9235,  1.9204, -0.0116],\n",
            "        [-2.0690,  1.5191,  0.1612],\n",
            "        [-2.1277,  1.8087,  0.3343],\n",
            "        [-1.8385,  0.5172,  0.7381],\n",
            "        [-2.0105,  0.1977,  1.2735],\n",
            "        [ 0.5281, -0.0678, -0.9905],\n",
            "        [-1.6922,  1.8607, -0.3567],\n",
            "        [-1.5217, -0.1141,  1.3411],\n",
            "        [-2.0466,  1.9453,  0.0757],\n",
            "        [-1.8716,  1.8692,  0.0061],\n",
            "        [ 0.2473,  0.3033, -0.8771],\n",
            "        [-1.6401,  1.7091, -0.1087],\n",
            "        [ 0.5816,  0.0304, -0.7649]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1409,  1.5472,  0.2009],\n",
            "        [ 0.2975,  0.0987, -0.7971],\n",
            "        [-2.0046,  0.4248,  1.2094],\n",
            "        [-1.1714,  1.3737, -0.4926],\n",
            "        [-1.4673,  1.7673, -0.2091],\n",
            "        [-1.8740,  1.8335, -0.0509],\n",
            "        [-2.0571,  1.9667,  0.1943],\n",
            "        [-1.9716,  0.4308,  1.2065],\n",
            "        [-1.7679,  1.6528, -0.0704],\n",
            "        [-0.6361,  1.0113, -0.5591],\n",
            "        [ 0.5161, -0.0299, -1.0043],\n",
            "        [-1.6463,  0.6808,  0.7744],\n",
            "        [-1.9951,  1.6743,  0.0552],\n",
            "        [ 0.6161, -0.1273, -0.8353],\n",
            "        [-1.8555,  1.8967, -0.2088],\n",
            "        [-1.8254,  1.9096, -0.0500]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1409,  1.5472,  0.2009],\n",
            "        [ 0.2975,  0.0987, -0.7971],\n",
            "        [-2.0046,  0.4248,  1.2094],\n",
            "        [-1.1714,  1.3737, -0.4926],\n",
            "        [-1.4673,  1.7673, -0.2091],\n",
            "        [-1.8740,  1.8335, -0.0509],\n",
            "        [-2.0571,  1.9667,  0.1943],\n",
            "        [-1.9716,  0.4308,  1.2065],\n",
            "        [-1.7679,  1.6528, -0.0704],\n",
            "        [-0.6361,  1.0113, -0.5591],\n",
            "        [ 0.5161, -0.0299, -1.0043],\n",
            "        [-1.6463,  0.6808,  0.7744],\n",
            "        [-1.9951,  1.6743,  0.0552],\n",
            "        [ 0.6161, -0.1273, -0.8353],\n",
            "        [-1.8555,  1.8967, -0.2088],\n",
            "        [-1.8254,  1.9096, -0.0500]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9986,  1.9892, -0.0401],\n",
            "        [-2.0546,  1.8604,  0.0294],\n",
            "        [-2.1170,  1.9269, -0.1032],\n",
            "        [-0.0488,  0.5116, -0.8600],\n",
            "        [-1.8008,  0.6259,  0.9415],\n",
            "        [-1.7673,  1.8669, -0.2276],\n",
            "        [-1.8233,  2.0263,  0.1019],\n",
            "        [-2.0224,  2.0370,  0.0346],\n",
            "        [-2.1376,  2.1673, -0.2032],\n",
            "        [ 0.3915, -0.0174, -0.7377],\n",
            "        [-1.9740,  2.1278, -0.0608],\n",
            "        [-1.8764,  1.6321, -0.1261],\n",
            "        [-1.5108,  1.2970,  0.0290],\n",
            "        [-2.0603,  2.0318,  0.0441],\n",
            "        [-1.8769,  1.8121, -0.0669],\n",
            "        [-2.0328,  0.5732,  1.1487]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9986,  1.9892, -0.0401],\n",
            "        [-2.0546,  1.8604,  0.0294],\n",
            "        [-2.1170,  1.9269, -0.1032],\n",
            "        [-0.0488,  0.5116, -0.8600],\n",
            "        [-1.8008,  0.6259,  0.9415],\n",
            "        [-1.7673,  1.8669, -0.2276],\n",
            "        [-1.8233,  2.0263,  0.1019],\n",
            "        [-2.0224,  2.0370,  0.0346],\n",
            "        [-2.1376,  2.1673, -0.2032],\n",
            "        [ 0.3915, -0.0174, -0.7377],\n",
            "        [-1.9740,  2.1278, -0.0608],\n",
            "        [-1.8764,  1.6321, -0.1261],\n",
            "        [-1.5108,  1.2970,  0.0290],\n",
            "        [-2.0603,  2.0318,  0.0441],\n",
            "        [-1.8769,  1.8121, -0.0669],\n",
            "        [-2.0328,  0.5732,  1.1487]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2429,  1.9614,  0.1404],\n",
            "        [-1.7766,  1.7295,  0.0293],\n",
            "        [-2.2854,  1.5669,  0.4702],\n",
            "        [-1.5702, -0.1204,  1.3506],\n",
            "        [-2.2436,  1.5027,  0.4552],\n",
            "        [-1.9607,  1.7375,  0.1340],\n",
            "        [-2.2638,  1.5732,  0.2601],\n",
            "        [-2.0281,  0.2873,  1.3472],\n",
            "        [-2.1977,  0.8094,  1.2240],\n",
            "        [-2.3911,  1.1915,  0.7232],\n",
            "        [-2.0322,  1.7049,  0.0798],\n",
            "        [ 0.3782,  0.0433, -0.7843],\n",
            "        [-2.2657,  2.0306, -0.0386],\n",
            "        [-0.1154,  0.0572, -0.3321],\n",
            "        [ 0.2114,  0.0765, -0.8176],\n",
            "        [-2.3311,  1.9211,  0.1678]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.2429,  1.9614,  0.1404],\n",
            "        [-1.7766,  1.7295,  0.0293],\n",
            "        [-2.2854,  1.5669,  0.4702],\n",
            "        [-1.5702, -0.1204,  1.3506],\n",
            "        [-2.2436,  1.5027,  0.4552],\n",
            "        [-1.9607,  1.7375,  0.1340],\n",
            "        [-2.2638,  1.5732,  0.2601],\n",
            "        [-2.0281,  0.2873,  1.3472],\n",
            "        [-2.1977,  0.8094,  1.2240],\n",
            "        [-2.3911,  1.1915,  0.7232],\n",
            "        [-2.0322,  1.7049,  0.0798],\n",
            "        [ 0.3782,  0.0433, -0.7843],\n",
            "        [-2.2657,  2.0306, -0.0386],\n",
            "        [-0.1154,  0.0572, -0.3321],\n",
            "        [ 0.2114,  0.0765, -0.8176],\n",
            "        [-2.3311,  1.9211,  0.1678]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9879,  0.3601,  1.2459],\n",
            "        [-2.0899,  1.5898,  0.2870],\n",
            "        [-1.7409,  0.3856,  1.2300],\n",
            "        [-0.4615,  0.3539, -0.5364],\n",
            "        [-1.0700,  0.5692,  0.3435],\n",
            "        [-1.5005,  0.7350,  0.5259],\n",
            "        [-2.2444,  1.6210,  0.0534],\n",
            "        [-1.6915,  0.5293,  0.9911],\n",
            "        [-2.0955,  1.7662, -0.1679],\n",
            "        [-2.1602,  1.9549,  0.0625],\n",
            "        [-2.3003,  0.6487,  1.3337],\n",
            "        [ 0.3956,  0.0258, -0.6257],\n",
            "        [-2.1501,  1.5451,  0.2912],\n",
            "        [ 0.5523, -0.1414, -0.6962],\n",
            "        [-1.2506,  1.2559, -0.3018],\n",
            "        [ 0.3406,  0.0046, -0.8321]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9879,  0.3601,  1.2459],\n",
            "        [-2.0899,  1.5898,  0.2870],\n",
            "        [-1.7409,  0.3856,  1.2300],\n",
            "        [-0.4615,  0.3539, -0.5364],\n",
            "        [-1.0700,  0.5692,  0.3435],\n",
            "        [-1.5005,  0.7350,  0.5259],\n",
            "        [-2.2444,  1.6210,  0.0534],\n",
            "        [-1.6915,  0.5293,  0.9911],\n",
            "        [-2.0955,  1.7662, -0.1679],\n",
            "        [-2.1602,  1.9549,  0.0625],\n",
            "        [-2.3003,  0.6487,  1.3337],\n",
            "        [ 0.3956,  0.0258, -0.6257],\n",
            "        [-2.1501,  1.5451,  0.2912],\n",
            "        [ 0.5523, -0.1414, -0.6962],\n",
            "        [-1.2506,  1.2559, -0.3018],\n",
            "        [ 0.3406,  0.0046, -0.8321]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9524,  0.4004,  1.1391],\n",
            "        [-2.1815,  0.8654,  1.1246],\n",
            "        [-2.0985,  1.8226,  0.3026],\n",
            "        [-1.9281,  1.5126, -0.1114],\n",
            "        [-1.9253,  1.4716,  0.0805],\n",
            "        [-2.3453,  1.8988,  0.0808],\n",
            "        [ 0.4987, -0.0051, -0.6302],\n",
            "        [-2.2792,  1.5851,  0.1037],\n",
            "        [-1.8387,  1.9276, -0.2637],\n",
            "        [-2.1941,  1.7888,  0.0851],\n",
            "        [-2.1824,  1.9362,  0.1904],\n",
            "        [-2.1550,  1.8435, -0.0096],\n",
            "        [-1.5949, -0.1857,  1.3051],\n",
            "        [-2.2723,  1.7165,  0.2818],\n",
            "        [-1.7280, -0.0708,  1.3021],\n",
            "        [-2.0832,  1.6110, -0.1172]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9524,  0.4004,  1.1391],\n",
            "        [-2.1815,  0.8654,  1.1246],\n",
            "        [-2.0985,  1.8226,  0.3026],\n",
            "        [-1.9281,  1.5126, -0.1114],\n",
            "        [-1.9253,  1.4716,  0.0805],\n",
            "        [-2.3453,  1.8988,  0.0808],\n",
            "        [ 0.4987, -0.0051, -0.6302],\n",
            "        [-2.2792,  1.5851,  0.1037],\n",
            "        [-1.8387,  1.9276, -0.2637],\n",
            "        [-2.1941,  1.7888,  0.0851],\n",
            "        [-2.1824,  1.9362,  0.1904],\n",
            "        [-2.1550,  1.8435, -0.0096],\n",
            "        [-1.5949, -0.1857,  1.3051],\n",
            "        [-2.2723,  1.7165,  0.2818],\n",
            "        [-1.7280, -0.0708,  1.3021],\n",
            "        [-2.0832,  1.6110, -0.1172]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9827,  1.7538, -0.0169],\n",
            "        [ 0.5003, -0.1890, -0.6232],\n",
            "        [-2.4823,  1.1385,  0.9052],\n",
            "        [-2.2339,  1.9621,  0.0877],\n",
            "        [-1.9878, -0.0385,  1.3451],\n",
            "        [-1.8909,  1.6778,  0.2908],\n",
            "        [-1.7586,  1.4903,  0.1697],\n",
            "        [-2.2393,  1.9862,  0.2403],\n",
            "        [-1.8787,  1.7773,  0.1327],\n",
            "        [-2.1942,  1.8776,  0.1235],\n",
            "        [-1.7314,  1.6989, -0.0405],\n",
            "        [ 0.3638, -0.2842, -0.6592],\n",
            "        [ 0.2932,  0.0637, -0.6743],\n",
            "        [-1.6009,  0.3315,  0.9690],\n",
            "        [-1.5229,  0.1758,  0.9395],\n",
            "        [-0.5025, -0.0148,  0.3643]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9827,  1.7538, -0.0169],\n",
            "        [ 0.5003, -0.1890, -0.6232],\n",
            "        [-2.4823,  1.1385,  0.9052],\n",
            "        [-2.2339,  1.9621,  0.0877],\n",
            "        [-1.9878, -0.0385,  1.3451],\n",
            "        [-1.8909,  1.6778,  0.2908],\n",
            "        [-1.7586,  1.4903,  0.1697],\n",
            "        [-2.2393,  1.9862,  0.2403],\n",
            "        [-1.8787,  1.7773,  0.1327],\n",
            "        [-2.1942,  1.8776,  0.1235],\n",
            "        [-1.7314,  1.6989, -0.0405],\n",
            "        [ 0.3638, -0.2842, -0.6592],\n",
            "        [ 0.2932,  0.0637, -0.6743],\n",
            "        [-1.6009,  0.3315,  0.9690],\n",
            "        [-1.5229,  0.1758,  0.9395],\n",
            "        [-0.5025, -0.0148,  0.3643]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2578,  1.7243,  0.0671],\n",
            "        [-2.1748,  1.2107,  0.5614],\n",
            "        [-2.1959,  1.4926,  0.5417],\n",
            "        [-1.8145,  1.2943,  0.1614],\n",
            "        [-1.9308,  1.8557,  0.0608],\n",
            "        [-1.7417,  0.3074,  1.2116],\n",
            "        [-1.0098,  0.3557,  0.3407],\n",
            "        [-2.2339,  0.3379,  1.4817],\n",
            "        [-2.2410,  1.7564,  0.0820],\n",
            "        [-1.7643,  1.5932, -0.3065],\n",
            "        [-1.8952,  1.4384, -0.0115],\n",
            "        [ 0.3581, -0.1806, -0.8143],\n",
            "        [-2.1424,  1.7808,  0.2295],\n",
            "        [-1.8574,  0.2481,  1.3264],\n",
            "        [-1.9296,  1.9931, -0.0256],\n",
            "        [-1.8751,  0.0097,  1.4562]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.2578,  1.7243,  0.0671],\n",
            "        [-2.1748,  1.2107,  0.5614],\n",
            "        [-2.1959,  1.4926,  0.5417],\n",
            "        [-1.8145,  1.2943,  0.1614],\n",
            "        [-1.9308,  1.8557,  0.0608],\n",
            "        [-1.7417,  0.3074,  1.2116],\n",
            "        [-1.0098,  0.3557,  0.3407],\n",
            "        [-2.2339,  0.3379,  1.4817],\n",
            "        [-2.2410,  1.7564,  0.0820],\n",
            "        [-1.7643,  1.5932, -0.3065],\n",
            "        [-1.8952,  1.4384, -0.0115],\n",
            "        [ 0.3581, -0.1806, -0.8143],\n",
            "        [-2.1424,  1.7808,  0.2295],\n",
            "        [-1.8574,  0.2481,  1.3264],\n",
            "        [-1.9296,  1.9931, -0.0256],\n",
            "        [-1.8751,  0.0097,  1.4562]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 1.8550e-01, -6.6454e-02, -4.0802e-01],\n",
            "        [-2.3452e+00,  1.8774e+00,  2.7355e-01],\n",
            "        [-2.2182e+00,  6.7701e-01,  1.3160e+00],\n",
            "        [-2.0088e+00,  3.4774e-01,  1.2738e+00],\n",
            "        [-2.2997e+00,  1.9197e+00,  4.0437e-01],\n",
            "        [-1.9742e+00,  4.8095e-01,  1.4711e+00],\n",
            "        [-2.2824e+00,  6.9714e-01,  8.8607e-01],\n",
            "        [-1.7714e+00,  1.2956e-03,  1.4237e+00],\n",
            "        [-2.2842e+00,  1.5973e+00,  2.6539e-01],\n",
            "        [ 4.7060e-01, -6.1313e-02, -6.1803e-01],\n",
            "        [-1.8425e+00,  1.7588e+00,  1.7532e-01],\n",
            "        [-1.9967e+00,  1.6791e+00,  8.1486e-02],\n",
            "        [-2.2253e+00,  8.7285e-01,  1.2634e+00],\n",
            "        [-2.3670e+00,  1.1510e+00,  6.0493e-01],\n",
            "        [-2.2300e+00,  1.6938e+00,  2.0844e-01],\n",
            "        [ 2.0146e-01,  1.1447e-01, -7.7836e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 1.8550e-01, -6.6454e-02, -4.0802e-01],\n",
            "        [-2.3452e+00,  1.8774e+00,  2.7355e-01],\n",
            "        [-2.2182e+00,  6.7701e-01,  1.3160e+00],\n",
            "        [-2.0088e+00,  3.4774e-01,  1.2738e+00],\n",
            "        [-2.2997e+00,  1.9197e+00,  4.0437e-01],\n",
            "        [-1.9742e+00,  4.8095e-01,  1.4711e+00],\n",
            "        [-2.2824e+00,  6.9714e-01,  8.8607e-01],\n",
            "        [-1.7714e+00,  1.2956e-03,  1.4237e+00],\n",
            "        [-2.2842e+00,  1.5973e+00,  2.6539e-01],\n",
            "        [ 4.7060e-01, -6.1313e-02, -6.1803e-01],\n",
            "        [-1.8425e+00,  1.7588e+00,  1.7532e-01],\n",
            "        [-1.9967e+00,  1.6791e+00,  8.1486e-02],\n",
            "        [-2.2253e+00,  8.7285e-01,  1.2634e+00],\n",
            "        [-2.3670e+00,  1.1510e+00,  6.0493e-01],\n",
            "        [-2.2300e+00,  1.6938e+00,  2.0844e-01],\n",
            "        [ 2.0146e-01,  1.1447e-01, -7.7836e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1683e+00,  1.7596e-01,  1.3482e+00],\n",
            "        [-3.0844e-01, -7.4550e-03,  3.3931e-02],\n",
            "        [-1.9840e+00,  8.0633e-01,  8.8481e-01],\n",
            "        [-1.9342e+00,  1.7138e+00,  1.3777e-01],\n",
            "        [-2.2205e+00,  1.5264e+00,  5.9592e-01],\n",
            "        [-1.8981e+00,  1.2304e-02,  1.4844e+00],\n",
            "        [-1.9341e+00,  1.4548e+00,  2.9653e-01],\n",
            "        [-1.9298e+00,  1.2402e-01,  1.1993e+00],\n",
            "        [-1.6865e+00,  1.6469e+00, -6.9512e-02],\n",
            "        [-1.8857e+00,  1.7035e+00, -3.4553e-04],\n",
            "        [-2.2346e+00,  1.9992e+00, -2.9898e-02],\n",
            "        [ 4.4297e-01, -9.5890e-02, -5.5328e-01],\n",
            "        [-2.0639e+00,  4.5922e-01,  1.2944e+00],\n",
            "        [-1.8733e+00,  7.8179e-03,  1.5865e+00],\n",
            "        [-2.1405e+00,  1.1458e+00,  1.0892e+00],\n",
            "        [-1.9925e+00,  8.2877e-01,  8.0980e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1683e+00,  1.7596e-01,  1.3482e+00],\n",
            "        [-3.0844e-01, -7.4550e-03,  3.3931e-02],\n",
            "        [-1.9840e+00,  8.0633e-01,  8.8481e-01],\n",
            "        [-1.9342e+00,  1.7138e+00,  1.3777e-01],\n",
            "        [-2.2205e+00,  1.5264e+00,  5.9592e-01],\n",
            "        [-1.8981e+00,  1.2304e-02,  1.4844e+00],\n",
            "        [-1.9341e+00,  1.4548e+00,  2.9653e-01],\n",
            "        [-1.9298e+00,  1.2402e-01,  1.1993e+00],\n",
            "        [-1.6865e+00,  1.6469e+00, -6.9512e-02],\n",
            "        [-1.8857e+00,  1.7035e+00, -3.4553e-04],\n",
            "        [-2.2346e+00,  1.9992e+00, -2.9898e-02],\n",
            "        [ 4.4297e-01, -9.5890e-02, -5.5328e-01],\n",
            "        [-2.0639e+00,  4.5922e-01,  1.2944e+00],\n",
            "        [-1.8733e+00,  7.8179e-03,  1.5865e+00],\n",
            "        [-2.1405e+00,  1.1458e+00,  1.0892e+00],\n",
            "        [-1.9925e+00,  8.2877e-01,  8.0980e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.4071, -0.0584,  0.1550],\n",
            "        [-0.3623,  0.7068, -0.8859],\n",
            "        [-2.3095,  0.4446,  1.3430],\n",
            "        [-0.0716,  0.2316, -0.4129],\n",
            "        [-2.2325,  1.7076,  0.3211],\n",
            "        [-2.0347,  1.7504, -0.1966],\n",
            "        [-2.0991,  1.7922,  0.0904],\n",
            "        [-1.8346,  0.3604,  1.2811],\n",
            "        [-1.1536,  1.2716, -0.3680],\n",
            "        [-2.3599,  1.8179,  0.0844],\n",
            "        [-2.0132,  0.3440,  1.3561],\n",
            "        [-1.5066,  1.5607, -0.1114],\n",
            "        [ 0.4046, -0.1341, -0.7614],\n",
            "        [-1.4870,  0.8783,  0.4010],\n",
            "        [-1.7100,  0.0316,  1.3478],\n",
            "        [-1.8823,  1.7258,  0.0600]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-0.4071, -0.0584,  0.1550],\n",
            "        [-0.3623,  0.7068, -0.8859],\n",
            "        [-2.3095,  0.4446,  1.3430],\n",
            "        [-0.0716,  0.2316, -0.4129],\n",
            "        [-2.2325,  1.7076,  0.3211],\n",
            "        [-2.0347,  1.7504, -0.1966],\n",
            "        [-2.0991,  1.7922,  0.0904],\n",
            "        [-1.8346,  0.3604,  1.2811],\n",
            "        [-1.1536,  1.2716, -0.3680],\n",
            "        [-2.3599,  1.8179,  0.0844],\n",
            "        [-2.0132,  0.3440,  1.3561],\n",
            "        [-1.5066,  1.5607, -0.1114],\n",
            "        [ 0.4046, -0.1341, -0.7614],\n",
            "        [-1.4870,  0.8783,  0.4010],\n",
            "        [-1.7100,  0.0316,  1.3478],\n",
            "        [-1.8823,  1.7258,  0.0600]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1940,  0.9678,  0.8905],\n",
            "        [-2.3988,  1.1978,  0.8125],\n",
            "        [-1.5627,  0.1567,  1.0047],\n",
            "        [-1.8386,  1.7623,  0.3003],\n",
            "        [-2.0199,  0.0114,  1.2929],\n",
            "        [ 0.3544, -0.1047, -0.5480],\n",
            "        [-1.9406,  1.8089, -0.0545],\n",
            "        [-1.8423,  0.0801,  1.3246],\n",
            "        [ 0.3617, -0.1898, -0.5609],\n",
            "        [-2.5776,  1.4888,  0.8690],\n",
            "        [-0.9759,  1.2395, -0.4509],\n",
            "        [-1.8985,  0.2619,  1.1281],\n",
            "        [-1.9680,  1.7949,  0.1556],\n",
            "        [-1.9239,  0.2211,  1.3188],\n",
            "        [-1.9134,  0.2684,  1.2422],\n",
            "        [-2.1184,  0.7554,  0.9817]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1940,  0.9678,  0.8905],\n",
            "        [-2.3988,  1.1978,  0.8125],\n",
            "        [-1.5627,  0.1567,  1.0047],\n",
            "        [-1.8386,  1.7623,  0.3003],\n",
            "        [-2.0199,  0.0114,  1.2929],\n",
            "        [ 0.3544, -0.1047, -0.5480],\n",
            "        [-1.9406,  1.8089, -0.0545],\n",
            "        [-1.8423,  0.0801,  1.3246],\n",
            "        [ 0.3617, -0.1898, -0.5609],\n",
            "        [-2.5776,  1.4888,  0.8690],\n",
            "        [-0.9759,  1.2395, -0.4509],\n",
            "        [-1.8985,  0.2619,  1.1281],\n",
            "        [-1.9680,  1.7949,  0.1556],\n",
            "        [-1.9239,  0.2211,  1.3188],\n",
            "        [-1.9134,  0.2684,  1.2422],\n",
            "        [-2.1184,  0.7554,  0.9817]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.3614,  1.1380,  1.0301],\n",
            "        [ 0.4110, -0.1803, -0.3939],\n",
            "        [-2.2228,  1.5175,  0.5413],\n",
            "        [-1.3929,  1.7136, -0.3633],\n",
            "        [-2.1800,  0.9457,  0.9585],\n",
            "        [-2.0276,  0.5464,  1.1645],\n",
            "        [-2.0455,  1.8832,  0.0643],\n",
            "        [-0.5774,  0.8598, -0.8602],\n",
            "        [-2.1465,  1.9067,  0.0156],\n",
            "        [-2.2301,  1.0629,  1.2173],\n",
            "        [ 0.2639,  0.0082, -0.5808],\n",
            "        [-1.5646,  0.1184,  1.1207],\n",
            "        [-2.0399,  0.5422,  1.3090],\n",
            "        [-1.9191,  1.9304, -0.0533],\n",
            "        [-1.9114,  1.8515, -0.0068],\n",
            "        [-1.7856,  1.5590, -0.0460]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.3614,  1.1380,  1.0301],\n",
            "        [ 0.4110, -0.1803, -0.3939],\n",
            "        [-2.2228,  1.5175,  0.5413],\n",
            "        [-1.3929,  1.7136, -0.3633],\n",
            "        [-2.1800,  0.9457,  0.9585],\n",
            "        [-2.0276,  0.5464,  1.1645],\n",
            "        [-2.0455,  1.8832,  0.0643],\n",
            "        [-0.5774,  0.8598, -0.8602],\n",
            "        [-2.1465,  1.9067,  0.0156],\n",
            "        [-2.2301,  1.0629,  1.2173],\n",
            "        [ 0.2639,  0.0082, -0.5808],\n",
            "        [-1.5646,  0.1184,  1.1207],\n",
            "        [-2.0399,  0.5422,  1.3090],\n",
            "        [-1.9191,  1.9304, -0.0533],\n",
            "        [-1.9114,  1.8515, -0.0068],\n",
            "        [-1.7856,  1.5590, -0.0460]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1384,  1.7499,  0.1229],\n",
            "        [-0.3868,  0.0195,  0.0995],\n",
            "        [-1.5003,  0.0654,  1.2575],\n",
            "        [-2.1200,  1.6607,  0.2727],\n",
            "        [-2.1375,  1.8108,  0.0888],\n",
            "        [-1.2767,  0.3778,  0.8539],\n",
            "        [-1.9883,  1.4429, -0.0473],\n",
            "        [-1.9132,  0.3411,  1.3088],\n",
            "        [ 0.3115,  0.0916, -0.7521],\n",
            "        [ 0.3214,  0.0421, -0.7095],\n",
            "        [-1.7365,  0.1405,  1.3313],\n",
            "        [-1.8219,  2.0185,  0.0314],\n",
            "        [-1.7574,  1.7531, -0.0812],\n",
            "        [-1.8857,  0.4573,  1.1570],\n",
            "        [-2.0843,  1.4320,  0.4892],\n",
            "        [-2.2087,  1.8138, -0.0059]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1384,  1.7499,  0.1229],\n",
            "        [-0.3868,  0.0195,  0.0995],\n",
            "        [-1.5003,  0.0654,  1.2575],\n",
            "        [-2.1200,  1.6607,  0.2727],\n",
            "        [-2.1375,  1.8108,  0.0888],\n",
            "        [-1.2767,  0.3778,  0.8539],\n",
            "        [-1.9883,  1.4429, -0.0473],\n",
            "        [-1.9132,  0.3411,  1.3088],\n",
            "        [ 0.3115,  0.0916, -0.7521],\n",
            "        [ 0.3214,  0.0421, -0.7095],\n",
            "        [-1.7365,  0.1405,  1.3313],\n",
            "        [-1.8219,  2.0185,  0.0314],\n",
            "        [-1.7574,  1.7531, -0.0812],\n",
            "        [-1.8857,  0.4573,  1.1570],\n",
            "        [-2.0843,  1.4320,  0.4892],\n",
            "        [-2.2087,  1.8138, -0.0059]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0240,  0.5834,  1.1283],\n",
            "        [-1.7183,  0.1488,  1.2269],\n",
            "        [-2.0897,  1.7379,  0.1642],\n",
            "        [-2.2035,  0.7779,  1.0803],\n",
            "        [-2.0807,  1.6935, -0.0776],\n",
            "        [-1.6213,  0.2046,  1.3093],\n",
            "        [ 0.1707,  0.0140, -0.5242],\n",
            "        [-1.8224,  1.4902,  0.2507],\n",
            "        [-1.6947,  1.9286,  0.1757],\n",
            "        [-2.4373,  2.1449, -0.0732],\n",
            "        [-1.9168,  1.6835,  0.1190],\n",
            "        [-0.2636,  0.6146, -0.6983],\n",
            "        [-1.8572,  1.9584,  0.0559],\n",
            "        [-1.8726,  1.9005, -0.0672],\n",
            "        [-2.1811,  0.2137,  1.2652],\n",
            "        [-0.7078,  0.5874, -0.1122]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0240,  0.5834,  1.1283],\n",
            "        [-1.7183,  0.1488,  1.2269],\n",
            "        [-2.0897,  1.7379,  0.1642],\n",
            "        [-2.2035,  0.7779,  1.0803],\n",
            "        [-2.0807,  1.6935, -0.0776],\n",
            "        [-1.6213,  0.2046,  1.3093],\n",
            "        [ 0.1707,  0.0140, -0.5242],\n",
            "        [-1.8224,  1.4902,  0.2507],\n",
            "        [-1.6947,  1.9286,  0.1757],\n",
            "        [-2.4373,  2.1449, -0.0732],\n",
            "        [-1.9168,  1.6835,  0.1190],\n",
            "        [-0.2636,  0.6146, -0.6983],\n",
            "        [-1.8572,  1.9584,  0.0559],\n",
            "        [-1.8726,  1.9005, -0.0672],\n",
            "        [-2.1811,  0.2137,  1.2652],\n",
            "        [-0.7078,  0.5874, -0.1122]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6439,  0.3138,  1.2551],\n",
            "        [-1.6702,  1.5267, -0.3727],\n",
            "        [-2.0169,  0.7118,  0.8616],\n",
            "        [-1.7934,  1.8505, -0.1025],\n",
            "        [-2.2947,  1.1398,  0.7626],\n",
            "        [-2.2112,  2.1920, -0.1253],\n",
            "        [ 0.2009, -0.0256, -0.5132],\n",
            "        [-2.1766,  1.6477,  0.2479],\n",
            "        [-2.4674,  1.4888,  0.6668],\n",
            "        [-1.9279,  2.0197, -0.1968],\n",
            "        [-2.1702,  2.1130, -0.1999],\n",
            "        [ 0.3988, -0.2165, -0.5653],\n",
            "        [-1.6635,  1.8969, -0.2454],\n",
            "        [-1.7774,  1.6064, -0.2258],\n",
            "        [-2.2335,  1.6717,  0.0502],\n",
            "        [-2.0220,  1.7896, -0.0185]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6439,  0.3138,  1.2551],\n",
            "        [-1.6702,  1.5267, -0.3727],\n",
            "        [-2.0169,  0.7118,  0.8616],\n",
            "        [-1.7934,  1.8505, -0.1025],\n",
            "        [-2.2947,  1.1398,  0.7626],\n",
            "        [-2.2112,  2.1920, -0.1253],\n",
            "        [ 0.2009, -0.0256, -0.5132],\n",
            "        [-2.1766,  1.6477,  0.2479],\n",
            "        [-2.4674,  1.4888,  0.6668],\n",
            "        [-1.9279,  2.0197, -0.1968],\n",
            "        [-2.1702,  2.1130, -0.1999],\n",
            "        [ 0.3988, -0.2165, -0.5653],\n",
            "        [-1.6635,  1.8969, -0.2454],\n",
            "        [-1.7774,  1.6064, -0.2258],\n",
            "        [-2.2335,  1.6717,  0.0502],\n",
            "        [-2.0220,  1.7896, -0.0185]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7549,  0.7328,  0.4039],\n",
            "        [ 0.2895, -0.0801, -0.5515],\n",
            "        [-1.9835,  2.0172, -0.0486],\n",
            "        [-1.7308,  1.7772, -0.2612],\n",
            "        [-1.8490,  1.8546, -0.1503],\n",
            "        [-1.9326,  1.9569, -0.1776],\n",
            "        [-1.5144,  1.6662, -0.4058],\n",
            "        [-1.9684,  1.9657, -0.0482],\n",
            "        [ 0.3548, -0.1471, -0.7216],\n",
            "        [ 0.2574,  0.0077, -0.6658],\n",
            "        [-1.8839,  2.0874, -0.3498],\n",
            "        [-1.8929,  2.1075, -0.1763],\n",
            "        [-2.4657,  1.3390,  0.9454],\n",
            "        [-1.7176,  1.7948, -0.2376],\n",
            "        [-1.8821,  1.6426, -0.0597],\n",
            "        [-1.8487,  0.5825,  1.1267]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7549,  0.7328,  0.4039],\n",
            "        [ 0.2895, -0.0801, -0.5515],\n",
            "        [-1.9835,  2.0172, -0.0486],\n",
            "        [-1.7308,  1.7772, -0.2612],\n",
            "        [-1.8490,  1.8546, -0.1503],\n",
            "        [-1.9326,  1.9569, -0.1776],\n",
            "        [-1.5144,  1.6662, -0.4058],\n",
            "        [-1.9684,  1.9657, -0.0482],\n",
            "        [ 0.3548, -0.1471, -0.7216],\n",
            "        [ 0.2574,  0.0077, -0.6658],\n",
            "        [-1.8839,  2.0874, -0.3498],\n",
            "        [-1.8929,  2.1075, -0.1763],\n",
            "        [-2.4657,  1.3390,  0.9454],\n",
            "        [-1.7176,  1.7948, -0.2376],\n",
            "        [-1.8821,  1.6426, -0.0597],\n",
            "        [-1.8487,  0.5825,  1.1267]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.2826,  0.1501, -0.8328],\n",
            "        [ 0.2755,  0.0087, -0.6638],\n",
            "        [-2.0299,  1.8631, -0.1432],\n",
            "        [-2.0139,  1.9577, -0.2332],\n",
            "        [-1.9429,  1.8388, -0.1134],\n",
            "        [-2.0182,  1.7790, -0.2344],\n",
            "        [-1.9457,  1.9980, -0.0561],\n",
            "        [-1.8038,  1.7324, -0.3496],\n",
            "        [-1.9849,  1.9060, -0.1028],\n",
            "        [ 0.0825,  0.1639, -0.5873],\n",
            "        [ 0.2449,  0.0213, -0.7051],\n",
            "        [-1.3982,  1.3944, -0.5707],\n",
            "        [-2.3346,  1.3084,  0.7468],\n",
            "        [-1.9931,  1.5528,  0.0134],\n",
            "        [-1.7922,  1.8609, -0.1935],\n",
            "        [-1.8100,  0.5899,  0.8082]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.2826,  0.1501, -0.8328],\n",
            "        [ 0.2755,  0.0087, -0.6638],\n",
            "        [-2.0299,  1.8631, -0.1432],\n",
            "        [-2.0139,  1.9577, -0.2332],\n",
            "        [-1.9429,  1.8388, -0.1134],\n",
            "        [-2.0182,  1.7790, -0.2344],\n",
            "        [-1.9457,  1.9980, -0.0561],\n",
            "        [-1.8038,  1.7324, -0.3496],\n",
            "        [-1.9849,  1.9060, -0.1028],\n",
            "        [ 0.0825,  0.1639, -0.5873],\n",
            "        [ 0.2449,  0.0213, -0.7051],\n",
            "        [-1.3982,  1.3944, -0.5707],\n",
            "        [-2.3346,  1.3084,  0.7468],\n",
            "        [-1.9931,  1.5528,  0.0134],\n",
            "        [-1.7922,  1.8609, -0.1935],\n",
            "        [-1.8100,  0.5899,  0.8082]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7501,  0.6862,  0.7280],\n",
            "        [-1.9211,  1.9553, -0.2012],\n",
            "        [-2.0001,  1.9428, -0.2515],\n",
            "        [-1.8213,  1.9829, -0.2607],\n",
            "        [-2.2371,  1.4698,  0.4496],\n",
            "        [-1.6691,  0.5143,  0.9057],\n",
            "        [-2.3334,  1.1120,  0.8973],\n",
            "        [-1.5597,  0.5505,  0.7185],\n",
            "        [-1.9727,  1.6849,  0.2625],\n",
            "        [-2.3728,  0.9357,  0.9793],\n",
            "        [-2.1159,  0.4489,  1.1196],\n",
            "        [-1.7320,  0.4637,  1.1406],\n",
            "        [-2.0510,  1.9693, -0.2150],\n",
            "        [-2.4250,  0.8491,  1.0057],\n",
            "        [-2.0708,  1.8928, -0.2013],\n",
            "        [-1.8983,  1.9538, -0.1508]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7501,  0.6862,  0.7280],\n",
            "        [-1.9211,  1.9553, -0.2012],\n",
            "        [-2.0001,  1.9428, -0.2515],\n",
            "        [-1.8213,  1.9829, -0.2607],\n",
            "        [-2.2371,  1.4698,  0.4496],\n",
            "        [-1.6691,  0.5143,  0.9057],\n",
            "        [-2.3334,  1.1120,  0.8973],\n",
            "        [-1.5597,  0.5505,  0.7185],\n",
            "        [-1.9727,  1.6849,  0.2625],\n",
            "        [-2.3728,  0.9357,  0.9793],\n",
            "        [-2.1159,  0.4489,  1.1196],\n",
            "        [-1.7320,  0.4637,  1.1406],\n",
            "        [-2.0510,  1.9693, -0.2150],\n",
            "        [-2.4250,  0.8491,  1.0057],\n",
            "        [-2.0708,  1.8928, -0.2013],\n",
            "        [-1.8983,  1.9538, -0.1508]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3327, -0.2144, -0.4604],\n",
            "        [-1.6136,  0.5918,  0.7576],\n",
            "        [-1.8637,  1.9608, -0.2252],\n",
            "        [-2.0785,  1.1700,  0.7060],\n",
            "        [ 0.4138, -0.1601, -0.7234],\n",
            "        [-2.0009,  0.6500,  1.0588],\n",
            "        [-2.1772,  1.2035,  0.8171],\n",
            "        [-1.9312,  2.0248, -0.1438],\n",
            "        [-2.1799,  1.0886,  1.0407],\n",
            "        [ 0.3216, -0.0735, -0.6430],\n",
            "        [-1.7455,  1.8386, -0.4077],\n",
            "        [-1.9492,  1.9423,  0.0341],\n",
            "        [-1.9112,  0.5874,  1.1702],\n",
            "        [-1.9190,  2.0275,  0.0036],\n",
            "        [-1.9467,  2.0114, -0.1583],\n",
            "        [-1.9342,  1.9379, -0.2027]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.3327, -0.2144, -0.4604],\n",
            "        [-1.6136,  0.5918,  0.7576],\n",
            "        [-1.8637,  1.9608, -0.2252],\n",
            "        [-2.0785,  1.1700,  0.7060],\n",
            "        [ 0.4138, -0.1601, -0.7234],\n",
            "        [-2.0009,  0.6500,  1.0588],\n",
            "        [-2.1772,  1.2035,  0.8171],\n",
            "        [-1.9312,  2.0248, -0.1438],\n",
            "        [-2.1799,  1.0886,  1.0407],\n",
            "        [ 0.3216, -0.0735, -0.6430],\n",
            "        [-1.7455,  1.8386, -0.4077],\n",
            "        [-1.9492,  1.9423,  0.0341],\n",
            "        [-1.9112,  0.5874,  1.1702],\n",
            "        [-1.9190,  2.0275,  0.0036],\n",
            "        [-1.9467,  2.0114, -0.1583],\n",
            "        [-1.9342,  1.9379, -0.2027]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3383, -0.1208, -0.5647],\n",
            "        [-1.9975,  0.5015,  1.2948],\n",
            "        [-1.9234,  1.9467, -0.0901],\n",
            "        [-1.5901,  1.7964, -0.7084],\n",
            "        [ 0.1963,  0.0539, -0.6886],\n",
            "        [ 0.3228,  0.0457, -0.7744],\n",
            "        [-2.0107,  0.7829,  1.1400],\n",
            "        [-2.2657,  0.8365,  0.8401],\n",
            "        [ 0.2290, -0.0478, -0.2443],\n",
            "        [-1.9262,  2.0177, -0.1345],\n",
            "        [-1.8076,  1.8180, -0.2609],\n",
            "        [-1.7220,  1.5027, -0.1744],\n",
            "        [-1.9109,  0.7208,  0.8693],\n",
            "        [-2.1894,  1.7405,  0.2135],\n",
            "        [-1.9404,  0.3486,  1.2165],\n",
            "        [ 0.3332, -0.0453, -0.6760]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.3383, -0.1208, -0.5647],\n",
            "        [-1.9975,  0.5015,  1.2948],\n",
            "        [-1.9234,  1.9467, -0.0901],\n",
            "        [-1.5901,  1.7964, -0.7084],\n",
            "        [ 0.1963,  0.0539, -0.6886],\n",
            "        [ 0.3228,  0.0457, -0.7744],\n",
            "        [-2.0107,  0.7829,  1.1400],\n",
            "        [-2.2657,  0.8365,  0.8401],\n",
            "        [ 0.2290, -0.0478, -0.2443],\n",
            "        [-1.9262,  2.0177, -0.1345],\n",
            "        [-1.8076,  1.8180, -0.2609],\n",
            "        [-1.7220,  1.5027, -0.1744],\n",
            "        [-1.9109,  0.7208,  0.8693],\n",
            "        [-2.1894,  1.7405,  0.2135],\n",
            "        [-1.9404,  0.3486,  1.2165],\n",
            "        [ 0.3332, -0.0453, -0.6760]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8422,  1.9656, -0.2923],\n",
            "        [-1.6314,  1.5139, -0.1757],\n",
            "        [-1.6300,  1.6077, -0.2910],\n",
            "        [ 0.3505, -0.1036, -0.5700],\n",
            "        [-1.9183,  2.0015, -0.4421],\n",
            "        [-1.8843,  2.0582, -0.4484],\n",
            "        [-1.8423,  1.5766, -0.0801],\n",
            "        [-1.9324,  1.8974, -0.1955],\n",
            "        [-1.7327,  1.7411, -0.1117],\n",
            "        [ 0.5660, -0.1318, -0.6085],\n",
            "        [-2.2457,  0.9831,  0.9038],\n",
            "        [-1.6041,  1.2048,  0.0526],\n",
            "        [-0.7426,  1.1820, -0.8448],\n",
            "        [-1.6953,  2.1308, -0.3348],\n",
            "        [-1.8428,  1.7744,  0.0801],\n",
            "        [-1.5882,  1.3855, -0.3809]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8422,  1.9656, -0.2923],\n",
            "        [-1.6314,  1.5139, -0.1757],\n",
            "        [-1.6300,  1.6077, -0.2910],\n",
            "        [ 0.3505, -0.1036, -0.5700],\n",
            "        [-1.9183,  2.0015, -0.4421],\n",
            "        [-1.8843,  2.0582, -0.4484],\n",
            "        [-1.8423,  1.5766, -0.0801],\n",
            "        [-1.9324,  1.8974, -0.1955],\n",
            "        [-1.7327,  1.7411, -0.1117],\n",
            "        [ 0.5660, -0.1318, -0.6085],\n",
            "        [-2.2457,  0.9831,  0.9038],\n",
            "        [-1.6041,  1.2048,  0.0526],\n",
            "        [-0.7426,  1.1820, -0.8448],\n",
            "        [-1.6953,  2.1308, -0.3348],\n",
            "        [-1.8428,  1.7744,  0.0801],\n",
            "        [-1.5882,  1.3855, -0.3809]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.6046, -0.2681, -0.4939],\n",
            "        [-1.9589,  2.0794, -0.1831],\n",
            "        [ 0.3738, -0.2106, -0.5040],\n",
            "        [-2.0299,  1.8561,  0.1633],\n",
            "        [-1.6060,  1.6782, -0.2209],\n",
            "        [-1.6331,  1.8780, -0.3861],\n",
            "        [-1.7302,  1.7020, -0.1430],\n",
            "        [-1.6720,  1.8437, -0.0957],\n",
            "        [-1.4949,  1.5722, -0.6568],\n",
            "        [-1.6800,  1.7706, -0.0705],\n",
            "        [-1.6151,  1.6932, -0.2948],\n",
            "        [ 0.1358, -0.0175, -0.1826],\n",
            "        [-2.0306,  0.7060,  1.1578],\n",
            "        [-2.0749,  1.2374,  0.7686],\n",
            "        [-1.8604,  2.1233, -0.2668],\n",
            "        [-1.9662,  2.0022, -0.0500]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.6046, -0.2681, -0.4939],\n",
            "        [-1.9589,  2.0794, -0.1831],\n",
            "        [ 0.3738, -0.2106, -0.5040],\n",
            "        [-2.0299,  1.8561,  0.1633],\n",
            "        [-1.6060,  1.6782, -0.2209],\n",
            "        [-1.6331,  1.8780, -0.3861],\n",
            "        [-1.7302,  1.7020, -0.1430],\n",
            "        [-1.6720,  1.8437, -0.0957],\n",
            "        [-1.4949,  1.5722, -0.6568],\n",
            "        [-1.6800,  1.7706, -0.0705],\n",
            "        [-1.6151,  1.6932, -0.2948],\n",
            "        [ 0.1358, -0.0175, -0.1826],\n",
            "        [-2.0306,  0.7060,  1.1578],\n",
            "        [-2.0749,  1.2374,  0.7686],\n",
            "        [-1.8604,  2.1233, -0.2668],\n",
            "        [-1.9662,  2.0022, -0.0500]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0053,  1.9630, -0.2635],\n",
            "        [-1.7212,  1.7683, -0.1600],\n",
            "        [-1.5804,  1.6754, -0.1747],\n",
            "        [-1.8246,  2.0506, -0.2326],\n",
            "        [ 0.5549, -0.3442, -0.5728],\n",
            "        [-1.6222,  1.9061, -0.2284],\n",
            "        [-2.0059,  1.3456,  0.3953],\n",
            "        [-1.7116,  1.9486, -0.2836],\n",
            "        [ 0.5424, -0.2562, -0.7357],\n",
            "        [-2.1031,  0.9706,  0.7918],\n",
            "        [-1.5315,  1.7214, -0.3573],\n",
            "        [-1.9696,  0.7237,  0.9097],\n",
            "        [-1.6891,  1.8513, -0.1964],\n",
            "        [-2.0974,  0.6349,  1.0521],\n",
            "        [-1.7463,  1.8837, -0.1926],\n",
            "        [-1.9457,  1.0880,  0.7165]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0053,  1.9630, -0.2635],\n",
            "        [-1.7212,  1.7683, -0.1600],\n",
            "        [-1.5804,  1.6754, -0.1747],\n",
            "        [-1.8246,  2.0506, -0.2326],\n",
            "        [ 0.5549, -0.3442, -0.5728],\n",
            "        [-1.6222,  1.9061, -0.2284],\n",
            "        [-2.0059,  1.3456,  0.3953],\n",
            "        [-1.7116,  1.9486, -0.2836],\n",
            "        [ 0.5424, -0.2562, -0.7357],\n",
            "        [-2.1031,  0.9706,  0.7918],\n",
            "        [-1.5315,  1.7214, -0.3573],\n",
            "        [-1.9696,  0.7237,  0.9097],\n",
            "        [-1.6891,  1.8513, -0.1964],\n",
            "        [-2.0974,  0.6349,  1.0521],\n",
            "        [-1.7463,  1.8837, -0.1926],\n",
            "        [-1.9457,  1.0880,  0.7165]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5921,  1.7952, -0.5719],\n",
            "        [ 0.6835, -0.2639, -0.6374],\n",
            "        [-2.0107,  1.6313, -0.2454],\n",
            "        [-2.1491,  1.2990,  0.8515],\n",
            "        [-1.9252,  1.8151, -0.0739],\n",
            "        [-1.5096,  1.9336, -0.3520],\n",
            "        [-1.9984,  1.3529,  0.1765],\n",
            "        [-1.9370,  1.8767, -0.1601],\n",
            "        [-1.6521,  1.7733, -0.3570],\n",
            "        [ 0.4416, -0.1979, -0.7911],\n",
            "        [-2.0955,  0.6307,  1.1763],\n",
            "        [-1.8926,  0.3659,  1.2650],\n",
            "        [-1.8250,  0.6338,  1.0186],\n",
            "        [-1.8260,  0.4561,  1.1119],\n",
            "        [-1.8770,  0.3462,  1.2695],\n",
            "        [-1.8650,  0.3518,  1.2318]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5921,  1.7952, -0.5719],\n",
            "        [ 0.6835, -0.2639, -0.6374],\n",
            "        [-2.0107,  1.6313, -0.2454],\n",
            "        [-2.1491,  1.2990,  0.8515],\n",
            "        [-1.9252,  1.8151, -0.0739],\n",
            "        [-1.5096,  1.9336, -0.3520],\n",
            "        [-1.9984,  1.3529,  0.1765],\n",
            "        [-1.9370,  1.8767, -0.1601],\n",
            "        [-1.6521,  1.7733, -0.3570],\n",
            "        [ 0.4416, -0.1979, -0.7911],\n",
            "        [-2.0955,  0.6307,  1.1763],\n",
            "        [-1.8926,  0.3659,  1.2650],\n",
            "        [-1.8250,  0.6338,  1.0186],\n",
            "        [-1.8260,  0.4561,  1.1119],\n",
            "        [-1.8770,  0.3462,  1.2695],\n",
            "        [-1.8650,  0.3518,  1.2318]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.6283, -0.1826, -0.7049],\n",
            "        [-1.7748,  1.6839, -0.2307],\n",
            "        [-1.9996,  1.7513, -0.1953],\n",
            "        [-1.5842,  0.1383,  1.1937],\n",
            "        [-0.8807,  1.2449, -0.5957],\n",
            "        [-1.5774,  1.8059, -0.1855],\n",
            "        [ 0.3287, -0.2067, -0.4829],\n",
            "        [-1.5462,  1.9049, -0.3444],\n",
            "        [-2.0603,  0.5104,  1.2070],\n",
            "        [-1.0619,  1.1828, -0.1818],\n",
            "        [-1.4085,  1.6259, -0.3607],\n",
            "        [-1.6584,  1.8479, -0.2547],\n",
            "        [-2.1705,  0.6494,  1.1099],\n",
            "        [-1.8988,  0.6122,  0.9639],\n",
            "        [-2.0991,  1.4746,  0.3426],\n",
            "        [-2.1831,  0.4791,  1.2352]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.6283, -0.1826, -0.7049],\n",
            "        [-1.7748,  1.6839, -0.2307],\n",
            "        [-1.9996,  1.7513, -0.1953],\n",
            "        [-1.5842,  0.1383,  1.1937],\n",
            "        [-0.8807,  1.2449, -0.5957],\n",
            "        [-1.5774,  1.8059, -0.1855],\n",
            "        [ 0.3287, -0.2067, -0.4829],\n",
            "        [-1.5462,  1.9049, -0.3444],\n",
            "        [-2.0603,  0.5104,  1.2070],\n",
            "        [-1.0619,  1.1828, -0.1818],\n",
            "        [-1.4085,  1.6259, -0.3607],\n",
            "        [-1.6584,  1.8479, -0.2547],\n",
            "        [-2.1705,  0.6494,  1.1099],\n",
            "        [-1.8988,  0.6122,  0.9639],\n",
            "        [-2.0991,  1.4746,  0.3426],\n",
            "        [-2.1831,  0.4791,  1.2352]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3901,  1.4092, -0.0511],\n",
            "        [-1.4465,  1.6953, -0.3598],\n",
            "        [-1.8695,  1.7841, -0.0262],\n",
            "        [-1.2305,  1.6056, -0.4609],\n",
            "        [-1.6284,  1.7681, -0.3665],\n",
            "        [-1.5633,  1.8026, -0.3127],\n",
            "        [-1.9050,  0.3854,  1.2984],\n",
            "        [-1.5886,  0.3281,  1.0247],\n",
            "        [ 0.5947, -0.2671, -0.5796],\n",
            "        [-1.5602,  1.5600, -0.1697],\n",
            "        [-1.8264,  1.4786,  0.3882],\n",
            "        [-1.5068,  1.7747, -0.3650],\n",
            "        [ 0.6347, -0.1367, -0.8848],\n",
            "        [-1.5514,  1.9702, -0.4218],\n",
            "        [-1.5795,  1.6672, -0.1137],\n",
            "        [-1.3950,  1.5794, -0.2023]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3901,  1.4092, -0.0511],\n",
            "        [-1.4465,  1.6953, -0.3598],\n",
            "        [-1.8695,  1.7841, -0.0262],\n",
            "        [-1.2305,  1.6056, -0.4609],\n",
            "        [-1.6284,  1.7681, -0.3665],\n",
            "        [-1.5633,  1.8026, -0.3127],\n",
            "        [-1.9050,  0.3854,  1.2984],\n",
            "        [-1.5886,  0.3281,  1.0247],\n",
            "        [ 0.5947, -0.2671, -0.5796],\n",
            "        [-1.5602,  1.5600, -0.1697],\n",
            "        [-1.8264,  1.4786,  0.3882],\n",
            "        [-1.5068,  1.7747, -0.3650],\n",
            "        [ 0.6347, -0.1367, -0.8848],\n",
            "        [-1.5514,  1.9702, -0.4218],\n",
            "        [-1.5795,  1.6672, -0.1137],\n",
            "        [-1.3950,  1.5794, -0.2023]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8408,  1.8151, -0.0258],\n",
            "        [-1.6678,  1.7961, -0.1367],\n",
            "        [-1.2831,  1.5526, -0.3167],\n",
            "        [-1.1016,  1.3384, -0.5793],\n",
            "        [ 0.4350, -0.0432, -0.7986],\n",
            "        [-1.7095,  1.5932,  0.1046],\n",
            "        [-1.4976,  1.5779, -0.4566],\n",
            "        [ 0.5996, -0.3481, -0.7182],\n",
            "        [-1.5852,  1.3729, -0.3650],\n",
            "        [-1.5143,  1.7373, -0.2262],\n",
            "        [-1.5872,  1.8143, -0.3000],\n",
            "        [-2.0723,  0.4465,  1.2569],\n",
            "        [-1.3636,  1.5796, -0.0614],\n",
            "        [-1.5025,  1.9414, -0.3255],\n",
            "        [-2.0911,  0.8937,  0.8682],\n",
            "        [-1.9078,  1.0182,  0.6844]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8408,  1.8151, -0.0258],\n",
            "        [-1.6678,  1.7961, -0.1367],\n",
            "        [-1.2831,  1.5526, -0.3167],\n",
            "        [-1.1016,  1.3384, -0.5793],\n",
            "        [ 0.4350, -0.0432, -0.7986],\n",
            "        [-1.7095,  1.5932,  0.1046],\n",
            "        [-1.4976,  1.5779, -0.4566],\n",
            "        [ 0.5996, -0.3481, -0.7182],\n",
            "        [-1.5852,  1.3729, -0.3650],\n",
            "        [-1.5143,  1.7373, -0.2262],\n",
            "        [-1.5872,  1.8143, -0.3000],\n",
            "        [-2.0723,  0.4465,  1.2569],\n",
            "        [-1.3636,  1.5796, -0.0614],\n",
            "        [-1.5025,  1.9414, -0.3255],\n",
            "        [-2.0911,  0.8937,  0.8682],\n",
            "        [-1.9078,  1.0182,  0.6844]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4944,  1.6047, -0.2635],\n",
            "        [-0.1791,  0.0941, -0.3416],\n",
            "        [-1.7691,  1.8495,  0.0372],\n",
            "        [-1.8817,  0.4052,  1.2445],\n",
            "        [-1.7408,  0.2653,  1.2230],\n",
            "        [-1.5548,  1.7629, -0.2701],\n",
            "        [-1.8317,  1.2728,  0.6713],\n",
            "        [ 0.1102, -0.3506, -0.2833],\n",
            "        [-1.7046,  1.9484, -0.2571],\n",
            "        [ 0.5964, -0.2380, -0.8013],\n",
            "        [-1.1743,  0.4940,  0.3489],\n",
            "        [-1.3196,  1.6114, -0.4265],\n",
            "        [-1.8662,  0.1184,  1.1918],\n",
            "        [-1.2087,  1.5047, -0.1798],\n",
            "        [-1.6372,  1.5383,  0.0233],\n",
            "        [-1.2254,  0.4552,  0.5615]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4944,  1.6047, -0.2635],\n",
            "        [-0.1791,  0.0941, -0.3416],\n",
            "        [-1.7691,  1.8495,  0.0372],\n",
            "        [-1.8817,  0.4052,  1.2445],\n",
            "        [-1.7408,  0.2653,  1.2230],\n",
            "        [-1.5548,  1.7629, -0.2701],\n",
            "        [-1.8317,  1.2728,  0.6713],\n",
            "        [ 0.1102, -0.3506, -0.2833],\n",
            "        [-1.7046,  1.9484, -0.2571],\n",
            "        [ 0.5964, -0.2380, -0.8013],\n",
            "        [-1.1743,  0.4940,  0.3489],\n",
            "        [-1.3196,  1.6114, -0.4265],\n",
            "        [-1.8662,  0.1184,  1.1918],\n",
            "        [-1.2087,  1.5047, -0.1798],\n",
            "        [-1.6372,  1.5383,  0.0233],\n",
            "        [-1.2254,  0.4552,  0.5615]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4955,  1.8767, -0.1760],\n",
            "        [-2.0662,  0.7212,  1.0551],\n",
            "        [-1.5056,  1.6040, -0.3254],\n",
            "        [-1.7858,  1.5633, -0.0123],\n",
            "        [ 0.5383, -0.3213, -0.7987],\n",
            "        [ 0.1820,  0.0437, -0.4260],\n",
            "        [-2.1241,  0.4418,  1.2268],\n",
            "        [-1.5846,  1.7956, -0.2847],\n",
            "        [-1.9541,  1.7477,  0.1119],\n",
            "        [-1.7652,  1.8529, -0.0703],\n",
            "        [-1.4398,  1.8733, -0.3436],\n",
            "        [-1.7914,  0.5977,  0.9998],\n",
            "        [-1.8585,  1.4072,  0.1210],\n",
            "        [-1.7044,  1.3285,  0.2770],\n",
            "        [-1.6164,  1.6647, -0.1685],\n",
            "        [-1.5548,  1.6137, -0.3061]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4955,  1.8767, -0.1760],\n",
            "        [-2.0662,  0.7212,  1.0551],\n",
            "        [-1.5056,  1.6040, -0.3254],\n",
            "        [-1.7858,  1.5633, -0.0123],\n",
            "        [ 0.5383, -0.3213, -0.7987],\n",
            "        [ 0.1820,  0.0437, -0.4260],\n",
            "        [-2.1241,  0.4418,  1.2268],\n",
            "        [-1.5846,  1.7956, -0.2847],\n",
            "        [-1.9541,  1.7477,  0.1119],\n",
            "        [-1.7652,  1.8529, -0.0703],\n",
            "        [-1.4398,  1.8733, -0.3436],\n",
            "        [-1.7914,  0.5977,  0.9998],\n",
            "        [-1.8585,  1.4072,  0.1210],\n",
            "        [-1.7044,  1.3285,  0.2770],\n",
            "        [-1.6164,  1.6647, -0.1685],\n",
            "        [-1.5548,  1.6137, -0.3061]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.6249, -0.0960, -0.9561],\n",
            "        [-1.4178,  1.6193, -0.0991],\n",
            "        [-1.6120,  0.9865,  0.4863],\n",
            "        [-1.6598,  1.7143, -0.3284],\n",
            "        [-1.7139,  0.3122,  1.3102],\n",
            "        [-1.7127,  1.8806, -0.0326],\n",
            "        [-0.6319, -0.0446,  0.4211],\n",
            "        [-1.8377,  1.3366,  0.4354],\n",
            "        [-1.4743,  1.7585, -0.3054],\n",
            "        [-1.5889,  1.7035, -0.2585],\n",
            "        [-1.4983,  1.3768, -0.1482],\n",
            "        [-1.6999,  1.4039,  0.1549],\n",
            "        [-1.6316,  1.7401, -0.1224],\n",
            "        [-1.5243,  1.7167, -0.3365],\n",
            "        [-1.6001,  1.7012, -0.1157],\n",
            "        [-1.5345,  1.4558, -0.0861]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.6249, -0.0960, -0.9561],\n",
            "        [-1.4178,  1.6193, -0.0991],\n",
            "        [-1.6120,  0.9865,  0.4863],\n",
            "        [-1.6598,  1.7143, -0.3284],\n",
            "        [-1.7139,  0.3122,  1.3102],\n",
            "        [-1.7127,  1.8806, -0.0326],\n",
            "        [-0.6319, -0.0446,  0.4211],\n",
            "        [-1.8377,  1.3366,  0.4354],\n",
            "        [-1.4743,  1.7585, -0.3054],\n",
            "        [-1.5889,  1.7035, -0.2585],\n",
            "        [-1.4983,  1.3768, -0.1482],\n",
            "        [-1.6999,  1.4039,  0.1549],\n",
            "        [-1.6316,  1.7401, -0.1224],\n",
            "        [-1.5243,  1.7167, -0.3365],\n",
            "        [-1.6001,  1.7012, -0.1157],\n",
            "        [-1.5345,  1.4558, -0.0861]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6343,  1.7427, -0.1658],\n",
            "        [-1.8266,  0.1946,  1.0970],\n",
            "        [-1.5207,  1.4862, -0.0067],\n",
            "        [ 0.0506,  0.2612, -0.8414],\n",
            "        [ 0.2638,  0.1914, -0.7276],\n",
            "        [-1.4637,  1.5000,  0.0496],\n",
            "        [-1.8880,  1.9234, -0.1622],\n",
            "        [-1.5329,  1.5569, -0.2602],\n",
            "        [-1.5939,  1.4886, -0.2003],\n",
            "        [-1.6847,  0.9071,  0.3746],\n",
            "        [-1.8103,  1.4769,  0.2853],\n",
            "        [-1.8994,  0.5477,  0.8349],\n",
            "        [-1.8936,  0.4547,  1.2716],\n",
            "        [-1.8210,  0.5271,  1.2407],\n",
            "        [-1.4860,  1.2120,  0.1349],\n",
            "        [-2.0524,  1.4360,  0.0783]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6343,  1.7427, -0.1658],\n",
            "        [-1.8266,  0.1946,  1.0970],\n",
            "        [-1.5207,  1.4862, -0.0067],\n",
            "        [ 0.0506,  0.2612, -0.8414],\n",
            "        [ 0.2638,  0.1914, -0.7276],\n",
            "        [-1.4637,  1.5000,  0.0496],\n",
            "        [-1.8880,  1.9234, -0.1622],\n",
            "        [-1.5329,  1.5569, -0.2602],\n",
            "        [-1.5939,  1.4886, -0.2003],\n",
            "        [-1.6847,  0.9071,  0.3746],\n",
            "        [-1.8103,  1.4769,  0.2853],\n",
            "        [-1.8994,  0.5477,  0.8349],\n",
            "        [-1.8936,  0.4547,  1.2716],\n",
            "        [-1.8210,  0.5271,  1.2407],\n",
            "        [-1.4860,  1.2120,  0.1349],\n",
            "        [-2.0524,  1.4360,  0.0783]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5381,  1.1984,  0.1751],\n",
            "        [-1.6014,  0.0479,  1.3752],\n",
            "        [-1.3216,  1.2579,  0.0205],\n",
            "        [-1.9269,  1.3544,  0.0929],\n",
            "        [-1.6707,  0.2839,  1.2107],\n",
            "        [-1.3197,  1.4474, -0.2152],\n",
            "        [-1.6671,  0.3669,  1.0056],\n",
            "        [ 0.2484,  0.0305, -0.7121],\n",
            "        [-1.4277,  1.6603, -0.3740],\n",
            "        [-1.3927,  1.4570, -0.0121],\n",
            "        [ 0.4968, -0.3757, -0.8160],\n",
            "        [-1.8559,  0.3816,  1.1995],\n",
            "        [ 0.4757, -0.1562, -0.9912],\n",
            "        [-1.5832,  0.0856,  1.3049],\n",
            "        [-1.1344,  1.2400, -0.0020],\n",
            "        [-1.5687,  1.5167,  0.0761]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5381,  1.1984,  0.1751],\n",
            "        [-1.6014,  0.0479,  1.3752],\n",
            "        [-1.3216,  1.2579,  0.0205],\n",
            "        [-1.9269,  1.3544,  0.0929],\n",
            "        [-1.6707,  0.2839,  1.2107],\n",
            "        [-1.3197,  1.4474, -0.2152],\n",
            "        [-1.6671,  0.3669,  1.0056],\n",
            "        [ 0.2484,  0.0305, -0.7121],\n",
            "        [-1.4277,  1.6603, -0.3740],\n",
            "        [-1.3927,  1.4570, -0.0121],\n",
            "        [ 0.4968, -0.3757, -0.8160],\n",
            "        [-1.8559,  0.3816,  1.1995],\n",
            "        [ 0.4757, -0.1562, -0.9912],\n",
            "        [-1.5832,  0.0856,  1.3049],\n",
            "        [-1.1344,  1.2400, -0.0020],\n",
            "        [-1.5687,  1.5167,  0.0761]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.8274, -0.2227, -0.9373],\n",
            "        [-1.8724,  1.3342,  0.1965],\n",
            "        [-1.3718,  1.1932, -0.1131],\n",
            "        [-1.3249,  1.1640, -0.0462],\n",
            "        [ 0.2409, -0.1041, -0.5989],\n",
            "        [-1.4274,  1.4218,  0.1351],\n",
            "        [ 0.5334, -0.3986, -0.6808],\n",
            "        [-1.3578,  1.3875, -0.0197],\n",
            "        [ 0.0264,  0.2692, -0.7970],\n",
            "        [-1.8650,  0.3672,  1.1732],\n",
            "        [-1.5088,  1.3052,  0.1008],\n",
            "        [-1.7631,  1.2673,  0.2880],\n",
            "        [-1.3413,  1.5022, -0.1829],\n",
            "        [-1.3787,  1.2702,  0.0825],\n",
            "        [-1.2799,  1.3542, -0.0038],\n",
            "        [ 0.4929,  0.2157, -0.8174]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.8274, -0.2227, -0.9373],\n",
            "        [-1.8724,  1.3342,  0.1965],\n",
            "        [-1.3718,  1.1932, -0.1131],\n",
            "        [-1.3249,  1.1640, -0.0462],\n",
            "        [ 0.2409, -0.1041, -0.5989],\n",
            "        [-1.4274,  1.4218,  0.1351],\n",
            "        [ 0.5334, -0.3986, -0.6808],\n",
            "        [-1.3578,  1.3875, -0.0197],\n",
            "        [ 0.0264,  0.2692, -0.7970],\n",
            "        [-1.8650,  0.3672,  1.1732],\n",
            "        [-1.5088,  1.3052,  0.1008],\n",
            "        [-1.7631,  1.2673,  0.2880],\n",
            "        [-1.3413,  1.5022, -0.1829],\n",
            "        [-1.3787,  1.2702,  0.0825],\n",
            "        [-1.2799,  1.3542, -0.0038],\n",
            "        [ 0.4929,  0.2157, -0.8174]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6754,  0.3446,  1.1233],\n",
            "        [-1.3263,  1.5419, -0.0268],\n",
            "        [-1.7029,  1.7913, -0.1859],\n",
            "        [-1.7108,  0.1192,  1.4258],\n",
            "        [-1.5442,  1.3685,  0.1262],\n",
            "        [-1.0713,  1.3391, -0.1216],\n",
            "        [-1.0985, -0.0144,  0.9212],\n",
            "        [-1.9366,  0.8564,  0.8132],\n",
            "        [-1.8413,  0.4964,  0.9844],\n",
            "        [-1.7162,  0.3388,  0.9613],\n",
            "        [-1.3313,  1.4235, -0.0172],\n",
            "        [-1.5741,  0.6552,  0.8263],\n",
            "        [-1.6451, -0.0928,  1.2361],\n",
            "        [-1.7812,  0.8226,  0.7294],\n",
            "        [-1.4350,  1.4176,  0.0321],\n",
            "        [-0.1105, -0.1614, -0.0429]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6754,  0.3446,  1.1233],\n",
            "        [-1.3263,  1.5419, -0.0268],\n",
            "        [-1.7029,  1.7913, -0.1859],\n",
            "        [-1.7108,  0.1192,  1.4258],\n",
            "        [-1.5442,  1.3685,  0.1262],\n",
            "        [-1.0713,  1.3391, -0.1216],\n",
            "        [-1.0985, -0.0144,  0.9212],\n",
            "        [-1.9366,  0.8564,  0.8132],\n",
            "        [-1.8413,  0.4964,  0.9844],\n",
            "        [-1.7162,  0.3388,  0.9613],\n",
            "        [-1.3313,  1.4235, -0.0172],\n",
            "        [-1.5741,  0.6552,  0.8263],\n",
            "        [-1.6451, -0.0928,  1.2361],\n",
            "        [-1.7812,  0.8226,  0.7294],\n",
            "        [-1.4350,  1.4176,  0.0321],\n",
            "        [-0.1105, -0.1614, -0.0429]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7332,  0.8843,  0.7106],\n",
            "        [-1.4708,  1.0852,  0.3193],\n",
            "        [-1.2075,  1.0982,  0.0969],\n",
            "        [-1.2352,  1.2779,  0.0344],\n",
            "        [-1.4556,  1.2725, -0.0605],\n",
            "        [-1.8672,  1.3499,  0.1319],\n",
            "        [-1.5653,  0.9536,  0.3420],\n",
            "        [-1.2785,  1.4626, -0.2228],\n",
            "        [-1.5167,  1.4099,  0.1879],\n",
            "        [-1.4044,  0.8809,  0.2933],\n",
            "        [ 0.4196, -0.1829, -0.7809],\n",
            "        [ 0.5996, -0.1231, -0.9879],\n",
            "        [-1.3790,  1.2909,  0.0477],\n",
            "        [-1.8351,  0.2391,  1.3917],\n",
            "        [ 0.2470, -0.0403, -0.5752],\n",
            "        [-1.4278,  1.4324, -0.0329]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7332,  0.8843,  0.7106],\n",
            "        [-1.4708,  1.0852,  0.3193],\n",
            "        [-1.2075,  1.0982,  0.0969],\n",
            "        [-1.2352,  1.2779,  0.0344],\n",
            "        [-1.4556,  1.2725, -0.0605],\n",
            "        [-1.8672,  1.3499,  0.1319],\n",
            "        [-1.5653,  0.9536,  0.3420],\n",
            "        [-1.2785,  1.4626, -0.2228],\n",
            "        [-1.5167,  1.4099,  0.1879],\n",
            "        [-1.4044,  0.8809,  0.2933],\n",
            "        [ 0.4196, -0.1829, -0.7809],\n",
            "        [ 0.5996, -0.1231, -0.9879],\n",
            "        [-1.3790,  1.2909,  0.0477],\n",
            "        [-1.8351,  0.2391,  1.3917],\n",
            "        [ 0.2470, -0.0403, -0.5752],\n",
            "        [-1.4278,  1.4324, -0.0329]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2752,  1.0903,  0.0509],\n",
            "        [-1.6599,  1.1704,  0.2927],\n",
            "        [ 0.4657, -0.0506, -0.8211],\n",
            "        [ 0.5251,  0.1161, -1.0495],\n",
            "        [ 0.3828,  0.2213, -0.9904],\n",
            "        [-1.3853,  0.9427,  0.0319],\n",
            "        [-1.6549,  0.2312,  1.2424],\n",
            "        [-1.4994,  1.2256,  0.1363],\n",
            "        [-1.9204,  0.4337,  1.1571],\n",
            "        [-0.4081, -0.0900,  0.2968],\n",
            "        [ 0.5020, -0.1757, -0.9514],\n",
            "        [-1.6905,  0.9876,  0.3250],\n",
            "        [-1.0487,  1.1481, -0.1633],\n",
            "        [-1.0798,  1.0682,  0.0562],\n",
            "        [ 0.1001, -0.0075, -0.3302],\n",
            "        [-2.0270,  0.3219,  1.2850]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2752,  1.0903,  0.0509],\n",
            "        [-1.6599,  1.1704,  0.2927],\n",
            "        [ 0.4657, -0.0506, -0.8211],\n",
            "        [ 0.5251,  0.1161, -1.0495],\n",
            "        [ 0.3828,  0.2213, -0.9904],\n",
            "        [-1.3853,  0.9427,  0.0319],\n",
            "        [-1.6549,  0.2312,  1.2424],\n",
            "        [-1.4994,  1.2256,  0.1363],\n",
            "        [-1.9204,  0.4337,  1.1571],\n",
            "        [-0.4081, -0.0900,  0.2968],\n",
            "        [ 0.5020, -0.1757, -0.9514],\n",
            "        [-1.6905,  0.9876,  0.3250],\n",
            "        [-1.0487,  1.1481, -0.1633],\n",
            "        [-1.0798,  1.0682,  0.0562],\n",
            "        [ 0.1001, -0.0075, -0.3302],\n",
            "        [-2.0270,  0.3219,  1.2850]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7267,  0.3379,  1.2051],\n",
            "        [-1.8049,  0.0194,  1.3827],\n",
            "        [ 0.2640, -0.0697, -0.5832],\n",
            "        [-1.3035,  1.5315, -0.1654],\n",
            "        [-1.6362,  1.2840, -0.0619],\n",
            "        [-1.7185,  0.2944,  1.4264],\n",
            "        [ 0.6259, -0.1948, -1.0903],\n",
            "        [-1.5189,  1.2686,  0.3431],\n",
            "        [-1.7054,  0.7130,  0.6288],\n",
            "        [-1.5938,  1.1734,  0.3499],\n",
            "        [ 0.3000, -0.1148, -0.7639],\n",
            "        [-1.5278,  0.3174,  0.9431],\n",
            "        [-1.8525,  0.3928,  1.1487],\n",
            "        [-1.4511,  1.4075, -0.1058],\n",
            "        [ 0.5879, -0.1329, -0.7995],\n",
            "        [-1.3239,  1.2044,  0.0504]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7267,  0.3379,  1.2051],\n",
            "        [-1.8049,  0.0194,  1.3827],\n",
            "        [ 0.2640, -0.0697, -0.5832],\n",
            "        [-1.3035,  1.5315, -0.1654],\n",
            "        [-1.6362,  1.2840, -0.0619],\n",
            "        [-1.7185,  0.2944,  1.4264],\n",
            "        [ 0.6259, -0.1948, -1.0903],\n",
            "        [-1.5189,  1.2686,  0.3431],\n",
            "        [-1.7054,  0.7130,  0.6288],\n",
            "        [-1.5938,  1.1734,  0.3499],\n",
            "        [ 0.3000, -0.1148, -0.7639],\n",
            "        [-1.5278,  0.3174,  0.9431],\n",
            "        [-1.8525,  0.3928,  1.1487],\n",
            "        [-1.4511,  1.4075, -0.1058],\n",
            "        [ 0.5879, -0.1329, -0.7995],\n",
            "        [-1.3239,  1.2044,  0.0504]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.0850,  1.4694, -0.5759],\n",
            "        [ 0.5341,  0.1782, -1.0246],\n",
            "        [-1.2459,  1.1444,  0.1973],\n",
            "        [-1.6194,  1.3439,  0.1856],\n",
            "        [ 0.4620, -0.0547, -0.8420],\n",
            "        [-1.3684,  1.2329,  0.0113],\n",
            "        [ 0.7515, -0.1860, -0.8134],\n",
            "        [ 0.5199,  0.0239, -0.8222],\n",
            "        [-1.1310,  1.2267, -0.6271],\n",
            "        [ 0.6012, -0.1328, -0.8262],\n",
            "        [-1.6435,  0.2610,  1.0828],\n",
            "        [ 0.4804,  0.0066, -0.9372],\n",
            "        [-1.4760,  1.3027,  0.1029],\n",
            "        [-1.5418,  1.2872, -0.1748],\n",
            "        [-1.3641,  1.0946,  0.0249],\n",
            "        [-1.5674,  0.1471,  1.1321]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.0850,  1.4694, -0.5759],\n",
            "        [ 0.5341,  0.1782, -1.0246],\n",
            "        [-1.2459,  1.1444,  0.1973],\n",
            "        [-1.6194,  1.3439,  0.1856],\n",
            "        [ 0.4620, -0.0547, -0.8420],\n",
            "        [-1.3684,  1.2329,  0.0113],\n",
            "        [ 0.7515, -0.1860, -0.8134],\n",
            "        [ 0.5199,  0.0239, -0.8222],\n",
            "        [-1.1310,  1.2267, -0.6271],\n",
            "        [ 0.6012, -0.1328, -0.8262],\n",
            "        [-1.6435,  0.2610,  1.0828],\n",
            "        [ 0.4804,  0.0066, -0.9372],\n",
            "        [-1.4760,  1.3027,  0.1029],\n",
            "        [-1.5418,  1.2872, -0.1748],\n",
            "        [-1.3641,  1.0946,  0.0249],\n",
            "        [-1.5674,  0.1471,  1.1321]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0140e-01,  3.3414e-01, -5.8073e-01],\n",
            "        [-1.7743e+00,  8.9174e-01,  7.0927e-01],\n",
            "        [-1.9361e+00,  1.5926e+00,  2.3969e-01],\n",
            "        [-1.5693e+00,  8.2812e-01,  6.9358e-01],\n",
            "        [-1.7199e+00,  2.0871e-01,  1.2610e+00],\n",
            "        [-1.0606e+00,  1.1059e+00, -1.8688e-04],\n",
            "        [ 2.7108e-01,  1.3764e-01, -9.0377e-01],\n",
            "        [-1.5115e+00,  1.4853e+00, -2.6728e-01],\n",
            "        [ 6.1963e-01, -2.1288e-02, -7.7768e-01],\n",
            "        [-1.3752e+00,  1.2639e+00, -8.2067e-02],\n",
            "        [-1.2392e+00,  1.2576e+00, -3.0805e-02],\n",
            "        [-1.3735e+00,  3.4863e-01,  9.9526e-01],\n",
            "        [-1.3876e+00,  1.2225e+00,  6.5730e-02],\n",
            "        [ 4.4718e-01, -7.5083e-02, -7.6457e-01],\n",
            "        [-1.1392e+00,  1.3173e+00, -4.1746e-02],\n",
            "        [ 2.2671e-01,  3.2475e-01, -8.6569e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0140e-01,  3.3414e-01, -5.8073e-01],\n",
            "        [-1.7743e+00,  8.9174e-01,  7.0927e-01],\n",
            "        [-1.9361e+00,  1.5926e+00,  2.3969e-01],\n",
            "        [-1.5693e+00,  8.2812e-01,  6.9358e-01],\n",
            "        [-1.7199e+00,  2.0871e-01,  1.2610e+00],\n",
            "        [-1.0606e+00,  1.1059e+00, -1.8688e-04],\n",
            "        [ 2.7108e-01,  1.3764e-01, -9.0377e-01],\n",
            "        [-1.5115e+00,  1.4853e+00, -2.6728e-01],\n",
            "        [ 6.1963e-01, -2.1288e-02, -7.7768e-01],\n",
            "        [-1.3752e+00,  1.2639e+00, -8.2067e-02],\n",
            "        [-1.2392e+00,  1.2576e+00, -3.0805e-02],\n",
            "        [-1.3735e+00,  3.4863e-01,  9.9526e-01],\n",
            "        [-1.3876e+00,  1.2225e+00,  6.5730e-02],\n",
            "        [ 4.4718e-01, -7.5083e-02, -7.6457e-01],\n",
            "        [-1.1392e+00,  1.3173e+00, -4.1746e-02],\n",
            "        [ 2.2671e-01,  3.2475e-01, -8.6569e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5406,  1.2338,  0.0671],\n",
            "        [-0.1343,  0.6280, -0.8277],\n",
            "        [ 0.2694, -0.1693, -0.5446],\n",
            "        [ 0.3956,  0.1016, -1.1015],\n",
            "        [-1.3505,  1.3351, -0.2408],\n",
            "        [-1.4774,  1.6251, -0.3501],\n",
            "        [-1.8450,  1.5492,  0.1108],\n",
            "        [ 0.0885, -0.1756, -0.3064],\n",
            "        [-1.6911,  1.2702,  0.2620],\n",
            "        [-1.6948,  1.5659, -0.1097],\n",
            "        [-1.4768,  1.4446,  0.0147],\n",
            "        [-1.4738,  1.0374,  0.0312],\n",
            "        [-1.5762,  1.6716,  0.0091],\n",
            "        [-1.7671,  1.1602,  0.4864],\n",
            "        [-1.3718,  1.2644,  0.1145],\n",
            "        [-1.6930,  0.4946,  1.1039]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5406,  1.2338,  0.0671],\n",
            "        [-0.1343,  0.6280, -0.8277],\n",
            "        [ 0.2694, -0.1693, -0.5446],\n",
            "        [ 0.3956,  0.1016, -1.1015],\n",
            "        [-1.3505,  1.3351, -0.2408],\n",
            "        [-1.4774,  1.6251, -0.3501],\n",
            "        [-1.8450,  1.5492,  0.1108],\n",
            "        [ 0.0885, -0.1756, -0.3064],\n",
            "        [-1.6911,  1.2702,  0.2620],\n",
            "        [-1.6948,  1.5659, -0.1097],\n",
            "        [-1.4768,  1.4446,  0.0147],\n",
            "        [-1.4738,  1.0374,  0.0312],\n",
            "        [-1.5762,  1.6716,  0.0091],\n",
            "        [-1.7671,  1.1602,  0.4864],\n",
            "        [-1.3718,  1.2644,  0.1145],\n",
            "        [-1.6930,  0.4946,  1.1039]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6405,  0.2032,  1.1575],\n",
            "        [-1.1115,  0.0056,  0.6102],\n",
            "        [ 0.3101, -0.0478, -0.7596],\n",
            "        [-1.6197,  1.1288, -0.0293],\n",
            "        [ 0.5268, -0.1358, -0.7584],\n",
            "        [-1.8106,  0.7106,  0.8023],\n",
            "        [-1.3334,  1.2698,  0.0785],\n",
            "        [-2.0541,  0.8664,  0.7210],\n",
            "        [-1.4129,  1.1886,  0.0426],\n",
            "        [-1.5637,  1.0169,  0.4110],\n",
            "        [-1.1496,  1.0881,  0.0635],\n",
            "        [-1.2558,  1.1909,  0.0800],\n",
            "        [-1.4638,  0.2158,  1.0488],\n",
            "        [-1.8492,  1.0481,  0.5014],\n",
            "        [-1.5725,  0.6013,  1.0538],\n",
            "        [-1.5425,  1.3956,  0.0592]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6405,  0.2032,  1.1575],\n",
            "        [-1.1115,  0.0056,  0.6102],\n",
            "        [ 0.3101, -0.0478, -0.7596],\n",
            "        [-1.6197,  1.1288, -0.0293],\n",
            "        [ 0.5268, -0.1358, -0.7584],\n",
            "        [-1.8106,  0.7106,  0.8023],\n",
            "        [-1.3334,  1.2698,  0.0785],\n",
            "        [-2.0541,  0.8664,  0.7210],\n",
            "        [-1.4129,  1.1886,  0.0426],\n",
            "        [-1.5637,  1.0169,  0.4110],\n",
            "        [-1.1496,  1.0881,  0.0635],\n",
            "        [-1.2558,  1.1909,  0.0800],\n",
            "        [-1.4638,  0.2158,  1.0488],\n",
            "        [-1.8492,  1.0481,  0.5014],\n",
            "        [-1.5725,  0.6013,  1.0538],\n",
            "        [-1.5425,  1.3956,  0.0592]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8240e+00,  4.3491e-01,  1.0697e+00],\n",
            "        [-1.7556e+00,  1.5119e+00,  1.4308e-03],\n",
            "        [-1.3197e+00,  1.9949e-01,  1.0614e+00],\n",
            "        [-1.6010e+00,  1.5597e+00, -6.8188e-02],\n",
            "        [ 3.5718e-01,  5.8909e-02, -9.4358e-01],\n",
            "        [ 4.7137e-01, -2.0690e-01, -8.1010e-01],\n",
            "        [-1.4879e+00,  1.3301e+00, -6.0698e-02],\n",
            "        [-1.4480e+00,  1.1040e+00, -2.4616e-02],\n",
            "        [-1.7804e+00,  6.7324e-01,  8.3161e-01],\n",
            "        [-1.7226e+00,  1.4934e+00,  1.3780e-01],\n",
            "        [-1.7983e+00,  1.3202e+00,  3.4764e-01],\n",
            "        [-1.4655e+00,  1.3894e-01,  1.2911e+00],\n",
            "        [-1.7275e+00,  1.3876e+00,  3.1341e-02],\n",
            "        [-1.6108e+00,  1.4974e+00, -7.4069e-02],\n",
            "        [-1.9197e+00,  1.0883e+00,  5.6735e-01],\n",
            "        [-1.6017e+00,  1.4602e-02,  1.4194e+00]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8240e+00,  4.3491e-01,  1.0697e+00],\n",
            "        [-1.7556e+00,  1.5119e+00,  1.4308e-03],\n",
            "        [-1.3197e+00,  1.9949e-01,  1.0614e+00],\n",
            "        [-1.6010e+00,  1.5597e+00, -6.8188e-02],\n",
            "        [ 3.5718e-01,  5.8909e-02, -9.4358e-01],\n",
            "        [ 4.7137e-01, -2.0690e-01, -8.1010e-01],\n",
            "        [-1.4879e+00,  1.3301e+00, -6.0698e-02],\n",
            "        [-1.4480e+00,  1.1040e+00, -2.4616e-02],\n",
            "        [-1.7804e+00,  6.7324e-01,  8.3161e-01],\n",
            "        [-1.7226e+00,  1.4934e+00,  1.3780e-01],\n",
            "        [-1.7983e+00,  1.3202e+00,  3.4764e-01],\n",
            "        [-1.4655e+00,  1.3894e-01,  1.2911e+00],\n",
            "        [-1.7275e+00,  1.3876e+00,  3.1341e-02],\n",
            "        [-1.6108e+00,  1.4974e+00, -7.4069e-02],\n",
            "        [-1.9197e+00,  1.0883e+00,  5.6735e-01],\n",
            "        [-1.6017e+00,  1.4602e-02,  1.4194e+00]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4347,  1.4259,  0.0052],\n",
            "        [-1.8950,  0.2950,  1.2582],\n",
            "        [-1.3129,  1.3578,  0.0041],\n",
            "        [-1.3011,  0.0434,  1.0184],\n",
            "        [-1.5029,  0.0243,  0.8957],\n",
            "        [-1.7484,  0.3695,  1.1634],\n",
            "        [-1.5519,  0.3373,  1.1858],\n",
            "        [-1.7856,  1.2405,  0.2642],\n",
            "        [-1.5629,  1.7158, -0.3755],\n",
            "        [-1.5940,  1.1144,  0.0865],\n",
            "        [-1.9289,  0.5261,  0.8173],\n",
            "        [ 0.5608,  0.0835, -1.1005],\n",
            "        [-1.5541,  1.0857, -0.0511],\n",
            "        [-1.5242,  1.3534, -0.0279],\n",
            "        [-1.4412,  1.2469,  0.1561],\n",
            "        [ 0.4977,  0.0152, -1.0171]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4347,  1.4259,  0.0052],\n",
            "        [-1.8950,  0.2950,  1.2582],\n",
            "        [-1.3129,  1.3578,  0.0041],\n",
            "        [-1.3011,  0.0434,  1.0184],\n",
            "        [-1.5029,  0.0243,  0.8957],\n",
            "        [-1.7484,  0.3695,  1.1634],\n",
            "        [-1.5519,  0.3373,  1.1858],\n",
            "        [-1.7856,  1.2405,  0.2642],\n",
            "        [-1.5629,  1.7158, -0.3755],\n",
            "        [-1.5940,  1.1144,  0.0865],\n",
            "        [-1.9289,  0.5261,  0.8173],\n",
            "        [ 0.5608,  0.0835, -1.1005],\n",
            "        [-1.5541,  1.0857, -0.0511],\n",
            "        [-1.5242,  1.3534, -0.0279],\n",
            "        [-1.4412,  1.2469,  0.1561],\n",
            "        [ 0.4977,  0.0152, -1.0171]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3774e+00,  1.3491e+00,  5.3384e-04],\n",
            "        [-7.9775e-01,  1.2066e+00, -4.0941e-01],\n",
            "        [-1.5110e+00,  1.1635e+00,  1.1793e-01],\n",
            "        [-1.6036e+00,  1.2292e+00,  3.6819e-01],\n",
            "        [-1.7060e+00,  1.6146e+00,  2.1022e-02],\n",
            "        [-1.5986e+00,  1.2245e+00, -5.9986e-02],\n",
            "        [-1.4346e+00,  1.0791e-01,  8.9763e-01],\n",
            "        [-1.5863e+00,  1.0855e+00,  2.2807e-01],\n",
            "        [-1.8507e+00,  6.4217e-01,  9.7364e-01],\n",
            "        [-1.8919e+00,  1.2499e+00,  3.4063e-01],\n",
            "        [-1.4142e+00,  1.1473e+00, -1.0589e-01],\n",
            "        [-2.2144e-01,  9.5724e-02, -2.5509e-01],\n",
            "        [-1.6531e+00,  5.0845e-01,  4.9132e-01],\n",
            "        [-1.9504e+00,  4.7484e-01,  1.2084e+00],\n",
            "        [ 7.4565e-02,  2.4506e-01, -6.9154e-01],\n",
            "        [-1.8512e+00,  1.6798e+00,  7.7640e-02]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3774e+00,  1.3491e+00,  5.3384e-04],\n",
            "        [-7.9775e-01,  1.2066e+00, -4.0941e-01],\n",
            "        [-1.5110e+00,  1.1635e+00,  1.1793e-01],\n",
            "        [-1.6036e+00,  1.2292e+00,  3.6819e-01],\n",
            "        [-1.7060e+00,  1.6146e+00,  2.1022e-02],\n",
            "        [-1.5986e+00,  1.2245e+00, -5.9986e-02],\n",
            "        [-1.4346e+00,  1.0791e-01,  8.9763e-01],\n",
            "        [-1.5863e+00,  1.0855e+00,  2.2807e-01],\n",
            "        [-1.8507e+00,  6.4217e-01,  9.7364e-01],\n",
            "        [-1.8919e+00,  1.2499e+00,  3.4063e-01],\n",
            "        [-1.4142e+00,  1.1473e+00, -1.0589e-01],\n",
            "        [-2.2144e-01,  9.5724e-02, -2.5509e-01],\n",
            "        [-1.6531e+00,  5.0845e-01,  4.9132e-01],\n",
            "        [-1.9504e+00,  4.7484e-01,  1.2084e+00],\n",
            "        [ 7.4565e-02,  2.4506e-01, -6.9154e-01],\n",
            "        [-1.8512e+00,  1.6798e+00,  7.7640e-02]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5988,  1.5680,  0.0646],\n",
            "        [-1.5752,  1.5649, -0.0633],\n",
            "        [ 0.4022,  0.0264, -1.0241],\n",
            "        [ 0.5311,  0.0292, -1.0300],\n",
            "        [-1.5631,  1.4599,  0.0874],\n",
            "        [-1.7773,  0.0711,  1.0051],\n",
            "        [-1.6797,  0.1546,  1.3194],\n",
            "        [-1.5606,  0.2702,  0.9794],\n",
            "        [-1.5409,  1.2513,  0.1188],\n",
            "        [-1.3540,  0.1240,  1.3123],\n",
            "        [ 0.5269,  0.0353, -0.8276],\n",
            "        [-1.2576,  1.1312,  0.1500],\n",
            "        [ 0.4046,  0.2338, -1.0288],\n",
            "        [-1.5261,  0.8091,  0.4610],\n",
            "        [-1.5306,  1.6742, -0.1396],\n",
            "        [-1.3197,  0.0766,  1.0444]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5988,  1.5680,  0.0646],\n",
            "        [-1.5752,  1.5649, -0.0633],\n",
            "        [ 0.4022,  0.0264, -1.0241],\n",
            "        [ 0.5311,  0.0292, -1.0300],\n",
            "        [-1.5631,  1.4599,  0.0874],\n",
            "        [-1.7773,  0.0711,  1.0051],\n",
            "        [-1.6797,  0.1546,  1.3194],\n",
            "        [-1.5606,  0.2702,  0.9794],\n",
            "        [-1.5409,  1.2513,  0.1188],\n",
            "        [-1.3540,  0.1240,  1.3123],\n",
            "        [ 0.5269,  0.0353, -0.8276],\n",
            "        [-1.2576,  1.1312,  0.1500],\n",
            "        [ 0.4046,  0.2338, -1.0288],\n",
            "        [-1.5261,  0.8091,  0.4610],\n",
            "        [-1.5306,  1.6742, -0.1396],\n",
            "        [-1.3197,  0.0766,  1.0444]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4043,  1.2494, -0.2870],\n",
            "        [-1.2591,  1.5246, -0.4960],\n",
            "        [-1.3841,  1.4757, -0.0234],\n",
            "        [ 0.1490,  0.5846, -1.0174],\n",
            "        [-1.3116,  1.5400, -0.3328],\n",
            "        [-1.5310,  1.3721, -0.1189],\n",
            "        [-1.7578,  0.4535,  1.0204],\n",
            "        [-1.4642,  1.5436, -0.2853],\n",
            "        [-1.6594,  1.5158,  0.1014],\n",
            "        [-2.0253,  0.4977,  1.1990],\n",
            "        [-1.5608,  1.3536,  0.2479],\n",
            "        [ 0.3350,  0.1108, -0.9865],\n",
            "        [-1.8074,  1.9347, -0.1663],\n",
            "        [-1.4224,  1.3062, -0.1261],\n",
            "        [-1.7988,  1.3463, -0.1657],\n",
            "        [-1.7957,  1.5599,  0.3014]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4043,  1.2494, -0.2870],\n",
            "        [-1.2591,  1.5246, -0.4960],\n",
            "        [-1.3841,  1.4757, -0.0234],\n",
            "        [ 0.1490,  0.5846, -1.0174],\n",
            "        [-1.3116,  1.5400, -0.3328],\n",
            "        [-1.5310,  1.3721, -0.1189],\n",
            "        [-1.7578,  0.4535,  1.0204],\n",
            "        [-1.4642,  1.5436, -0.2853],\n",
            "        [-1.6594,  1.5158,  0.1014],\n",
            "        [-2.0253,  0.4977,  1.1990],\n",
            "        [-1.5608,  1.3536,  0.2479],\n",
            "        [ 0.3350,  0.1108, -0.9865],\n",
            "        [-1.8074,  1.9347, -0.1663],\n",
            "        [-1.4224,  1.3062, -0.1261],\n",
            "        [-1.7988,  1.3463, -0.1657],\n",
            "        [-1.7957,  1.5599,  0.3014]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 4.8773e-01,  1.6422e-01, -1.0833e+00],\n",
            "        [-1.4927e+00,  1.6104e+00, -2.3649e-01],\n",
            "        [-1.8015e+00,  6.0284e-01,  1.1438e+00],\n",
            "        [-1.6781e+00,  1.8801e-01,  1.1323e+00],\n",
            "        [ 6.7304e-02,  6.4004e-01, -1.1722e+00],\n",
            "        [-1.6747e+00,  1.5605e+00, -4.5511e-02],\n",
            "        [-2.0814e+00,  1.0671e+00,  5.2518e-01],\n",
            "        [ 5.7903e-01,  2.0316e-01, -1.1209e+00],\n",
            "        [ 1.0761e-01,  1.5193e-03, -4.6654e-01],\n",
            "        [-1.5774e+00,  4.2154e-01,  1.0876e+00],\n",
            "        [-1.9767e+00,  1.3892e+00,  1.6594e-01],\n",
            "        [-1.5845e+00,  1.5327e+00, -2.1776e-01],\n",
            "        [ 5.1207e-01,  1.9021e-02, -9.9005e-01],\n",
            "        [-1.9290e+00,  1.6697e+00,  1.0314e-01],\n",
            "        [-1.7425e+00,  1.5502e+00, -5.6260e-02],\n",
            "        [-1.8699e+00,  1.7202e+00, -1.5457e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 4.8773e-01,  1.6422e-01, -1.0833e+00],\n",
            "        [-1.4927e+00,  1.6104e+00, -2.3649e-01],\n",
            "        [-1.8015e+00,  6.0284e-01,  1.1438e+00],\n",
            "        [-1.6781e+00,  1.8801e-01,  1.1323e+00],\n",
            "        [ 6.7304e-02,  6.4004e-01, -1.1722e+00],\n",
            "        [-1.6747e+00,  1.5605e+00, -4.5511e-02],\n",
            "        [-2.0814e+00,  1.0671e+00,  5.2518e-01],\n",
            "        [ 5.7903e-01,  2.0316e-01, -1.1209e+00],\n",
            "        [ 1.0761e-01,  1.5193e-03, -4.6654e-01],\n",
            "        [-1.5774e+00,  4.2154e-01,  1.0876e+00],\n",
            "        [-1.9767e+00,  1.3892e+00,  1.6594e-01],\n",
            "        [-1.5845e+00,  1.5327e+00, -2.1776e-01],\n",
            "        [ 5.1207e-01,  1.9021e-02, -9.9005e-01],\n",
            "        [-1.9290e+00,  1.6697e+00,  1.0314e-01],\n",
            "        [-1.7425e+00,  1.5502e+00, -5.6260e-02],\n",
            "        [-1.8699e+00,  1.7202e+00, -1.5457e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8233,  1.5853, -0.2400],\n",
            "        [-0.0897, -0.0030, -0.2684],\n",
            "        [-1.5785,  1.3103, -0.0986],\n",
            "        [-1.6523,  1.7152, -0.0551],\n",
            "        [ 0.4626,  0.2669, -1.1566],\n",
            "        [-1.7576,  0.7302,  0.7963],\n",
            "        [-1.5091,  1.7236, -0.0630],\n",
            "        [-1.5714,  1.5116,  0.0774],\n",
            "        [-0.8037,  1.4487, -0.7336],\n",
            "        [-1.8365,  1.7864, -0.0411],\n",
            "        [ 0.1088,  0.3826, -0.9204],\n",
            "        [-1.2552,  1.3660, -0.2644],\n",
            "        [ 0.5141,  0.1226, -1.0923],\n",
            "        [-0.9004,  1.1758, -0.6801],\n",
            "        [-1.4886,  1.5484,  0.0172],\n",
            "        [-1.6799,  1.3891,  0.1097]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8233,  1.5853, -0.2400],\n",
            "        [-0.0897, -0.0030, -0.2684],\n",
            "        [-1.5785,  1.3103, -0.0986],\n",
            "        [-1.6523,  1.7152, -0.0551],\n",
            "        [ 0.4626,  0.2669, -1.1566],\n",
            "        [-1.7576,  0.7302,  0.7963],\n",
            "        [-1.5091,  1.7236, -0.0630],\n",
            "        [-1.5714,  1.5116,  0.0774],\n",
            "        [-0.8037,  1.4487, -0.7336],\n",
            "        [-1.8365,  1.7864, -0.0411],\n",
            "        [ 0.1088,  0.3826, -0.9204],\n",
            "        [-1.2552,  1.3660, -0.2644],\n",
            "        [ 0.5141,  0.1226, -1.0923],\n",
            "        [-0.9004,  1.1758, -0.6801],\n",
            "        [-1.4886,  1.5484,  0.0172],\n",
            "        [-1.6799,  1.3891,  0.1097]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7150e+00,  1.9257e-01,  1.3709e+00],\n",
            "        [-1.5180e+00,  1.4361e+00,  4.7035e-03],\n",
            "        [-1.6922e+00,  1.5969e+00,  9.5192e-02],\n",
            "        [ 5.2747e-01,  2.9831e-01, -1.0035e+00],\n",
            "        [-6.4880e-01,  1.3299e+00, -7.6181e-01],\n",
            "        [-1.6524e+00,  4.4935e-01,  1.1226e+00],\n",
            "        [-1.6466e+00,  1.0508e+00,  1.5383e-01],\n",
            "        [-1.0143e+00,  6.0812e-01,  3.4682e-01],\n",
            "        [ 4.3454e-01, -1.4135e-03, -6.3426e-01],\n",
            "        [-1.7497e+00,  2.7209e-01,  1.1285e+00],\n",
            "        [-1.5315e+00,  6.1458e-01,  6.3165e-01],\n",
            "        [-1.4578e+00,  1.4970e+00, -1.6539e-01],\n",
            "        [-1.5117e+00,  1.5538e+00, -2.8478e-01],\n",
            "        [-1.9282e+00,  1.6423e+00,  4.6726e-02],\n",
            "        [-1.6750e+00,  1.6799e+00, -1.5301e-01],\n",
            "        [-1.4817e+00,  1.1786e+00,  4.0410e-02]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7150e+00,  1.9257e-01,  1.3709e+00],\n",
            "        [-1.5180e+00,  1.4361e+00,  4.7035e-03],\n",
            "        [-1.6922e+00,  1.5969e+00,  9.5192e-02],\n",
            "        [ 5.2747e-01,  2.9831e-01, -1.0035e+00],\n",
            "        [-6.4880e-01,  1.3299e+00, -7.6181e-01],\n",
            "        [-1.6524e+00,  4.4935e-01,  1.1226e+00],\n",
            "        [-1.6466e+00,  1.0508e+00,  1.5383e-01],\n",
            "        [-1.0143e+00,  6.0812e-01,  3.4682e-01],\n",
            "        [ 4.3454e-01, -1.4135e-03, -6.3426e-01],\n",
            "        [-1.7497e+00,  2.7209e-01,  1.1285e+00],\n",
            "        [-1.5315e+00,  6.1458e-01,  6.3165e-01],\n",
            "        [-1.4578e+00,  1.4970e+00, -1.6539e-01],\n",
            "        [-1.5117e+00,  1.5538e+00, -2.8478e-01],\n",
            "        [-1.9282e+00,  1.6423e+00,  4.6726e-02],\n",
            "        [-1.6750e+00,  1.6799e+00, -1.5301e-01],\n",
            "        [-1.4817e+00,  1.1786e+00,  4.0410e-02]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7328,  1.5762, -0.1616],\n",
            "        [-1.9475,  0.5378,  1.0089],\n",
            "        [ 0.3842,  0.2028, -1.1508],\n",
            "        [-0.1035,  0.6140, -0.9635],\n",
            "        [-1.6605,  0.4435,  1.2957],\n",
            "        [-1.8641,  0.2681,  1.0046],\n",
            "        [-1.5915,  1.5485, -0.1697],\n",
            "        [-1.7948,  1.5642, -0.1639],\n",
            "        [-1.6278,  1.6994, -0.1636],\n",
            "        [-1.5591,  0.7203,  0.6920],\n",
            "        [-1.0753,  0.2821,  0.6671],\n",
            "        [ 0.3960,  0.1171, -1.0726],\n",
            "        [-1.9128,  1.3134,  0.1784],\n",
            "        [-1.4533,  1.4374,  0.0281],\n",
            "        [-1.9593,  1.8695, -0.2747],\n",
            "        [-1.7809,  0.8938,  0.7059]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7328,  1.5762, -0.1616],\n",
            "        [-1.9475,  0.5378,  1.0089],\n",
            "        [ 0.3842,  0.2028, -1.1508],\n",
            "        [-0.1035,  0.6140, -0.9635],\n",
            "        [-1.6605,  0.4435,  1.2957],\n",
            "        [-1.8641,  0.2681,  1.0046],\n",
            "        [-1.5915,  1.5485, -0.1697],\n",
            "        [-1.7948,  1.5642, -0.1639],\n",
            "        [-1.6278,  1.6994, -0.1636],\n",
            "        [-1.5591,  0.7203,  0.6920],\n",
            "        [-1.0753,  0.2821,  0.6671],\n",
            "        [ 0.3960,  0.1171, -1.0726],\n",
            "        [-1.9128,  1.3134,  0.1784],\n",
            "        [-1.4533,  1.4374,  0.0281],\n",
            "        [-1.9593,  1.8695, -0.2747],\n",
            "        [-1.7809,  0.8938,  0.7059]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6874,  1.3671, -0.0529],\n",
            "        [-1.5714,  1.0241,  0.4602],\n",
            "        [-1.5468,  1.3847,  0.0306],\n",
            "        [ 0.1093,  0.6923, -1.1097],\n",
            "        [-1.7733,  1.6817, -0.0114],\n",
            "        [-1.7240,  1.5835, -0.2228],\n",
            "        [-1.7645,  1.8581, -0.1797],\n",
            "        [-1.4764,  1.4517, -0.2929],\n",
            "        [-1.6984,  0.3202,  1.2562],\n",
            "        [-1.7267,  1.7542, -0.1494],\n",
            "        [-1.3487,  1.4492, -0.0354],\n",
            "        [-1.4051,  1.5084, -0.1476],\n",
            "        [-1.6308,  1.7747, -0.1390],\n",
            "        [-1.4989,  1.5906, -0.2531],\n",
            "        [-2.0568,  0.1206,  1.2602],\n",
            "        [-1.8216,  0.0473,  1.3872]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6874,  1.3671, -0.0529],\n",
            "        [-1.5714,  1.0241,  0.4602],\n",
            "        [-1.5468,  1.3847,  0.0306],\n",
            "        [ 0.1093,  0.6923, -1.1097],\n",
            "        [-1.7733,  1.6817, -0.0114],\n",
            "        [-1.7240,  1.5835, -0.2228],\n",
            "        [-1.7645,  1.8581, -0.1797],\n",
            "        [-1.4764,  1.4517, -0.2929],\n",
            "        [-1.6984,  0.3202,  1.2562],\n",
            "        [-1.7267,  1.7542, -0.1494],\n",
            "        [-1.3487,  1.4492, -0.0354],\n",
            "        [-1.4051,  1.5084, -0.1476],\n",
            "        [-1.6308,  1.7747, -0.1390],\n",
            "        [-1.4989,  1.5906, -0.2531],\n",
            "        [-2.0568,  0.1206,  1.2602],\n",
            "        [-1.8216,  0.0473,  1.3872]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7311,  0.5898,  0.8662],\n",
            "        [ 0.5266,  0.1550, -1.3046],\n",
            "        [-1.6297,  1.7281, -0.2657],\n",
            "        [-1.5576,  0.2250,  1.2206],\n",
            "        [-1.6545,  1.7696, -0.3713],\n",
            "        [-1.0636,  1.2458, -0.4840],\n",
            "        [-1.6795,  1.5764,  0.0163],\n",
            "        [-1.8507,  1.7627, -0.2870],\n",
            "        [-1.5530,  1.5347, -0.1071],\n",
            "        [-1.9723,  1.1971,  0.3440],\n",
            "        [-1.7291,  1.6095,  0.0443],\n",
            "        [-1.8327,  1.4457,  0.4624],\n",
            "        [ 0.5797,  0.4467, -1.1790],\n",
            "        [-1.9476,  0.8112,  0.7260],\n",
            "        [-1.8158,  0.2409,  1.2241],\n",
            "        [-1.8973,  1.6976,  0.0584]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7311,  0.5898,  0.8662],\n",
            "        [ 0.5266,  0.1550, -1.3046],\n",
            "        [-1.6297,  1.7281, -0.2657],\n",
            "        [-1.5576,  0.2250,  1.2206],\n",
            "        [-1.6545,  1.7696, -0.3713],\n",
            "        [-1.0636,  1.2458, -0.4840],\n",
            "        [-1.6795,  1.5764,  0.0163],\n",
            "        [-1.8507,  1.7627, -0.2870],\n",
            "        [-1.5530,  1.5347, -0.1071],\n",
            "        [-1.9723,  1.1971,  0.3440],\n",
            "        [-1.7291,  1.6095,  0.0443],\n",
            "        [-1.8327,  1.4457,  0.4624],\n",
            "        [ 0.5797,  0.4467, -1.1790],\n",
            "        [-1.9476,  0.8112,  0.7260],\n",
            "        [-1.8158,  0.2409,  1.2241],\n",
            "        [-1.8973,  1.6976,  0.0584]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7076,  1.5558,  0.0649],\n",
            "        [-1.6371,  1.0105,  0.5634],\n",
            "        [ 0.6281,  0.0285, -1.2754],\n",
            "        [-1.5233,  1.8539, -0.2733],\n",
            "        [-1.8474,  0.3642,  1.3116],\n",
            "        [-1.7396,  2.0084, -0.1413],\n",
            "        [ 0.2835,  0.0049, -1.0683],\n",
            "        [-1.4295,  1.8070, -0.1921],\n",
            "        [-1.8686,  0.3440,  1.0822],\n",
            "        [-1.7977,  0.7824,  0.7732],\n",
            "        [-1.6424,  1.8321, -0.4987],\n",
            "        [-1.5879,  1.7947, -0.4378],\n",
            "        [-1.7618,  1.8081, -0.2463],\n",
            "        [-1.7607,  0.3214,  1.2043],\n",
            "        [-1.7629,  1.7408, -0.2581],\n",
            "        [ 0.2279,  0.1734, -1.0501]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7076,  1.5558,  0.0649],\n",
            "        [-1.6371,  1.0105,  0.5634],\n",
            "        [ 0.6281,  0.0285, -1.2754],\n",
            "        [-1.5233,  1.8539, -0.2733],\n",
            "        [-1.8474,  0.3642,  1.3116],\n",
            "        [-1.7396,  2.0084, -0.1413],\n",
            "        [ 0.2835,  0.0049, -1.0683],\n",
            "        [-1.4295,  1.8070, -0.1921],\n",
            "        [-1.8686,  0.3440,  1.0822],\n",
            "        [-1.7977,  0.7824,  0.7732],\n",
            "        [-1.6424,  1.8321, -0.4987],\n",
            "        [-1.5879,  1.7947, -0.4378],\n",
            "        [-1.7618,  1.8081, -0.2463],\n",
            "        [-1.7607,  0.3214,  1.2043],\n",
            "        [-1.7629,  1.7408, -0.2581],\n",
            "        [ 0.2279,  0.1734, -1.0501]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8267,  2.0654, -0.2306],\n",
            "        [-1.8935,  1.2777,  0.6264],\n",
            "        [-1.8639,  0.3729,  1.3272],\n",
            "        [-1.7690,  1.7687, -0.3630],\n",
            "        [-1.5734,  1.8831, -0.3874],\n",
            "        [-1.7589,  1.5292, -0.0147],\n",
            "        [-1.6698,  1.2952,  0.1582],\n",
            "        [-1.6026,  1.1946,  0.3688],\n",
            "        [-1.5800,  1.8070, -0.4066],\n",
            "        [-1.5058,  1.5341, -0.2084],\n",
            "        [ 0.5299,  0.2433, -1.2581],\n",
            "        [ 0.4143,  0.3010, -1.2606],\n",
            "        [-1.8524,  1.9505, -0.2893],\n",
            "        [-1.5025,  1.7677, -0.2287],\n",
            "        [-1.6609,  1.9490, -0.2101],\n",
            "        [-1.5321,  1.7406, -0.2647]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8267,  2.0654, -0.2306],\n",
            "        [-1.8935,  1.2777,  0.6264],\n",
            "        [-1.8639,  0.3729,  1.3272],\n",
            "        [-1.7690,  1.7687, -0.3630],\n",
            "        [-1.5734,  1.8831, -0.3874],\n",
            "        [-1.7589,  1.5292, -0.0147],\n",
            "        [-1.6698,  1.2952,  0.1582],\n",
            "        [-1.6026,  1.1946,  0.3688],\n",
            "        [-1.5800,  1.8070, -0.4066],\n",
            "        [-1.5058,  1.5341, -0.2084],\n",
            "        [ 0.5299,  0.2433, -1.2581],\n",
            "        [ 0.4143,  0.3010, -1.2606],\n",
            "        [-1.8524,  1.9505, -0.2893],\n",
            "        [-1.5025,  1.7677, -0.2287],\n",
            "        [-1.6609,  1.9490, -0.2101],\n",
            "        [-1.5321,  1.7406, -0.2647]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5760,  1.9634, -0.4918],\n",
            "        [-1.7606,  0.1933,  1.3688],\n",
            "        [ 0.4631,  0.2449, -1.0974],\n",
            "        [-1.6604,  1.7649, -0.2444],\n",
            "        [-1.3827,  1.6952, -0.4434],\n",
            "        [-1.8244,  1.7652, -0.1679],\n",
            "        [-1.5448,  1.6591, -0.2488],\n",
            "        [-1.7154,  0.1331,  1.2778],\n",
            "        [-1.6618,  1.8567, -0.3953],\n",
            "        [-1.7075,  0.4956,  1.0923],\n",
            "        [-1.7538,  1.7859, -0.0837],\n",
            "        [-1.6498,  1.8411, -0.1859],\n",
            "        [ 0.4508,  0.2071, -1.0559],\n",
            "        [-1.8047,  0.4381,  1.0016],\n",
            "        [-1.6646,  1.8217, -0.6678],\n",
            "        [-1.8605,  0.2523,  1.4498]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5760,  1.9634, -0.4918],\n",
            "        [-1.7606,  0.1933,  1.3688],\n",
            "        [ 0.4631,  0.2449, -1.0974],\n",
            "        [-1.6604,  1.7649, -0.2444],\n",
            "        [-1.3827,  1.6952, -0.4434],\n",
            "        [-1.8244,  1.7652, -0.1679],\n",
            "        [-1.5448,  1.6591, -0.2488],\n",
            "        [-1.7154,  0.1331,  1.2778],\n",
            "        [-1.6618,  1.8567, -0.3953],\n",
            "        [-1.7075,  0.4956,  1.0923],\n",
            "        [-1.7538,  1.7859, -0.0837],\n",
            "        [-1.6498,  1.8411, -0.1859],\n",
            "        [ 0.4508,  0.2071, -1.0559],\n",
            "        [-1.8047,  0.4381,  1.0016],\n",
            "        [-1.6646,  1.8217, -0.6678],\n",
            "        [-1.8605,  0.2523,  1.4498]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-9.4157e-01,  1.3919e+00, -8.2194e-01],\n",
            "        [-1.6483e+00,  2.1630e-01,  1.4804e+00],\n",
            "        [ 3.6638e-01,  2.1032e-01, -1.2299e+00],\n",
            "        [ 2.9982e-01,  3.1770e-01, -1.1921e+00],\n",
            "        [-1.7567e+00,  1.1956e+00,  5.7104e-01],\n",
            "        [-1.5920e+00,  1.6880e+00,  1.9019e-04],\n",
            "        [-1.9195e+00,  1.1301e+00,  6.0801e-01],\n",
            "        [-5.2892e-01,  3.0229e-01, -1.1621e-01],\n",
            "        [-1.0180e+00,  1.4688e+00, -6.5472e-01],\n",
            "        [-1.6874e+00,  4.2598e-02,  1.3475e+00],\n",
            "        [-1.1342e-01,  1.1230e-01, -5.7489e-01],\n",
            "        [-1.6313e+00,  2.0450e-01,  1.2058e+00],\n",
            "        [ 3.4800e-01,  3.5607e-01, -1.2233e+00],\n",
            "        [-1.9076e+00,  1.1515e+00,  6.0455e-01],\n",
            "        [-1.6822e+00,  2.0365e+00, -3.2051e-01],\n",
            "        [ 3.5212e-01,  2.8074e-01, -1.2400e+00]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-9.4157e-01,  1.3919e+00, -8.2194e-01],\n",
            "        [-1.6483e+00,  2.1630e-01,  1.4804e+00],\n",
            "        [ 3.6638e-01,  2.1032e-01, -1.2299e+00],\n",
            "        [ 2.9982e-01,  3.1770e-01, -1.1921e+00],\n",
            "        [-1.7567e+00,  1.1956e+00,  5.7104e-01],\n",
            "        [-1.5920e+00,  1.6880e+00,  1.9019e-04],\n",
            "        [-1.9195e+00,  1.1301e+00,  6.0801e-01],\n",
            "        [-5.2892e-01,  3.0229e-01, -1.1621e-01],\n",
            "        [-1.0180e+00,  1.4688e+00, -6.5472e-01],\n",
            "        [-1.6874e+00,  4.2598e-02,  1.3475e+00],\n",
            "        [-1.1342e-01,  1.1230e-01, -5.7489e-01],\n",
            "        [-1.6313e+00,  2.0450e-01,  1.2058e+00],\n",
            "        [ 3.4800e-01,  3.5607e-01, -1.2233e+00],\n",
            "        [-1.9076e+00,  1.1515e+00,  6.0455e-01],\n",
            "        [-1.6822e+00,  2.0365e+00, -3.2051e-01],\n",
            "        [ 3.5212e-01,  2.8074e-01, -1.2400e+00]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7344,  1.7751,  0.1480],\n",
            "        [-1.9432,  0.3059,  1.1133],\n",
            "        [-2.0526,  1.1942,  0.4277],\n",
            "        [ 0.5701,  0.4018, -1.2777],\n",
            "        [-1.6665,  0.7124,  0.7488],\n",
            "        [ 0.4891,  0.3204, -1.2989],\n",
            "        [-1.6684,  0.2439,  1.2760],\n",
            "        [-1.9982,  0.5700,  1.0685],\n",
            "        [-1.5895,  1.6957, -0.2906],\n",
            "        [-1.5937,  1.9984, -0.4099],\n",
            "        [-1.8677,  2.1438, -0.4215],\n",
            "        [ 0.1258,  0.4307, -1.0312],\n",
            "        [-1.6125,  1.8556, -0.4511],\n",
            "        [-1.5394,  1.9095, -0.3933],\n",
            "        [-1.8037,  2.1181, -0.2575],\n",
            "        [ 0.2713,  0.6176, -1.1831]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7344,  1.7751,  0.1480],\n",
            "        [-1.9432,  0.3059,  1.1133],\n",
            "        [-2.0526,  1.1942,  0.4277],\n",
            "        [ 0.5701,  0.4018, -1.2777],\n",
            "        [-1.6665,  0.7124,  0.7488],\n",
            "        [ 0.4891,  0.3204, -1.2989],\n",
            "        [-1.6684,  0.2439,  1.2760],\n",
            "        [-1.9982,  0.5700,  1.0685],\n",
            "        [-1.5895,  1.6957, -0.2906],\n",
            "        [-1.5937,  1.9984, -0.4099],\n",
            "        [-1.8677,  2.1438, -0.4215],\n",
            "        [ 0.1258,  0.4307, -1.0312],\n",
            "        [-1.6125,  1.8556, -0.4511],\n",
            "        [-1.5394,  1.9095, -0.3933],\n",
            "        [-1.8037,  2.1181, -0.2575],\n",
            "        [ 0.2713,  0.6176, -1.1831]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4884,  1.7074, -0.1277],\n",
            "        [ 0.3758,  0.2596, -1.3442],\n",
            "        [-1.7574,  0.5762,  1.0470],\n",
            "        [ 0.4303,  0.3631, -1.2397],\n",
            "        [-0.5585,  0.1059,  0.0064],\n",
            "        [-1.9498,  0.3662,  1.2487],\n",
            "        [-1.8099,  1.7121, -0.0621],\n",
            "        [-1.8930,  0.2391,  1.1967],\n",
            "        [-1.5762,  0.9048,  0.6212],\n",
            "        [-1.5037,  0.2562,  1.4114],\n",
            "        [-1.5182,  0.3954,  0.9144],\n",
            "        [-1.4667,  1.7550, -0.3375],\n",
            "        [ 0.2841,  0.7290, -1.2488],\n",
            "        [-1.8384,  0.8699,  0.8383],\n",
            "        [-1.7140,  1.0359,  0.6878],\n",
            "        [-1.7332,  2.0534, -0.6849]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4884,  1.7074, -0.1277],\n",
            "        [ 0.3758,  0.2596, -1.3442],\n",
            "        [-1.7574,  0.5762,  1.0470],\n",
            "        [ 0.4303,  0.3631, -1.2397],\n",
            "        [-0.5585,  0.1059,  0.0064],\n",
            "        [-1.9498,  0.3662,  1.2487],\n",
            "        [-1.8099,  1.7121, -0.0621],\n",
            "        [-1.8930,  0.2391,  1.1967],\n",
            "        [-1.5762,  0.9048,  0.6212],\n",
            "        [-1.5037,  0.2562,  1.4114],\n",
            "        [-1.5182,  0.3954,  0.9144],\n",
            "        [-1.4667,  1.7550, -0.3375],\n",
            "        [ 0.2841,  0.7290, -1.2488],\n",
            "        [-1.8384,  0.8699,  0.8383],\n",
            "        [-1.7140,  1.0359,  0.6878],\n",
            "        [-1.7332,  2.0534, -0.6849]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8291,  1.5084, -0.1764],\n",
            "        [-1.7540,  1.8619, -0.4229],\n",
            "        [ 0.3745,  0.4795, -1.0420],\n",
            "        [-1.7794, -0.0788,  1.2069],\n",
            "        [-0.0294,  0.4591, -0.9194],\n",
            "        [-1.7717,  0.9341,  0.2690],\n",
            "        [-1.6508,  0.3429,  1.0282],\n",
            "        [-1.4407,  1.9834, -0.4440],\n",
            "        [-1.8413,  0.1124,  1.2972],\n",
            "        [-1.6353,  2.0659, -0.5176],\n",
            "        [-0.7281,  1.1605, -0.4750],\n",
            "        [-1.7183,  2.0978, -0.5473],\n",
            "        [-1.4878,  1.5330, -0.1593],\n",
            "        [-1.6564,  2.0000, -0.3361],\n",
            "        [-1.5350,  0.2063,  1.3498],\n",
            "        [-1.7023,  1.9929, -0.3875]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8291,  1.5084, -0.1764],\n",
            "        [-1.7540,  1.8619, -0.4229],\n",
            "        [ 0.3745,  0.4795, -1.0420],\n",
            "        [-1.7794, -0.0788,  1.2069],\n",
            "        [-0.0294,  0.4591, -0.9194],\n",
            "        [-1.7717,  0.9341,  0.2690],\n",
            "        [-1.6508,  0.3429,  1.0282],\n",
            "        [-1.4407,  1.9834, -0.4440],\n",
            "        [-1.8413,  0.1124,  1.2972],\n",
            "        [-1.6353,  2.0659, -0.5176],\n",
            "        [-0.7281,  1.1605, -0.4750],\n",
            "        [-1.7183,  2.0978, -0.5473],\n",
            "        [-1.4878,  1.5330, -0.1593],\n",
            "        [-1.6564,  2.0000, -0.3361],\n",
            "        [-1.5350,  0.2063,  1.3498],\n",
            "        [-1.7023,  1.9929, -0.3875]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3268,  0.4995, -1.1391],\n",
            "        [-1.8351,  0.0069,  1.2039],\n",
            "        [-1.9394,  1.4339,  0.3483],\n",
            "        [ 0.4293,  0.3908, -1.2064],\n",
            "        [-1.1238,  0.1451,  0.5848],\n",
            "        [-1.9124,  1.0508,  0.5804],\n",
            "        [-1.5362,  1.4065,  0.0348],\n",
            "        [-1.7427,  2.0852, -0.2102],\n",
            "        [-1.6514,  2.0050, -0.4907],\n",
            "        [-1.9576,  1.0869,  0.4012],\n",
            "        [-1.5804,  0.1312,  1.2399],\n",
            "        [-1.8895,  1.3702,  0.1606],\n",
            "        [ 0.3761,  0.4053, -1.3211],\n",
            "        [-1.4869,  1.6654, -0.3208],\n",
            "        [ 0.3916,  0.3057, -1.1212],\n",
            "        [-1.4866,  1.7664, -0.4643]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.3268,  0.4995, -1.1391],\n",
            "        [-1.8351,  0.0069,  1.2039],\n",
            "        [-1.9394,  1.4339,  0.3483],\n",
            "        [ 0.4293,  0.3908, -1.2064],\n",
            "        [-1.1238,  0.1451,  0.5848],\n",
            "        [-1.9124,  1.0508,  0.5804],\n",
            "        [-1.5362,  1.4065,  0.0348],\n",
            "        [-1.7427,  2.0852, -0.2102],\n",
            "        [-1.6514,  2.0050, -0.4907],\n",
            "        [-1.9576,  1.0869,  0.4012],\n",
            "        [-1.5804,  0.1312,  1.2399],\n",
            "        [-1.8895,  1.3702,  0.1606],\n",
            "        [ 0.3761,  0.4053, -1.3211],\n",
            "        [-1.4869,  1.6654, -0.3208],\n",
            "        [ 0.3916,  0.3057, -1.1212],\n",
            "        [-1.4866,  1.7664, -0.4643]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.4618,  0.2711, -1.2033],\n",
            "        [ 0.0656,  0.7318, -1.2364],\n",
            "        [-1.8276,  0.3257,  1.5009],\n",
            "        [-1.4061,  1.6870, -0.5433],\n",
            "        [-1.7186,  0.0960,  1.3970],\n",
            "        [-1.6558,  1.7715, -0.0954],\n",
            "        [-1.5053,  0.2717,  1.0541],\n",
            "        [-1.7960,  1.6246, -0.0025],\n",
            "        [-1.7196,  0.3246,  1.0859],\n",
            "        [-1.7400,  1.9606, -0.6798],\n",
            "        [-1.6387,  0.9039,  0.3892],\n",
            "        [-1.7625,  2.1095, -0.4555],\n",
            "        [-1.7633,  0.4569,  0.8263],\n",
            "        [-1.4292,  1.7330, -0.2070],\n",
            "        [-1.7531,  0.5397,  1.1362],\n",
            "        [-1.4066,  1.8334, -0.7235]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.4618,  0.2711, -1.2033],\n",
            "        [ 0.0656,  0.7318, -1.2364],\n",
            "        [-1.8276,  0.3257,  1.5009],\n",
            "        [-1.4061,  1.6870, -0.5433],\n",
            "        [-1.7186,  0.0960,  1.3970],\n",
            "        [-1.6558,  1.7715, -0.0954],\n",
            "        [-1.5053,  0.2717,  1.0541],\n",
            "        [-1.7960,  1.6246, -0.0025],\n",
            "        [-1.7196,  0.3246,  1.0859],\n",
            "        [-1.7400,  1.9606, -0.6798],\n",
            "        [-1.6387,  0.9039,  0.3892],\n",
            "        [-1.7625,  2.1095, -0.4555],\n",
            "        [-1.7633,  0.4569,  0.8263],\n",
            "        [-1.4292,  1.7330, -0.2070],\n",
            "        [-1.7531,  0.5397,  1.1362],\n",
            "        [-1.4066,  1.8334, -0.7235]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3332,  0.3996, -1.2178],\n",
            "        [-1.3170,  1.6801, -0.5940],\n",
            "        [-1.6009,  1.8679, -0.5332],\n",
            "        [-1.6233,  0.8114,  0.8550],\n",
            "        [-1.7701,  2.1166, -0.5588],\n",
            "        [-1.7558,  1.7748, -0.0676],\n",
            "        [-1.7828,  0.0427,  1.5107],\n",
            "        [-1.5031,  1.6432, -0.4736],\n",
            "        [-1.8377,  0.1331,  1.2141],\n",
            "        [-1.7836,  1.6418, -0.1155],\n",
            "        [-1.6888,  1.9668, -0.5007],\n",
            "        [-1.6967, -0.0426,  1.3690],\n",
            "        [-1.5707,  0.3616,  0.8760],\n",
            "        [ 0.5618,  0.3189, -1.3209],\n",
            "        [-1.7482,  0.3832,  1.1861],\n",
            "        [-1.7737,  1.7628, -0.2543]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.3332,  0.3996, -1.2178],\n",
            "        [-1.3170,  1.6801, -0.5940],\n",
            "        [-1.6009,  1.8679, -0.5332],\n",
            "        [-1.6233,  0.8114,  0.8550],\n",
            "        [-1.7701,  2.1166, -0.5588],\n",
            "        [-1.7558,  1.7748, -0.0676],\n",
            "        [-1.7828,  0.0427,  1.5107],\n",
            "        [-1.5031,  1.6432, -0.4736],\n",
            "        [-1.8377,  0.1331,  1.2141],\n",
            "        [-1.7836,  1.6418, -0.1155],\n",
            "        [-1.6888,  1.9668, -0.5007],\n",
            "        [-1.6967, -0.0426,  1.3690],\n",
            "        [-1.5707,  0.3616,  0.8760],\n",
            "        [ 0.5618,  0.3189, -1.3209],\n",
            "        [-1.7482,  0.3832,  1.1861],\n",
            "        [-1.7737,  1.7628, -0.2543]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5296,  0.2119, -1.1879],\n",
            "        [-1.5975,  2.0142, -0.5254],\n",
            "        [-1.6831,  0.6012,  0.9468],\n",
            "        [-1.5535,  1.9735, -0.3223],\n",
            "        [-1.5850,  1.9472, -0.3468],\n",
            "        [-1.7444,  2.0428, -0.4787],\n",
            "        [-1.6131,  1.8681, -0.5985],\n",
            "        [-1.4223,  1.7962, -0.5601],\n",
            "        [-1.6250,  1.1963,  0.3523],\n",
            "        [-1.2185,  0.2143,  0.8481],\n",
            "        [-1.7560,  1.7918, -0.5102],\n",
            "        [-1.3069,  1.5724, -0.4184],\n",
            "        [ 0.4152,  0.3225, -1.1918],\n",
            "        [-1.5949,  2.0721, -0.4511],\n",
            "        [-1.5583,  2.0117, -0.4593],\n",
            "        [-1.2694,  0.5390,  0.5780]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.5296,  0.2119, -1.1879],\n",
            "        [-1.5975,  2.0142, -0.5254],\n",
            "        [-1.6831,  0.6012,  0.9468],\n",
            "        [-1.5535,  1.9735, -0.3223],\n",
            "        [-1.5850,  1.9472, -0.3468],\n",
            "        [-1.7444,  2.0428, -0.4787],\n",
            "        [-1.6131,  1.8681, -0.5985],\n",
            "        [-1.4223,  1.7962, -0.5601],\n",
            "        [-1.6250,  1.1963,  0.3523],\n",
            "        [-1.2185,  0.2143,  0.8481],\n",
            "        [-1.7560,  1.7918, -0.5102],\n",
            "        [-1.3069,  1.5724, -0.4184],\n",
            "        [ 0.4152,  0.3225, -1.1918],\n",
            "        [-1.5949,  2.0721, -0.4511],\n",
            "        [-1.5583,  2.0117, -0.4593],\n",
            "        [-1.2694,  0.5390,  0.5780]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0455,  1.7517, -0.1057],\n",
            "        [-1.3567,  0.3624,  0.6882],\n",
            "        [-1.7377,  1.5535, -0.0970],\n",
            "        [-1.5010,  1.7754, -0.5566],\n",
            "        [-1.5834,  0.0954,  1.0683],\n",
            "        [-1.2902,  1.6895, -0.7779],\n",
            "        [-1.6051,  0.2689,  1.2094],\n",
            "        [-1.4664,  1.7624, -0.4038],\n",
            "        [ 0.4325,  0.1185, -1.0598],\n",
            "        [-1.4583, -0.1061,  1.6323],\n",
            "        [-1.5830,  1.4911,  0.1335],\n",
            "        [-1.5047,  0.2328,  1.2433],\n",
            "        [-1.4471,  1.5972, -0.4202],\n",
            "        [-1.5451,  0.6308,  0.9527],\n",
            "        [ 0.3257,  0.3478, -1.0497],\n",
            "        [ 0.4359,  0.0788, -1.2347]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0455,  1.7517, -0.1057],\n",
            "        [-1.3567,  0.3624,  0.6882],\n",
            "        [-1.7377,  1.5535, -0.0970],\n",
            "        [-1.5010,  1.7754, -0.5566],\n",
            "        [-1.5834,  0.0954,  1.0683],\n",
            "        [-1.2902,  1.6895, -0.7779],\n",
            "        [-1.6051,  0.2689,  1.2094],\n",
            "        [-1.4664,  1.7624, -0.4038],\n",
            "        [ 0.4325,  0.1185, -1.0598],\n",
            "        [-1.4583, -0.1061,  1.6323],\n",
            "        [-1.5830,  1.4911,  0.1335],\n",
            "        [-1.5047,  0.2328,  1.2433],\n",
            "        [-1.4471,  1.5972, -0.4202],\n",
            "        [-1.5451,  0.6308,  0.9527],\n",
            "        [ 0.3257,  0.3478, -1.0497],\n",
            "        [ 0.4359,  0.0788, -1.2347]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6172,  0.1944,  1.2180],\n",
            "        [ 0.4446,  0.1177, -1.1033],\n",
            "        [-1.8686,  1.7087, -0.0927],\n",
            "        [-1.4338,  1.4766, -0.3710],\n",
            "        [-0.2094, -0.0071, -0.1716],\n",
            "        [-1.9076,  1.1429,  0.4563],\n",
            "        [ 0.4066,  0.2254, -1.0137],\n",
            "        [-1.3551,  1.8189, -0.8570],\n",
            "        [-1.5505,  0.6173,  0.8632],\n",
            "        [-1.5619,  0.5465,  0.8732],\n",
            "        [-1.4881, -0.0376,  1.4196],\n",
            "        [-0.1925,  0.6817, -1.1089],\n",
            "        [-1.4331,  1.5646, -0.5353],\n",
            "        [-1.4192,  0.2314,  1.1404],\n",
            "        [ 0.3664,  0.3409, -1.0644],\n",
            "        [ 0.4407,  0.2537, -1.2345]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6172,  0.1944,  1.2180],\n",
            "        [ 0.4446,  0.1177, -1.1033],\n",
            "        [-1.8686,  1.7087, -0.0927],\n",
            "        [-1.4338,  1.4766, -0.3710],\n",
            "        [-0.2094, -0.0071, -0.1716],\n",
            "        [-1.9076,  1.1429,  0.4563],\n",
            "        [ 0.4066,  0.2254, -1.0137],\n",
            "        [-1.3551,  1.8189, -0.8570],\n",
            "        [-1.5505,  0.6173,  0.8632],\n",
            "        [-1.5619,  0.5465,  0.8732],\n",
            "        [-1.4881, -0.0376,  1.4196],\n",
            "        [-0.1925,  0.6817, -1.1089],\n",
            "        [-1.4331,  1.5646, -0.5353],\n",
            "        [-1.4192,  0.2314,  1.1404],\n",
            "        [ 0.3664,  0.3409, -1.0644],\n",
            "        [ 0.4407,  0.2537, -1.2345]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5480e+00,  8.0399e-02,  1.2795e+00],\n",
            "        [-1.3190e+00,  1.7067e+00, -6.6505e-01],\n",
            "        [-1.5539e+00, -1.3599e-05,  1.3107e+00],\n",
            "        [-1.5152e+00,  1.8256e+00, -4.0869e-01],\n",
            "        [-1.5138e+00,  1.7773e+00, -9.8601e-02],\n",
            "        [-1.1009e+00,  9.0198e-01,  3.6408e-01],\n",
            "        [-1.4788e+00,  1.3133e-01,  1.0347e+00],\n",
            "        [-1.5636e+00,  1.8608e+00, -3.1653e-01],\n",
            "        [-1.5647e+00,  1.9193e+00, -4.9791e-01],\n",
            "        [-1.6009e+00,  4.4207e-01,  1.0252e+00],\n",
            "        [-1.5083e+00,  2.7256e-02,  1.4077e+00],\n",
            "        [-1.5195e+00,  3.6334e-02,  1.3258e+00],\n",
            "        [-1.3169e+00,  1.9627e+00, -5.6433e-01],\n",
            "        [-1.3254e+00,  6.7057e-01,  5.2465e-01],\n",
            "        [-1.7249e+00,  4.0823e-01,  1.1774e+00],\n",
            "        [ 3.0789e-01,  3.3249e-01, -9.0281e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5480e+00,  8.0399e-02,  1.2795e+00],\n",
            "        [-1.3190e+00,  1.7067e+00, -6.6505e-01],\n",
            "        [-1.5539e+00, -1.3599e-05,  1.3107e+00],\n",
            "        [-1.5152e+00,  1.8256e+00, -4.0869e-01],\n",
            "        [-1.5138e+00,  1.7773e+00, -9.8601e-02],\n",
            "        [-1.1009e+00,  9.0198e-01,  3.6408e-01],\n",
            "        [-1.4788e+00,  1.3133e-01,  1.0347e+00],\n",
            "        [-1.5636e+00,  1.8608e+00, -3.1653e-01],\n",
            "        [-1.5647e+00,  1.9193e+00, -4.9791e-01],\n",
            "        [-1.6009e+00,  4.4207e-01,  1.0252e+00],\n",
            "        [-1.5083e+00,  2.7256e-02,  1.4077e+00],\n",
            "        [-1.5195e+00,  3.6334e-02,  1.3258e+00],\n",
            "        [-1.3169e+00,  1.9627e+00, -5.6433e-01],\n",
            "        [-1.3254e+00,  6.7057e-01,  5.2465e-01],\n",
            "        [-1.7249e+00,  4.0823e-01,  1.1774e+00],\n",
            "        [ 3.0789e-01,  3.3249e-01, -9.0281e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6022, -0.0079,  1.2913],\n",
            "        [-1.6367,  0.5067,  1.2925],\n",
            "        [-1.7108,  0.0741,  1.5814],\n",
            "        [-1.2131,  1.7320, -0.4419],\n",
            "        [-1.5802,  1.5819,  0.1510],\n",
            "        [-1.2447,  0.9315, -0.0026],\n",
            "        [-1.5440, -0.0329,  1.1443],\n",
            "        [ 0.4988,  0.1312, -1.0523],\n",
            "        [-1.5362,  1.8466, -0.5458],\n",
            "        [ 0.2623,  0.1479, -1.0326],\n",
            "        [-1.5438,  1.9437, -0.5595],\n",
            "        [-1.9753,  0.2002,  1.3399],\n",
            "        [-1.5707, -0.0166,  1.3200],\n",
            "        [-1.5164,  0.4713,  0.7562],\n",
            "        [-1.4777,  1.3952, -0.5793],\n",
            "        [-1.5926,  0.0746,  1.4086]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6022, -0.0079,  1.2913],\n",
            "        [-1.6367,  0.5067,  1.2925],\n",
            "        [-1.7108,  0.0741,  1.5814],\n",
            "        [-1.2131,  1.7320, -0.4419],\n",
            "        [-1.5802,  1.5819,  0.1510],\n",
            "        [-1.2447,  0.9315, -0.0026],\n",
            "        [-1.5440, -0.0329,  1.1443],\n",
            "        [ 0.4988,  0.1312, -1.0523],\n",
            "        [-1.5362,  1.8466, -0.5458],\n",
            "        [ 0.2623,  0.1479, -1.0326],\n",
            "        [-1.5438,  1.9437, -0.5595],\n",
            "        [-1.9753,  0.2002,  1.3399],\n",
            "        [-1.5707, -0.0166,  1.3200],\n",
            "        [-1.5164,  0.4713,  0.7562],\n",
            "        [-1.4777,  1.3952, -0.5793],\n",
            "        [-1.5926,  0.0746,  1.4086]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4864,  1.5780, -0.2805],\n",
            "        [-1.4768,  1.7481, -0.1462],\n",
            "        [ 0.5578,  0.2706, -1.0826],\n",
            "        [-1.2333,  1.2709,  0.1100],\n",
            "        [-0.9817,  0.4337,  0.4984],\n",
            "        [-1.4584,  1.4617,  0.1032],\n",
            "        [-1.6388, -0.0541,  1.1293],\n",
            "        [-1.6030,  1.1728,  0.4252],\n",
            "        [-1.6858,  0.7465,  0.4658],\n",
            "        [-1.3282,  1.4717, -0.1853],\n",
            "        [ 0.2255,  0.1354, -0.9134],\n",
            "        [-1.4001,  1.6662, -0.5434],\n",
            "        [-1.5070,  0.2024,  1.3587],\n",
            "        [-1.4015,  1.6788, -0.2746],\n",
            "        [-1.5008,  1.5120, -0.4240],\n",
            "        [ 0.3393,  0.1116, -0.7732]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4864,  1.5780, -0.2805],\n",
            "        [-1.4768,  1.7481, -0.1462],\n",
            "        [ 0.5578,  0.2706, -1.0826],\n",
            "        [-1.2333,  1.2709,  0.1100],\n",
            "        [-0.9817,  0.4337,  0.4984],\n",
            "        [-1.4584,  1.4617,  0.1032],\n",
            "        [-1.6388, -0.0541,  1.1293],\n",
            "        [-1.6030,  1.1728,  0.4252],\n",
            "        [-1.6858,  0.7465,  0.4658],\n",
            "        [-1.3282,  1.4717, -0.1853],\n",
            "        [ 0.2255,  0.1354, -0.9134],\n",
            "        [-1.4001,  1.6662, -0.5434],\n",
            "        [-1.5070,  0.2024,  1.3587],\n",
            "        [-1.4015,  1.6788, -0.2746],\n",
            "        [-1.5008,  1.5120, -0.4240],\n",
            "        [ 0.3393,  0.1116, -0.7732]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3203,  0.1427,  1.3337],\n",
            "        [-1.7396,  0.3815,  1.1404],\n",
            "        [ 0.5136,  0.2786, -1.2197],\n",
            "        [-1.6912,  0.2618,  1.0688],\n",
            "        [-1.0565,  1.3968, -0.1228],\n",
            "        [-1.5587,  1.9296, -0.4756],\n",
            "        [-1.5210,  1.3617,  0.1213],\n",
            "        [-1.5286,  0.9792,  0.2246],\n",
            "        [-1.6613,  0.8485,  0.6723],\n",
            "        [-1.0946,  1.4610, -0.1646],\n",
            "        [-0.8187,  1.4076, -1.1329],\n",
            "        [-1.4674,  1.7325, -0.7461],\n",
            "        [-1.1103,  1.3574, -0.5478],\n",
            "        [ 0.5368,  0.1302, -1.2082],\n",
            "        [-1.4583,  1.0972,  0.2062],\n",
            "        [-1.4884,  0.2517,  1.1783]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3203,  0.1427,  1.3337],\n",
            "        [-1.7396,  0.3815,  1.1404],\n",
            "        [ 0.5136,  0.2786, -1.2197],\n",
            "        [-1.6912,  0.2618,  1.0688],\n",
            "        [-1.0565,  1.3968, -0.1228],\n",
            "        [-1.5587,  1.9296, -0.4756],\n",
            "        [-1.5210,  1.3617,  0.1213],\n",
            "        [-1.5286,  0.9792,  0.2246],\n",
            "        [-1.6613,  0.8485,  0.6723],\n",
            "        [-1.0946,  1.4610, -0.1646],\n",
            "        [-0.8187,  1.4076, -1.1329],\n",
            "        [-1.4674,  1.7325, -0.7461],\n",
            "        [-1.1103,  1.3574, -0.5478],\n",
            "        [ 0.5368,  0.1302, -1.2082],\n",
            "        [-1.4583,  1.0972,  0.2062],\n",
            "        [-1.4884,  0.2517,  1.1783]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5833,  1.4680, -0.2106],\n",
            "        [-1.4256,  1.7487, -0.3193],\n",
            "        [-1.2177,  1.6745, -0.4403],\n",
            "        [-1.5692,  1.6454, -0.2117],\n",
            "        [-1.0790,  1.6855, -0.4410],\n",
            "        [-1.4926,  1.1514,  0.2438],\n",
            "        [-1.3616,  1.6332, -0.3906],\n",
            "        [-1.1601,  1.2425, -0.1504],\n",
            "        [-1.5607,  1.3860, -0.1479],\n",
            "        [-1.2913,  1.9167, -0.6567],\n",
            "        [-0.6328,  0.7750, -0.4580],\n",
            "        [-1.1937,  1.5183, -0.4768],\n",
            "        [ 0.4622,  0.0805, -1.0238],\n",
            "        [-1.1215,  1.5936, -0.6052],\n",
            "        [-1.4579,  1.1679,  0.0485],\n",
            "        [-0.8252,  0.2151,  0.3894]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5833,  1.4680, -0.2106],\n",
            "        [-1.4256,  1.7487, -0.3193],\n",
            "        [-1.2177,  1.6745, -0.4403],\n",
            "        [-1.5692,  1.6454, -0.2117],\n",
            "        [-1.0790,  1.6855, -0.4410],\n",
            "        [-1.4926,  1.1514,  0.2438],\n",
            "        [-1.3616,  1.6332, -0.3906],\n",
            "        [-1.1601,  1.2425, -0.1504],\n",
            "        [-1.5607,  1.3860, -0.1479],\n",
            "        [-1.2913,  1.9167, -0.6567],\n",
            "        [-0.6328,  0.7750, -0.4580],\n",
            "        [-1.1937,  1.5183, -0.4768],\n",
            "        [ 0.4622,  0.0805, -1.0238],\n",
            "        [-1.1215,  1.5936, -0.6052],\n",
            "        [-1.4579,  1.1679,  0.0485],\n",
            "        [-0.8252,  0.2151,  0.3894]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5827,  0.1849,  1.1541],\n",
            "        [-1.6367,  1.2797,  0.0827],\n",
            "        [-1.7756,  0.9557,  0.6747],\n",
            "        [-1.5162,  0.5767,  0.9104],\n",
            "        [-1.3976,  1.9745, -0.4387],\n",
            "        [ 0.3150,  0.1986, -1.0103],\n",
            "        [-1.6373,  0.2782,  1.1819],\n",
            "        [-1.6005,  1.0687,  0.5281],\n",
            "        [-1.2609,  0.4586,  0.8847],\n",
            "        [-1.4543,  1.7025, -0.3051],\n",
            "        [-1.1837,  1.6218, -0.2445],\n",
            "        [-1.2730,  1.6702, -0.4491],\n",
            "        [-1.5974,  0.5388,  0.9425],\n",
            "        [ 0.3395,  0.1522, -0.8918],\n",
            "        [ 0.3780,  0.2085, -1.1187],\n",
            "        [-1.6624,  1.7238, -0.5187]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5827,  0.1849,  1.1541],\n",
            "        [-1.6367,  1.2797,  0.0827],\n",
            "        [-1.7756,  0.9557,  0.6747],\n",
            "        [-1.5162,  0.5767,  0.9104],\n",
            "        [-1.3976,  1.9745, -0.4387],\n",
            "        [ 0.3150,  0.1986, -1.0103],\n",
            "        [-1.6373,  0.2782,  1.1819],\n",
            "        [-1.6005,  1.0687,  0.5281],\n",
            "        [-1.2609,  0.4586,  0.8847],\n",
            "        [-1.4543,  1.7025, -0.3051],\n",
            "        [-1.1837,  1.6218, -0.2445],\n",
            "        [-1.2730,  1.6702, -0.4491],\n",
            "        [-1.5974,  0.5388,  0.9425],\n",
            "        [ 0.3395,  0.1522, -0.8918],\n",
            "        [ 0.3780,  0.2085, -1.1187],\n",
            "        [-1.6624,  1.7238, -0.5187]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5443,  0.7098,  0.7279],\n",
            "        [-1.5644,  1.6453, -0.3897],\n",
            "        [-1.1719,  1.9052, -0.9764],\n",
            "        [-1.4623,  1.7206, -0.3246],\n",
            "        [-1.5340,  0.7417,  0.7935],\n",
            "        [-1.3447,  1.9009, -0.6701],\n",
            "        [ 0.3399,  0.1703, -1.0889],\n",
            "        [-0.7518,  0.2519,  0.3901],\n",
            "        [-1.7728,  0.5606,  0.9677],\n",
            "        [ 0.0341,  0.2259, -0.8335],\n",
            "        [-1.5179,  1.9629, -0.3948],\n",
            "        [-1.6597, -0.0455,  1.4703],\n",
            "        [ 0.4389,  0.1132, -1.0524],\n",
            "        [-1.7490,  0.4655,  1.2511],\n",
            "        [-1.0089,  1.2969, -0.1093],\n",
            "        [-1.6822,  1.0537,  0.3305]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5443,  0.7098,  0.7279],\n",
            "        [-1.5644,  1.6453, -0.3897],\n",
            "        [-1.1719,  1.9052, -0.9764],\n",
            "        [-1.4623,  1.7206, -0.3246],\n",
            "        [-1.5340,  0.7417,  0.7935],\n",
            "        [-1.3447,  1.9009, -0.6701],\n",
            "        [ 0.3399,  0.1703, -1.0889],\n",
            "        [-0.7518,  0.2519,  0.3901],\n",
            "        [-1.7728,  0.5606,  0.9677],\n",
            "        [ 0.0341,  0.2259, -0.8335],\n",
            "        [-1.5179,  1.9629, -0.3948],\n",
            "        [-1.6597, -0.0455,  1.4703],\n",
            "        [ 0.4389,  0.1132, -1.0524],\n",
            "        [-1.7490,  0.4655,  1.2511],\n",
            "        [-1.0089,  1.2969, -0.1093],\n",
            "        [-1.6822,  1.0537,  0.3305]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5890,  1.9627, -0.2472],\n",
            "        [-1.2382,  1.4711, -0.6534],\n",
            "        [-1.3771,  1.5748, -0.5175],\n",
            "        [-1.4408,  1.0709,  0.2810],\n",
            "        [-1.5839,  0.2799,  1.0577],\n",
            "        [ 0.4732,  0.0232, -0.8018],\n",
            "        [-1.4254,  1.3427,  0.4882],\n",
            "        [-1.4108,  1.4401, -0.4915],\n",
            "        [ 0.3421,  0.0511, -0.8899],\n",
            "        [-1.4470,  0.2870,  1.0769],\n",
            "        [-1.5868,  1.3840, -0.1240],\n",
            "        [-1.6362,  1.4431, -0.0484],\n",
            "        [-1.0194,  1.5556, -0.8286],\n",
            "        [-1.6612,  1.3340,  0.2443],\n",
            "        [-1.6065,  1.8767, -0.3361],\n",
            "        [-1.3890,  1.8883, -0.3494]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5890,  1.9627, -0.2472],\n",
            "        [-1.2382,  1.4711, -0.6534],\n",
            "        [-1.3771,  1.5748, -0.5175],\n",
            "        [-1.4408,  1.0709,  0.2810],\n",
            "        [-1.5839,  0.2799,  1.0577],\n",
            "        [ 0.4732,  0.0232, -0.8018],\n",
            "        [-1.4254,  1.3427,  0.4882],\n",
            "        [-1.4108,  1.4401, -0.4915],\n",
            "        [ 0.3421,  0.0511, -0.8899],\n",
            "        [-1.4470,  0.2870,  1.0769],\n",
            "        [-1.5868,  1.3840, -0.1240],\n",
            "        [-1.6362,  1.4431, -0.0484],\n",
            "        [-1.0194,  1.5556, -0.8286],\n",
            "        [-1.6612,  1.3340,  0.2443],\n",
            "        [-1.6065,  1.8767, -0.3361],\n",
            "        [-1.3890,  1.8883, -0.3494]], grad_fn=<AddmmBackward0>)\n",
            "Epoch 1/3, Loss: 0.6177\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4485,  2.0752, -0.7274],\n",
            "        [-0.5155,  0.4191, -0.3043],\n",
            "        [-1.7204,  0.2690,  1.0380],\n",
            "        [-1.5407,  1.8707, -0.5008],\n",
            "        [-1.3855,  1.9309, -0.7021],\n",
            "        [-1.7423,  1.1646,  0.6149],\n",
            "        [ 0.5511,  0.0591, -1.0089],\n",
            "        [-1.7006,  1.9496, -0.3070],\n",
            "        [-1.5253,  1.7423, -0.2981],\n",
            "        [-1.5178,  1.6330, -0.2278],\n",
            "        [-1.5899,  1.3149,  0.2426],\n",
            "        [-1.4200,  0.5173,  1.1284],\n",
            "        [-1.5881,  1.8861, -0.4367],\n",
            "        [-1.4559,  0.4416,  0.8990],\n",
            "        [-0.4859,  0.1893,  0.0196],\n",
            "        [-1.7676,  1.8937, -0.2291]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4485,  2.0752, -0.7274],\n",
            "        [-0.5155,  0.4191, -0.3043],\n",
            "        [-1.7204,  0.2690,  1.0380],\n",
            "        [-1.5407,  1.8707, -0.5008],\n",
            "        [-1.3855,  1.9309, -0.7021],\n",
            "        [-1.7423,  1.1646,  0.6149],\n",
            "        [ 0.5511,  0.0591, -1.0089],\n",
            "        [-1.7006,  1.9496, -0.3070],\n",
            "        [-1.5253,  1.7423, -0.2981],\n",
            "        [-1.5178,  1.6330, -0.2278],\n",
            "        [-1.5899,  1.3149,  0.2426],\n",
            "        [-1.4200,  0.5173,  1.1284],\n",
            "        [-1.5881,  1.8861, -0.4367],\n",
            "        [-1.4559,  0.4416,  0.8990],\n",
            "        [-0.4859,  0.1893,  0.0196],\n",
            "        [-1.7676,  1.8937, -0.2291]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3878,  1.9606, -0.5221],\n",
            "        [-1.5723,  2.0585, -0.5577],\n",
            "        [-1.5952,  2.1116, -0.9646],\n",
            "        [-1.6014,  0.3774,  1.0650],\n",
            "        [-1.6391,  1.9252, -0.6249],\n",
            "        [-1.5581,  1.2263, -0.0059],\n",
            "        [-1.7241,  1.7379, -0.2880],\n",
            "        [-1.3670,  0.1675,  0.7775],\n",
            "        [-1.4339,  1.2548, -0.0682],\n",
            "        [ 0.4632, -0.0036, -0.9866],\n",
            "        [-1.5142,  1.5252, -0.2293],\n",
            "        [-1.5025,  2.0399, -0.4948],\n",
            "        [-1.6709,  1.7396, -0.0709],\n",
            "        [-1.2930,  0.4555,  0.5473],\n",
            "        [-1.4573,  0.4275,  0.8730],\n",
            "        [-1.3231,  0.2192,  0.9791]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3878,  1.9606, -0.5221],\n",
            "        [-1.5723,  2.0585, -0.5577],\n",
            "        [-1.5952,  2.1116, -0.9646],\n",
            "        [-1.6014,  0.3774,  1.0650],\n",
            "        [-1.6391,  1.9252, -0.6249],\n",
            "        [-1.5581,  1.2263, -0.0059],\n",
            "        [-1.7241,  1.7379, -0.2880],\n",
            "        [-1.3670,  0.1675,  0.7775],\n",
            "        [-1.4339,  1.2548, -0.0682],\n",
            "        [ 0.4632, -0.0036, -0.9866],\n",
            "        [-1.5142,  1.5252, -0.2293],\n",
            "        [-1.5025,  2.0399, -0.4948],\n",
            "        [-1.6709,  1.7396, -0.0709],\n",
            "        [-1.2930,  0.4555,  0.5473],\n",
            "        [-1.4573,  0.4275,  0.8730],\n",
            "        [-1.3231,  0.2192,  0.9791]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.1115,  1.5779, -0.6552],\n",
            "        [-1.5399,  1.8953, -0.3126],\n",
            "        [-1.5924,  1.8661, -0.0861],\n",
            "        [-1.5598,  1.8385, -0.4715],\n",
            "        [-1.7561,  0.8326,  0.7716],\n",
            "        [-1.7700,  0.4009,  1.1007],\n",
            "        [-1.7324,  0.5962,  0.8682],\n",
            "        [-1.6923,  0.4239,  1.1498],\n",
            "        [-1.6057,  1.9345, -0.7065],\n",
            "        [-1.4868,  0.8626,  0.3693],\n",
            "        [-1.2918,  1.7831, -0.5148],\n",
            "        [-1.7047,  1.7670, -0.1164],\n",
            "        [-1.4672,  0.3545,  1.0483],\n",
            "        [-1.2849,  1.4194, -0.3947],\n",
            "        [-1.5660,  0.3418,  0.9423],\n",
            "        [-1.6155,  0.6555,  1.1066]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.1115,  1.5779, -0.6552],\n",
            "        [-1.5399,  1.8953, -0.3126],\n",
            "        [-1.5924,  1.8661, -0.0861],\n",
            "        [-1.5598,  1.8385, -0.4715],\n",
            "        [-1.7561,  0.8326,  0.7716],\n",
            "        [-1.7700,  0.4009,  1.1007],\n",
            "        [-1.7324,  0.5962,  0.8682],\n",
            "        [-1.6923,  0.4239,  1.1498],\n",
            "        [-1.6057,  1.9345, -0.7065],\n",
            "        [-1.4868,  0.8626,  0.3693],\n",
            "        [-1.2918,  1.7831, -0.5148],\n",
            "        [-1.7047,  1.7670, -0.1164],\n",
            "        [-1.4672,  0.3545,  1.0483],\n",
            "        [-1.2849,  1.4194, -0.3947],\n",
            "        [-1.5660,  0.3418,  0.9423],\n",
            "        [-1.6155,  0.6555,  1.1066]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5593,  0.2843,  1.1484],\n",
            "        [-1.3850,  1.8727, -0.5840],\n",
            "        [-1.5304,  1.4264, -0.2573],\n",
            "        [-1.6775,  0.5830,  0.9966],\n",
            "        [-1.3580,  0.2842,  0.8110],\n",
            "        [ 0.3878,  0.0156, -1.0252],\n",
            "        [-1.5380,  1.8718, -0.2135],\n",
            "        [ 0.3107,  0.1543, -0.9282],\n",
            "        [-1.6730,  0.0942,  1.2986],\n",
            "        [-1.5033,  1.7717, -0.3517],\n",
            "        [-1.4022,  1.9869, -0.4783],\n",
            "        [-1.4801,  0.5605,  0.5590],\n",
            "        [-1.6711,  2.2582, -0.5488],\n",
            "        [-1.4757,  1.9766, -0.4140],\n",
            "        [-1.1789,  1.5351, -0.4388],\n",
            "        [-1.6154,  1.1828,  0.5317]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5593,  0.2843,  1.1484],\n",
            "        [-1.3850,  1.8727, -0.5840],\n",
            "        [-1.5304,  1.4264, -0.2573],\n",
            "        [-1.6775,  0.5830,  0.9966],\n",
            "        [-1.3580,  0.2842,  0.8110],\n",
            "        [ 0.3878,  0.0156, -1.0252],\n",
            "        [-1.5380,  1.8718, -0.2135],\n",
            "        [ 0.3107,  0.1543, -0.9282],\n",
            "        [-1.6730,  0.0942,  1.2986],\n",
            "        [-1.5033,  1.7717, -0.3517],\n",
            "        [-1.4022,  1.9869, -0.4783],\n",
            "        [-1.4801,  0.5605,  0.5590],\n",
            "        [-1.6711,  2.2582, -0.5488],\n",
            "        [-1.4757,  1.9766, -0.4140],\n",
            "        [-1.1789,  1.5351, -0.4388],\n",
            "        [-1.6154,  1.1828,  0.5317]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5205,  1.4853, -0.1467],\n",
            "        [-1.4950,  1.9429, -0.2826],\n",
            "        [-1.5981,  1.8700, -0.3216],\n",
            "        [-1.6286,  0.3489,  1.0298],\n",
            "        [-1.6904,  1.5971,  0.0142],\n",
            "        [-0.4270,  1.0714, -0.9768],\n",
            "        [ 0.5653, -0.1231, -0.8548],\n",
            "        [-1.4456,  1.6981, -0.4948],\n",
            "        [-1.7819,  1.2726,  0.2995],\n",
            "        [-1.7524,  2.1469, -0.4656],\n",
            "        [-1.6668,  1.9996, -0.3360],\n",
            "        [-1.4175,  0.5586,  0.8767],\n",
            "        [-1.2851,  1.7211, -0.4697],\n",
            "        [-0.9640,  0.4246,  0.3558],\n",
            "        [ 0.3155,  0.0995, -0.9192],\n",
            "        [-1.7245,  0.9527,  0.5298]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5205,  1.4853, -0.1467],\n",
            "        [-1.4950,  1.9429, -0.2826],\n",
            "        [-1.5981,  1.8700, -0.3216],\n",
            "        [-1.6286,  0.3489,  1.0298],\n",
            "        [-1.6904,  1.5971,  0.0142],\n",
            "        [-0.4270,  1.0714, -0.9768],\n",
            "        [ 0.5653, -0.1231, -0.8548],\n",
            "        [-1.4456,  1.6981, -0.4948],\n",
            "        [-1.7819,  1.2726,  0.2995],\n",
            "        [-1.7524,  2.1469, -0.4656],\n",
            "        [-1.6668,  1.9996, -0.3360],\n",
            "        [-1.4175,  0.5586,  0.8767],\n",
            "        [-1.2851,  1.7211, -0.4697],\n",
            "        [-0.9640,  0.4246,  0.3558],\n",
            "        [ 0.3155,  0.0995, -0.9192],\n",
            "        [-1.7245,  0.9527,  0.5298]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7350,  2.0024, -0.5823],\n",
            "        [-1.7047,  1.7994, -0.0239],\n",
            "        [-0.0208,  0.1432, -0.5033],\n",
            "        [ 0.4618, -0.0585, -0.9501],\n",
            "        [-0.9873,  0.3592,  0.3709],\n",
            "        [-1.8940,  0.4563,  1.0645],\n",
            "        [-1.4819,  1.8777, -0.3691],\n",
            "        [ 0.3855,  0.2402, -0.9408],\n",
            "        [-1.5760,  0.3585,  0.8729],\n",
            "        [-1.4066,  1.1415,  0.6052],\n",
            "        [-1.2735,  1.8023, -0.3911],\n",
            "        [-1.5922,  0.4994,  1.1693],\n",
            "        [ 0.2224,  0.3009, -1.0535],\n",
            "        [ 0.3887,  0.0180, -0.8738],\n",
            "        [-1.5390,  1.9939, -0.4690],\n",
            "        [-1.7676,  0.7212,  0.7845]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7350,  2.0024, -0.5823],\n",
            "        [-1.7047,  1.7994, -0.0239],\n",
            "        [-0.0208,  0.1432, -0.5033],\n",
            "        [ 0.4618, -0.0585, -0.9501],\n",
            "        [-0.9873,  0.3592,  0.3709],\n",
            "        [-1.8940,  0.4563,  1.0645],\n",
            "        [-1.4819,  1.8777, -0.3691],\n",
            "        [ 0.3855,  0.2402, -0.9408],\n",
            "        [-1.5760,  0.3585,  0.8729],\n",
            "        [-1.4066,  1.1415,  0.6052],\n",
            "        [-1.2735,  1.8023, -0.3911],\n",
            "        [-1.5922,  0.4994,  1.1693],\n",
            "        [ 0.2224,  0.3009, -1.0535],\n",
            "        [ 0.3887,  0.0180, -0.8738],\n",
            "        [-1.5390,  1.9939, -0.4690],\n",
            "        [-1.7676,  0.7212,  0.7845]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5800,  2.0931, -0.5048],\n",
            "        [-1.2564,  1.8702, -0.4041],\n",
            "        [-1.4384,  2.3145, -0.6760],\n",
            "        [-1.7901,  1.8990, -0.3479],\n",
            "        [-1.4885,  0.6866,  0.6823],\n",
            "        [-1.5971,  2.0120, -0.4495],\n",
            "        [-1.3430,  1.7421, -0.6463],\n",
            "        [-1.4037,  1.9837, -0.5669],\n",
            "        [-1.5933,  2.1382, -0.5400],\n",
            "        [-0.9778,  1.6387, -0.6988],\n",
            "        [-1.5027,  0.6699,  0.6166],\n",
            "        [-0.0752,  0.7625, -1.1183],\n",
            "        [-1.3007,  1.9486, -0.4322],\n",
            "        [-1.8119,  2.0350, -0.3080],\n",
            "        [-1.6130,  1.7910, -0.3154],\n",
            "        [ 0.5530, -0.1601, -0.9376]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5800,  2.0931, -0.5048],\n",
            "        [-1.2564,  1.8702, -0.4041],\n",
            "        [-1.4384,  2.3145, -0.6760],\n",
            "        [-1.7901,  1.8990, -0.3479],\n",
            "        [-1.4885,  0.6866,  0.6823],\n",
            "        [-1.5971,  2.0120, -0.4495],\n",
            "        [-1.3430,  1.7421, -0.6463],\n",
            "        [-1.4037,  1.9837, -0.5669],\n",
            "        [-1.5933,  2.1382, -0.5400],\n",
            "        [-0.9778,  1.6387, -0.6988],\n",
            "        [-1.5027,  0.6699,  0.6166],\n",
            "        [-0.0752,  0.7625, -1.1183],\n",
            "        [-1.3007,  1.9486, -0.4322],\n",
            "        [-1.8119,  2.0350, -0.3080],\n",
            "        [-1.6130,  1.7910, -0.3154],\n",
            "        [ 0.5530, -0.1601, -0.9376]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7048,  2.2333, -0.5352],\n",
            "        [-1.4017,  1.9627, -0.7903],\n",
            "        [-1.4257,  1.9160, -0.6687],\n",
            "        [-1.4338,  0.4215,  0.9311],\n",
            "        [-1.5569,  0.1093,  1.0928],\n",
            "        [-1.2824,  1.7868, -0.4973],\n",
            "        [-1.5267,  1.8422, -0.4887],\n",
            "        [-0.1602,  0.2169, -0.5604],\n",
            "        [ 0.0395,  0.6294, -1.0896],\n",
            "        [-1.5696,  0.5947,  0.9431],\n",
            "        [-1.5567,  0.5920,  0.7663],\n",
            "        [-1.5645,  2.3186, -0.4542],\n",
            "        [-1.5526,  0.4766,  0.9584],\n",
            "        [-1.5556,  1.0503,  0.4195],\n",
            "        [-1.5668,  0.2828,  0.9736],\n",
            "        [-1.3691,  0.0823,  1.1518]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7048,  2.2333, -0.5352],\n",
            "        [-1.4017,  1.9627, -0.7903],\n",
            "        [-1.4257,  1.9160, -0.6687],\n",
            "        [-1.4338,  0.4215,  0.9311],\n",
            "        [-1.5569,  0.1093,  1.0928],\n",
            "        [-1.2824,  1.7868, -0.4973],\n",
            "        [-1.5267,  1.8422, -0.4887],\n",
            "        [-0.1602,  0.2169, -0.5604],\n",
            "        [ 0.0395,  0.6294, -1.0896],\n",
            "        [-1.5696,  0.5947,  0.9431],\n",
            "        [-1.5567,  0.5920,  0.7663],\n",
            "        [-1.5645,  2.3186, -0.4542],\n",
            "        [-1.5526,  0.4766,  0.9584],\n",
            "        [-1.5556,  1.0503,  0.4195],\n",
            "        [-1.5668,  0.2828,  0.9736],\n",
            "        [-1.3691,  0.0823,  1.1518]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9076,  1.9435, -0.4114],\n",
            "        [-1.6627,  2.0398, -0.7955],\n",
            "        [-1.6634,  2.2645, -0.5654],\n",
            "        [-1.3159,  1.9568, -0.8007],\n",
            "        [ 0.0582,  0.6734, -1.0096],\n",
            "        [-1.7695,  1.9925, -0.7227],\n",
            "        [-1.3448,  2.0557, -0.2952],\n",
            "        [-0.2475,  0.9873, -1.0265],\n",
            "        [-1.7257,  0.6283,  0.9593],\n",
            "        [-1.5160,  2.0958, -0.6030],\n",
            "        [-1.6974,  2.0141, -0.5430],\n",
            "        [-1.5297,  1.8561, -0.5897],\n",
            "        [-1.6270,  1.9051, -0.4281],\n",
            "        [ 0.3101,  0.2424, -0.8375],\n",
            "        [-1.6247,  2.1146, -0.6298],\n",
            "        [-1.5481,  0.1260,  1.1617]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9076,  1.9435, -0.4114],\n",
            "        [-1.6627,  2.0398, -0.7955],\n",
            "        [-1.6634,  2.2645, -0.5654],\n",
            "        [-1.3159,  1.9568, -0.8007],\n",
            "        [ 0.0582,  0.6734, -1.0096],\n",
            "        [-1.7695,  1.9925, -0.7227],\n",
            "        [-1.3448,  2.0557, -0.2952],\n",
            "        [-0.2475,  0.9873, -1.0265],\n",
            "        [-1.7257,  0.6283,  0.9593],\n",
            "        [-1.5160,  2.0958, -0.6030],\n",
            "        [-1.6974,  2.0141, -0.5430],\n",
            "        [-1.5297,  1.8561, -0.5897],\n",
            "        [-1.6270,  1.9051, -0.4281],\n",
            "        [ 0.3101,  0.2424, -0.8375],\n",
            "        [-1.6247,  2.1146, -0.6298],\n",
            "        [-1.5481,  0.1260,  1.1617]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7307,  0.1253,  1.2508],\n",
            "        [-1.5947,  2.0215, -0.4498],\n",
            "        [-1.5863,  0.3703,  1.2194],\n",
            "        [-1.5590,  0.1473,  1.3219],\n",
            "        [-1.6012,  1.9353, -0.4563],\n",
            "        [ 0.3796,  0.1348, -0.9543],\n",
            "        [-1.5414,  0.1378,  0.8923],\n",
            "        [-1.7453,  1.9687, -0.6100],\n",
            "        [ 0.4415, -0.0477, -0.9116],\n",
            "        [-1.3327,  0.1059,  0.9296],\n",
            "        [-1.8142,  2.1961, -0.4565],\n",
            "        [-1.5767,  1.3757,  0.1179],\n",
            "        [-1.4900,  1.9936, -0.5401],\n",
            "        [-1.7545,  0.8928,  0.5924],\n",
            "        [-1.4762,  0.2997,  1.1875],\n",
            "        [-1.4209,  2.1333, -0.5005]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7307,  0.1253,  1.2508],\n",
            "        [-1.5947,  2.0215, -0.4498],\n",
            "        [-1.5863,  0.3703,  1.2194],\n",
            "        [-1.5590,  0.1473,  1.3219],\n",
            "        [-1.6012,  1.9353, -0.4563],\n",
            "        [ 0.3796,  0.1348, -0.9543],\n",
            "        [-1.5414,  0.1378,  0.8923],\n",
            "        [-1.7453,  1.9687, -0.6100],\n",
            "        [ 0.4415, -0.0477, -0.9116],\n",
            "        [-1.3327,  0.1059,  0.9296],\n",
            "        [-1.8142,  2.1961, -0.4565],\n",
            "        [-1.5767,  1.3757,  0.1179],\n",
            "        [-1.4900,  1.9936, -0.5401],\n",
            "        [-1.7545,  0.8928,  0.5924],\n",
            "        [-1.4762,  0.2997,  1.1875],\n",
            "        [-1.4209,  2.1333, -0.5005]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8332,  0.3511,  1.3822],\n",
            "        [-1.5541,  1.9061, -0.4221],\n",
            "        [-1.3373,  1.9666, -0.3987],\n",
            "        [-1.4998,  1.5656, -0.0593],\n",
            "        [-1.4586,  1.9508, -0.6267],\n",
            "        [-1.7434,  2.1379, -0.4103],\n",
            "        [ 0.5958, -0.0270, -0.8198],\n",
            "        [-1.6705,  1.8582, -0.6169],\n",
            "        [-1.6485,  1.3709,  0.3577],\n",
            "        [-1.5215,  2.0571, -0.7566],\n",
            "        [-1.0019,  0.1792,  0.8505],\n",
            "        [-1.7554,  1.9956, -0.2727],\n",
            "        [-1.9246,  1.9496, -0.1240],\n",
            "        [-1.0823,  1.6493, -0.9716],\n",
            "        [-1.6693,  0.3869,  1.0596],\n",
            "        [-1.4787,  2.1394, -0.6998]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8332,  0.3511,  1.3822],\n",
            "        [-1.5541,  1.9061, -0.4221],\n",
            "        [-1.3373,  1.9666, -0.3987],\n",
            "        [-1.4998,  1.5656, -0.0593],\n",
            "        [-1.4586,  1.9508, -0.6267],\n",
            "        [-1.7434,  2.1379, -0.4103],\n",
            "        [ 0.5958, -0.0270, -0.8198],\n",
            "        [-1.6705,  1.8582, -0.6169],\n",
            "        [-1.6485,  1.3709,  0.3577],\n",
            "        [-1.5215,  2.0571, -0.7566],\n",
            "        [-1.0019,  0.1792,  0.8505],\n",
            "        [-1.7554,  1.9956, -0.2727],\n",
            "        [-1.9246,  1.9496, -0.1240],\n",
            "        [-1.0823,  1.6493, -0.9716],\n",
            "        [-1.6693,  0.3869,  1.0596],\n",
            "        [-1.4787,  2.1394, -0.6998]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6614,  2.0562, -0.5259],\n",
            "        [ 0.3956, -0.0237, -0.8556],\n",
            "        [ 0.5006, -0.0052, -0.9478],\n",
            "        [-1.4442,  2.0449, -0.7562],\n",
            "        [-1.7427,  1.9222, -0.5191],\n",
            "        [-1.6649,  0.2110,  1.2069],\n",
            "        [-1.6223,  2.1472, -0.3781],\n",
            "        [-1.6895,  0.4824,  1.3191],\n",
            "        [-1.8603,  2.0387, -0.1372],\n",
            "        [-1.8556,  2.1060, -0.3136],\n",
            "        [-1.6384,  1.9662, -0.5038],\n",
            "        [-1.7325,  1.8890, -0.5069],\n",
            "        [-1.3270,  1.7068, -0.6694],\n",
            "        [-1.6570,  0.7528,  0.7536],\n",
            "        [-0.5801,  0.4565, -0.0532],\n",
            "        [-1.7355,  2.0345, -0.5429]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6614,  2.0562, -0.5259],\n",
            "        [ 0.3956, -0.0237, -0.8556],\n",
            "        [ 0.5006, -0.0052, -0.9478],\n",
            "        [-1.4442,  2.0449, -0.7562],\n",
            "        [-1.7427,  1.9222, -0.5191],\n",
            "        [-1.6649,  0.2110,  1.2069],\n",
            "        [-1.6223,  2.1472, -0.3781],\n",
            "        [-1.6895,  0.4824,  1.3191],\n",
            "        [-1.8603,  2.0387, -0.1372],\n",
            "        [-1.8556,  2.1060, -0.3136],\n",
            "        [-1.6384,  1.9662, -0.5038],\n",
            "        [-1.7325,  1.8890, -0.5069],\n",
            "        [-1.3270,  1.7068, -0.6694],\n",
            "        [-1.6570,  0.7528,  0.7536],\n",
            "        [-0.5801,  0.4565, -0.0532],\n",
            "        [-1.7355,  2.0345, -0.5429]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7705,  1.1449,  0.6890],\n",
            "        [-1.4835,  1.9739, -0.2355],\n",
            "        [-1.8668,  0.0754,  1.3514],\n",
            "        [-1.2743,  1.5267, -0.2662],\n",
            "        [-1.5754,  1.8011, -0.4968],\n",
            "        [-1.6361,  2.3602, -0.6656],\n",
            "        [-1.6379,  1.2929,  0.0470],\n",
            "        [-1.6786,  2.2319, -0.6267],\n",
            "        [-1.6823,  0.1384,  1.3622],\n",
            "        [-1.9048,  1.8657, -0.4649],\n",
            "        [-1.5941,  0.5088,  0.9850],\n",
            "        [-1.6444,  2.1990, -0.5127],\n",
            "        [-1.7394,  1.7428, -0.1104],\n",
            "        [-1.6055,  1.9518, -0.3847],\n",
            "        [-0.5914,  0.1151,  0.2187],\n",
            "        [-1.8129,  2.1793, -0.4090]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7705,  1.1449,  0.6890],\n",
            "        [-1.4835,  1.9739, -0.2355],\n",
            "        [-1.8668,  0.0754,  1.3514],\n",
            "        [-1.2743,  1.5267, -0.2662],\n",
            "        [-1.5754,  1.8011, -0.4968],\n",
            "        [-1.6361,  2.3602, -0.6656],\n",
            "        [-1.6379,  1.2929,  0.0470],\n",
            "        [-1.6786,  2.2319, -0.6267],\n",
            "        [-1.6823,  0.1384,  1.3622],\n",
            "        [-1.9048,  1.8657, -0.4649],\n",
            "        [-1.5941,  0.5088,  0.9850],\n",
            "        [-1.6444,  2.1990, -0.5127],\n",
            "        [-1.7394,  1.7428, -0.1104],\n",
            "        [-1.6055,  1.9518, -0.3847],\n",
            "        [-0.5914,  0.1151,  0.2187],\n",
            "        [-1.8129,  2.1793, -0.4090]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4778,  2.0819, -0.4722],\n",
            "        [-1.5266,  1.9775, -0.5446],\n",
            "        [-1.9716,  0.8743,  0.8611],\n",
            "        [-1.5595,  2.0351, -0.5766],\n",
            "        [-1.6878,  2.2156, -0.5854],\n",
            "        [-1.3773,  2.0433, -0.6264],\n",
            "        [-1.8681,  0.1422,  1.3255],\n",
            "        [ 0.5254, -0.0613, -0.8748],\n",
            "        [-1.7749,  2.0980, -0.5540],\n",
            "        [-1.6012,  0.1824,  1.2792],\n",
            "        [ 0.2622,  0.1147, -0.7708],\n",
            "        [-1.8573,  0.4497,  1.1385],\n",
            "        [-1.6212,  2.1378, -0.8758],\n",
            "        [-1.7843, -0.0031,  1.5358],\n",
            "        [-1.8321,  2.0488, -0.2711],\n",
            "        [ 0.3704,  0.0409, -0.8673]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4778,  2.0819, -0.4722],\n",
            "        [-1.5266,  1.9775, -0.5446],\n",
            "        [-1.9716,  0.8743,  0.8611],\n",
            "        [-1.5595,  2.0351, -0.5766],\n",
            "        [-1.6878,  2.2156, -0.5854],\n",
            "        [-1.3773,  2.0433, -0.6264],\n",
            "        [-1.8681,  0.1422,  1.3255],\n",
            "        [ 0.5254, -0.0613, -0.8748],\n",
            "        [-1.7749,  2.0980, -0.5540],\n",
            "        [-1.6012,  0.1824,  1.2792],\n",
            "        [ 0.2622,  0.1147, -0.7708],\n",
            "        [-1.8573,  0.4497,  1.1385],\n",
            "        [-1.6212,  2.1378, -0.8758],\n",
            "        [-1.7843, -0.0031,  1.5358],\n",
            "        [-1.8321,  2.0488, -0.2711],\n",
            "        [ 0.3704,  0.0409, -0.8673]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6231,  1.9852, -0.6181],\n",
            "        [-1.7993,  2.0818, -0.1544],\n",
            "        [-0.9035,  1.5219, -0.8779],\n",
            "        [-1.5718,  2.0574, -0.5419],\n",
            "        [-1.8853,  0.4694,  1.1745],\n",
            "        [-1.7238,  0.0634,  1.1843],\n",
            "        [-1.5875,  0.2973,  0.9024],\n",
            "        [-1.1523,  0.0870,  0.9664],\n",
            "        [-0.7490,  1.0780, -0.6804],\n",
            "        [-0.9207,  1.2856, -0.7141],\n",
            "        [-1.5991,  2.2241, -0.6105],\n",
            "        [-1.7433,  0.3347,  1.1302],\n",
            "        [-1.4086,  1.7253, -0.2969],\n",
            "        [-1.6867,  2.2905, -0.4666],\n",
            "        [-1.4992,  2.0364, -0.5715],\n",
            "        [-1.8562,  0.1279,  1.3397]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6231,  1.9852, -0.6181],\n",
            "        [-1.7993,  2.0818, -0.1544],\n",
            "        [-0.9035,  1.5219, -0.8779],\n",
            "        [-1.5718,  2.0574, -0.5419],\n",
            "        [-1.8853,  0.4694,  1.1745],\n",
            "        [-1.7238,  0.0634,  1.1843],\n",
            "        [-1.5875,  0.2973,  0.9024],\n",
            "        [-1.1523,  0.0870,  0.9664],\n",
            "        [-0.7490,  1.0780, -0.6804],\n",
            "        [-0.9207,  1.2856, -0.7141],\n",
            "        [-1.5991,  2.2241, -0.6105],\n",
            "        [-1.7433,  0.3347,  1.1302],\n",
            "        [-1.4086,  1.7253, -0.2969],\n",
            "        [-1.6867,  2.2905, -0.4666],\n",
            "        [-1.4992,  2.0364, -0.5715],\n",
            "        [-1.8562,  0.1279,  1.3397]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8165,  1.9379, -0.2983],\n",
            "        [-1.6862,  1.8563, -0.2461],\n",
            "        [-1.5634,  1.5595, -0.2269],\n",
            "        [-1.6806,  2.2781, -0.5167],\n",
            "        [-1.7580,  1.9326, -0.5052],\n",
            "        [ 0.2483,  0.0371, -0.9076],\n",
            "        [-1.8797,  2.2354, -0.2769],\n",
            "        [-1.6317,  1.7459, -0.2226],\n",
            "        [ 0.0654,  0.4249, -0.9411],\n",
            "        [-1.8538,  2.1374, -0.2678],\n",
            "        [-1.7397,  1.3553,  0.2856],\n",
            "        [ 0.3711, -0.1829, -0.7678],\n",
            "        [-1.7877,  1.5737,  0.2891],\n",
            "        [-1.3224,  1.3039, -0.1489],\n",
            "        [ 0.3084,  0.0259, -0.7640],\n",
            "        [-1.3741,  0.0237,  1.2784]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8165,  1.9379, -0.2983],\n",
            "        [-1.6862,  1.8563, -0.2461],\n",
            "        [-1.5634,  1.5595, -0.2269],\n",
            "        [-1.6806,  2.2781, -0.5167],\n",
            "        [-1.7580,  1.9326, -0.5052],\n",
            "        [ 0.2483,  0.0371, -0.9076],\n",
            "        [-1.8797,  2.2354, -0.2769],\n",
            "        [-1.6317,  1.7459, -0.2226],\n",
            "        [ 0.0654,  0.4249, -0.9411],\n",
            "        [-1.8538,  2.1374, -0.2678],\n",
            "        [-1.7397,  1.3553,  0.2856],\n",
            "        [ 0.3711, -0.1829, -0.7678],\n",
            "        [-1.7877,  1.5737,  0.2891],\n",
            "        [-1.3224,  1.3039, -0.1489],\n",
            "        [ 0.3084,  0.0259, -0.7640],\n",
            "        [-1.3741,  0.0237,  1.2784]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5531,  0.0280,  1.5801],\n",
            "        [ 0.3313,  0.0811, -0.8746],\n",
            "        [-1.8371,  1.9144, -0.5603],\n",
            "        [-1.0661,  1.3080, -0.6739],\n",
            "        [ 0.4588,  0.0310, -0.8608],\n",
            "        [ 0.3308, -0.1145, -0.7887],\n",
            "        [-1.6034,  1.8673, -0.4659],\n",
            "        [ 0.4352,  0.0089, -0.8894],\n",
            "        [-1.6911,  0.3739,  0.9754],\n",
            "        [-1.7405,  2.1642, -0.3712],\n",
            "        [-1.7163,  1.3134,  0.0237],\n",
            "        [-1.8297,  1.8668, -0.0499],\n",
            "        [-1.7949,  2.1510, -0.4506],\n",
            "        [-1.5289,  0.4267,  1.1432],\n",
            "        [-1.6205,  0.1166,  1.4220],\n",
            "        [-1.6280,  0.0895,  1.3533]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5531,  0.0280,  1.5801],\n",
            "        [ 0.3313,  0.0811, -0.8746],\n",
            "        [-1.8371,  1.9144, -0.5603],\n",
            "        [-1.0661,  1.3080, -0.6739],\n",
            "        [ 0.4588,  0.0310, -0.8608],\n",
            "        [ 0.3308, -0.1145, -0.7887],\n",
            "        [-1.6034,  1.8673, -0.4659],\n",
            "        [ 0.4352,  0.0089, -0.8894],\n",
            "        [-1.6911,  0.3739,  0.9754],\n",
            "        [-1.7405,  2.1642, -0.3712],\n",
            "        [-1.7163,  1.3134,  0.0237],\n",
            "        [-1.8297,  1.8668, -0.0499],\n",
            "        [-1.7949,  2.1510, -0.4506],\n",
            "        [-1.5289,  0.4267,  1.1432],\n",
            "        [-1.6205,  0.1166,  1.4220],\n",
            "        [-1.6280,  0.0895,  1.3533]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8038,  0.0813,  1.3856],\n",
            "        [-1.9471,  1.3156,  0.0795],\n",
            "        [-1.6725,  1.9204, -0.3756],\n",
            "        [-1.5898,  1.1930,  0.2293],\n",
            "        [-1.5674,  1.8475, -0.4882],\n",
            "        [-1.6163,  1.8869, -0.6319],\n",
            "        [-1.7730, -0.0627,  1.6469],\n",
            "        [-1.6866,  1.6996, -0.1548],\n",
            "        [-0.3131,  0.7519, -0.8307],\n",
            "        [-2.0407,  1.8807, -0.2765],\n",
            "        [-1.4494,  1.4902, -0.1957],\n",
            "        [-1.9152,  1.0644,  0.6990],\n",
            "        [-1.6360,  2.0106, -0.6467],\n",
            "        [-1.5315,  1.8011, -0.5887],\n",
            "        [-1.6414,  2.0343, -0.3175],\n",
            "        [-1.5573,  1.9806, -0.3286]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8038,  0.0813,  1.3856],\n",
            "        [-1.9471,  1.3156,  0.0795],\n",
            "        [-1.6725,  1.9204, -0.3756],\n",
            "        [-1.5898,  1.1930,  0.2293],\n",
            "        [-1.5674,  1.8475, -0.4882],\n",
            "        [-1.6163,  1.8869, -0.6319],\n",
            "        [-1.7730, -0.0627,  1.6469],\n",
            "        [-1.6866,  1.6996, -0.1548],\n",
            "        [-0.3131,  0.7519, -0.8307],\n",
            "        [-2.0407,  1.8807, -0.2765],\n",
            "        [-1.4494,  1.4902, -0.1957],\n",
            "        [-1.9152,  1.0644,  0.6990],\n",
            "        [-1.6360,  2.0106, -0.6467],\n",
            "        [-1.5315,  1.8011, -0.5887],\n",
            "        [-1.6414,  2.0343, -0.3175],\n",
            "        [-1.5573,  1.9806, -0.3286]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7215,  0.1154,  1.2276],\n",
            "        [-1.8117,  0.1755,  1.4723],\n",
            "        [-1.8328,  2.1312, -0.5187],\n",
            "        [-1.7385,  0.0921,  1.2811],\n",
            "        [ 0.3868, -0.0609, -0.7752],\n",
            "        [-1.5911,  1.8627, -0.5657],\n",
            "        [-1.7673,  0.5423,  1.0181],\n",
            "        [-1.7558,  0.1873,  1.2828],\n",
            "        [-0.6991,  0.2095,  0.0485],\n",
            "        [-1.9910,  1.6843,  0.1490],\n",
            "        [-0.1483,  0.4771, -1.0562],\n",
            "        [-2.0958,  0.5673,  1.1248],\n",
            "        [-1.7485, -0.0165,  1.5759],\n",
            "        [-1.9374,  0.1526,  1.4211],\n",
            "        [-1.7753,  1.8162, -0.4234],\n",
            "        [ 0.3999,  0.0610, -0.9096]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7215,  0.1154,  1.2276],\n",
            "        [-1.8117,  0.1755,  1.4723],\n",
            "        [-1.8328,  2.1312, -0.5187],\n",
            "        [-1.7385,  0.0921,  1.2811],\n",
            "        [ 0.3868, -0.0609, -0.7752],\n",
            "        [-1.5911,  1.8627, -0.5657],\n",
            "        [-1.7673,  0.5423,  1.0181],\n",
            "        [-1.7558,  0.1873,  1.2828],\n",
            "        [-0.6991,  0.2095,  0.0485],\n",
            "        [-1.9910,  1.6843,  0.1490],\n",
            "        [-0.1483,  0.4771, -1.0562],\n",
            "        [-2.0958,  0.5673,  1.1248],\n",
            "        [-1.7485, -0.0165,  1.5759],\n",
            "        [-1.9374,  0.1526,  1.4211],\n",
            "        [-1.7753,  1.8162, -0.4234],\n",
            "        [ 0.3999,  0.0610, -0.9096]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6785,  1.8300, -0.3898],\n",
            "        [-1.6730,  0.9391,  0.2842],\n",
            "        [-1.7387,  1.9310, -0.1856],\n",
            "        [-1.4798,  0.1689,  1.1534],\n",
            "        [-1.4892,  0.2604,  1.0486],\n",
            "        [-1.7267,  0.1707,  1.1931],\n",
            "        [-1.5666,  0.3413,  0.8821],\n",
            "        [-0.1647,  0.4552, -0.4586],\n",
            "        [-1.7994,  2.0155, -0.3464],\n",
            "        [-1.7427,  0.1785,  1.4520],\n",
            "        [-1.5818,  0.4846,  1.0847],\n",
            "        [-1.5879,  1.8821, -0.6391],\n",
            "        [-1.7782,  1.7537, -0.3864],\n",
            "        [-1.4428,  1.7457, -0.3065],\n",
            "        [-1.7338,  0.7130,  0.9999],\n",
            "        [-1.7036,  0.1703,  1.4775]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6785,  1.8300, -0.3898],\n",
            "        [-1.6730,  0.9391,  0.2842],\n",
            "        [-1.7387,  1.9310, -0.1856],\n",
            "        [-1.4798,  0.1689,  1.1534],\n",
            "        [-1.4892,  0.2604,  1.0486],\n",
            "        [-1.7267,  0.1707,  1.1931],\n",
            "        [-1.5666,  0.3413,  0.8821],\n",
            "        [-0.1647,  0.4552, -0.4586],\n",
            "        [-1.7994,  2.0155, -0.3464],\n",
            "        [-1.7427,  0.1785,  1.4520],\n",
            "        [-1.5818,  0.4846,  1.0847],\n",
            "        [-1.5879,  1.8821, -0.6391],\n",
            "        [-1.7782,  1.7537, -0.3864],\n",
            "        [-1.4428,  1.7457, -0.3065],\n",
            "        [-1.7338,  0.7130,  0.9999],\n",
            "        [-1.7036,  0.1703,  1.4775]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5135, -0.0867, -0.7853],\n",
            "        [-1.5212,  0.1740,  1.2492],\n",
            "        [ 0.4265,  0.0533, -0.9036],\n",
            "        [-1.7702,  1.0527,  0.7025],\n",
            "        [ 0.2807,  0.0292, -0.8393],\n",
            "        [-1.1542,  1.6368, -0.6917],\n",
            "        [ 0.0932,  0.1093, -0.8177],\n",
            "        [-1.8436,  0.1083,  1.3519],\n",
            "        [-1.5286,  1.7779, -0.5410],\n",
            "        [ 0.0959,  0.3445, -0.8596],\n",
            "        [-1.4119,  0.1555,  0.9834],\n",
            "        [-1.5482,  1.9907, -0.5045],\n",
            "        [-1.6901,  2.0649, -0.2534],\n",
            "        [-1.7320,  0.4279,  1.3182],\n",
            "        [-1.2351,  1.3801, -0.3586],\n",
            "        [-1.8307,  2.0323,  0.0110]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.5135, -0.0867, -0.7853],\n",
            "        [-1.5212,  0.1740,  1.2492],\n",
            "        [ 0.4265,  0.0533, -0.9036],\n",
            "        [-1.7702,  1.0527,  0.7025],\n",
            "        [ 0.2807,  0.0292, -0.8393],\n",
            "        [-1.1542,  1.6368, -0.6917],\n",
            "        [ 0.0932,  0.1093, -0.8177],\n",
            "        [-1.8436,  0.1083,  1.3519],\n",
            "        [-1.5286,  1.7779, -0.5410],\n",
            "        [ 0.0959,  0.3445, -0.8596],\n",
            "        [-1.4119,  0.1555,  0.9834],\n",
            "        [-1.5482,  1.9907, -0.5045],\n",
            "        [-1.6901,  2.0649, -0.2534],\n",
            "        [-1.7320,  0.4279,  1.3182],\n",
            "        [-1.2351,  1.3801, -0.3586],\n",
            "        [-1.8307,  2.0323,  0.0110]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7528,  2.3253, -0.3889],\n",
            "        [-1.5948,  2.0545, -0.3673],\n",
            "        [-1.5822,  1.5039, -0.2184],\n",
            "        [-1.7257,  1.8429, -0.3761],\n",
            "        [-1.8827,  1.0843,  0.3897],\n",
            "        [-1.7372,  2.0746, -0.3372],\n",
            "        [-1.4254,  1.6297, -0.2598],\n",
            "        [-1.9322,  0.2775,  1.3032],\n",
            "        [-1.6476,  0.5322,  1.0265],\n",
            "        [-1.2642,  1.6668, -0.2271],\n",
            "        [-1.7491,  2.1344, -0.3920],\n",
            "        [ 0.3172,  0.0484, -0.9910],\n",
            "        [-1.5407,  1.7757, -0.4294],\n",
            "        [-1.5503,  1.8033, -0.3218],\n",
            "        [-1.6855,  0.2679,  0.8705],\n",
            "        [-1.6151,  1.8466, -0.1601]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7528,  2.3253, -0.3889],\n",
            "        [-1.5948,  2.0545, -0.3673],\n",
            "        [-1.5822,  1.5039, -0.2184],\n",
            "        [-1.7257,  1.8429, -0.3761],\n",
            "        [-1.8827,  1.0843,  0.3897],\n",
            "        [-1.7372,  2.0746, -0.3372],\n",
            "        [-1.4254,  1.6297, -0.2598],\n",
            "        [-1.9322,  0.2775,  1.3032],\n",
            "        [-1.6476,  0.5322,  1.0265],\n",
            "        [-1.2642,  1.6668, -0.2271],\n",
            "        [-1.7491,  2.1344, -0.3920],\n",
            "        [ 0.3172,  0.0484, -0.9910],\n",
            "        [-1.5407,  1.7757, -0.4294],\n",
            "        [-1.5503,  1.8033, -0.3218],\n",
            "        [-1.6855,  0.2679,  0.8705],\n",
            "        [-1.6151,  1.8466, -0.1601]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3560,  0.4169,  0.7598],\n",
            "        [-1.8547,  1.5746,  0.0070],\n",
            "        [ 0.3053, -0.0191, -0.8235],\n",
            "        [-1.8260,  1.5312,  0.1719],\n",
            "        [ 0.3599,  0.1906, -1.0369],\n",
            "        [-1.7749,  1.3755,  0.2660],\n",
            "        [-1.4491,  1.6800, -0.2775],\n",
            "        [-1.8090,  0.5893,  0.8840],\n",
            "        [-1.8489,  0.2449,  1.3796],\n",
            "        [-1.8225,  1.7227, -0.1518],\n",
            "        [-1.8761,  0.7131,  0.7318],\n",
            "        [-1.8668,  0.2839,  1.3686],\n",
            "        [-1.7413,  0.5722,  0.9698],\n",
            "        [-1.6447,  1.6591, -0.2289],\n",
            "        [-1.9147,  0.5275,  1.0227],\n",
            "        [-1.8770,  0.3154,  1.1180]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3560,  0.4169,  0.7598],\n",
            "        [-1.8547,  1.5746,  0.0070],\n",
            "        [ 0.3053, -0.0191, -0.8235],\n",
            "        [-1.8260,  1.5312,  0.1719],\n",
            "        [ 0.3599,  0.1906, -1.0369],\n",
            "        [-1.7749,  1.3755,  0.2660],\n",
            "        [-1.4491,  1.6800, -0.2775],\n",
            "        [-1.8090,  0.5893,  0.8840],\n",
            "        [-1.8489,  0.2449,  1.3796],\n",
            "        [-1.8225,  1.7227, -0.1518],\n",
            "        [-1.8761,  0.7131,  0.7318],\n",
            "        [-1.8668,  0.2839,  1.3686],\n",
            "        [-1.7413,  0.5722,  0.9698],\n",
            "        [-1.6447,  1.6591, -0.2289],\n",
            "        [-1.9147,  0.5275,  1.0227],\n",
            "        [-1.8770,  0.3154,  1.1180]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6216,  2.0025, -0.4473],\n",
            "        [-1.5779,  1.4179,  0.4098],\n",
            "        [-1.5404,  1.5688, -0.1254],\n",
            "        [-1.7568,  1.8291, -0.1805],\n",
            "        [-1.6424,  1.3468,  0.1876],\n",
            "        [-1.5338,  1.4296, -0.2464],\n",
            "        [-0.0750,  0.1328, -0.4534],\n",
            "        [-1.4319,  0.6557,  0.3923],\n",
            "        [-1.5635,  1.7846, -0.2881],\n",
            "        [-1.4860,  1.4732, -0.6114],\n",
            "        [-1.5903,  1.8333, -0.4387],\n",
            "        [-1.7279,  1.6331, -0.2545],\n",
            "        [-1.5347,  1.4264, -0.4136],\n",
            "        [-1.7285,  2.0700, -0.4807],\n",
            "        [-1.7399,  1.2571,  0.4065],\n",
            "        [-1.8158,  1.7144, -0.0337]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6216,  2.0025, -0.4473],\n",
            "        [-1.5779,  1.4179,  0.4098],\n",
            "        [-1.5404,  1.5688, -0.1254],\n",
            "        [-1.7568,  1.8291, -0.1805],\n",
            "        [-1.6424,  1.3468,  0.1876],\n",
            "        [-1.5338,  1.4296, -0.2464],\n",
            "        [-0.0750,  0.1328, -0.4534],\n",
            "        [-1.4319,  0.6557,  0.3923],\n",
            "        [-1.5635,  1.7846, -0.2881],\n",
            "        [-1.4860,  1.4732, -0.6114],\n",
            "        [-1.5903,  1.8333, -0.4387],\n",
            "        [-1.7279,  1.6331, -0.2545],\n",
            "        [-1.5347,  1.4264, -0.4136],\n",
            "        [-1.7285,  2.0700, -0.4807],\n",
            "        [-1.7399,  1.2571,  0.4065],\n",
            "        [-1.8158,  1.7144, -0.0337]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0398,  0.3001,  1.2541],\n",
            "        [-1.7143,  1.3656,  0.1760],\n",
            "        [-1.6329,  0.3483,  1.2202],\n",
            "        [-1.6108,  1.6276, -0.1950],\n",
            "        [-0.0337,  0.2247, -0.6293],\n",
            "        [-1.7803,  0.5360,  1.0290],\n",
            "        [-1.7775,  0.1686,  1.2746],\n",
            "        [ 0.3204,  0.0145, -0.8777],\n",
            "        [-1.7806,  0.2844,  1.3206],\n",
            "        [-1.5339,  0.2799,  0.9405],\n",
            "        [-1.7330,  0.8943,  0.7269],\n",
            "        [-1.6384,  1.9887, -0.5086],\n",
            "        [-1.5453,  1.5151,  0.1041],\n",
            "        [ 0.5060, -0.0036, -0.9114],\n",
            "        [-1.5847,  0.7607,  0.5514],\n",
            "        [-1.4916,  0.7366,  0.6498]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0398,  0.3001,  1.2541],\n",
            "        [-1.7143,  1.3656,  0.1760],\n",
            "        [-1.6329,  0.3483,  1.2202],\n",
            "        [-1.6108,  1.6276, -0.1950],\n",
            "        [-0.0337,  0.2247, -0.6293],\n",
            "        [-1.7803,  0.5360,  1.0290],\n",
            "        [-1.7775,  0.1686,  1.2746],\n",
            "        [ 0.3204,  0.0145, -0.8777],\n",
            "        [-1.7806,  0.2844,  1.3206],\n",
            "        [-1.5339,  0.2799,  0.9405],\n",
            "        [-1.7330,  0.8943,  0.7269],\n",
            "        [-1.6384,  1.9887, -0.5086],\n",
            "        [-1.5453,  1.5151,  0.1041],\n",
            "        [ 0.5060, -0.0036, -0.9114],\n",
            "        [-1.5847,  0.7607,  0.5514],\n",
            "        [-1.4916,  0.7366,  0.6498]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3484,  1.6612, -0.2012],\n",
            "        [-1.3590,  1.3463, -0.3381],\n",
            "        [-1.6944,  1.9550, -0.3265],\n",
            "        [-1.1085,  1.4230, -0.2188],\n",
            "        [-1.5410,  0.4343,  1.1843],\n",
            "        [-1.2968,  1.5355, -0.2323],\n",
            "        [-1.6142,  0.5668,  0.9189],\n",
            "        [-1.3631,  1.4867, -0.4254],\n",
            "        [-1.4464,  1.6049, -0.3215],\n",
            "        [-1.6842,  1.2435,  0.4330],\n",
            "        [-1.0063,  0.2430,  0.5760],\n",
            "        [-1.2824,  1.1354,  0.1934],\n",
            "        [-1.5405,  0.3998,  1.2256],\n",
            "        [-1.7894,  0.9230,  0.8541],\n",
            "        [-1.5993,  1.6245, -0.3999],\n",
            "        [-1.5698,  1.7296, -0.4847]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3484,  1.6612, -0.2012],\n",
            "        [-1.3590,  1.3463, -0.3381],\n",
            "        [-1.6944,  1.9550, -0.3265],\n",
            "        [-1.1085,  1.4230, -0.2188],\n",
            "        [-1.5410,  0.4343,  1.1843],\n",
            "        [-1.2968,  1.5355, -0.2323],\n",
            "        [-1.6142,  0.5668,  0.9189],\n",
            "        [-1.3631,  1.4867, -0.4254],\n",
            "        [-1.4464,  1.6049, -0.3215],\n",
            "        [-1.6842,  1.2435,  0.4330],\n",
            "        [-1.0063,  0.2430,  0.5760],\n",
            "        [-1.2824,  1.1354,  0.1934],\n",
            "        [-1.5405,  0.3998,  1.2256],\n",
            "        [-1.7894,  0.9230,  0.8541],\n",
            "        [-1.5993,  1.6245, -0.3999],\n",
            "        [-1.5698,  1.7296, -0.4847]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5404,  1.2911,  0.2657],\n",
            "        [-1.6634,  1.3832, -0.0151],\n",
            "        [-1.6807,  0.3331,  1.4464],\n",
            "        [-1.4366,  1.4557, -0.0678],\n",
            "        [-1.6640,  1.7412, -0.1513],\n",
            "        [-1.7146,  0.4627,  1.1327],\n",
            "        [ 0.4328,  0.0463, -0.8151],\n",
            "        [-1.6821,  0.4517,  1.2687],\n",
            "        [-1.5330,  1.6420, -0.3794],\n",
            "        [-1.3730,  1.6970, -0.2895],\n",
            "        [-1.7421,  1.3456,  0.2881],\n",
            "        [ 0.3828, -0.0854, -0.8514],\n",
            "        [-1.5238,  0.3972,  1.0052],\n",
            "        [-1.7835,  0.0450,  1.5090],\n",
            "        [-1.6658,  1.7366, -0.0931],\n",
            "        [ 0.5685, -0.0904, -0.9773]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5404,  1.2911,  0.2657],\n",
            "        [-1.6634,  1.3832, -0.0151],\n",
            "        [-1.6807,  0.3331,  1.4464],\n",
            "        [-1.4366,  1.4557, -0.0678],\n",
            "        [-1.6640,  1.7412, -0.1513],\n",
            "        [-1.7146,  0.4627,  1.1327],\n",
            "        [ 0.4328,  0.0463, -0.8151],\n",
            "        [-1.6821,  0.4517,  1.2687],\n",
            "        [-1.5330,  1.6420, -0.3794],\n",
            "        [-1.3730,  1.6970, -0.2895],\n",
            "        [-1.7421,  1.3456,  0.2881],\n",
            "        [ 0.3828, -0.0854, -0.8514],\n",
            "        [-1.5238,  0.3972,  1.0052],\n",
            "        [-1.7835,  0.0450,  1.5090],\n",
            "        [-1.6658,  1.7366, -0.0931],\n",
            "        [ 0.5685, -0.0904, -0.9773]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5678,  0.9803,  0.5526],\n",
            "        [-1.5543,  0.3601,  1.0068],\n",
            "        [-1.8271,  0.3953,  1.3172],\n",
            "        [-1.6590,  0.3317,  1.2503],\n",
            "        [-1.7297,  0.3315,  1.0901],\n",
            "        [-0.2103,  0.2499, -0.4258],\n",
            "        [-1.2643,  1.1617,  0.0726],\n",
            "        [-1.2886,  0.1929,  0.9455],\n",
            "        [-1.1165,  1.2657, -0.1632],\n",
            "        [ 0.2384, -0.0324, -0.7331],\n",
            "        [-1.3037,  1.7127, -0.4807],\n",
            "        [-1.6162,  0.3092,  1.2642],\n",
            "        [ 0.4682,  0.0293, -0.9325],\n",
            "        [-1.6073,  1.7675, -0.3053],\n",
            "        [-1.1146,  1.0936, -0.1436],\n",
            "        [-1.6584,  1.8174, -0.3683]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5678,  0.9803,  0.5526],\n",
            "        [-1.5543,  0.3601,  1.0068],\n",
            "        [-1.8271,  0.3953,  1.3172],\n",
            "        [-1.6590,  0.3317,  1.2503],\n",
            "        [-1.7297,  0.3315,  1.0901],\n",
            "        [-0.2103,  0.2499, -0.4258],\n",
            "        [-1.2643,  1.1617,  0.0726],\n",
            "        [-1.2886,  0.1929,  0.9455],\n",
            "        [-1.1165,  1.2657, -0.1632],\n",
            "        [ 0.2384, -0.0324, -0.7331],\n",
            "        [-1.3037,  1.7127, -0.4807],\n",
            "        [-1.6162,  0.3092,  1.2642],\n",
            "        [ 0.4682,  0.0293, -0.9325],\n",
            "        [-1.6073,  1.7675, -0.3053],\n",
            "        [-1.1146,  1.0936, -0.1436],\n",
            "        [-1.6584,  1.8174, -0.3683]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7946,  0.2559,  1.3670],\n",
            "        [-1.8000,  0.5514,  1.1080],\n",
            "        [-1.6273,  1.5158, -0.0291],\n",
            "        [-0.8791,  1.3153, -0.4964],\n",
            "        [-1.6585,  1.3187,  0.3293],\n",
            "        [ 0.3095, -0.0254, -0.7457],\n",
            "        [-1.0819,  1.2903, -0.6478],\n",
            "        [-1.2781,  1.3809, -0.2024],\n",
            "        [-1.4177,  1.2832,  0.0943],\n",
            "        [-1.5405,  1.8144, -0.0929],\n",
            "        [-1.1247,  1.7136, -0.4958],\n",
            "        [ 0.2389, -0.0543, -0.8812],\n",
            "        [-1.4221,  1.5635, -0.3735],\n",
            "        [-1.4993,  1.2963,  0.0827],\n",
            "        [-1.5022,  1.6658, -0.3343],\n",
            "        [-1.2859,  1.6789, -0.3882]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7946,  0.2559,  1.3670],\n",
            "        [-1.8000,  0.5514,  1.1080],\n",
            "        [-1.6273,  1.5158, -0.0291],\n",
            "        [-0.8791,  1.3153, -0.4964],\n",
            "        [-1.6585,  1.3187,  0.3293],\n",
            "        [ 0.3095, -0.0254, -0.7457],\n",
            "        [-1.0819,  1.2903, -0.6478],\n",
            "        [-1.2781,  1.3809, -0.2024],\n",
            "        [-1.4177,  1.2832,  0.0943],\n",
            "        [-1.5405,  1.8144, -0.0929],\n",
            "        [-1.1247,  1.7136, -0.4958],\n",
            "        [ 0.2389, -0.0543, -0.8812],\n",
            "        [-1.4221,  1.5635, -0.3735],\n",
            "        [-1.4993,  1.2963,  0.0827],\n",
            "        [-1.5022,  1.6658, -0.3343],\n",
            "        [-1.2859,  1.6789, -0.3882]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2841,  1.6231, -0.3944],\n",
            "        [-1.4476,  0.7786,  0.5027],\n",
            "        [ 0.3933,  0.0125, -0.9762],\n",
            "        [-1.1080,  1.1599, -0.0070],\n",
            "        [-1.3838,  1.4142, -0.2665],\n",
            "        [-1.7545,  1.1259,  0.6280],\n",
            "        [-1.8741,  0.2736,  1.0869],\n",
            "        [-1.8300,  0.2413,  1.2261],\n",
            "        [-1.1837,  1.2744, -0.0191],\n",
            "        [-1.7308,  0.5675,  0.8626],\n",
            "        [-1.3494,  1.5638, -0.3730],\n",
            "        [-1.6285,  1.9489, -0.3425],\n",
            "        [-1.4272,  1.5679, -0.3009],\n",
            "        [-1.6063,  1.0609,  0.2468],\n",
            "        [ 0.2895, -0.0106, -0.6078],\n",
            "        [-1.4406,  1.6562, -0.2632]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2841,  1.6231, -0.3944],\n",
            "        [-1.4476,  0.7786,  0.5027],\n",
            "        [ 0.3933,  0.0125, -0.9762],\n",
            "        [-1.1080,  1.1599, -0.0070],\n",
            "        [-1.3838,  1.4142, -0.2665],\n",
            "        [-1.7545,  1.1259,  0.6280],\n",
            "        [-1.8741,  0.2736,  1.0869],\n",
            "        [-1.8300,  0.2413,  1.2261],\n",
            "        [-1.1837,  1.2744, -0.0191],\n",
            "        [-1.7308,  0.5675,  0.8626],\n",
            "        [-1.3494,  1.5638, -0.3730],\n",
            "        [-1.6285,  1.9489, -0.3425],\n",
            "        [-1.4272,  1.5679, -0.3009],\n",
            "        [-1.6063,  1.0609,  0.2468],\n",
            "        [ 0.2895, -0.0106, -0.6078],\n",
            "        [-1.4406,  1.6562, -0.2632]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7280,  1.3306,  0.0735],\n",
            "        [-1.4840,  1.5231, -0.6480],\n",
            "        [-1.5036,  1.7581, -0.2875],\n",
            "        [-1.1057,  0.3946,  0.7229],\n",
            "        [-1.3890,  1.3445, -0.0940],\n",
            "        [-1.4073,  1.4188, -0.1757],\n",
            "        [-1.3845,  1.5869, -0.3884],\n",
            "        [-1.5288,  1.3789,  0.1498],\n",
            "        [-1.7167,  0.6404,  1.2116],\n",
            "        [-1.3184,  1.4989, -0.3598],\n",
            "        [-1.7373,  0.9894,  0.6373],\n",
            "        [-1.6881,  0.4272,  1.3612],\n",
            "        [-1.2860,  0.3855,  1.0457],\n",
            "        [ 0.6227, -0.2985, -0.8861],\n",
            "        [ 0.4428, -0.1150, -0.8444],\n",
            "        [-1.7453,  1.8486, -0.2399]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7280,  1.3306,  0.0735],\n",
            "        [-1.4840,  1.5231, -0.6480],\n",
            "        [-1.5036,  1.7581, -0.2875],\n",
            "        [-1.1057,  0.3946,  0.7229],\n",
            "        [-1.3890,  1.3445, -0.0940],\n",
            "        [-1.4073,  1.4188, -0.1757],\n",
            "        [-1.3845,  1.5869, -0.3884],\n",
            "        [-1.5288,  1.3789,  0.1498],\n",
            "        [-1.7167,  0.6404,  1.2116],\n",
            "        [-1.3184,  1.4989, -0.3598],\n",
            "        [-1.7373,  0.9894,  0.6373],\n",
            "        [-1.6881,  0.4272,  1.3612],\n",
            "        [-1.2860,  0.3855,  1.0457],\n",
            "        [ 0.6227, -0.2985, -0.8861],\n",
            "        [ 0.4428, -0.1150, -0.8444],\n",
            "        [-1.7453,  1.8486, -0.2399]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3175,  0.0813, -0.9399],\n",
            "        [-1.4005,  1.5641, -0.3190],\n",
            "        [-1.5563,  0.3798,  1.0969],\n",
            "        [-1.6942,  0.7149,  0.6844],\n",
            "        [-1.5259,  0.2764,  1.1063],\n",
            "        [-1.0445,  0.3596,  0.2736],\n",
            "        [-1.2899,  1.6025, -0.2483],\n",
            "        [-1.5251,  0.3118,  1.0749],\n",
            "        [ 0.3540,  0.0032, -0.7585],\n",
            "        [ 0.6093,  0.1106, -0.8815],\n",
            "        [-1.7026,  1.0586,  0.4393],\n",
            "        [ 0.3769, -0.1272, -0.7465],\n",
            "        [-1.3920,  1.8465, -0.4877],\n",
            "        [-1.5640,  1.4783, -0.1551],\n",
            "        [-1.2717,  1.3820, -0.3332],\n",
            "        [-0.4176,  0.1928, -0.0421]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.3175,  0.0813, -0.9399],\n",
            "        [-1.4005,  1.5641, -0.3190],\n",
            "        [-1.5563,  0.3798,  1.0969],\n",
            "        [-1.6942,  0.7149,  0.6844],\n",
            "        [-1.5259,  0.2764,  1.1063],\n",
            "        [-1.0445,  0.3596,  0.2736],\n",
            "        [-1.2899,  1.6025, -0.2483],\n",
            "        [-1.5251,  0.3118,  1.0749],\n",
            "        [ 0.3540,  0.0032, -0.7585],\n",
            "        [ 0.6093,  0.1106, -0.8815],\n",
            "        [-1.7026,  1.0586,  0.4393],\n",
            "        [ 0.3769, -0.1272, -0.7465],\n",
            "        [-1.3920,  1.8465, -0.4877],\n",
            "        [-1.5640,  1.4783, -0.1551],\n",
            "        [-1.2717,  1.3820, -0.3332],\n",
            "        [-0.4176,  0.1928, -0.0421]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8202,  0.4728,  1.1181],\n",
            "        [-1.2459,  1.1139, -0.0738],\n",
            "        [-1.4667,  1.6009, -0.1728],\n",
            "        [-1.4920,  1.3921, -0.3580],\n",
            "        [-1.4094,  1.2686,  0.1735],\n",
            "        [-1.3314,  1.5682, -0.3023],\n",
            "        [-1.5989,  0.2820,  1.1612],\n",
            "        [-1.4261,  1.1915, -0.0104],\n",
            "        [-1.6198,  1.9932, -0.2268],\n",
            "        [-1.4038,  1.8064, -0.4323],\n",
            "        [-1.3506,  1.7825, -0.5272],\n",
            "        [-1.5472,  1.5917, -0.3323],\n",
            "        [-1.3518,  1.3700, -0.2502],\n",
            "        [-1.3879,  1.6518, -0.3355],\n",
            "        [-1.4443,  1.0853,  0.2282],\n",
            "        [-1.7727,  0.2124,  1.4873]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8202,  0.4728,  1.1181],\n",
            "        [-1.2459,  1.1139, -0.0738],\n",
            "        [-1.4667,  1.6009, -0.1728],\n",
            "        [-1.4920,  1.3921, -0.3580],\n",
            "        [-1.4094,  1.2686,  0.1735],\n",
            "        [-1.3314,  1.5682, -0.3023],\n",
            "        [-1.5989,  0.2820,  1.1612],\n",
            "        [-1.4261,  1.1915, -0.0104],\n",
            "        [-1.6198,  1.9932, -0.2268],\n",
            "        [-1.4038,  1.8064, -0.4323],\n",
            "        [-1.3506,  1.7825, -0.5272],\n",
            "        [-1.5472,  1.5917, -0.3323],\n",
            "        [-1.3518,  1.3700, -0.2502],\n",
            "        [-1.3879,  1.6518, -0.3355],\n",
            "        [-1.4443,  1.0853,  0.2282],\n",
            "        [-1.7727,  0.2124,  1.4873]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3983,  1.0189,  0.5649],\n",
            "        [-1.5488,  0.2975,  1.1005],\n",
            "        [-1.3811,  0.5272,  0.9292],\n",
            "        [ 0.6493, -0.0979, -0.8506],\n",
            "        [-1.5309,  0.6216,  0.8855],\n",
            "        [-1.5358,  1.4149,  0.0256],\n",
            "        [-1.5656,  0.5185,  0.9502],\n",
            "        [-0.5625,  0.2130,  0.1710],\n",
            "        [-1.5614,  1.7345, -0.4025],\n",
            "        [-1.4673,  1.5750, -0.4954],\n",
            "        [-1.2687,  0.8806,  0.4185],\n",
            "        [-1.4608,  0.4204,  1.0550],\n",
            "        [-1.5174,  0.3836,  1.0466],\n",
            "        [-1.6453,  1.9511, -0.3074],\n",
            "        [-1.5970,  0.8497,  0.6311],\n",
            "        [-1.7026,  0.3650,  1.3363]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3983,  1.0189,  0.5649],\n",
            "        [-1.5488,  0.2975,  1.1005],\n",
            "        [-1.3811,  0.5272,  0.9292],\n",
            "        [ 0.6493, -0.0979, -0.8506],\n",
            "        [-1.5309,  0.6216,  0.8855],\n",
            "        [-1.5358,  1.4149,  0.0256],\n",
            "        [-1.5656,  0.5185,  0.9502],\n",
            "        [-0.5625,  0.2130,  0.1710],\n",
            "        [-1.5614,  1.7345, -0.4025],\n",
            "        [-1.4673,  1.5750, -0.4954],\n",
            "        [-1.2687,  0.8806,  0.4185],\n",
            "        [-1.4608,  0.4204,  1.0550],\n",
            "        [-1.5174,  0.3836,  1.0466],\n",
            "        [-1.6453,  1.9511, -0.3074],\n",
            "        [-1.5970,  0.8497,  0.6311],\n",
            "        [-1.7026,  0.3650,  1.3363]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6071,  0.4458,  1.0080],\n",
            "        [-0.4947,  0.6841, -0.4864],\n",
            "        [-1.5823,  1.6948, -0.4218],\n",
            "        [-1.6179,  1.5935, -0.3209],\n",
            "        [ 0.4937,  0.0508, -0.8344],\n",
            "        [-1.4487,  0.2400,  1.1575],\n",
            "        [-1.7052,  1.3948,  0.2095],\n",
            "        [-1.7859,  0.3010,  1.0974],\n",
            "        [-1.0075,  1.3997, -0.5041],\n",
            "        [ 0.6170, -0.2117, -0.8853],\n",
            "        [-1.4317,  1.7449, -0.2120],\n",
            "        [-1.3339,  1.1836, -0.0653],\n",
            "        [ 0.5204, -0.0659, -0.8965],\n",
            "        [-1.4557,  1.4319, -0.3571],\n",
            "        [-1.4764,  0.1406,  1.0785],\n",
            "        [-1.5914,  1.7637, -0.3233]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6071,  0.4458,  1.0080],\n",
            "        [-0.4947,  0.6841, -0.4864],\n",
            "        [-1.5823,  1.6948, -0.4218],\n",
            "        [-1.6179,  1.5935, -0.3209],\n",
            "        [ 0.4937,  0.0508, -0.8344],\n",
            "        [-1.4487,  0.2400,  1.1575],\n",
            "        [-1.7052,  1.3948,  0.2095],\n",
            "        [-1.7859,  0.3010,  1.0974],\n",
            "        [-1.0075,  1.3997, -0.5041],\n",
            "        [ 0.6170, -0.2117, -0.8853],\n",
            "        [-1.4317,  1.7449, -0.2120],\n",
            "        [-1.3339,  1.1836, -0.0653],\n",
            "        [ 0.5204, -0.0659, -0.8965],\n",
            "        [-1.4557,  1.4319, -0.3571],\n",
            "        [-1.4764,  0.1406,  1.0785],\n",
            "        [-1.5914,  1.7637, -0.3233]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2964,  1.5653, -0.3592],\n",
            "        [-1.3136,  1.0574,  0.0980],\n",
            "        [-1.6748,  0.6936,  0.8819],\n",
            "        [-1.1910,  1.0867,  0.0132],\n",
            "        [-1.0298,  0.9062, -0.0055],\n",
            "        [-0.1892,  0.6103, -0.8066],\n",
            "        [ 0.3668,  0.1614, -0.9849],\n",
            "        [-1.4874,  0.6129,  0.9216],\n",
            "        [-1.3543,  1.7981, -0.5375],\n",
            "        [-1.6141,  0.2118,  1.2387],\n",
            "        [-1.5299,  1.9864, -0.4899],\n",
            "        [-1.7140,  1.5678, -0.5352],\n",
            "        [ 0.7135, -0.1390, -1.0658],\n",
            "        [-1.4167,  1.5507, -0.0479],\n",
            "        [ 0.5204, -0.0874, -0.8780],\n",
            "        [-1.7617,  0.3928,  1.1969]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2964,  1.5653, -0.3592],\n",
            "        [-1.3136,  1.0574,  0.0980],\n",
            "        [-1.6748,  0.6936,  0.8819],\n",
            "        [-1.1910,  1.0867,  0.0132],\n",
            "        [-1.0298,  0.9062, -0.0055],\n",
            "        [-0.1892,  0.6103, -0.8066],\n",
            "        [ 0.3668,  0.1614, -0.9849],\n",
            "        [-1.4874,  0.6129,  0.9216],\n",
            "        [-1.3543,  1.7981, -0.5375],\n",
            "        [-1.6141,  0.2118,  1.2387],\n",
            "        [-1.5299,  1.9864, -0.4899],\n",
            "        [-1.7140,  1.5678, -0.5352],\n",
            "        [ 0.7135, -0.1390, -1.0658],\n",
            "        [-1.4167,  1.5507, -0.0479],\n",
            "        [ 0.5204, -0.0874, -0.8780],\n",
            "        [-1.7617,  0.3928,  1.1969]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.8039, -0.1927, -1.1503],\n",
            "        [-1.3283,  1.5542, -0.4308],\n",
            "        [-1.4636,  1.4113, -0.2277],\n",
            "        [-1.5966,  0.4308,  1.0654],\n",
            "        [-1.3946,  1.7923, -0.4717],\n",
            "        [-1.4066,  1.5693, -0.3897],\n",
            "        [ 0.7169, -0.1620, -1.0351],\n",
            "        [-1.1319,  1.1760, -0.0766],\n",
            "        [ 0.6054, -0.0059, -0.9910],\n",
            "        [-1.4937,  1.8291, -0.5118],\n",
            "        [-1.5715,  0.4827,  1.0459],\n",
            "        [ 0.5288,  0.0169, -0.9970],\n",
            "        [-1.6705,  1.9662, -0.4866],\n",
            "        [-1.4035,  0.3904,  0.7845],\n",
            "        [-1.6326,  0.9219,  0.6324],\n",
            "        [ 0.6421, -0.1753, -0.8134]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.8039, -0.1927, -1.1503],\n",
            "        [-1.3283,  1.5542, -0.4308],\n",
            "        [-1.4636,  1.4113, -0.2277],\n",
            "        [-1.5966,  0.4308,  1.0654],\n",
            "        [-1.3946,  1.7923, -0.4717],\n",
            "        [-1.4066,  1.5693, -0.3897],\n",
            "        [ 0.7169, -0.1620, -1.0351],\n",
            "        [-1.1319,  1.1760, -0.0766],\n",
            "        [ 0.6054, -0.0059, -0.9910],\n",
            "        [-1.4937,  1.8291, -0.5118],\n",
            "        [-1.5715,  0.4827,  1.0459],\n",
            "        [ 0.5288,  0.0169, -0.9970],\n",
            "        [-1.6705,  1.9662, -0.4866],\n",
            "        [-1.4035,  0.3904,  0.7845],\n",
            "        [-1.6326,  0.9219,  0.6324],\n",
            "        [ 0.6421, -0.1753, -0.8134]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5671,  1.7084, -0.2822],\n",
            "        [ 0.9017, -0.1788, -0.9165],\n",
            "        [-1.7840,  0.4150,  1.0576],\n",
            "        [-1.5502,  0.4188,  1.0320],\n",
            "        [-1.6879,  1.8159, -0.2441],\n",
            "        [ 0.6381, -0.2332, -1.0288],\n",
            "        [ 0.8501, -0.1490, -1.0606],\n",
            "        [ 0.6435, -0.2112, -1.0661],\n",
            "        [-1.4142,  0.4224,  0.8363],\n",
            "        [-1.4633,  1.2162,  0.0941],\n",
            "        [-1.7123,  1.7660, -0.2512],\n",
            "        [-1.6987,  2.0610, -0.2913],\n",
            "        [-1.3855,  1.0749,  0.4411],\n",
            "        [ 0.4989,  0.0596, -0.9922],\n",
            "        [-1.6012,  0.8841,  0.6769],\n",
            "        [-1.4843,  0.7463,  0.7674]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5671,  1.7084, -0.2822],\n",
            "        [ 0.9017, -0.1788, -0.9165],\n",
            "        [-1.7840,  0.4150,  1.0576],\n",
            "        [-1.5502,  0.4188,  1.0320],\n",
            "        [-1.6879,  1.8159, -0.2441],\n",
            "        [ 0.6381, -0.2332, -1.0288],\n",
            "        [ 0.8501, -0.1490, -1.0606],\n",
            "        [ 0.6435, -0.2112, -1.0661],\n",
            "        [-1.4142,  0.4224,  0.8363],\n",
            "        [-1.4633,  1.2162,  0.0941],\n",
            "        [-1.7123,  1.7660, -0.2512],\n",
            "        [-1.6987,  2.0610, -0.2913],\n",
            "        [-1.3855,  1.0749,  0.4411],\n",
            "        [ 0.4989,  0.0596, -0.9922],\n",
            "        [-1.6012,  0.8841,  0.6769],\n",
            "        [-1.4843,  0.7463,  0.7674]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5080,  0.2918, -0.7832],\n",
            "        [-1.3903,  1.7599, -0.5258],\n",
            "        [-1.5318,  1.7638, -0.3773],\n",
            "        [-1.5321,  1.7127, -0.3207],\n",
            "        [-1.5182,  1.9905, -0.3620],\n",
            "        [ 0.4372,  0.2232, -1.0773],\n",
            "        [ 0.6893, -0.1010, -1.1229],\n",
            "        [-1.5508,  1.9823, -0.4224],\n",
            "        [-1.0506,  0.5281,  0.2776],\n",
            "        [-1.6418,  1.9268, -0.5137],\n",
            "        [-1.4095,  1.7877, -0.5039],\n",
            "        [-1.6336,  2.0154, -0.3405],\n",
            "        [-1.5563,  1.6903, -0.3312],\n",
            "        [-1.4107,  1.1404,  0.2635],\n",
            "        [-0.4391,  0.2839, -0.1601],\n",
            "        [ 0.2289,  0.2694, -0.9287]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.5080,  0.2918, -0.7832],\n",
            "        [-1.3903,  1.7599, -0.5258],\n",
            "        [-1.5318,  1.7638, -0.3773],\n",
            "        [-1.5321,  1.7127, -0.3207],\n",
            "        [-1.5182,  1.9905, -0.3620],\n",
            "        [ 0.4372,  0.2232, -1.0773],\n",
            "        [ 0.6893, -0.1010, -1.1229],\n",
            "        [-1.5508,  1.9823, -0.4224],\n",
            "        [-1.0506,  0.5281,  0.2776],\n",
            "        [-1.6418,  1.9268, -0.5137],\n",
            "        [-1.4095,  1.7877, -0.5039],\n",
            "        [-1.6336,  2.0154, -0.3405],\n",
            "        [-1.5563,  1.6903, -0.3312],\n",
            "        [-1.4107,  1.1404,  0.2635],\n",
            "        [-0.4391,  0.2839, -0.1601],\n",
            "        [ 0.2289,  0.2694, -0.9287]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8065,  0.5786,  1.1738],\n",
            "        [-1.3001,  1.6346, -0.2137],\n",
            "        [-1.4557,  0.5608,  0.6759],\n",
            "        [-1.3195,  1.3404, -0.0755],\n",
            "        [-1.0579,  1.3292, -0.5816],\n",
            "        [-1.4588,  1.3240,  0.0321],\n",
            "        [-1.5858,  1.9250, -0.3375],\n",
            "        [-1.6872,  0.6004,  0.9818],\n",
            "        [-0.7267,  0.4974,  0.0423],\n",
            "        [-1.5422,  1.1886,  0.0468],\n",
            "        [-1.6517,  1.5687,  0.0571],\n",
            "        [-1.7582,  0.4159,  1.1362],\n",
            "        [-1.6803,  1.9294, -0.4656],\n",
            "        [-1.4329,  1.4502, -0.2569],\n",
            "        [-1.6579,  1.7229, -0.4289],\n",
            "        [-1.5118,  1.7111, -0.3575]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8065,  0.5786,  1.1738],\n",
            "        [-1.3001,  1.6346, -0.2137],\n",
            "        [-1.4557,  0.5608,  0.6759],\n",
            "        [-1.3195,  1.3404, -0.0755],\n",
            "        [-1.0579,  1.3292, -0.5816],\n",
            "        [-1.4588,  1.3240,  0.0321],\n",
            "        [-1.5858,  1.9250, -0.3375],\n",
            "        [-1.6872,  0.6004,  0.9818],\n",
            "        [-0.7267,  0.4974,  0.0423],\n",
            "        [-1.5422,  1.1886,  0.0468],\n",
            "        [-1.6517,  1.5687,  0.0571],\n",
            "        [-1.7582,  0.4159,  1.1362],\n",
            "        [-1.6803,  1.9294, -0.4656],\n",
            "        [-1.4329,  1.4502, -0.2569],\n",
            "        [-1.6579,  1.7229, -0.4289],\n",
            "        [-1.5118,  1.7111, -0.3575]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6089,  1.5335,  0.0763],\n",
            "        [ 0.5815, -0.0103, -0.9066],\n",
            "        [-1.3670,  1.6096, -0.3144],\n",
            "        [-1.6741,  0.5820,  1.0193],\n",
            "        [-1.4888,  1.7409, -0.3798],\n",
            "        [-1.8732,  1.3966,  0.0983],\n",
            "        [-1.0064,  0.5473, -0.0739],\n",
            "        [-1.5261,  1.6944, -0.3232],\n",
            "        [ 0.6169, -0.2436, -1.1093],\n",
            "        [ 0.3665, -0.1115, -0.8817],\n",
            "        [-1.4731,  1.9459, -0.4118],\n",
            "        [-1.7520,  1.7987, -0.1127],\n",
            "        [-1.5439,  1.3793,  0.0751],\n",
            "        [-1.5255,  1.7280, -0.3763],\n",
            "        [-1.6804,  1.9130, -0.1272],\n",
            "        [-1.4011,  1.7201, -0.6861]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6089,  1.5335,  0.0763],\n",
            "        [ 0.5815, -0.0103, -0.9066],\n",
            "        [-1.3670,  1.6096, -0.3144],\n",
            "        [-1.6741,  0.5820,  1.0193],\n",
            "        [-1.4888,  1.7409, -0.3798],\n",
            "        [-1.8732,  1.3966,  0.0983],\n",
            "        [-1.0064,  0.5473, -0.0739],\n",
            "        [-1.5261,  1.6944, -0.3232],\n",
            "        [ 0.6169, -0.2436, -1.1093],\n",
            "        [ 0.3665, -0.1115, -0.8817],\n",
            "        [-1.4731,  1.9459, -0.4118],\n",
            "        [-1.7520,  1.7987, -0.1127],\n",
            "        [-1.5439,  1.3793,  0.0751],\n",
            "        [-1.5255,  1.7280, -0.3763],\n",
            "        [-1.6804,  1.9130, -0.1272],\n",
            "        [-1.4011,  1.7201, -0.6861]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6876,  0.7235,  0.8723],\n",
            "        [-1.7339,  1.4474,  0.1040],\n",
            "        [-1.6630,  1.7818, -0.2214],\n",
            "        [-1.3896,  1.5481, -0.1955],\n",
            "        [-1.7964,  2.0319, -0.6756],\n",
            "        [-1.5754,  1.4030,  0.3039],\n",
            "        [ 0.5670,  0.0912, -0.9198],\n",
            "        [-1.5918,  1.9792, -0.4765],\n",
            "        [-1.6475,  1.6918,  0.0048],\n",
            "        [ 0.7656, -0.1237, -1.1646],\n",
            "        [-1.6956,  1.4389, -0.0309],\n",
            "        [-1.5333,  1.7980, -0.4542],\n",
            "        [-1.7964,  0.3429,  1.0754],\n",
            "        [-1.4613,  2.0164, -0.3351],\n",
            "        [-1.7341,  1.9386, -0.2760],\n",
            "        [-1.8373,  1.9801, -0.4247]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6876,  0.7235,  0.8723],\n",
            "        [-1.7339,  1.4474,  0.1040],\n",
            "        [-1.6630,  1.7818, -0.2214],\n",
            "        [-1.3896,  1.5481, -0.1955],\n",
            "        [-1.7964,  2.0319, -0.6756],\n",
            "        [-1.5754,  1.4030,  0.3039],\n",
            "        [ 0.5670,  0.0912, -0.9198],\n",
            "        [-1.5918,  1.9792, -0.4765],\n",
            "        [-1.6475,  1.6918,  0.0048],\n",
            "        [ 0.7656, -0.1237, -1.1646],\n",
            "        [-1.6956,  1.4389, -0.0309],\n",
            "        [-1.5333,  1.7980, -0.4542],\n",
            "        [-1.7964,  0.3429,  1.0754],\n",
            "        [-1.4613,  2.0164, -0.3351],\n",
            "        [-1.7341,  1.9386, -0.2760],\n",
            "        [-1.8373,  1.9801, -0.4247]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6500,  1.8810, -0.2811],\n",
            "        [-1.7712,  2.0845, -0.3382],\n",
            "        [-1.1787,  1.4976, -0.5893],\n",
            "        [-1.8242,  2.0132, -0.1290],\n",
            "        [ 0.5607,  0.0926, -1.1884],\n",
            "        [-1.8991,  0.5180,  1.3642],\n",
            "        [-1.8924,  1.9114, -0.3484],\n",
            "        [-1.7780,  2.1515, -0.4486],\n",
            "        [-1.6223,  1.8569, -0.0375],\n",
            "        [-1.7112,  0.4525,  1.0046],\n",
            "        [ 0.7630, -0.1574, -1.1166],\n",
            "        [-0.7294,  0.8234, -0.7114],\n",
            "        [-1.6484,  1.5502,  0.2080],\n",
            "        [-1.7164,  1.8377, -0.3464],\n",
            "        [-1.8207,  0.2941,  0.9730],\n",
            "        [ 0.3020,  0.2974, -1.0670]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6500,  1.8810, -0.2811],\n",
            "        [-1.7712,  2.0845, -0.3382],\n",
            "        [-1.1787,  1.4976, -0.5893],\n",
            "        [-1.8242,  2.0132, -0.1290],\n",
            "        [ 0.5607,  0.0926, -1.1884],\n",
            "        [-1.8991,  0.5180,  1.3642],\n",
            "        [-1.8924,  1.9114, -0.3484],\n",
            "        [-1.7780,  2.1515, -0.4486],\n",
            "        [-1.6223,  1.8569, -0.0375],\n",
            "        [-1.7112,  0.4525,  1.0046],\n",
            "        [ 0.7630, -0.1574, -1.1166],\n",
            "        [-0.7294,  0.8234, -0.7114],\n",
            "        [-1.6484,  1.5502,  0.2080],\n",
            "        [-1.7164,  1.8377, -0.3464],\n",
            "        [-1.8207,  0.2941,  0.9730],\n",
            "        [ 0.3020,  0.2974, -1.0670]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8207,  2.1766, -0.3122],\n",
            "        [ 0.3410,  0.3166, -1.2471],\n",
            "        [-1.6127,  1.8059, -0.5151],\n",
            "        [-1.8391,  2.0600, -0.4975],\n",
            "        [-1.9724,  1.0774,  0.6136],\n",
            "        [-1.8534,  0.5692,  1.1380],\n",
            "        [ 0.6064,  0.0177, -1.2158],\n",
            "        [-1.9445,  1.7625, -0.1130],\n",
            "        [-1.8157,  2.0740, -0.3229],\n",
            "        [-1.8132,  2.0032, -0.0675],\n",
            "        [-1.9307,  1.1214,  0.6198],\n",
            "        [-2.0204,  2.1297, -0.5654],\n",
            "        [-1.8345,  0.9209,  0.7634],\n",
            "        [-1.8086,  1.3150,  0.1809],\n",
            "        [-1.7163,  2.2443, -0.5848],\n",
            "        [-1.9531,  1.4376,  0.4195]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8207,  2.1766, -0.3122],\n",
            "        [ 0.3410,  0.3166, -1.2471],\n",
            "        [-1.6127,  1.8059, -0.5151],\n",
            "        [-1.8391,  2.0600, -0.4975],\n",
            "        [-1.9724,  1.0774,  0.6136],\n",
            "        [-1.8534,  0.5692,  1.1380],\n",
            "        [ 0.6064,  0.0177, -1.2158],\n",
            "        [-1.9445,  1.7625, -0.1130],\n",
            "        [-1.8157,  2.0740, -0.3229],\n",
            "        [-1.8132,  2.0032, -0.0675],\n",
            "        [-1.9307,  1.1214,  0.6198],\n",
            "        [-2.0204,  2.1297, -0.5654],\n",
            "        [-1.8345,  0.9209,  0.7634],\n",
            "        [-1.8086,  1.3150,  0.1809],\n",
            "        [-1.7163,  2.2443, -0.5848],\n",
            "        [-1.9531,  1.4376,  0.4195]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9668,  0.6298,  1.2886],\n",
            "        [-1.8843,  2.2780, -0.4539],\n",
            "        [-1.5761,  1.7709,  0.0079],\n",
            "        [-1.7318,  1.0106,  0.4099],\n",
            "        [-1.6627,  0.5497,  0.9678],\n",
            "        [-1.7832,  0.7301,  0.9641],\n",
            "        [-1.7954,  0.8018,  0.7312],\n",
            "        [-2.1447,  1.5855,  0.2379],\n",
            "        [-1.6714,  0.5623,  1.0130],\n",
            "        [-1.6370,  0.6991,  1.0335],\n",
            "        [-1.9241,  2.3286, -0.2539],\n",
            "        [-1.6630,  0.8402,  1.2545],\n",
            "        [-1.7444,  0.8629,  0.7208],\n",
            "        [-1.6912,  1.3977,  0.2204],\n",
            "        [-1.7201,  2.0459, -0.4019],\n",
            "        [-1.7545,  0.5466,  1.1286]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9668,  0.6298,  1.2886],\n",
            "        [-1.8843,  2.2780, -0.4539],\n",
            "        [-1.5761,  1.7709,  0.0079],\n",
            "        [-1.7318,  1.0106,  0.4099],\n",
            "        [-1.6627,  0.5497,  0.9678],\n",
            "        [-1.7832,  0.7301,  0.9641],\n",
            "        [-1.7954,  0.8018,  0.7312],\n",
            "        [-2.1447,  1.5855,  0.2379],\n",
            "        [-1.6714,  0.5623,  1.0130],\n",
            "        [-1.6370,  0.6991,  1.0335],\n",
            "        [-1.9241,  2.3286, -0.2539],\n",
            "        [-1.6630,  0.8402,  1.2545],\n",
            "        [-1.7444,  0.8629,  0.7208],\n",
            "        [-1.6912,  1.3977,  0.2204],\n",
            "        [-1.7201,  2.0459, -0.4019],\n",
            "        [-1.7545,  0.5466,  1.1286]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9491,  1.9294,  0.1814],\n",
            "        [-1.7947,  0.3566,  1.2900],\n",
            "        [-1.9408,  2.3319, -0.4492],\n",
            "        [-1.7597,  1.7471, -0.2486],\n",
            "        [ 0.6276, -0.0165, -1.1206],\n",
            "        [-1.9773,  1.1452,  0.7318],\n",
            "        [-2.1344,  2.4958, -0.3244],\n",
            "        [-1.9630,  1.0593,  0.7103],\n",
            "        [-1.9211,  0.5447,  1.0300],\n",
            "        [-1.7597,  2.4080, -0.4631],\n",
            "        [-1.9407,  1.7691, -0.3092],\n",
            "        [-2.1477,  2.1110, -0.1361],\n",
            "        [-1.8159,  0.7567,  0.8596],\n",
            "        [-2.0827,  2.3447, -0.2960],\n",
            "        [-1.6425,  1.9595, -0.6143],\n",
            "        [-1.7737,  2.2532, -0.4818]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9491,  1.9294,  0.1814],\n",
            "        [-1.7947,  0.3566,  1.2900],\n",
            "        [-1.9408,  2.3319, -0.4492],\n",
            "        [-1.7597,  1.7471, -0.2486],\n",
            "        [ 0.6276, -0.0165, -1.1206],\n",
            "        [-1.9773,  1.1452,  0.7318],\n",
            "        [-2.1344,  2.4958, -0.3244],\n",
            "        [-1.9630,  1.0593,  0.7103],\n",
            "        [-1.9211,  0.5447,  1.0300],\n",
            "        [-1.7597,  2.4080, -0.4631],\n",
            "        [-1.9407,  1.7691, -0.3092],\n",
            "        [-2.1477,  2.1110, -0.1361],\n",
            "        [-1.8159,  0.7567,  0.8596],\n",
            "        [-2.0827,  2.3447, -0.2960],\n",
            "        [-1.6425,  1.9595, -0.6143],\n",
            "        [-1.7737,  2.2532, -0.4818]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8641,  0.9141,  0.9778],\n",
            "        [ 0.5147, -0.1086, -1.1776],\n",
            "        [-1.8528,  1.9191,  0.0211],\n",
            "        [-1.8233,  1.4728,  0.1179],\n",
            "        [-1.9090,  1.9558, -0.4669],\n",
            "        [-1.7383,  1.8430, -0.5229],\n",
            "        [-1.6478,  1.1091,  0.4232],\n",
            "        [-1.9195,  0.5703,  1.0206],\n",
            "        [-1.7770,  2.0252, -0.1762],\n",
            "        [-1.7379,  0.6128,  1.0086],\n",
            "        [-1.7610,  1.7332,  0.0596],\n",
            "        [-1.7573,  1.0668,  0.6957],\n",
            "        [-1.7391,  0.5350,  1.2104],\n",
            "        [-1.7291,  0.5806,  1.0721],\n",
            "        [ 0.5501, -0.0112, -1.1210],\n",
            "        [-2.1065,  1.1185,  0.5113]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8641,  0.9141,  0.9778],\n",
            "        [ 0.5147, -0.1086, -1.1776],\n",
            "        [-1.8528,  1.9191,  0.0211],\n",
            "        [-1.8233,  1.4728,  0.1179],\n",
            "        [-1.9090,  1.9558, -0.4669],\n",
            "        [-1.7383,  1.8430, -0.5229],\n",
            "        [-1.6478,  1.1091,  0.4232],\n",
            "        [-1.9195,  0.5703,  1.0206],\n",
            "        [-1.7770,  2.0252, -0.1762],\n",
            "        [-1.7379,  0.6128,  1.0086],\n",
            "        [-1.7610,  1.7332,  0.0596],\n",
            "        [-1.7573,  1.0668,  0.6957],\n",
            "        [-1.7391,  0.5350,  1.2104],\n",
            "        [-1.7291,  0.5806,  1.0721],\n",
            "        [ 0.5501, -0.0112, -1.1210],\n",
            "        [-2.1065,  1.1185,  0.5113]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9735,  0.6236,  1.0674],\n",
            "        [-1.9541,  1.9232, -0.4994],\n",
            "        [-1.9374,  0.9563,  0.7539],\n",
            "        [-1.7051,  2.0096, -0.3315],\n",
            "        [-1.8848,  0.7851,  1.1022],\n",
            "        [ 0.7814, -0.2405, -1.1767],\n",
            "        [-1.8904,  1.7222, -0.0358],\n",
            "        [-1.9245,  0.6369,  0.9842],\n",
            "        [ 0.7246,  0.0282, -1.3488],\n",
            "        [-1.9557,  1.0236,  0.9678],\n",
            "        [-1.9228,  0.5350,  1.1890],\n",
            "        [ 0.6348,  0.0335, -1.2176],\n",
            "        [ 0.9124, -0.1193, -1.0237],\n",
            "        [-1.9363,  0.4751,  1.2850],\n",
            "        [-1.7275,  2.0069, -0.4085],\n",
            "        [-1.4588,  1.6994, -0.3921]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9735,  0.6236,  1.0674],\n",
            "        [-1.9541,  1.9232, -0.4994],\n",
            "        [-1.9374,  0.9563,  0.7539],\n",
            "        [-1.7051,  2.0096, -0.3315],\n",
            "        [-1.8848,  0.7851,  1.1022],\n",
            "        [ 0.7814, -0.2405, -1.1767],\n",
            "        [-1.8904,  1.7222, -0.0358],\n",
            "        [-1.9245,  0.6369,  0.9842],\n",
            "        [ 0.7246,  0.0282, -1.3488],\n",
            "        [-1.9557,  1.0236,  0.9678],\n",
            "        [-1.9228,  0.5350,  1.1890],\n",
            "        [ 0.6348,  0.0335, -1.2176],\n",
            "        [ 0.9124, -0.1193, -1.0237],\n",
            "        [-1.9363,  0.4751,  1.2850],\n",
            "        [-1.7275,  2.0069, -0.4085],\n",
            "        [-1.4588,  1.6994, -0.3921]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2292,  1.6123,  0.6995],\n",
            "        [-2.3656,  1.0969,  0.8342],\n",
            "        [-0.7607,  1.1739, -0.8377],\n",
            "        [-1.5628,  1.2535,  0.0679],\n",
            "        [-0.5718,  1.2267, -1.0460],\n",
            "        [-1.9926,  2.1183, -0.2132],\n",
            "        [-1.9328,  1.4695,  0.3834],\n",
            "        [-2.0004,  1.1305,  0.6354],\n",
            "        [ 0.2898,  0.1989, -1.0716],\n",
            "        [-1.9934,  1.6592,  0.3426],\n",
            "        [-1.9734,  1.9200, -0.0235],\n",
            "        [-1.7115,  0.3966,  1.1890],\n",
            "        [ 0.1728,  0.2345, -1.1292],\n",
            "        [-1.9989,  0.4961,  1.3857],\n",
            "        [-1.7242,  1.8647, -0.0138],\n",
            "        [-2.0545,  1.8180, -0.1053]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.2292,  1.6123,  0.6995],\n",
            "        [-2.3656,  1.0969,  0.8342],\n",
            "        [-0.7607,  1.1739, -0.8377],\n",
            "        [-1.5628,  1.2535,  0.0679],\n",
            "        [-0.5718,  1.2267, -1.0460],\n",
            "        [-1.9926,  2.1183, -0.2132],\n",
            "        [-1.9328,  1.4695,  0.3834],\n",
            "        [-2.0004,  1.1305,  0.6354],\n",
            "        [ 0.2898,  0.1989, -1.0716],\n",
            "        [-1.9934,  1.6592,  0.3426],\n",
            "        [-1.9734,  1.9200, -0.0235],\n",
            "        [-1.7115,  0.3966,  1.1890],\n",
            "        [ 0.1728,  0.2345, -1.1292],\n",
            "        [-1.9989,  0.4961,  1.3857],\n",
            "        [-1.7242,  1.8647, -0.0138],\n",
            "        [-2.0545,  1.8180, -0.1053]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1170,  2.1902, -0.4607],\n",
            "        [-2.0577,  1.4811,  0.1394],\n",
            "        [-1.8924,  2.0659, -0.3826],\n",
            "        [-2.0476,  2.0799, -0.0854],\n",
            "        [-1.9935,  2.0835, -0.2457],\n",
            "        [-2.0727,  2.0042,  0.1120],\n",
            "        [-2.0580,  0.7653,  1.2203],\n",
            "        [-2.2585,  2.0322, -0.0536],\n",
            "        [-1.7531,  1.8357, -0.0561],\n",
            "        [ 0.3319,  0.3723, -1.2516],\n",
            "        [-2.1214,  2.1723, -0.3182],\n",
            "        [-2.0319,  1.8940, -0.2828],\n",
            "        [-2.2809,  0.4702,  1.4819],\n",
            "        [-1.8600,  2.0046, -0.1793],\n",
            "        [-1.7956,  2.3206, -0.2998],\n",
            "        [-1.9236,  1.9590, -0.2244]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1170,  2.1902, -0.4607],\n",
            "        [-2.0577,  1.4811,  0.1394],\n",
            "        [-1.8924,  2.0659, -0.3826],\n",
            "        [-2.0476,  2.0799, -0.0854],\n",
            "        [-1.9935,  2.0835, -0.2457],\n",
            "        [-2.0727,  2.0042,  0.1120],\n",
            "        [-2.0580,  0.7653,  1.2203],\n",
            "        [-2.2585,  2.0322, -0.0536],\n",
            "        [-1.7531,  1.8357, -0.0561],\n",
            "        [ 0.3319,  0.3723, -1.2516],\n",
            "        [-2.1214,  2.1723, -0.3182],\n",
            "        [-2.0319,  1.8940, -0.2828],\n",
            "        [-2.2809,  0.4702,  1.4819],\n",
            "        [-1.8600,  2.0046, -0.1793],\n",
            "        [-1.7956,  2.3206, -0.2998],\n",
            "        [-1.9236,  1.9590, -0.2244]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.4775,  0.1040, -1.2240],\n",
            "        [-1.9517,  0.6065,  1.3460],\n",
            "        [-2.1107,  2.0184, -0.1848],\n",
            "        [-1.8237,  1.8923, -0.0025],\n",
            "        [-1.9402,  2.0196, -0.1095],\n",
            "        [-1.8982,  1.8560, -0.0334],\n",
            "        [-1.9596,  1.9899, -0.0247],\n",
            "        [-2.1070,  2.1608, -0.5008],\n",
            "        [-1.9532,  0.4775,  1.3200],\n",
            "        [-1.8672,  2.0747, -0.1959],\n",
            "        [-2.2002,  1.6776,  0.4746],\n",
            "        [-1.8834,  0.8257,  0.7013],\n",
            "        [-2.0334,  0.8546,  1.1672],\n",
            "        [-1.9172,  1.0001,  0.7898],\n",
            "        [ 0.7132,  0.0562, -1.2556],\n",
            "        [-2.0107,  1.8836, -0.2480]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.4775,  0.1040, -1.2240],\n",
            "        [-1.9517,  0.6065,  1.3460],\n",
            "        [-2.1107,  2.0184, -0.1848],\n",
            "        [-1.8237,  1.8923, -0.0025],\n",
            "        [-1.9402,  2.0196, -0.1095],\n",
            "        [-1.8982,  1.8560, -0.0334],\n",
            "        [-1.9596,  1.9899, -0.0247],\n",
            "        [-2.1070,  2.1608, -0.5008],\n",
            "        [-1.9532,  0.4775,  1.3200],\n",
            "        [-1.8672,  2.0747, -0.1959],\n",
            "        [-2.2002,  1.6776,  0.4746],\n",
            "        [-1.8834,  0.8257,  0.7013],\n",
            "        [-2.0334,  0.8546,  1.1672],\n",
            "        [-1.9172,  1.0001,  0.7898],\n",
            "        [ 0.7132,  0.0562, -1.2556],\n",
            "        [-2.0107,  1.8836, -0.2480]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0699,  1.6010,  0.0027],\n",
            "        [-2.0452,  0.5150,  1.2269],\n",
            "        [-1.7279,  0.5040,  0.9272],\n",
            "        [-2.0503,  2.3329, -0.1930],\n",
            "        [-1.8678,  1.8877, -0.1048],\n",
            "        [-1.8468,  1.7860,  0.2894],\n",
            "        [-2.1027,  1.8676, -0.1990],\n",
            "        [-1.9707,  0.6386,  1.3421],\n",
            "        [-1.8293,  1.5787,  0.2258],\n",
            "        [-1.8046,  0.7213,  1.0999],\n",
            "        [-1.9970,  1.8764, -0.2013],\n",
            "        [-1.9795,  1.9785, -0.1175],\n",
            "        [-2.1784,  1.8793, -0.0616],\n",
            "        [-2.1630,  1.1568,  0.5844],\n",
            "        [-2.0654,  1.6018,  0.4898],\n",
            "        [-2.2817,  0.9603,  0.9650]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0699,  1.6010,  0.0027],\n",
            "        [-2.0452,  0.5150,  1.2269],\n",
            "        [-1.7279,  0.5040,  0.9272],\n",
            "        [-2.0503,  2.3329, -0.1930],\n",
            "        [-1.8678,  1.8877, -0.1048],\n",
            "        [-1.8468,  1.7860,  0.2894],\n",
            "        [-2.1027,  1.8676, -0.1990],\n",
            "        [-1.9707,  0.6386,  1.3421],\n",
            "        [-1.8293,  1.5787,  0.2258],\n",
            "        [-1.8046,  0.7213,  1.0999],\n",
            "        [-1.9970,  1.8764, -0.2013],\n",
            "        [-1.9795,  1.9785, -0.1175],\n",
            "        [-2.1784,  1.8793, -0.0616],\n",
            "        [-2.1630,  1.1568,  0.5844],\n",
            "        [-2.0654,  1.6018,  0.4898],\n",
            "        [-2.2817,  0.9603,  0.9650]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.0542,  0.5864, -1.1789],\n",
            "        [-2.0303,  1.9518,  0.1649],\n",
            "        [-1.9631,  0.8432,  0.8595],\n",
            "        [-2.0901,  2.0665, -0.3278],\n",
            "        [-1.9257,  2.2320, -0.2800],\n",
            "        [-2.3267,  2.3315,  0.0660],\n",
            "        [-2.1915,  2.2310, -0.0227],\n",
            "        [-1.8409,  0.7775,  1.3181],\n",
            "        [ 0.7533, -0.2509, -1.1474],\n",
            "        [-1.9777,  1.6873,  0.0610],\n",
            "        [ 0.5789,  0.0743, -1.0745],\n",
            "        [-2.2949,  1.8458,  0.4408],\n",
            "        [-2.0013,  1.8812, -0.0947],\n",
            "        [-2.1249,  0.5657,  1.2163],\n",
            "        [-1.9912,  1.5608,  0.0917],\n",
            "        [-2.1829,  0.4015,  0.9998]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-0.0542,  0.5864, -1.1789],\n",
            "        [-2.0303,  1.9518,  0.1649],\n",
            "        [-1.9631,  0.8432,  0.8595],\n",
            "        [-2.0901,  2.0665, -0.3278],\n",
            "        [-1.9257,  2.2320, -0.2800],\n",
            "        [-2.3267,  2.3315,  0.0660],\n",
            "        [-2.1915,  2.2310, -0.0227],\n",
            "        [-1.8409,  0.7775,  1.3181],\n",
            "        [ 0.7533, -0.2509, -1.1474],\n",
            "        [-1.9777,  1.6873,  0.0610],\n",
            "        [ 0.5789,  0.0743, -1.0745],\n",
            "        [-2.2949,  1.8458,  0.4408],\n",
            "        [-2.0013,  1.8812, -0.0947],\n",
            "        [-2.1249,  0.5657,  1.2163],\n",
            "        [-1.9912,  1.5608,  0.0917],\n",
            "        [-2.1829,  0.4015,  0.9998]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1234,  1.9841, -0.0132],\n",
            "        [-2.1560,  0.6066,  1.2508],\n",
            "        [ 0.5989,  0.2888, -1.1512],\n",
            "        [ 0.0647,  0.2929, -0.9637],\n",
            "        [-2.1680,  2.1275, -0.1429],\n",
            "        [-2.2184,  1.3719,  0.5643],\n",
            "        [-1.9026,  0.6169,  1.1091],\n",
            "        [-2.0942,  1.3316,  0.5197],\n",
            "        [-1.9421,  2.0990, -0.3341],\n",
            "        [-2.0466,  1.2152,  0.7401],\n",
            "        [-2.1308,  2.0961, -0.3190],\n",
            "        [-2.2153,  2.2341, -0.1613],\n",
            "        [-2.0693,  1.3062,  0.0132],\n",
            "        [-2.0719,  2.1492, -0.3356],\n",
            "        [-2.2321,  0.8349,  1.0973],\n",
            "        [-1.9965,  2.2063, -0.0985]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1234,  1.9841, -0.0132],\n",
            "        [-2.1560,  0.6066,  1.2508],\n",
            "        [ 0.5989,  0.2888, -1.1512],\n",
            "        [ 0.0647,  0.2929, -0.9637],\n",
            "        [-2.1680,  2.1275, -0.1429],\n",
            "        [-2.2184,  1.3719,  0.5643],\n",
            "        [-1.9026,  0.6169,  1.1091],\n",
            "        [-2.0942,  1.3316,  0.5197],\n",
            "        [-1.9421,  2.0990, -0.3341],\n",
            "        [-2.0466,  1.2152,  0.7401],\n",
            "        [-2.1308,  2.0961, -0.3190],\n",
            "        [-2.2153,  2.2341, -0.1613],\n",
            "        [-2.0693,  1.3062,  0.0132],\n",
            "        [-2.0719,  2.1492, -0.3356],\n",
            "        [-2.2321,  0.8349,  1.0973],\n",
            "        [-1.9965,  2.2063, -0.0985]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0966,  2.2229, -0.3478],\n",
            "        [ 0.5151,  0.1312, -1.1714],\n",
            "        [-1.8466,  2.0661, -0.4124],\n",
            "        [-2.1629,  1.4212,  0.6910],\n",
            "        [-1.9098,  2.1128, -0.1877],\n",
            "        [-1.4013,  1.9152, -0.7539],\n",
            "        [-2.0215,  1.8646,  0.3940],\n",
            "        [-1.9599,  2.1715,  0.0321],\n",
            "        [-1.8614,  1.8106,  0.2005],\n",
            "        [-2.0278,  1.0041,  0.5946],\n",
            "        [ 0.6655, -0.0124, -0.9777],\n",
            "        [-2.0850,  1.9112,  0.0707],\n",
            "        [-2.0327,  1.8603, -0.0175],\n",
            "        [-2.1276,  2.2307, -0.3067],\n",
            "        [-1.8221,  0.7383,  1.0536],\n",
            "        [ 0.3979,  0.0599, -0.9285]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0966,  2.2229, -0.3478],\n",
            "        [ 0.5151,  0.1312, -1.1714],\n",
            "        [-1.8466,  2.0661, -0.4124],\n",
            "        [-2.1629,  1.4212,  0.6910],\n",
            "        [-1.9098,  2.1128, -0.1877],\n",
            "        [-1.4013,  1.9152, -0.7539],\n",
            "        [-2.0215,  1.8646,  0.3940],\n",
            "        [-1.9599,  2.1715,  0.0321],\n",
            "        [-1.8614,  1.8106,  0.2005],\n",
            "        [-2.0278,  1.0041,  0.5946],\n",
            "        [ 0.6655, -0.0124, -0.9777],\n",
            "        [-2.0850,  1.9112,  0.0707],\n",
            "        [-2.0327,  1.8603, -0.0175],\n",
            "        [-2.1276,  2.2307, -0.3067],\n",
            "        [-1.8221,  0.7383,  1.0536],\n",
            "        [ 0.3979,  0.0599, -0.9285]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1278,  2.2138, -0.1600],\n",
            "        [-2.2351,  2.1976, -0.2771],\n",
            "        [ 0.4400, -0.1867, -1.1980],\n",
            "        [-2.2606,  1.8608,  0.2750],\n",
            "        [-2.4362,  2.0534,  0.1828],\n",
            "        [-1.9982,  2.0802, -0.3131],\n",
            "        [-1.9566,  1.9898, -0.0548],\n",
            "        [-2.3283,  2.2405, -0.0522],\n",
            "        [ 0.6022, -0.1210, -1.1503],\n",
            "        [-2.2009,  2.2058,  0.1559],\n",
            "        [-2.1701,  0.6887,  1.2832],\n",
            "        [-2.4474,  2.1316, -0.2336],\n",
            "        [-2.2578,  0.7108,  1.1962],\n",
            "        [-2.2526,  1.9698, -0.1274],\n",
            "        [-2.0763,  2.0975, -0.3042],\n",
            "        [ 0.9512, -0.1556, -1.2645]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1278,  2.2138, -0.1600],\n",
            "        [-2.2351,  2.1976, -0.2771],\n",
            "        [ 0.4400, -0.1867, -1.1980],\n",
            "        [-2.2606,  1.8608,  0.2750],\n",
            "        [-2.4362,  2.0534,  0.1828],\n",
            "        [-1.9982,  2.0802, -0.3131],\n",
            "        [-1.9566,  1.9898, -0.0548],\n",
            "        [-2.3283,  2.2405, -0.0522],\n",
            "        [ 0.6022, -0.1210, -1.1503],\n",
            "        [-2.2009,  2.2058,  0.1559],\n",
            "        [-2.1701,  0.6887,  1.2832],\n",
            "        [-2.4474,  2.1316, -0.2336],\n",
            "        [-2.2578,  0.7108,  1.1962],\n",
            "        [-2.2526,  1.9698, -0.1274],\n",
            "        [-2.0763,  2.0975, -0.3042],\n",
            "        [ 0.9512, -0.1556, -1.2645]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0461,  1.8873, -0.0364],\n",
            "        [ 0.5654, -0.0161, -1.1706],\n",
            "        [-2.4040,  2.1617,  0.0133],\n",
            "        [-2.2205,  1.4452,  0.3742],\n",
            "        [-1.9424,  2.1596, -0.3335],\n",
            "        [ 0.3149,  0.1999, -1.0837],\n",
            "        [-2.2971,  2.0980, -0.1576],\n",
            "        [-2.0962,  2.2517, -0.1459],\n",
            "        [-1.9324,  2.1573, -0.4309],\n",
            "        [-2.1800,  1.8267, -0.0452],\n",
            "        [-2.1021,  2.2626, -0.2007],\n",
            "        [-2.1163,  0.6493,  1.1058],\n",
            "        [-1.9682,  2.1943, -0.5442],\n",
            "        [-2.0089,  1.4936,  0.2800],\n",
            "        [-1.8543,  1.9950, -0.0846],\n",
            "        [-2.0088,  0.5582,  1.0771]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0461,  1.8873, -0.0364],\n",
            "        [ 0.5654, -0.0161, -1.1706],\n",
            "        [-2.4040,  2.1617,  0.0133],\n",
            "        [-2.2205,  1.4452,  0.3742],\n",
            "        [-1.9424,  2.1596, -0.3335],\n",
            "        [ 0.3149,  0.1999, -1.0837],\n",
            "        [-2.2971,  2.0980, -0.1576],\n",
            "        [-2.0962,  2.2517, -0.1459],\n",
            "        [-1.9324,  2.1573, -0.4309],\n",
            "        [-2.1800,  1.8267, -0.0452],\n",
            "        [-2.1021,  2.2626, -0.2007],\n",
            "        [-2.1163,  0.6493,  1.1058],\n",
            "        [-1.9682,  2.1943, -0.5442],\n",
            "        [-2.0089,  1.4936,  0.2800],\n",
            "        [-1.8543,  1.9950, -0.0846],\n",
            "        [-2.0088,  0.5582,  1.0771]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2311,  2.2924, -0.0979],\n",
            "        [-2.1339,  1.1902,  0.8105],\n",
            "        [-2.1072,  1.8472, -0.0532],\n",
            "        [-2.1660,  1.7961,  0.3066],\n",
            "        [-1.8965,  2.1118, -0.0910],\n",
            "        [-1.9602,  1.7418,  0.1977],\n",
            "        [-2.1132,  1.0653,  0.7909],\n",
            "        [ 0.5655,  0.2005, -1.0329],\n",
            "        [-1.9815,  2.0200,  0.1004],\n",
            "        [-2.3077,  1.2203,  0.7309],\n",
            "        [-2.2247,  2.1043, -0.2468],\n",
            "        [-2.4094,  1.7049,  0.2608],\n",
            "        [-2.1585,  2.0884, -0.0328],\n",
            "        [-2.2957,  1.2068,  0.8818],\n",
            "        [-2.4039,  2.5237, -0.0969],\n",
            "        [-2.1418,  2.2364, -0.2148]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.2311,  2.2924, -0.0979],\n",
            "        [-2.1339,  1.1902,  0.8105],\n",
            "        [-2.1072,  1.8472, -0.0532],\n",
            "        [-2.1660,  1.7961,  0.3066],\n",
            "        [-1.8965,  2.1118, -0.0910],\n",
            "        [-1.9602,  1.7418,  0.1977],\n",
            "        [-2.1132,  1.0653,  0.7909],\n",
            "        [ 0.5655,  0.2005, -1.0329],\n",
            "        [-1.9815,  2.0200,  0.1004],\n",
            "        [-2.3077,  1.2203,  0.7309],\n",
            "        [-2.2247,  2.1043, -0.2468],\n",
            "        [-2.4094,  1.7049,  0.2608],\n",
            "        [-2.1585,  2.0884, -0.0328],\n",
            "        [-2.2957,  1.2068,  0.8818],\n",
            "        [-2.4039,  2.5237, -0.0969],\n",
            "        [-2.1418,  2.2364, -0.2148]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0514,  0.6662,  1.1864],\n",
            "        [-2.1052,  0.8191,  1.1464],\n",
            "        [-2.1782,  1.4664,  0.5983],\n",
            "        [-1.8814,  1.4883,  0.2837],\n",
            "        [-1.9664,  1.9789, -0.0793],\n",
            "        [-2.2037,  2.2837, -0.0764],\n",
            "        [-2.0827,  0.9767,  1.1097],\n",
            "        [-2.0337,  0.8569,  1.1035],\n",
            "        [-1.9473,  0.9536,  0.9050],\n",
            "        [-2.1211,  1.1948,  0.6980],\n",
            "        [-2.2588,  1.8803,  0.5365],\n",
            "        [-1.9671,  2.0398, -0.6185],\n",
            "        [-2.1604,  2.2070, -0.3986],\n",
            "        [-2.0854,  2.1482, -0.2190],\n",
            "        [-2.1742,  0.8104,  1.0711],\n",
            "        [-2.2619,  2.3461, -0.3685]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0514,  0.6662,  1.1864],\n",
            "        [-2.1052,  0.8191,  1.1464],\n",
            "        [-2.1782,  1.4664,  0.5983],\n",
            "        [-1.8814,  1.4883,  0.2837],\n",
            "        [-1.9664,  1.9789, -0.0793],\n",
            "        [-2.2037,  2.2837, -0.0764],\n",
            "        [-2.0827,  0.9767,  1.1097],\n",
            "        [-2.0337,  0.8569,  1.1035],\n",
            "        [-1.9473,  0.9536,  0.9050],\n",
            "        [-2.1211,  1.1948,  0.6980],\n",
            "        [-2.2588,  1.8803,  0.5365],\n",
            "        [-1.9671,  2.0398, -0.6185],\n",
            "        [-2.1604,  2.2070, -0.3986],\n",
            "        [-2.0854,  2.1482, -0.2190],\n",
            "        [-2.1742,  0.8104,  1.0711],\n",
            "        [-2.2619,  2.3461, -0.3685]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9139,  2.3562, -0.3512],\n",
            "        [-1.9667,  1.8563,  0.0505],\n",
            "        [-1.9987,  2.1860, -0.2676],\n",
            "        [-0.6239,  0.4432, -0.2084],\n",
            "        [-2.2130,  1.2175,  0.8662],\n",
            "        [-2.0642,  1.9791, -0.0683],\n",
            "        [ 0.1922,  0.3218, -1.3173],\n",
            "        [-2.1448,  1.4505,  0.5662],\n",
            "        [-2.0784,  2.1678, -0.3641],\n",
            "        [-2.2039,  1.1320,  0.9414],\n",
            "        [-1.8273,  1.8800, -0.6838],\n",
            "        [-2.1827,  0.7395,  1.2455],\n",
            "        [-1.8658,  2.0844, -0.4931],\n",
            "        [-1.7452,  1.1743,  0.2445],\n",
            "        [-2.0302,  0.9575,  0.8273],\n",
            "        [-2.0712,  1.9055,  0.1502]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9139,  2.3562, -0.3512],\n",
            "        [-1.9667,  1.8563,  0.0505],\n",
            "        [-1.9987,  2.1860, -0.2676],\n",
            "        [-0.6239,  0.4432, -0.2084],\n",
            "        [-2.2130,  1.2175,  0.8662],\n",
            "        [-2.0642,  1.9791, -0.0683],\n",
            "        [ 0.1922,  0.3218, -1.3173],\n",
            "        [-2.1448,  1.4505,  0.5662],\n",
            "        [-2.0784,  2.1678, -0.3641],\n",
            "        [-2.2039,  1.1320,  0.9414],\n",
            "        [-1.8273,  1.8800, -0.6838],\n",
            "        [-2.1827,  0.7395,  1.2455],\n",
            "        [-1.8658,  2.0844, -0.4931],\n",
            "        [-1.7452,  1.1743,  0.2445],\n",
            "        [-2.0302,  0.9575,  0.8273],\n",
            "        [-2.0712,  1.9055,  0.1502]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8872,  2.0606, -0.3291],\n",
            "        [-1.8652,  1.8234, -0.1162],\n",
            "        [-1.9690,  2.1481, -0.5070],\n",
            "        [-2.0818,  1.3793,  0.6021],\n",
            "        [-2.3498,  1.5257,  0.3367],\n",
            "        [-1.8268,  1.6793,  0.0298],\n",
            "        [-2.0159,  1.7237,  0.2037],\n",
            "        [-1.9626,  1.4966,  0.3514],\n",
            "        [-2.0640,  1.0937,  0.9625],\n",
            "        [-1.8647,  2.1453, -0.5299],\n",
            "        [-2.1262,  2.2139, -0.1734],\n",
            "        [-1.9311,  2.0216, -0.4322],\n",
            "        [-2.0273,  2.1460, -0.2385],\n",
            "        [-2.0349,  2.3183, -0.3803],\n",
            "        [-2.2478,  2.1753, -0.3013],\n",
            "        [-1.6922,  2.2639, -0.4232]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8872,  2.0606, -0.3291],\n",
            "        [-1.8652,  1.8234, -0.1162],\n",
            "        [-1.9690,  2.1481, -0.5070],\n",
            "        [-2.0818,  1.3793,  0.6021],\n",
            "        [-2.3498,  1.5257,  0.3367],\n",
            "        [-1.8268,  1.6793,  0.0298],\n",
            "        [-2.0159,  1.7237,  0.2037],\n",
            "        [-1.9626,  1.4966,  0.3514],\n",
            "        [-2.0640,  1.0937,  0.9625],\n",
            "        [-1.8647,  2.1453, -0.5299],\n",
            "        [-2.1262,  2.2139, -0.1734],\n",
            "        [-1.9311,  2.0216, -0.4322],\n",
            "        [-2.0273,  2.1460, -0.2385],\n",
            "        [-2.0349,  2.3183, -0.3803],\n",
            "        [-2.2478,  2.1753, -0.3013],\n",
            "        [-1.6922,  2.2639, -0.4232]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9388,  2.0164, -0.3205],\n",
            "        [-2.2213,  0.8662,  1.1237],\n",
            "        [-2.0232,  2.1687, -0.1584],\n",
            "        [-2.1688,  1.0352,  0.6610],\n",
            "        [-1.5711,  2.1260, -0.6315],\n",
            "        [-2.2254,  0.8573,  1.2324],\n",
            "        [-1.9958,  2.0835, -0.1847],\n",
            "        [-1.9909,  2.1869, -0.4229],\n",
            "        [-2.2793,  0.9579,  0.7563],\n",
            "        [ 0.3219,  0.4891, -1.0127],\n",
            "        [-1.7119,  1.4762, -0.1566],\n",
            "        [-2.2053,  1.5150,  0.5140],\n",
            "        [ 0.3231,  0.1925, -1.1793],\n",
            "        [-2.3670,  1.0121,  0.9579],\n",
            "        [-1.8595,  2.2625, -0.2969],\n",
            "        [-1.7776,  1.8497, -0.2427]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9388,  2.0164, -0.3205],\n",
            "        [-2.2213,  0.8662,  1.1237],\n",
            "        [-2.0232,  2.1687, -0.1584],\n",
            "        [-2.1688,  1.0352,  0.6610],\n",
            "        [-1.5711,  2.1260, -0.6315],\n",
            "        [-2.2254,  0.8573,  1.2324],\n",
            "        [-1.9958,  2.0835, -0.1847],\n",
            "        [-1.9909,  2.1869, -0.4229],\n",
            "        [-2.2793,  0.9579,  0.7563],\n",
            "        [ 0.3219,  0.4891, -1.0127],\n",
            "        [-1.7119,  1.4762, -0.1566],\n",
            "        [-2.2053,  1.5150,  0.5140],\n",
            "        [ 0.3231,  0.1925, -1.1793],\n",
            "        [-2.3670,  1.0121,  0.9579],\n",
            "        [-1.8595,  2.2625, -0.2969],\n",
            "        [-1.7776,  1.8497, -0.2427]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.8686,  1.0871, -1.0531],\n",
            "        [-2.1283,  0.8494,  1.1733],\n",
            "        [ 0.2223,  0.3207, -1.1602],\n",
            "        [-1.9464,  1.0830,  0.9907],\n",
            "        [ 0.5824,  0.1679, -1.0490],\n",
            "        [-2.2349,  1.5490,  0.5563],\n",
            "        [-1.9089,  1.7658,  0.0983],\n",
            "        [-1.7387,  2.1923, -0.4414],\n",
            "        [ 0.4879,  0.0481, -1.2778],\n",
            "        [-2.2017,  1.9462, -0.2898],\n",
            "        [-2.0897,  0.7600,  1.4555],\n",
            "        [-1.9588,  1.9699, -0.4351],\n",
            "        [-2.0103,  2.0239,  0.0034],\n",
            "        [-2.2882,  1.9479,  0.3035],\n",
            "        [-1.9978,  1.9574,  0.0646],\n",
            "        [-2.1032,  1.3513,  0.6440]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-0.8686,  1.0871, -1.0531],\n",
            "        [-2.1283,  0.8494,  1.1733],\n",
            "        [ 0.2223,  0.3207, -1.1602],\n",
            "        [-1.9464,  1.0830,  0.9907],\n",
            "        [ 0.5824,  0.1679, -1.0490],\n",
            "        [-2.2349,  1.5490,  0.5563],\n",
            "        [-1.9089,  1.7658,  0.0983],\n",
            "        [-1.7387,  2.1923, -0.4414],\n",
            "        [ 0.4879,  0.0481, -1.2778],\n",
            "        [-2.2017,  1.9462, -0.2898],\n",
            "        [-2.0897,  0.7600,  1.4555],\n",
            "        [-1.9588,  1.9699, -0.4351],\n",
            "        [-2.0103,  2.0239,  0.0034],\n",
            "        [-2.2882,  1.9479,  0.3035],\n",
            "        [-1.9978,  1.9574,  0.0646],\n",
            "        [-2.1032,  1.3513,  0.6440]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7189,  2.0344, -0.3572],\n",
            "        [-2.2466,  0.7972,  1.2925],\n",
            "        [-2.2966,  0.6322,  1.3553],\n",
            "        [-1.7663,  1.9830, -0.0770],\n",
            "        [-1.9963,  2.2055, -0.4502],\n",
            "        [ 0.4413,  0.1240, -1.1291],\n",
            "        [-2.0067,  0.8859,  0.9538],\n",
            "        [-1.7986,  2.0446, -0.4022],\n",
            "        [ 0.2777,  0.2000, -1.0955],\n",
            "        [-2.0470,  1.8594,  0.1087],\n",
            "        [-1.9738,  2.0176, -0.4938],\n",
            "        [-2.3844,  2.0454,  0.0254],\n",
            "        [-2.0686,  1.6555,  0.0998],\n",
            "        [ 0.4743,  0.1123, -1.2973],\n",
            "        [-1.9361,  0.7926,  0.9768],\n",
            "        [-2.0946,  0.7633,  1.3169]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7189,  2.0344, -0.3572],\n",
            "        [-2.2466,  0.7972,  1.2925],\n",
            "        [-2.2966,  0.6322,  1.3553],\n",
            "        [-1.7663,  1.9830, -0.0770],\n",
            "        [-1.9963,  2.2055, -0.4502],\n",
            "        [ 0.4413,  0.1240, -1.1291],\n",
            "        [-2.0067,  0.8859,  0.9538],\n",
            "        [-1.7986,  2.0446, -0.4022],\n",
            "        [ 0.2777,  0.2000, -1.0955],\n",
            "        [-2.0470,  1.8594,  0.1087],\n",
            "        [-1.9738,  2.0176, -0.4938],\n",
            "        [-2.3844,  2.0454,  0.0254],\n",
            "        [-2.0686,  1.6555,  0.0998],\n",
            "        [ 0.4743,  0.1123, -1.2973],\n",
            "        [-1.9361,  0.7926,  0.9768],\n",
            "        [-2.0946,  0.7633,  1.3169]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7154,  1.9449, -0.3431],\n",
            "        [-1.8105,  2.0477, -0.2544],\n",
            "        [-1.8874,  2.3700, -0.5358],\n",
            "        [-2.2082,  0.6538,  0.9779],\n",
            "        [-2.4088,  1.9239,  0.1366],\n",
            "        [-2.3036,  0.8239,  1.2682],\n",
            "        [-2.0500,  2.0913, -0.1734],\n",
            "        [-2.0138,  1.8660, -0.2755],\n",
            "        [-2.1912,  0.8106,  1.1464],\n",
            "        [-1.6172,  1.4804, -0.2241],\n",
            "        [-1.8160,  2.0625, -0.4677],\n",
            "        [-2.0589,  0.8034,  1.1179],\n",
            "        [-2.1970,  0.7355,  0.9959],\n",
            "        [-2.0698,  1.7817, -0.3276],\n",
            "        [-1.9610,  2.0590, -0.2073],\n",
            "        [-1.8235,  2.1269, -0.4578]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7154,  1.9449, -0.3431],\n",
            "        [-1.8105,  2.0477, -0.2544],\n",
            "        [-1.8874,  2.3700, -0.5358],\n",
            "        [-2.2082,  0.6538,  0.9779],\n",
            "        [-2.4088,  1.9239,  0.1366],\n",
            "        [-2.3036,  0.8239,  1.2682],\n",
            "        [-2.0500,  2.0913, -0.1734],\n",
            "        [-2.0138,  1.8660, -0.2755],\n",
            "        [-2.1912,  0.8106,  1.1464],\n",
            "        [-1.6172,  1.4804, -0.2241],\n",
            "        [-1.8160,  2.0625, -0.4677],\n",
            "        [-2.0589,  0.8034,  1.1179],\n",
            "        [-2.1970,  0.7355,  0.9959],\n",
            "        [-2.0698,  1.7817, -0.3276],\n",
            "        [-1.9610,  2.0590, -0.2073],\n",
            "        [-1.8235,  2.1269, -0.4578]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1970,  0.5930,  1.0666],\n",
            "        [-1.9896,  1.9537, -0.0040],\n",
            "        [-2.0595,  1.8562, -0.0367],\n",
            "        [-1.9353,  1.9823,  0.0869],\n",
            "        [-2.1829,  1.8686,  0.3783],\n",
            "        [-1.9221,  1.8241,  0.0532],\n",
            "        [-1.9347,  1.8213,  0.0580],\n",
            "        [-1.6863,  1.8631, -0.1141],\n",
            "        [-2.0152,  1.7506, -0.2285],\n",
            "        [-1.6510,  1.9609, -0.0419],\n",
            "        [-2.1363,  1.4063,  0.6277],\n",
            "        [-2.0481,  2.1436, -0.1913],\n",
            "        [-1.6951,  2.0708, -0.3254],\n",
            "        [-2.0578,  2.0421, -0.1338],\n",
            "        [-1.6647,  2.0276, -0.3033],\n",
            "        [-1.8332,  1.9415, -0.1836]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1970,  0.5930,  1.0666],\n",
            "        [-1.9896,  1.9537, -0.0040],\n",
            "        [-2.0595,  1.8562, -0.0367],\n",
            "        [-1.9353,  1.9823,  0.0869],\n",
            "        [-2.1829,  1.8686,  0.3783],\n",
            "        [-1.9221,  1.8241,  0.0532],\n",
            "        [-1.9347,  1.8213,  0.0580],\n",
            "        [-1.6863,  1.8631, -0.1141],\n",
            "        [-2.0152,  1.7506, -0.2285],\n",
            "        [-1.6510,  1.9609, -0.0419],\n",
            "        [-2.1363,  1.4063,  0.6277],\n",
            "        [-2.0481,  2.1436, -0.1913],\n",
            "        [-1.6951,  2.0708, -0.3254],\n",
            "        [-2.0578,  2.0421, -0.1338],\n",
            "        [-1.6647,  2.0276, -0.3033],\n",
            "        [-1.8332,  1.9415, -0.1836]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2087,  0.7629,  1.0986],\n",
            "        [-1.6403,  2.0309, -0.1931],\n",
            "        [-1.8835,  1.9050, -0.1246],\n",
            "        [ 0.5479, -0.0344, -1.1814],\n",
            "        [-2.1120,  0.4799,  1.2377],\n",
            "        [-1.9582,  1.5319,  0.1563],\n",
            "        [-1.9804,  1.7348, -0.1086],\n",
            "        [-2.2280,  0.7240,  0.9942],\n",
            "        [-2.0100,  0.5300,  1.1412],\n",
            "        [-2.1200,  2.0063,  0.2847],\n",
            "        [-2.0005,  2.1343, -0.0097],\n",
            "        [-2.0915,  1.3479,  0.4842],\n",
            "        [-2.2187,  0.7657,  1.3719],\n",
            "        [-1.8058,  1.6183,  0.4307],\n",
            "        [-2.0920,  0.5567,  1.3353],\n",
            "        [-1.9170,  1.5540,  0.1022]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.2087,  0.7629,  1.0986],\n",
            "        [-1.6403,  2.0309, -0.1931],\n",
            "        [-1.8835,  1.9050, -0.1246],\n",
            "        [ 0.5479, -0.0344, -1.1814],\n",
            "        [-2.1120,  0.4799,  1.2377],\n",
            "        [-1.9582,  1.5319,  0.1563],\n",
            "        [-1.9804,  1.7348, -0.1086],\n",
            "        [-2.2280,  0.7240,  0.9942],\n",
            "        [-2.0100,  0.5300,  1.1412],\n",
            "        [-2.1200,  2.0063,  0.2847],\n",
            "        [-2.0005,  2.1343, -0.0097],\n",
            "        [-2.0915,  1.3479,  0.4842],\n",
            "        [-2.2187,  0.7657,  1.3719],\n",
            "        [-1.8058,  1.6183,  0.4307],\n",
            "        [-2.0920,  0.5567,  1.3353],\n",
            "        [-1.9170,  1.5540,  0.1022]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0278,  1.8908, -0.2736],\n",
            "        [-1.3840,  1.9021, -0.2669],\n",
            "        [-2.0637,  1.7744,  0.0559],\n",
            "        [-2.2556,  0.6597,  1.3678],\n",
            "        [-1.9330,  2.0550, -0.1579],\n",
            "        [-1.6871,  1.8936, -0.1408],\n",
            "        [-1.7916,  1.3348,  0.1654],\n",
            "        [ 0.0492, -0.0736, -0.8351],\n",
            "        [-1.8045,  2.0300,  0.0110],\n",
            "        [-2.0068,  0.6566,  1.1385],\n",
            "        [-1.8764,  1.8574, -0.3144],\n",
            "        [-1.5660,  1.7840, -0.1910],\n",
            "        [-1.7235,  1.6467, -0.0088],\n",
            "        [-2.3584,  0.5117,  1.2204],\n",
            "        [-1.8502,  1.7716, -0.2059],\n",
            "        [-1.8308,  1.8270,  0.0588]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0278,  1.8908, -0.2736],\n",
            "        [-1.3840,  1.9021, -0.2669],\n",
            "        [-2.0637,  1.7744,  0.0559],\n",
            "        [-2.2556,  0.6597,  1.3678],\n",
            "        [-1.9330,  2.0550, -0.1579],\n",
            "        [-1.6871,  1.8936, -0.1408],\n",
            "        [-1.7916,  1.3348,  0.1654],\n",
            "        [ 0.0492, -0.0736, -0.8351],\n",
            "        [-1.8045,  2.0300,  0.0110],\n",
            "        [-2.0068,  0.6566,  1.1385],\n",
            "        [-1.8764,  1.8574, -0.3144],\n",
            "        [-1.5660,  1.7840, -0.1910],\n",
            "        [-1.7235,  1.6467, -0.0088],\n",
            "        [-2.3584,  0.5117,  1.2204],\n",
            "        [-1.8502,  1.7716, -0.2059],\n",
            "        [-1.8308,  1.8270,  0.0588]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3042,  0.0834, -1.0186],\n",
            "        [ 0.5261,  0.2989, -1.0544],\n",
            "        [ 0.0732,  0.1672, -0.8858],\n",
            "        [-2.2367,  1.4680,  0.7288],\n",
            "        [-2.0157,  1.0832,  0.8136],\n",
            "        [-2.0268,  0.5264,  1.3172],\n",
            "        [-2.0650,  0.6487,  1.3167],\n",
            "        [-2.2156,  0.4208,  1.4343],\n",
            "        [-1.9827,  1.3227,  0.5005],\n",
            "        [-1.6410,  1.5831, -0.1982],\n",
            "        [ 0.0243,  0.5582, -1.2556],\n",
            "        [-2.2211,  0.5077,  1.4161],\n",
            "        [-2.1026,  1.3324,  0.5239],\n",
            "        [-1.9045,  1.6342,  0.1501],\n",
            "        [-2.1811,  0.7340,  1.1671],\n",
            "        [-1.8886,  1.8908, -0.0637]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.3042,  0.0834, -1.0186],\n",
            "        [ 0.5261,  0.2989, -1.0544],\n",
            "        [ 0.0732,  0.1672, -0.8858],\n",
            "        [-2.2367,  1.4680,  0.7288],\n",
            "        [-2.0157,  1.0832,  0.8136],\n",
            "        [-2.0268,  0.5264,  1.3172],\n",
            "        [-2.0650,  0.6487,  1.3167],\n",
            "        [-2.2156,  0.4208,  1.4343],\n",
            "        [-1.9827,  1.3227,  0.5005],\n",
            "        [-1.6410,  1.5831, -0.1982],\n",
            "        [ 0.0243,  0.5582, -1.2556],\n",
            "        [-2.2211,  0.5077,  1.4161],\n",
            "        [-2.1026,  1.3324,  0.5239],\n",
            "        [-1.9045,  1.6342,  0.1501],\n",
            "        [-2.1811,  0.7340,  1.1671],\n",
            "        [-1.8886,  1.8908, -0.0637]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2261,  0.8265,  1.0314],\n",
            "        [-1.8933,  1.7015,  0.0422],\n",
            "        [-1.8279,  1.7596,  0.1928],\n",
            "        [ 0.2714,  0.1915, -1.2193],\n",
            "        [-1.9945,  0.3763,  1.2884],\n",
            "        [ 0.3528,  0.1377, -1.1414],\n",
            "        [-2.0828,  0.7120,  1.0043],\n",
            "        [-1.9875,  1.6742, -0.0034],\n",
            "        [-2.4305,  0.4432,  1.1049],\n",
            "        [-2.0035,  2.0194, -0.2675],\n",
            "        [-2.1909,  1.3040,  0.8690],\n",
            "        [-2.0237,  1.6685,  0.4271],\n",
            "        [-0.7284,  0.8303, -0.6147],\n",
            "        [-1.8342,  1.9407, -0.1105],\n",
            "        [-0.9474,  0.6769,  0.0580],\n",
            "        [-1.4441,  1.4388, -0.4503]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.2261,  0.8265,  1.0314],\n",
            "        [-1.8933,  1.7015,  0.0422],\n",
            "        [-1.8279,  1.7596,  0.1928],\n",
            "        [ 0.2714,  0.1915, -1.2193],\n",
            "        [-1.9945,  0.3763,  1.2884],\n",
            "        [ 0.3528,  0.1377, -1.1414],\n",
            "        [-2.0828,  0.7120,  1.0043],\n",
            "        [-1.9875,  1.6742, -0.0034],\n",
            "        [-2.4305,  0.4432,  1.1049],\n",
            "        [-2.0035,  2.0194, -0.2675],\n",
            "        [-2.1909,  1.3040,  0.8690],\n",
            "        [-2.0237,  1.6685,  0.4271],\n",
            "        [-0.7284,  0.8303, -0.6147],\n",
            "        [-1.8342,  1.9407, -0.1105],\n",
            "        [-0.9474,  0.6769,  0.0580],\n",
            "        [-1.4441,  1.4388, -0.4503]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1482,  1.6674,  0.2930],\n",
            "        [-1.7846,  1.7235, -0.1688],\n",
            "        [-2.1723,  0.5135,  1.1611],\n",
            "        [-2.0015,  1.1555,  0.7705],\n",
            "        [-2.1270,  0.6100,  1.3642],\n",
            "        [-1.8389,  1.1873,  0.4985],\n",
            "        [-1.3353,  1.9103, -0.7445],\n",
            "        [-2.2503,  0.9338,  0.8591],\n",
            "        [-1.7451,  1.8111, -0.3168],\n",
            "        [-1.9300,  0.4947,  1.0909],\n",
            "        [ 0.4307,  0.1548, -1.0834],\n",
            "        [-1.7191,  1.9828, -0.5884],\n",
            "        [-1.9049,  1.8715,  0.0687],\n",
            "        [-2.2866,  0.6291,  1.2506],\n",
            "        [-1.3070,  1.7469, -0.3807],\n",
            "        [-2.1939,  0.7004,  1.1158]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1482,  1.6674,  0.2930],\n",
            "        [-1.7846,  1.7235, -0.1688],\n",
            "        [-2.1723,  0.5135,  1.1611],\n",
            "        [-2.0015,  1.1555,  0.7705],\n",
            "        [-2.1270,  0.6100,  1.3642],\n",
            "        [-1.8389,  1.1873,  0.4985],\n",
            "        [-1.3353,  1.9103, -0.7445],\n",
            "        [-2.2503,  0.9338,  0.8591],\n",
            "        [-1.7451,  1.8111, -0.3168],\n",
            "        [-1.9300,  0.4947,  1.0909],\n",
            "        [ 0.4307,  0.1548, -1.0834],\n",
            "        [-1.7191,  1.9828, -0.5884],\n",
            "        [-1.9049,  1.8715,  0.0687],\n",
            "        [-2.2866,  0.6291,  1.2506],\n",
            "        [-1.3070,  1.7469, -0.3807],\n",
            "        [-2.1939,  0.7004,  1.1158]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7744e+00,  1.7364e+00, -6.3627e-04],\n",
            "        [-1.9365e+00,  1.7298e+00,  5.1011e-02],\n",
            "        [-2.3246e+00,  6.3141e-01,  1.1653e+00],\n",
            "        [-1.7655e+00,  1.8608e+00, -1.8253e-01],\n",
            "        [-1.7896e+00,  1.4309e+00,  4.0192e-01],\n",
            "        [-2.2204e+00,  8.0701e-01,  1.3499e+00],\n",
            "        [-1.9006e+00,  1.2636e+00,  6.4173e-01],\n",
            "        [-2.2342e+00,  4.2685e-01,  1.4329e+00],\n",
            "        [-2.0919e+00,  1.2427e+00,  5.8822e-01],\n",
            "        [-1.9874e+00,  6.0888e-01,  1.2794e+00],\n",
            "        [-1.7835e+00,  1.6690e+00, -2.7327e-01],\n",
            "        [-1.4783e+00,  1.6507e+00, -5.4078e-01],\n",
            "        [-1.5066e+00,  1.7956e+00, -3.4990e-01],\n",
            "        [-1.9172e+00,  1.4412e+00,  5.6498e-02],\n",
            "        [ 4.2814e-01,  6.6264e-02, -1.0610e+00],\n",
            "        [-2.0578e+00,  9.6868e-01,  8.9048e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7744e+00,  1.7364e+00, -6.3627e-04],\n",
            "        [-1.9365e+00,  1.7298e+00,  5.1011e-02],\n",
            "        [-2.3246e+00,  6.3141e-01,  1.1653e+00],\n",
            "        [-1.7655e+00,  1.8608e+00, -1.8253e-01],\n",
            "        [-1.7896e+00,  1.4309e+00,  4.0192e-01],\n",
            "        [-2.2204e+00,  8.0701e-01,  1.3499e+00],\n",
            "        [-1.9006e+00,  1.2636e+00,  6.4173e-01],\n",
            "        [-2.2342e+00,  4.2685e-01,  1.4329e+00],\n",
            "        [-2.0919e+00,  1.2427e+00,  5.8822e-01],\n",
            "        [-1.9874e+00,  6.0888e-01,  1.2794e+00],\n",
            "        [-1.7835e+00,  1.6690e+00, -2.7327e-01],\n",
            "        [-1.4783e+00,  1.6507e+00, -5.4078e-01],\n",
            "        [-1.5066e+00,  1.7956e+00, -3.4990e-01],\n",
            "        [-1.9172e+00,  1.4412e+00,  5.6498e-02],\n",
            "        [ 4.2814e-01,  6.6264e-02, -1.0610e+00],\n",
            "        [-2.0578e+00,  9.6868e-01,  8.9048e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.4371,  0.1817, -1.2157],\n",
            "        [-1.9783,  0.5664,  1.3216],\n",
            "        [-1.5641,  1.9293, -0.4354],\n",
            "        [-1.7390,  1.5558,  0.2335],\n",
            "        [-1.6193,  1.7487, -0.2610],\n",
            "        [-1.6541,  1.7739, -0.0443],\n",
            "        [-1.6481,  1.6558, -0.1084],\n",
            "        [-1.7813,  1.8264, -0.3801],\n",
            "        [ 0.6431,  0.1650, -1.2940],\n",
            "        [-2.3928,  0.6681,  1.3511],\n",
            "        [-2.0799,  0.7426,  1.0916],\n",
            "        [-1.8469,  1.5887,  0.2574],\n",
            "        [-1.9951,  1.7347,  0.1130],\n",
            "        [-2.1654,  0.3064,  1.3908],\n",
            "        [-1.7673,  1.8243, -0.3023],\n",
            "        [-1.5140,  1.7581, -0.2221]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.4371,  0.1817, -1.2157],\n",
            "        [-1.9783,  0.5664,  1.3216],\n",
            "        [-1.5641,  1.9293, -0.4354],\n",
            "        [-1.7390,  1.5558,  0.2335],\n",
            "        [-1.6193,  1.7487, -0.2610],\n",
            "        [-1.6541,  1.7739, -0.0443],\n",
            "        [-1.6481,  1.6558, -0.1084],\n",
            "        [-1.7813,  1.8264, -0.3801],\n",
            "        [ 0.6431,  0.1650, -1.2940],\n",
            "        [-2.3928,  0.6681,  1.3511],\n",
            "        [-2.0799,  0.7426,  1.0916],\n",
            "        [-1.8469,  1.5887,  0.2574],\n",
            "        [-1.9951,  1.7347,  0.1130],\n",
            "        [-2.1654,  0.3064,  1.3908],\n",
            "        [-1.7673,  1.8243, -0.3023],\n",
            "        [-1.5140,  1.7581, -0.2221]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7700,  2.1070, -0.4344],\n",
            "        [-2.0502,  0.8251,  1.2017],\n",
            "        [-1.9414,  1.1882,  0.6461],\n",
            "        [-2.0006,  0.6326,  1.1504],\n",
            "        [-1.5521,  1.7761, -0.3503],\n",
            "        [-1.6646,  1.8528, -0.4455],\n",
            "        [ 0.4389,  0.1613, -1.1754],\n",
            "        [-2.0899,  0.8782,  0.9366],\n",
            "        [-2.0900,  0.4649,  1.2380],\n",
            "        [-2.0120,  1.6263,  0.2856],\n",
            "        [ 0.5829,  0.1119, -1.3963],\n",
            "        [-1.8621,  1.8334, -0.3072],\n",
            "        [-2.0085,  1.4782,  0.1588],\n",
            "        [-1.8724,  1.7935, -0.0454],\n",
            "        [-1.6974,  1.6192, -0.0245],\n",
            "        [-1.5445,  1.8455, -0.4327]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7700,  2.1070, -0.4344],\n",
            "        [-2.0502,  0.8251,  1.2017],\n",
            "        [-1.9414,  1.1882,  0.6461],\n",
            "        [-2.0006,  0.6326,  1.1504],\n",
            "        [-1.5521,  1.7761, -0.3503],\n",
            "        [-1.6646,  1.8528, -0.4455],\n",
            "        [ 0.4389,  0.1613, -1.1754],\n",
            "        [-2.0899,  0.8782,  0.9366],\n",
            "        [-2.0900,  0.4649,  1.2380],\n",
            "        [-2.0120,  1.6263,  0.2856],\n",
            "        [ 0.5829,  0.1119, -1.3963],\n",
            "        [-1.8621,  1.8334, -0.3072],\n",
            "        [-2.0085,  1.4782,  0.1588],\n",
            "        [-1.8724,  1.7935, -0.0454],\n",
            "        [-1.6974,  1.6192, -0.0245],\n",
            "        [-1.5445,  1.8455, -0.4327]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0680,  0.3846,  1.2530],\n",
            "        [ 0.6308,  0.0650, -1.2821],\n",
            "        [-1.7752,  1.5327,  0.0805],\n",
            "        [-1.9280,  0.5050,  1.3407],\n",
            "        [-2.0894,  0.4448,  1.2733],\n",
            "        [ 0.6226,  0.2591, -1.3792],\n",
            "        [-1.4537,  1.7601, -0.2921],\n",
            "        [-2.0502,  0.5032,  1.3378],\n",
            "        [ 0.7016, -0.0450, -1.2358],\n",
            "        [-2.1957,  0.4968,  1.4407],\n",
            "        [-1.5155,  1.8496, -0.2407],\n",
            "        [ 0.3676, -0.0127, -1.1029],\n",
            "        [-1.4867,  1.6405, -0.4090],\n",
            "        [-1.5140,  1.5658, -0.0469],\n",
            "        [-1.8889,  1.5298,  0.2135],\n",
            "        [-2.0844,  0.5865,  1.2108]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0680,  0.3846,  1.2530],\n",
            "        [ 0.6308,  0.0650, -1.2821],\n",
            "        [-1.7752,  1.5327,  0.0805],\n",
            "        [-1.9280,  0.5050,  1.3407],\n",
            "        [-2.0894,  0.4448,  1.2733],\n",
            "        [ 0.6226,  0.2591, -1.3792],\n",
            "        [-1.4537,  1.7601, -0.2921],\n",
            "        [-2.0502,  0.5032,  1.3378],\n",
            "        [ 0.7016, -0.0450, -1.2358],\n",
            "        [-2.1957,  0.4968,  1.4407],\n",
            "        [-1.5155,  1.8496, -0.2407],\n",
            "        [ 0.3676, -0.0127, -1.1029],\n",
            "        [-1.4867,  1.6405, -0.4090],\n",
            "        [-1.5140,  1.5658, -0.0469],\n",
            "        [-1.8889,  1.5298,  0.2135],\n",
            "        [-2.0844,  0.5865,  1.2108]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4275,  1.8857, -0.5434],\n",
            "        [-1.5677,  1.8403, -0.3143],\n",
            "        [-1.6145,  1.4749, -0.0973],\n",
            "        [ 0.3514,  0.3503, -1.2969],\n",
            "        [-1.5124,  1.5743, -0.2030],\n",
            "        [-2.2980,  0.6132,  1.1091],\n",
            "        [-1.9034,  1.7228,  0.0600],\n",
            "        [-1.4194,  1.5877, -0.2764],\n",
            "        [-2.0004,  0.8539,  0.8033],\n",
            "        [-1.9444,  1.1276,  0.7114],\n",
            "        [-2.2329,  1.1517,  1.0604],\n",
            "        [-2.0356,  0.6334,  1.1168],\n",
            "        [-2.2653,  0.4814,  1.2836],\n",
            "        [-1.8935,  2.0770, -0.1364],\n",
            "        [-1.4758,  1.4741,  0.1013],\n",
            "        [-2.1497,  0.3690,  1.3492]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4275,  1.8857, -0.5434],\n",
            "        [-1.5677,  1.8403, -0.3143],\n",
            "        [-1.6145,  1.4749, -0.0973],\n",
            "        [ 0.3514,  0.3503, -1.2969],\n",
            "        [-1.5124,  1.5743, -0.2030],\n",
            "        [-2.2980,  0.6132,  1.1091],\n",
            "        [-1.9034,  1.7228,  0.0600],\n",
            "        [-1.4194,  1.5877, -0.2764],\n",
            "        [-2.0004,  0.8539,  0.8033],\n",
            "        [-1.9444,  1.1276,  0.7114],\n",
            "        [-2.2329,  1.1517,  1.0604],\n",
            "        [-2.0356,  0.6334,  1.1168],\n",
            "        [-2.2653,  0.4814,  1.2836],\n",
            "        [-1.8935,  2.0770, -0.1364],\n",
            "        [-1.4758,  1.4741,  0.1013],\n",
            "        [-2.1497,  0.3690,  1.3492]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6036,  1.7754, -0.3838],\n",
            "        [-1.6627,  1.4591,  0.3960],\n",
            "        [-2.1452,  0.7919,  1.1798],\n",
            "        [-1.5158,  1.5349, -0.3259],\n",
            "        [-1.5010,  1.6189, -0.3564],\n",
            "        [-1.7613,  0.7688,  0.7064],\n",
            "        [-1.6792,  1.8220, -0.2262],\n",
            "        [-1.4458,  1.6376, -0.3246],\n",
            "        [-1.8705,  0.4658,  1.2202],\n",
            "        [-1.4303,  1.5731, -0.0331],\n",
            "        [-1.5753,  1.4748, -0.1590],\n",
            "        [-2.1266,  0.5016,  1.1647],\n",
            "        [ 0.8696, -0.0408, -1.2907],\n",
            "        [-2.1133,  0.5985,  1.3193],\n",
            "        [-1.1906,  1.9480, -0.4931],\n",
            "        [-1.3779,  1.6936, -0.4467]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6036,  1.7754, -0.3838],\n",
            "        [-1.6627,  1.4591,  0.3960],\n",
            "        [-2.1452,  0.7919,  1.1798],\n",
            "        [-1.5158,  1.5349, -0.3259],\n",
            "        [-1.5010,  1.6189, -0.3564],\n",
            "        [-1.7613,  0.7688,  0.7064],\n",
            "        [-1.6792,  1.8220, -0.2262],\n",
            "        [-1.4458,  1.6376, -0.3246],\n",
            "        [-1.8705,  0.4658,  1.2202],\n",
            "        [-1.4303,  1.5731, -0.0331],\n",
            "        [-1.5753,  1.4748, -0.1590],\n",
            "        [-2.1266,  0.5016,  1.1647],\n",
            "        [ 0.8696, -0.0408, -1.2907],\n",
            "        [-2.1133,  0.5985,  1.3193],\n",
            "        [-1.1906,  1.9480, -0.4931],\n",
            "        [-1.3779,  1.6936, -0.4467]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6430,  1.8200, -0.4528],\n",
            "        [-2.1152,  0.7125,  1.2232],\n",
            "        [-1.8913,  1.2449,  0.4786],\n",
            "        [-2.0824,  0.6900,  1.2677],\n",
            "        [-1.8490,  1.2789,  0.6043],\n",
            "        [-1.2817,  1.5467, -0.6196],\n",
            "        [-1.4578,  1.8085, -0.3809],\n",
            "        [-1.3479,  1.5987, -0.3484],\n",
            "        [ 0.8639, -0.0292, -1.1289],\n",
            "        [-1.6943,  1.0639,  0.2872],\n",
            "        [-1.3530,  1.6270, -0.3142],\n",
            "        [-2.1100,  0.5202,  1.3543],\n",
            "        [-1.4582,  1.7935, -0.5642],\n",
            "        [-2.1298,  0.4163,  1.4155],\n",
            "        [-1.6560,  1.5863, -0.2836],\n",
            "        [-1.3569,  1.4009, -0.0364]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6430,  1.8200, -0.4528],\n",
            "        [-2.1152,  0.7125,  1.2232],\n",
            "        [-1.8913,  1.2449,  0.4786],\n",
            "        [-2.0824,  0.6900,  1.2677],\n",
            "        [-1.8490,  1.2789,  0.6043],\n",
            "        [-1.2817,  1.5467, -0.6196],\n",
            "        [-1.4578,  1.8085, -0.3809],\n",
            "        [-1.3479,  1.5987, -0.3484],\n",
            "        [ 0.8639, -0.0292, -1.1289],\n",
            "        [-1.6943,  1.0639,  0.2872],\n",
            "        [-1.3530,  1.6270, -0.3142],\n",
            "        [-2.1100,  0.5202,  1.3543],\n",
            "        [-1.4582,  1.7935, -0.5642],\n",
            "        [-2.1298,  0.4163,  1.4155],\n",
            "        [-1.6560,  1.5863, -0.2836],\n",
            "        [-1.3569,  1.4009, -0.0364]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7091,  1.2747,  0.2455],\n",
            "        [-2.0644,  1.1379,  0.5544],\n",
            "        [-1.8658,  0.5972,  0.9914],\n",
            "        [-1.4446,  1.6457, -0.3790],\n",
            "        [-1.2427,  1.8800, -0.5873],\n",
            "        [-1.3875,  1.8957, -0.3655],\n",
            "        [ 0.6997,  0.0087, -1.4136],\n",
            "        [-1.4048,  1.9460, -0.6549],\n",
            "        [ 0.6836,  0.0296, -1.1335],\n",
            "        [-1.3977,  1.5744, -0.4604],\n",
            "        [-1.3797,  1.8501, -0.6644],\n",
            "        [-2.1322,  0.5232,  1.2318],\n",
            "        [-1.6985,  1.8314, -0.3480],\n",
            "        [-1.4587,  1.6165, -0.6113],\n",
            "        [-1.4979,  2.1582, -0.5309],\n",
            "        [-1.3282,  1.8292, -0.7027]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7091,  1.2747,  0.2455],\n",
            "        [-2.0644,  1.1379,  0.5544],\n",
            "        [-1.8658,  0.5972,  0.9914],\n",
            "        [-1.4446,  1.6457, -0.3790],\n",
            "        [-1.2427,  1.8800, -0.5873],\n",
            "        [-1.3875,  1.8957, -0.3655],\n",
            "        [ 0.6997,  0.0087, -1.4136],\n",
            "        [-1.4048,  1.9460, -0.6549],\n",
            "        [ 0.6836,  0.0296, -1.1335],\n",
            "        [-1.3977,  1.5744, -0.4604],\n",
            "        [-1.3797,  1.8501, -0.6644],\n",
            "        [-2.1322,  0.5232,  1.2318],\n",
            "        [-1.6985,  1.8314, -0.3480],\n",
            "        [-1.4587,  1.6165, -0.6113],\n",
            "        [-1.4979,  2.1582, -0.5309],\n",
            "        [-1.3282,  1.8292, -0.7027]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4307,  1.7797, -0.3557],\n",
            "        [-1.5763,  1.5317, -0.2567],\n",
            "        [-1.7503,  1.6742,  0.0958],\n",
            "        [-1.4134,  1.7317, -0.3477],\n",
            "        [-1.0490,  1.8366, -0.7156],\n",
            "        [-2.1515,  0.8311,  0.8790],\n",
            "        [-1.4899,  1.9087, -0.6580],\n",
            "        [-1.9180,  0.3413,  1.1226],\n",
            "        [-1.4417,  1.7664, -0.4665],\n",
            "        [-1.6933,  1.4883, -0.0877],\n",
            "        [-1.9794,  1.0201,  0.6594],\n",
            "        [ 0.6716,  0.0218, -1.2978],\n",
            "        [-1.7065,  1.8456, -0.1414],\n",
            "        [-1.4476,  1.8623, -0.7150],\n",
            "        [-2.0862,  1.0048,  0.9254],\n",
            "        [-2.0286,  0.7037,  1.1953]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4307,  1.7797, -0.3557],\n",
            "        [-1.5763,  1.5317, -0.2567],\n",
            "        [-1.7503,  1.6742,  0.0958],\n",
            "        [-1.4134,  1.7317, -0.3477],\n",
            "        [-1.0490,  1.8366, -0.7156],\n",
            "        [-2.1515,  0.8311,  0.8790],\n",
            "        [-1.4899,  1.9087, -0.6580],\n",
            "        [-1.9180,  0.3413,  1.1226],\n",
            "        [-1.4417,  1.7664, -0.4665],\n",
            "        [-1.6933,  1.4883, -0.0877],\n",
            "        [-1.9794,  1.0201,  0.6594],\n",
            "        [ 0.6716,  0.0218, -1.2978],\n",
            "        [-1.7065,  1.8456, -0.1414],\n",
            "        [-1.4476,  1.8623, -0.7150],\n",
            "        [-2.0862,  1.0048,  0.9254],\n",
            "        [-2.0286,  0.7037,  1.1953]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9182,  0.6705,  1.2135],\n",
            "        [-1.4147,  1.9409, -0.6385],\n",
            "        [-1.3212,  1.7437, -0.6972],\n",
            "        [-1.8652,  0.6957,  1.1057],\n",
            "        [ 0.8869,  0.0180, -1.0531],\n",
            "        [-1.8557,  0.4067,  1.1731],\n",
            "        [-1.1706,  1.7244, -0.6950],\n",
            "        [-1.5109,  1.9220, -0.5945],\n",
            "        [-2.0722,  0.4845,  1.2829],\n",
            "        [-1.2609,  1.7952, -0.4736],\n",
            "        [-1.1271,  1.7924, -0.5193],\n",
            "        [-2.0926,  0.4744,  0.8705],\n",
            "        [-2.1410,  0.3834,  1.2187],\n",
            "        [-1.7444,  1.0950,  0.4633],\n",
            "        [-2.1424,  0.4369,  1.2400],\n",
            "        [ 0.6134,  0.1705, -1.2637]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9182,  0.6705,  1.2135],\n",
            "        [-1.4147,  1.9409, -0.6385],\n",
            "        [-1.3212,  1.7437, -0.6972],\n",
            "        [-1.8652,  0.6957,  1.1057],\n",
            "        [ 0.8869,  0.0180, -1.0531],\n",
            "        [-1.8557,  0.4067,  1.1731],\n",
            "        [-1.1706,  1.7244, -0.6950],\n",
            "        [-1.5109,  1.9220, -0.5945],\n",
            "        [-2.0722,  0.4845,  1.2829],\n",
            "        [-1.2609,  1.7952, -0.4736],\n",
            "        [-1.1271,  1.7924, -0.5193],\n",
            "        [-2.0926,  0.4744,  0.8705],\n",
            "        [-2.1410,  0.3834,  1.2187],\n",
            "        [-1.7444,  1.0950,  0.4633],\n",
            "        [-2.1424,  0.4369,  1.2400],\n",
            "        [ 0.6134,  0.1705, -1.2637]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2230,  1.7260, -0.5721],\n",
            "        [ 0.4844,  0.0548, -1.2928],\n",
            "        [-1.9146,  0.4881,  1.1401],\n",
            "        [-1.1236,  1.8237, -0.6936],\n",
            "        [-1.2575,  1.8025, -0.7942],\n",
            "        [-1.7539,  0.9195,  0.7819],\n",
            "        [-1.3229,  1.7824, -0.6866],\n",
            "        [-1.2576,  1.6920, -0.7410],\n",
            "        [-1.1460,  1.6915, -0.4082],\n",
            "        [-1.2487,  1.8380, -0.6483],\n",
            "        [-1.4020,  1.9758, -0.6805],\n",
            "        [-1.4553,  1.6299, -0.5433],\n",
            "        [ 0.8784, -0.0973, -1.5148],\n",
            "        [-2.1698,  0.9719,  1.0023],\n",
            "        [-1.5623,  2.0327, -0.5930],\n",
            "        [-1.4193,  1.6842, -0.6759]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2230,  1.7260, -0.5721],\n",
            "        [ 0.4844,  0.0548, -1.2928],\n",
            "        [-1.9146,  0.4881,  1.1401],\n",
            "        [-1.1236,  1.8237, -0.6936],\n",
            "        [-1.2575,  1.8025, -0.7942],\n",
            "        [-1.7539,  0.9195,  0.7819],\n",
            "        [-1.3229,  1.7824, -0.6866],\n",
            "        [-1.2576,  1.6920, -0.7410],\n",
            "        [-1.1460,  1.6915, -0.4082],\n",
            "        [-1.2487,  1.8380, -0.6483],\n",
            "        [-1.4020,  1.9758, -0.6805],\n",
            "        [-1.4553,  1.6299, -0.5433],\n",
            "        [ 0.8784, -0.0973, -1.5148],\n",
            "        [-2.1698,  0.9719,  1.0023],\n",
            "        [-1.5623,  2.0327, -0.5930],\n",
            "        [-1.4193,  1.6842, -0.6759]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5464,  1.9728, -0.5843],\n",
            "        [ 0.2994,  0.5409, -1.3286],\n",
            "        [-1.2858,  1.9562, -0.6760],\n",
            "        [-1.3944,  1.8175, -0.5205],\n",
            "        [-1.2658,  1.9602, -0.5192],\n",
            "        [-0.9726,  1.5920, -0.6153],\n",
            "        [-1.3663,  2.0263, -0.5498],\n",
            "        [-1.1800,  2.0644, -0.8729],\n",
            "        [-1.3224,  1.8881, -0.5845],\n",
            "        [-1.1211,  1.6591, -0.6654],\n",
            "        [-1.8040,  0.8419,  1.0696],\n",
            "        [-1.3856,  1.8127, -0.5920],\n",
            "        [-1.3789,  1.7856, -0.8844],\n",
            "        [-2.0842,  0.5684,  1.3097],\n",
            "        [-1.8666,  0.4077,  1.4099],\n",
            "        [-1.1933,  1.6860, -0.6123]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5464,  1.9728, -0.5843],\n",
            "        [ 0.2994,  0.5409, -1.3286],\n",
            "        [-1.2858,  1.9562, -0.6760],\n",
            "        [-1.3944,  1.8175, -0.5205],\n",
            "        [-1.2658,  1.9602, -0.5192],\n",
            "        [-0.9726,  1.5920, -0.6153],\n",
            "        [-1.3663,  2.0263, -0.5498],\n",
            "        [-1.1800,  2.0644, -0.8729],\n",
            "        [-1.3224,  1.8881, -0.5845],\n",
            "        [-1.1211,  1.6591, -0.6654],\n",
            "        [-1.8040,  0.8419,  1.0696],\n",
            "        [-1.3856,  1.8127, -0.5920],\n",
            "        [-1.3789,  1.7856, -0.8844],\n",
            "        [-2.0842,  0.5684,  1.3097],\n",
            "        [-1.8666,  0.4077,  1.4099],\n",
            "        [-1.1933,  1.6860, -0.6123]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0654,  0.7857,  0.9667],\n",
            "        [-2.0715,  0.6821,  1.1525],\n",
            "        [-1.1638,  1.8495, -0.7548],\n",
            "        [-1.9374,  0.3100,  1.1615],\n",
            "        [-1.9757,  0.5018,  1.1756],\n",
            "        [ 0.5410,  0.5442, -1.4320],\n",
            "        [-1.1750,  1.7128, -0.7033],\n",
            "        [-1.9599,  1.4369, -0.0343],\n",
            "        [-1.6082,  1.2177,  0.2608],\n",
            "        [-2.1619,  0.3883,  1.4059],\n",
            "        [-1.2408,  1.8533, -0.6565],\n",
            "        [-2.0921,  0.4307,  1.3296],\n",
            "        [-1.2488,  1.7007, -0.5931],\n",
            "        [-1.8630,  0.7860,  0.9583],\n",
            "        [-1.2012,  1.6320, -0.7519],\n",
            "        [-0.3129,  0.4164, -0.4739]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0654,  0.7857,  0.9667],\n",
            "        [-2.0715,  0.6821,  1.1525],\n",
            "        [-1.1638,  1.8495, -0.7548],\n",
            "        [-1.9374,  0.3100,  1.1615],\n",
            "        [-1.9757,  0.5018,  1.1756],\n",
            "        [ 0.5410,  0.5442, -1.4320],\n",
            "        [-1.1750,  1.7128, -0.7033],\n",
            "        [-1.9599,  1.4369, -0.0343],\n",
            "        [-1.6082,  1.2177,  0.2608],\n",
            "        [-2.1619,  0.3883,  1.4059],\n",
            "        [-1.2408,  1.8533, -0.6565],\n",
            "        [-2.0921,  0.4307,  1.3296],\n",
            "        [-1.2488,  1.7007, -0.5931],\n",
            "        [-1.8630,  0.7860,  0.9583],\n",
            "        [-1.2012,  1.6320, -0.7519],\n",
            "        [-0.3129,  0.4164, -0.4739]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5568,  0.4292, -1.3453],\n",
            "        [-1.8409,  1.0242,  0.7166],\n",
            "        [-1.1672,  1.8231, -0.7262],\n",
            "        [-1.3786,  1.6938, -0.6403],\n",
            "        [-1.6864,  0.9725,  0.4815],\n",
            "        [-1.7907,  0.6383,  1.2391],\n",
            "        [-1.1072,  1.7749, -0.9505],\n",
            "        [ 0.6613,  0.0315, -1.3803],\n",
            "        [-1.3122,  1.7186, -0.3937],\n",
            "        [-0.1576,  1.2097, -1.3143],\n",
            "        [-2.0510,  0.5821,  1.0222],\n",
            "        [-1.4201,  1.8472, -0.7247],\n",
            "        [-1.2571,  1.8037, -0.5596],\n",
            "        [-1.2376,  1.9978, -0.7919],\n",
            "        [-1.5114,  1.8378, -0.6587],\n",
            "        [-0.9912,  1.5882, -0.9602]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.5568,  0.4292, -1.3453],\n",
            "        [-1.8409,  1.0242,  0.7166],\n",
            "        [-1.1672,  1.8231, -0.7262],\n",
            "        [-1.3786,  1.6938, -0.6403],\n",
            "        [-1.6864,  0.9725,  0.4815],\n",
            "        [-1.7907,  0.6383,  1.2391],\n",
            "        [-1.1072,  1.7749, -0.9505],\n",
            "        [ 0.6613,  0.0315, -1.3803],\n",
            "        [-1.3122,  1.7186, -0.3937],\n",
            "        [-0.1576,  1.2097, -1.3143],\n",
            "        [-2.0510,  0.5821,  1.0222],\n",
            "        [-1.4201,  1.8472, -0.7247],\n",
            "        [-1.2571,  1.8037, -0.5596],\n",
            "        [-1.2376,  1.9978, -0.7919],\n",
            "        [-1.5114,  1.8378, -0.6587],\n",
            "        [-0.9912,  1.5882, -0.9602]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3022e+00,  1.9159e+00, -7.8685e-01],\n",
            "        [ 7.0236e-01, -6.1270e-04, -1.3235e+00],\n",
            "        [-1.0925e+00,  1.6672e+00, -6.3969e-01],\n",
            "        [-1.3856e+00,  1.8600e+00, -5.8580e-01],\n",
            "        [-1.1209e+00,  1.9830e+00, -7.8471e-01],\n",
            "        [-1.1855e+00,  1.8249e+00, -7.4370e-01],\n",
            "        [-1.5269e+00,  1.7148e+00, -4.1585e-01],\n",
            "        [-1.3917e+00,  1.7128e+00, -5.0233e-01],\n",
            "        [-1.4011e+00,  2.0413e+00, -6.4042e-01],\n",
            "        [-1.9527e+00,  9.6954e-01,  8.2678e-01],\n",
            "        [-1.3062e+00,  2.2253e+00, -9.1745e-01],\n",
            "        [-1.1559e+00,  1.9323e+00, -9.1174e-01],\n",
            "        [-1.3734e+00,  1.8555e+00, -7.8837e-01],\n",
            "        [-1.1349e+00,  1.7496e+00, -6.5388e-01],\n",
            "        [ 6.0231e-01,  2.6591e-01, -1.2346e+00],\n",
            "        [ 7.0978e-01,  2.5408e-01, -1.2132e+00]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3022e+00,  1.9159e+00, -7.8685e-01],\n",
            "        [ 7.0236e-01, -6.1270e-04, -1.3235e+00],\n",
            "        [-1.0925e+00,  1.6672e+00, -6.3969e-01],\n",
            "        [-1.3856e+00,  1.8600e+00, -5.8580e-01],\n",
            "        [-1.1209e+00,  1.9830e+00, -7.8471e-01],\n",
            "        [-1.1855e+00,  1.8249e+00, -7.4370e-01],\n",
            "        [-1.5269e+00,  1.7148e+00, -4.1585e-01],\n",
            "        [-1.3917e+00,  1.7128e+00, -5.0233e-01],\n",
            "        [-1.4011e+00,  2.0413e+00, -6.4042e-01],\n",
            "        [-1.9527e+00,  9.6954e-01,  8.2678e-01],\n",
            "        [-1.3062e+00,  2.2253e+00, -9.1745e-01],\n",
            "        [-1.1559e+00,  1.9323e+00, -9.1174e-01],\n",
            "        [-1.3734e+00,  1.8555e+00, -7.8837e-01],\n",
            "        [-1.1349e+00,  1.7496e+00, -6.5388e-01],\n",
            "        [ 6.0231e-01,  2.6591e-01, -1.2346e+00],\n",
            "        [ 7.0978e-01,  2.5408e-01, -1.2132e+00]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.0045,  1.7508, -0.7985],\n",
            "        [-1.7530,  1.3519,  0.3213],\n",
            "        [-1.9702,  0.4337,  0.9729],\n",
            "        [ 0.7948,  0.0865, -1.3782],\n",
            "        [ 0.9227, -0.0269, -1.4967],\n",
            "        [-1.4366,  2.0554, -1.1314],\n",
            "        [-1.9684,  0.8793,  0.8256],\n",
            "        [-1.5901,  0.6566,  0.7490],\n",
            "        [-2.1799,  0.6012,  1.1130],\n",
            "        [-1.6804,  1.0236,  0.6753],\n",
            "        [ 0.5366,  0.2473, -1.2606],\n",
            "        [-1.1310,  1.9484, -0.9212],\n",
            "        [-0.8821,  1.8953, -0.7711],\n",
            "        [-1.2510,  1.7944, -0.4676],\n",
            "        [-1.0121,  1.8656, -0.9432],\n",
            "        [-1.2250,  1.5960, -0.8978]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.0045,  1.7508, -0.7985],\n",
            "        [-1.7530,  1.3519,  0.3213],\n",
            "        [-1.9702,  0.4337,  0.9729],\n",
            "        [ 0.7948,  0.0865, -1.3782],\n",
            "        [ 0.9227, -0.0269, -1.4967],\n",
            "        [-1.4366,  2.0554, -1.1314],\n",
            "        [-1.9684,  0.8793,  0.8256],\n",
            "        [-1.5901,  0.6566,  0.7490],\n",
            "        [-2.1799,  0.6012,  1.1130],\n",
            "        [-1.6804,  1.0236,  0.6753],\n",
            "        [ 0.5366,  0.2473, -1.2606],\n",
            "        [-1.1310,  1.9484, -0.9212],\n",
            "        [-0.8821,  1.8953, -0.7711],\n",
            "        [-1.2510,  1.7944, -0.4676],\n",
            "        [-1.0121,  1.8656, -0.9432],\n",
            "        [-1.2250,  1.5960, -0.8978]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.0879,  1.6673, -0.8520],\n",
            "        [-1.8490,  0.5803,  1.1191],\n",
            "        [-1.2699,  1.7404, -0.8651],\n",
            "        [-0.9991,  1.7683, -0.9722],\n",
            "        [-1.5849,  2.0401, -0.6617],\n",
            "        [-1.7385,  0.6299,  1.0002],\n",
            "        [-1.2610,  1.8504, -0.8388],\n",
            "        [-1.0468,  1.9685, -0.9539],\n",
            "        [-1.3102,  1.7936, -1.0276],\n",
            "        [-1.3861,  1.7502, -0.8206],\n",
            "        [-1.1645,  1.9035, -0.9399],\n",
            "        [-1.8903,  0.6225,  0.9835],\n",
            "        [-1.0608,  1.7873, -1.2894],\n",
            "        [-1.2349,  1.6266, -0.8761],\n",
            "        [-0.8548,  1.8699, -0.8309],\n",
            "        [ 0.7458,  0.1585, -1.2875]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.0879,  1.6673, -0.8520],\n",
            "        [-1.8490,  0.5803,  1.1191],\n",
            "        [-1.2699,  1.7404, -0.8651],\n",
            "        [-0.9991,  1.7683, -0.9722],\n",
            "        [-1.5849,  2.0401, -0.6617],\n",
            "        [-1.7385,  0.6299,  1.0002],\n",
            "        [-1.2610,  1.8504, -0.8388],\n",
            "        [-1.0468,  1.9685, -0.9539],\n",
            "        [-1.3102,  1.7936, -1.0276],\n",
            "        [-1.3861,  1.7502, -0.8206],\n",
            "        [-1.1645,  1.9035, -0.9399],\n",
            "        [-1.8903,  0.6225,  0.9835],\n",
            "        [-1.0608,  1.7873, -1.2894],\n",
            "        [-1.2349,  1.6266, -0.8761],\n",
            "        [-0.8548,  1.8699, -0.8309],\n",
            "        [ 0.7458,  0.1585, -1.2875]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5460,  1.5132, -0.2246],\n",
            "        [-1.1616,  1.9937, -0.9842],\n",
            "        [-1.1928,  2.0404, -0.9426],\n",
            "        [-1.0432,  1.7096, -0.9011],\n",
            "        [-1.0689,  1.8844, -1.0115],\n",
            "        [-1.0370,  1.8997, -0.7174],\n",
            "        [-1.9597,  0.3398,  1.3562],\n",
            "        [-1.3898,  1.8579, -0.7156],\n",
            "        [-1.1565,  2.0296, -1.1172],\n",
            "        [-1.7355,  1.1915,  0.6051],\n",
            "        [ 0.8996,  0.0133, -1.4088],\n",
            "        [-1.7188,  0.2684,  1.1036],\n",
            "        [-1.2149,  2.2147, -0.8110],\n",
            "        [-1.1661,  1.9460, -1.0870],\n",
            "        [-1.1402,  1.7817, -0.8169],\n",
            "        [-1.6898,  0.8359,  0.5573]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5460,  1.5132, -0.2246],\n",
            "        [-1.1616,  1.9937, -0.9842],\n",
            "        [-1.1928,  2.0404, -0.9426],\n",
            "        [-1.0432,  1.7096, -0.9011],\n",
            "        [-1.0689,  1.8844, -1.0115],\n",
            "        [-1.0370,  1.8997, -0.7174],\n",
            "        [-1.9597,  0.3398,  1.3562],\n",
            "        [-1.3898,  1.8579, -0.7156],\n",
            "        [-1.1565,  2.0296, -1.1172],\n",
            "        [-1.7355,  1.1915,  0.6051],\n",
            "        [ 0.8996,  0.0133, -1.4088],\n",
            "        [-1.7188,  0.2684,  1.1036],\n",
            "        [-1.2149,  2.2147, -0.8110],\n",
            "        [-1.1661,  1.9460, -1.0870],\n",
            "        [-1.1402,  1.7817, -0.8169],\n",
            "        [-1.6898,  0.8359,  0.5573]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.1539,  1.8567, -0.9108],\n",
            "        [-1.0757,  1.7874, -0.9408],\n",
            "        [ 0.6980,  0.1571, -1.5232],\n",
            "        [-0.9135,  1.7426, -0.8436],\n",
            "        [-1.2011,  1.9592, -0.8463],\n",
            "        [-1.1043,  1.9942, -0.8999],\n",
            "        [ 0.7722,  0.2031, -1.4467],\n",
            "        [-1.3314,  1.7983, -1.2084],\n",
            "        [-1.0578,  1.8830, -0.8569],\n",
            "        [ 0.7598,  0.1153, -1.5907],\n",
            "        [-1.1494,  2.0112, -0.7062],\n",
            "        [-1.2194,  1.9500, -0.9169],\n",
            "        [-1.0593,  1.7605, -0.9848],\n",
            "        [-0.9623,  1.7225, -0.7948],\n",
            "        [-1.1187,  1.7423, -0.6794],\n",
            "        [-0.7864,  0.3707, -0.1227]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.1539,  1.8567, -0.9108],\n",
            "        [-1.0757,  1.7874, -0.9408],\n",
            "        [ 0.6980,  0.1571, -1.5232],\n",
            "        [-0.9135,  1.7426, -0.8436],\n",
            "        [-1.2011,  1.9592, -0.8463],\n",
            "        [-1.1043,  1.9942, -0.8999],\n",
            "        [ 0.7722,  0.2031, -1.4467],\n",
            "        [-1.3314,  1.7983, -1.2084],\n",
            "        [-1.0578,  1.8830, -0.8569],\n",
            "        [ 0.7598,  0.1153, -1.5907],\n",
            "        [-1.1494,  2.0112, -0.7062],\n",
            "        [-1.2194,  1.9500, -0.9169],\n",
            "        [-1.0593,  1.7605, -0.9848],\n",
            "        [-0.9623,  1.7225, -0.7948],\n",
            "        [-1.1187,  1.7423, -0.6794],\n",
            "        [-0.7864,  0.3707, -0.1227]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2572,  2.0995, -0.9043],\n",
            "        [-1.5693,  1.1207,  0.2180],\n",
            "        [-1.7638,  0.6563,  1.2064],\n",
            "        [-1.1339,  1.8548, -0.8653],\n",
            "        [-1.8923,  0.3318,  1.0385],\n",
            "        [-1.1638,  2.0942, -0.8223],\n",
            "        [-0.9418,  1.9050, -1.1166],\n",
            "        [-1.3714,  1.6882, -0.3002],\n",
            "        [-1.1794,  1.9711, -0.9391],\n",
            "        [-1.1239,  1.7946, -0.9890],\n",
            "        [-0.9185,  1.6848, -0.7656],\n",
            "        [-1.1132,  1.8664, -1.1011],\n",
            "        [-1.0569,  1.9514, -0.8969],\n",
            "        [ 0.7641,  0.1688, -1.5592],\n",
            "        [-1.7221,  0.4351,  1.1763],\n",
            "        [-1.8044,  0.4678,  0.7190]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2572,  2.0995, -0.9043],\n",
            "        [-1.5693,  1.1207,  0.2180],\n",
            "        [-1.7638,  0.6563,  1.2064],\n",
            "        [-1.1339,  1.8548, -0.8653],\n",
            "        [-1.8923,  0.3318,  1.0385],\n",
            "        [-1.1638,  2.0942, -0.8223],\n",
            "        [-0.9418,  1.9050, -1.1166],\n",
            "        [-1.3714,  1.6882, -0.3002],\n",
            "        [-1.1794,  1.9711, -0.9391],\n",
            "        [-1.1239,  1.7946, -0.9890],\n",
            "        [-0.9185,  1.6848, -0.7656],\n",
            "        [-1.1132,  1.8664, -1.1011],\n",
            "        [-1.0569,  1.9514, -0.8969],\n",
            "        [ 0.7641,  0.1688, -1.5592],\n",
            "        [-1.7221,  0.4351,  1.1763],\n",
            "        [-1.8044,  0.4678,  0.7190]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3968,  1.1170,  0.1600],\n",
            "        [-1.1105,  1.8828, -0.9412],\n",
            "        [ 0.7416,  0.1530, -1.4807],\n",
            "        [-1.2506,  1.6742, -0.7394],\n",
            "        [-1.1582,  1.6643, -0.8424],\n",
            "        [-1.4683,  2.0730, -1.0563],\n",
            "        [-1.2266,  1.8609, -0.8621],\n",
            "        [-1.1568,  1.6935, -0.7392],\n",
            "        [-1.0782,  1.7536, -0.9230],\n",
            "        [-1.0543,  2.0300, -1.2610],\n",
            "        [-1.2875,  2.0253, -1.0269],\n",
            "        [-1.2144,  1.5157, -0.6906],\n",
            "        [-1.3458,  1.8697, -0.5831],\n",
            "        [ 0.9517,  0.1654, -1.5232],\n",
            "        [ 0.6612,  0.2588, -1.4772],\n",
            "        [-1.5680,  2.0453, -0.5553]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3968,  1.1170,  0.1600],\n",
            "        [-1.1105,  1.8828, -0.9412],\n",
            "        [ 0.7416,  0.1530, -1.4807],\n",
            "        [-1.2506,  1.6742, -0.7394],\n",
            "        [-1.1582,  1.6643, -0.8424],\n",
            "        [-1.4683,  2.0730, -1.0563],\n",
            "        [-1.2266,  1.8609, -0.8621],\n",
            "        [-1.1568,  1.6935, -0.7392],\n",
            "        [-1.0782,  1.7536, -0.9230],\n",
            "        [-1.0543,  2.0300, -1.2610],\n",
            "        [-1.2875,  2.0253, -1.0269],\n",
            "        [-1.2144,  1.5157, -0.6906],\n",
            "        [-1.3458,  1.8697, -0.5831],\n",
            "        [ 0.9517,  0.1654, -1.5232],\n",
            "        [ 0.6612,  0.2588, -1.4772],\n",
            "        [-1.5680,  2.0453, -0.5553]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9363,  0.7292,  0.9451],\n",
            "        [-0.9691,  1.8176, -0.9657],\n",
            "        [-0.1176,  1.1636, -1.3991],\n",
            "        [ 0.4409,  0.5328, -1.4785],\n",
            "        [-0.8600,  1.6185, -1.1559],\n",
            "        [-1.2246,  1.8541, -0.9727],\n",
            "        [ 1.0418,  0.0141, -1.4413],\n",
            "        [ 0.9509, -0.0255, -1.5660],\n",
            "        [-1.1041,  1.8692, -0.9663],\n",
            "        [-1.0476,  1.9305, -1.0825],\n",
            "        [-1.2880,  1.8826, -0.6314],\n",
            "        [-1.2366,  2.0376, -0.9280],\n",
            "        [-1.4903,  1.1711,  0.3159],\n",
            "        [-1.2137,  2.0383, -1.0807],\n",
            "        [-1.5031,  0.9657,  0.4169],\n",
            "        [-0.9496,  1.6362, -0.6836]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9363,  0.7292,  0.9451],\n",
            "        [-0.9691,  1.8176, -0.9657],\n",
            "        [-0.1176,  1.1636, -1.3991],\n",
            "        [ 0.4409,  0.5328, -1.4785],\n",
            "        [-0.8600,  1.6185, -1.1559],\n",
            "        [-1.2246,  1.8541, -0.9727],\n",
            "        [ 1.0418,  0.0141, -1.4413],\n",
            "        [ 0.9509, -0.0255, -1.5660],\n",
            "        [-1.1041,  1.8692, -0.9663],\n",
            "        [-1.0476,  1.9305, -1.0825],\n",
            "        [-1.2880,  1.8826, -0.6314],\n",
            "        [-1.2366,  2.0376, -0.9280],\n",
            "        [-1.4903,  1.1711,  0.3159],\n",
            "        [-1.2137,  2.0383, -1.0807],\n",
            "        [-1.5031,  0.9657,  0.4169],\n",
            "        [-0.9496,  1.6362, -0.6836]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2209,  1.7011, -0.8016],\n",
            "        [-0.2799,  0.6785, -1.1007],\n",
            "        [-1.1602,  1.8352, -0.9001],\n",
            "        [-1.9805,  0.3911,  1.3652],\n",
            "        [-1.0625,  1.8297, -0.7860],\n",
            "        [-1.1465,  1.9567, -0.8079],\n",
            "        [-1.3293,  1.8865, -0.7376],\n",
            "        [-1.6228,  0.4929,  1.1897],\n",
            "        [-2.0465,  0.4673,  1.3679],\n",
            "        [-1.3154,  1.7574, -0.3704],\n",
            "        [-0.9323,  1.6516, -0.7405],\n",
            "        [-1.6412,  0.5156,  0.9000],\n",
            "        [-1.1796,  1.8227, -0.8473],\n",
            "        [ 0.8915,  0.0726, -1.4268],\n",
            "        [-1.4766,  0.6681,  0.9950],\n",
            "        [-1.0744,  1.8677, -0.6860]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2209,  1.7011, -0.8016],\n",
            "        [-0.2799,  0.6785, -1.1007],\n",
            "        [-1.1602,  1.8352, -0.9001],\n",
            "        [-1.9805,  0.3911,  1.3652],\n",
            "        [-1.0625,  1.8297, -0.7860],\n",
            "        [-1.1465,  1.9567, -0.8079],\n",
            "        [-1.3293,  1.8865, -0.7376],\n",
            "        [-1.6228,  0.4929,  1.1897],\n",
            "        [-2.0465,  0.4673,  1.3679],\n",
            "        [-1.3154,  1.7574, -0.3704],\n",
            "        [-0.9323,  1.6516, -0.7405],\n",
            "        [-1.6412,  0.5156,  0.9000],\n",
            "        [-1.1796,  1.8227, -0.8473],\n",
            "        [ 0.8915,  0.0726, -1.4268],\n",
            "        [-1.4766,  0.6681,  0.9950],\n",
            "        [-1.0744,  1.8677, -0.6860]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2481e+00,  1.6101e+00, -6.4918e-01],\n",
            "        [ 9.0738e-01,  4.2274e-02, -1.6025e+00],\n",
            "        [-1.2278e+00,  1.8212e+00, -9.5408e-01],\n",
            "        [-1.2248e+00,  1.6238e+00, -7.1598e-01],\n",
            "        [-1.2919e+00,  1.8981e+00, -1.0462e+00],\n",
            "        [-1.2756e+00,  1.8487e+00, -7.5254e-01],\n",
            "        [-1.7241e+00,  5.8346e-01,  9.6085e-01],\n",
            "        [-1.2902e+00,  1.8767e+00, -9.1800e-01],\n",
            "        [-1.2703e+00,  1.7327e+00, -7.0105e-01],\n",
            "        [ 7.2231e-01, -9.1702e-04, -1.4584e+00],\n",
            "        [-1.8788e+00,  5.6083e-01,  1.1984e+00],\n",
            "        [-1.8518e+00,  3.5096e-01,  9.6794e-01],\n",
            "        [-1.7351e+00,  4.3894e-01,  1.2448e+00],\n",
            "        [-1.4215e+00,  2.0234e+00, -8.3062e-01],\n",
            "        [-1.1393e+00,  1.9277e+00, -7.3338e-01],\n",
            "        [-1.1849e+00,  1.7090e+00, -6.6905e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2481e+00,  1.6101e+00, -6.4918e-01],\n",
            "        [ 9.0738e-01,  4.2274e-02, -1.6025e+00],\n",
            "        [-1.2278e+00,  1.8212e+00, -9.5408e-01],\n",
            "        [-1.2248e+00,  1.6238e+00, -7.1598e-01],\n",
            "        [-1.2919e+00,  1.8981e+00, -1.0462e+00],\n",
            "        [-1.2756e+00,  1.8487e+00, -7.5254e-01],\n",
            "        [-1.7241e+00,  5.8346e-01,  9.6085e-01],\n",
            "        [-1.2902e+00,  1.8767e+00, -9.1800e-01],\n",
            "        [-1.2703e+00,  1.7327e+00, -7.0105e-01],\n",
            "        [ 7.2231e-01, -9.1702e-04, -1.4584e+00],\n",
            "        [-1.8788e+00,  5.6083e-01,  1.1984e+00],\n",
            "        [-1.8518e+00,  3.5096e-01,  9.6794e-01],\n",
            "        [-1.7351e+00,  4.3894e-01,  1.2448e+00],\n",
            "        [-1.4215e+00,  2.0234e+00, -8.3062e-01],\n",
            "        [-1.1393e+00,  1.9277e+00, -7.3338e-01],\n",
            "        [-1.1849e+00,  1.7090e+00, -6.6905e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2338,  1.7177, -0.4985],\n",
            "        [-1.1805,  1.7912, -0.6841],\n",
            "        [ 0.9378,  0.1752, -1.6889],\n",
            "        [-1.5436,  0.5266,  0.5592],\n",
            "        [-1.2166,  1.9537, -0.7880],\n",
            "        [-1.3335,  1.4409, -0.4241],\n",
            "        [-1.7363,  0.5391,  0.7738],\n",
            "        [-1.0982,  1.9428, -0.7983],\n",
            "        [-1.8147,  0.4436,  1.0849],\n",
            "        [-1.5541,  0.2378,  1.2293],\n",
            "        [-1.1311,  1.7413, -0.8503],\n",
            "        [ 0.7526, -0.0091, -1.4832],\n",
            "        [-1.0009,  1.7955, -0.9088],\n",
            "        [-1.9593,  0.2709,  1.1546],\n",
            "        [ 0.1098,  0.8952, -1.4808],\n",
            "        [ 0.8535,  0.0531, -1.6597]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2338,  1.7177, -0.4985],\n",
            "        [-1.1805,  1.7912, -0.6841],\n",
            "        [ 0.9378,  0.1752, -1.6889],\n",
            "        [-1.5436,  0.5266,  0.5592],\n",
            "        [-1.2166,  1.9537, -0.7880],\n",
            "        [-1.3335,  1.4409, -0.4241],\n",
            "        [-1.7363,  0.5391,  0.7738],\n",
            "        [-1.0982,  1.9428, -0.7983],\n",
            "        [-1.8147,  0.4436,  1.0849],\n",
            "        [-1.5541,  0.2378,  1.2293],\n",
            "        [-1.1311,  1.7413, -0.8503],\n",
            "        [ 0.7526, -0.0091, -1.4832],\n",
            "        [-1.0009,  1.7955, -0.9088],\n",
            "        [-1.9593,  0.2709,  1.1546],\n",
            "        [ 0.1098,  0.8952, -1.4808],\n",
            "        [ 0.8535,  0.0531, -1.6597]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.9450,  0.1052, -1.3090],\n",
            "        [-1.2086,  1.3895, -0.2545],\n",
            "        [-1.0190,  1.6859, -0.5554],\n",
            "        [ 0.7835,  0.0860, -1.4539],\n",
            "        [ 0.9375,  0.0878, -1.5258],\n",
            "        [-1.7934,  0.3142,  1.2431],\n",
            "        [-1.1605,  1.8327, -0.9538],\n",
            "        [-1.0869,  1.5878, -0.6539],\n",
            "        [-1.7040,  0.4626,  1.0026],\n",
            "        [-1.3446,  1.7849, -0.6961],\n",
            "        [-1.2607,  1.5759, -0.6249],\n",
            "        [-1.1654,  1.9066, -0.7969],\n",
            "        [-1.7107,  0.1848,  1.3696],\n",
            "        [-1.5572,  0.4600,  1.0537],\n",
            "        [-1.2287,  1.8028, -0.8689],\n",
            "        [-1.7073,  0.1150,  1.2444]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.9450,  0.1052, -1.3090],\n",
            "        [-1.2086,  1.3895, -0.2545],\n",
            "        [-1.0190,  1.6859, -0.5554],\n",
            "        [ 0.7835,  0.0860, -1.4539],\n",
            "        [ 0.9375,  0.0878, -1.5258],\n",
            "        [-1.7934,  0.3142,  1.2431],\n",
            "        [-1.1605,  1.8327, -0.9538],\n",
            "        [-1.0869,  1.5878, -0.6539],\n",
            "        [-1.7040,  0.4626,  1.0026],\n",
            "        [-1.3446,  1.7849, -0.6961],\n",
            "        [-1.2607,  1.5759, -0.6249],\n",
            "        [-1.1654,  1.9066, -0.7969],\n",
            "        [-1.7107,  0.1848,  1.3696],\n",
            "        [-1.5572,  0.4600,  1.0537],\n",
            "        [-1.2287,  1.8028, -0.8689],\n",
            "        [-1.7073,  0.1150,  1.2444]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7845,  0.4552,  1.2346],\n",
            "        [ 0.8440,  0.1666, -1.4210],\n",
            "        [-1.1233,  1.4841, -0.4240],\n",
            "        [-0.9956,  1.6255, -0.7161],\n",
            "        [-1.1959,  1.7438, -0.7610],\n",
            "        [ 0.8869,  0.0531, -1.4117],\n",
            "        [ 0.7825,  0.0673, -1.5320],\n",
            "        [-1.3825,  1.1081,  0.1086],\n",
            "        [ 0.1039,  0.5704, -1.3997],\n",
            "        [-1.7065,  0.2163,  1.3812],\n",
            "        [-1.2708,  1.6437, -0.5231],\n",
            "        [-1.2938,  1.2109, -0.2221],\n",
            "        [-1.2406,  1.7289, -0.7072],\n",
            "        [-1.1225,  1.5731, -0.7730],\n",
            "        [ 0.8619, -0.0785, -1.5279],\n",
            "        [-1.8423,  0.4825,  1.0006]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7845,  0.4552,  1.2346],\n",
            "        [ 0.8440,  0.1666, -1.4210],\n",
            "        [-1.1233,  1.4841, -0.4240],\n",
            "        [-0.9956,  1.6255, -0.7161],\n",
            "        [-1.1959,  1.7438, -0.7610],\n",
            "        [ 0.8869,  0.0531, -1.4117],\n",
            "        [ 0.7825,  0.0673, -1.5320],\n",
            "        [-1.3825,  1.1081,  0.1086],\n",
            "        [ 0.1039,  0.5704, -1.3997],\n",
            "        [-1.7065,  0.2163,  1.3812],\n",
            "        [-1.2708,  1.6437, -0.5231],\n",
            "        [-1.2938,  1.2109, -0.2221],\n",
            "        [-1.2406,  1.7289, -0.7072],\n",
            "        [-1.1225,  1.5731, -0.7730],\n",
            "        [ 0.8619, -0.0785, -1.5279],\n",
            "        [-1.8423,  0.4825,  1.0006]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5473,  0.7803,  0.6165],\n",
            "        [-1.4082,  0.6253,  0.5837],\n",
            "        [-1.7222,  0.4513,  0.7043],\n",
            "        [-1.7344,  0.6622,  0.9333],\n",
            "        [-1.2916,  1.6426, -0.5133],\n",
            "        [-1.6109,  0.3032,  1.0685],\n",
            "        [-1.0674,  1.5396, -0.3808],\n",
            "        [-1.1699,  1.3881, -0.4750],\n",
            "        [-1.4407,  1.4239, -0.0321],\n",
            "        [-1.6251,  0.3611,  0.8804],\n",
            "        [ 1.0697, -0.0382, -1.6058],\n",
            "        [-1.6235,  0.8798,  0.6938],\n",
            "        [-1.3666,  1.2061, -0.0809],\n",
            "        [-1.6660,  0.3404,  0.9834],\n",
            "        [ 0.8424,  0.0662, -1.4357],\n",
            "        [ 0.9498, -0.0369, -1.4848]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5473,  0.7803,  0.6165],\n",
            "        [-1.4082,  0.6253,  0.5837],\n",
            "        [-1.7222,  0.4513,  0.7043],\n",
            "        [-1.7344,  0.6622,  0.9333],\n",
            "        [-1.2916,  1.6426, -0.5133],\n",
            "        [-1.6109,  0.3032,  1.0685],\n",
            "        [-1.0674,  1.5396, -0.3808],\n",
            "        [-1.1699,  1.3881, -0.4750],\n",
            "        [-1.4407,  1.4239, -0.0321],\n",
            "        [-1.6251,  0.3611,  0.8804],\n",
            "        [ 1.0697, -0.0382, -1.6058],\n",
            "        [-1.6235,  0.8798,  0.6938],\n",
            "        [-1.3666,  1.2061, -0.0809],\n",
            "        [-1.6660,  0.3404,  0.9834],\n",
            "        [ 0.8424,  0.0662, -1.4357],\n",
            "        [ 0.9498, -0.0369, -1.4848]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7395,  0.0594,  1.2972],\n",
            "        [-1.2829,  1.5133, -0.7517],\n",
            "        [-1.5283,  0.2230,  1.0148],\n",
            "        [ 0.6335,  0.1647, -1.5151],\n",
            "        [-1.0690,  1.4453, -0.7077],\n",
            "        [-1.9143,  0.1568,  1.2654],\n",
            "        [-1.6928,  0.9902,  0.4754],\n",
            "        [ 0.7896, -0.1167, -1.3857],\n",
            "        [-1.4923,  1.4078, -0.0893],\n",
            "        [-0.8384,  1.3448, -0.3420],\n",
            "        [-1.6880,  0.1416,  1.3195],\n",
            "        [-1.3519,  1.3868, -0.1737],\n",
            "        [ 0.8461,  0.0455, -1.4572],\n",
            "        [ 0.8685, -0.0135, -1.5054],\n",
            "        [-1.9520,  0.1426,  1.3394],\n",
            "        [-1.7225,  0.2304,  1.2305]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7395,  0.0594,  1.2972],\n",
            "        [-1.2829,  1.5133, -0.7517],\n",
            "        [-1.5283,  0.2230,  1.0148],\n",
            "        [ 0.6335,  0.1647, -1.5151],\n",
            "        [-1.0690,  1.4453, -0.7077],\n",
            "        [-1.9143,  0.1568,  1.2654],\n",
            "        [-1.6928,  0.9902,  0.4754],\n",
            "        [ 0.7896, -0.1167, -1.3857],\n",
            "        [-1.4923,  1.4078, -0.0893],\n",
            "        [-0.8384,  1.3448, -0.3420],\n",
            "        [-1.6880,  0.1416,  1.3195],\n",
            "        [-1.3519,  1.3868, -0.1737],\n",
            "        [ 0.8461,  0.0455, -1.4572],\n",
            "        [ 0.8685, -0.0135, -1.5054],\n",
            "        [-1.9520,  0.1426,  1.3394],\n",
            "        [-1.7225,  0.2304,  1.2305]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4194,  1.4233, -0.4683],\n",
            "        [-1.2843,  1.5269, -0.5704],\n",
            "        [-1.2215,  1.5642, -0.6836],\n",
            "        [-1.0153,  1.2649, -0.7450],\n",
            "        [-1.0909,  1.3958, -0.4184],\n",
            "        [ 0.8235,  0.2344, -1.3819],\n",
            "        [-0.8785,  1.2923, -0.7392],\n",
            "        [-1.2760,  1.4570, -0.4326],\n",
            "        [ 0.9348,  0.1582, -1.4956],\n",
            "        [-1.2649,  1.3128, -0.3762],\n",
            "        [-1.3653,  0.9772,  0.1114],\n",
            "        [-1.1063,  1.3956, -0.3967],\n",
            "        [ 0.2966,  0.4154, -1.1788],\n",
            "        [-1.2358,  1.6846, -0.5981],\n",
            "        [-1.1069,  1.5519, -0.5028],\n",
            "        [-1.2776,  1.6619, -0.4673]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4194,  1.4233, -0.4683],\n",
            "        [-1.2843,  1.5269, -0.5704],\n",
            "        [-1.2215,  1.5642, -0.6836],\n",
            "        [-1.0153,  1.2649, -0.7450],\n",
            "        [-1.0909,  1.3958, -0.4184],\n",
            "        [ 0.8235,  0.2344, -1.3819],\n",
            "        [-0.8785,  1.2923, -0.7392],\n",
            "        [-1.2760,  1.4570, -0.4326],\n",
            "        [ 0.9348,  0.1582, -1.4956],\n",
            "        [-1.2649,  1.3128, -0.3762],\n",
            "        [-1.3653,  0.9772,  0.1114],\n",
            "        [-1.1063,  1.3956, -0.3967],\n",
            "        [ 0.2966,  0.4154, -1.1788],\n",
            "        [-1.2358,  1.6846, -0.5981],\n",
            "        [-1.1069,  1.5519, -0.5028],\n",
            "        [-1.2776,  1.6619, -0.4673]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.7311, -0.0650, -1.3182],\n",
            "        [-1.5111,  1.6931, -0.5944],\n",
            "        [-1.1448,  1.4995, -0.2483],\n",
            "        [-1.6911,  0.3942,  1.1317],\n",
            "        [-1.5439,  1.6742, -0.3924],\n",
            "        [-1.2498,  1.3907, -0.5784],\n",
            "        [-1.0719,  1.3836, -0.6486],\n",
            "        [-1.0495,  1.5175, -0.5909],\n",
            "        [-1.5975,  0.9455,  0.3678],\n",
            "        [-1.5062,  0.2657,  1.2227],\n",
            "        [-1.3058,  1.5403, -0.5557],\n",
            "        [-1.6271,  0.6143,  0.4407],\n",
            "        [-1.5424,  0.3577,  1.1948],\n",
            "        [ 0.8443, -0.0388, -1.3555],\n",
            "        [-1.8571,  0.5172,  1.1264],\n",
            "        [-1.2189,  1.3568, -0.6057]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.7311, -0.0650, -1.3182],\n",
            "        [-1.5111,  1.6931, -0.5944],\n",
            "        [-1.1448,  1.4995, -0.2483],\n",
            "        [-1.6911,  0.3942,  1.1317],\n",
            "        [-1.5439,  1.6742, -0.3924],\n",
            "        [-1.2498,  1.3907, -0.5784],\n",
            "        [-1.0719,  1.3836, -0.6486],\n",
            "        [-1.0495,  1.5175, -0.5909],\n",
            "        [-1.5975,  0.9455,  0.3678],\n",
            "        [-1.5062,  0.2657,  1.2227],\n",
            "        [-1.3058,  1.5403, -0.5557],\n",
            "        [-1.6271,  0.6143,  0.4407],\n",
            "        [-1.5424,  0.3577,  1.1948],\n",
            "        [ 0.8443, -0.0388, -1.3555],\n",
            "        [-1.8571,  0.5172,  1.1264],\n",
            "        [-1.2189,  1.3568, -0.6057]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2319,  1.3747, -0.4830],\n",
            "        [-1.4232,  1.6019, -0.5232],\n",
            "        [ 0.8824,  0.1264, -1.2420],\n",
            "        [-1.0115,  1.5204, -0.6015],\n",
            "        [ 0.8742, -0.0176, -1.2907],\n",
            "        [-0.3580,  0.0865, -0.4361],\n",
            "        [-1.3002,  1.5524, -0.5966],\n",
            "        [-1.2322,  1.4855, -0.4186],\n",
            "        [-1.2239,  1.1088,  0.2638],\n",
            "        [-1.1872,  1.4020, -0.4268],\n",
            "        [-1.2022,  1.6373, -0.7079],\n",
            "        [-1.1509,  1.4039, -0.4190],\n",
            "        [-1.2008,  1.5685, -0.5751],\n",
            "        [-1.0146,  1.4621, -0.5386],\n",
            "        [-1.8223,  0.9962,  0.7762],\n",
            "        [-1.1531,  1.4324, -0.2690]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2319,  1.3747, -0.4830],\n",
            "        [-1.4232,  1.6019, -0.5232],\n",
            "        [ 0.8824,  0.1264, -1.2420],\n",
            "        [-1.0115,  1.5204, -0.6015],\n",
            "        [ 0.8742, -0.0176, -1.2907],\n",
            "        [-0.3580,  0.0865, -0.4361],\n",
            "        [-1.3002,  1.5524, -0.5966],\n",
            "        [-1.2322,  1.4855, -0.4186],\n",
            "        [-1.2239,  1.1088,  0.2638],\n",
            "        [-1.1872,  1.4020, -0.4268],\n",
            "        [-1.2022,  1.6373, -0.7079],\n",
            "        [-1.1509,  1.4039, -0.4190],\n",
            "        [-1.2008,  1.5685, -0.5751],\n",
            "        [-1.0146,  1.4621, -0.5386],\n",
            "        [-1.8223,  0.9962,  0.7762],\n",
            "        [-1.1531,  1.4324, -0.2690]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6500,  0.2648,  1.1344],\n",
            "        [-1.8280,  0.3065,  1.3491],\n",
            "        [-1.5803,  0.4109,  0.8618],\n",
            "        [-1.3347,  1.6757, -0.4845],\n",
            "        [-1.8669,  0.3047,  1.2771],\n",
            "        [-1.8367,  0.7435,  0.6953],\n",
            "        [ 0.7155, -0.2095, -1.2811],\n",
            "        [-1.5144,  0.4050,  0.6611],\n",
            "        [ 0.5909,  0.0516, -1.2843],\n",
            "        [-1.2118,  1.6497, -0.5463],\n",
            "        [-1.2012,  1.5865, -0.3231],\n",
            "        [-1.2974,  1.5765, -0.5196],\n",
            "        [-1.7316,  0.5576,  1.0830],\n",
            "        [ 0.3425,  0.1548, -1.2967],\n",
            "        [-1.9221,  0.3196,  1.3028],\n",
            "        [-1.3030,  1.3680, -0.4324]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6500,  0.2648,  1.1344],\n",
            "        [-1.8280,  0.3065,  1.3491],\n",
            "        [-1.5803,  0.4109,  0.8618],\n",
            "        [-1.3347,  1.6757, -0.4845],\n",
            "        [-1.8669,  0.3047,  1.2771],\n",
            "        [-1.8367,  0.7435,  0.6953],\n",
            "        [ 0.7155, -0.2095, -1.2811],\n",
            "        [-1.5144,  0.4050,  0.6611],\n",
            "        [ 0.5909,  0.0516, -1.2843],\n",
            "        [-1.2118,  1.6497, -0.5463],\n",
            "        [-1.2012,  1.5865, -0.3231],\n",
            "        [-1.2974,  1.5765, -0.5196],\n",
            "        [-1.7316,  0.5576,  1.0830],\n",
            "        [ 0.3425,  0.1548, -1.2967],\n",
            "        [-1.9221,  0.3196,  1.3028],\n",
            "        [-1.3030,  1.3680, -0.4324]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7127,  0.6542,  0.8089],\n",
            "        [-1.9784,  0.3024,  1.1467],\n",
            "        [-1.4240,  1.7167, -0.4325],\n",
            "        [-1.8239,  0.3555,  1.4811],\n",
            "        [-1.4296,  1.4566, -0.3509],\n",
            "        [ 0.7373,  0.0763, -1.1247],\n",
            "        [-1.7304,  1.0373,  0.3476],\n",
            "        [-1.5278,  1.6722, -0.4388],\n",
            "        [-2.1506,  0.2411,  1.1690],\n",
            "        [-1.4712,  1.5008, -0.4876],\n",
            "        [-1.4334,  1.2518, -0.0951],\n",
            "        [-1.8495,  0.4049,  1.0965],\n",
            "        [ 0.7611,  0.1529, -1.3797],\n",
            "        [-2.0108,  0.2234,  1.2850],\n",
            "        [-1.7896,  0.5349,  0.7742],\n",
            "        [-1.9435,  0.3320,  1.3788]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7127,  0.6542,  0.8089],\n",
            "        [-1.9784,  0.3024,  1.1467],\n",
            "        [-1.4240,  1.7167, -0.4325],\n",
            "        [-1.8239,  0.3555,  1.4811],\n",
            "        [-1.4296,  1.4566, -0.3509],\n",
            "        [ 0.7373,  0.0763, -1.1247],\n",
            "        [-1.7304,  1.0373,  0.3476],\n",
            "        [-1.5278,  1.6722, -0.4388],\n",
            "        [-2.1506,  0.2411,  1.1690],\n",
            "        [-1.4712,  1.5008, -0.4876],\n",
            "        [-1.4334,  1.2518, -0.0951],\n",
            "        [-1.8495,  0.4049,  1.0965],\n",
            "        [ 0.7611,  0.1529, -1.3797],\n",
            "        [-2.0108,  0.2234,  1.2850],\n",
            "        [-1.7896,  0.5349,  0.7742],\n",
            "        [-1.9435,  0.3320,  1.3788]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8646,  0.2702,  1.1433],\n",
            "        [-1.7733,  0.9756,  0.2533],\n",
            "        [-1.1991,  1.6099, -0.4840],\n",
            "        [-1.3933,  1.3644, -0.2193],\n",
            "        [-0.7151,  1.1705, -0.9671],\n",
            "        [-1.1931,  1.3953, -0.5147],\n",
            "        [ 0.4185,  0.3924, -1.0878],\n",
            "        [-1.1967,  1.7546, -0.4502],\n",
            "        [-1.5091,  1.2852, -0.2201],\n",
            "        [-1.4127,  1.4071, -0.3239],\n",
            "        [-1.9795,  0.3961,  1.1312],\n",
            "        [-1.1576,  1.3166, -0.2295],\n",
            "        [-1.3776,  1.5198, -0.4447],\n",
            "        [-1.0778,  1.1876, -0.1084],\n",
            "        [ 0.8626, -0.1333, -1.2625],\n",
            "        [-1.2398,  1.5753, -0.4338]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8646,  0.2702,  1.1433],\n",
            "        [-1.7733,  0.9756,  0.2533],\n",
            "        [-1.1991,  1.6099, -0.4840],\n",
            "        [-1.3933,  1.3644, -0.2193],\n",
            "        [-0.7151,  1.1705, -0.9671],\n",
            "        [-1.1931,  1.3953, -0.5147],\n",
            "        [ 0.4185,  0.3924, -1.0878],\n",
            "        [-1.1967,  1.7546, -0.4502],\n",
            "        [-1.5091,  1.2852, -0.2201],\n",
            "        [-1.4127,  1.4071, -0.3239],\n",
            "        [-1.9795,  0.3961,  1.1312],\n",
            "        [-1.1576,  1.3166, -0.2295],\n",
            "        [-1.3776,  1.5198, -0.4447],\n",
            "        [-1.0778,  1.1876, -0.1084],\n",
            "        [ 0.8626, -0.1333, -1.2625],\n",
            "        [-1.2398,  1.5753, -0.4338]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3478,  1.6947, -0.3865],\n",
            "        [-1.9357,  0.4183,  1.2156],\n",
            "        [-1.2414,  1.5292, -0.5826],\n",
            "        [-1.9644,  0.4724,  1.1213],\n",
            "        [ 0.7355, -0.0554, -1.1373],\n",
            "        [-1.3071,  1.6060, -0.2901],\n",
            "        [-1.4915,  1.5927, -0.2930],\n",
            "        [-1.4906,  1.4856, -0.5445],\n",
            "        [-1.6913,  0.4430,  1.1161],\n",
            "        [-1.1363,  1.5962, -0.2959],\n",
            "        [ 0.8704, -0.0848, -1.2662],\n",
            "        [-1.3308,  1.6376, -0.3967],\n",
            "        [-1.3795,  1.4462, -0.3199],\n",
            "        [ 0.7124,  0.1545, -1.0887],\n",
            "        [ 0.8813, -0.0183, -1.1687],\n",
            "        [ 0.8702, -0.0266, -1.1140]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3478,  1.6947, -0.3865],\n",
            "        [-1.9357,  0.4183,  1.2156],\n",
            "        [-1.2414,  1.5292, -0.5826],\n",
            "        [-1.9644,  0.4724,  1.1213],\n",
            "        [ 0.7355, -0.0554, -1.1373],\n",
            "        [-1.3071,  1.6060, -0.2901],\n",
            "        [-1.4915,  1.5927, -0.2930],\n",
            "        [-1.4906,  1.4856, -0.5445],\n",
            "        [-1.6913,  0.4430,  1.1161],\n",
            "        [-1.1363,  1.5962, -0.2959],\n",
            "        [ 0.8704, -0.0848, -1.2662],\n",
            "        [-1.3308,  1.6376, -0.3967],\n",
            "        [-1.3795,  1.4462, -0.3199],\n",
            "        [ 0.7124,  0.1545, -1.0887],\n",
            "        [ 0.8813, -0.0183, -1.1687],\n",
            "        [ 0.8702, -0.0266, -1.1140]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6604,  1.0155,  0.5482],\n",
            "        [-1.2378,  1.6229, -0.3434],\n",
            "        [-1.7073,  0.4479,  1.0907],\n",
            "        [-1.7688,  0.6071,  1.0239],\n",
            "        [-1.3926,  1.3165, -0.4828],\n",
            "        [-1.7956,  0.5813,  0.9887],\n",
            "        [-1.1401,  1.5316, -0.6384],\n",
            "        [-1.7839,  0.7698,  0.9600],\n",
            "        [-1.3770,  1.7243, -0.7434],\n",
            "        [-1.2547,  1.7151, -0.5165],\n",
            "        [-1.4982,  1.6194, -0.4914],\n",
            "        [-1.3244,  1.6066, -0.5537],\n",
            "        [-1.7099,  0.6024,  0.7702],\n",
            "        [-1.9391,  0.4967,  1.3140],\n",
            "        [ 0.6076,  0.0162, -1.2623],\n",
            "        [-1.2562,  1.5436, -0.3713]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6604,  1.0155,  0.5482],\n",
            "        [-1.2378,  1.6229, -0.3434],\n",
            "        [-1.7073,  0.4479,  1.0907],\n",
            "        [-1.7688,  0.6071,  1.0239],\n",
            "        [-1.3926,  1.3165, -0.4828],\n",
            "        [-1.7956,  0.5813,  0.9887],\n",
            "        [-1.1401,  1.5316, -0.6384],\n",
            "        [-1.7839,  0.7698,  0.9600],\n",
            "        [-1.3770,  1.7243, -0.7434],\n",
            "        [-1.2547,  1.7151, -0.5165],\n",
            "        [-1.4982,  1.6194, -0.4914],\n",
            "        [-1.3244,  1.6066, -0.5537],\n",
            "        [-1.7099,  0.6024,  0.7702],\n",
            "        [-1.9391,  0.4967,  1.3140],\n",
            "        [ 0.6076,  0.0162, -1.2623],\n",
            "        [-1.2562,  1.5436, -0.3713]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.8332,  0.0454, -1.1640],\n",
            "        [-1.5699,  1.5436, -0.2541],\n",
            "        [-1.7987,  1.1147,  0.6372],\n",
            "        [-2.0563,  0.4580,  1.1145],\n",
            "        [-1.5753,  1.8549, -0.6522],\n",
            "        [-2.0364,  0.4692,  1.3504],\n",
            "        [-1.4394,  1.8417, -0.5128],\n",
            "        [-1.7371,  0.6059,  1.0673],\n",
            "        [-1.3650,  1.7555, -0.3829],\n",
            "        [-1.3187,  1.6373, -0.4381],\n",
            "        [-1.5279,  1.7628, -0.3859],\n",
            "        [-1.3328,  1.7343, -0.4530],\n",
            "        [-1.3860,  1.5962, -0.1153],\n",
            "        [-1.4257,  1.5689, -0.4959],\n",
            "        [-1.6327,  1.3521, -0.1773],\n",
            "        [ 0.7857,  0.0276, -1.1685]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.8332,  0.0454, -1.1640],\n",
            "        [-1.5699,  1.5436, -0.2541],\n",
            "        [-1.7987,  1.1147,  0.6372],\n",
            "        [-2.0563,  0.4580,  1.1145],\n",
            "        [-1.5753,  1.8549, -0.6522],\n",
            "        [-2.0364,  0.4692,  1.3504],\n",
            "        [-1.4394,  1.8417, -0.5128],\n",
            "        [-1.7371,  0.6059,  1.0673],\n",
            "        [-1.3650,  1.7555, -0.3829],\n",
            "        [-1.3187,  1.6373, -0.4381],\n",
            "        [-1.5279,  1.7628, -0.3859],\n",
            "        [-1.3328,  1.7343, -0.4530],\n",
            "        [-1.3860,  1.5962, -0.1153],\n",
            "        [-1.4257,  1.5689, -0.4959],\n",
            "        [-1.6327,  1.3521, -0.1773],\n",
            "        [ 0.7857,  0.0276, -1.1685]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.3130,  0.5464, -0.7475],\n",
            "        [-1.2938,  1.7043, -0.3873],\n",
            "        [-1.5365,  1.5644, -0.0504],\n",
            "        [-2.0903,  0.5578,  1.2598],\n",
            "        [-2.1467,  0.8975,  1.1075],\n",
            "        [ 0.6997,  0.0311, -1.2849],\n",
            "        [-1.6216,  0.2548,  0.9040],\n",
            "        [-1.5677,  1.4653, -0.0430],\n",
            "        [-1.8674,  0.9818,  0.6507],\n",
            "        [-1.7389,  1.8073, -0.4413],\n",
            "        [-1.8331,  0.8003,  0.9739],\n",
            "        [-1.5813,  1.8667, -0.5390],\n",
            "        [-1.8847,  0.5511,  1.0722],\n",
            "        [-1.5226,  1.6107, -0.0027],\n",
            "        [-1.5127,  1.8899, -0.3856],\n",
            "        [-0.4887,  0.2154, -0.2878]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-0.3130,  0.5464, -0.7475],\n",
            "        [-1.2938,  1.7043, -0.3873],\n",
            "        [-1.5365,  1.5644, -0.0504],\n",
            "        [-2.0903,  0.5578,  1.2598],\n",
            "        [-2.1467,  0.8975,  1.1075],\n",
            "        [ 0.6997,  0.0311, -1.2849],\n",
            "        [-1.6216,  0.2548,  0.9040],\n",
            "        [-1.5677,  1.4653, -0.0430],\n",
            "        [-1.8674,  0.9818,  0.6507],\n",
            "        [-1.7389,  1.8073, -0.4413],\n",
            "        [-1.8331,  0.8003,  0.9739],\n",
            "        [-1.5813,  1.8667, -0.5390],\n",
            "        [-1.8847,  0.5511,  1.0722],\n",
            "        [-1.5226,  1.6107, -0.0027],\n",
            "        [-1.5127,  1.8899, -0.3856],\n",
            "        [-0.4887,  0.2154, -0.2878]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9783,  0.8449,  0.9736],\n",
            "        [-1.7054,  0.6322,  1.2184],\n",
            "        [-1.3637,  1.6659, -0.3531],\n",
            "        [-1.6383,  1.7700, -0.2650],\n",
            "        [-0.9550,  1.5749, -0.9238],\n",
            "        [-0.9746,  1.5981, -0.7315],\n",
            "        [-1.4975,  1.5045, -0.4240],\n",
            "        [-1.8196,  0.6680,  0.9109],\n",
            "        [-2.0048,  0.3002,  0.8922],\n",
            "        [-1.2780,  1.7291, -0.2388],\n",
            "        [-1.5051,  1.7916, -0.4947],\n",
            "        [-1.9982,  0.4547,  0.9998],\n",
            "        [-1.4016,  1.6161, -0.6049],\n",
            "        [-1.5443,  1.7188, -0.3842],\n",
            "        [-1.5866,  1.6066, -0.2372],\n",
            "        [-1.5463,  1.8993, -0.3644]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9783,  0.8449,  0.9736],\n",
            "        [-1.7054,  0.6322,  1.2184],\n",
            "        [-1.3637,  1.6659, -0.3531],\n",
            "        [-1.6383,  1.7700, -0.2650],\n",
            "        [-0.9550,  1.5749, -0.9238],\n",
            "        [-0.9746,  1.5981, -0.7315],\n",
            "        [-1.4975,  1.5045, -0.4240],\n",
            "        [-1.8196,  0.6680,  0.9109],\n",
            "        [-2.0048,  0.3002,  0.8922],\n",
            "        [-1.2780,  1.7291, -0.2388],\n",
            "        [-1.5051,  1.7916, -0.4947],\n",
            "        [-1.9982,  0.4547,  0.9998],\n",
            "        [-1.4016,  1.6161, -0.6049],\n",
            "        [-1.5443,  1.7188, -0.3842],\n",
            "        [-1.5866,  1.6066, -0.2372],\n",
            "        [-1.5463,  1.8993, -0.3644]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3136,  1.5902, -0.5112],\n",
            "        [ 0.7096, -0.1270, -1.2147],\n",
            "        [-1.0270,  1.1001, -0.2966],\n",
            "        [-1.9627,  0.4918,  1.2720],\n",
            "        [ 0.8780, -0.1102, -1.2956],\n",
            "        [-1.2584,  1.7526, -0.3917],\n",
            "        [-2.1053,  0.5603,  1.1325],\n",
            "        [-1.9079,  0.7782,  0.7833],\n",
            "        [-1.8409,  1.3804,  0.0776],\n",
            "        [ 0.4777, -0.0935, -1.2431],\n",
            "        [-1.5096,  1.8867, -0.4133],\n",
            "        [-1.9709,  0.5486,  1.2458],\n",
            "        [-1.5286,  1.6605, -0.0954],\n",
            "        [-1.8676,  0.5191,  0.9045],\n",
            "        [-1.5490,  1.9116, -0.6679],\n",
            "        [ 0.6980, -0.0974, -1.1223]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3136,  1.5902, -0.5112],\n",
            "        [ 0.7096, -0.1270, -1.2147],\n",
            "        [-1.0270,  1.1001, -0.2966],\n",
            "        [-1.9627,  0.4918,  1.2720],\n",
            "        [ 0.8780, -0.1102, -1.2956],\n",
            "        [-1.2584,  1.7526, -0.3917],\n",
            "        [-2.1053,  0.5603,  1.1325],\n",
            "        [-1.9079,  0.7782,  0.7833],\n",
            "        [-1.8409,  1.3804,  0.0776],\n",
            "        [ 0.4777, -0.0935, -1.2431],\n",
            "        [-1.5096,  1.8867, -0.4133],\n",
            "        [-1.9709,  0.5486,  1.2458],\n",
            "        [-1.5286,  1.6605, -0.0954],\n",
            "        [-1.8676,  0.5191,  0.9045],\n",
            "        [-1.5490,  1.9116, -0.6679],\n",
            "        [ 0.6980, -0.0974, -1.1223]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7610,  1.7175, -0.0374],\n",
            "        [-1.5387,  1.7460, -0.4824],\n",
            "        [ 0.4251, -0.0502, -1.1125],\n",
            "        [-1.2672,  1.5132, -0.5068],\n",
            "        [-1.4891,  1.6385, -0.4849],\n",
            "        [-1.4609,  1.6613, -0.3905],\n",
            "        [ 0.5579, -0.0233, -1.0235],\n",
            "        [-1.9201,  1.2441,  0.2777],\n",
            "        [-1.6950,  1.7653, -0.2647],\n",
            "        [-1.6592,  1.8762, -0.2554],\n",
            "        [-2.0511,  0.5309,  1.0319],\n",
            "        [-2.0605,  0.6900,  1.1617],\n",
            "        [-1.9827,  0.5754,  1.2170],\n",
            "        [-1.5506,  1.9015, -0.5592],\n",
            "        [-1.9444,  0.4830,  1.1188],\n",
            "        [-0.4614,  0.0955,  0.0528]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7610,  1.7175, -0.0374],\n",
            "        [-1.5387,  1.7460, -0.4824],\n",
            "        [ 0.4251, -0.0502, -1.1125],\n",
            "        [-1.2672,  1.5132, -0.5068],\n",
            "        [-1.4891,  1.6385, -0.4849],\n",
            "        [-1.4609,  1.6613, -0.3905],\n",
            "        [ 0.5579, -0.0233, -1.0235],\n",
            "        [-1.9201,  1.2441,  0.2777],\n",
            "        [-1.6950,  1.7653, -0.2647],\n",
            "        [-1.6592,  1.8762, -0.2554],\n",
            "        [-2.0511,  0.5309,  1.0319],\n",
            "        [-2.0605,  0.6900,  1.1617],\n",
            "        [-1.9827,  0.5754,  1.2170],\n",
            "        [-1.5506,  1.9015, -0.5592],\n",
            "        [-1.9444,  0.4830,  1.1188],\n",
            "        [-0.4614,  0.0955,  0.0528]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3870,  1.8747, -0.5252],\n",
            "        [-0.6808,  0.5764, -0.3189],\n",
            "        [-1.5552,  1.6978, -0.5673],\n",
            "        [-1.8719,  0.6016,  1.2056],\n",
            "        [ 0.3636,  0.1326, -1.1680],\n",
            "        [ 0.4047,  0.0034, -1.0980],\n",
            "        [ 0.6545, -0.1523, -1.1883],\n",
            "        [-1.5553,  1.4817, -0.1674],\n",
            "        [-1.8692,  1.7253,  0.1265],\n",
            "        [-2.0642,  1.0620,  0.6283],\n",
            "        [-1.5214,  1.7471, -0.3785],\n",
            "        [-1.9054,  0.4298,  1.1921],\n",
            "        [ 0.6562,  0.0435, -1.0392],\n",
            "        [-1.8737,  1.7900, -0.3048],\n",
            "        [ 0.6531, -0.0565, -1.0490],\n",
            "        [-1.3043,  1.8035, -0.6089]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3870,  1.8747, -0.5252],\n",
            "        [-0.6808,  0.5764, -0.3189],\n",
            "        [-1.5552,  1.6978, -0.5673],\n",
            "        [-1.8719,  0.6016,  1.2056],\n",
            "        [ 0.3636,  0.1326, -1.1680],\n",
            "        [ 0.4047,  0.0034, -1.0980],\n",
            "        [ 0.6545, -0.1523, -1.1883],\n",
            "        [-1.5553,  1.4817, -0.1674],\n",
            "        [-1.8692,  1.7253,  0.1265],\n",
            "        [-2.0642,  1.0620,  0.6283],\n",
            "        [-1.5214,  1.7471, -0.3785],\n",
            "        [-1.9054,  0.4298,  1.1921],\n",
            "        [ 0.6562,  0.0435, -1.0392],\n",
            "        [-1.8737,  1.7900, -0.3048],\n",
            "        [ 0.6531, -0.0565, -1.0490],\n",
            "        [-1.3043,  1.8035, -0.6089]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.6877,  0.0825, -1.0842],\n",
            "        [ 0.3188,  0.0414, -0.9937],\n",
            "        [-1.9203,  0.5059,  1.1309],\n",
            "        [-1.8470,  1.6172, -0.1391],\n",
            "        [-1.7868,  0.5889,  1.0344],\n",
            "        [-1.6309,  1.7605, -0.4309],\n",
            "        [-1.7507,  0.6170,  1.0000],\n",
            "        [-1.7595,  0.7326,  1.1672],\n",
            "        [-1.7489,  1.6784, -0.0684],\n",
            "        [-1.6789,  1.8460, -0.5965],\n",
            "        [-1.6598,  1.5342, -0.1678],\n",
            "        [-1.8706,  0.6895,  1.0202],\n",
            "        [ 0.4774,  0.0574, -1.0752],\n",
            "        [-1.9362,  1.5017,  0.0409],\n",
            "        [-1.8719,  1.9139, -0.3835],\n",
            "        [-1.7111,  1.8147, -0.2902]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.6877,  0.0825, -1.0842],\n",
            "        [ 0.3188,  0.0414, -0.9937],\n",
            "        [-1.9203,  0.5059,  1.1309],\n",
            "        [-1.8470,  1.6172, -0.1391],\n",
            "        [-1.7868,  0.5889,  1.0344],\n",
            "        [-1.6309,  1.7605, -0.4309],\n",
            "        [-1.7507,  0.6170,  1.0000],\n",
            "        [-1.7595,  0.7326,  1.1672],\n",
            "        [-1.7489,  1.6784, -0.0684],\n",
            "        [-1.6789,  1.8460, -0.5965],\n",
            "        [-1.6598,  1.5342, -0.1678],\n",
            "        [-1.8706,  0.6895,  1.0202],\n",
            "        [ 0.4774,  0.0574, -1.0752],\n",
            "        [-1.9362,  1.5017,  0.0409],\n",
            "        [-1.8719,  1.9139, -0.3835],\n",
            "        [-1.7111,  1.8147, -0.2902]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7926,  1.2538,  0.1324],\n",
            "        [-1.4643,  1.5333, -0.3716],\n",
            "        [-1.2582,  1.7926, -0.7374],\n",
            "        [-1.7174,  1.8820, -0.3118],\n",
            "        [-1.3848,  1.7812, -0.1496],\n",
            "        [-1.3915,  1.7756, -0.3984],\n",
            "        [-2.0721,  0.3824,  1.0687],\n",
            "        [-1.8623,  0.5505,  1.3003],\n",
            "        [-1.3988,  1.8949, -0.6814],\n",
            "        [ 0.5483, -0.1260, -0.9051],\n",
            "        [-1.5344,  1.7347, -0.4198],\n",
            "        [-1.8799,  0.6302,  0.7981],\n",
            "        [-1.2248,  1.7088, -0.3904],\n",
            "        [ 0.6741, -0.1529, -1.0382],\n",
            "        [-1.6245,  1.7248, -0.1776],\n",
            "        [ 0.5092,  0.3719, -1.1278]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7926,  1.2538,  0.1324],\n",
            "        [-1.4643,  1.5333, -0.3716],\n",
            "        [-1.2582,  1.7926, -0.7374],\n",
            "        [-1.7174,  1.8820, -0.3118],\n",
            "        [-1.3848,  1.7812, -0.1496],\n",
            "        [-1.3915,  1.7756, -0.3984],\n",
            "        [-2.0721,  0.3824,  1.0687],\n",
            "        [-1.8623,  0.5505,  1.3003],\n",
            "        [-1.3988,  1.8949, -0.6814],\n",
            "        [ 0.5483, -0.1260, -0.9051],\n",
            "        [-1.5344,  1.7347, -0.4198],\n",
            "        [-1.8799,  0.6302,  0.7981],\n",
            "        [-1.2248,  1.7088, -0.3904],\n",
            "        [ 0.6741, -0.1529, -1.0382],\n",
            "        [-1.6245,  1.7248, -0.1776],\n",
            "        [ 0.5092,  0.3719, -1.1278]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7493,  1.8066, -0.3060],\n",
            "        [-1.8466,  1.6551, -0.1940],\n",
            "        [-1.6501,  2.0675, -0.2103],\n",
            "        [-1.8050,  0.4219,  1.0088],\n",
            "        [-1.6517,  1.6133, -0.0089],\n",
            "        [-1.4355,  1.6309, -0.4093],\n",
            "        [-1.6227,  1.9014, -0.4526],\n",
            "        [-2.0161,  0.5188,  1.0512],\n",
            "        [-0.1399,  0.0906, -0.7190],\n",
            "        [-1.2718,  1.7319, -0.3560],\n",
            "        [ 0.5033,  0.0126, -1.0248],\n",
            "        [-1.6985,  1.9408, -0.6873],\n",
            "        [ 0.4278,  0.0590, -0.9776],\n",
            "        [-1.7257,  1.8730, -0.6668],\n",
            "        [-1.5839,  1.8679, -0.2501],\n",
            "        [-1.4954,  1.8168, -0.4137]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7493,  1.8066, -0.3060],\n",
            "        [-1.8466,  1.6551, -0.1940],\n",
            "        [-1.6501,  2.0675, -0.2103],\n",
            "        [-1.8050,  0.4219,  1.0088],\n",
            "        [-1.6517,  1.6133, -0.0089],\n",
            "        [-1.4355,  1.6309, -0.4093],\n",
            "        [-1.6227,  1.9014, -0.4526],\n",
            "        [-2.0161,  0.5188,  1.0512],\n",
            "        [-0.1399,  0.0906, -0.7190],\n",
            "        [-1.2718,  1.7319, -0.3560],\n",
            "        [ 0.5033,  0.0126, -1.0248],\n",
            "        [-1.6985,  1.9408, -0.6873],\n",
            "        [ 0.4278,  0.0590, -0.9776],\n",
            "        [-1.7257,  1.8730, -0.6668],\n",
            "        [-1.5839,  1.8679, -0.2501],\n",
            "        [-1.4954,  1.8168, -0.4137]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7259,  1.7368, -0.2479],\n",
            "        [-1.6895,  1.6306, -0.3804],\n",
            "        [ 0.4343, -0.0604, -1.0008],\n",
            "        [-1.3779,  1.8124, -0.3625],\n",
            "        [ 0.6756,  0.0095, -0.9997],\n",
            "        [-1.8957,  0.2728,  1.1351],\n",
            "        [-1.3018,  1.6902, -0.5133],\n",
            "        [-1.8607,  0.5557,  1.0020],\n",
            "        [ 0.4196,  0.1003, -1.2012],\n",
            "        [-2.0616,  0.6477,  1.2719],\n",
            "        [-1.8006,  1.8503, -0.4527],\n",
            "        [-1.4441,  1.7524, -0.4437],\n",
            "        [ 0.5141,  0.0537, -0.9983],\n",
            "        [-1.9433,  0.5941,  0.9625],\n",
            "        [-1.3910,  1.8121, -0.4031],\n",
            "        [-1.4052,  1.7558, -0.4799]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7259,  1.7368, -0.2479],\n",
            "        [-1.6895,  1.6306, -0.3804],\n",
            "        [ 0.4343, -0.0604, -1.0008],\n",
            "        [-1.3779,  1.8124, -0.3625],\n",
            "        [ 0.6756,  0.0095, -0.9997],\n",
            "        [-1.8957,  0.2728,  1.1351],\n",
            "        [-1.3018,  1.6902, -0.5133],\n",
            "        [-1.8607,  0.5557,  1.0020],\n",
            "        [ 0.4196,  0.1003, -1.2012],\n",
            "        [-2.0616,  0.6477,  1.2719],\n",
            "        [-1.8006,  1.8503, -0.4527],\n",
            "        [-1.4441,  1.7524, -0.4437],\n",
            "        [ 0.5141,  0.0537, -0.9983],\n",
            "        [-1.9433,  0.5941,  0.9625],\n",
            "        [-1.3910,  1.8121, -0.4031],\n",
            "        [-1.4052,  1.7558, -0.4799]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5915,  1.6810, -0.4745],\n",
            "        [-1.1975,  1.5447, -0.3282],\n",
            "        [-1.4628,  1.5660, -0.4459],\n",
            "        [-2.0123,  0.7495,  0.9439],\n",
            "        [-1.6156,  1.7273, -0.5315],\n",
            "        [-0.0138,  0.6013, -1.0542],\n",
            "        [ 0.5276,  0.0164, -0.8731],\n",
            "        [ 0.5389, -0.2086, -1.1330],\n",
            "        [ 0.4266, -0.0875, -1.0895],\n",
            "        [-1.6777,  1.5985, -0.2665],\n",
            "        [-1.7716,  1.9595, -0.3429],\n",
            "        [-0.6334,  0.3456, -0.1269],\n",
            "        [-2.0059,  1.1196,  0.8211],\n",
            "        [-1.4174,  1.8089, -0.1430],\n",
            "        [ 0.5941, -0.0174, -1.0389],\n",
            "        [-1.7215,  2.0467, -0.5487]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5915,  1.6810, -0.4745],\n",
            "        [-1.1975,  1.5447, -0.3282],\n",
            "        [-1.4628,  1.5660, -0.4459],\n",
            "        [-2.0123,  0.7495,  0.9439],\n",
            "        [-1.6156,  1.7273, -0.5315],\n",
            "        [-0.0138,  0.6013, -1.0542],\n",
            "        [ 0.5276,  0.0164, -0.8731],\n",
            "        [ 0.5389, -0.2086, -1.1330],\n",
            "        [ 0.4266, -0.0875, -1.0895],\n",
            "        [-1.6777,  1.5985, -0.2665],\n",
            "        [-1.7716,  1.9595, -0.3429],\n",
            "        [-0.6334,  0.3456, -0.1269],\n",
            "        [-2.0059,  1.1196,  0.8211],\n",
            "        [-1.4174,  1.8089, -0.1430],\n",
            "        [ 0.5941, -0.0174, -1.0389],\n",
            "        [-1.7215,  2.0467, -0.5487]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8738,  0.9999,  0.7472],\n",
            "        [-1.7668,  0.3663,  1.0391],\n",
            "        [-1.5064,  1.9793, -0.7428],\n",
            "        [-1.6527,  1.7843, -0.3672],\n",
            "        [-1.5615,  1.4983, -0.2631],\n",
            "        [-1.9133,  0.9148,  0.7166],\n",
            "        [-1.8024,  0.6218,  0.9474],\n",
            "        [-1.9101,  0.8138,  1.0283],\n",
            "        [-1.5873,  1.6972, -0.3673],\n",
            "        [ 0.4719,  0.1115, -0.9263],\n",
            "        [-1.6149,  1.5395,  0.2697],\n",
            "        [-1.5896,  1.7750, -0.2543],\n",
            "        [-1.6042,  2.1437, -0.5672],\n",
            "        [-2.1619,  0.7106,  1.0542],\n",
            "        [-1.7202,  1.0387,  0.5896],\n",
            "        [ 0.3119, -0.0426, -1.1309]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8738,  0.9999,  0.7472],\n",
            "        [-1.7668,  0.3663,  1.0391],\n",
            "        [-1.5064,  1.9793, -0.7428],\n",
            "        [-1.6527,  1.7843, -0.3672],\n",
            "        [-1.5615,  1.4983, -0.2631],\n",
            "        [-1.9133,  0.9148,  0.7166],\n",
            "        [-1.8024,  0.6218,  0.9474],\n",
            "        [-1.9101,  0.8138,  1.0283],\n",
            "        [-1.5873,  1.6972, -0.3673],\n",
            "        [ 0.4719,  0.1115, -0.9263],\n",
            "        [-1.6149,  1.5395,  0.2697],\n",
            "        [-1.5896,  1.7750, -0.2543],\n",
            "        [-1.6042,  2.1437, -0.5672],\n",
            "        [-2.1619,  0.7106,  1.0542],\n",
            "        [-1.7202,  1.0387,  0.5896],\n",
            "        [ 0.3119, -0.0426, -1.1309]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7022,  1.8766, -0.3303],\n",
            "        [-1.6848,  1.7804,  0.0296],\n",
            "        [-1.3732,  1.7541, -0.6703],\n",
            "        [-1.6590,  1.3935, -0.0576],\n",
            "        [-1.4124,  1.5945, -0.5280],\n",
            "        [-1.7464,  0.7454,  0.8787],\n",
            "        [ 0.2333,  0.0666, -0.9316],\n",
            "        [-1.6996,  0.6265,  0.9180],\n",
            "        [-1.6029,  1.7154, -0.1192],\n",
            "        [-2.0075,  0.8397,  0.8324],\n",
            "        [ 0.4199,  0.0363, -0.9235],\n",
            "        [-1.7616,  1.5063,  0.0929],\n",
            "        [-1.6413,  0.5028,  0.9327],\n",
            "        [-1.8800,  0.5749,  1.0072],\n",
            "        [ 0.2321, -0.1021, -0.8881],\n",
            "        [-1.8112,  0.6606,  0.9214]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7022,  1.8766, -0.3303],\n",
            "        [-1.6848,  1.7804,  0.0296],\n",
            "        [-1.3732,  1.7541, -0.6703],\n",
            "        [-1.6590,  1.3935, -0.0576],\n",
            "        [-1.4124,  1.5945, -0.5280],\n",
            "        [-1.7464,  0.7454,  0.8787],\n",
            "        [ 0.2333,  0.0666, -0.9316],\n",
            "        [-1.6996,  0.6265,  0.9180],\n",
            "        [-1.6029,  1.7154, -0.1192],\n",
            "        [-2.0075,  0.8397,  0.8324],\n",
            "        [ 0.4199,  0.0363, -0.9235],\n",
            "        [-1.7616,  1.5063,  0.0929],\n",
            "        [-1.6413,  0.5028,  0.9327],\n",
            "        [-1.8800,  0.5749,  1.0072],\n",
            "        [ 0.2321, -0.1021, -0.8881],\n",
            "        [-1.8112,  0.6606,  0.9214]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6509,  1.7240, -0.4084],\n",
            "        [-1.6662,  1.8180,  0.0030],\n",
            "        [-1.8449,  1.2857, -0.0028],\n",
            "        [-1.5329,  1.4043,  0.0221],\n",
            "        [-1.4670,  1.5271, -0.3293],\n",
            "        [-1.6408,  1.2345, -0.0190],\n",
            "        [-1.8369,  0.5460,  1.0128],\n",
            "        [-1.6930,  1.6429, -0.3711],\n",
            "        [-1.7184,  1.7716, -0.0739],\n",
            "        [-1.8335,  0.5122,  1.0599],\n",
            "        [-1.7393,  0.5746,  0.8765],\n",
            "        [-1.5766,  1.7982, -0.0382],\n",
            "        [-1.9390,  0.5352,  0.8296],\n",
            "        [-1.7382,  0.4407,  0.9546],\n",
            "        [-1.6217,  1.5794, -0.0860],\n",
            "        [-1.5763,  1.7593, -0.1771]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6509,  1.7240, -0.4084],\n",
            "        [-1.6662,  1.8180,  0.0030],\n",
            "        [-1.8449,  1.2857, -0.0028],\n",
            "        [-1.5329,  1.4043,  0.0221],\n",
            "        [-1.4670,  1.5271, -0.3293],\n",
            "        [-1.6408,  1.2345, -0.0190],\n",
            "        [-1.8369,  0.5460,  1.0128],\n",
            "        [-1.6930,  1.6429, -0.3711],\n",
            "        [-1.7184,  1.7716, -0.0739],\n",
            "        [-1.8335,  0.5122,  1.0599],\n",
            "        [-1.7393,  0.5746,  0.8765],\n",
            "        [-1.5766,  1.7982, -0.0382],\n",
            "        [-1.9390,  0.5352,  0.8296],\n",
            "        [-1.7382,  0.4407,  0.9546],\n",
            "        [-1.6217,  1.5794, -0.0860],\n",
            "        [-1.5763,  1.7593, -0.1771]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3802,  1.2849, -0.0542],\n",
            "        [ 0.3511,  0.0776, -0.9710],\n",
            "        [-1.6171,  1.8058, -0.0964],\n",
            "        [-1.6557,  0.3513,  1.0410],\n",
            "        [-1.6253,  1.6181, -0.0555],\n",
            "        [-1.6384,  1.6075, -0.1877],\n",
            "        [ 0.5009,  0.1121, -0.8591],\n",
            "        [-1.4952,  1.7549, -0.1316],\n",
            "        [ 0.4035,  0.0761, -0.8058],\n",
            "        [-2.0544,  1.1643,  0.7762],\n",
            "        [-1.5359,  1.4548, -0.1110],\n",
            "        [-1.6754,  0.5099,  0.8383],\n",
            "        [ 0.4792, -0.0197, -1.0175],\n",
            "        [-1.7186,  0.5084,  1.0729],\n",
            "        [-1.6672,  0.4393,  0.8619],\n",
            "        [-0.1713,  0.0681, -0.6034]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3802,  1.2849, -0.0542],\n",
            "        [ 0.3511,  0.0776, -0.9710],\n",
            "        [-1.6171,  1.8058, -0.0964],\n",
            "        [-1.6557,  0.3513,  1.0410],\n",
            "        [-1.6253,  1.6181, -0.0555],\n",
            "        [-1.6384,  1.6075, -0.1877],\n",
            "        [ 0.5009,  0.1121, -0.8591],\n",
            "        [-1.4952,  1.7549, -0.1316],\n",
            "        [ 0.4035,  0.0761, -0.8058],\n",
            "        [-2.0544,  1.1643,  0.7762],\n",
            "        [-1.5359,  1.4548, -0.1110],\n",
            "        [-1.6754,  0.5099,  0.8383],\n",
            "        [ 0.4792, -0.0197, -1.0175],\n",
            "        [-1.7186,  0.5084,  1.0729],\n",
            "        [-1.6672,  0.4393,  0.8619],\n",
            "        [-0.1713,  0.0681, -0.6034]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2086,  0.9485,  0.8228],\n",
            "        [-1.6310,  1.8045, -0.3475],\n",
            "        [-1.6272,  1.9088, -0.0549],\n",
            "        [-1.7628,  0.5359,  1.0229],\n",
            "        [-1.6580,  1.6644, -0.3388],\n",
            "        [-1.5936,  1.7318, -0.5406],\n",
            "        [-1.7973,  0.7020,  1.2605],\n",
            "        [-1.7312,  1.6755, -0.1264],\n",
            "        [-1.4174,  1.8860, -0.1012],\n",
            "        [-1.7911,  1.5370, -0.2294],\n",
            "        [-1.4961,  1.5409, -0.3471],\n",
            "        [-1.5226,  1.1931,  0.2591],\n",
            "        [-1.8824,  1.2255,  0.4844],\n",
            "        [-1.6116,  2.1356, -0.5208],\n",
            "        [-1.5408,  1.5306, -0.2389],\n",
            "        [-1.8781,  1.4343,  0.1380]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.2086,  0.9485,  0.8228],\n",
            "        [-1.6310,  1.8045, -0.3475],\n",
            "        [-1.6272,  1.9088, -0.0549],\n",
            "        [-1.7628,  0.5359,  1.0229],\n",
            "        [-1.6580,  1.6644, -0.3388],\n",
            "        [-1.5936,  1.7318, -0.5406],\n",
            "        [-1.7973,  0.7020,  1.2605],\n",
            "        [-1.7312,  1.6755, -0.1264],\n",
            "        [-1.4174,  1.8860, -0.1012],\n",
            "        [-1.7911,  1.5370, -0.2294],\n",
            "        [-1.4961,  1.5409, -0.3471],\n",
            "        [-1.5226,  1.1931,  0.2591],\n",
            "        [-1.8824,  1.2255,  0.4844],\n",
            "        [-1.6116,  2.1356, -0.5208],\n",
            "        [-1.5408,  1.5306, -0.2389],\n",
            "        [-1.8781,  1.4343,  0.1380]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7121,  1.4517, -0.0955],\n",
            "        [-1.5181,  1.7374, -0.3168],\n",
            "        [-1.7725,  0.6270,  1.0591],\n",
            "        [-1.6666,  1.8874, -0.4567],\n",
            "        [-1.7137,  1.9366, -0.3336],\n",
            "        [-0.7007,  1.0823, -0.8382],\n",
            "        [-1.7512,  1.7924, -0.5256],\n",
            "        [ 0.2514, -0.0343, -0.9109],\n",
            "        [-1.5483,  1.6970, -0.2156],\n",
            "        [ 0.2626, -0.0306, -0.9062],\n",
            "        [-1.4696,  1.7020, -0.1306],\n",
            "        [-1.7043,  1.7023, -0.3423],\n",
            "        [-2.0564,  0.6373,  1.1336],\n",
            "        [-1.5670,  1.7854, -0.3273],\n",
            "        [-1.7100,  1.6082, -0.1675],\n",
            "        [-1.5897,  1.9176, -0.2263]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7121,  1.4517, -0.0955],\n",
            "        [-1.5181,  1.7374, -0.3168],\n",
            "        [-1.7725,  0.6270,  1.0591],\n",
            "        [-1.6666,  1.8874, -0.4567],\n",
            "        [-1.7137,  1.9366, -0.3336],\n",
            "        [-0.7007,  1.0823, -0.8382],\n",
            "        [-1.7512,  1.7924, -0.5256],\n",
            "        [ 0.2514, -0.0343, -0.9109],\n",
            "        [-1.5483,  1.6970, -0.2156],\n",
            "        [ 0.2626, -0.0306, -0.9062],\n",
            "        [-1.4696,  1.7020, -0.1306],\n",
            "        [-1.7043,  1.7023, -0.3423],\n",
            "        [-2.0564,  0.6373,  1.1336],\n",
            "        [-1.5670,  1.7854, -0.3273],\n",
            "        [-1.7100,  1.6082, -0.1675],\n",
            "        [-1.5897,  1.9176, -0.2263]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3801,  0.2338, -0.9375],\n",
            "        [-1.6211,  1.9860, -0.4975],\n",
            "        [-1.7957,  0.4672,  0.9757],\n",
            "        [-1.9741,  0.9226,  0.7266],\n",
            "        [-1.6841,  0.4602,  0.8981],\n",
            "        [-1.5944,  1.8431, -0.2109],\n",
            "        [ 0.3315,  0.1338, -0.8914],\n",
            "        [-1.7478,  0.6228,  0.8693],\n",
            "        [ 0.3064, -0.1256, -0.9325],\n",
            "        [-1.3969,  1.7262, -0.6361],\n",
            "        [-1.7543,  1.3060,  0.1969],\n",
            "        [-1.8196,  0.8097,  0.9570],\n",
            "        [-1.5026,  1.6751, -0.0532],\n",
            "        [-1.6889,  1.0472,  0.7146],\n",
            "        [-2.0123,  0.5538,  0.8540],\n",
            "        [-1.5723,  1.8600, -0.3206]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.3801,  0.2338, -0.9375],\n",
            "        [-1.6211,  1.9860, -0.4975],\n",
            "        [-1.7957,  0.4672,  0.9757],\n",
            "        [-1.9741,  0.9226,  0.7266],\n",
            "        [-1.6841,  0.4602,  0.8981],\n",
            "        [-1.5944,  1.8431, -0.2109],\n",
            "        [ 0.3315,  0.1338, -0.8914],\n",
            "        [-1.7478,  0.6228,  0.8693],\n",
            "        [ 0.3064, -0.1256, -0.9325],\n",
            "        [-1.3969,  1.7262, -0.6361],\n",
            "        [-1.7543,  1.3060,  0.1969],\n",
            "        [-1.8196,  0.8097,  0.9570],\n",
            "        [-1.5026,  1.6751, -0.0532],\n",
            "        [-1.6889,  1.0472,  0.7146],\n",
            "        [-2.0123,  0.5538,  0.8540],\n",
            "        [-1.5723,  1.8600, -0.3206]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.5633,  0.0499,  0.0585],\n",
            "        [-1.7509,  1.7157, -0.2564],\n",
            "        [-1.6317,  1.8051, -0.5502],\n",
            "        [-1.9252,  1.9191, -0.4182],\n",
            "        [-1.6463,  1.8332, -0.0860],\n",
            "        [-1.7795,  1.0855,  0.6090],\n",
            "        [-1.7038,  0.8228,  0.6337],\n",
            "        [-1.5327,  1.4852, -0.1349],\n",
            "        [-1.6047,  1.8957, -0.4550],\n",
            "        [-1.7642,  0.5718,  0.8998],\n",
            "        [-2.0118,  0.7838,  0.9195],\n",
            "        [ 0.3696, -0.0115, -0.8378],\n",
            "        [-1.6408,  1.7329, -0.2990],\n",
            "        [-1.7751,  0.8846,  0.8574],\n",
            "        [-1.6503,  0.5879,  0.8486],\n",
            "        [-1.7746,  1.9312, -0.3806]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-0.5633,  0.0499,  0.0585],\n",
            "        [-1.7509,  1.7157, -0.2564],\n",
            "        [-1.6317,  1.8051, -0.5502],\n",
            "        [-1.9252,  1.9191, -0.4182],\n",
            "        [-1.6463,  1.8332, -0.0860],\n",
            "        [-1.7795,  1.0855,  0.6090],\n",
            "        [-1.7038,  0.8228,  0.6337],\n",
            "        [-1.5327,  1.4852, -0.1349],\n",
            "        [-1.6047,  1.8957, -0.4550],\n",
            "        [-1.7642,  0.5718,  0.8998],\n",
            "        [-2.0118,  0.7838,  0.9195],\n",
            "        [ 0.3696, -0.0115, -0.8378],\n",
            "        [-1.6408,  1.7329, -0.2990],\n",
            "        [-1.7751,  0.8846,  0.8574],\n",
            "        [-1.6503,  0.5879,  0.8486],\n",
            "        [-1.7746,  1.9312, -0.3806]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8517,  0.5981,  1.0467],\n",
            "        [-1.5945,  1.9346, -0.2156],\n",
            "        [-1.4919,  1.7977, -0.4101],\n",
            "        [-1.5277,  1.9043, -0.7973],\n",
            "        [ 0.0987,  0.1077, -1.0276],\n",
            "        [-1.7561,  1.7392,  0.0134],\n",
            "        [ 0.2128,  0.3110, -0.9650],\n",
            "        [-1.6700,  1.9100, -0.5321],\n",
            "        [-1.8558,  2.0826, -0.1712],\n",
            "        [-1.7170,  0.5772,  1.0371],\n",
            "        [-1.6391,  1.8957, -0.5136],\n",
            "        [-1.5922,  1.5265, -0.2298],\n",
            "        [-1.9091,  0.6726,  0.8843],\n",
            "        [-1.6938,  1.9434, -0.4080],\n",
            "        [-1.5649,  0.3384,  1.0274],\n",
            "        [-2.0017,  1.6207,  0.1490]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8517,  0.5981,  1.0467],\n",
            "        [-1.5945,  1.9346, -0.2156],\n",
            "        [-1.4919,  1.7977, -0.4101],\n",
            "        [-1.5277,  1.9043, -0.7973],\n",
            "        [ 0.0987,  0.1077, -1.0276],\n",
            "        [-1.7561,  1.7392,  0.0134],\n",
            "        [ 0.2128,  0.3110, -0.9650],\n",
            "        [-1.6700,  1.9100, -0.5321],\n",
            "        [-1.8558,  2.0826, -0.1712],\n",
            "        [-1.7170,  0.5772,  1.0371],\n",
            "        [-1.6391,  1.8957, -0.5136],\n",
            "        [-1.5922,  1.5265, -0.2298],\n",
            "        [-1.9091,  0.6726,  0.8843],\n",
            "        [-1.6938,  1.9434, -0.4080],\n",
            "        [-1.5649,  0.3384,  1.0274],\n",
            "        [-2.0017,  1.6207,  0.1490]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3493, -0.1457, -0.8999],\n",
            "        [-1.5813,  1.7386, -0.2679],\n",
            "        [-1.9161,  0.6639,  1.1261],\n",
            "        [-1.7899,  1.7630, -0.1966],\n",
            "        [-2.0045,  1.1728,  0.6611],\n",
            "        [-1.8848,  0.8672,  0.6822],\n",
            "        [-1.8870,  1.2379,  0.3015],\n",
            "        [-1.7384,  1.9443, -0.3798],\n",
            "        [-1.6802,  0.3418,  1.0362],\n",
            "        [-1.6925,  2.0153, -0.4035],\n",
            "        [-1.7644,  1.8636, -0.4417],\n",
            "        [-1.7842,  0.7821,  0.8121],\n",
            "        [ 0.2843, -0.1404, -0.8527],\n",
            "        [-1.4883,  1.7667, -0.3606],\n",
            "        [ 0.3434, -0.0639, -0.8469],\n",
            "        [-1.5391,  2.0920, -0.3897]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.3493, -0.1457, -0.8999],\n",
            "        [-1.5813,  1.7386, -0.2679],\n",
            "        [-1.9161,  0.6639,  1.1261],\n",
            "        [-1.7899,  1.7630, -0.1966],\n",
            "        [-2.0045,  1.1728,  0.6611],\n",
            "        [-1.8848,  0.8672,  0.6822],\n",
            "        [-1.8870,  1.2379,  0.3015],\n",
            "        [-1.7384,  1.9443, -0.3798],\n",
            "        [-1.6802,  0.3418,  1.0362],\n",
            "        [-1.6925,  2.0153, -0.4035],\n",
            "        [-1.7644,  1.8636, -0.4417],\n",
            "        [-1.7842,  0.7821,  0.8121],\n",
            "        [ 0.2843, -0.1404, -0.8527],\n",
            "        [-1.4883,  1.7667, -0.3606],\n",
            "        [ 0.3434, -0.0639, -0.8469],\n",
            "        [-1.5391,  2.0920, -0.3897]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6053,  1.9436, -0.5422],\n",
            "        [-1.8089,  1.8275, -0.5344],\n",
            "        [ 0.4776, -0.2012, -0.9687],\n",
            "        [-1.6384,  1.8452, -0.4524],\n",
            "        [ 0.3514,  0.0295, -0.9570],\n",
            "        [-1.7714,  1.6923, -0.1573],\n",
            "        [-1.8362,  1.5493,  0.1061],\n",
            "        [-1.7656,  1.3173,  0.0874],\n",
            "        [-1.7632,  1.6686, -0.4125],\n",
            "        [-1.7684,  1.2561,  0.3205],\n",
            "        [-1.5590,  1.8245, -0.3079],\n",
            "        [ 0.2408,  0.0152, -0.8492],\n",
            "        [-1.8124,  0.5650,  1.0243],\n",
            "        [-1.5567,  1.9612, -0.3240],\n",
            "        [-1.7590,  0.7368,  0.5774],\n",
            "        [-1.6754,  2.0079, -0.3971]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6053,  1.9436, -0.5422],\n",
            "        [-1.8089,  1.8275, -0.5344],\n",
            "        [ 0.4776, -0.2012, -0.9687],\n",
            "        [-1.6384,  1.8452, -0.4524],\n",
            "        [ 0.3514,  0.0295, -0.9570],\n",
            "        [-1.7714,  1.6923, -0.1573],\n",
            "        [-1.8362,  1.5493,  0.1061],\n",
            "        [-1.7656,  1.3173,  0.0874],\n",
            "        [-1.7632,  1.6686, -0.4125],\n",
            "        [-1.7684,  1.2561,  0.3205],\n",
            "        [-1.5590,  1.8245, -0.3079],\n",
            "        [ 0.2408,  0.0152, -0.8492],\n",
            "        [-1.8124,  0.5650,  1.0243],\n",
            "        [-1.5567,  1.9612, -0.3240],\n",
            "        [-1.7590,  0.7368,  0.5774],\n",
            "        [-1.6754,  2.0079, -0.3971]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7322,  0.5833,  0.8712],\n",
            "        [-1.5441,  1.7207, -0.1714],\n",
            "        [-1.4173,  1.9071, -0.6055],\n",
            "        [-1.7539,  0.7153,  0.8468],\n",
            "        [-0.3406,  0.7273, -0.9769],\n",
            "        [-1.8413,  0.4675,  1.0166],\n",
            "        [-1.7750,  0.7875,  0.9322],\n",
            "        [-1.7127,  0.9301,  0.8975],\n",
            "        [-1.6560,  1.9659, -0.5360],\n",
            "        [-1.7196,  1.9586, -0.3239],\n",
            "        [-1.7311,  0.4297,  0.9182],\n",
            "        [-1.0358,  0.7666,  0.4168],\n",
            "        [-1.5250,  1.8217, -0.4477],\n",
            "        [-1.8247,  1.8839, -0.7165],\n",
            "        [-1.6689,  1.8355, -0.2694],\n",
            "        [ 0.4420, -0.0880, -0.9167]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7322,  0.5833,  0.8712],\n",
            "        [-1.5441,  1.7207, -0.1714],\n",
            "        [-1.4173,  1.9071, -0.6055],\n",
            "        [-1.7539,  0.7153,  0.8468],\n",
            "        [-0.3406,  0.7273, -0.9769],\n",
            "        [-1.8413,  0.4675,  1.0166],\n",
            "        [-1.7750,  0.7875,  0.9322],\n",
            "        [-1.7127,  0.9301,  0.8975],\n",
            "        [-1.6560,  1.9659, -0.5360],\n",
            "        [-1.7196,  1.9586, -0.3239],\n",
            "        [-1.7311,  0.4297,  0.9182],\n",
            "        [-1.0358,  0.7666,  0.4168],\n",
            "        [-1.5250,  1.8217, -0.4477],\n",
            "        [-1.8247,  1.8839, -0.7165],\n",
            "        [-1.6689,  1.8355, -0.2694],\n",
            "        [ 0.4420, -0.0880, -0.9167]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7437,  2.0448, -0.5546],\n",
            "        [-1.6738,  1.9089, -0.4855],\n",
            "        [-1.4335,  1.7948, -0.6577],\n",
            "        [-1.7304,  1.9475, -0.3578],\n",
            "        [-1.7789,  2.0496, -0.5071],\n",
            "        [-1.2005,  0.6983,  0.4250],\n",
            "        [-1.7411,  2.0197, -0.4741],\n",
            "        [-0.4037,  0.2771, -0.3014],\n",
            "        [-1.6126,  0.2149,  1.0812],\n",
            "        [ 0.5812, -0.1288, -0.8380],\n",
            "        [-1.6224,  1.9599, -0.3730],\n",
            "        [-1.8983,  0.7563,  0.7534],\n",
            "        [-1.7568,  1.7041, -0.4759],\n",
            "        [ 0.0692,  0.1435, -0.9741],\n",
            "        [ 0.1324,  0.2429, -1.0195],\n",
            "        [-1.7623,  0.7693,  0.7694]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7437,  2.0448, -0.5546],\n",
            "        [-1.6738,  1.9089, -0.4855],\n",
            "        [-1.4335,  1.7948, -0.6577],\n",
            "        [-1.7304,  1.9475, -0.3578],\n",
            "        [-1.7789,  2.0496, -0.5071],\n",
            "        [-1.2005,  0.6983,  0.4250],\n",
            "        [-1.7411,  2.0197, -0.4741],\n",
            "        [-0.4037,  0.2771, -0.3014],\n",
            "        [-1.6126,  0.2149,  1.0812],\n",
            "        [ 0.5812, -0.1288, -0.8380],\n",
            "        [-1.6224,  1.9599, -0.3730],\n",
            "        [-1.8983,  0.7563,  0.7534],\n",
            "        [-1.7568,  1.7041, -0.4759],\n",
            "        [ 0.0692,  0.1435, -0.9741],\n",
            "        [ 0.1324,  0.2429, -1.0195],\n",
            "        [-1.7623,  0.7693,  0.7694]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6019,  2.0041, -0.8306],\n",
            "        [-1.6421,  2.0453, -0.4202],\n",
            "        [ 0.4389, -0.1379, -0.8017],\n",
            "        [-1.5533,  1.8997, -0.5175],\n",
            "        [-1.8128,  0.5446,  1.1388],\n",
            "        [-1.6396,  1.7638, -0.5588],\n",
            "        [-1.5916,  2.0492, -0.7416],\n",
            "        [ 0.4771, -0.2299, -0.8506],\n",
            "        [-1.9977,  0.5615,  0.9539],\n",
            "        [-1.6164,  2.0879, -0.4113],\n",
            "        [ 0.3795, -0.1234, -0.6830],\n",
            "        [-1.5766,  0.6052,  0.8614],\n",
            "        [-1.5846,  1.9017, -0.1139],\n",
            "        [-1.7014,  1.7508, -0.2860],\n",
            "        [-1.4770,  1.4877, -0.5657],\n",
            "        [-1.5585,  1.9586, -0.6742]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6019,  2.0041, -0.8306],\n",
            "        [-1.6421,  2.0453, -0.4202],\n",
            "        [ 0.4389, -0.1379, -0.8017],\n",
            "        [-1.5533,  1.8997, -0.5175],\n",
            "        [-1.8128,  0.5446,  1.1388],\n",
            "        [-1.6396,  1.7638, -0.5588],\n",
            "        [-1.5916,  2.0492, -0.7416],\n",
            "        [ 0.4771, -0.2299, -0.8506],\n",
            "        [-1.9977,  0.5615,  0.9539],\n",
            "        [-1.6164,  2.0879, -0.4113],\n",
            "        [ 0.3795, -0.1234, -0.6830],\n",
            "        [-1.5766,  0.6052,  0.8614],\n",
            "        [-1.5846,  1.9017, -0.1139],\n",
            "        [-1.7014,  1.7508, -0.2860],\n",
            "        [-1.4770,  1.4877, -0.5657],\n",
            "        [-1.5585,  1.9586, -0.6742]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7065,  1.8254, -0.3477],\n",
            "        [ 0.2224,  0.1974, -0.9744],\n",
            "        [-1.6090,  0.7140,  1.1357],\n",
            "        [-1.5833,  2.1213, -0.5496],\n",
            "        [-1.8342,  0.5057,  1.0899],\n",
            "        [-1.5672,  1.6880, -0.5944],\n",
            "        [-1.7604,  0.4576,  0.8434],\n",
            "        [-1.8244,  1.9796, -0.8075],\n",
            "        [-1.5622,  1.9199, -0.2403],\n",
            "        [-1.7333,  1.9685, -0.6525],\n",
            "        [-1.8403,  2.1271, -0.4833],\n",
            "        [-1.6670,  0.8526,  0.8462],\n",
            "        [-1.6258,  2.2357, -0.5507],\n",
            "        [-1.2688,  1.9601, -0.7827],\n",
            "        [-1.5731,  2.1601, -0.4835],\n",
            "        [-1.5495,  0.6542,  0.6791]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7065,  1.8254, -0.3477],\n",
            "        [ 0.2224,  0.1974, -0.9744],\n",
            "        [-1.6090,  0.7140,  1.1357],\n",
            "        [-1.5833,  2.1213, -0.5496],\n",
            "        [-1.8342,  0.5057,  1.0899],\n",
            "        [-1.5672,  1.6880, -0.5944],\n",
            "        [-1.7604,  0.4576,  0.8434],\n",
            "        [-1.8244,  1.9796, -0.8075],\n",
            "        [-1.5622,  1.9199, -0.2403],\n",
            "        [-1.7333,  1.9685, -0.6525],\n",
            "        [-1.8403,  2.1271, -0.4833],\n",
            "        [-1.6670,  0.8526,  0.8462],\n",
            "        [-1.6258,  2.2357, -0.5507],\n",
            "        [-1.2688,  1.9601, -0.7827],\n",
            "        [-1.5731,  2.1601, -0.4835],\n",
            "        [-1.5495,  0.6542,  0.6791]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7118,  2.2183, -0.6238],\n",
            "        [-1.6831,  1.8727, -0.6320],\n",
            "        [-1.3401,  1.9675, -0.4143],\n",
            "        [ 0.1783,  0.2057, -1.1051],\n",
            "        [-2.0132,  2.0027, -0.1249],\n",
            "        [ 0.5054, -0.2267, -0.9375],\n",
            "        [-1.5523,  1.3576, -0.0148],\n",
            "        [-1.8589,  0.4266,  1.1245],\n",
            "        [-1.8025,  1.4686,  0.0481],\n",
            "        [-1.7106,  2.0143, -0.4253],\n",
            "        [-1.5467,  2.0352, -0.3726],\n",
            "        [-1.0385,  0.1158,  0.5062],\n",
            "        [-1.5078,  1.8373, -0.5735],\n",
            "        [ 0.0368,  0.2646, -1.1202],\n",
            "        [-1.4570,  1.8124, -0.2613],\n",
            "        [-1.7669,  1.6671,  0.0975]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7118,  2.2183, -0.6238],\n",
            "        [-1.6831,  1.8727, -0.6320],\n",
            "        [-1.3401,  1.9675, -0.4143],\n",
            "        [ 0.1783,  0.2057, -1.1051],\n",
            "        [-2.0132,  2.0027, -0.1249],\n",
            "        [ 0.5054, -0.2267, -0.9375],\n",
            "        [-1.5523,  1.3576, -0.0148],\n",
            "        [-1.8589,  0.4266,  1.1245],\n",
            "        [-1.8025,  1.4686,  0.0481],\n",
            "        [-1.7106,  2.0143, -0.4253],\n",
            "        [-1.5467,  2.0352, -0.3726],\n",
            "        [-1.0385,  0.1158,  0.5062],\n",
            "        [-1.5078,  1.8373, -0.5735],\n",
            "        [ 0.0368,  0.2646, -1.1202],\n",
            "        [-1.4570,  1.8124, -0.2613],\n",
            "        [-1.7669,  1.6671,  0.0975]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6655,  2.0827, -0.3907],\n",
            "        [-1.9213,  2.0319, -0.4715],\n",
            "        [-1.7127,  2.0406, -0.3392],\n",
            "        [-1.6673,  0.7010,  0.7634],\n",
            "        [-1.5330,  1.9561, -0.5189],\n",
            "        [ 0.2909, -0.1607, -0.6177],\n",
            "        [ 0.4890, -0.3274, -0.6618],\n",
            "        [-1.5621,  1.9332, -0.6246],\n",
            "        [-1.4838,  1.8994, -0.5419],\n",
            "        [-1.8331,  0.5519,  0.9931],\n",
            "        [-1.6209,  2.0409, -0.6764],\n",
            "        [-1.6443,  1.9465, -0.3636],\n",
            "        [-1.8636,  2.0527, -0.2969],\n",
            "        [-1.4469,  1.8125, -0.2063],\n",
            "        [-1.7338,  2.1229, -0.5602],\n",
            "        [-1.6909,  1.6198, -0.2978]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6655,  2.0827, -0.3907],\n",
            "        [-1.9213,  2.0319, -0.4715],\n",
            "        [-1.7127,  2.0406, -0.3392],\n",
            "        [-1.6673,  0.7010,  0.7634],\n",
            "        [-1.5330,  1.9561, -0.5189],\n",
            "        [ 0.2909, -0.1607, -0.6177],\n",
            "        [ 0.4890, -0.3274, -0.6618],\n",
            "        [-1.5621,  1.9332, -0.6246],\n",
            "        [-1.4838,  1.8994, -0.5419],\n",
            "        [-1.8331,  0.5519,  0.9931],\n",
            "        [-1.6209,  2.0409, -0.6764],\n",
            "        [-1.6443,  1.9465, -0.3636],\n",
            "        [-1.8636,  2.0527, -0.2969],\n",
            "        [-1.4469,  1.8125, -0.2063],\n",
            "        [-1.7338,  2.1229, -0.5602],\n",
            "        [-1.6909,  1.6198, -0.2978]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8094,  1.8633, -0.6160],\n",
            "        [-1.7225,  0.3433,  1.0621],\n",
            "        [-1.7957,  1.9848, -0.4167],\n",
            "        [-1.9262,  0.7486,  0.8310],\n",
            "        [ 0.4763, -0.2744, -0.7507],\n",
            "        [-1.9679,  0.4663,  1.1724],\n",
            "        [-1.5480,  0.5361,  1.0039],\n",
            "        [-1.7245,  2.1123, -0.5769],\n",
            "        [-1.8360,  1.9398, -0.3278],\n",
            "        [-1.8872,  0.6248,  1.0219],\n",
            "        [-1.6805,  0.3840,  1.1367],\n",
            "        [-1.7665,  1.9022, -0.2766],\n",
            "        [-1.2665,  1.7644, -0.4730],\n",
            "        [-1.6298,  2.0635, -0.4711],\n",
            "        [-1.6417,  0.4009,  0.9251],\n",
            "        [-1.6630,  2.0078, -0.4439]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8094,  1.8633, -0.6160],\n",
            "        [-1.7225,  0.3433,  1.0621],\n",
            "        [-1.7957,  1.9848, -0.4167],\n",
            "        [-1.9262,  0.7486,  0.8310],\n",
            "        [ 0.4763, -0.2744, -0.7507],\n",
            "        [-1.9679,  0.4663,  1.1724],\n",
            "        [-1.5480,  0.5361,  1.0039],\n",
            "        [-1.7245,  2.1123, -0.5769],\n",
            "        [-1.8360,  1.9398, -0.3278],\n",
            "        [-1.8872,  0.6248,  1.0219],\n",
            "        [-1.6805,  0.3840,  1.1367],\n",
            "        [-1.7665,  1.9022, -0.2766],\n",
            "        [-1.2665,  1.7644, -0.4730],\n",
            "        [-1.6298,  2.0635, -0.4711],\n",
            "        [-1.6417,  0.4009,  0.9251],\n",
            "        [-1.6630,  2.0078, -0.4439]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7707,  1.7335, -0.2259],\n",
            "        [-1.5566,  1.7763, -0.5101],\n",
            "        [-1.9082,  2.0146, -0.1573],\n",
            "        [-1.8710,  1.7731,  0.1729],\n",
            "        [-1.7237,  2.1202, -0.3626],\n",
            "        [-1.5457,  0.3285,  1.0272],\n",
            "        [-1.7147,  1.9887, -0.5448],\n",
            "        [-1.8297,  1.4826,  0.3143],\n",
            "        [-1.3802,  0.0455,  0.6718],\n",
            "        [-1.8738,  1.7058, -0.0769],\n",
            "        [-1.8756,  1.4405, -0.0903],\n",
            "        [-1.7592,  1.3426,  0.3612],\n",
            "        [-1.5435,  1.8204, -0.4647],\n",
            "        [-1.7759,  0.5901,  0.9739],\n",
            "        [ 0.5486, -0.2652, -0.7763],\n",
            "        [-1.6763,  2.0776, -0.2302]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7707,  1.7335, -0.2259],\n",
            "        [-1.5566,  1.7763, -0.5101],\n",
            "        [-1.9082,  2.0146, -0.1573],\n",
            "        [-1.8710,  1.7731,  0.1729],\n",
            "        [-1.7237,  2.1202, -0.3626],\n",
            "        [-1.5457,  0.3285,  1.0272],\n",
            "        [-1.7147,  1.9887, -0.5448],\n",
            "        [-1.8297,  1.4826,  0.3143],\n",
            "        [-1.3802,  0.0455,  0.6718],\n",
            "        [-1.8738,  1.7058, -0.0769],\n",
            "        [-1.8756,  1.4405, -0.0903],\n",
            "        [-1.7592,  1.3426,  0.3612],\n",
            "        [-1.5435,  1.8204, -0.4647],\n",
            "        [-1.7759,  0.5901,  0.9739],\n",
            "        [ 0.5486, -0.2652, -0.7763],\n",
            "        [-1.6763,  2.0776, -0.2302]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3289,  1.6413, -0.7728],\n",
            "        [ 0.4096, -0.1663, -0.8247],\n",
            "        [-2.0974,  2.0976, -0.3369],\n",
            "        [-1.7512,  0.8841,  0.9885],\n",
            "        [ 0.5345, -0.1702, -0.8664],\n",
            "        [-1.6641,  0.2440,  0.9708],\n",
            "        [-1.9175,  0.4807,  1.3735],\n",
            "        [-1.7679,  2.0421, -0.4198],\n",
            "        [-1.8150,  0.7540,  0.9288],\n",
            "        [-1.8085,  1.5231,  0.0976],\n",
            "        [-1.6194,  1.9576, -0.5871],\n",
            "        [-0.8456,  0.0736,  0.2901],\n",
            "        [-1.6709,  2.0734, -0.2772],\n",
            "        [ 0.4604, -0.2250, -0.6429],\n",
            "        [-1.6285,  0.3698,  1.0869],\n",
            "        [-1.7858,  0.3491,  1.2211]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3289,  1.6413, -0.7728],\n",
            "        [ 0.4096, -0.1663, -0.8247],\n",
            "        [-2.0974,  2.0976, -0.3369],\n",
            "        [-1.7512,  0.8841,  0.9885],\n",
            "        [ 0.5345, -0.1702, -0.8664],\n",
            "        [-1.6641,  0.2440,  0.9708],\n",
            "        [-1.9175,  0.4807,  1.3735],\n",
            "        [-1.7679,  2.0421, -0.4198],\n",
            "        [-1.8150,  0.7540,  0.9288],\n",
            "        [-1.8085,  1.5231,  0.0976],\n",
            "        [-1.6194,  1.9576, -0.5871],\n",
            "        [-0.8456,  0.0736,  0.2901],\n",
            "        [-1.6709,  2.0734, -0.2772],\n",
            "        [ 0.4604, -0.2250, -0.6429],\n",
            "        [-1.6285,  0.3698,  1.0869],\n",
            "        [-1.7858,  0.3491,  1.2211]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6308,  1.7296, -0.3942],\n",
            "        [-1.9579,  1.7922,  0.0146],\n",
            "        [-1.4591,  0.1624,  1.1802],\n",
            "        [ 0.4970, -0.1785, -0.9226],\n",
            "        [-1.7179,  1.9122, -0.4836],\n",
            "        [-1.7995,  2.1261, -0.2306],\n",
            "        [-1.8418,  1.9652, -0.3473],\n",
            "        [-1.4297,  0.1334,  1.1818],\n",
            "        [-1.8699,  0.5926,  0.8324],\n",
            "        [-1.9244,  0.9474,  0.5301],\n",
            "        [-1.7440,  0.9746,  1.0141],\n",
            "        [-2.0022,  2.0746,  0.0764],\n",
            "        [-1.5102,  1.9464, -0.4964],\n",
            "        [-1.8486,  2.1571, -0.2800],\n",
            "        [-1.8504,  0.5147,  1.0303],\n",
            "        [-1.7886,  1.5782, -0.3427]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6308,  1.7296, -0.3942],\n",
            "        [-1.9579,  1.7922,  0.0146],\n",
            "        [-1.4591,  0.1624,  1.1802],\n",
            "        [ 0.4970, -0.1785, -0.9226],\n",
            "        [-1.7179,  1.9122, -0.4836],\n",
            "        [-1.7995,  2.1261, -0.2306],\n",
            "        [-1.8418,  1.9652, -0.3473],\n",
            "        [-1.4297,  0.1334,  1.1818],\n",
            "        [-1.8699,  0.5926,  0.8324],\n",
            "        [-1.9244,  0.9474,  0.5301],\n",
            "        [-1.7440,  0.9746,  1.0141],\n",
            "        [-2.0022,  2.0746,  0.0764],\n",
            "        [-1.5102,  1.9464, -0.4964],\n",
            "        [-1.8486,  2.1571, -0.2800],\n",
            "        [-1.8504,  0.5147,  1.0303],\n",
            "        [-1.7886,  1.5782, -0.3427]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.3920,  0.7532, -0.6900],\n",
            "        [-1.8025,  1.9164, -0.4972],\n",
            "        [-1.8844,  2.1888, -0.2351],\n",
            "        [-1.6875,  0.7625,  0.6862],\n",
            "        [-1.7248,  1.9270, -0.4190],\n",
            "        [ 0.0719,  0.2219, -0.7717],\n",
            "        [-1.7970,  0.2967,  1.2698],\n",
            "        [-2.0413,  0.5414,  1.2319],\n",
            "        [-1.5996,  1.9234, -0.4221],\n",
            "        [ 0.6151, -0.2913, -0.7568],\n",
            "        [-1.7363,  1.9348, -0.0990],\n",
            "        [-1.6429,  0.3479,  1.2216],\n",
            "        [-1.9164,  1.8624, -0.4039],\n",
            "        [-1.7619,  0.3300,  1.1911],\n",
            "        [-1.6175,  0.8652,  0.3778],\n",
            "        [-1.6818,  0.2448,  1.2245]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-0.3920,  0.7532, -0.6900],\n",
            "        [-1.8025,  1.9164, -0.4972],\n",
            "        [-1.8844,  2.1888, -0.2351],\n",
            "        [-1.6875,  0.7625,  0.6862],\n",
            "        [-1.7248,  1.9270, -0.4190],\n",
            "        [ 0.0719,  0.2219, -0.7717],\n",
            "        [-1.7970,  0.2967,  1.2698],\n",
            "        [-2.0413,  0.5414,  1.2319],\n",
            "        [-1.5996,  1.9234, -0.4221],\n",
            "        [ 0.6151, -0.2913, -0.7568],\n",
            "        [-1.7363,  1.9348, -0.0990],\n",
            "        [-1.6429,  0.3479,  1.2216],\n",
            "        [-1.9164,  1.8624, -0.4039],\n",
            "        [-1.7619,  0.3300,  1.1911],\n",
            "        [-1.6175,  0.8652,  0.3778],\n",
            "        [-1.6818,  0.2448,  1.2245]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6843,  0.1769,  1.3577],\n",
            "        [-1.6072,  0.1309,  1.3600],\n",
            "        [-1.7617,  2.0308, -0.3095],\n",
            "        [-1.5440,  0.2296,  1.2404],\n",
            "        [-1.7038,  1.9413, -0.5335],\n",
            "        [-1.7616,  0.8513,  0.8934],\n",
            "        [-1.8252,  0.5180,  1.0525],\n",
            "        [-1.9035,  2.0929, -0.4117],\n",
            "        [-1.9184,  1.9947, -0.4135],\n",
            "        [-1.7971,  2.0681, -0.2863],\n",
            "        [-1.3335,  0.9165,  0.2362],\n",
            "        [-1.6263,  1.5903, -0.4650],\n",
            "        [-1.5783,  1.6040, -0.4449],\n",
            "        [-1.8806,  1.9936, -0.4118],\n",
            "        [-2.0156,  0.4158,  1.1894],\n",
            "        [-1.9758,  1.8286, -0.1532]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6843,  0.1769,  1.3577],\n",
            "        [-1.6072,  0.1309,  1.3600],\n",
            "        [-1.7617,  2.0308, -0.3095],\n",
            "        [-1.5440,  0.2296,  1.2404],\n",
            "        [-1.7038,  1.9413, -0.5335],\n",
            "        [-1.7616,  0.8513,  0.8934],\n",
            "        [-1.8252,  0.5180,  1.0525],\n",
            "        [-1.9035,  2.0929, -0.4117],\n",
            "        [-1.9184,  1.9947, -0.4135],\n",
            "        [-1.7971,  2.0681, -0.2863],\n",
            "        [-1.3335,  0.9165,  0.2362],\n",
            "        [-1.6263,  1.5903, -0.4650],\n",
            "        [-1.5783,  1.6040, -0.4449],\n",
            "        [-1.8806,  1.9936, -0.4118],\n",
            "        [-2.0156,  0.4158,  1.1894],\n",
            "        [-1.9758,  1.8286, -0.1532]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4401,  1.7471, -0.4319],\n",
            "        [-1.8308,  1.9789, -0.4953],\n",
            "        [ 0.4783, -0.2634, -0.7905],\n",
            "        [-1.8522,  1.4586, -0.0225],\n",
            "        [-1.7396,  1.6992, -0.3369],\n",
            "        [-1.9616,  1.9712, -0.1244],\n",
            "        [-1.7606,  1.9050,  0.0033],\n",
            "        [-1.7555,  0.3587,  1.1986],\n",
            "        [-1.9027,  1.7576, -0.1189],\n",
            "        [-1.9804,  0.7706,  1.0117],\n",
            "        [-1.7503,  0.1044,  1.1608],\n",
            "        [ 0.2854, -0.1032, -0.7467],\n",
            "        [-1.1399,  1.4867, -0.8154],\n",
            "        [-1.9156,  0.7014,  0.9613],\n",
            "        [-1.3528,  0.2496,  0.7380],\n",
            "        [ 0.3150, -0.1402, -0.7129]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4401,  1.7471, -0.4319],\n",
            "        [-1.8308,  1.9789, -0.4953],\n",
            "        [ 0.4783, -0.2634, -0.7905],\n",
            "        [-1.8522,  1.4586, -0.0225],\n",
            "        [-1.7396,  1.6992, -0.3369],\n",
            "        [-1.9616,  1.9712, -0.1244],\n",
            "        [-1.7606,  1.9050,  0.0033],\n",
            "        [-1.7555,  0.3587,  1.1986],\n",
            "        [-1.9027,  1.7576, -0.1189],\n",
            "        [-1.9804,  0.7706,  1.0117],\n",
            "        [-1.7503,  0.1044,  1.1608],\n",
            "        [ 0.2854, -0.1032, -0.7467],\n",
            "        [-1.1399,  1.4867, -0.8154],\n",
            "        [-1.9156,  0.7014,  0.9613],\n",
            "        [-1.3528,  0.2496,  0.7380],\n",
            "        [ 0.3150, -0.1402, -0.7129]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7807e+00,  1.7876e+00, -4.2513e-01],\n",
            "        [-1.7246e+00,  1.7366e+00, -4.2808e-01],\n",
            "        [-2.0551e+00,  1.9004e+00, -8.0623e-02],\n",
            "        [-1.8931e+00,  1.7496e+00, -1.1227e-01],\n",
            "        [ 5.6146e-01, -4.1001e-01, -7.4135e-01],\n",
            "        [-2.1209e+00,  1.1192e+00,  7.5940e-01],\n",
            "        [-1.6049e+00,  1.3540e+00, -9.3923e-04],\n",
            "        [-1.8110e+00,  2.0291e+00, -3.3600e-01],\n",
            "        [-1.8309e+00,  2.9771e-01,  1.1976e+00],\n",
            "        [-1.6937e+00,  1.9827e+00, -4.9205e-01],\n",
            "        [-1.7052e+00,  1.6801e+00, -3.6186e-01],\n",
            "        [-1.7495e+00,  1.9099e+00, -2.9835e-01],\n",
            "        [-1.8756e+00,  2.0135e+00, -1.6908e-01],\n",
            "        [-1.9282e+00,  2.0731e+00, -4.7202e-01],\n",
            "        [-2.0190e+00,  1.0086e+00,  7.5922e-01],\n",
            "        [-1.7815e+00,  2.9947e-01,  1.3453e+00]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7807e+00,  1.7876e+00, -4.2513e-01],\n",
            "        [-1.7246e+00,  1.7366e+00, -4.2808e-01],\n",
            "        [-2.0551e+00,  1.9004e+00, -8.0623e-02],\n",
            "        [-1.8931e+00,  1.7496e+00, -1.1227e-01],\n",
            "        [ 5.6146e-01, -4.1001e-01, -7.4135e-01],\n",
            "        [-2.1209e+00,  1.1192e+00,  7.5940e-01],\n",
            "        [-1.6049e+00,  1.3540e+00, -9.3923e-04],\n",
            "        [-1.8110e+00,  2.0291e+00, -3.3600e-01],\n",
            "        [-1.8309e+00,  2.9771e-01,  1.1976e+00],\n",
            "        [-1.6937e+00,  1.9827e+00, -4.9205e-01],\n",
            "        [-1.7052e+00,  1.6801e+00, -3.6186e-01],\n",
            "        [-1.7495e+00,  1.9099e+00, -2.9835e-01],\n",
            "        [-1.8756e+00,  2.0135e+00, -1.6908e-01],\n",
            "        [-1.9282e+00,  2.0731e+00, -4.7202e-01],\n",
            "        [-2.0190e+00,  1.0086e+00,  7.5922e-01],\n",
            "        [-1.7815e+00,  2.9947e-01,  1.3453e+00]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9591,  1.9848, -0.4950],\n",
            "        [-1.8128,  0.3613,  1.1985],\n",
            "        [-1.6925, -0.0460,  1.1841],\n",
            "        [-2.0027,  1.9906, -0.2109],\n",
            "        [-2.0759,  1.8091,  0.1674],\n",
            "        [-1.9404,  1.9098, -0.5035],\n",
            "        [-1.6906,  1.6400, -0.5598],\n",
            "        [-0.4487, -0.1111,  0.3103],\n",
            "        [-1.8152,  2.0337, -0.4377],\n",
            "        [-1.6800,  0.3643,  1.4768],\n",
            "        [-1.8685,  0.4880,  1.1960],\n",
            "        [-1.7564,  1.9096, -0.5442],\n",
            "        [ 0.1167, -0.3576, -0.2345],\n",
            "        [-1.8418,  2.0271, -0.0193],\n",
            "        [ 0.4915, -0.1280, -0.8629],\n",
            "        [-1.7678,  0.6611,  0.9612]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9591,  1.9848, -0.4950],\n",
            "        [-1.8128,  0.3613,  1.1985],\n",
            "        [-1.6925, -0.0460,  1.1841],\n",
            "        [-2.0027,  1.9906, -0.2109],\n",
            "        [-2.0759,  1.8091,  0.1674],\n",
            "        [-1.9404,  1.9098, -0.5035],\n",
            "        [-1.6906,  1.6400, -0.5598],\n",
            "        [-0.4487, -0.1111,  0.3103],\n",
            "        [-1.8152,  2.0337, -0.4377],\n",
            "        [-1.6800,  0.3643,  1.4768],\n",
            "        [-1.8685,  0.4880,  1.1960],\n",
            "        [-1.7564,  1.9096, -0.5442],\n",
            "        [ 0.1167, -0.3576, -0.2345],\n",
            "        [-1.8418,  2.0271, -0.0193],\n",
            "        [ 0.4915, -0.1280, -0.8629],\n",
            "        [-1.7678,  0.6611,  0.9612]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8886,  1.8432, -0.4014],\n",
            "        [-1.6874,  0.2042,  1.0564],\n",
            "        [-1.7265,  0.1982,  1.3502],\n",
            "        [-2.0174,  0.9551,  0.7042],\n",
            "        [-1.8036,  1.7396, -0.1978],\n",
            "        [-1.7975,  0.1959,  1.1254],\n",
            "        [-1.6980,  0.0931,  1.3476],\n",
            "        [-1.8170,  1.9174, -0.1391],\n",
            "        [ 0.5860, -0.2478, -0.7467],\n",
            "        [-1.8614,  0.3235,  1.3141],\n",
            "        [-1.7047,  0.3196,  1.1920],\n",
            "        [-2.0189,  1.3377,  0.5843],\n",
            "        [-2.0697,  1.3644,  0.4477],\n",
            "        [-1.7230,  1.6711, -0.0886],\n",
            "        [-1.6518,  1.5920, -0.2389],\n",
            "        [-1.7698,  2.0265, -0.3664]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8886,  1.8432, -0.4014],\n",
            "        [-1.6874,  0.2042,  1.0564],\n",
            "        [-1.7265,  0.1982,  1.3502],\n",
            "        [-2.0174,  0.9551,  0.7042],\n",
            "        [-1.8036,  1.7396, -0.1978],\n",
            "        [-1.7975,  0.1959,  1.1254],\n",
            "        [-1.6980,  0.0931,  1.3476],\n",
            "        [-1.8170,  1.9174, -0.1391],\n",
            "        [ 0.5860, -0.2478, -0.7467],\n",
            "        [-1.8614,  0.3235,  1.3141],\n",
            "        [-1.7047,  0.3196,  1.1920],\n",
            "        [-2.0189,  1.3377,  0.5843],\n",
            "        [-2.0697,  1.3644,  0.4477],\n",
            "        [-1.7230,  1.6711, -0.0886],\n",
            "        [-1.6518,  1.5920, -0.2389],\n",
            "        [-1.7698,  2.0265, -0.3664]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8703,  2.0375, -0.3745],\n",
            "        [ 0.4498, -0.3314, -0.5276],\n",
            "        [-1.8296,  2.0449, -0.2855],\n",
            "        [ 0.4702, -0.2653, -0.6470],\n",
            "        [ 0.4545, -0.2352, -0.5545],\n",
            "        [-1.7816,  0.2990,  1.2059],\n",
            "        [-1.8029,  1.3795,  0.5076],\n",
            "        [-1.7112,  2.1280, -0.1571],\n",
            "        [-1.6846,  0.2005,  1.2975],\n",
            "        [-1.7614,  0.3176,  1.2898],\n",
            "        [-1.8518,  0.0038,  1.3602],\n",
            "        [-1.9010,  0.5104,  1.2126],\n",
            "        [-1.8700,  1.8871, -0.3431],\n",
            "        [ 0.5457, -0.3524, -0.6591],\n",
            "        [-1.7149,  1.8313, -0.3377],\n",
            "        [-1.9166,  2.0826, -0.4553]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8703,  2.0375, -0.3745],\n",
            "        [ 0.4498, -0.3314, -0.5276],\n",
            "        [-1.8296,  2.0449, -0.2855],\n",
            "        [ 0.4702, -0.2653, -0.6470],\n",
            "        [ 0.4545, -0.2352, -0.5545],\n",
            "        [-1.7816,  0.2990,  1.2059],\n",
            "        [-1.8029,  1.3795,  0.5076],\n",
            "        [-1.7112,  2.1280, -0.1571],\n",
            "        [-1.6846,  0.2005,  1.2975],\n",
            "        [-1.7614,  0.3176,  1.2898],\n",
            "        [-1.8518,  0.0038,  1.3602],\n",
            "        [-1.9010,  0.5104,  1.2126],\n",
            "        [-1.8700,  1.8871, -0.3431],\n",
            "        [ 0.5457, -0.3524, -0.6591],\n",
            "        [-1.7149,  1.8313, -0.3377],\n",
            "        [-1.9166,  2.0826, -0.4553]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5395, -0.3721, -0.4823],\n",
            "        [-1.8125,  1.8929, -0.3455],\n",
            "        [-1.7749,  0.1634,  1.1482],\n",
            "        [-1.9298,  0.4172,  1.4179],\n",
            "        [-1.5416,  0.0719,  1.2284],\n",
            "        [-1.8498,  2.1528, -0.2375],\n",
            "        [-1.7350,  1.8910, -0.3426],\n",
            "        [-1.6599,  0.1748,  1.3470],\n",
            "        [-1.6160,  0.0694,  1.3876],\n",
            "        [-1.9034,  0.9514,  0.8598],\n",
            "        [-2.0746,  1.3503,  0.2479],\n",
            "        [-1.9786,  1.9734, -0.3770],\n",
            "        [-1.8187,  2.0177,  0.0131],\n",
            "        [-2.1479,  1.4218,  0.3714],\n",
            "        [ 0.6155, -0.0675, -1.0099],\n",
            "        [-1.7672,  0.6291,  1.0321]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.5395, -0.3721, -0.4823],\n",
            "        [-1.8125,  1.8929, -0.3455],\n",
            "        [-1.7749,  0.1634,  1.1482],\n",
            "        [-1.9298,  0.4172,  1.4179],\n",
            "        [-1.5416,  0.0719,  1.2284],\n",
            "        [-1.8498,  2.1528, -0.2375],\n",
            "        [-1.7350,  1.8910, -0.3426],\n",
            "        [-1.6599,  0.1748,  1.3470],\n",
            "        [-1.6160,  0.0694,  1.3876],\n",
            "        [-1.9034,  0.9514,  0.8598],\n",
            "        [-2.0746,  1.3503,  0.2479],\n",
            "        [-1.9786,  1.9734, -0.3770],\n",
            "        [-1.8187,  2.0177,  0.0131],\n",
            "        [-2.1479,  1.4218,  0.3714],\n",
            "        [ 0.6155, -0.0675, -1.0099],\n",
            "        [-1.7672,  0.6291,  1.0321]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6417,  0.0209,  1.0898],\n",
            "        [-1.9437,  1.6656, -0.2564],\n",
            "        [-1.8523,  1.7375, -0.0519],\n",
            "        [-1.7421,  0.1594,  1.3260],\n",
            "        [-1.9392,  0.2180,  1.4721],\n",
            "        [-1.8019,  2.1797, -0.3790],\n",
            "        [-1.7822,  0.3324,  1.3926],\n",
            "        [-1.8517,  0.3612,  1.2866],\n",
            "        [-1.8370, -0.0113,  1.3769],\n",
            "        [-1.6706,  1.2658,  0.2034],\n",
            "        [-1.6699,  0.1073,  1.3629],\n",
            "        [-1.4715,  1.7640, -0.2369],\n",
            "        [-1.7433,  1.4366,  0.3219],\n",
            "        [-2.0055,  1.5747,  0.4604],\n",
            "        [-1.8676,  1.9647, -0.1825],\n",
            "        [ 0.5906, -0.3750, -0.6570]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6417,  0.0209,  1.0898],\n",
            "        [-1.9437,  1.6656, -0.2564],\n",
            "        [-1.8523,  1.7375, -0.0519],\n",
            "        [-1.7421,  0.1594,  1.3260],\n",
            "        [-1.9392,  0.2180,  1.4721],\n",
            "        [-1.8019,  2.1797, -0.3790],\n",
            "        [-1.7822,  0.3324,  1.3926],\n",
            "        [-1.8517,  0.3612,  1.2866],\n",
            "        [-1.8370, -0.0113,  1.3769],\n",
            "        [-1.6706,  1.2658,  0.2034],\n",
            "        [-1.6699,  0.1073,  1.3629],\n",
            "        [-1.4715,  1.7640, -0.2369],\n",
            "        [-1.7433,  1.4366,  0.3219],\n",
            "        [-2.0055,  1.5747,  0.4604],\n",
            "        [-1.8676,  1.9647, -0.1825],\n",
            "        [ 0.5906, -0.3750, -0.6570]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8931,  2.0495, -0.2419],\n",
            "        [-1.9637,  1.9117, -0.0381],\n",
            "        [-1.9247,  2.0737, -0.1458],\n",
            "        [-1.5088,  0.1296,  1.2519],\n",
            "        [ 0.5192, -0.2805, -0.7036],\n",
            "        [-1.6604,  1.8089, -0.5408],\n",
            "        [-1.6813,  0.2542,  1.2028],\n",
            "        [-1.7607,  1.7305, -0.2105],\n",
            "        [-1.9380,  2.0496, -0.1304],\n",
            "        [ 0.1920,  0.0380, -0.7151],\n",
            "        [ 0.5217, -0.3065, -0.6612],\n",
            "        [-2.0030,  1.7364,  0.3692],\n",
            "        [-1.6273,  0.3169,  1.2388],\n",
            "        [-1.9336,  1.9714, -0.3434],\n",
            "        [-1.6065,  0.1750,  1.2159],\n",
            "        [-2.1647,  1.4079,  0.5221]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8931,  2.0495, -0.2419],\n",
            "        [-1.9637,  1.9117, -0.0381],\n",
            "        [-1.9247,  2.0737, -0.1458],\n",
            "        [-1.5088,  0.1296,  1.2519],\n",
            "        [ 0.5192, -0.2805, -0.7036],\n",
            "        [-1.6604,  1.8089, -0.5408],\n",
            "        [-1.6813,  0.2542,  1.2028],\n",
            "        [-1.7607,  1.7305, -0.2105],\n",
            "        [-1.9380,  2.0496, -0.1304],\n",
            "        [ 0.1920,  0.0380, -0.7151],\n",
            "        [ 0.5217, -0.3065, -0.6612],\n",
            "        [-2.0030,  1.7364,  0.3692],\n",
            "        [-1.6273,  0.3169,  1.2388],\n",
            "        [-1.9336,  1.9714, -0.3434],\n",
            "        [-1.6065,  0.1750,  1.2159],\n",
            "        [-2.1647,  1.4079,  0.5221]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1525e-01,  4.4840e-01, -7.3604e-01],\n",
            "        [-1.1952e+00, -1.4731e-03,  7.8673e-01],\n",
            "        [-1.7758e+00,  8.7489e-02,  1.4558e+00],\n",
            "        [-1.7848e+00,  1.6653e+00,  1.3726e-01],\n",
            "        [-2.0209e+00,  6.5676e-01,  1.0358e+00],\n",
            "        [-1.9971e+00,  1.0282e+00,  6.8901e-01],\n",
            "        [-2.1296e+00,  1.8007e+00,  1.6147e-01],\n",
            "        [-1.8087e+00,  3.2696e-01,  1.2659e+00],\n",
            "        [-1.8852e+00,  1.9149e-01,  1.3444e+00],\n",
            "        [-1.9916e+00,  2.1724e+00, -3.9776e-02],\n",
            "        [-1.8943e+00,  1.8954e+00, -1.7236e-01],\n",
            "        [-2.0126e+00,  1.9431e+00, -3.9563e-02],\n",
            "        [-2.0094e+00,  1.5383e+00,  1.2323e-01],\n",
            "        [-1.5184e+00,  1.6918e-01,  1.2311e+00],\n",
            "        [-1.9519e+00,  4.5030e-01,  1.1876e+00],\n",
            "        [-1.9226e+00,  1.6026e+00, -1.1362e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1525e-01,  4.4840e-01, -7.3604e-01],\n",
            "        [-1.1952e+00, -1.4731e-03,  7.8673e-01],\n",
            "        [-1.7758e+00,  8.7489e-02,  1.4558e+00],\n",
            "        [-1.7848e+00,  1.6653e+00,  1.3726e-01],\n",
            "        [-2.0209e+00,  6.5676e-01,  1.0358e+00],\n",
            "        [-1.9971e+00,  1.0282e+00,  6.8901e-01],\n",
            "        [-2.1296e+00,  1.8007e+00,  1.6147e-01],\n",
            "        [-1.8087e+00,  3.2696e-01,  1.2659e+00],\n",
            "        [-1.8852e+00,  1.9149e-01,  1.3444e+00],\n",
            "        [-1.9916e+00,  2.1724e+00, -3.9776e-02],\n",
            "        [-1.8943e+00,  1.8954e+00, -1.7236e-01],\n",
            "        [-2.0126e+00,  1.9431e+00, -3.9563e-02],\n",
            "        [-2.0094e+00,  1.5383e+00,  1.2323e-01],\n",
            "        [-1.5184e+00,  1.6918e-01,  1.2311e+00],\n",
            "        [-1.9519e+00,  4.5030e-01,  1.1876e+00],\n",
            "        [-1.9226e+00,  1.6026e+00, -1.1362e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5797,  1.5619, -0.1841],\n",
            "        [ 0.4033, -0.3110, -0.6366],\n",
            "        [-2.0159,  0.7345,  1.0301],\n",
            "        [-1.6959,  0.2869,  1.2141],\n",
            "        [-2.0938,  2.0062, -0.1665],\n",
            "        [-1.7929,  0.2637,  1.3208],\n",
            "        [-1.8544,  1.9201, -0.2765],\n",
            "        [-1.8827,  0.2916,  1.2978],\n",
            "        [-1.6822,  0.1366,  1.1805],\n",
            "        [-1.7741,  0.1703,  1.1474],\n",
            "        [-1.9546,  1.9004, -0.2761],\n",
            "        [ 0.4406, -0.2960, -0.6011],\n",
            "        [-2.0298,  1.8378,  0.3122],\n",
            "        [-1.9376,  1.8065, -0.0492],\n",
            "        [-1.9413,  2.1012, -0.2113],\n",
            "        [-1.7281,  2.0292, -0.2028]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5797,  1.5619, -0.1841],\n",
            "        [ 0.4033, -0.3110, -0.6366],\n",
            "        [-2.0159,  0.7345,  1.0301],\n",
            "        [-1.6959,  0.2869,  1.2141],\n",
            "        [-2.0938,  2.0062, -0.1665],\n",
            "        [-1.7929,  0.2637,  1.3208],\n",
            "        [-1.8544,  1.9201, -0.2765],\n",
            "        [-1.8827,  0.2916,  1.2978],\n",
            "        [-1.6822,  0.1366,  1.1805],\n",
            "        [-1.7741,  0.1703,  1.1474],\n",
            "        [-1.9546,  1.9004, -0.2761],\n",
            "        [ 0.4406, -0.2960, -0.6011],\n",
            "        [-2.0298,  1.8378,  0.3122],\n",
            "        [-1.9376,  1.8065, -0.0492],\n",
            "        [-1.9413,  2.1012, -0.2113],\n",
            "        [-1.7281,  2.0292, -0.2028]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9040,  0.3191,  1.2624],\n",
            "        [-1.8317,  1.7365, -0.2838],\n",
            "        [-1.9062,  1.6405, -0.0745],\n",
            "        [-1.9965,  2.0625, -0.3428],\n",
            "        [-1.7629,  0.0165,  1.2940],\n",
            "        [-1.6235,  1.5081,  0.0501],\n",
            "        [-2.0516,  1.4360,  0.4331],\n",
            "        [-2.0246,  1.8520,  0.0543],\n",
            "        [-1.7723,  0.0607,  1.1290],\n",
            "        [-2.0805,  0.6259,  1.0571],\n",
            "        [-2.2728,  1.9049, -0.0030],\n",
            "        [-1.9261,  0.8980,  0.7692],\n",
            "        [-1.9357,  2.0784, -0.3157],\n",
            "        [-1.8302,  0.3942,  1.2044],\n",
            "        [-1.9622,  0.3462,  1.2181],\n",
            "        [-2.2025,  1.4694,  0.3780]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9040,  0.3191,  1.2624],\n",
            "        [-1.8317,  1.7365, -0.2838],\n",
            "        [-1.9062,  1.6405, -0.0745],\n",
            "        [-1.9965,  2.0625, -0.3428],\n",
            "        [-1.7629,  0.0165,  1.2940],\n",
            "        [-1.6235,  1.5081,  0.0501],\n",
            "        [-2.0516,  1.4360,  0.4331],\n",
            "        [-2.0246,  1.8520,  0.0543],\n",
            "        [-1.7723,  0.0607,  1.1290],\n",
            "        [-2.0805,  0.6259,  1.0571],\n",
            "        [-2.2728,  1.9049, -0.0030],\n",
            "        [-1.9261,  0.8980,  0.7692],\n",
            "        [-1.9357,  2.0784, -0.3157],\n",
            "        [-1.8302,  0.3942,  1.2044],\n",
            "        [-1.9622,  0.3462,  1.2181],\n",
            "        [-2.2025,  1.4694,  0.3780]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1508,  2.1157, -0.0844],\n",
            "        [-2.0445,  1.7399,  0.1653],\n",
            "        [-2.0639,  2.1908,  0.0153],\n",
            "        [ 0.6842, -0.4120, -0.7304],\n",
            "        [-2.1147,  1.7749, -0.2860],\n",
            "        [ 0.5524, -0.3747, -0.6106],\n",
            "        [-2.0058,  0.5799,  0.9978],\n",
            "        [-1.6463,  0.3354,  1.1800],\n",
            "        [-1.5613,  1.7739, -0.1684],\n",
            "        [-1.6162,  0.2460,  1.1453],\n",
            "        [-1.9810,  2.0154, -0.1399],\n",
            "        [-1.7103,  0.3298,  1.4100],\n",
            "        [-1.7642,  0.2989,  1.4783],\n",
            "        [-2.0868,  2.0116,  0.1137],\n",
            "        [-1.6753,  0.1799,  1.2345],\n",
            "        [-1.8975,  0.7500,  0.9080]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1508,  2.1157, -0.0844],\n",
            "        [-2.0445,  1.7399,  0.1653],\n",
            "        [-2.0639,  2.1908,  0.0153],\n",
            "        [ 0.6842, -0.4120, -0.7304],\n",
            "        [-2.1147,  1.7749, -0.2860],\n",
            "        [ 0.5524, -0.3747, -0.6106],\n",
            "        [-2.0058,  0.5799,  0.9978],\n",
            "        [-1.6463,  0.3354,  1.1800],\n",
            "        [-1.5613,  1.7739, -0.1684],\n",
            "        [-1.6162,  0.2460,  1.1453],\n",
            "        [-1.9810,  2.0154, -0.1399],\n",
            "        [-1.7103,  0.3298,  1.4100],\n",
            "        [-1.7642,  0.2989,  1.4783],\n",
            "        [-2.0868,  2.0116,  0.1137],\n",
            "        [-1.6753,  0.1799,  1.2345],\n",
            "        [-1.8975,  0.7500,  0.9080]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0530,  1.3896,  0.4569],\n",
            "        [ 0.4655, -0.1691, -0.8925],\n",
            "        [-2.2295,  1.7352,  0.4504],\n",
            "        [-0.2436, -0.2033,  0.1926],\n",
            "        [-2.0389,  1.9485,  0.0586],\n",
            "        [-2.2112,  2.0202, -0.1152],\n",
            "        [-1.7956,  2.0562, -0.2731],\n",
            "        [-2.0115,  1.7215,  0.3722],\n",
            "        [-2.1531,  1.9398,  0.2716],\n",
            "        [-1.8908,  1.8438, -0.2331],\n",
            "        [-1.8036,  1.7498,  0.1791],\n",
            "        [-1.4995,  1.1897,  0.2119],\n",
            "        [-1.9935,  1.9426,  0.0598],\n",
            "        [-1.9112,  1.5886,  0.2603],\n",
            "        [ 0.5265, -0.3638, -0.5571],\n",
            "        [-1.9292,  1.9759, -0.1274]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0530,  1.3896,  0.4569],\n",
            "        [ 0.4655, -0.1691, -0.8925],\n",
            "        [-2.2295,  1.7352,  0.4504],\n",
            "        [-0.2436, -0.2033,  0.1926],\n",
            "        [-2.0389,  1.9485,  0.0586],\n",
            "        [-2.2112,  2.0202, -0.1152],\n",
            "        [-1.7956,  2.0562, -0.2731],\n",
            "        [-2.0115,  1.7215,  0.3722],\n",
            "        [-2.1531,  1.9398,  0.2716],\n",
            "        [-1.8908,  1.8438, -0.2331],\n",
            "        [-1.8036,  1.7498,  0.1791],\n",
            "        [-1.4995,  1.1897,  0.2119],\n",
            "        [-1.9935,  1.9426,  0.0598],\n",
            "        [-1.9112,  1.5886,  0.2603],\n",
            "        [ 0.5265, -0.3638, -0.5571],\n",
            "        [-1.9292,  1.9759, -0.1274]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0190,  1.8902,  0.0921],\n",
            "        [-1.4648,  0.4068,  1.1492],\n",
            "        [-1.6236,  0.0995,  0.9791],\n",
            "        [-1.7912,  0.3169,  1.3152],\n",
            "        [-2.2625,  1.4440,  0.5272],\n",
            "        [-2.0620,  1.7150, -0.1161],\n",
            "        [-1.9353,  0.4469,  1.0454],\n",
            "        [-1.6377,  1.5938, -0.7938],\n",
            "        [-1.9824,  1.8237, -0.0951],\n",
            "        [-1.6412,  0.3116,  1.2957],\n",
            "        [-1.8038,  1.9834, -0.2496],\n",
            "        [-1.8081,  0.7006,  1.1352],\n",
            "        [-1.8593,  0.3553,  1.2386],\n",
            "        [-1.8453,  2.1005, -0.2585],\n",
            "        [-2.3704,  2.0814, -0.0670],\n",
            "        [-1.8468,  1.9887, -0.1745]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0190,  1.8902,  0.0921],\n",
            "        [-1.4648,  0.4068,  1.1492],\n",
            "        [-1.6236,  0.0995,  0.9791],\n",
            "        [-1.7912,  0.3169,  1.3152],\n",
            "        [-2.2625,  1.4440,  0.5272],\n",
            "        [-2.0620,  1.7150, -0.1161],\n",
            "        [-1.9353,  0.4469,  1.0454],\n",
            "        [-1.6377,  1.5938, -0.7938],\n",
            "        [-1.9824,  1.8237, -0.0951],\n",
            "        [-1.6412,  0.3116,  1.2957],\n",
            "        [-1.8038,  1.9834, -0.2496],\n",
            "        [-1.8081,  0.7006,  1.1352],\n",
            "        [-1.8593,  0.3553,  1.2386],\n",
            "        [-1.8453,  2.1005, -0.2585],\n",
            "        [-2.3704,  2.0814, -0.0670],\n",
            "        [-1.8468,  1.9887, -0.1745]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8982,  1.8575, -0.1670],\n",
            "        [-1.9041,  2.1491, -0.1489],\n",
            "        [-2.0045,  2.2060, -0.2544],\n",
            "        [-2.1197,  1.5508,  0.1969],\n",
            "        [ 0.3906, -0.3121, -0.4689],\n",
            "        [ 0.2879, -0.1317, -0.5682],\n",
            "        [-2.0377,  0.6480,  1.0348],\n",
            "        [-2.0649,  2.1799, -0.2084],\n",
            "        [-2.0142,  0.7870,  0.9118],\n",
            "        [-2.1416,  1.6956,  0.0731],\n",
            "        [-2.0702,  1.4710,  0.3179],\n",
            "        [-2.1149,  1.3431,  0.7531],\n",
            "        [ 0.4613, -0.0889, -0.6067],\n",
            "        [-2.0112,  1.9811,  0.0096],\n",
            "        [-2.1597,  2.0078, -0.0897],\n",
            "        [-1.8137,  2.0989, -0.3450]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8982,  1.8575, -0.1670],\n",
            "        [-1.9041,  2.1491, -0.1489],\n",
            "        [-2.0045,  2.2060, -0.2544],\n",
            "        [-2.1197,  1.5508,  0.1969],\n",
            "        [ 0.3906, -0.3121, -0.4689],\n",
            "        [ 0.2879, -0.1317, -0.5682],\n",
            "        [-2.0377,  0.6480,  1.0348],\n",
            "        [-2.0649,  2.1799, -0.2084],\n",
            "        [-2.0142,  0.7870,  0.9118],\n",
            "        [-2.1416,  1.6956,  0.0731],\n",
            "        [-2.0702,  1.4710,  0.3179],\n",
            "        [-2.1149,  1.3431,  0.7531],\n",
            "        [ 0.4613, -0.0889, -0.6067],\n",
            "        [-2.0112,  1.9811,  0.0096],\n",
            "        [-2.1597,  2.0078, -0.0897],\n",
            "        [-1.8137,  2.0989, -0.3450]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7441,  1.9693, -0.4576],\n",
            "        [ 0.6212, -0.3752, -0.6486],\n",
            "        [-1.8506,  2.1404, -0.2364],\n",
            "        [ 0.4420, -0.1604, -0.6945],\n",
            "        [-1.8267,  2.0880, -0.4502],\n",
            "        [-2.0077,  0.7526,  1.0061],\n",
            "        [-1.9348,  0.4480,  1.2014],\n",
            "        [-1.9930,  1.9113,  0.1144],\n",
            "        [-1.8969,  2.2834, -0.3945],\n",
            "        [-1.6737,  0.6108,  1.1524],\n",
            "        [-2.0411,  1.8948, -0.0995],\n",
            "        [-2.1341,  1.8382,  0.0025],\n",
            "        [-2.1564,  1.7983,  0.1806],\n",
            "        [-2.0366,  2.2174, -0.3440],\n",
            "        [-2.1234,  1.0999,  0.9496],\n",
            "        [-2.1260,  2.0978, -0.2445]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7441,  1.9693, -0.4576],\n",
            "        [ 0.6212, -0.3752, -0.6486],\n",
            "        [-1.8506,  2.1404, -0.2364],\n",
            "        [ 0.4420, -0.1604, -0.6945],\n",
            "        [-1.8267,  2.0880, -0.4502],\n",
            "        [-2.0077,  0.7526,  1.0061],\n",
            "        [-1.9348,  0.4480,  1.2014],\n",
            "        [-1.9930,  1.9113,  0.1144],\n",
            "        [-1.8969,  2.2834, -0.3945],\n",
            "        [-1.6737,  0.6108,  1.1524],\n",
            "        [-2.0411,  1.8948, -0.0995],\n",
            "        [-2.1341,  1.8382,  0.0025],\n",
            "        [-2.1564,  1.7983,  0.1806],\n",
            "        [-2.0366,  2.2174, -0.3440],\n",
            "        [-2.1234,  1.0999,  0.9496],\n",
            "        [-2.1260,  2.0978, -0.2445]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9551,  2.0948, -0.7409],\n",
            "        [-1.2043,  1.1230, -0.2497],\n",
            "        [-1.9584,  2.0826, -0.1850],\n",
            "        [ 0.2401, -0.3239, -0.4739],\n",
            "        [-1.7957,  1.9391, -0.3577],\n",
            "        [-1.7922,  0.8093,  0.8744],\n",
            "        [-1.9673,  0.5434,  1.2153],\n",
            "        [-1.9692,  1.8176,  0.0136],\n",
            "        [-2.0775,  2.3198, -0.4444],\n",
            "        [-1.6306,  0.3392,  0.9780],\n",
            "        [-2.1600,  1.8533,  0.2841],\n",
            "        [-2.2056,  1.1423,  0.7785],\n",
            "        [-2.0882,  2.0214, -0.3014],\n",
            "        [-2.1024,  1.1839,  0.4812],\n",
            "        [-1.7640,  0.7770,  0.9612],\n",
            "        [-1.8933,  2.0121, -0.5023]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9551,  2.0948, -0.7409],\n",
            "        [-1.2043,  1.1230, -0.2497],\n",
            "        [-1.9584,  2.0826, -0.1850],\n",
            "        [ 0.2401, -0.3239, -0.4739],\n",
            "        [-1.7957,  1.9391, -0.3577],\n",
            "        [-1.7922,  0.8093,  0.8744],\n",
            "        [-1.9673,  0.5434,  1.2153],\n",
            "        [-1.9692,  1.8176,  0.0136],\n",
            "        [-2.0775,  2.3198, -0.4444],\n",
            "        [-1.6306,  0.3392,  0.9780],\n",
            "        [-2.1600,  1.8533,  0.2841],\n",
            "        [-2.2056,  1.1423,  0.7785],\n",
            "        [-2.0882,  2.0214, -0.3014],\n",
            "        [-2.1024,  1.1839,  0.4812],\n",
            "        [-1.7640,  0.7770,  0.9612],\n",
            "        [-1.8933,  2.0121, -0.5023]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7056,  0.5542,  1.1721],\n",
            "        [ 0.2749, -0.1447, -0.7523],\n",
            "        [-1.7161,  0.5878,  0.8619],\n",
            "        [-1.8809,  2.1240, -0.2583],\n",
            "        [-1.7149,  0.6827,  0.8691],\n",
            "        [-1.9544,  2.2063, -0.2236],\n",
            "        [-1.5261,  0.3856,  0.9738],\n",
            "        [-1.6837,  0.5277,  1.0083],\n",
            "        [ 0.3398,  0.0100, -0.6318],\n",
            "        [-2.0358,  2.1599, -0.2504],\n",
            "        [-1.9881,  2.2171, -0.4003],\n",
            "        [ 0.3760, -0.4207, -0.4899],\n",
            "        [-2.0476,  2.1581, -0.1192],\n",
            "        [-1.6446,  0.2416,  1.1619],\n",
            "        [-1.9397,  2.1188, -0.4396],\n",
            "        [-2.0232,  2.0339, -0.2389]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7056,  0.5542,  1.1721],\n",
            "        [ 0.2749, -0.1447, -0.7523],\n",
            "        [-1.7161,  0.5878,  0.8619],\n",
            "        [-1.8809,  2.1240, -0.2583],\n",
            "        [-1.7149,  0.6827,  0.8691],\n",
            "        [-1.9544,  2.2063, -0.2236],\n",
            "        [-1.5261,  0.3856,  0.9738],\n",
            "        [-1.6837,  0.5277,  1.0083],\n",
            "        [ 0.3398,  0.0100, -0.6318],\n",
            "        [-2.0358,  2.1599, -0.2504],\n",
            "        [-1.9881,  2.2171, -0.4003],\n",
            "        [ 0.3760, -0.4207, -0.4899],\n",
            "        [-2.0476,  2.1581, -0.1192],\n",
            "        [-1.6446,  0.2416,  1.1619],\n",
            "        [-1.9397,  2.1188, -0.4396],\n",
            "        [-2.0232,  2.0339, -0.2389]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6216,  0.4080,  1.1239],\n",
            "        [-2.1500,  2.1079, -0.2706],\n",
            "        [-1.9219,  2.0905, -0.2795],\n",
            "        [-1.5441,  0.3479,  1.0921],\n",
            "        [-0.4379, -0.0036,  0.0757],\n",
            "        [-2.0334,  1.1711,  0.8045],\n",
            "        [-2.0601,  1.7063,  0.2438],\n",
            "        [ 0.4211, -0.3911, -0.5609],\n",
            "        [-1.9514,  0.7898,  1.1208],\n",
            "        [-2.1000,  2.3234, -0.4967],\n",
            "        [-2.1422,  2.3984, -0.2929],\n",
            "        [-2.0895,  2.0877, -0.2077],\n",
            "        [-2.1315,  2.0161,  0.0554],\n",
            "        [-0.7393,  0.0446,  0.2152],\n",
            "        [-2.1645,  2.2157, -0.2793],\n",
            "        [-2.1107,  1.4639,  0.7034]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6216,  0.4080,  1.1239],\n",
            "        [-2.1500,  2.1079, -0.2706],\n",
            "        [-1.9219,  2.0905, -0.2795],\n",
            "        [-1.5441,  0.3479,  1.0921],\n",
            "        [-0.4379, -0.0036,  0.0757],\n",
            "        [-2.0334,  1.1711,  0.8045],\n",
            "        [-2.0601,  1.7063,  0.2438],\n",
            "        [ 0.4211, -0.3911, -0.5609],\n",
            "        [-1.9514,  0.7898,  1.1208],\n",
            "        [-2.1000,  2.3234, -0.4967],\n",
            "        [-2.1422,  2.3984, -0.2929],\n",
            "        [-2.0895,  2.0877, -0.2077],\n",
            "        [-2.1315,  2.0161,  0.0554],\n",
            "        [-0.7393,  0.0446,  0.2152],\n",
            "        [-2.1645,  2.2157, -0.2793],\n",
            "        [-2.1107,  1.4639,  0.7034]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7307,  2.0880, -0.3760],\n",
            "        [ 0.3925, -0.3332, -0.3962],\n",
            "        [-1.6472,  0.4631,  0.9789],\n",
            "        [-1.6214,  0.5359,  1.0217],\n",
            "        [-1.9769,  1.8589,  0.0375],\n",
            "        [-1.7447,  2.0196, -0.3445],\n",
            "        [-1.8305,  0.4980,  1.1344],\n",
            "        [-2.4135,  1.6477,  0.3643],\n",
            "        [-2.0313,  2.1573, -0.2593],\n",
            "        [-2.0098,  2.2692, -0.3217],\n",
            "        [-2.0519,  2.2994, -0.2340],\n",
            "        [-0.5400,  0.0763,  0.1698],\n",
            "        [-1.7807,  1.9231, -0.2168],\n",
            "        [-2.0897,  0.9368,  0.4655],\n",
            "        [-2.0544,  2.2323, -0.3661],\n",
            "        [-2.0736,  2.1863,  0.0382]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7307,  2.0880, -0.3760],\n",
            "        [ 0.3925, -0.3332, -0.3962],\n",
            "        [-1.6472,  0.4631,  0.9789],\n",
            "        [-1.6214,  0.5359,  1.0217],\n",
            "        [-1.9769,  1.8589,  0.0375],\n",
            "        [-1.7447,  2.0196, -0.3445],\n",
            "        [-1.8305,  0.4980,  1.1344],\n",
            "        [-2.4135,  1.6477,  0.3643],\n",
            "        [-2.0313,  2.1573, -0.2593],\n",
            "        [-2.0098,  2.2692, -0.3217],\n",
            "        [-2.0519,  2.2994, -0.2340],\n",
            "        [-0.5400,  0.0763,  0.1698],\n",
            "        [-1.7807,  1.9231, -0.2168],\n",
            "        [-2.0897,  0.9368,  0.4655],\n",
            "        [-2.0544,  2.2323, -0.3661],\n",
            "        [-2.0736,  2.1863,  0.0382]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0293,  1.1253,  0.8817],\n",
            "        [-1.9259,  1.7974,  0.0818],\n",
            "        [-1.9832,  0.8944,  0.9076],\n",
            "        [-1.9466,  0.5699,  1.0736],\n",
            "        [-2.0926,  1.9708, -0.4159],\n",
            "        [-2.1057,  2.3305, -0.5604],\n",
            "        [-0.9996,  0.7789, -0.2754],\n",
            "        [-1.8326,  2.1770, -0.3537],\n",
            "        [-1.9304,  2.1795, -0.3767],\n",
            "        [ 0.1441,  0.2902, -0.8446],\n",
            "        [-2.1375,  2.0549, -0.0567],\n",
            "        [-2.0133,  1.4925,  0.6535],\n",
            "        [-2.0494,  0.7895,  0.8340],\n",
            "        [ 0.4068, -0.2716, -0.6346],\n",
            "        [-1.9494,  2.1848, -0.2142],\n",
            "        [-2.1015,  2.2722, -0.3073]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0293,  1.1253,  0.8817],\n",
            "        [-1.9259,  1.7974,  0.0818],\n",
            "        [-1.9832,  0.8944,  0.9076],\n",
            "        [-1.9466,  0.5699,  1.0736],\n",
            "        [-2.0926,  1.9708, -0.4159],\n",
            "        [-2.1057,  2.3305, -0.5604],\n",
            "        [-0.9996,  0.7789, -0.2754],\n",
            "        [-1.8326,  2.1770, -0.3537],\n",
            "        [-1.9304,  2.1795, -0.3767],\n",
            "        [ 0.1441,  0.2902, -0.8446],\n",
            "        [-2.1375,  2.0549, -0.0567],\n",
            "        [-2.0133,  1.4925,  0.6535],\n",
            "        [-2.0494,  0.7895,  0.8340],\n",
            "        [ 0.4068, -0.2716, -0.6346],\n",
            "        [-1.9494,  2.1848, -0.2142],\n",
            "        [-2.1015,  2.2722, -0.3073]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9280,  1.7247, -0.1962],\n",
            "        [ 0.3515, -0.1977, -0.4271],\n",
            "        [-2.2401,  2.0365,  0.0210],\n",
            "        [-1.5931,  0.3681,  1.1825],\n",
            "        [-1.9375,  1.4880,  0.1919],\n",
            "        [ 0.3523, -0.0276, -0.3998],\n",
            "        [-1.9340,  1.8704, -0.2562],\n",
            "        [-2.1674,  1.9839, -0.3429],\n",
            "        [-1.5916,  0.3897,  0.9962],\n",
            "        [-1.8240,  0.6802,  0.9629],\n",
            "        [-2.0828,  1.8866, -0.4015],\n",
            "        [-1.8163,  1.9776, -0.3466],\n",
            "        [-1.8664,  0.4674,  1.0749],\n",
            "        [-1.9734,  1.9053, -0.1702],\n",
            "        [-1.6717,  0.5178,  0.7523],\n",
            "        [-2.0656,  0.8500,  0.8370]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9280,  1.7247, -0.1962],\n",
            "        [ 0.3515, -0.1977, -0.4271],\n",
            "        [-2.2401,  2.0365,  0.0210],\n",
            "        [-1.5931,  0.3681,  1.1825],\n",
            "        [-1.9375,  1.4880,  0.1919],\n",
            "        [ 0.3523, -0.0276, -0.3998],\n",
            "        [-1.9340,  1.8704, -0.2562],\n",
            "        [-2.1674,  1.9839, -0.3429],\n",
            "        [-1.5916,  0.3897,  0.9962],\n",
            "        [-1.8240,  0.6802,  0.9629],\n",
            "        [-2.0828,  1.8866, -0.4015],\n",
            "        [-1.8163,  1.9776, -0.3466],\n",
            "        [-1.8664,  0.4674,  1.0749],\n",
            "        [-1.9734,  1.9053, -0.1702],\n",
            "        [-1.6717,  0.5178,  0.7523],\n",
            "        [-2.0656,  0.8500,  0.8370]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8979e+00,  7.0519e-01,  1.1801e+00],\n",
            "        [-1.5951e+00,  4.1678e-01,  9.8371e-01],\n",
            "        [-1.9854e+00,  1.6247e+00,  1.1751e-04],\n",
            "        [-1.7697e+00,  3.2248e-01,  1.0056e+00],\n",
            "        [-1.6489e+00,  3.4829e-01,  9.1054e-01],\n",
            "        [-1.9816e+00,  2.1756e+00, -1.0065e-01],\n",
            "        [-1.9767e+00,  1.7930e+00, -6.9692e-02],\n",
            "        [-2.1866e+00,  1.4722e+00,  4.8242e-01],\n",
            "        [-1.6298e+00,  4.4718e-01,  9.3425e-01],\n",
            "        [-1.9583e+00,  2.4018e+00, -3.7784e-01],\n",
            "        [-1.0993e+00,  1.3882e+00, -8.2803e-01],\n",
            "        [-1.7071e+00,  8.0199e-01,  6.1283e-01],\n",
            "        [-1.7957e+00,  1.9407e+00, -4.9200e-01],\n",
            "        [-1.9385e+00,  2.0732e+00, -2.4162e-01],\n",
            "        [-1.5425e+00,  5.4942e-01,  8.4694e-01],\n",
            "        [-1.8352e+00,  1.9658e+00, -1.5862e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8979e+00,  7.0519e-01,  1.1801e+00],\n",
            "        [-1.5951e+00,  4.1678e-01,  9.8371e-01],\n",
            "        [-1.9854e+00,  1.6247e+00,  1.1751e-04],\n",
            "        [-1.7697e+00,  3.2248e-01,  1.0056e+00],\n",
            "        [-1.6489e+00,  3.4829e-01,  9.1054e-01],\n",
            "        [-1.9816e+00,  2.1756e+00, -1.0065e-01],\n",
            "        [-1.9767e+00,  1.7930e+00, -6.9692e-02],\n",
            "        [-2.1866e+00,  1.4722e+00,  4.8242e-01],\n",
            "        [-1.6298e+00,  4.4718e-01,  9.3425e-01],\n",
            "        [-1.9583e+00,  2.4018e+00, -3.7784e-01],\n",
            "        [-1.0993e+00,  1.3882e+00, -8.2803e-01],\n",
            "        [-1.7071e+00,  8.0199e-01,  6.1283e-01],\n",
            "        [-1.7957e+00,  1.9407e+00, -4.9200e-01],\n",
            "        [-1.9385e+00,  2.0732e+00, -2.4162e-01],\n",
            "        [-1.5425e+00,  5.4942e-01,  8.4694e-01],\n",
            "        [-1.8352e+00,  1.9658e+00, -1.5862e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7203,  1.6547,  0.0772],\n",
            "        [-1.9963,  1.9926, -0.1208],\n",
            "        [-1.6106,  0.4219,  0.8785],\n",
            "        [-1.8870,  1.9904, -0.1449],\n",
            "        [ 0.4855, -0.2227, -0.5661],\n",
            "        [-1.5840,  0.4163,  1.0463],\n",
            "        [-1.9545,  1.9473, -0.2612],\n",
            "        [-2.0888,  2.1887, -0.4122],\n",
            "        [-1.5048,  1.7337, -0.4655],\n",
            "        [-2.0608,  1.8705, -0.1998],\n",
            "        [-2.0135,  2.0033, -0.2776],\n",
            "        [-1.6948,  1.8687, -0.2225],\n",
            "        [-1.7790,  1.8635, -0.3702],\n",
            "        [ 0.2273,  0.0565, -0.6486],\n",
            "        [-1.6292,  1.7346, -0.4019],\n",
            "        [-2.0886,  2.1368, -0.1333]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7203,  1.6547,  0.0772],\n",
            "        [-1.9963,  1.9926, -0.1208],\n",
            "        [-1.6106,  0.4219,  0.8785],\n",
            "        [-1.8870,  1.9904, -0.1449],\n",
            "        [ 0.4855, -0.2227, -0.5661],\n",
            "        [-1.5840,  0.4163,  1.0463],\n",
            "        [-1.9545,  1.9473, -0.2612],\n",
            "        [-2.0888,  2.1887, -0.4122],\n",
            "        [-1.5048,  1.7337, -0.4655],\n",
            "        [-2.0608,  1.8705, -0.1998],\n",
            "        [-2.0135,  2.0033, -0.2776],\n",
            "        [-1.6948,  1.8687, -0.2225],\n",
            "        [-1.7790,  1.8635, -0.3702],\n",
            "        [ 0.2273,  0.0565, -0.6486],\n",
            "        [-1.6292,  1.7346, -0.4019],\n",
            "        [-2.0886,  2.1368, -0.1333]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6950,  1.7902, -0.4915],\n",
            "        [-2.0714,  1.9333, -0.3824],\n",
            "        [-1.7611,  1.8555, -0.2025],\n",
            "        [-1.7201,  0.5477,  1.0353],\n",
            "        [-2.0211,  2.0530, -0.2857],\n",
            "        [-0.6003, -0.1698,  0.5554],\n",
            "        [-1.5315,  1.1946,  0.6461],\n",
            "        [-1.8430,  0.6228,  0.9161],\n",
            "        [-1.8523,  1.9239, -0.4998],\n",
            "        [-1.7433,  0.5994,  1.0570],\n",
            "        [-1.7232,  0.8939,  0.6069],\n",
            "        [-1.6826,  0.3872,  1.0917],\n",
            "        [-1.9115,  2.0010, -0.4837],\n",
            "        [-1.9768,  0.7747,  0.8966],\n",
            "        [-1.5880,  0.6290,  0.9349],\n",
            "        [-1.8098,  1.6826, -0.0082]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6950,  1.7902, -0.4915],\n",
            "        [-2.0714,  1.9333, -0.3824],\n",
            "        [-1.7611,  1.8555, -0.2025],\n",
            "        [-1.7201,  0.5477,  1.0353],\n",
            "        [-2.0211,  2.0530, -0.2857],\n",
            "        [-0.6003, -0.1698,  0.5554],\n",
            "        [-1.5315,  1.1946,  0.6461],\n",
            "        [-1.8430,  0.6228,  0.9161],\n",
            "        [-1.8523,  1.9239, -0.4998],\n",
            "        [-1.7433,  0.5994,  1.0570],\n",
            "        [-1.7232,  0.8939,  0.6069],\n",
            "        [-1.6826,  0.3872,  1.0917],\n",
            "        [-1.9115,  2.0010, -0.4837],\n",
            "        [-1.9768,  0.7747,  0.8966],\n",
            "        [-1.5880,  0.6290,  0.9349],\n",
            "        [-1.8098,  1.6826, -0.0082]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1069,  1.8984, -0.0531],\n",
            "        [-1.6321,  0.8869,  0.5563],\n",
            "        [-1.8670,  0.9525,  0.6462],\n",
            "        [-1.6342,  0.5913,  1.0895],\n",
            "        [-1.7233,  1.8863, -0.2787],\n",
            "        [ 0.3565,  0.0664, -0.6597],\n",
            "        [-1.4624,  0.4535,  0.9757],\n",
            "        [-1.5441,  0.1857,  0.8076],\n",
            "        [-1.7902,  1.8078, -0.1875],\n",
            "        [-1.4875,  0.4366,  1.0735],\n",
            "        [-1.8612,  1.9501, -0.4329],\n",
            "        [-1.7023,  0.3103,  1.0717],\n",
            "        [-0.4134,  0.7170, -0.8061],\n",
            "        [-1.7585,  0.7949,  0.6551],\n",
            "        [-1.3901,  0.2314,  0.7600],\n",
            "        [-1.6845,  1.9080, -0.2295]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1069,  1.8984, -0.0531],\n",
            "        [-1.6321,  0.8869,  0.5563],\n",
            "        [-1.8670,  0.9525,  0.6462],\n",
            "        [-1.6342,  0.5913,  1.0895],\n",
            "        [-1.7233,  1.8863, -0.2787],\n",
            "        [ 0.3565,  0.0664, -0.6597],\n",
            "        [-1.4624,  0.4535,  0.9757],\n",
            "        [-1.5441,  0.1857,  0.8076],\n",
            "        [-1.7902,  1.8078, -0.1875],\n",
            "        [-1.4875,  0.4366,  1.0735],\n",
            "        [-1.8612,  1.9501, -0.4329],\n",
            "        [-1.7023,  0.3103,  1.0717],\n",
            "        [-0.4134,  0.7170, -0.8061],\n",
            "        [-1.7585,  0.7949,  0.6551],\n",
            "        [-1.3901,  0.2314,  0.7600],\n",
            "        [-1.6845,  1.9080, -0.2295]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8556,  0.4453,  1.0464],\n",
            "        [-1.9379,  1.4019,  0.2683],\n",
            "        [-0.6171,  0.2913, -0.2343],\n",
            "        [-1.8722,  2.1962, -0.1492],\n",
            "        [-1.9814,  1.9535, -0.1092],\n",
            "        [-1.6447,  0.4356,  0.8447],\n",
            "        [-1.8059,  2.0275, -0.2996],\n",
            "        [ 0.2657, -0.3026, -0.3986],\n",
            "        [-1.5425,  0.5631,  0.9800],\n",
            "        [ 0.3042, -0.2980, -0.5396],\n",
            "        [-1.4275,  0.3969,  0.7261],\n",
            "        [-1.9389,  1.4901,  0.1423],\n",
            "        [-1.9907,  1.5478,  0.4418],\n",
            "        [ 0.2857, -0.1582, -0.7167],\n",
            "        [-1.8656,  1.9090, -0.3747],\n",
            "        [-1.8698,  1.8488, -0.2092]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8556,  0.4453,  1.0464],\n",
            "        [-1.9379,  1.4019,  0.2683],\n",
            "        [-0.6171,  0.2913, -0.2343],\n",
            "        [-1.8722,  2.1962, -0.1492],\n",
            "        [-1.9814,  1.9535, -0.1092],\n",
            "        [-1.6447,  0.4356,  0.8447],\n",
            "        [-1.8059,  2.0275, -0.2996],\n",
            "        [ 0.2657, -0.3026, -0.3986],\n",
            "        [-1.5425,  0.5631,  0.9800],\n",
            "        [ 0.3042, -0.2980, -0.5396],\n",
            "        [-1.4275,  0.3969,  0.7261],\n",
            "        [-1.9389,  1.4901,  0.1423],\n",
            "        [-1.9907,  1.5478,  0.4418],\n",
            "        [ 0.2857, -0.1582, -0.7167],\n",
            "        [-1.8656,  1.9090, -0.3747],\n",
            "        [-1.8698,  1.8488, -0.2092]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9177,  1.6329,  0.0486],\n",
            "        [-1.6253,  1.8923, -0.1788],\n",
            "        [-1.8763,  1.9184, -0.3069],\n",
            "        [-1.7523,  0.5890,  1.0086],\n",
            "        [ 0.4090, -0.2858, -0.4933],\n",
            "        [-1.5451,  0.2479,  0.9341],\n",
            "        [-1.6950,  0.8093,  0.5982],\n",
            "        [-1.7385,  1.6457, -0.3238],\n",
            "        [-1.5685,  0.2823,  0.8485],\n",
            "        [-1.7104,  1.6968, -0.3130],\n",
            "        [-1.5998,  1.8629, -0.2458],\n",
            "        [-1.6123,  0.4069,  0.8256],\n",
            "        [-1.6192,  1.8948, -0.3680],\n",
            "        [-1.9683,  1.7061,  0.1536],\n",
            "        [-1.5161,  0.4123,  1.0043],\n",
            "        [-2.0219,  2.1080, -0.2087]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9177,  1.6329,  0.0486],\n",
            "        [-1.6253,  1.8923, -0.1788],\n",
            "        [-1.8763,  1.9184, -0.3069],\n",
            "        [-1.7523,  0.5890,  1.0086],\n",
            "        [ 0.4090, -0.2858, -0.4933],\n",
            "        [-1.5451,  0.2479,  0.9341],\n",
            "        [-1.6950,  0.8093,  0.5982],\n",
            "        [-1.7385,  1.6457, -0.3238],\n",
            "        [-1.5685,  0.2823,  0.8485],\n",
            "        [-1.7104,  1.6968, -0.3130],\n",
            "        [-1.5998,  1.8629, -0.2458],\n",
            "        [-1.6123,  0.4069,  0.8256],\n",
            "        [-1.6192,  1.8948, -0.3680],\n",
            "        [-1.9683,  1.7061,  0.1536],\n",
            "        [-1.5161,  0.4123,  1.0043],\n",
            "        [-2.0219,  2.1080, -0.2087]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5305,  0.3602,  0.9203],\n",
            "        [-1.5843,  0.6238,  0.8661],\n",
            "        [-1.7916,  1.8936, -0.2844],\n",
            "        [-1.8852,  1.8820, -0.1425],\n",
            "        [-1.7219,  1.0479,  0.4552],\n",
            "        [-1.7601,  1.8933, -0.1689],\n",
            "        [-1.9711,  1.3720,  0.3383],\n",
            "        [-1.8099,  1.9046, -0.3051],\n",
            "        [-1.7800,  1.8037,  0.1282],\n",
            "        [-1.8905,  1.7399, -0.2010],\n",
            "        [-1.5868,  0.3131,  0.9888],\n",
            "        [-1.7563,  1.8196, -0.3938],\n",
            "        [-0.0752,  0.2788, -0.6751],\n",
            "        [-1.7638,  0.4484,  1.0698],\n",
            "        [-1.9571,  1.7221, -0.0701],\n",
            "        [ 0.4725, -0.3241, -0.6027]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5305,  0.3602,  0.9203],\n",
            "        [-1.5843,  0.6238,  0.8661],\n",
            "        [-1.7916,  1.8936, -0.2844],\n",
            "        [-1.8852,  1.8820, -0.1425],\n",
            "        [-1.7219,  1.0479,  0.4552],\n",
            "        [-1.7601,  1.8933, -0.1689],\n",
            "        [-1.9711,  1.3720,  0.3383],\n",
            "        [-1.8099,  1.9046, -0.3051],\n",
            "        [-1.7800,  1.8037,  0.1282],\n",
            "        [-1.8905,  1.7399, -0.2010],\n",
            "        [-1.5868,  0.3131,  0.9888],\n",
            "        [-1.7563,  1.8196, -0.3938],\n",
            "        [-0.0752,  0.2788, -0.6751],\n",
            "        [-1.7638,  0.4484,  1.0698],\n",
            "        [-1.9571,  1.7221, -0.0701],\n",
            "        [ 0.4725, -0.3241, -0.6027]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7146,  0.5669,  0.8921],\n",
            "        [-1.6759,  1.8033, -0.1811],\n",
            "        [-1.6993,  0.8914,  0.7003],\n",
            "        [-1.4241,  0.4443,  1.1050],\n",
            "        [ 0.1523,  0.0771, -0.6875],\n",
            "        [-1.7039,  0.4674,  0.9456],\n",
            "        [-1.6655,  1.8078,  0.0571],\n",
            "        [-1.6749,  1.8432, -0.0218],\n",
            "        [-1.2712,  1.5361, -0.6020],\n",
            "        [-1.7523,  0.4655,  0.6506],\n",
            "        [-1.7449,  1.9379, -0.5365],\n",
            "        [-1.7149,  0.9410,  0.7139],\n",
            "        [-2.0074,  1.7855, -0.1615],\n",
            "        [-1.2209,  0.1343,  1.0590],\n",
            "        [-1.8603,  1.6360, -0.1039],\n",
            "        [-2.0778,  1.6908,  0.0135]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7146,  0.5669,  0.8921],\n",
            "        [-1.6759,  1.8033, -0.1811],\n",
            "        [-1.6993,  0.8914,  0.7003],\n",
            "        [-1.4241,  0.4443,  1.1050],\n",
            "        [ 0.1523,  0.0771, -0.6875],\n",
            "        [-1.7039,  0.4674,  0.9456],\n",
            "        [-1.6655,  1.8078,  0.0571],\n",
            "        [-1.6749,  1.8432, -0.0218],\n",
            "        [-1.2712,  1.5361, -0.6020],\n",
            "        [-1.7523,  0.4655,  0.6506],\n",
            "        [-1.7449,  1.9379, -0.5365],\n",
            "        [-1.7149,  0.9410,  0.7139],\n",
            "        [-2.0074,  1.7855, -0.1615],\n",
            "        [-1.2209,  0.1343,  1.0590],\n",
            "        [-1.8603,  1.6360, -0.1039],\n",
            "        [-2.0778,  1.6908,  0.0135]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7883,  1.9507, -0.1453],\n",
            "        [-1.5661,  0.2366,  1.0108],\n",
            "        [-1.6623,  1.4040,  0.2851],\n",
            "        [-1.7531,  1.8065, -0.1699],\n",
            "        [-1.7353,  0.7217,  0.8540],\n",
            "        [-1.4980,  0.2498,  1.1284],\n",
            "        [-1.4304,  0.2168,  1.0398],\n",
            "        [-1.7959,  1.5534, -0.1154],\n",
            "        [-0.4270,  0.2891, -0.2713],\n",
            "        [-1.5765,  0.9987,  0.2496],\n",
            "        [-2.0578,  0.9293,  0.8836],\n",
            "        [-1.7083,  1.5179, -0.1594],\n",
            "        [-1.6774,  0.7989,  0.6841],\n",
            "        [-1.7256,  1.4939, -0.2231],\n",
            "        [ 0.3882, -0.2854, -0.5156],\n",
            "        [-1.4859,  1.7050, -0.2460]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7883,  1.9507, -0.1453],\n",
            "        [-1.5661,  0.2366,  1.0108],\n",
            "        [-1.6623,  1.4040,  0.2851],\n",
            "        [-1.7531,  1.8065, -0.1699],\n",
            "        [-1.7353,  0.7217,  0.8540],\n",
            "        [-1.4980,  0.2498,  1.1284],\n",
            "        [-1.4304,  0.2168,  1.0398],\n",
            "        [-1.7959,  1.5534, -0.1154],\n",
            "        [-0.4270,  0.2891, -0.2713],\n",
            "        [-1.5765,  0.9987,  0.2496],\n",
            "        [-2.0578,  0.9293,  0.8836],\n",
            "        [-1.7083,  1.5179, -0.1594],\n",
            "        [-1.6774,  0.7989,  0.6841],\n",
            "        [-1.7256,  1.4939, -0.2231],\n",
            "        [ 0.3882, -0.2854, -0.5156],\n",
            "        [-1.4859,  1.7050, -0.2460]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5122,  0.4061,  0.9924],\n",
            "        [ 0.3285, -0.1500, -0.4319],\n",
            "        [-1.5488,  0.0301,  0.7999],\n",
            "        [-1.9377,  1.7279, -0.1499],\n",
            "        [-1.5981,  1.9370, -0.2123],\n",
            "        [-1.5785,  1.5026, -0.2472],\n",
            "        [-1.2899,  0.2413,  0.8271],\n",
            "        [-1.8283,  1.6210, -0.0966],\n",
            "        [ 0.4227, -0.2600, -0.5006],\n",
            "        [ 0.3118, -0.2649, -0.3832],\n",
            "        [-1.5880,  1.6987, -0.1838],\n",
            "        [-1.8540,  1.7086, -0.0374],\n",
            "        [-1.6751,  1.0912,  0.3555],\n",
            "        [-1.8694,  2.0058, -0.5167],\n",
            "        [-1.8480,  1.8329, -0.2310],\n",
            "        [-1.7954,  1.4219,  0.3230]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5122,  0.4061,  0.9924],\n",
            "        [ 0.3285, -0.1500, -0.4319],\n",
            "        [-1.5488,  0.0301,  0.7999],\n",
            "        [-1.9377,  1.7279, -0.1499],\n",
            "        [-1.5981,  1.9370, -0.2123],\n",
            "        [-1.5785,  1.5026, -0.2472],\n",
            "        [-1.2899,  0.2413,  0.8271],\n",
            "        [-1.8283,  1.6210, -0.0966],\n",
            "        [ 0.4227, -0.2600, -0.5006],\n",
            "        [ 0.3118, -0.2649, -0.3832],\n",
            "        [-1.5880,  1.6987, -0.1838],\n",
            "        [-1.8540,  1.7086, -0.0374],\n",
            "        [-1.6751,  1.0912,  0.3555],\n",
            "        [-1.8694,  2.0058, -0.5167],\n",
            "        [-1.8480,  1.8329, -0.2310],\n",
            "        [-1.7954,  1.4219,  0.3230]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3406,  0.3552,  0.8883],\n",
            "        [-1.8439,  1.8643,  0.1725],\n",
            "        [-1.6762,  2.0335, -0.3329],\n",
            "        [-1.6481,  1.3355,  0.1047],\n",
            "        [-1.8099,  1.7386,  0.3518],\n",
            "        [-1.8987,  1.7393, -0.0394],\n",
            "        [-1.2578,  0.2810,  0.8320],\n",
            "        [-1.8127,  0.3523,  0.9573],\n",
            "        [-1.2058,  0.2094,  0.8611],\n",
            "        [-1.8199,  1.9482, -0.1484],\n",
            "        [-2.0910,  2.0032, -0.2544],\n",
            "        [ 0.3925, -0.2153, -0.4004],\n",
            "        [-1.8586,  1.9913, -0.2836],\n",
            "        [-1.8401,  1.6895, -0.2414],\n",
            "        [-1.8640,  1.6211, -0.2205],\n",
            "        [-2.0210,  1.0850,  0.5589]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3406,  0.3552,  0.8883],\n",
            "        [-1.8439,  1.8643,  0.1725],\n",
            "        [-1.6762,  2.0335, -0.3329],\n",
            "        [-1.6481,  1.3355,  0.1047],\n",
            "        [-1.8099,  1.7386,  0.3518],\n",
            "        [-1.8987,  1.7393, -0.0394],\n",
            "        [-1.2578,  0.2810,  0.8320],\n",
            "        [-1.8127,  0.3523,  0.9573],\n",
            "        [-1.2058,  0.2094,  0.8611],\n",
            "        [-1.8199,  1.9482, -0.1484],\n",
            "        [-2.0910,  2.0032, -0.2544],\n",
            "        [ 0.3925, -0.2153, -0.4004],\n",
            "        [-1.8586,  1.9913, -0.2836],\n",
            "        [-1.8401,  1.6895, -0.2414],\n",
            "        [-1.8640,  1.6211, -0.2205],\n",
            "        [-2.0210,  1.0850,  0.5589]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8602,  1.6958, -0.0824],\n",
            "        [-0.1176, -0.1872, -0.0540],\n",
            "        [-1.9265,  0.9071,  0.6519],\n",
            "        [-1.7593,  1.2191,  0.4981],\n",
            "        [ 0.2645,  0.0052, -0.4882],\n",
            "        [-1.2899,  0.9552, -0.0577],\n",
            "        [-1.0748, -0.0333,  0.9111],\n",
            "        [-1.2554,  0.3346,  0.8487],\n",
            "        [-1.7243,  0.9659,  0.4878],\n",
            "        [-1.9831,  1.2057,  0.5060],\n",
            "        [-1.3317,  0.1754,  0.9574],\n",
            "        [ 0.2015, -0.2953, -0.4152],\n",
            "        [-1.8246,  1.9027, -0.1317],\n",
            "        [-1.7939,  1.7237, -0.1448],\n",
            "        [-1.9110,  1.8197, -0.0361],\n",
            "        [-1.9373,  1.5119,  0.1924]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8602,  1.6958, -0.0824],\n",
            "        [-0.1176, -0.1872, -0.0540],\n",
            "        [-1.9265,  0.9071,  0.6519],\n",
            "        [-1.7593,  1.2191,  0.4981],\n",
            "        [ 0.2645,  0.0052, -0.4882],\n",
            "        [-1.2899,  0.9552, -0.0577],\n",
            "        [-1.0748, -0.0333,  0.9111],\n",
            "        [-1.2554,  0.3346,  0.8487],\n",
            "        [-1.7243,  0.9659,  0.4878],\n",
            "        [-1.9831,  1.2057,  0.5060],\n",
            "        [-1.3317,  0.1754,  0.9574],\n",
            "        [ 0.2015, -0.2953, -0.4152],\n",
            "        [-1.8246,  1.9027, -0.1317],\n",
            "        [-1.7939,  1.7237, -0.1448],\n",
            "        [-1.9110,  1.8197, -0.0361],\n",
            "        [-1.9373,  1.5119,  0.1924]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5704,  0.3371,  0.9759],\n",
            "        [-1.1658,  1.0345, -0.3749],\n",
            "        [-1.6962,  1.7708, -0.2534],\n",
            "        [ 0.2535, -0.0678, -0.5904],\n",
            "        [-1.8942,  1.6128, -0.2138],\n",
            "        [-1.8027,  1.1920,  0.2030],\n",
            "        [-1.6471,  1.8788, -0.2164],\n",
            "        [ 0.2666, -0.1797, -0.6001],\n",
            "        [-0.8457,  0.8956, -0.5896],\n",
            "        [-0.1046,  0.1874, -0.6853],\n",
            "        [-1.7413,  1.3446,  0.5145],\n",
            "        [-1.9530,  1.7420, -0.1466],\n",
            "        [-1.4332,  0.2467,  1.2042],\n",
            "        [-1.1542,  0.8837, -0.1883],\n",
            "        [-1.6803,  1.7925, -0.0861],\n",
            "        [-1.5964,  1.5972, -0.0020]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5704,  0.3371,  0.9759],\n",
            "        [-1.1658,  1.0345, -0.3749],\n",
            "        [-1.6962,  1.7708, -0.2534],\n",
            "        [ 0.2535, -0.0678, -0.5904],\n",
            "        [-1.8942,  1.6128, -0.2138],\n",
            "        [-1.8027,  1.1920,  0.2030],\n",
            "        [-1.6471,  1.8788, -0.2164],\n",
            "        [ 0.2666, -0.1797, -0.6001],\n",
            "        [-0.8457,  0.8956, -0.5896],\n",
            "        [-0.1046,  0.1874, -0.6853],\n",
            "        [-1.7413,  1.3446,  0.5145],\n",
            "        [-1.9530,  1.7420, -0.1466],\n",
            "        [-1.4332,  0.2467,  1.2042],\n",
            "        [-1.1542,  0.8837, -0.1883],\n",
            "        [-1.6803,  1.7925, -0.0861],\n",
            "        [-1.5964,  1.5972, -0.0020]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6422,  0.9528,  0.5068],\n",
            "        [-1.4279,  0.2979,  0.9838],\n",
            "        [-1.3741,  0.4202,  1.0064],\n",
            "        [-1.5946,  1.6881, -0.1748],\n",
            "        [-1.3145,  0.1893,  1.0846],\n",
            "        [-1.3127,  0.0491,  0.9406],\n",
            "        [ 0.4041, -0.1813, -0.4825],\n",
            "        [-1.4796,  0.1934,  0.8865],\n",
            "        [-1.6990,  1.7079, -0.2266],\n",
            "        [ 0.1657, -0.0286, -0.6825],\n",
            "        [-1.6344,  0.2350,  0.8837],\n",
            "        [ 0.0700, -0.2761, -0.1786],\n",
            "        [-1.7842,  1.8159, -0.0613],\n",
            "        [-1.2957,  0.2378,  0.9400],\n",
            "        [-1.6808,  1.3390, -0.1858],\n",
            "        [ 0.3413, -0.1444, -0.4671]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6422,  0.9528,  0.5068],\n",
            "        [-1.4279,  0.2979,  0.9838],\n",
            "        [-1.3741,  0.4202,  1.0064],\n",
            "        [-1.5946,  1.6881, -0.1748],\n",
            "        [-1.3145,  0.1893,  1.0846],\n",
            "        [-1.3127,  0.0491,  0.9406],\n",
            "        [ 0.4041, -0.1813, -0.4825],\n",
            "        [-1.4796,  0.1934,  0.8865],\n",
            "        [-1.6990,  1.7079, -0.2266],\n",
            "        [ 0.1657, -0.0286, -0.6825],\n",
            "        [-1.6344,  0.2350,  0.8837],\n",
            "        [ 0.0700, -0.2761, -0.1786],\n",
            "        [-1.7842,  1.8159, -0.0613],\n",
            "        [-1.2957,  0.2378,  0.9400],\n",
            "        [-1.6808,  1.3390, -0.1858],\n",
            "        [ 0.3413, -0.1444, -0.4671]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4650,  0.1915,  0.9670],\n",
            "        [-1.6190,  1.5602, -0.4194],\n",
            "        [-1.5998,  1.5092, -0.0611],\n",
            "        [-1.7205,  1.4263,  0.1331],\n",
            "        [-1.4074,  1.6731, -0.3743],\n",
            "        [-1.4364,  1.3040,  0.0981],\n",
            "        [-1.7499,  1.8220, -0.1179],\n",
            "        [-1.2190,  0.1089,  0.7377],\n",
            "        [-1.3949,  0.0310,  0.9003],\n",
            "        [-1.2310,  0.2821,  0.7725],\n",
            "        [-1.1682,  1.1663, -0.3912],\n",
            "        [-1.4888,  0.0351,  1.0403],\n",
            "        [-1.3696,  0.1324,  1.0545],\n",
            "        [-1.5484,  1.6259, -0.1946],\n",
            "        [-1.6394,  0.6776,  0.6578],\n",
            "        [-1.2185,  1.4851, -0.5432]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4650,  0.1915,  0.9670],\n",
            "        [-1.6190,  1.5602, -0.4194],\n",
            "        [-1.5998,  1.5092, -0.0611],\n",
            "        [-1.7205,  1.4263,  0.1331],\n",
            "        [-1.4074,  1.6731, -0.3743],\n",
            "        [-1.4364,  1.3040,  0.0981],\n",
            "        [-1.7499,  1.8220, -0.1179],\n",
            "        [-1.2190,  0.1089,  0.7377],\n",
            "        [-1.3949,  0.0310,  0.9003],\n",
            "        [-1.2310,  0.2821,  0.7725],\n",
            "        [-1.1682,  1.1663, -0.3912],\n",
            "        [-1.4888,  0.0351,  1.0403],\n",
            "        [-1.3696,  0.1324,  1.0545],\n",
            "        [-1.5484,  1.6259, -0.1946],\n",
            "        [-1.6394,  0.6776,  0.6578],\n",
            "        [-1.2185,  1.4851, -0.5432]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4609,  0.3165,  0.9512],\n",
            "        [-1.4667,  1.5669, -0.0661],\n",
            "        [-1.5282,  1.5204, -0.1168],\n",
            "        [-1.6329,  1.7366,  0.0441],\n",
            "        [-1.4492,  1.5498, -0.2158],\n",
            "        [-1.6344,  1.6173, -0.0418],\n",
            "        [-1.5517,  1.0077,  0.3104],\n",
            "        [-1.7214,  1.1908,  0.2173],\n",
            "        [-1.7332,  1.4952,  0.2109],\n",
            "        [-1.6687,  0.4860,  0.9115],\n",
            "        [-1.6651,  1.3918,  0.0977],\n",
            "        [-1.6041,  1.6837, -0.2398],\n",
            "        [-1.7107,  1.5760, -0.0319],\n",
            "        [-1.3768,  0.1288,  1.0335],\n",
            "        [-1.7892,  1.4599, -0.0571],\n",
            "        [-1.7726,  1.7226, -0.1102]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4609,  0.3165,  0.9512],\n",
            "        [-1.4667,  1.5669, -0.0661],\n",
            "        [-1.5282,  1.5204, -0.1168],\n",
            "        [-1.6329,  1.7366,  0.0441],\n",
            "        [-1.4492,  1.5498, -0.2158],\n",
            "        [-1.6344,  1.6173, -0.0418],\n",
            "        [-1.5517,  1.0077,  0.3104],\n",
            "        [-1.7214,  1.1908,  0.2173],\n",
            "        [-1.7332,  1.4952,  0.2109],\n",
            "        [-1.6687,  0.4860,  0.9115],\n",
            "        [-1.6651,  1.3918,  0.0977],\n",
            "        [-1.6041,  1.6837, -0.2398],\n",
            "        [-1.7107,  1.5760, -0.0319],\n",
            "        [-1.3768,  0.1288,  1.0335],\n",
            "        [-1.7892,  1.4599, -0.0571],\n",
            "        [-1.7726,  1.7226, -0.1102]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7864,  1.6557,  0.0863],\n",
            "        [-1.7568,  0.7768,  0.7463],\n",
            "        [-1.7182,  0.9680,  0.4907],\n",
            "        [-0.7460, -0.0480,  0.5871],\n",
            "        [-1.3828,  0.2526,  0.8746],\n",
            "        [-1.5107,  1.4938, -0.3720],\n",
            "        [-1.7927,  0.9726,  0.6224],\n",
            "        [-1.7329,  1.3943, -0.0537],\n",
            "        [-1.6818,  1.1677,  0.4432],\n",
            "        [-1.8928,  1.7844, -0.1542],\n",
            "        [-1.5485,  1.2671,  0.0899],\n",
            "        [-1.5301,  1.3553, -0.0228],\n",
            "        [-1.3190,  0.2199,  0.9575],\n",
            "        [-1.3867,  0.0326,  0.9607],\n",
            "        [-1.5576,  1.1752, -0.2347],\n",
            "        [-1.9026,  1.5299, -0.1863]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7864,  1.6557,  0.0863],\n",
            "        [-1.7568,  0.7768,  0.7463],\n",
            "        [-1.7182,  0.9680,  0.4907],\n",
            "        [-0.7460, -0.0480,  0.5871],\n",
            "        [-1.3828,  0.2526,  0.8746],\n",
            "        [-1.5107,  1.4938, -0.3720],\n",
            "        [-1.7927,  0.9726,  0.6224],\n",
            "        [-1.7329,  1.3943, -0.0537],\n",
            "        [-1.6818,  1.1677,  0.4432],\n",
            "        [-1.8928,  1.7844, -0.1542],\n",
            "        [-1.5485,  1.2671,  0.0899],\n",
            "        [-1.5301,  1.3553, -0.0228],\n",
            "        [-1.3190,  0.2199,  0.9575],\n",
            "        [-1.3867,  0.0326,  0.9607],\n",
            "        [-1.5576,  1.1752, -0.2347],\n",
            "        [-1.9026,  1.5299, -0.1863]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4975,  0.1686,  0.9857],\n",
            "        [ 0.1310,  0.0320, -0.6754],\n",
            "        [-0.6506,  1.0332, -0.6708],\n",
            "        [-1.5171,  0.3241,  0.9961],\n",
            "        [-0.5193,  0.4641, -0.5470],\n",
            "        [-1.7587,  1.2763,  0.5701],\n",
            "        [-1.4980,  1.0621,  0.3984],\n",
            "        [-1.4677,  1.5097, -0.0758],\n",
            "        [-1.5482,  1.5155, -0.2330],\n",
            "        [-1.4586,  1.2848, -0.1900],\n",
            "        [-1.5755,  0.3846,  1.1401],\n",
            "        [-1.7287,  1.7924, -0.2507],\n",
            "        [-1.7082,  1.6859, -0.4087],\n",
            "        [-1.2324,  0.0582,  0.8575],\n",
            "        [-1.4702,  1.6997, -0.1872],\n",
            "        [ 0.3093, -0.0373, -0.6132]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4975,  0.1686,  0.9857],\n",
            "        [ 0.1310,  0.0320, -0.6754],\n",
            "        [-0.6506,  1.0332, -0.6708],\n",
            "        [-1.5171,  0.3241,  0.9961],\n",
            "        [-0.5193,  0.4641, -0.5470],\n",
            "        [-1.7587,  1.2763,  0.5701],\n",
            "        [-1.4980,  1.0621,  0.3984],\n",
            "        [-1.4677,  1.5097, -0.0758],\n",
            "        [-1.5482,  1.5155, -0.2330],\n",
            "        [-1.4586,  1.2848, -0.1900],\n",
            "        [-1.5755,  0.3846,  1.1401],\n",
            "        [-1.7287,  1.7924, -0.2507],\n",
            "        [-1.7082,  1.6859, -0.4087],\n",
            "        [-1.2324,  0.0582,  0.8575],\n",
            "        [-1.4702,  1.6997, -0.1872],\n",
            "        [ 0.3093, -0.0373, -0.6132]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6543,  1.4891, -0.0428],\n",
            "        [-1.4159,  1.5801, -0.3646],\n",
            "        [-1.7949,  1.1391,  0.4081],\n",
            "        [ 0.1906, -0.2524, -0.5046],\n",
            "        [-1.5091,  1.5863, -0.3592],\n",
            "        [-1.3681,  1.4828, -0.2573],\n",
            "        [-1.4921,  0.1741,  1.0944],\n",
            "        [-1.6923,  1.5777, -0.2087],\n",
            "        [-1.7114,  1.6439,  0.0164],\n",
            "        [-1.9285,  1.0184,  0.4399],\n",
            "        [-1.7130,  1.7467, -0.2373],\n",
            "        [-1.7148,  1.2243,  0.0452],\n",
            "        [-1.7316,  0.7566,  0.4301],\n",
            "        [-0.1116,  0.4428, -0.9655],\n",
            "        [-1.8263,  1.4342,  0.4208],\n",
            "        [-1.5416,  1.5907, -0.3416]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6543,  1.4891, -0.0428],\n",
            "        [-1.4159,  1.5801, -0.3646],\n",
            "        [-1.7949,  1.1391,  0.4081],\n",
            "        [ 0.1906, -0.2524, -0.5046],\n",
            "        [-1.5091,  1.5863, -0.3592],\n",
            "        [-1.3681,  1.4828, -0.2573],\n",
            "        [-1.4921,  0.1741,  1.0944],\n",
            "        [-1.6923,  1.5777, -0.2087],\n",
            "        [-1.7114,  1.6439,  0.0164],\n",
            "        [-1.9285,  1.0184,  0.4399],\n",
            "        [-1.7130,  1.7467, -0.2373],\n",
            "        [-1.7148,  1.2243,  0.0452],\n",
            "        [-1.7316,  0.7566,  0.4301],\n",
            "        [-0.1116,  0.4428, -0.9655],\n",
            "        [-1.8263,  1.4342,  0.4208],\n",
            "        [-1.5416,  1.5907, -0.3416]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6002,  1.6663, -0.3978],\n",
            "        [-1.8235,  1.4550,  0.2530],\n",
            "        [-1.2568,  1.5976, -0.6218],\n",
            "        [-1.3140,  0.0774,  1.0708],\n",
            "        [-0.3598, -0.1279,  0.2134],\n",
            "        [-1.7428,  0.7871,  0.9112],\n",
            "        [ 0.2631, -0.1912, -0.6935],\n",
            "        [-1.4893,  1.6905, -0.4444],\n",
            "        [-1.5367,  0.2719,  1.0114],\n",
            "        [-1.4823,  1.4998,  0.0071],\n",
            "        [-1.6921,  1.4909, -0.0954],\n",
            "        [-1.4211,  0.7149,  0.1728],\n",
            "        [-1.4312,  0.2046,  0.9603],\n",
            "        [-1.5502,  1.5807, -0.3131],\n",
            "        [-0.6693,  0.8298, -0.5521],\n",
            "        [-1.4561,  1.6516, -0.3538]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6002,  1.6663, -0.3978],\n",
            "        [-1.8235,  1.4550,  0.2530],\n",
            "        [-1.2568,  1.5976, -0.6218],\n",
            "        [-1.3140,  0.0774,  1.0708],\n",
            "        [-0.3598, -0.1279,  0.2134],\n",
            "        [-1.7428,  0.7871,  0.9112],\n",
            "        [ 0.2631, -0.1912, -0.6935],\n",
            "        [-1.4893,  1.6905, -0.4444],\n",
            "        [-1.5367,  0.2719,  1.0114],\n",
            "        [-1.4823,  1.4998,  0.0071],\n",
            "        [-1.6921,  1.4909, -0.0954],\n",
            "        [-1.4211,  0.7149,  0.1728],\n",
            "        [-1.4312,  0.2046,  0.9603],\n",
            "        [-1.5502,  1.5807, -0.3131],\n",
            "        [-0.6693,  0.8298, -0.5521],\n",
            "        [-1.4561,  1.6516, -0.3538]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5039,  1.5629, -0.1926],\n",
            "        [-1.5414,  1.6076, -0.2633],\n",
            "        [-1.6356,  1.4153, -0.2694],\n",
            "        [-1.3122,  0.1675,  0.9520],\n",
            "        [-1.8534,  1.6977, -0.2535],\n",
            "        [-1.5263,  1.6144,  0.0651],\n",
            "        [-1.4377,  1.7075, -0.1753],\n",
            "        [-1.3969,  1.5025, -0.3025],\n",
            "        [-1.6467,  0.3251,  1.0636],\n",
            "        [-0.8025,  1.1116, -0.6895],\n",
            "        [-1.3971,  0.3503,  0.7876],\n",
            "        [-1.5268,  1.4551, -0.4449],\n",
            "        [-1.5432,  0.4482,  0.8256],\n",
            "        [-1.5210,  1.6508, -0.1950],\n",
            "        [-1.7139,  1.4789, -0.0821],\n",
            "        [-0.0352,  0.2524, -0.8105]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5039,  1.5629, -0.1926],\n",
            "        [-1.5414,  1.6076, -0.2633],\n",
            "        [-1.6356,  1.4153, -0.2694],\n",
            "        [-1.3122,  0.1675,  0.9520],\n",
            "        [-1.8534,  1.6977, -0.2535],\n",
            "        [-1.5263,  1.6144,  0.0651],\n",
            "        [-1.4377,  1.7075, -0.1753],\n",
            "        [-1.3969,  1.5025, -0.3025],\n",
            "        [-1.6467,  0.3251,  1.0636],\n",
            "        [-0.8025,  1.1116, -0.6895],\n",
            "        [-1.3971,  0.3503,  0.7876],\n",
            "        [-1.5268,  1.4551, -0.4449],\n",
            "        [-1.5432,  0.4482,  0.8256],\n",
            "        [-1.5210,  1.6508, -0.1950],\n",
            "        [-1.7139,  1.4789, -0.0821],\n",
            "        [-0.0352,  0.2524, -0.8105]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5414,  1.5050, -0.3351],\n",
            "        [-1.6120,  1.5549, -0.3075],\n",
            "        [-1.5454,  1.4726, -0.2790],\n",
            "        [-1.7279,  1.7502, -0.2338],\n",
            "        [-1.2884,  0.2232,  0.7760],\n",
            "        [ 0.0899,  0.4070, -0.8992],\n",
            "        [-1.5728,  1.4206, -0.1493],\n",
            "        [ 0.2129, -0.1970, -0.4246],\n",
            "        [-1.5334,  1.6625, -0.3509],\n",
            "        [-1.5924,  0.3264,  0.9303],\n",
            "        [-1.7247,  1.2535,  0.2935],\n",
            "        [-1.4849,  1.5764, -0.1283],\n",
            "        [ 0.3366, -0.1747, -0.7518],\n",
            "        [-1.7312,  1.4895, -0.2393],\n",
            "        [-1.7657,  1.1369,  0.3551],\n",
            "        [-1.7401,  1.7110, -0.2861]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5414,  1.5050, -0.3351],\n",
            "        [-1.6120,  1.5549, -0.3075],\n",
            "        [-1.5454,  1.4726, -0.2790],\n",
            "        [-1.7279,  1.7502, -0.2338],\n",
            "        [-1.2884,  0.2232,  0.7760],\n",
            "        [ 0.0899,  0.4070, -0.8992],\n",
            "        [-1.5728,  1.4206, -0.1493],\n",
            "        [ 0.2129, -0.1970, -0.4246],\n",
            "        [-1.5334,  1.6625, -0.3509],\n",
            "        [-1.5924,  0.3264,  0.9303],\n",
            "        [-1.7247,  1.2535,  0.2935],\n",
            "        [-1.4849,  1.5764, -0.1283],\n",
            "        [ 0.3366, -0.1747, -0.7518],\n",
            "        [-1.7312,  1.4895, -0.2393],\n",
            "        [-1.7657,  1.1369,  0.3551],\n",
            "        [-1.7401,  1.7110, -0.2861]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4536,  1.6587, -0.2285],\n",
            "        [-1.5313,  1.4217, -0.4563],\n",
            "        [-1.5336,  1.7283, -0.3728],\n",
            "        [-1.4815,  1.7449, -0.3263],\n",
            "        [-1.5327,  0.7301,  0.7764],\n",
            "        [-1.7208,  1.5624, -0.2408],\n",
            "        [-1.7051,  0.4442,  0.8621],\n",
            "        [-1.2710,  0.1173,  1.0319],\n",
            "        [-1.3305,  1.5176, -0.4067],\n",
            "        [-1.4279,  0.2603,  0.9414],\n",
            "        [-1.7885,  1.8305, -0.2329],\n",
            "        [-1.3992,  1.4214, -0.2593],\n",
            "        [-1.4925,  0.1146,  1.0997],\n",
            "        [-1.5077,  0.0535,  1.0683],\n",
            "        [ 0.2663, -0.1274, -0.6499],\n",
            "        [-1.7952,  1.5778, -0.3339]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4536,  1.6587, -0.2285],\n",
            "        [-1.5313,  1.4217, -0.4563],\n",
            "        [-1.5336,  1.7283, -0.3728],\n",
            "        [-1.4815,  1.7449, -0.3263],\n",
            "        [-1.5327,  0.7301,  0.7764],\n",
            "        [-1.7208,  1.5624, -0.2408],\n",
            "        [-1.7051,  0.4442,  0.8621],\n",
            "        [-1.2710,  0.1173,  1.0319],\n",
            "        [-1.3305,  1.5176, -0.4067],\n",
            "        [-1.4279,  0.2603,  0.9414],\n",
            "        [-1.7885,  1.8305, -0.2329],\n",
            "        [-1.3992,  1.4214, -0.2593],\n",
            "        [-1.4925,  0.1146,  1.0997],\n",
            "        [-1.5077,  0.0535,  1.0683],\n",
            "        [ 0.2663, -0.1274, -0.6499],\n",
            "        [-1.7952,  1.5778, -0.3339]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8154,  1.6703,  0.0820],\n",
            "        [-1.6066,  1.7289, -0.4824],\n",
            "        [-1.4976,  1.6302, -0.3315],\n",
            "        [-1.5199,  1.7651, -0.5435],\n",
            "        [-1.3630,  1.5187, -0.5266],\n",
            "        [-1.6910,  1.8499, -0.3425],\n",
            "        [-1.6532,  1.1154,  0.0644],\n",
            "        [-1.7904,  1.0063,  0.6535],\n",
            "        [-1.5859,  0.9191,  0.4464],\n",
            "        [-1.5481,  0.1242,  0.9783],\n",
            "        [-0.2344,  0.5874, -0.9642],\n",
            "        [ 0.0529,  0.4737, -0.8250],\n",
            "        [-1.6430,  1.6572, -0.2237],\n",
            "        [-1.6335,  0.6375,  0.8389],\n",
            "        [-1.5544,  1.6371, -0.3808],\n",
            "        [-1.5982,  0.3635,  1.0461]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8154,  1.6703,  0.0820],\n",
            "        [-1.6066,  1.7289, -0.4824],\n",
            "        [-1.4976,  1.6302, -0.3315],\n",
            "        [-1.5199,  1.7651, -0.5435],\n",
            "        [-1.3630,  1.5187, -0.5266],\n",
            "        [-1.6910,  1.8499, -0.3425],\n",
            "        [-1.6532,  1.1154,  0.0644],\n",
            "        [-1.7904,  1.0063,  0.6535],\n",
            "        [-1.5859,  0.9191,  0.4464],\n",
            "        [-1.5481,  0.1242,  0.9783],\n",
            "        [-0.2344,  0.5874, -0.9642],\n",
            "        [ 0.0529,  0.4737, -0.8250],\n",
            "        [-1.6430,  1.6572, -0.2237],\n",
            "        [-1.6335,  0.6375,  0.8389],\n",
            "        [-1.5544,  1.6371, -0.3808],\n",
            "        [-1.5982,  0.3635,  1.0461]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5453, -0.1110, -0.6912],\n",
            "        [-1.5632,  1.5973, -0.2784],\n",
            "        [-1.4183,  0.1077,  0.9425],\n",
            "        [-1.9185,  1.4670,  0.0945],\n",
            "        [ 0.4428, -0.1250, -0.8002],\n",
            "        [-1.5137,  1.7585, -0.4959],\n",
            "        [-1.5331,  1.6442, -0.1584],\n",
            "        [-1.6178,  1.5347, -0.3230],\n",
            "        [-0.8402,  0.0596,  0.7645],\n",
            "        [ 0.3594, -0.2459, -0.8257],\n",
            "        [-1.5050,  1.8176, -0.3569],\n",
            "        [ 0.1338, -0.0588, -0.6479],\n",
            "        [-1.3832,  1.5950, -0.2169],\n",
            "        [-1.5981,  1.6249, -0.5120],\n",
            "        [-1.3342,  1.6384, -0.2775],\n",
            "        [-1.6784,  1.7087, -0.3743]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.5453, -0.1110, -0.6912],\n",
            "        [-1.5632,  1.5973, -0.2784],\n",
            "        [-1.4183,  0.1077,  0.9425],\n",
            "        [-1.9185,  1.4670,  0.0945],\n",
            "        [ 0.4428, -0.1250, -0.8002],\n",
            "        [-1.5137,  1.7585, -0.4959],\n",
            "        [-1.5331,  1.6442, -0.1584],\n",
            "        [-1.6178,  1.5347, -0.3230],\n",
            "        [-0.8402,  0.0596,  0.7645],\n",
            "        [ 0.3594, -0.2459, -0.8257],\n",
            "        [-1.5050,  1.8176, -0.3569],\n",
            "        [ 0.1338, -0.0588, -0.6479],\n",
            "        [-1.3832,  1.5950, -0.2169],\n",
            "        [-1.5981,  1.6249, -0.5120],\n",
            "        [-1.3342,  1.6384, -0.2775],\n",
            "        [-1.6784,  1.7087, -0.3743]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7270,  1.7740, -0.1209],\n",
            "        [-1.4360,  1.5887, -0.3289],\n",
            "        [ 0.5066, -0.2212, -0.4803],\n",
            "        [-0.9280,  0.6164, -0.1292],\n",
            "        [ 0.4495, -0.2640, -0.7062],\n",
            "        [-1.2175,  1.4758, -0.3570],\n",
            "        [-1.3077,  0.2404,  1.1476],\n",
            "        [-1.7011,  1.7013, -0.1686],\n",
            "        [ 0.2913, -0.0301, -0.6076],\n",
            "        [-1.7178,  0.1032,  1.1677],\n",
            "        [-1.4916,  0.3557,  0.7168],\n",
            "        [-1.6643,  0.9866,  0.1737],\n",
            "        [-1.7428,  0.5572,  1.1013],\n",
            "        [-1.5578,  1.6765, -0.2505],\n",
            "        [-1.4638,  1.5317, -0.3959],\n",
            "        [-1.5478,  1.7196, -0.3160]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7270,  1.7740, -0.1209],\n",
            "        [-1.4360,  1.5887, -0.3289],\n",
            "        [ 0.5066, -0.2212, -0.4803],\n",
            "        [-0.9280,  0.6164, -0.1292],\n",
            "        [ 0.4495, -0.2640, -0.7062],\n",
            "        [-1.2175,  1.4758, -0.3570],\n",
            "        [-1.3077,  0.2404,  1.1476],\n",
            "        [-1.7011,  1.7013, -0.1686],\n",
            "        [ 0.2913, -0.0301, -0.6076],\n",
            "        [-1.7178,  0.1032,  1.1677],\n",
            "        [-1.4916,  0.3557,  0.7168],\n",
            "        [-1.6643,  0.9866,  0.1737],\n",
            "        [-1.7428,  0.5572,  1.1013],\n",
            "        [-1.5578,  1.6765, -0.2505],\n",
            "        [-1.4638,  1.5317, -0.3959],\n",
            "        [-1.5478,  1.7196, -0.3160]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.1597, -0.2046, -0.8707],\n",
            "        [-1.5388,  0.8941,  0.7359],\n",
            "        [-1.6609,  1.7892, -0.4378],\n",
            "        [-1.6921,  0.4208,  1.0034],\n",
            "        [-1.5557,  1.5806, -0.2155],\n",
            "        [-1.7035,  1.7014, -0.2780],\n",
            "        [-1.4309,  1.7114, -0.3257],\n",
            "        [-1.7006,  0.8506,  0.8789],\n",
            "        [ 0.4416, -0.1885, -0.7912],\n",
            "        [-1.4197,  1.8219, -0.4129],\n",
            "        [-1.6051,  1.3002,  0.2605],\n",
            "        [-1.5101,  1.6050, -0.2718],\n",
            "        [-1.3445,  0.5514,  0.8461],\n",
            "        [-1.4615,  1.7027, -0.5706],\n",
            "        [-1.5897,  1.7076, -0.3357],\n",
            "        [-1.5390,  1.5479, -0.2771]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.1597, -0.2046, -0.8707],\n",
            "        [-1.5388,  0.8941,  0.7359],\n",
            "        [-1.6609,  1.7892, -0.4378],\n",
            "        [-1.6921,  0.4208,  1.0034],\n",
            "        [-1.5557,  1.5806, -0.2155],\n",
            "        [-1.7035,  1.7014, -0.2780],\n",
            "        [-1.4309,  1.7114, -0.3257],\n",
            "        [-1.7006,  0.8506,  0.8789],\n",
            "        [ 0.4416, -0.1885, -0.7912],\n",
            "        [-1.4197,  1.8219, -0.4129],\n",
            "        [-1.6051,  1.3002,  0.2605],\n",
            "        [-1.5101,  1.6050, -0.2718],\n",
            "        [-1.3445,  0.5514,  0.8461],\n",
            "        [-1.4615,  1.7027, -0.5706],\n",
            "        [-1.5897,  1.7076, -0.3357],\n",
            "        [-1.5390,  1.5479, -0.2771]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5777, -0.0043,  1.0596],\n",
            "        [-1.4689,  1.7226, -0.2867],\n",
            "        [-1.4926,  1.6097, -0.3549],\n",
            "        [ 0.5543, -0.1903, -0.6267],\n",
            "        [-1.5241,  1.5244, -0.3101],\n",
            "        [-1.5272,  0.5103,  1.0256],\n",
            "        [-1.6260,  1.6816, -0.2968],\n",
            "        [ 0.3817, -0.2366, -0.9315],\n",
            "        [-1.5350,  1.6425, -0.4569],\n",
            "        [ 0.3383, -0.1946, -0.6495],\n",
            "        [-1.5231,  1.6636, -0.2969],\n",
            "        [-1.4396,  1.5275, -0.2744],\n",
            "        [-1.5974,  1.7054, -0.4160],\n",
            "        [-1.5525,  1.7583, -0.4141],\n",
            "        [-1.7395,  1.1403,  0.1766],\n",
            "        [-1.7677,  1.4349, -0.0568]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5777, -0.0043,  1.0596],\n",
            "        [-1.4689,  1.7226, -0.2867],\n",
            "        [-1.4926,  1.6097, -0.3549],\n",
            "        [ 0.5543, -0.1903, -0.6267],\n",
            "        [-1.5241,  1.5244, -0.3101],\n",
            "        [-1.5272,  0.5103,  1.0256],\n",
            "        [-1.6260,  1.6816, -0.2968],\n",
            "        [ 0.3817, -0.2366, -0.9315],\n",
            "        [-1.5350,  1.6425, -0.4569],\n",
            "        [ 0.3383, -0.1946, -0.6495],\n",
            "        [-1.5231,  1.6636, -0.2969],\n",
            "        [-1.4396,  1.5275, -0.2744],\n",
            "        [-1.5974,  1.7054, -0.4160],\n",
            "        [-1.5525,  1.7583, -0.4141],\n",
            "        [-1.7395,  1.1403,  0.1766],\n",
            "        [-1.7677,  1.4349, -0.0568]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3007, -0.0228, -0.9128],\n",
            "        [-1.8394,  1.3511,  0.4665],\n",
            "        [-1.5969,  1.9031, -0.5017],\n",
            "        [-1.5115,  1.7227, -0.3342],\n",
            "        [ 0.4062, -0.0868, -0.7614],\n",
            "        [-1.5192,  1.5180, -0.1211],\n",
            "        [-1.6556,  1.6783, -0.4374],\n",
            "        [-1.2499,  1.5970, -0.5862],\n",
            "        [-1.4145,  1.8549, -0.4484],\n",
            "        [-1.5729,  1.8672, -0.4780],\n",
            "        [-1.5563,  1.7447, -0.2540],\n",
            "        [-1.5344,  1.7727, -0.2782],\n",
            "        [-1.6795,  1.8360, -0.2010],\n",
            "        [-1.6603,  1.6149, -0.0258],\n",
            "        [-1.7151,  1.5678, -0.3529],\n",
            "        [-1.4707,  1.6560, -0.3010]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.3007, -0.0228, -0.9128],\n",
            "        [-1.8394,  1.3511,  0.4665],\n",
            "        [-1.5969,  1.9031, -0.5017],\n",
            "        [-1.5115,  1.7227, -0.3342],\n",
            "        [ 0.4062, -0.0868, -0.7614],\n",
            "        [-1.5192,  1.5180, -0.1211],\n",
            "        [-1.6556,  1.6783, -0.4374],\n",
            "        [-1.2499,  1.5970, -0.5862],\n",
            "        [-1.4145,  1.8549, -0.4484],\n",
            "        [-1.5729,  1.8672, -0.4780],\n",
            "        [-1.5563,  1.7447, -0.2540],\n",
            "        [-1.5344,  1.7727, -0.2782],\n",
            "        [-1.6795,  1.8360, -0.2010],\n",
            "        [-1.6603,  1.6149, -0.0258],\n",
            "        [-1.7151,  1.5678, -0.3529],\n",
            "        [-1.4707,  1.6560, -0.3010]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5330, -0.0802, -0.8477],\n",
            "        [-1.4648,  1.6837, -0.1472],\n",
            "        [-1.5629,  1.5294, -0.2176],\n",
            "        [-1.4552,  1.5239, -0.4555],\n",
            "        [-1.4265,  0.0755,  0.9470],\n",
            "        [-1.4075,  1.6216, -0.3518],\n",
            "        [-1.8345,  0.4074,  1.1200],\n",
            "        [-1.4340,  1.5672, -0.4984],\n",
            "        [-1.3820,  1.6074, -0.2760],\n",
            "        [-1.6093,  1.7677, -0.3387],\n",
            "        [-1.4058,  0.3268,  0.8673],\n",
            "        [-1.7299,  1.7718, -0.4240],\n",
            "        [-1.5460,  1.4175, -0.2538],\n",
            "        [-1.5188,  1.5553, -0.4432],\n",
            "        [-0.4487,  0.5458, -0.8455],\n",
            "        [-1.5681,  0.1376,  1.0761]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.5330, -0.0802, -0.8477],\n",
            "        [-1.4648,  1.6837, -0.1472],\n",
            "        [-1.5629,  1.5294, -0.2176],\n",
            "        [-1.4552,  1.5239, -0.4555],\n",
            "        [-1.4265,  0.0755,  0.9470],\n",
            "        [-1.4075,  1.6216, -0.3518],\n",
            "        [-1.8345,  0.4074,  1.1200],\n",
            "        [-1.4340,  1.5672, -0.4984],\n",
            "        [-1.3820,  1.6074, -0.2760],\n",
            "        [-1.6093,  1.7677, -0.3387],\n",
            "        [-1.4058,  0.3268,  0.8673],\n",
            "        [-1.7299,  1.7718, -0.4240],\n",
            "        [-1.5460,  1.4175, -0.2538],\n",
            "        [-1.5188,  1.5553, -0.4432],\n",
            "        [-0.4487,  0.5458, -0.8455],\n",
            "        [-1.5681,  0.1376,  1.0761]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6987,  1.7169, -0.2103],\n",
            "        [-1.4001,  0.3033,  0.8526],\n",
            "        [-1.4795,  1.7069, -0.4616],\n",
            "        [-1.4715,  0.4400,  1.0297],\n",
            "        [ 0.5456, -0.1937, -0.8013],\n",
            "        [-1.6979,  1.6079, -0.3129],\n",
            "        [ 0.4484, -0.1561, -0.8019],\n",
            "        [-1.5193,  1.4950,  0.1652],\n",
            "        [-1.5545,  1.5080, -0.3590],\n",
            "        [-1.4228,  1.5620, -0.4921],\n",
            "        [-1.6360,  1.6978, -0.5527],\n",
            "        [-1.7256,  1.6806, -0.2319],\n",
            "        [-1.3894,  0.1836,  1.0874],\n",
            "        [-1.6517,  1.7059, -0.4969],\n",
            "        [-1.2329,  1.5898, -0.4990],\n",
            "        [-1.5816,  1.8471, -0.3177]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6987,  1.7169, -0.2103],\n",
            "        [-1.4001,  0.3033,  0.8526],\n",
            "        [-1.4795,  1.7069, -0.4616],\n",
            "        [-1.4715,  0.4400,  1.0297],\n",
            "        [ 0.5456, -0.1937, -0.8013],\n",
            "        [-1.6979,  1.6079, -0.3129],\n",
            "        [ 0.4484, -0.1561, -0.8019],\n",
            "        [-1.5193,  1.4950,  0.1652],\n",
            "        [-1.5545,  1.5080, -0.3590],\n",
            "        [-1.4228,  1.5620, -0.4921],\n",
            "        [-1.6360,  1.6978, -0.5527],\n",
            "        [-1.7256,  1.6806, -0.2319],\n",
            "        [-1.3894,  0.1836,  1.0874],\n",
            "        [-1.6517,  1.7059, -0.4969],\n",
            "        [-1.2329,  1.5898, -0.4990],\n",
            "        [-1.5816,  1.8471, -0.3177]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4388,  0.2965,  1.1343],\n",
            "        [-1.4772,  1.8869, -0.4161],\n",
            "        [-1.7282,  0.4212,  0.9332],\n",
            "        [ 0.4945, -0.1153, -0.9469],\n",
            "        [-1.2927,  0.7547,  0.0923],\n",
            "        [ 0.3977, -0.1402, -0.8195],\n",
            "        [ 0.5382, -0.0838, -0.7783],\n",
            "        [ 0.3501,  0.0469, -0.7768],\n",
            "        [-1.6901,  0.4419,  0.8301],\n",
            "        [-1.4952,  1.6884, -0.3299],\n",
            "        [-1.7139,  1.9503, -0.3204],\n",
            "        [-1.5440,  1.6790, -0.3538],\n",
            "        [-1.4098,  1.6198, -0.2838],\n",
            "        [-1.3730,  1.4134, -0.3671],\n",
            "        [-1.3277,  1.6492, -0.4805],\n",
            "        [-1.7548,  0.6299,  0.8507]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4388,  0.2965,  1.1343],\n",
            "        [-1.4772,  1.8869, -0.4161],\n",
            "        [-1.7282,  0.4212,  0.9332],\n",
            "        [ 0.4945, -0.1153, -0.9469],\n",
            "        [-1.2927,  0.7547,  0.0923],\n",
            "        [ 0.3977, -0.1402, -0.8195],\n",
            "        [ 0.5382, -0.0838, -0.7783],\n",
            "        [ 0.3501,  0.0469, -0.7768],\n",
            "        [-1.6901,  0.4419,  0.8301],\n",
            "        [-1.4952,  1.6884, -0.3299],\n",
            "        [-1.7139,  1.9503, -0.3204],\n",
            "        [-1.5440,  1.6790, -0.3538],\n",
            "        [-1.4098,  1.6198, -0.2838],\n",
            "        [-1.3730,  1.4134, -0.3671],\n",
            "        [-1.3277,  1.6492, -0.4805],\n",
            "        [-1.7548,  0.6299,  0.8507]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5663e+00,  2.7197e-01,  1.0268e+00],\n",
            "        [-1.4256e+00,  3.8039e-01,  1.0420e+00],\n",
            "        [-1.6211e+00,  1.8182e+00, -5.2521e-01],\n",
            "        [-1.4853e+00,  1.7010e+00, -6.6117e-02],\n",
            "        [-1.4776e+00,  1.3707e+00,  6.4830e-02],\n",
            "        [-1.8602e+00,  1.0316e+00,  4.5215e-01],\n",
            "        [ 4.5270e-01, -1.6652e-01, -8.3899e-01],\n",
            "        [-1.1678e-01,  6.8320e-01, -6.0803e-01],\n",
            "        [-1.8548e+00,  1.6722e+00, -1.5389e-01],\n",
            "        [-1.8470e+00,  1.1126e+00,  5.0678e-01],\n",
            "        [-1.5739e+00,  1.5585e+00, -3.4155e-01],\n",
            "        [ 1.2976e-01, -3.8634e-02, -5.0318e-01],\n",
            "        [-1.8726e+00,  1.2137e+00,  3.5865e-01],\n",
            "        [-1.2352e+00,  1.3681e-03,  8.8560e-01],\n",
            "        [-1.4610e+00,  1.8544e+00, -4.2263e-01],\n",
            "        [-1.4774e+00,  1.5992e+00, -2.6034e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5663e+00,  2.7197e-01,  1.0268e+00],\n",
            "        [-1.4256e+00,  3.8039e-01,  1.0420e+00],\n",
            "        [-1.6211e+00,  1.8182e+00, -5.2521e-01],\n",
            "        [-1.4853e+00,  1.7010e+00, -6.6117e-02],\n",
            "        [-1.4776e+00,  1.3707e+00,  6.4830e-02],\n",
            "        [-1.8602e+00,  1.0316e+00,  4.5215e-01],\n",
            "        [ 4.5270e-01, -1.6652e-01, -8.3899e-01],\n",
            "        [-1.1678e-01,  6.8320e-01, -6.0803e-01],\n",
            "        [-1.8548e+00,  1.6722e+00, -1.5389e-01],\n",
            "        [-1.8470e+00,  1.1126e+00,  5.0678e-01],\n",
            "        [-1.5739e+00,  1.5585e+00, -3.4155e-01],\n",
            "        [ 1.2976e-01, -3.8634e-02, -5.0318e-01],\n",
            "        [-1.8726e+00,  1.2137e+00,  3.5865e-01],\n",
            "        [-1.2352e+00,  1.3681e-03,  8.8560e-01],\n",
            "        [-1.4610e+00,  1.8544e+00, -4.2263e-01],\n",
            "        [-1.4774e+00,  1.5992e+00, -2.6034e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5282,  1.4808, -0.5496],\n",
            "        [ 0.2756, -0.1297, -0.3936],\n",
            "        [-1.5467,  1.7357, -0.2684],\n",
            "        [-1.4915,  1.6058, -0.2988],\n",
            "        [-1.5390,  1.6932, -0.2095],\n",
            "        [-1.6999,  1.6882, -0.3205],\n",
            "        [ 0.2045,  0.0363, -0.9102],\n",
            "        [-1.2838,  1.4108, -0.3758],\n",
            "        [-1.5798,  1.5354, -0.2854],\n",
            "        [-1.5748,  1.3447, -0.2814],\n",
            "        [-1.4186,  1.5370, -0.1221],\n",
            "        [-1.5121,  1.6627, -0.2571],\n",
            "        [ 0.2676,  0.0243, -0.7772],\n",
            "        [-1.7395,  0.1855,  1.1395],\n",
            "        [-1.8658,  0.7914,  0.7610],\n",
            "        [-1.5582,  1.7532, -0.4279]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5282,  1.4808, -0.5496],\n",
            "        [ 0.2756, -0.1297, -0.3936],\n",
            "        [-1.5467,  1.7357, -0.2684],\n",
            "        [-1.4915,  1.6058, -0.2988],\n",
            "        [-1.5390,  1.6932, -0.2095],\n",
            "        [-1.6999,  1.6882, -0.3205],\n",
            "        [ 0.2045,  0.0363, -0.9102],\n",
            "        [-1.2838,  1.4108, -0.3758],\n",
            "        [-1.5798,  1.5354, -0.2854],\n",
            "        [-1.5748,  1.3447, -0.2814],\n",
            "        [-1.4186,  1.5370, -0.1221],\n",
            "        [-1.5121,  1.6627, -0.2571],\n",
            "        [ 0.2676,  0.0243, -0.7772],\n",
            "        [-1.7395,  0.1855,  1.1395],\n",
            "        [-1.8658,  0.7914,  0.7610],\n",
            "        [-1.5582,  1.7532, -0.4279]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8658e+00,  7.2888e-01,  9.5642e-01],\n",
            "        [-1.8702e+00,  8.2492e-01,  9.4928e-01],\n",
            "        [ 3.5974e-01, -6.2281e-04, -5.0509e-01],\n",
            "        [-1.5946e+00,  1.7099e+00, -4.2379e-01],\n",
            "        [-1.4914e+00,  1.7229e+00, -4.7052e-01],\n",
            "        [-1.5934e+00,  1.7427e+00, -4.4878e-01],\n",
            "        [-1.5755e+00,  1.8341e+00, -2.3678e-01],\n",
            "        [-1.6689e+00,  1.5859e+00, -4.2695e-01],\n",
            "        [-1.4788e+00,  1.7266e+00, -4.0582e-01],\n",
            "        [-1.6315e+00,  1.4851e+00, -3.8174e-01],\n",
            "        [-1.5016e+00,  1.6218e+00, -3.4059e-01],\n",
            "        [-1.4255e+00,  1.6768e+00, -5.1570e-01],\n",
            "        [-1.8396e+00,  3.8387e-01,  1.1448e+00],\n",
            "        [-1.7415e+00,  1.6755e+00, -1.9321e-01],\n",
            "        [ 5.4820e-01, -4.0627e-02, -8.8969e-01],\n",
            "        [-1.4588e+00,  1.4441e+00, -2.9387e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8658e+00,  7.2888e-01,  9.5642e-01],\n",
            "        [-1.8702e+00,  8.2492e-01,  9.4928e-01],\n",
            "        [ 3.5974e-01, -6.2281e-04, -5.0509e-01],\n",
            "        [-1.5946e+00,  1.7099e+00, -4.2379e-01],\n",
            "        [-1.4914e+00,  1.7229e+00, -4.7052e-01],\n",
            "        [-1.5934e+00,  1.7427e+00, -4.4878e-01],\n",
            "        [-1.5755e+00,  1.8341e+00, -2.3678e-01],\n",
            "        [-1.6689e+00,  1.5859e+00, -4.2695e-01],\n",
            "        [-1.4788e+00,  1.7266e+00, -4.0582e-01],\n",
            "        [-1.6315e+00,  1.4851e+00, -3.8174e-01],\n",
            "        [-1.5016e+00,  1.6218e+00, -3.4059e-01],\n",
            "        [-1.4255e+00,  1.6768e+00, -5.1570e-01],\n",
            "        [-1.8396e+00,  3.8387e-01,  1.1448e+00],\n",
            "        [-1.7415e+00,  1.6755e+00, -1.9321e-01],\n",
            "        [ 5.4820e-01, -4.0627e-02, -8.8969e-01],\n",
            "        [-1.4588e+00,  1.4441e+00, -2.9387e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6953,  1.8920, -0.4259],\n",
            "        [-1.4533,  1.7722, -0.4142],\n",
            "        [-1.7499,  1.7883, -0.4980],\n",
            "        [-1.4835,  0.0660,  1.0829],\n",
            "        [ 0.5630, -0.1048, -0.7709],\n",
            "        [-1.5452,  1.7493, -0.4105],\n",
            "        [-1.6663,  1.7336, -0.4515],\n",
            "        [-1.5794,  1.8579, -0.3817],\n",
            "        [-1.3845,  1.7216, -0.4340],\n",
            "        [ 0.3099,  0.1681, -1.0443],\n",
            "        [-1.6469,  1.6218, -0.3514],\n",
            "        [-1.7606,  1.6124, -0.2806],\n",
            "        [-0.7799,  0.9443, -0.8486],\n",
            "        [-1.8120,  1.7828, -0.3449],\n",
            "        [-1.7133,  1.5876, -0.0810],\n",
            "        [-0.7493, -0.0677,  0.5938]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6953,  1.8920, -0.4259],\n",
            "        [-1.4533,  1.7722, -0.4142],\n",
            "        [-1.7499,  1.7883, -0.4980],\n",
            "        [-1.4835,  0.0660,  1.0829],\n",
            "        [ 0.5630, -0.1048, -0.7709],\n",
            "        [-1.5452,  1.7493, -0.4105],\n",
            "        [-1.6663,  1.7336, -0.4515],\n",
            "        [-1.5794,  1.8579, -0.3817],\n",
            "        [-1.3845,  1.7216, -0.4340],\n",
            "        [ 0.3099,  0.1681, -1.0443],\n",
            "        [-1.6469,  1.6218, -0.3514],\n",
            "        [-1.7606,  1.6124, -0.2806],\n",
            "        [-0.7799,  0.9443, -0.8486],\n",
            "        [-1.8120,  1.7828, -0.3449],\n",
            "        [-1.7133,  1.5876, -0.0810],\n",
            "        [-0.7493, -0.0677,  0.5938]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.4721,  0.1276, -0.8382],\n",
            "        [-1.4529,  1.6115, -0.1851],\n",
            "        [-1.5012,  1.7224, -0.5894],\n",
            "        [-1.2996,  1.8990, -0.3971],\n",
            "        [ 0.2181, -0.0068, -0.7127],\n",
            "        [ 0.0767,  0.2336, -0.8980],\n",
            "        [-1.5307,  1.5611, -0.3463],\n",
            "        [-2.1414,  0.7476,  0.8473],\n",
            "        [-1.6779,  1.6758, -0.3862],\n",
            "        [ 0.2622, -0.2009, -0.7386],\n",
            "        [-1.5756,  1.8671, -0.5914],\n",
            "        [-1.4145,  1.6379, -0.5124],\n",
            "        [-1.4690,  0.1497,  1.0522],\n",
            "        [-1.6420,  1.6490, -0.3904],\n",
            "        [-1.5974,  1.6113, -0.4980],\n",
            "        [-1.8561,  0.0576,  1.1985]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.4721,  0.1276, -0.8382],\n",
            "        [-1.4529,  1.6115, -0.1851],\n",
            "        [-1.5012,  1.7224, -0.5894],\n",
            "        [-1.2996,  1.8990, -0.3971],\n",
            "        [ 0.2181, -0.0068, -0.7127],\n",
            "        [ 0.0767,  0.2336, -0.8980],\n",
            "        [-1.5307,  1.5611, -0.3463],\n",
            "        [-2.1414,  0.7476,  0.8473],\n",
            "        [-1.6779,  1.6758, -0.3862],\n",
            "        [ 0.2622, -0.2009, -0.7386],\n",
            "        [-1.5756,  1.8671, -0.5914],\n",
            "        [-1.4145,  1.6379, -0.5124],\n",
            "        [-1.4690,  0.1497,  1.0522],\n",
            "        [-1.6420,  1.6490, -0.3904],\n",
            "        [-1.5974,  1.6113, -0.4980],\n",
            "        [-1.8561,  0.0576,  1.1985]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5794,  1.6810, -0.3233],\n",
            "        [ 0.3810, -0.1794, -0.6938],\n",
            "        [-1.4327,  1.5899, -0.3728],\n",
            "        [ 0.4582, -0.2325, -0.7279],\n",
            "        [-1.7327,  0.4541,  1.1682],\n",
            "        [-1.8983,  0.6069,  1.0741],\n",
            "        [-1.7980,  0.1362,  1.4413],\n",
            "        [-1.5994,  1.7452, -0.4484],\n",
            "        [-1.7316,  0.2580,  1.1256],\n",
            "        [-1.6609,  1.5144,  0.0909],\n",
            "        [-2.0141,  1.2434,  0.7509],\n",
            "        [-1.6300,  1.6804, -0.4324],\n",
            "        [-1.7052,  1.7042, -0.3360],\n",
            "        [-1.7668,  0.7568,  0.8010],\n",
            "        [-1.8151,  1.4513, -0.3588],\n",
            "        [-1.6510,  0.1665,  1.0742]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5794,  1.6810, -0.3233],\n",
            "        [ 0.3810, -0.1794, -0.6938],\n",
            "        [-1.4327,  1.5899, -0.3728],\n",
            "        [ 0.4582, -0.2325, -0.7279],\n",
            "        [-1.7327,  0.4541,  1.1682],\n",
            "        [-1.8983,  0.6069,  1.0741],\n",
            "        [-1.7980,  0.1362,  1.4413],\n",
            "        [-1.5994,  1.7452, -0.4484],\n",
            "        [-1.7316,  0.2580,  1.1256],\n",
            "        [-1.6609,  1.5144,  0.0909],\n",
            "        [-2.0141,  1.2434,  0.7509],\n",
            "        [-1.6300,  1.6804, -0.4324],\n",
            "        [-1.7052,  1.7042, -0.3360],\n",
            "        [-1.7668,  0.7568,  0.8010],\n",
            "        [-1.8151,  1.4513, -0.3588],\n",
            "        [-1.6510,  0.1665,  1.0742]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5381,  1.7228, -0.4822],\n",
            "        [-1.6873,  1.7568, -0.1877],\n",
            "        [-1.6621,  1.2593,  0.2037],\n",
            "        [-1.4852,  1.4199, -0.4267],\n",
            "        [-1.8975,  0.2334,  1.0418],\n",
            "        [-1.4643,  1.3040, -0.1408],\n",
            "        [-1.7027,  0.1869,  1.2871],\n",
            "        [-1.5427,  0.0513,  1.2705],\n",
            "        [-1.3145,  1.5057, -0.5235],\n",
            "        [-1.5429,  0.1111,  1.1660],\n",
            "        [ 0.0469,  0.3790, -1.0454],\n",
            "        [-1.7450,  0.9871,  0.7026],\n",
            "        [-1.3882,  1.7385, -0.2750],\n",
            "        [-1.2901,  1.5691, -0.5973],\n",
            "        [-1.5397,  1.4345, -0.4842],\n",
            "        [-1.5359,  1.3923, -0.0045]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5381,  1.7228, -0.4822],\n",
            "        [-1.6873,  1.7568, -0.1877],\n",
            "        [-1.6621,  1.2593,  0.2037],\n",
            "        [-1.4852,  1.4199, -0.4267],\n",
            "        [-1.8975,  0.2334,  1.0418],\n",
            "        [-1.4643,  1.3040, -0.1408],\n",
            "        [-1.7027,  0.1869,  1.2871],\n",
            "        [-1.5427,  0.0513,  1.2705],\n",
            "        [-1.3145,  1.5057, -0.5235],\n",
            "        [-1.5429,  0.1111,  1.1660],\n",
            "        [ 0.0469,  0.3790, -1.0454],\n",
            "        [-1.7450,  0.9871,  0.7026],\n",
            "        [-1.3882,  1.7385, -0.2750],\n",
            "        [-1.2901,  1.5691, -0.5973],\n",
            "        [-1.5397,  1.4345, -0.4842],\n",
            "        [-1.5359,  1.3923, -0.0045]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5312,  1.7170, -0.1548],\n",
            "        [-1.9396,  0.5305,  0.8623],\n",
            "        [ 0.3603, -0.1292, -0.7219],\n",
            "        [-1.2148,  1.4118, -0.5409],\n",
            "        [-1.5141,  1.6232, -0.5005],\n",
            "        [-1.7339,  0.1736,  1.2063],\n",
            "        [-1.4534,  1.7937, -0.4791],\n",
            "        [-1.6277,  0.1695,  1.2463],\n",
            "        [-1.3947,  1.5770, -0.1186],\n",
            "        [ 0.4226, -0.1449, -0.7634],\n",
            "        [-1.6067, -0.0422,  1.1601],\n",
            "        [-1.5756,  0.2184,  1.0112],\n",
            "        [ 0.4704, -0.0735, -0.7244],\n",
            "        [-1.3834,  1.7831, -0.7523],\n",
            "        [-1.7232,  0.1332,  1.0053],\n",
            "        [-0.7622,  1.3085, -0.8759]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5312,  1.7170, -0.1548],\n",
            "        [-1.9396,  0.5305,  0.8623],\n",
            "        [ 0.3603, -0.1292, -0.7219],\n",
            "        [-1.2148,  1.4118, -0.5409],\n",
            "        [-1.5141,  1.6232, -0.5005],\n",
            "        [-1.7339,  0.1736,  1.2063],\n",
            "        [-1.4534,  1.7937, -0.4791],\n",
            "        [-1.6277,  0.1695,  1.2463],\n",
            "        [-1.3947,  1.5770, -0.1186],\n",
            "        [ 0.4226, -0.1449, -0.7634],\n",
            "        [-1.6067, -0.0422,  1.1601],\n",
            "        [-1.5756,  0.2184,  1.0112],\n",
            "        [ 0.4704, -0.0735, -0.7244],\n",
            "        [-1.3834,  1.7831, -0.7523],\n",
            "        [-1.7232,  0.1332,  1.0053],\n",
            "        [-0.7622,  1.3085, -0.8759]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.4178, -0.1710, -1.0664],\n",
            "        [-1.3989,  1.6262, -0.3893],\n",
            "        [-1.5068,  1.7341, -0.2868],\n",
            "        [-1.3640,  1.7260, -0.5554],\n",
            "        [-1.2924,  1.6705, -0.3325],\n",
            "        [-1.3260,  1.5570, -0.6110],\n",
            "        [-1.6167,  0.1437,  1.2279],\n",
            "        [-1.4900,  1.8668, -0.5665],\n",
            "        [-1.8934,  0.6248,  1.0926],\n",
            "        [ 0.0142, -0.0102, -0.5331],\n",
            "        [-1.5189,  1.6871, -0.6186],\n",
            "        [-1.5946,  0.1982,  1.1882],\n",
            "        [-1.4334,  1.7369, -0.3976],\n",
            "        [-1.5294,  1.6007, -0.2180],\n",
            "        [-1.3360,  1.7872, -0.6026],\n",
            "        [-1.6888,  0.2153,  1.2308]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.4178, -0.1710, -1.0664],\n",
            "        [-1.3989,  1.6262, -0.3893],\n",
            "        [-1.5068,  1.7341, -0.2868],\n",
            "        [-1.3640,  1.7260, -0.5554],\n",
            "        [-1.2924,  1.6705, -0.3325],\n",
            "        [-1.3260,  1.5570, -0.6110],\n",
            "        [-1.6167,  0.1437,  1.2279],\n",
            "        [-1.4900,  1.8668, -0.5665],\n",
            "        [-1.8934,  0.6248,  1.0926],\n",
            "        [ 0.0142, -0.0102, -0.5331],\n",
            "        [-1.5189,  1.6871, -0.6186],\n",
            "        [-1.5946,  0.1982,  1.1882],\n",
            "        [-1.4334,  1.7369, -0.3976],\n",
            "        [-1.5294,  1.6007, -0.2180],\n",
            "        [-1.3360,  1.7872, -0.6026],\n",
            "        [-1.6888,  0.2153,  1.2308]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3298,  1.5978, -0.1921],\n",
            "        [-1.8261,  0.2846,  1.1475],\n",
            "        [-1.6514,  1.5635, -0.3438],\n",
            "        [-1.6408,  1.4882, -0.2020],\n",
            "        [-1.5008,  0.1774,  1.2155],\n",
            "        [-1.5774,  1.6462, -0.2548],\n",
            "        [-1.4171,  1.2803, -0.4437],\n",
            "        [-1.8228,  0.0830,  1.3317],\n",
            "        [-1.5905,  1.6761, -0.5068],\n",
            "        [-1.4499,  1.6910, -0.4277],\n",
            "        [-1.8984,  0.6588,  1.3080],\n",
            "        [-1.6151,  1.1575,  0.4371],\n",
            "        [-1.4914,  1.5968, -0.5819],\n",
            "        [-1.8494,  0.8672,  0.7874],\n",
            "        [-1.8742,  1.6990, -0.0262],\n",
            "        [-1.4641,  1.6538, -0.5240]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3298,  1.5978, -0.1921],\n",
            "        [-1.8261,  0.2846,  1.1475],\n",
            "        [-1.6514,  1.5635, -0.3438],\n",
            "        [-1.6408,  1.4882, -0.2020],\n",
            "        [-1.5008,  0.1774,  1.2155],\n",
            "        [-1.5774,  1.6462, -0.2548],\n",
            "        [-1.4171,  1.2803, -0.4437],\n",
            "        [-1.8228,  0.0830,  1.3317],\n",
            "        [-1.5905,  1.6761, -0.5068],\n",
            "        [-1.4499,  1.6910, -0.4277],\n",
            "        [-1.8984,  0.6588,  1.3080],\n",
            "        [-1.6151,  1.1575,  0.4371],\n",
            "        [-1.4914,  1.5968, -0.5819],\n",
            "        [-1.8494,  0.8672,  0.7874],\n",
            "        [-1.8742,  1.6990, -0.0262],\n",
            "        [-1.4641,  1.6538, -0.5240]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6738,  0.2392,  1.2251],\n",
            "        [-1.6771,  0.1029,  1.3065],\n",
            "        [-1.6804,  1.6331, -0.0503],\n",
            "        [-1.6038,  0.1920,  1.2252],\n",
            "        [-1.4835,  1.3764, -0.0554],\n",
            "        [-1.7759,  0.1181,  1.2266],\n",
            "        [-1.7414,  0.1494,  1.2517],\n",
            "        [-1.4158,  1.9068, -0.6375],\n",
            "        [-1.4175,  1.8077, -0.5498],\n",
            "        [-1.5089,  1.4605, -0.2153],\n",
            "        [-1.6409,  1.8381, -0.5597],\n",
            "        [-1.3526,  1.4434, -0.4782],\n",
            "        [-1.4337,  1.6182, -0.5561],\n",
            "        [-0.4311,  0.7247, -0.6739],\n",
            "        [-1.4387,  1.8337, -0.4639],\n",
            "        [-1.8037,  0.0960,  1.2812]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6738,  0.2392,  1.2251],\n",
            "        [-1.6771,  0.1029,  1.3065],\n",
            "        [-1.6804,  1.6331, -0.0503],\n",
            "        [-1.6038,  0.1920,  1.2252],\n",
            "        [-1.4835,  1.3764, -0.0554],\n",
            "        [-1.7759,  0.1181,  1.2266],\n",
            "        [-1.7414,  0.1494,  1.2517],\n",
            "        [-1.4158,  1.9068, -0.6375],\n",
            "        [-1.4175,  1.8077, -0.5498],\n",
            "        [-1.5089,  1.4605, -0.2153],\n",
            "        [-1.6409,  1.8381, -0.5597],\n",
            "        [-1.3526,  1.4434, -0.4782],\n",
            "        [-1.4337,  1.6182, -0.5561],\n",
            "        [-0.4311,  0.7247, -0.6739],\n",
            "        [-1.4387,  1.8337, -0.4639],\n",
            "        [-1.8037,  0.0960,  1.2812]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8400,  0.0769,  1.2547],\n",
            "        [ 0.0511, -0.0228, -0.6657],\n",
            "        [-1.6437,  0.0531,  1.2605],\n",
            "        [ 0.3705, -0.1048, -0.9349],\n",
            "        [-1.6096,  1.6589, -0.2488],\n",
            "        [ 0.6033, -0.1777, -0.6988],\n",
            "        [-1.5096,  1.4525, -0.6269],\n",
            "        [-1.4353,  1.4535, -0.7636],\n",
            "        [-1.9481,  0.6169,  0.8668],\n",
            "        [-1.6410,  1.8252, -0.2979],\n",
            "        [-1.1274,  1.5838, -0.5364],\n",
            "        [-1.8573,  0.0659,  1.2486],\n",
            "        [-1.6615,  0.2996,  1.1626],\n",
            "        [-1.3707,  1.5800, -0.4402],\n",
            "        [-1.5722,  1.6132, -0.6034],\n",
            "        [-1.6244,  0.7232,  0.8164]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8400,  0.0769,  1.2547],\n",
            "        [ 0.0511, -0.0228, -0.6657],\n",
            "        [-1.6437,  0.0531,  1.2605],\n",
            "        [ 0.3705, -0.1048, -0.9349],\n",
            "        [-1.6096,  1.6589, -0.2488],\n",
            "        [ 0.6033, -0.1777, -0.6988],\n",
            "        [-1.5096,  1.4525, -0.6269],\n",
            "        [-1.4353,  1.4535, -0.7636],\n",
            "        [-1.9481,  0.6169,  0.8668],\n",
            "        [-1.6410,  1.8252, -0.2979],\n",
            "        [-1.1274,  1.5838, -0.5364],\n",
            "        [-1.8573,  0.0659,  1.2486],\n",
            "        [-1.6615,  0.2996,  1.1626],\n",
            "        [-1.3707,  1.5800, -0.4402],\n",
            "        [-1.5722,  1.6132, -0.6034],\n",
            "        [-1.6244,  0.7232,  0.8164]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4191,  1.6609, -0.5062],\n",
            "        [-1.2536,  1.6262, -0.4874],\n",
            "        [-1.1999,  1.4573, -0.7451],\n",
            "        [-1.8088,  0.9374,  0.6546],\n",
            "        [ 0.6166, -0.3138, -0.8455],\n",
            "        [-1.5433,  1.2691, -0.1153],\n",
            "        [-1.1926,  1.6602, -0.6942],\n",
            "        [-1.4067,  1.6395, -0.3469],\n",
            "        [ 0.4601, -0.0308, -0.7116],\n",
            "        [-1.2651,  1.5365, -0.6004],\n",
            "        [-1.2973,  1.5399, -0.4974],\n",
            "        [-1.5855,  1.7331, -0.2400],\n",
            "        [-1.6876,  0.1725,  1.1123],\n",
            "        [-1.8462,  0.1967,  1.3906],\n",
            "        [-1.3921,  1.7028, -0.1323],\n",
            "        [-1.8851,  1.0887,  0.2849]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4191,  1.6609, -0.5062],\n",
            "        [-1.2536,  1.6262, -0.4874],\n",
            "        [-1.1999,  1.4573, -0.7451],\n",
            "        [-1.8088,  0.9374,  0.6546],\n",
            "        [ 0.6166, -0.3138, -0.8455],\n",
            "        [-1.5433,  1.2691, -0.1153],\n",
            "        [-1.1926,  1.6602, -0.6942],\n",
            "        [-1.4067,  1.6395, -0.3469],\n",
            "        [ 0.4601, -0.0308, -0.7116],\n",
            "        [-1.2651,  1.5365, -0.6004],\n",
            "        [-1.2973,  1.5399, -0.4974],\n",
            "        [-1.5855,  1.7331, -0.2400],\n",
            "        [-1.6876,  0.1725,  1.1123],\n",
            "        [-1.8462,  0.1967,  1.3906],\n",
            "        [-1.3921,  1.7028, -0.1323],\n",
            "        [-1.8851,  1.0887,  0.2849]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8371,  0.3359,  1.0338],\n",
            "        [-1.4796,  1.8816, -0.4293],\n",
            "        [-1.4242,  1.8201, -0.4117],\n",
            "        [-1.7142,  1.4126,  0.0363],\n",
            "        [-1.3444,  1.6355, -0.6277],\n",
            "        [-1.8075,  1.2582,  0.3924],\n",
            "        [-0.7791,  0.0202,  0.4171],\n",
            "        [-1.8671,  0.3574,  1.4555],\n",
            "        [-1.3594,  1.2501, -0.5473],\n",
            "        [-1.3784,  1.2572, -0.1191],\n",
            "        [-1.3758,  1.8471, -0.6770],\n",
            "        [ 0.0252,  0.5221, -0.9414],\n",
            "        [-1.5312,  1.7072, -0.5170],\n",
            "        [ 0.4011, -0.2162, -0.6183],\n",
            "        [-1.9207,  0.2000,  1.3643],\n",
            "        [-1.4355,  1.4992, -0.2371]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8371,  0.3359,  1.0338],\n",
            "        [-1.4796,  1.8816, -0.4293],\n",
            "        [-1.4242,  1.8201, -0.4117],\n",
            "        [-1.7142,  1.4126,  0.0363],\n",
            "        [-1.3444,  1.6355, -0.6277],\n",
            "        [-1.8075,  1.2582,  0.3924],\n",
            "        [-0.7791,  0.0202,  0.4171],\n",
            "        [-1.8671,  0.3574,  1.4555],\n",
            "        [-1.3594,  1.2501, -0.5473],\n",
            "        [-1.3784,  1.2572, -0.1191],\n",
            "        [-1.3758,  1.8471, -0.6770],\n",
            "        [ 0.0252,  0.5221, -0.9414],\n",
            "        [-1.5312,  1.7072, -0.5170],\n",
            "        [ 0.4011, -0.2162, -0.6183],\n",
            "        [-1.9207,  0.2000,  1.3643],\n",
            "        [-1.4355,  1.4992, -0.2371]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8404,  0.3204,  1.3645],\n",
            "        [-1.3059,  1.5057, -0.3883],\n",
            "        [-1.4457,  1.7223, -0.5413],\n",
            "        [-1.6829,  0.0573,  1.3040],\n",
            "        [-1.7112,  0.2797,  1.1320],\n",
            "        [-1.8404,  0.1541,  1.4735],\n",
            "        [-1.3918,  1.5009, -0.1126],\n",
            "        [-1.8615,  0.7055,  0.6772],\n",
            "        [-1.2977,  1.4530, -0.7110],\n",
            "        [-1.3680,  1.7558, -0.4445],\n",
            "        [-1.8647,  0.3482,  1.3808],\n",
            "        [-1.8317,  0.2588,  1.3462],\n",
            "        [-1.1226,  1.3740, -0.6960],\n",
            "        [-0.7805,  0.9506, -0.6109],\n",
            "        [-1.7630, -0.1149,  1.4570],\n",
            "        [-1.4114,  1.6287, -0.3364]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8404,  0.3204,  1.3645],\n",
            "        [-1.3059,  1.5057, -0.3883],\n",
            "        [-1.4457,  1.7223, -0.5413],\n",
            "        [-1.6829,  0.0573,  1.3040],\n",
            "        [-1.7112,  0.2797,  1.1320],\n",
            "        [-1.8404,  0.1541,  1.4735],\n",
            "        [-1.3918,  1.5009, -0.1126],\n",
            "        [-1.8615,  0.7055,  0.6772],\n",
            "        [-1.2977,  1.4530, -0.7110],\n",
            "        [-1.3680,  1.7558, -0.4445],\n",
            "        [-1.8647,  0.3482,  1.3808],\n",
            "        [-1.8317,  0.2588,  1.3462],\n",
            "        [-1.1226,  1.3740, -0.6960],\n",
            "        [-0.7805,  0.9506, -0.6109],\n",
            "        [-1.7630, -0.1149,  1.4570],\n",
            "        [-1.4114,  1.6287, -0.3364]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0052,  0.7741,  0.8835],\n",
            "        [-1.7759,  0.8081,  0.8445],\n",
            "        [-1.3123,  1.5222, -0.5733],\n",
            "        [-1.7149,  0.0201,  1.3711],\n",
            "        [-1.7918,  0.8067,  0.8659],\n",
            "        [-1.9732,  0.1674,  1.3942],\n",
            "        [-0.0300, -0.0954, -0.1516],\n",
            "        [-1.9674,  0.8308,  0.5673],\n",
            "        [-1.5720,  1.4257, -0.0532],\n",
            "        [-1.6120,  1.5640, -0.3980],\n",
            "        [ 0.6908, -0.1350, -0.8179],\n",
            "        [-1.9681,  0.4830,  1.3712],\n",
            "        [-1.9398,  0.1324,  1.3509],\n",
            "        [-1.2689,  1.6483, -0.4429],\n",
            "        [-0.2184,  0.6676, -0.9272],\n",
            "        [ 0.3528, -0.2344, -0.6018]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0052,  0.7741,  0.8835],\n",
            "        [-1.7759,  0.8081,  0.8445],\n",
            "        [-1.3123,  1.5222, -0.5733],\n",
            "        [-1.7149,  0.0201,  1.3711],\n",
            "        [-1.7918,  0.8067,  0.8659],\n",
            "        [-1.9732,  0.1674,  1.3942],\n",
            "        [-0.0300, -0.0954, -0.1516],\n",
            "        [-1.9674,  0.8308,  0.5673],\n",
            "        [-1.5720,  1.4257, -0.0532],\n",
            "        [-1.6120,  1.5640, -0.3980],\n",
            "        [ 0.6908, -0.1350, -0.8179],\n",
            "        [-1.9681,  0.4830,  1.3712],\n",
            "        [-1.9398,  0.1324,  1.3509],\n",
            "        [-1.2689,  1.6483, -0.4429],\n",
            "        [-0.2184,  0.6676, -0.9272],\n",
            "        [ 0.3528, -0.2344, -0.6018]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2741,  1.8129, -0.3945],\n",
            "        [-1.1854,  1.5820, -0.3347],\n",
            "        [-2.0528,  0.1078,  1.5043],\n",
            "        [-1.1232,  1.6509, -0.7493],\n",
            "        [-1.9995,  0.0389,  1.4796],\n",
            "        [-1.6688,  0.5826,  0.9632],\n",
            "        [-1.4888,  1.8353, -0.5932],\n",
            "        [-1.3406,  1.6521, -0.6183],\n",
            "        [-1.1938,  1.4846, -0.5984],\n",
            "        [ 0.4815, -0.3056, -0.9037],\n",
            "        [-1.3246,  1.6454, -0.4175],\n",
            "        [-1.2725,  1.5154, -0.7270],\n",
            "        [-1.4786,  1.7952, -0.6567],\n",
            "        [-1.6580,  1.4434,  0.1524],\n",
            "        [-1.3315,  1.6882, -0.5829],\n",
            "        [-1.2108,  1.4866, -0.5945]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2741,  1.8129, -0.3945],\n",
            "        [-1.1854,  1.5820, -0.3347],\n",
            "        [-2.0528,  0.1078,  1.5043],\n",
            "        [-1.1232,  1.6509, -0.7493],\n",
            "        [-1.9995,  0.0389,  1.4796],\n",
            "        [-1.6688,  0.5826,  0.9632],\n",
            "        [-1.4888,  1.8353, -0.5932],\n",
            "        [-1.3406,  1.6521, -0.6183],\n",
            "        [-1.1938,  1.4846, -0.5984],\n",
            "        [ 0.4815, -0.3056, -0.9037],\n",
            "        [-1.3246,  1.6454, -0.4175],\n",
            "        [-1.2725,  1.5154, -0.7270],\n",
            "        [-1.4786,  1.7952, -0.6567],\n",
            "        [-1.6580,  1.4434,  0.1524],\n",
            "        [-1.3315,  1.6882, -0.5829],\n",
            "        [-1.2108,  1.4866, -0.5945]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2363,  1.5890, -0.4830],\n",
            "        [-1.2594,  1.7776, -0.3476],\n",
            "        [ 0.3630, -0.0859, -0.8690],\n",
            "        [-1.3373,  1.6390, -0.4982],\n",
            "        [-1.7754,  0.2505,  1.3710],\n",
            "        [-0.7805,  0.8397, -0.6401],\n",
            "        [-1.6397,  0.6101,  0.8659],\n",
            "        [-1.5731,  1.6586, -0.3373],\n",
            "        [-1.9265,  0.1411,  1.5105],\n",
            "        [ 0.5677, -0.3094, -0.8294],\n",
            "        [ 0.4691, -0.2033, -0.8759],\n",
            "        [-1.7470,  1.0144,  0.4243],\n",
            "        [ 0.3404, -0.3407, -0.6136],\n",
            "        [-1.3279,  1.6272, -0.4702],\n",
            "        [-1.8867,  0.1956,  1.3348],\n",
            "        [-1.1293,  1.3342, -0.5047]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2363,  1.5890, -0.4830],\n",
            "        [-1.2594,  1.7776, -0.3476],\n",
            "        [ 0.3630, -0.0859, -0.8690],\n",
            "        [-1.3373,  1.6390, -0.4982],\n",
            "        [-1.7754,  0.2505,  1.3710],\n",
            "        [-0.7805,  0.8397, -0.6401],\n",
            "        [-1.6397,  0.6101,  0.8659],\n",
            "        [-1.5731,  1.6586, -0.3373],\n",
            "        [-1.9265,  0.1411,  1.5105],\n",
            "        [ 0.5677, -0.3094, -0.8294],\n",
            "        [ 0.4691, -0.2033, -0.8759],\n",
            "        [-1.7470,  1.0144,  0.4243],\n",
            "        [ 0.3404, -0.3407, -0.6136],\n",
            "        [-1.3279,  1.6272, -0.4702],\n",
            "        [-1.8867,  0.1956,  1.3348],\n",
            "        [-1.1293,  1.3342, -0.5047]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3752,  1.9096, -0.6552],\n",
            "        [-1.2988,  1.7059, -0.6655],\n",
            "        [-2.0420,  0.1111,  1.4700],\n",
            "        [ 0.6601, -0.2273, -0.8923],\n",
            "        [-1.1410,  1.2030, -0.4821],\n",
            "        [-1.2423,  1.0611, -0.3329],\n",
            "        [-1.3204,  1.6454, -0.4420],\n",
            "        [-1.4738,  1.8673, -0.7113],\n",
            "        [-1.7641,  1.2907,  0.1833],\n",
            "        [-1.5202,  1.6689, -0.7497],\n",
            "        [ 0.2895, -0.2077, -0.7456],\n",
            "        [-1.2729,  1.7545, -0.7879],\n",
            "        [-1.9832,  0.8513,  1.0038],\n",
            "        [ 0.0261, -0.2102, -0.3151],\n",
            "        [-1.1886,  1.6218, -0.6958],\n",
            "        [-1.9754,  0.4544,  1.2801]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3752,  1.9096, -0.6552],\n",
            "        [-1.2988,  1.7059, -0.6655],\n",
            "        [-2.0420,  0.1111,  1.4700],\n",
            "        [ 0.6601, -0.2273, -0.8923],\n",
            "        [-1.1410,  1.2030, -0.4821],\n",
            "        [-1.2423,  1.0611, -0.3329],\n",
            "        [-1.3204,  1.6454, -0.4420],\n",
            "        [-1.4738,  1.8673, -0.7113],\n",
            "        [-1.7641,  1.2907,  0.1833],\n",
            "        [-1.5202,  1.6689, -0.7497],\n",
            "        [ 0.2895, -0.2077, -0.7456],\n",
            "        [-1.2729,  1.7545, -0.7879],\n",
            "        [-1.9832,  0.8513,  1.0038],\n",
            "        [ 0.0261, -0.2102, -0.3151],\n",
            "        [-1.1886,  1.6218, -0.6958],\n",
            "        [-1.9754,  0.4544,  1.2801]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8803,  0.8695,  0.8729],\n",
            "        [-2.0663,  0.1413,  1.6616],\n",
            "        [-1.1736,  1.7094, -0.7029],\n",
            "        [ 0.5438, -0.2780, -0.7520],\n",
            "        [-1.9700,  0.6045,  0.8962],\n",
            "        [-1.8412,  0.1438,  1.2979],\n",
            "        [-1.1802,  1.5904, -0.1980],\n",
            "        [-1.2830,  1.6283, -0.7419],\n",
            "        [-1.0725,  1.4442, -0.7880],\n",
            "        [-1.2947,  1.6099, -0.7612],\n",
            "        [-0.4886, -0.0711,  0.4730],\n",
            "        [-1.2174,  1.5789, -0.7488],\n",
            "        [-1.9055,  0.2009,  1.4346],\n",
            "        [ 0.0399,  0.4033, -1.0332],\n",
            "        [ 0.5689, -0.1632, -0.7281],\n",
            "        [-1.3239,  1.7698, -0.8400]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8803,  0.8695,  0.8729],\n",
            "        [-2.0663,  0.1413,  1.6616],\n",
            "        [-1.1736,  1.7094, -0.7029],\n",
            "        [ 0.5438, -0.2780, -0.7520],\n",
            "        [-1.9700,  0.6045,  0.8962],\n",
            "        [-1.8412,  0.1438,  1.2979],\n",
            "        [-1.1802,  1.5904, -0.1980],\n",
            "        [-1.2830,  1.6283, -0.7419],\n",
            "        [-1.0725,  1.4442, -0.7880],\n",
            "        [-1.2947,  1.6099, -0.7612],\n",
            "        [-0.4886, -0.0711,  0.4730],\n",
            "        [-1.2174,  1.5789, -0.7488],\n",
            "        [-1.9055,  0.2009,  1.4346],\n",
            "        [ 0.0399,  0.4033, -1.0332],\n",
            "        [ 0.5689, -0.1632, -0.7281],\n",
            "        [-1.3239,  1.7698, -0.8400]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.3042e+00,  3.8154e-02,  1.4723e+00],\n",
            "        [-1.3766e+00,  1.6980e+00, -5.0230e-01],\n",
            "        [-1.4006e+00,  1.4478e+00, -3.7470e-01],\n",
            "        [-1.5776e+00,  4.9251e-02,  1.2136e+00],\n",
            "        [-1.8201e+00,  1.9408e-01,  1.4369e+00],\n",
            "        [ 4.2648e-01,  1.9317e-01, -9.5834e-01],\n",
            "        [-1.2188e+00,  1.4496e+00, -6.1818e-01],\n",
            "        [-1.0883e+00,  1.8338e+00, -8.2992e-01],\n",
            "        [-1.0607e+00,  1.6011e+00, -8.5876e-01],\n",
            "        [-1.6975e+00,  1.5476e+00, -7.6429e-02],\n",
            "        [-1.1090e+00,  1.4891e+00, -4.5939e-01],\n",
            "        [-1.0054e+00,  1.3985e+00, -9.1941e-01],\n",
            "        [ 4.0699e-01,  2.5526e-03, -1.0234e+00],\n",
            "        [-1.0878e+00,  1.7974e+00, -7.2944e-01],\n",
            "        [-2.0271e+00, -1.8129e-03,  1.6829e+00],\n",
            "        [-1.7350e+00,  8.6226e-01,  8.4085e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.3042e+00,  3.8154e-02,  1.4723e+00],\n",
            "        [-1.3766e+00,  1.6980e+00, -5.0230e-01],\n",
            "        [-1.4006e+00,  1.4478e+00, -3.7470e-01],\n",
            "        [-1.5776e+00,  4.9251e-02,  1.2136e+00],\n",
            "        [-1.8201e+00,  1.9408e-01,  1.4369e+00],\n",
            "        [ 4.2648e-01,  1.9317e-01, -9.5834e-01],\n",
            "        [-1.2188e+00,  1.4496e+00, -6.1818e-01],\n",
            "        [-1.0883e+00,  1.8338e+00, -8.2992e-01],\n",
            "        [-1.0607e+00,  1.6011e+00, -8.5876e-01],\n",
            "        [-1.6975e+00,  1.5476e+00, -7.6429e-02],\n",
            "        [-1.1090e+00,  1.4891e+00, -4.5939e-01],\n",
            "        [-1.0054e+00,  1.3985e+00, -9.1941e-01],\n",
            "        [ 4.0699e-01,  2.5526e-03, -1.0234e+00],\n",
            "        [-1.0878e+00,  1.7974e+00, -7.2944e-01],\n",
            "        [-2.0271e+00, -1.8129e-03,  1.6829e+00],\n",
            "        [-1.7350e+00,  8.6226e-01,  8.4085e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9671,  0.0831,  1.2752],\n",
            "        [-0.7182, -0.1161,  0.5457],\n",
            "        [-1.3961,  1.3861, -0.2833],\n",
            "        [ 0.6834, -0.1178, -0.7958],\n",
            "        [-1.2357,  1.6892, -0.5152],\n",
            "        [-1.8306,  0.1648,  1.4271],\n",
            "        [-1.9811,  0.0641,  1.4506],\n",
            "        [-1.1176,  1.6245, -0.5046],\n",
            "        [-2.1111,  0.5011,  1.4621],\n",
            "        [-1.1038,  1.3968, -0.6593],\n",
            "        [-1.8535,  0.9896,  0.2404],\n",
            "        [-1.2898,  1.8157, -0.7248],\n",
            "        [-1.9341,  0.0955,  1.4808],\n",
            "        [-1.3634,  1.8056, -0.6491],\n",
            "        [ 0.3751, -0.2073, -0.7555],\n",
            "        [-2.0060,  0.2108,  1.6685]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9671,  0.0831,  1.2752],\n",
            "        [-0.7182, -0.1161,  0.5457],\n",
            "        [-1.3961,  1.3861, -0.2833],\n",
            "        [ 0.6834, -0.1178, -0.7958],\n",
            "        [-1.2357,  1.6892, -0.5152],\n",
            "        [-1.8306,  0.1648,  1.4271],\n",
            "        [-1.9811,  0.0641,  1.4506],\n",
            "        [-1.1176,  1.6245, -0.5046],\n",
            "        [-2.1111,  0.5011,  1.4621],\n",
            "        [-1.1038,  1.3968, -0.6593],\n",
            "        [-1.8535,  0.9896,  0.2404],\n",
            "        [-1.2898,  1.8157, -0.7248],\n",
            "        [-1.9341,  0.0955,  1.4808],\n",
            "        [-1.3634,  1.8056, -0.6491],\n",
            "        [ 0.3751, -0.2073, -0.7555],\n",
            "        [-2.0060,  0.2108,  1.6685]], grad_fn=<AddmmBackward0>)\n",
            "Epoch 2/3, Loss: 0.6025\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4193,  1.7030, -0.6536],\n",
            "        [-2.1103,  0.2947,  1.4580],\n",
            "        [-1.4710,  1.7076, -0.6102],\n",
            "        [-1.2073,  1.7804, -0.8777],\n",
            "        [-1.5131,  1.7694, -0.4873],\n",
            "        [-0.9811,  0.0109,  0.3823],\n",
            "        [-1.3377,  1.6726, -0.5325],\n",
            "        [-1.3490,  1.4266, -0.5032],\n",
            "        [-1.5182,  1.6899, -0.6127],\n",
            "        [-1.1671,  1.6608, -0.9529],\n",
            "        [-0.9427,  1.4583, -0.8423],\n",
            "        [-2.0271,  0.2098,  1.5688],\n",
            "        [-1.1574,  1.5486, -0.5985],\n",
            "        [-1.7703,  0.3657,  1.3405],\n",
            "        [-1.9578,  0.7924,  1.1799],\n",
            "        [-1.2351,  1.7214, -0.6795]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4193,  1.7030, -0.6536],\n",
            "        [-2.1103,  0.2947,  1.4580],\n",
            "        [-1.4710,  1.7076, -0.6102],\n",
            "        [-1.2073,  1.7804, -0.8777],\n",
            "        [-1.5131,  1.7694, -0.4873],\n",
            "        [-0.9811,  0.0109,  0.3823],\n",
            "        [-1.3377,  1.6726, -0.5325],\n",
            "        [-1.3490,  1.4266, -0.5032],\n",
            "        [-1.5182,  1.6899, -0.6127],\n",
            "        [-1.1671,  1.6608, -0.9529],\n",
            "        [-0.9427,  1.4583, -0.8423],\n",
            "        [-2.0271,  0.2098,  1.5688],\n",
            "        [-1.1574,  1.5486, -0.5985],\n",
            "        [-1.7703,  0.3657,  1.3405],\n",
            "        [-1.9578,  0.7924,  1.1799],\n",
            "        [-1.2351,  1.7214, -0.6795]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3215, -0.1050, -0.7276],\n",
            "        [-1.5160,  1.6485, -0.4672],\n",
            "        [-0.9540,  1.8687, -0.9279],\n",
            "        [-1.3259,  1.7395, -0.6482],\n",
            "        [-1.8902,  0.3401,  1.1044],\n",
            "        [-1.9305,  0.3032,  1.1931],\n",
            "        [-2.1630,  0.1831,  1.3141],\n",
            "        [-1.2888,  1.9189, -1.0127],\n",
            "        [-1.6834,  1.2513,  0.0231],\n",
            "        [ 0.5552, -0.0612, -0.9427],\n",
            "        [-1.2663,  1.4467, -0.4704],\n",
            "        [-1.2656,  1.7309, -0.6110],\n",
            "        [-1.1962,  1.8669, -0.7640],\n",
            "        [-1.0402, -0.0901,  0.7562],\n",
            "        [-2.1294,  0.0579,  1.4900],\n",
            "        [-1.3212,  1.7280, -0.8597]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.3215, -0.1050, -0.7276],\n",
            "        [-1.5160,  1.6485, -0.4672],\n",
            "        [-0.9540,  1.8687, -0.9279],\n",
            "        [-1.3259,  1.7395, -0.6482],\n",
            "        [-1.8902,  0.3401,  1.1044],\n",
            "        [-1.9305,  0.3032,  1.1931],\n",
            "        [-2.1630,  0.1831,  1.3141],\n",
            "        [-1.2888,  1.9189, -1.0127],\n",
            "        [-1.6834,  1.2513,  0.0231],\n",
            "        [ 0.5552, -0.0612, -0.9427],\n",
            "        [-1.2663,  1.4467, -0.4704],\n",
            "        [-1.2656,  1.7309, -0.6110],\n",
            "        [-1.1962,  1.8669, -0.7640],\n",
            "        [-1.0402, -0.0901,  0.7562],\n",
            "        [-2.1294,  0.0579,  1.4900],\n",
            "        [-1.3212,  1.7280, -0.8597]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1420,  0.6529,  1.1286],\n",
            "        [-1.2963,  1.7953, -0.6443],\n",
            "        [-1.0458,  1.7629, -0.7777],\n",
            "        [-1.8383,  1.0094,  0.5796],\n",
            "        [-1.9792,  0.3698,  1.4376],\n",
            "        [-1.3293,  1.5248, -1.0041],\n",
            "        [-0.8927, -0.0396,  0.3517],\n",
            "        [-1.4158,  1.1723,  0.0664],\n",
            "        [ 0.5724, -0.2939, -0.8349],\n",
            "        [-2.0433,  0.5499,  1.4244],\n",
            "        [-1.0249,  1.6521, -0.7574],\n",
            "        [ 0.1162,  0.5346, -1.1294],\n",
            "        [-2.0568,  0.2867,  1.4502],\n",
            "        [-1.2270,  1.8765, -0.8393],\n",
            "        [-1.0278,  1.6500, -0.8996],\n",
            "        [-1.1958,  1.8031, -0.9843]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1420,  0.6529,  1.1286],\n",
            "        [-1.2963,  1.7953, -0.6443],\n",
            "        [-1.0458,  1.7629, -0.7777],\n",
            "        [-1.8383,  1.0094,  0.5796],\n",
            "        [-1.9792,  0.3698,  1.4376],\n",
            "        [-1.3293,  1.5248, -1.0041],\n",
            "        [-0.8927, -0.0396,  0.3517],\n",
            "        [-1.4158,  1.1723,  0.0664],\n",
            "        [ 0.5724, -0.2939, -0.8349],\n",
            "        [-2.0433,  0.5499,  1.4244],\n",
            "        [-1.0249,  1.6521, -0.7574],\n",
            "        [ 0.1162,  0.5346, -1.1294],\n",
            "        [-2.0568,  0.2867,  1.4502],\n",
            "        [-1.2270,  1.8765, -0.8393],\n",
            "        [-1.0278,  1.6500, -0.8996],\n",
            "        [-1.1958,  1.8031, -0.9843]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2858,  1.6692, -0.7251],\n",
            "        [-1.1690,  1.7031, -0.6376],\n",
            "        [-2.0482,  0.2066,  1.4962],\n",
            "        [-1.1821,  1.8519, -0.7978],\n",
            "        [-1.3911,  1.7470, -0.4273],\n",
            "        [-1.5696,  0.0825,  0.9101],\n",
            "        [-1.8945,  0.8104,  0.7467],\n",
            "        [-1.4592,  1.6309, -0.4525],\n",
            "        [-1.3435,  1.7631, -0.5904],\n",
            "        [-1.4505,  1.6917, -0.5725],\n",
            "        [-1.9390,  0.3007,  1.4243],\n",
            "        [-1.2595,  1.5524, -0.6703],\n",
            "        [-1.1367,  1.7296, -0.7673],\n",
            "        [-2.1466,  0.2510,  1.4693],\n",
            "        [ 0.7237, -0.3840, -0.7992],\n",
            "        [-1.2346,  1.4716, -0.8086]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2858,  1.6692, -0.7251],\n",
            "        [-1.1690,  1.7031, -0.6376],\n",
            "        [-2.0482,  0.2066,  1.4962],\n",
            "        [-1.1821,  1.8519, -0.7978],\n",
            "        [-1.3911,  1.7470, -0.4273],\n",
            "        [-1.5696,  0.0825,  0.9101],\n",
            "        [-1.8945,  0.8104,  0.7467],\n",
            "        [-1.4592,  1.6309, -0.4525],\n",
            "        [-1.3435,  1.7631, -0.5904],\n",
            "        [-1.4505,  1.6917, -0.5725],\n",
            "        [-1.9390,  0.3007,  1.4243],\n",
            "        [-1.2595,  1.5524, -0.6703],\n",
            "        [-1.1367,  1.7296, -0.7673],\n",
            "        [-2.1466,  0.2510,  1.4693],\n",
            "        [ 0.7237, -0.3840, -0.7992],\n",
            "        [-1.2346,  1.4716, -0.8086]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0333,  0.3777,  1.4873],\n",
            "        [-1.4523,  1.7751, -0.4240],\n",
            "        [-2.2066,  0.4378,  1.2802],\n",
            "        [-1.9870,  0.6007,  1.0013],\n",
            "        [-1.4423,  1.5531, -0.7264],\n",
            "        [-1.3140,  1.6514, -0.7911],\n",
            "        [-1.2970,  1.7902, -0.4408],\n",
            "        [-1.3006,  1.8157, -0.8323],\n",
            "        [-1.3864,  1.5924, -0.6956],\n",
            "        [-1.3294,  1.5297, -0.4421],\n",
            "        [-2.2106,  0.3760,  1.4325],\n",
            "        [-1.3282,  1.6083, -0.3460],\n",
            "        [-1.1282,  1.8306, -0.8594],\n",
            "        [-1.2310,  1.5429, -0.6563],\n",
            "        [-1.0923,  1.6308, -1.0819],\n",
            "        [-2.1352,  0.3980,  1.4441]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0333,  0.3777,  1.4873],\n",
            "        [-1.4523,  1.7751, -0.4240],\n",
            "        [-2.2066,  0.4378,  1.2802],\n",
            "        [-1.9870,  0.6007,  1.0013],\n",
            "        [-1.4423,  1.5531, -0.7264],\n",
            "        [-1.3140,  1.6514, -0.7911],\n",
            "        [-1.2970,  1.7902, -0.4408],\n",
            "        [-1.3006,  1.8157, -0.8323],\n",
            "        [-1.3864,  1.5924, -0.6956],\n",
            "        [-1.3294,  1.5297, -0.4421],\n",
            "        [-2.2106,  0.3760,  1.4325],\n",
            "        [-1.3282,  1.6083, -0.3460],\n",
            "        [-1.1282,  1.8306, -0.8594],\n",
            "        [-1.2310,  1.5429, -0.6563],\n",
            "        [-1.0923,  1.6308, -1.0819],\n",
            "        [-2.1352,  0.3980,  1.4441]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.6262, -0.3082, -0.8915],\n",
            "        [-1.1986,  1.7466, -1.0105],\n",
            "        [-1.4192,  1.7318, -0.7946],\n",
            "        [-1.9039,  1.0298,  0.7750],\n",
            "        [-1.1259,  1.6442, -0.8734],\n",
            "        [-2.0452,  0.3767,  1.5661],\n",
            "        [-1.9245,  1.1106,  0.5016],\n",
            "        [-1.8586,  0.5137,  1.0473],\n",
            "        [-2.0207,  0.5112,  1.4096],\n",
            "        [-2.0695,  0.3015,  1.5073],\n",
            "        [-1.8694,  0.2872,  1.2784],\n",
            "        [ 0.5435, -0.3213, -0.8238],\n",
            "        [-1.3609,  1.7283, -0.7257],\n",
            "        [-1.0696,  1.5190, -0.5513],\n",
            "        [-1.2768,  1.6888, -0.7544],\n",
            "        [-1.0964,  1.5243, -0.7460]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.6262, -0.3082, -0.8915],\n",
            "        [-1.1986,  1.7466, -1.0105],\n",
            "        [-1.4192,  1.7318, -0.7946],\n",
            "        [-1.9039,  1.0298,  0.7750],\n",
            "        [-1.1259,  1.6442, -0.8734],\n",
            "        [-2.0452,  0.3767,  1.5661],\n",
            "        [-1.9245,  1.1106,  0.5016],\n",
            "        [-1.8586,  0.5137,  1.0473],\n",
            "        [-2.0207,  0.5112,  1.4096],\n",
            "        [-2.0695,  0.3015,  1.5073],\n",
            "        [-1.8694,  0.2872,  1.2784],\n",
            "        [ 0.5435, -0.3213, -0.8238],\n",
            "        [-1.3609,  1.7283, -0.7257],\n",
            "        [-1.0696,  1.5190, -0.5513],\n",
            "        [-1.2768,  1.6888, -0.7544],\n",
            "        [-1.0964,  1.5243, -0.7460]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1373,  0.4479,  1.5177],\n",
            "        [-1.1484,  1.8409, -0.8009],\n",
            "        [-1.9507,  0.3418,  1.2717],\n",
            "        [-1.3158,  1.8213, -0.7974],\n",
            "        [ 0.6009, -0.1810, -0.6746],\n",
            "        [-1.8285,  0.4584,  1.3962],\n",
            "        [-1.9139,  0.4501,  1.0555],\n",
            "        [-2.0569,  0.3693,  1.3207],\n",
            "        [ 0.4380, -0.1808, -0.6895],\n",
            "        [-1.2788,  1.7255, -0.9043],\n",
            "        [ 0.7008, -0.3931, -0.8887],\n",
            "        [-1.5224,  1.7598, -0.1498],\n",
            "        [-1.3301,  1.8159, -0.9121],\n",
            "        [ 0.6954, -0.0645, -0.7215],\n",
            "        [-1.3147,  1.7558, -0.6399],\n",
            "        [-1.4028,  1.9153, -0.7932]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1373,  0.4479,  1.5177],\n",
            "        [-1.1484,  1.8409, -0.8009],\n",
            "        [-1.9507,  0.3418,  1.2717],\n",
            "        [-1.3158,  1.8213, -0.7974],\n",
            "        [ 0.6009, -0.1810, -0.6746],\n",
            "        [-1.8285,  0.4584,  1.3962],\n",
            "        [-1.9139,  0.4501,  1.0555],\n",
            "        [-2.0569,  0.3693,  1.3207],\n",
            "        [ 0.4380, -0.1808, -0.6895],\n",
            "        [-1.2788,  1.7255, -0.9043],\n",
            "        [ 0.7008, -0.3931, -0.8887],\n",
            "        [-1.5224,  1.7598, -0.1498],\n",
            "        [-1.3301,  1.8159, -0.9121],\n",
            "        [ 0.6954, -0.0645, -0.7215],\n",
            "        [-1.3147,  1.7558, -0.6399],\n",
            "        [-1.4028,  1.9153, -0.7932]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.7368, -0.2514, -0.7886],\n",
            "        [-1.4682,  1.8094, -0.7191],\n",
            "        [-1.9540,  0.4839,  1.4685],\n",
            "        [ 0.5518, -0.2844, -0.9409],\n",
            "        [ 0.6507, -0.2725, -0.8077],\n",
            "        [-1.8640,  0.2733,  1.3482],\n",
            "        [-1.3363,  1.7933, -0.7910],\n",
            "        [ 0.6194, -0.1045, -0.8543],\n",
            "        [-2.1211,  0.4676,  1.3724],\n",
            "        [-1.8771,  0.3977,  1.0392],\n",
            "        [-1.4508,  1.6778, -0.6758],\n",
            "        [-1.0436,  1.5639, -0.6116],\n",
            "        [-1.1399,  1.8085, -0.6934],\n",
            "        [-1.1501,  1.7785, -0.7104],\n",
            "        [-1.3214,  1.8671, -0.8247],\n",
            "        [ 0.6447, -0.2470, -0.9796]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.7368, -0.2514, -0.7886],\n",
            "        [-1.4682,  1.8094, -0.7191],\n",
            "        [-1.9540,  0.4839,  1.4685],\n",
            "        [ 0.5518, -0.2844, -0.9409],\n",
            "        [ 0.6507, -0.2725, -0.8077],\n",
            "        [-1.8640,  0.2733,  1.3482],\n",
            "        [-1.3363,  1.7933, -0.7910],\n",
            "        [ 0.6194, -0.1045, -0.8543],\n",
            "        [-2.1211,  0.4676,  1.3724],\n",
            "        [-1.8771,  0.3977,  1.0392],\n",
            "        [-1.4508,  1.6778, -0.6758],\n",
            "        [-1.0436,  1.5639, -0.6116],\n",
            "        [-1.1399,  1.8085, -0.6934],\n",
            "        [-1.1501,  1.7785, -0.7104],\n",
            "        [-1.3214,  1.8671, -0.8247],\n",
            "        [ 0.6447, -0.2470, -0.9796]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.1604,  1.5758, -0.4697],\n",
            "        [-1.4604,  1.4518, -0.2132],\n",
            "        [-1.9131,  0.4069,  1.2456],\n",
            "        [-1.5920,  1.3860, -0.0509],\n",
            "        [-1.7651,  0.4934,  1.1461],\n",
            "        [ 0.7854, -0.3526, -0.7726],\n",
            "        [ 0.5834, -0.4536, -0.7747],\n",
            "        [-2.1661,  0.2538,  1.5007],\n",
            "        [-1.1991,  1.7350, -0.7124],\n",
            "        [-2.0541,  0.5141,  1.2024],\n",
            "        [-1.2068,  1.5147, -0.6151],\n",
            "        [-1.9579,  0.7493,  1.1367],\n",
            "        [-1.2042,  2.0086, -0.8534],\n",
            "        [-1.2655,  1.7756, -0.7067],\n",
            "        [-1.2958,  1.7068, -0.9810],\n",
            "        [-2.0214,  0.4281,  1.4194]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.1604,  1.5758, -0.4697],\n",
            "        [-1.4604,  1.4518, -0.2132],\n",
            "        [-1.9131,  0.4069,  1.2456],\n",
            "        [-1.5920,  1.3860, -0.0509],\n",
            "        [-1.7651,  0.4934,  1.1461],\n",
            "        [ 0.7854, -0.3526, -0.7726],\n",
            "        [ 0.5834, -0.4536, -0.7747],\n",
            "        [-2.1661,  0.2538,  1.5007],\n",
            "        [-1.1991,  1.7350, -0.7124],\n",
            "        [-2.0541,  0.5141,  1.2024],\n",
            "        [-1.2068,  1.5147, -0.6151],\n",
            "        [-1.9579,  0.7493,  1.1367],\n",
            "        [-1.2042,  2.0086, -0.8534],\n",
            "        [-1.2655,  1.7756, -0.7067],\n",
            "        [-1.2958,  1.7068, -0.9810],\n",
            "        [-2.0214,  0.4281,  1.4194]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2149,  1.7957, -0.6428],\n",
            "        [-1.1115,  1.6936, -0.7613],\n",
            "        [-1.8736,  0.3318,  1.3068],\n",
            "        [-2.1986,  0.4255,  1.4362],\n",
            "        [ 0.7270, -0.4412, -0.7124],\n",
            "        [-2.0109,  0.9417,  1.0271],\n",
            "        [-0.6607,  1.3085, -0.8623],\n",
            "        [-2.1528,  0.4799,  1.3860],\n",
            "        [ 0.4379, -0.2807, -0.7665],\n",
            "        [-2.0073,  0.6369,  1.1659],\n",
            "        [-1.4302,  1.6993, -0.6555],\n",
            "        [-1.4681,  1.8133, -0.5912],\n",
            "        [-1.9337,  0.4074,  1.1424],\n",
            "        [-1.2658,  1.7630, -0.8068],\n",
            "        [-1.8273,  0.4274,  1.2402],\n",
            "        [-1.3074,  1.5893, -0.7164]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2149,  1.7957, -0.6428],\n",
            "        [-1.1115,  1.6936, -0.7613],\n",
            "        [-1.8736,  0.3318,  1.3068],\n",
            "        [-2.1986,  0.4255,  1.4362],\n",
            "        [ 0.7270, -0.4412, -0.7124],\n",
            "        [-2.0109,  0.9417,  1.0271],\n",
            "        [-0.6607,  1.3085, -0.8623],\n",
            "        [-2.1528,  0.4799,  1.3860],\n",
            "        [ 0.4379, -0.2807, -0.7665],\n",
            "        [-2.0073,  0.6369,  1.1659],\n",
            "        [-1.4302,  1.6993, -0.6555],\n",
            "        [-1.4681,  1.8133, -0.5912],\n",
            "        [-1.9337,  0.4074,  1.1424],\n",
            "        [-1.2658,  1.7630, -0.8068],\n",
            "        [-1.8273,  0.4274,  1.2402],\n",
            "        [-1.3074,  1.5893, -0.7164]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5962,  1.7650, -0.3852],\n",
            "        [-1.2774,  1.8375, -0.5346],\n",
            "        [-1.5231,  1.6467, -0.3811],\n",
            "        [-1.3662,  1.6485, -0.6822],\n",
            "        [-2.0559,  0.5550,  1.3851],\n",
            "        [ 0.6828, -0.1133, -0.9840],\n",
            "        [-1.1888,  1.6961, -0.6406],\n",
            "        [-0.7322,  0.8383, -0.5616],\n",
            "        [-2.2230,  0.5302,  1.5322],\n",
            "        [-0.8669,  1.4624, -0.7470],\n",
            "        [-1.3801,  1.7099, -0.5405],\n",
            "        [-1.9118,  0.6050,  1.3296],\n",
            "        [ 0.7982, -0.3050, -0.8577],\n",
            "        [-2.1140,  0.5621,  1.5388],\n",
            "        [-1.2846,  1.7164, -0.5174],\n",
            "        [-1.5716,  1.5798, -0.3204]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5962,  1.7650, -0.3852],\n",
            "        [-1.2774,  1.8375, -0.5346],\n",
            "        [-1.5231,  1.6467, -0.3811],\n",
            "        [-1.3662,  1.6485, -0.6822],\n",
            "        [-2.0559,  0.5550,  1.3851],\n",
            "        [ 0.6828, -0.1133, -0.9840],\n",
            "        [-1.1888,  1.6961, -0.6406],\n",
            "        [-0.7322,  0.8383, -0.5616],\n",
            "        [-2.2230,  0.5302,  1.5322],\n",
            "        [-0.8669,  1.4624, -0.7470],\n",
            "        [-1.3801,  1.7099, -0.5405],\n",
            "        [-1.9118,  0.6050,  1.3296],\n",
            "        [ 0.7982, -0.3050, -0.8577],\n",
            "        [-2.1140,  0.5621,  1.5388],\n",
            "        [-1.2846,  1.7164, -0.5174],\n",
            "        [-1.5716,  1.5798, -0.3204]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4306,  1.5204, -0.4995],\n",
            "        [-1.4420,  1.7929, -0.4948],\n",
            "        [-0.6701,  0.8398, -0.8244],\n",
            "        [-1.1726,  1.7416, -0.6725],\n",
            "        [-1.4229,  1.9781, -0.7813],\n",
            "        [-1.1424,  1.4169, -0.6506],\n",
            "        [-1.4270,  1.7264, -0.7390],\n",
            "        [-1.8998,  1.3429, -0.0032],\n",
            "        [-2.1694,  0.6026,  1.1514],\n",
            "        [-1.9698,  0.5221,  1.2609],\n",
            "        [-1.2771,  1.6531, -0.7687],\n",
            "        [-1.4095,  1.9188, -0.6695],\n",
            "        [-2.1134,  0.5665,  1.2296],\n",
            "        [-1.9726,  1.0234,  0.9855],\n",
            "        [-0.9174,  1.3142, -0.7974],\n",
            "        [ 0.7683, -0.3470, -0.9094]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4306,  1.5204, -0.4995],\n",
            "        [-1.4420,  1.7929, -0.4948],\n",
            "        [-0.6701,  0.8398, -0.8244],\n",
            "        [-1.1726,  1.7416, -0.6725],\n",
            "        [-1.4229,  1.9781, -0.7813],\n",
            "        [-1.1424,  1.4169, -0.6506],\n",
            "        [-1.4270,  1.7264, -0.7390],\n",
            "        [-1.8998,  1.3429, -0.0032],\n",
            "        [-2.1694,  0.6026,  1.1514],\n",
            "        [-1.9698,  0.5221,  1.2609],\n",
            "        [-1.2771,  1.6531, -0.7687],\n",
            "        [-1.4095,  1.9188, -0.6695],\n",
            "        [-2.1134,  0.5665,  1.2296],\n",
            "        [-1.9726,  1.0234,  0.9855],\n",
            "        [-0.9174,  1.3142, -0.7974],\n",
            "        [ 0.7683, -0.3470, -0.9094]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2190,  1.6586, -0.4684],\n",
            "        [-1.8530,  0.8523,  0.8957],\n",
            "        [-1.4466,  1.9768, -0.5814],\n",
            "        [-1.7205,  1.3339,  0.6159],\n",
            "        [-1.4669,  1.8014, -0.7907],\n",
            "        [-1.4407,  1.6794, -0.6248],\n",
            "        [-2.0567,  0.3152,  1.3019],\n",
            "        [-1.9304,  0.7957,  0.7721],\n",
            "        [-1.5539,  1.9375, -0.6063],\n",
            "        [-1.3999,  1.8069, -0.5477],\n",
            "        [-1.6090,  1.6335, -0.2621],\n",
            "        [-1.9092,  1.7136,  0.0443],\n",
            "        [-2.0392,  0.5226,  1.1931],\n",
            "        [-1.4118,  1.7887, -0.6635],\n",
            "        [-1.6925,  1.5091,  0.1001],\n",
            "        [-1.6997,  1.1364,  0.3555]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2190,  1.6586, -0.4684],\n",
            "        [-1.8530,  0.8523,  0.8957],\n",
            "        [-1.4466,  1.9768, -0.5814],\n",
            "        [-1.7205,  1.3339,  0.6159],\n",
            "        [-1.4669,  1.8014, -0.7907],\n",
            "        [-1.4407,  1.6794, -0.6248],\n",
            "        [-2.0567,  0.3152,  1.3019],\n",
            "        [-1.9304,  0.7957,  0.7721],\n",
            "        [-1.5539,  1.9375, -0.6063],\n",
            "        [-1.3999,  1.8069, -0.5477],\n",
            "        [-1.6090,  1.6335, -0.2621],\n",
            "        [-1.9092,  1.7136,  0.0443],\n",
            "        [-2.0392,  0.5226,  1.1931],\n",
            "        [-1.4118,  1.7887, -0.6635],\n",
            "        [-1.6925,  1.5091,  0.1001],\n",
            "        [-1.6997,  1.1364,  0.3555]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2599,  1.4752, -0.5720],\n",
            "        [-1.3456,  1.6753, -0.5531],\n",
            "        [-1.2688,  1.7588, -0.7398],\n",
            "        [-1.4809,  1.8623, -0.6566],\n",
            "        [-2.0323,  0.6233,  1.1499],\n",
            "        [-1.3625,  1.8436, -0.7152],\n",
            "        [-1.2607,  1.7442, -0.6945],\n",
            "        [-1.8149,  1.6112, -0.3281],\n",
            "        [-1.3670,  1.6033, -0.6387],\n",
            "        [-1.2732,  1.7337, -0.6394],\n",
            "        [-1.4566,  1.8678, -0.5779],\n",
            "        [-1.4924,  1.8932, -0.4952],\n",
            "        [-2.3039,  0.4315,  1.3017],\n",
            "        [-1.5370,  1.4493, -0.1903],\n",
            "        [-1.6345,  1.2518, -0.0335],\n",
            "        [-1.2555,  1.7938, -0.5573]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2599,  1.4752, -0.5720],\n",
            "        [-1.3456,  1.6753, -0.5531],\n",
            "        [-1.2688,  1.7588, -0.7398],\n",
            "        [-1.4809,  1.8623, -0.6566],\n",
            "        [-2.0323,  0.6233,  1.1499],\n",
            "        [-1.3625,  1.8436, -0.7152],\n",
            "        [-1.2607,  1.7442, -0.6945],\n",
            "        [-1.8149,  1.6112, -0.3281],\n",
            "        [-1.3670,  1.6033, -0.6387],\n",
            "        [-1.2732,  1.7337, -0.6394],\n",
            "        [-1.4566,  1.8678, -0.5779],\n",
            "        [-1.4924,  1.8932, -0.4952],\n",
            "        [-2.3039,  0.4315,  1.3017],\n",
            "        [-1.5370,  1.4493, -0.1903],\n",
            "        [-1.6345,  1.2518, -0.0335],\n",
            "        [-1.2555,  1.7938, -0.5573]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3847,  1.7516, -0.5161],\n",
            "        [-2.0285,  0.5768,  1.1857],\n",
            "        [-2.1550,  0.5645,  1.1593],\n",
            "        [-1.5296,  1.9707, -0.5775],\n",
            "        [-1.3238,  1.6970, -0.4927],\n",
            "        [-1.6580,  0.3815,  1.0555],\n",
            "        [-2.0154,  0.6318,  1.2055],\n",
            "        [ 0.1850,  0.4126, -0.9949],\n",
            "        [-1.4644,  1.6642, -0.5766],\n",
            "        [ 0.7612, -0.3464, -0.7993],\n",
            "        [-1.4476,  1.4108, -0.4335],\n",
            "        [-1.4367,  1.8615, -0.4416],\n",
            "        [-2.0104,  0.6431,  1.2234],\n",
            "        [-1.7094,  1.4407, -0.0457],\n",
            "        [-1.4057,  1.7141, -0.3004],\n",
            "        [-2.1015,  0.5759,  1.4149]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3847,  1.7516, -0.5161],\n",
            "        [-2.0285,  0.5768,  1.1857],\n",
            "        [-2.1550,  0.5645,  1.1593],\n",
            "        [-1.5296,  1.9707, -0.5775],\n",
            "        [-1.3238,  1.6970, -0.4927],\n",
            "        [-1.6580,  0.3815,  1.0555],\n",
            "        [-2.0154,  0.6318,  1.2055],\n",
            "        [ 0.1850,  0.4126, -0.9949],\n",
            "        [-1.4644,  1.6642, -0.5766],\n",
            "        [ 0.7612, -0.3464, -0.7993],\n",
            "        [-1.4476,  1.4108, -0.4335],\n",
            "        [-1.4367,  1.8615, -0.4416],\n",
            "        [-2.0104,  0.6431,  1.2234],\n",
            "        [-1.7094,  1.4407, -0.0457],\n",
            "        [-1.4057,  1.7141, -0.3004],\n",
            "        [-2.1015,  0.5759,  1.4149]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0257,  0.5464,  1.1653],\n",
            "        [ 0.6244, -0.2142, -0.9198],\n",
            "        [-2.0470,  0.5035,  1.1766],\n",
            "        [-2.2781,  0.6355,  1.3383],\n",
            "        [ 0.6991, -0.1208, -0.9891],\n",
            "        [-2.0724,  0.6600,  1.1435],\n",
            "        [ 0.7679, -0.3123, -0.9527],\n",
            "        [-2.1178,  0.5060,  1.3095],\n",
            "        [-2.0189,  0.5533,  1.2639],\n",
            "        [-1.4787,  1.8234, -0.4852],\n",
            "        [-1.4984,  1.7165, -0.3856],\n",
            "        [-1.7601,  1.4960, -0.0806],\n",
            "        [-1.9809,  0.5152,  1.1877],\n",
            "        [-1.4722,  1.9971, -0.6124],\n",
            "        [-2.0814,  0.5980,  1.1023],\n",
            "        [-1.5510,  1.8658, -0.4876]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0257,  0.5464,  1.1653],\n",
            "        [ 0.6244, -0.2142, -0.9198],\n",
            "        [-2.0470,  0.5035,  1.1766],\n",
            "        [-2.2781,  0.6355,  1.3383],\n",
            "        [ 0.6991, -0.1208, -0.9891],\n",
            "        [-2.0724,  0.6600,  1.1435],\n",
            "        [ 0.7679, -0.3123, -0.9527],\n",
            "        [-2.1178,  0.5060,  1.3095],\n",
            "        [-2.0189,  0.5533,  1.2639],\n",
            "        [-1.4787,  1.8234, -0.4852],\n",
            "        [-1.4984,  1.7165, -0.3856],\n",
            "        [-1.7601,  1.4960, -0.0806],\n",
            "        [-1.9809,  0.5152,  1.1877],\n",
            "        [-1.4722,  1.9971, -0.6124],\n",
            "        [-2.0814,  0.5980,  1.1023],\n",
            "        [-1.5510,  1.8658, -0.4876]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5232,  1.7964, -0.5475],\n",
            "        [-1.4949,  0.2801,  1.0300],\n",
            "        [-2.1501,  0.6201,  1.2047],\n",
            "        [-2.1760,  0.3323,  1.3087],\n",
            "        [-1.9375,  1.4197,  0.5801],\n",
            "        [-1.6275,  1.7997, -0.3442],\n",
            "        [-1.4634,  1.8682, -0.2891],\n",
            "        [-1.6892,  1.7677, -0.2338],\n",
            "        [ 0.7392, -0.3949, -0.7982],\n",
            "        [-2.0941,  0.4307,  1.1244],\n",
            "        [-1.5671,  1.8430, -0.4915],\n",
            "        [-1.5453,  1.8312, -0.4098],\n",
            "        [-1.3453,  0.1008,  0.7827],\n",
            "        [-1.4684,  1.7660, -0.6294],\n",
            "        [-2.0850,  0.4072,  1.0519],\n",
            "        [-1.5939,  1.5793, -0.2857]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5232,  1.7964, -0.5475],\n",
            "        [-1.4949,  0.2801,  1.0300],\n",
            "        [-2.1501,  0.6201,  1.2047],\n",
            "        [-2.1760,  0.3323,  1.3087],\n",
            "        [-1.9375,  1.4197,  0.5801],\n",
            "        [-1.6275,  1.7997, -0.3442],\n",
            "        [-1.4634,  1.8682, -0.2891],\n",
            "        [-1.6892,  1.7677, -0.2338],\n",
            "        [ 0.7392, -0.3949, -0.7982],\n",
            "        [-2.0941,  0.4307,  1.1244],\n",
            "        [-1.5671,  1.8430, -0.4915],\n",
            "        [-1.5453,  1.8312, -0.4098],\n",
            "        [-1.3453,  0.1008,  0.7827],\n",
            "        [-1.4684,  1.7660, -0.6294],\n",
            "        [-2.0850,  0.4072,  1.0519],\n",
            "        [-1.5939,  1.5793, -0.2857]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4035,  1.5301, -0.2320],\n",
            "        [-2.1661,  0.5599,  1.2322],\n",
            "        [-1.3928,  1.7301, -0.4441],\n",
            "        [-1.6141,  1.6234, -0.3378],\n",
            "        [-1.8504,  0.8374,  0.9522],\n",
            "        [-1.9887,  1.3744,  0.3391],\n",
            "        [-1.3821,  1.6411, -0.6345],\n",
            "        [ 0.6239, -0.1661, -0.9799],\n",
            "        [-1.7109,  1.7092, -0.3920],\n",
            "        [-1.9428,  0.5054,  1.1571],\n",
            "        [ 0.5860, -0.3144, -0.9235],\n",
            "        [-1.9376,  0.5451,  0.9950],\n",
            "        [-1.4217,  1.9934, -0.5309],\n",
            "        [-1.9890,  0.5165,  1.2696],\n",
            "        [-1.8036,  0.5414,  1.2330],\n",
            "        [-1.4370,  1.7664, -0.3086]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4035,  1.5301, -0.2320],\n",
            "        [-2.1661,  0.5599,  1.2322],\n",
            "        [-1.3928,  1.7301, -0.4441],\n",
            "        [-1.6141,  1.6234, -0.3378],\n",
            "        [-1.8504,  0.8374,  0.9522],\n",
            "        [-1.9887,  1.3744,  0.3391],\n",
            "        [-1.3821,  1.6411, -0.6345],\n",
            "        [ 0.6239, -0.1661, -0.9799],\n",
            "        [-1.7109,  1.7092, -0.3920],\n",
            "        [-1.9428,  0.5054,  1.1571],\n",
            "        [ 0.5860, -0.3144, -0.9235],\n",
            "        [-1.9376,  0.5451,  0.9950],\n",
            "        [-1.4217,  1.9934, -0.5309],\n",
            "        [-1.9890,  0.5165,  1.2696],\n",
            "        [-1.8036,  0.5414,  1.2330],\n",
            "        [-1.4370,  1.7664, -0.3086]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9982,  0.5510,  0.7982],\n",
            "        [-2.2990,  0.5463,  1.2648],\n",
            "        [-2.2305,  0.4542,  1.2249],\n",
            "        [-1.8780,  0.5347,  1.1411],\n",
            "        [-1.5535,  1.8575, -0.4452],\n",
            "        [-2.0370,  1.1147,  0.6937],\n",
            "        [ 0.4160, -0.2136, -0.8507],\n",
            "        [-1.6867,  1.8394, -0.5203],\n",
            "        [-1.3267,  1.8309, -0.6165],\n",
            "        [-1.9790,  0.7889,  1.1578],\n",
            "        [-1.4836,  1.7156, -0.6211],\n",
            "        [ 0.1337, -0.1444, -0.3757],\n",
            "        [-1.5070,  1.7467, -0.4373],\n",
            "        [-1.6711,  2.1178, -0.6429],\n",
            "        [-1.9841,  0.4371,  1.2121],\n",
            "        [-1.5093,  1.5866, -0.1736]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9982,  0.5510,  0.7982],\n",
            "        [-2.2990,  0.5463,  1.2648],\n",
            "        [-2.2305,  0.4542,  1.2249],\n",
            "        [-1.8780,  0.5347,  1.1411],\n",
            "        [-1.5535,  1.8575, -0.4452],\n",
            "        [-2.0370,  1.1147,  0.6937],\n",
            "        [ 0.4160, -0.2136, -0.8507],\n",
            "        [-1.6867,  1.8394, -0.5203],\n",
            "        [-1.3267,  1.8309, -0.6165],\n",
            "        [-1.9790,  0.7889,  1.1578],\n",
            "        [-1.4836,  1.7156, -0.6211],\n",
            "        [ 0.1337, -0.1444, -0.3757],\n",
            "        [-1.5070,  1.7467, -0.4373],\n",
            "        [-1.6711,  2.1178, -0.6429],\n",
            "        [-1.9841,  0.4371,  1.2121],\n",
            "        [-1.5093,  1.5866, -0.1736]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6353,  1.7665, -0.4401],\n",
            "        [-1.5507,  1.8226, -0.4199],\n",
            "        [ 0.7607, -0.2781, -0.8645],\n",
            "        [-1.6298,  1.6324, -0.4388],\n",
            "        [-2.2566,  0.4974,  1.2185],\n",
            "        [-1.3530,  1.6484, -0.6168],\n",
            "        [-1.5299,  1.7503, -0.4802],\n",
            "        [-2.1815,  0.4250,  1.1006],\n",
            "        [-1.7228,  1.9581, -0.4734],\n",
            "        [-1.6666,  1.5606, -0.2003],\n",
            "        [-1.4292,  1.7054, -0.4896],\n",
            "        [-1.6544,  1.5933, -0.0922],\n",
            "        [-1.9450,  1.3118,  0.2705],\n",
            "        [-1.5853,  1.6825, -0.5065],\n",
            "        [ 0.6100, -0.4265, -0.9473],\n",
            "        [-2.0992,  0.5941,  1.2276]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6353,  1.7665, -0.4401],\n",
            "        [-1.5507,  1.8226, -0.4199],\n",
            "        [ 0.7607, -0.2781, -0.8645],\n",
            "        [-1.6298,  1.6324, -0.4388],\n",
            "        [-2.2566,  0.4974,  1.2185],\n",
            "        [-1.3530,  1.6484, -0.6168],\n",
            "        [-1.5299,  1.7503, -0.4802],\n",
            "        [-2.1815,  0.4250,  1.1006],\n",
            "        [-1.7228,  1.9581, -0.4734],\n",
            "        [-1.6666,  1.5606, -0.2003],\n",
            "        [-1.4292,  1.7054, -0.4896],\n",
            "        [-1.6544,  1.5933, -0.0922],\n",
            "        [-1.9450,  1.3118,  0.2705],\n",
            "        [-1.5853,  1.6825, -0.5065],\n",
            "        [ 0.6100, -0.4265, -0.9473],\n",
            "        [-2.0992,  0.5941,  1.2276]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0049,  0.7963,  0.7651],\n",
            "        [-1.4467,  1.7358, -0.3487],\n",
            "        [-2.0577,  0.4840,  1.2611],\n",
            "        [-1.6002,  1.6620, -0.2515],\n",
            "        [-2.3116,  1.0965,  0.6646],\n",
            "        [ 0.5982, -0.3555, -0.7313],\n",
            "        [-1.6300,  1.8087, -0.3446],\n",
            "        [ 0.7403, -0.4303, -0.9283],\n",
            "        [-1.4539,  0.3564,  1.0511],\n",
            "        [-1.9217,  1.6717, -0.1172],\n",
            "        [-2.1990,  0.6378,  1.0827],\n",
            "        [-1.9363,  1.8361, -0.3283],\n",
            "        [-1.5200,  1.7375, -0.4727],\n",
            "        [-1.4374,  1.7443, -0.4234],\n",
            "        [-1.8286,  0.4906,  1.3655],\n",
            "        [ 0.7879, -0.2778, -0.7374]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0049,  0.7963,  0.7651],\n",
            "        [-1.4467,  1.7358, -0.3487],\n",
            "        [-2.0577,  0.4840,  1.2611],\n",
            "        [-1.6002,  1.6620, -0.2515],\n",
            "        [-2.3116,  1.0965,  0.6646],\n",
            "        [ 0.5982, -0.3555, -0.7313],\n",
            "        [-1.6300,  1.8087, -0.3446],\n",
            "        [ 0.7403, -0.4303, -0.9283],\n",
            "        [-1.4539,  0.3564,  1.0511],\n",
            "        [-1.9217,  1.6717, -0.1172],\n",
            "        [-2.1990,  0.6378,  1.0827],\n",
            "        [-1.9363,  1.8361, -0.3283],\n",
            "        [-1.5200,  1.7375, -0.4727],\n",
            "        [-1.4374,  1.7443, -0.4234],\n",
            "        [-1.8286,  0.4906,  1.3655],\n",
            "        [ 0.7879, -0.2778, -0.7374]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3348,  1.6955, -0.6426],\n",
            "        [-2.1782,  0.4095,  1.4813],\n",
            "        [-1.7889,  1.9434, -0.7010],\n",
            "        [-2.1253,  0.5270,  1.3665],\n",
            "        [-2.0617,  0.5395,  1.3053],\n",
            "        [ 0.3641, -0.2552, -0.5883],\n",
            "        [-1.7538,  1.7783, -0.1395],\n",
            "        [-1.5308,  2.0882, -0.5548],\n",
            "        [-1.6563,  1.8628, -0.5103],\n",
            "        [-2.0063,  0.6174,  1.2254],\n",
            "        [-1.7141,  1.8444, -0.3877],\n",
            "        [-1.6235,  1.9526, -0.4746],\n",
            "        [-1.4377,  2.0413, -0.5292],\n",
            "        [-2.1157,  0.6476,  1.2421],\n",
            "        [-1.5914,  1.9072, -0.2272],\n",
            "        [ 0.7424, -0.4646, -0.7397]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3348,  1.6955, -0.6426],\n",
            "        [-2.1782,  0.4095,  1.4813],\n",
            "        [-1.7889,  1.9434, -0.7010],\n",
            "        [-2.1253,  0.5270,  1.3665],\n",
            "        [-2.0617,  0.5395,  1.3053],\n",
            "        [ 0.3641, -0.2552, -0.5883],\n",
            "        [-1.7538,  1.7783, -0.1395],\n",
            "        [-1.5308,  2.0882, -0.5548],\n",
            "        [-1.6563,  1.8628, -0.5103],\n",
            "        [-2.0063,  0.6174,  1.2254],\n",
            "        [-1.7141,  1.8444, -0.3877],\n",
            "        [-1.6235,  1.9526, -0.4746],\n",
            "        [-1.4377,  2.0413, -0.5292],\n",
            "        [-2.1157,  0.6476,  1.2421],\n",
            "        [-1.5914,  1.9072, -0.2272],\n",
            "        [ 0.7424, -0.4646, -0.7397]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9209,  0.3994,  1.0837],\n",
            "        [-1.8986,  0.5317,  1.3431],\n",
            "        [-2.0547,  0.5178,  1.2447],\n",
            "        [-1.9609,  0.4499,  1.3386],\n",
            "        [-2.0357,  0.3478,  1.4483],\n",
            "        [-1.3217,  1.5981, -0.3376],\n",
            "        [-1.5283,  2.0152, -0.5797],\n",
            "        [-1.4904,  1.8910, -0.4873],\n",
            "        [ 0.8139, -0.3678, -0.8598],\n",
            "        [-1.8085,  0.3773,  1.2065],\n",
            "        [ 0.4708, -0.2985, -0.8941],\n",
            "        [-1.3824,  1.8495, -0.5157],\n",
            "        [-1.4312,  1.7077, -0.6363],\n",
            "        [-1.4967,  2.0657, -0.7648],\n",
            "        [-1.6317,  1.8410, -0.4164],\n",
            "        [-1.6481,  1.6758, -0.6795]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9209,  0.3994,  1.0837],\n",
            "        [-1.8986,  0.5317,  1.3431],\n",
            "        [-2.0547,  0.5178,  1.2447],\n",
            "        [-1.9609,  0.4499,  1.3386],\n",
            "        [-2.0357,  0.3478,  1.4483],\n",
            "        [-1.3217,  1.5981, -0.3376],\n",
            "        [-1.5283,  2.0152, -0.5797],\n",
            "        [-1.4904,  1.8910, -0.4873],\n",
            "        [ 0.8139, -0.3678, -0.8598],\n",
            "        [-1.8085,  0.3773,  1.2065],\n",
            "        [ 0.4708, -0.2985, -0.8941],\n",
            "        [-1.3824,  1.8495, -0.5157],\n",
            "        [-1.4312,  1.7077, -0.6363],\n",
            "        [-1.4967,  2.0657, -0.7648],\n",
            "        [-1.6317,  1.8410, -0.4164],\n",
            "        [-1.6481,  1.6758, -0.6795]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6406,  1.8667, -0.5540],\n",
            "        [-1.7728,  1.6968, -0.0740],\n",
            "        [-1.5482,  1.8713, -0.5350],\n",
            "        [-1.7828,  1.7373, -0.4733],\n",
            "        [ 0.8248, -0.5385, -0.8313],\n",
            "        [ 0.8318, -0.4196, -0.7507],\n",
            "        [-1.4980,  1.7783, -0.4447],\n",
            "        [-2.0102,  1.0859,  0.3810],\n",
            "        [-1.6357,  1.8293, -0.4278],\n",
            "        [-2.0017,  0.5931,  1.2292],\n",
            "        [ 0.6716, -0.3941, -0.8717],\n",
            "        [-1.7008,  1.8401, -0.4959],\n",
            "        [-1.7226,  1.9423, -0.2800],\n",
            "        [-2.0415,  0.8369,  1.0613],\n",
            "        [-2.0033,  0.4951,  1.1829],\n",
            "        [ 0.9046, -0.4301, -0.8284]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6406,  1.8667, -0.5540],\n",
            "        [-1.7728,  1.6968, -0.0740],\n",
            "        [-1.5482,  1.8713, -0.5350],\n",
            "        [-1.7828,  1.7373, -0.4733],\n",
            "        [ 0.8248, -0.5385, -0.8313],\n",
            "        [ 0.8318, -0.4196, -0.7507],\n",
            "        [-1.4980,  1.7783, -0.4447],\n",
            "        [-2.0102,  1.0859,  0.3810],\n",
            "        [-1.6357,  1.8293, -0.4278],\n",
            "        [-2.0017,  0.5931,  1.2292],\n",
            "        [ 0.6716, -0.3941, -0.8717],\n",
            "        [-1.7008,  1.8401, -0.4959],\n",
            "        [-1.7226,  1.9423, -0.2800],\n",
            "        [-2.0415,  0.8369,  1.0613],\n",
            "        [-2.0033,  0.4951,  1.1829],\n",
            "        [ 0.9046, -0.4301, -0.8284]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1280,  0.5124,  1.3958],\n",
            "        [-1.7193,  0.5454,  1.1164],\n",
            "        [-1.3488,  1.8400, -0.5445],\n",
            "        [-1.6318,  1.9056, -0.6012],\n",
            "        [-2.0275,  0.3063,  1.4427],\n",
            "        [-1.6281,  1.8240, -0.5082],\n",
            "        [-1.6735,  2.0090, -0.5410],\n",
            "        [-1.7515,  1.8257, -0.1750],\n",
            "        [-1.3986,  1.7672, -0.3661],\n",
            "        [-1.8031,  0.6776,  1.1159],\n",
            "        [-1.6668,  1.7992, -0.4691],\n",
            "        [-1.2817,  1.4620, -0.6506],\n",
            "        [-1.9016,  0.4141,  1.3805],\n",
            "        [-1.8265,  2.0869, -0.4075],\n",
            "        [-1.9808,  0.8842,  0.7935],\n",
            "        [-1.8327,  2.0295, -0.4630]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1280,  0.5124,  1.3958],\n",
            "        [-1.7193,  0.5454,  1.1164],\n",
            "        [-1.3488,  1.8400, -0.5445],\n",
            "        [-1.6318,  1.9056, -0.6012],\n",
            "        [-2.0275,  0.3063,  1.4427],\n",
            "        [-1.6281,  1.8240, -0.5082],\n",
            "        [-1.6735,  2.0090, -0.5410],\n",
            "        [-1.7515,  1.8257, -0.1750],\n",
            "        [-1.3986,  1.7672, -0.3661],\n",
            "        [-1.8031,  0.6776,  1.1159],\n",
            "        [-1.6668,  1.7992, -0.4691],\n",
            "        [-1.2817,  1.4620, -0.6506],\n",
            "        [-1.9016,  0.4141,  1.3805],\n",
            "        [-1.8265,  2.0869, -0.4075],\n",
            "        [-1.9808,  0.8842,  0.7935],\n",
            "        [-1.8327,  2.0295, -0.4630]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7874,  1.3830,  0.0498],\n",
            "        [ 0.4047, -0.2431, -0.9765],\n",
            "        [-1.7210,  1.9633, -0.2111],\n",
            "        [-1.6198,  1.6743, -0.3068],\n",
            "        [-1.9882,  1.5797,  0.1463],\n",
            "        [-2.1390,  0.4389,  1.2435],\n",
            "        [-1.7798,  1.9520, -0.4399],\n",
            "        [-1.9710,  0.4381,  1.5667],\n",
            "        [-1.5503,  1.6448, -0.2935],\n",
            "        [-1.8732,  1.4965, -0.2188],\n",
            "        [-1.4797,  1.8983, -0.5149],\n",
            "        [-2.1181,  0.2965,  1.5182],\n",
            "        [-2.1021,  0.5874,  0.9489],\n",
            "        [-1.8911,  1.6599,  0.0951],\n",
            "        [-2.2136,  0.5659,  1.1935],\n",
            "        [-1.7555,  0.3767,  1.2631]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7874,  1.3830,  0.0498],\n",
            "        [ 0.4047, -0.2431, -0.9765],\n",
            "        [-1.7210,  1.9633, -0.2111],\n",
            "        [-1.6198,  1.6743, -0.3068],\n",
            "        [-1.9882,  1.5797,  0.1463],\n",
            "        [-2.1390,  0.4389,  1.2435],\n",
            "        [-1.7798,  1.9520, -0.4399],\n",
            "        [-1.9710,  0.4381,  1.5667],\n",
            "        [-1.5503,  1.6448, -0.2935],\n",
            "        [-1.8732,  1.4965, -0.2188],\n",
            "        [-1.4797,  1.8983, -0.5149],\n",
            "        [-2.1181,  0.2965,  1.5182],\n",
            "        [-2.1021,  0.5874,  0.9489],\n",
            "        [-1.8911,  1.6599,  0.0951],\n",
            "        [-2.2136,  0.5659,  1.1935],\n",
            "        [-1.7555,  0.3767,  1.2631]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1914,  0.5084,  1.3677],\n",
            "        [-2.0625,  0.3950,  1.5146],\n",
            "        [-1.7109,  1.4093, -0.0833],\n",
            "        [ 0.3316,  0.1398, -0.9050],\n",
            "        [-1.8592,  0.4371,  1.3313],\n",
            "        [-1.8304,  0.2666,  1.4956],\n",
            "        [ 0.8445, -0.3513, -0.8785],\n",
            "        [-1.8035,  1.8589, -0.4486],\n",
            "        [-0.1687, -0.1283,  0.1283],\n",
            "        [ 0.6407, -0.2998, -0.8114],\n",
            "        [-2.0180,  0.3078,  1.2598],\n",
            "        [ 0.5512, -0.1733, -1.0634],\n",
            "        [-2.0638,  0.2603,  1.4454],\n",
            "        [-1.6051,  2.0727, -0.3716],\n",
            "        [-1.5851,  1.8884, -0.4867],\n",
            "        [-1.7221,  1.8726, -0.5154]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1914,  0.5084,  1.3677],\n",
            "        [-2.0625,  0.3950,  1.5146],\n",
            "        [-1.7109,  1.4093, -0.0833],\n",
            "        [ 0.3316,  0.1398, -0.9050],\n",
            "        [-1.8592,  0.4371,  1.3313],\n",
            "        [-1.8304,  0.2666,  1.4956],\n",
            "        [ 0.8445, -0.3513, -0.8785],\n",
            "        [-1.8035,  1.8589, -0.4486],\n",
            "        [-0.1687, -0.1283,  0.1283],\n",
            "        [ 0.6407, -0.2998, -0.8114],\n",
            "        [-2.0180,  0.3078,  1.2598],\n",
            "        [ 0.5512, -0.1733, -1.0634],\n",
            "        [-2.0638,  0.2603,  1.4454],\n",
            "        [-1.6051,  2.0727, -0.3716],\n",
            "        [-1.5851,  1.8884, -0.4867],\n",
            "        [-1.7221,  1.8726, -0.5154]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7772,  2.0640, -0.5544],\n",
            "        [-1.7567,  1.9473, -0.5679],\n",
            "        [-1.5423,  1.9160, -0.3641],\n",
            "        [-1.9348,  0.5442,  1.3224],\n",
            "        [-1.6199,  2.0379, -0.3023],\n",
            "        [ 0.6684,  0.0254, -1.0011],\n",
            "        [-1.7635,  2.0837, -0.5067],\n",
            "        [-1.8426,  0.1808,  1.3160],\n",
            "        [-1.8242,  0.6990,  1.0519],\n",
            "        [-1.9006,  2.0865, -0.2842],\n",
            "        [-1.9321,  0.5630,  1.2927],\n",
            "        [-1.7311,  2.0127, -0.2915],\n",
            "        [-1.6225,  1.7671, -0.4068],\n",
            "        [-1.5777,  2.1289, -0.3603],\n",
            "        [-1.6882,  1.8044, -0.3337],\n",
            "        [ 0.4608, -0.3555, -0.6026]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7772,  2.0640, -0.5544],\n",
            "        [-1.7567,  1.9473, -0.5679],\n",
            "        [-1.5423,  1.9160, -0.3641],\n",
            "        [-1.9348,  0.5442,  1.3224],\n",
            "        [-1.6199,  2.0379, -0.3023],\n",
            "        [ 0.6684,  0.0254, -1.0011],\n",
            "        [-1.7635,  2.0837, -0.5067],\n",
            "        [-1.8426,  0.1808,  1.3160],\n",
            "        [-1.8242,  0.6990,  1.0519],\n",
            "        [-1.9006,  2.0865, -0.2842],\n",
            "        [-1.9321,  0.5630,  1.2927],\n",
            "        [-1.7311,  2.0127, -0.2915],\n",
            "        [-1.6225,  1.7671, -0.4068],\n",
            "        [-1.5777,  2.1289, -0.3603],\n",
            "        [-1.6882,  1.8044, -0.3337],\n",
            "        [ 0.4608, -0.3555, -0.6026]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.6244, -0.1774, -0.8937],\n",
            "        [-1.9826,  2.1356, -0.3225],\n",
            "        [-2.2187,  0.1773,  1.5474],\n",
            "        [-1.8816,  2.1149, -0.3247],\n",
            "        [-2.0344,  0.1676,  1.5429],\n",
            "        [-1.7091,  1.8208, -0.1792],\n",
            "        [-1.6824,  1.7704, -0.3983],\n",
            "        [-1.5655,  2.0067, -0.5756],\n",
            "        [-1.9351,  1.8454, -0.4566],\n",
            "        [-2.0385,  1.3831,  0.7049],\n",
            "        [ 0.6985, -0.4913, -0.8027],\n",
            "        [-1.5495,  1.9689, -0.2983],\n",
            "        [ 0.7599, -0.4211, -0.8321],\n",
            "        [-1.5788,  1.6670, -0.2578],\n",
            "        [-1.6949,  2.0380, -0.4498],\n",
            "        [-1.9654,  0.6517,  1.0845]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.6244, -0.1774, -0.8937],\n",
            "        [-1.9826,  2.1356, -0.3225],\n",
            "        [-2.2187,  0.1773,  1.5474],\n",
            "        [-1.8816,  2.1149, -0.3247],\n",
            "        [-2.0344,  0.1676,  1.5429],\n",
            "        [-1.7091,  1.8208, -0.1792],\n",
            "        [-1.6824,  1.7704, -0.3983],\n",
            "        [-1.5655,  2.0067, -0.5756],\n",
            "        [-1.9351,  1.8454, -0.4566],\n",
            "        [-2.0385,  1.3831,  0.7049],\n",
            "        [ 0.6985, -0.4913, -0.8027],\n",
            "        [-1.5495,  1.9689, -0.2983],\n",
            "        [ 0.7599, -0.4211, -0.8321],\n",
            "        [-1.5788,  1.6670, -0.2578],\n",
            "        [-1.6949,  2.0380, -0.4498],\n",
            "        [-1.9654,  0.6517,  1.0845]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7200,  2.1053, -0.2825],\n",
            "        [-1.8228,  1.7430, -0.5257],\n",
            "        [-1.4976,  1.9513, -0.5484],\n",
            "        [-1.7445,  2.0053, -0.4266],\n",
            "        [-1.6163,  1.8199, -0.3533],\n",
            "        [-1.5579,  1.8206, -0.5471],\n",
            "        [-2.0813,  0.3655,  1.5532],\n",
            "        [ 0.7516, -0.4143, -0.6572],\n",
            "        [-1.7220,  2.0153, -0.5127],\n",
            "        [-1.7071,  2.0916, -0.4352],\n",
            "        [-1.6354,  1.9024, -0.4700],\n",
            "        [-1.8972,  0.2745,  1.5167],\n",
            "        [-1.9756,  0.2248,  1.2911],\n",
            "        [-1.8730,  0.2625,  1.3161],\n",
            "        [-1.7216,  1.8327, -0.6388],\n",
            "        [ 0.3768, -0.2587, -0.8132]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7200,  2.1053, -0.2825],\n",
            "        [-1.8228,  1.7430, -0.5257],\n",
            "        [-1.4976,  1.9513, -0.5484],\n",
            "        [-1.7445,  2.0053, -0.4266],\n",
            "        [-1.6163,  1.8199, -0.3533],\n",
            "        [-1.5579,  1.8206, -0.5471],\n",
            "        [-2.0813,  0.3655,  1.5532],\n",
            "        [ 0.7516, -0.4143, -0.6572],\n",
            "        [-1.7220,  2.0153, -0.5127],\n",
            "        [-1.7071,  2.0916, -0.4352],\n",
            "        [-1.6354,  1.9024, -0.4700],\n",
            "        [-1.8972,  0.2745,  1.5167],\n",
            "        [-1.9756,  0.2248,  1.2911],\n",
            "        [-1.8730,  0.2625,  1.3161],\n",
            "        [-1.7216,  1.8327, -0.6388],\n",
            "        [ 0.3768, -0.2587, -0.8132]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8278,  2.0601, -0.5359],\n",
            "        [-1.8051,  1.7011, -0.1385],\n",
            "        [-1.7040,  1.8830, -0.4955],\n",
            "        [-2.1157,  0.4763,  1.3954],\n",
            "        [-1.5760,  1.9123, -0.4323],\n",
            "        [-1.7739,  1.9384, -0.4221],\n",
            "        [-1.7854,  1.9622, -0.2602],\n",
            "        [-1.5010,  1.9844, -0.6671],\n",
            "        [-1.9157,  2.0248, -0.5622],\n",
            "        [ 0.3934, -0.1047, -0.8455],\n",
            "        [-1.8002,  0.0874,  1.4221],\n",
            "        [-1.7056,  1.9484, -0.5149],\n",
            "        [ 0.3950, -0.2307, -0.7454],\n",
            "        [-1.9017,  1.8628, -0.4446],\n",
            "        [-1.7275,  1.9212, -0.2929],\n",
            "        [ 0.6993, -0.3744, -0.7534]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8278,  2.0601, -0.5359],\n",
            "        [-1.8051,  1.7011, -0.1385],\n",
            "        [-1.7040,  1.8830, -0.4955],\n",
            "        [-2.1157,  0.4763,  1.3954],\n",
            "        [-1.5760,  1.9123, -0.4323],\n",
            "        [-1.7739,  1.9384, -0.4221],\n",
            "        [-1.7854,  1.9622, -0.2602],\n",
            "        [-1.5010,  1.9844, -0.6671],\n",
            "        [-1.9157,  2.0248, -0.5622],\n",
            "        [ 0.3934, -0.1047, -0.8455],\n",
            "        [-1.8002,  0.0874,  1.4221],\n",
            "        [-1.7056,  1.9484, -0.5149],\n",
            "        [ 0.3950, -0.2307, -0.7454],\n",
            "        [-1.9017,  1.8628, -0.4446],\n",
            "        [-1.7275,  1.9212, -0.2929],\n",
            "        [ 0.6993, -0.3744, -0.7534]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5847,  1.7640, -0.4502],\n",
            "        [-1.9071,  0.3479,  1.3520],\n",
            "        [-1.8215,  2.0813, -0.2957],\n",
            "        [-1.5355,  2.0370, -0.5476],\n",
            "        [-1.7685,  1.9947, -0.3459],\n",
            "        [-1.8164,  1.8916, -0.3688],\n",
            "        [-2.0550,  0.0895,  1.3609],\n",
            "        [-1.8006,  1.3332,  0.2649],\n",
            "        [-1.8937,  2.1801, -0.3695],\n",
            "        [-1.2686,  1.3187, -0.2085],\n",
            "        [-1.7404,  2.0376, -0.3996],\n",
            "        [-1.7048,  1.9540, -0.4213],\n",
            "        [-2.1909,  0.3512,  1.7142],\n",
            "        [-1.8448,  2.0232, -0.3212],\n",
            "        [-1.7126,  2.1231, -0.4284],\n",
            "        [-1.7621,  1.9207, -0.4148]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5847,  1.7640, -0.4502],\n",
            "        [-1.9071,  0.3479,  1.3520],\n",
            "        [-1.8215,  2.0813, -0.2957],\n",
            "        [-1.5355,  2.0370, -0.5476],\n",
            "        [-1.7685,  1.9947, -0.3459],\n",
            "        [-1.8164,  1.8916, -0.3688],\n",
            "        [-2.0550,  0.0895,  1.3609],\n",
            "        [-1.8006,  1.3332,  0.2649],\n",
            "        [-1.8937,  2.1801, -0.3695],\n",
            "        [-1.2686,  1.3187, -0.2085],\n",
            "        [-1.7404,  2.0376, -0.3996],\n",
            "        [-1.7048,  1.9540, -0.4213],\n",
            "        [-2.1909,  0.3512,  1.7142],\n",
            "        [-1.8448,  2.0232, -0.3212],\n",
            "        [-1.7126,  2.1231, -0.4284],\n",
            "        [-1.7621,  1.9207, -0.4148]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9186,  0.2574,  1.4176],\n",
            "        [-1.8974,  0.1097,  1.5442],\n",
            "        [-1.5781,  1.7488, -0.4264],\n",
            "        [-1.8392,  2.0683, -0.5190],\n",
            "        [-1.7877,  2.0661, -0.6208],\n",
            "        [ 0.6743, -0.3073, -0.7801],\n",
            "        [-1.8219,  1.9188, -0.5094],\n",
            "        [-1.5631,  1.7787, -0.3773],\n",
            "        [-1.7562,  1.9828, -0.2961],\n",
            "        [-1.7402,  0.1082,  1.4247],\n",
            "        [-1.8195,  1.9928, -0.2140],\n",
            "        [-2.0146,  0.3431,  1.5188],\n",
            "        [-1.7388,  2.1065, -0.4431],\n",
            "        [-1.7144,  1.9813, -0.3261],\n",
            "        [-1.7174,  1.6245, -0.1371],\n",
            "        [-1.7476,  0.3184,  1.2421]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9186,  0.2574,  1.4176],\n",
            "        [-1.8974,  0.1097,  1.5442],\n",
            "        [-1.5781,  1.7488, -0.4264],\n",
            "        [-1.8392,  2.0683, -0.5190],\n",
            "        [-1.7877,  2.0661, -0.6208],\n",
            "        [ 0.6743, -0.3073, -0.7801],\n",
            "        [-1.8219,  1.9188, -0.5094],\n",
            "        [-1.5631,  1.7787, -0.3773],\n",
            "        [-1.7562,  1.9828, -0.2961],\n",
            "        [-1.7402,  0.1082,  1.4247],\n",
            "        [-1.8195,  1.9928, -0.2140],\n",
            "        [-2.0146,  0.3431,  1.5188],\n",
            "        [-1.7388,  2.1065, -0.4431],\n",
            "        [-1.7144,  1.9813, -0.3261],\n",
            "        [-1.7174,  1.6245, -0.1371],\n",
            "        [-1.7476,  0.3184,  1.2421]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5704, -0.3328, -0.6943],\n",
            "        [-1.9281,  0.3699,  1.3292],\n",
            "        [-1.7607,  0.1924,  1.1065],\n",
            "        [-0.5921,  1.1009, -1.0372],\n",
            "        [-1.9193,  0.2616,  1.5664],\n",
            "        [-1.9566,  0.2193,  1.3815],\n",
            "        [ 0.5289, -0.3962, -0.8371],\n",
            "        [-2.0668,  0.3114,  1.2892],\n",
            "        [-0.0749, -0.1925, -0.2281],\n",
            "        [-1.6824,  2.0281, -0.4394],\n",
            "        [-1.8515,  0.1497,  1.4560],\n",
            "        [-1.8262,  1.6851, -0.1404],\n",
            "        [-1.8116,  2.0586, -0.2431],\n",
            "        [-1.4792,  1.9161, -0.4992],\n",
            "        [-1.7867,  0.2142,  1.3349],\n",
            "        [-1.9693,  0.0687,  1.2284]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.5704, -0.3328, -0.6943],\n",
            "        [-1.9281,  0.3699,  1.3292],\n",
            "        [-1.7607,  0.1924,  1.1065],\n",
            "        [-0.5921,  1.1009, -1.0372],\n",
            "        [-1.9193,  0.2616,  1.5664],\n",
            "        [-1.9566,  0.2193,  1.3815],\n",
            "        [ 0.5289, -0.3962, -0.8371],\n",
            "        [-2.0668,  0.3114,  1.2892],\n",
            "        [-0.0749, -0.1925, -0.2281],\n",
            "        [-1.6824,  2.0281, -0.4394],\n",
            "        [-1.8515,  0.1497,  1.4560],\n",
            "        [-1.8262,  1.6851, -0.1404],\n",
            "        [-1.8116,  2.0586, -0.2431],\n",
            "        [-1.4792,  1.9161, -0.4992],\n",
            "        [-1.7867,  0.2142,  1.3349],\n",
            "        [-1.9693,  0.0687,  1.2284]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0860,  1.3141,  0.7167],\n",
            "        [-2.0381,  1.8258, -0.0391],\n",
            "        [-1.6240,  1.8675, -0.4273],\n",
            "        [-1.6539,  1.7705, -0.4562],\n",
            "        [-1.8660,  0.3671,  1.1213],\n",
            "        [-1.5852,  1.8608, -0.4807],\n",
            "        [-1.8636,  2.0071, -0.1424],\n",
            "        [-1.7810,  1.8698, -0.4626],\n",
            "        [-1.6223,  2.0465, -0.6581],\n",
            "        [-1.8972,  0.4639,  1.5095],\n",
            "        [ 0.7311, -0.4260, -0.7428],\n",
            "        [-1.6642,  1.9891, -0.6145],\n",
            "        [-1.7362,  0.2510,  1.2961],\n",
            "        [-1.7171,  1.9493, -0.4033],\n",
            "        [-1.5660,  1.7689, -0.4048],\n",
            "        [-1.7601,  1.6284, -0.2655]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0860,  1.3141,  0.7167],\n",
            "        [-2.0381,  1.8258, -0.0391],\n",
            "        [-1.6240,  1.8675, -0.4273],\n",
            "        [-1.6539,  1.7705, -0.4562],\n",
            "        [-1.8660,  0.3671,  1.1213],\n",
            "        [-1.5852,  1.8608, -0.4807],\n",
            "        [-1.8636,  2.0071, -0.1424],\n",
            "        [-1.7810,  1.8698, -0.4626],\n",
            "        [-1.6223,  2.0465, -0.6581],\n",
            "        [-1.8972,  0.4639,  1.5095],\n",
            "        [ 0.7311, -0.4260, -0.7428],\n",
            "        [-1.6642,  1.9891, -0.6145],\n",
            "        [-1.7362,  0.2510,  1.2961],\n",
            "        [-1.7171,  1.9493, -0.4033],\n",
            "        [-1.5660,  1.7689, -0.4048],\n",
            "        [-1.7601,  1.6284, -0.2655]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8199,  0.3822,  1.2776],\n",
            "        [-1.5390,  1.7917, -0.5264],\n",
            "        [-1.9156,  0.3068,  1.3451],\n",
            "        [-1.8280,  1.9841, -0.5177],\n",
            "        [-1.8512,  0.4016,  1.2880],\n",
            "        [-1.5528,  2.0575, -0.5039],\n",
            "        [-1.6546,  2.0537, -0.7152],\n",
            "        [-1.9283,  0.4279,  1.3940],\n",
            "        [-1.7788,  1.8817, -0.3454],\n",
            "        [-1.7706,  1.8674, -0.4783],\n",
            "        [-2.1220,  0.5930,  1.1646],\n",
            "        [-1.8139,  1.9901, -0.2620],\n",
            "        [-1.7798,  0.3212,  1.3207],\n",
            "        [-1.9965,  0.5315,  1.4303],\n",
            "        [-1.5932,  1.9364, -0.4399],\n",
            "        [-1.6544,  1.8425, -0.4065]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8199,  0.3822,  1.2776],\n",
            "        [-1.5390,  1.7917, -0.5264],\n",
            "        [-1.9156,  0.3068,  1.3451],\n",
            "        [-1.8280,  1.9841, -0.5177],\n",
            "        [-1.8512,  0.4016,  1.2880],\n",
            "        [-1.5528,  2.0575, -0.5039],\n",
            "        [-1.6546,  2.0537, -0.7152],\n",
            "        [-1.9283,  0.4279,  1.3940],\n",
            "        [-1.7788,  1.8817, -0.3454],\n",
            "        [-1.7706,  1.8674, -0.4783],\n",
            "        [-2.1220,  0.5930,  1.1646],\n",
            "        [-1.8139,  1.9901, -0.2620],\n",
            "        [-1.7798,  0.3212,  1.3207],\n",
            "        [-1.9965,  0.5315,  1.4303],\n",
            "        [-1.5932,  1.9364, -0.4399],\n",
            "        [-1.6544,  1.8425, -0.4065]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5514,  1.7810, -0.3237],\n",
            "        [-1.6858,  1.9327, -0.4579],\n",
            "        [-1.6774,  2.0548, -0.4737],\n",
            "        [-1.7164,  1.8876, -0.5156],\n",
            "        [-1.8277,  0.3859,  1.3495],\n",
            "        [ 0.3942,  0.0201, -1.1379],\n",
            "        [-1.5835,  1.9065, -0.4923],\n",
            "        [-1.8262,  0.3353,  1.4903],\n",
            "        [-1.4625,  1.5044, -0.2503],\n",
            "        [-1.5234,  1.7533, -0.3024],\n",
            "        [-1.8506,  1.9012, -0.1037],\n",
            "        [-1.6675,  1.7196, -0.4873],\n",
            "        [-1.6990,  2.0454, -0.3579],\n",
            "        [-2.0034,  0.5382,  1.2115],\n",
            "        [-1.7657,  1.4260, -0.3912],\n",
            "        [-1.4803,  1.7424, -0.3896]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5514,  1.7810, -0.3237],\n",
            "        [-1.6858,  1.9327, -0.4579],\n",
            "        [-1.6774,  2.0548, -0.4737],\n",
            "        [-1.7164,  1.8876, -0.5156],\n",
            "        [-1.8277,  0.3859,  1.3495],\n",
            "        [ 0.3942,  0.0201, -1.1379],\n",
            "        [-1.5835,  1.9065, -0.4923],\n",
            "        [-1.8262,  0.3353,  1.4903],\n",
            "        [-1.4625,  1.5044, -0.2503],\n",
            "        [-1.5234,  1.7533, -0.3024],\n",
            "        [-1.8506,  1.9012, -0.1037],\n",
            "        [-1.6675,  1.7196, -0.4873],\n",
            "        [-1.6990,  2.0454, -0.3579],\n",
            "        [-2.0034,  0.5382,  1.2115],\n",
            "        [-1.7657,  1.4260, -0.3912],\n",
            "        [-1.4803,  1.7424, -0.3896]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6612,  1.8865, -0.4084],\n",
            "        [-1.6985,  1.8803, -0.2423],\n",
            "        [-2.1013,  1.0445,  0.7445],\n",
            "        [-1.7314,  2.0948, -0.5667],\n",
            "        [-1.7128,  0.4799,  1.3220],\n",
            "        [ 0.1025,  0.4923, -1.0277],\n",
            "        [-1.6155,  1.6099, -0.2899],\n",
            "        [-1.6524,  1.9676, -0.4198],\n",
            "        [-1.7581,  2.0037, -0.5390],\n",
            "        [-1.6403,  1.7646, -0.3182],\n",
            "        [-1.8065,  1.7631, -0.3548],\n",
            "        [-1.8500,  1.9595, -0.4595],\n",
            "        [-0.3361,  0.9178, -0.9599],\n",
            "        [-1.4714,  1.9567, -0.6257],\n",
            "        [-1.9631,  0.4512,  1.2557],\n",
            "        [-1.1757,  0.0823,  1.0122]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6612,  1.8865, -0.4084],\n",
            "        [-1.6985,  1.8803, -0.2423],\n",
            "        [-2.1013,  1.0445,  0.7445],\n",
            "        [-1.7314,  2.0948, -0.5667],\n",
            "        [-1.7128,  0.4799,  1.3220],\n",
            "        [ 0.1025,  0.4923, -1.0277],\n",
            "        [-1.6155,  1.6099, -0.2899],\n",
            "        [-1.6524,  1.9676, -0.4198],\n",
            "        [-1.7581,  2.0037, -0.5390],\n",
            "        [-1.6403,  1.7646, -0.3182],\n",
            "        [-1.8065,  1.7631, -0.3548],\n",
            "        [-1.8500,  1.9595, -0.4595],\n",
            "        [-0.3361,  0.9178, -0.9599],\n",
            "        [-1.4714,  1.9567, -0.6257],\n",
            "        [-1.9631,  0.4512,  1.2557],\n",
            "        [-1.1757,  0.0823,  1.0122]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4349e+00,  1.7506e+00, -2.7144e-01],\n",
            "        [-2.0397e+00,  5.9577e-01,  1.2960e+00],\n",
            "        [-1.7220e+00,  1.8245e+00, -2.6808e-01],\n",
            "        [-1.5946e+00,  1.8844e+00, -2.8326e-01],\n",
            "        [-1.6721e+00,  1.8843e+00, -4.1333e-01],\n",
            "        [ 6.2858e-01, -3.6403e-01, -8.3379e-01],\n",
            "        [-1.8233e+00,  3.8058e-01,  1.0640e+00],\n",
            "        [-1.6307e+00,  1.6612e+00, -4.5697e-01],\n",
            "        [ 6.4083e-01, -1.6829e-01, -8.5690e-01],\n",
            "        [-1.7498e+00,  1.6035e+00,  5.5818e-04],\n",
            "        [-1.7939e+00,  3.9197e-01,  1.1163e+00],\n",
            "        [-2.6458e-01, -2.3657e-01,  4.5358e-03],\n",
            "        [-2.1880e+00,  1.0367e+00,  6.0173e-01],\n",
            "        [-1.2593e+00,  1.0565e+00, -2.3042e-01],\n",
            "        [-1.8768e+00,  2.0021e+00, -5.0798e-01],\n",
            "        [-2.1312e+00,  5.7647e-01,  1.3473e+00]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4349e+00,  1.7506e+00, -2.7144e-01],\n",
            "        [-2.0397e+00,  5.9577e-01,  1.2960e+00],\n",
            "        [-1.7220e+00,  1.8245e+00, -2.6808e-01],\n",
            "        [-1.5946e+00,  1.8844e+00, -2.8326e-01],\n",
            "        [-1.6721e+00,  1.8843e+00, -4.1333e-01],\n",
            "        [ 6.2858e-01, -3.6403e-01, -8.3379e-01],\n",
            "        [-1.8233e+00,  3.8058e-01,  1.0640e+00],\n",
            "        [-1.6307e+00,  1.6612e+00, -4.5697e-01],\n",
            "        [ 6.4083e-01, -1.6829e-01, -8.5690e-01],\n",
            "        [-1.7498e+00,  1.6035e+00,  5.5818e-04],\n",
            "        [-1.7939e+00,  3.9197e-01,  1.1163e+00],\n",
            "        [-2.6458e-01, -2.3657e-01,  4.5358e-03],\n",
            "        [-2.1880e+00,  1.0367e+00,  6.0173e-01],\n",
            "        [-1.2593e+00,  1.0565e+00, -2.3042e-01],\n",
            "        [-1.8768e+00,  2.0021e+00, -5.0798e-01],\n",
            "        [-2.1312e+00,  5.7647e-01,  1.3473e+00]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9318,  0.4461,  1.5011],\n",
            "        [-1.5309,  1.8706, -0.2954],\n",
            "        [-1.9473,  0.3233,  0.9567],\n",
            "        [-1.6929,  1.5563, -0.2980],\n",
            "        [-1.7846,  0.8876,  0.6146],\n",
            "        [ 0.6336, -0.2969, -0.7195],\n",
            "        [-0.1847,  0.0909, -0.2780],\n",
            "        [-1.3790,  1.6249, -0.6997],\n",
            "        [-1.5929,  1.9102, -0.5617],\n",
            "        [-1.6567,  1.9890, -0.2723],\n",
            "        [-1.8597,  1.8970,  0.0468],\n",
            "        [ 0.7300, -0.4344, -0.8166],\n",
            "        [-1.5871,  1.6681, -0.4566],\n",
            "        [-1.9420,  1.9571, -0.2903],\n",
            "        [-1.4514,  1.7650, -0.4473],\n",
            "        [-1.7827,  1.9673, -0.5086]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9318,  0.4461,  1.5011],\n",
            "        [-1.5309,  1.8706, -0.2954],\n",
            "        [-1.9473,  0.3233,  0.9567],\n",
            "        [-1.6929,  1.5563, -0.2980],\n",
            "        [-1.7846,  0.8876,  0.6146],\n",
            "        [ 0.6336, -0.2969, -0.7195],\n",
            "        [-0.1847,  0.0909, -0.2780],\n",
            "        [-1.3790,  1.6249, -0.6997],\n",
            "        [-1.5929,  1.9102, -0.5617],\n",
            "        [-1.6567,  1.9890, -0.2723],\n",
            "        [-1.8597,  1.8970,  0.0468],\n",
            "        [ 0.7300, -0.4344, -0.8166],\n",
            "        [-1.5871,  1.6681, -0.4566],\n",
            "        [-1.9420,  1.9571, -0.2903],\n",
            "        [-1.4514,  1.7650, -0.4473],\n",
            "        [-1.7827,  1.9673, -0.5086]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6808,  1.8377, -0.2857],\n",
            "        [ 0.4948, -0.3155, -0.8937],\n",
            "        [-1.8199,  1.9609, -0.1825],\n",
            "        [ 0.1908,  0.4005, -1.1673],\n",
            "        [-1.8100,  0.4624,  1.1128],\n",
            "        [-1.5951,  1.8130, -0.4154],\n",
            "        [-1.3356,  1.9255, -0.4149],\n",
            "        [-1.8264,  1.2003,  0.4749],\n",
            "        [-1.8942,  0.5149,  1.2509],\n",
            "        [-1.7755,  1.7964, -0.1060],\n",
            "        [-1.9382,  0.5967,  1.2037],\n",
            "        [-1.5276,  1.9418, -0.4981],\n",
            "        [-1.6276,  1.5943, -0.4725],\n",
            "        [-1.8572,  1.9237, -0.1621],\n",
            "        [-1.9186,  0.3889,  1.2105],\n",
            "        [-1.1996,  1.5869, -0.6414]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6808,  1.8377, -0.2857],\n",
            "        [ 0.4948, -0.3155, -0.8937],\n",
            "        [-1.8199,  1.9609, -0.1825],\n",
            "        [ 0.1908,  0.4005, -1.1673],\n",
            "        [-1.8100,  0.4624,  1.1128],\n",
            "        [-1.5951,  1.8130, -0.4154],\n",
            "        [-1.3356,  1.9255, -0.4149],\n",
            "        [-1.8264,  1.2003,  0.4749],\n",
            "        [-1.8942,  0.5149,  1.2509],\n",
            "        [-1.7755,  1.7964, -0.1060],\n",
            "        [-1.9382,  0.5967,  1.2037],\n",
            "        [-1.5276,  1.9418, -0.4981],\n",
            "        [-1.6276,  1.5943, -0.4725],\n",
            "        [-1.8572,  1.9237, -0.1621],\n",
            "        [-1.9186,  0.3889,  1.2105],\n",
            "        [-1.1996,  1.5869, -0.6414]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9132,  0.5224,  1.1151],\n",
            "        [-1.6913,  1.7883, -0.3674],\n",
            "        [-1.6099,  1.9169, -0.4747],\n",
            "        [-1.7291,  0.4365,  1.1320],\n",
            "        [-1.6515,  1.9381, -0.2421],\n",
            "        [-1.5405,  1.8702, -0.3196],\n",
            "        [ 0.6404, -0.1465, -1.0495],\n",
            "        [-2.2375,  0.8080,  0.9239],\n",
            "        [ 0.0680,  0.3771, -1.0868],\n",
            "        [-1.6456,  1.8424, -0.3791],\n",
            "        [-1.8056,  0.6629,  1.1853],\n",
            "        [-1.5666,  1.7533, -0.4090],\n",
            "        [-1.6741,  1.9242, -0.1690],\n",
            "        [ 0.6957, -0.2122, -0.8684],\n",
            "        [-0.2868,  0.7828, -1.0843],\n",
            "        [-1.6127,  1.6573, -0.3695]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9132,  0.5224,  1.1151],\n",
            "        [-1.6913,  1.7883, -0.3674],\n",
            "        [-1.6099,  1.9169, -0.4747],\n",
            "        [-1.7291,  0.4365,  1.1320],\n",
            "        [-1.6515,  1.9381, -0.2421],\n",
            "        [-1.5405,  1.8702, -0.3196],\n",
            "        [ 0.6404, -0.1465, -1.0495],\n",
            "        [-2.2375,  0.8080,  0.9239],\n",
            "        [ 0.0680,  0.3771, -1.0868],\n",
            "        [-1.6456,  1.8424, -0.3791],\n",
            "        [-1.8056,  0.6629,  1.1853],\n",
            "        [-1.5666,  1.7533, -0.4090],\n",
            "        [-1.6741,  1.9242, -0.1690],\n",
            "        [ 0.6957, -0.2122, -0.8684],\n",
            "        [-0.2868,  0.7828, -1.0843],\n",
            "        [-1.6127,  1.6573, -0.3695]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8414,  1.9981, -0.5238],\n",
            "        [-2.0437,  0.5741,  1.1347],\n",
            "        [-1.7305,  1.5719, -0.2109],\n",
            "        [-1.8016,  1.8491, -0.2870],\n",
            "        [-1.9364,  0.5786,  1.2609],\n",
            "        [ 0.7014, -0.3250, -0.8755],\n",
            "        [-1.5959,  1.6687, -0.4181],\n",
            "        [-1.6542,  1.7587, -0.1969],\n",
            "        [ 0.2341,  0.4500, -1.0398],\n",
            "        [-1.5708,  1.7218, -0.3547],\n",
            "        [-1.5997,  0.4809,  0.9966],\n",
            "        [-0.5918,  1.1108, -0.8138],\n",
            "        [-1.3145,  1.7891, -0.9156],\n",
            "        [-1.8129,  1.6749, -0.1850],\n",
            "        [-1.9259,  1.8596, -0.3740],\n",
            "        [-1.7846,  1.7778, -0.4027]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8414,  1.9981, -0.5238],\n",
            "        [-2.0437,  0.5741,  1.1347],\n",
            "        [-1.7305,  1.5719, -0.2109],\n",
            "        [-1.8016,  1.8491, -0.2870],\n",
            "        [-1.9364,  0.5786,  1.2609],\n",
            "        [ 0.7014, -0.3250, -0.8755],\n",
            "        [-1.5959,  1.6687, -0.4181],\n",
            "        [-1.6542,  1.7587, -0.1969],\n",
            "        [ 0.2341,  0.4500, -1.0398],\n",
            "        [-1.5708,  1.7218, -0.3547],\n",
            "        [-1.5997,  0.4809,  0.9966],\n",
            "        [-0.5918,  1.1108, -0.8138],\n",
            "        [-1.3145,  1.7891, -0.9156],\n",
            "        [-1.8129,  1.6749, -0.1850],\n",
            "        [-1.9259,  1.8596, -0.3740],\n",
            "        [-1.7846,  1.7778, -0.4027]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6767,  1.6492, -0.1980],\n",
            "        [ 0.5093, -0.1468, -0.9827],\n",
            "        [-1.8809,  1.9651, -0.3052],\n",
            "        [-1.6596,  0.4154,  1.1613],\n",
            "        [-1.6018,  1.7797, -0.4107],\n",
            "        [-1.8258,  1.7629,  0.0566],\n",
            "        [-1.9989,  1.4731,  0.2596],\n",
            "        [-1.8166,  1.1891,  0.4711],\n",
            "        [-1.7727,  1.9004, -0.3694],\n",
            "        [-1.7367,  0.5287,  0.9877],\n",
            "        [ 0.5889, -0.0846, -0.7587],\n",
            "        [-1.6779,  0.4410,  1.3148],\n",
            "        [-1.6185,  1.8742, -0.2694],\n",
            "        [-1.7082,  1.6684, -0.1952],\n",
            "        [-1.5162,  2.0016, -0.4487],\n",
            "        [-1.5803,  1.6510, -0.4539]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6767,  1.6492, -0.1980],\n",
            "        [ 0.5093, -0.1468, -0.9827],\n",
            "        [-1.8809,  1.9651, -0.3052],\n",
            "        [-1.6596,  0.4154,  1.1613],\n",
            "        [-1.6018,  1.7797, -0.4107],\n",
            "        [-1.8258,  1.7629,  0.0566],\n",
            "        [-1.9989,  1.4731,  0.2596],\n",
            "        [-1.8166,  1.1891,  0.4711],\n",
            "        [-1.7727,  1.9004, -0.3694],\n",
            "        [-1.7367,  0.5287,  0.9877],\n",
            "        [ 0.5889, -0.0846, -0.7587],\n",
            "        [-1.6779,  0.4410,  1.3148],\n",
            "        [-1.6185,  1.8742, -0.2694],\n",
            "        [-1.7082,  1.6684, -0.1952],\n",
            "        [-1.5162,  2.0016, -0.4487],\n",
            "        [-1.5803,  1.6510, -0.4539]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.6198, -0.2798, -0.9268],\n",
            "        [-1.4860,  1.6372, -0.3152],\n",
            "        [-1.7033,  1.6936, -0.2214],\n",
            "        [-1.6870,  0.4535,  1.1260],\n",
            "        [-1.7873,  1.7778, -0.3314],\n",
            "        [-1.6655,  1.6955, -0.5334],\n",
            "        [ 0.8095, -0.1772, -0.9347],\n",
            "        [-1.2176,  1.7860, -0.4211],\n",
            "        [-1.6838,  0.5048,  1.1266],\n",
            "        [ 0.6952, -0.4254, -0.7693],\n",
            "        [-1.7272,  0.5229,  1.0783],\n",
            "        [-1.6462,  1.6843, -0.3449],\n",
            "        [-1.0441,  1.2587, -0.5530],\n",
            "        [ 0.5353, -0.1000, -0.9311],\n",
            "        [-1.9007,  1.6606,  0.1321],\n",
            "        [-1.5769,  1.5444, -0.2287]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.6198, -0.2798, -0.9268],\n",
            "        [-1.4860,  1.6372, -0.3152],\n",
            "        [-1.7033,  1.6936, -0.2214],\n",
            "        [-1.6870,  0.4535,  1.1260],\n",
            "        [-1.7873,  1.7778, -0.3314],\n",
            "        [-1.6655,  1.6955, -0.5334],\n",
            "        [ 0.8095, -0.1772, -0.9347],\n",
            "        [-1.2176,  1.7860, -0.4211],\n",
            "        [-1.6838,  0.5048,  1.1266],\n",
            "        [ 0.6952, -0.4254, -0.7693],\n",
            "        [-1.7272,  0.5229,  1.0783],\n",
            "        [-1.6462,  1.6843, -0.3449],\n",
            "        [-1.0441,  1.2587, -0.5530],\n",
            "        [ 0.5353, -0.1000, -0.9311],\n",
            "        [-1.9007,  1.6606,  0.1321],\n",
            "        [-1.5769,  1.5444, -0.2287]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0720,  0.8250,  0.9116],\n",
            "        [-1.8440,  1.8419, -0.3867],\n",
            "        [-1.7144,  1.8183, -0.5590],\n",
            "        [-1.8009,  1.7881, -0.2946],\n",
            "        [-1.7953,  1.5042, -0.0489],\n",
            "        [-1.7321,  1.9809, -0.3528],\n",
            "        [-1.7212,  1.9055, -0.1863],\n",
            "        [-1.7379,  1.7611, -0.2437],\n",
            "        [-1.8300,  0.5146,  1.0621],\n",
            "        [-1.7424,  1.7703,  0.1453],\n",
            "        [-1.8370,  0.2897,  1.2636],\n",
            "        [-1.9216,  0.6810,  0.9194],\n",
            "        [-1.7865,  1.8500, -0.4751],\n",
            "        [-1.8571,  0.7625,  1.1031],\n",
            "        [-1.8632,  0.7188,  0.7906],\n",
            "        [-1.8619,  2.0693, -0.4092]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0720,  0.8250,  0.9116],\n",
            "        [-1.8440,  1.8419, -0.3867],\n",
            "        [-1.7144,  1.8183, -0.5590],\n",
            "        [-1.8009,  1.7881, -0.2946],\n",
            "        [-1.7953,  1.5042, -0.0489],\n",
            "        [-1.7321,  1.9809, -0.3528],\n",
            "        [-1.7212,  1.9055, -0.1863],\n",
            "        [-1.7379,  1.7611, -0.2437],\n",
            "        [-1.8300,  0.5146,  1.0621],\n",
            "        [-1.7424,  1.7703,  0.1453],\n",
            "        [-1.8370,  0.2897,  1.2636],\n",
            "        [-1.9216,  0.6810,  0.9194],\n",
            "        [-1.7865,  1.8500, -0.4751],\n",
            "        [-1.8571,  0.7625,  1.1031],\n",
            "        [-1.8632,  0.7188,  0.7906],\n",
            "        [-1.8619,  2.0693, -0.4092]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5818,  1.7307, -0.0100],\n",
            "        [-1.5188,  1.8058, -0.2931],\n",
            "        [-1.8103,  0.7057,  0.8654],\n",
            "        [-1.7951,  1.9965, -0.1571],\n",
            "        [-1.7970,  0.5691,  1.1387],\n",
            "        [ 0.6320, -0.3138, -0.9932],\n",
            "        [-1.7005,  0.6328,  1.0155],\n",
            "        [-1.8171,  2.2183, -0.1769],\n",
            "        [-1.9537,  0.7035,  1.1944],\n",
            "        [-1.5601,  1.7115, -0.3407],\n",
            "        [ 0.6182, -0.2395, -0.7269],\n",
            "        [-1.6750,  1.6891, -0.3279],\n",
            "        [-1.6717,  1.5079, -0.1605],\n",
            "        [-2.0380,  1.1643,  0.5203],\n",
            "        [-1.6337,  1.8013, -0.3706],\n",
            "        [-1.7594,  1.8112, -0.3949]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5818,  1.7307, -0.0100],\n",
            "        [-1.5188,  1.8058, -0.2931],\n",
            "        [-1.8103,  0.7057,  0.8654],\n",
            "        [-1.7951,  1.9965, -0.1571],\n",
            "        [-1.7970,  0.5691,  1.1387],\n",
            "        [ 0.6320, -0.3138, -0.9932],\n",
            "        [-1.7005,  0.6328,  1.0155],\n",
            "        [-1.8171,  2.2183, -0.1769],\n",
            "        [-1.9537,  0.7035,  1.1944],\n",
            "        [-1.5601,  1.7115, -0.3407],\n",
            "        [ 0.6182, -0.2395, -0.7269],\n",
            "        [-1.6750,  1.6891, -0.3279],\n",
            "        [-1.6717,  1.5079, -0.1605],\n",
            "        [-2.0380,  1.1643,  0.5203],\n",
            "        [-1.6337,  1.8013, -0.3706],\n",
            "        [-1.7594,  1.8112, -0.3949]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8532,  0.6356,  1.0969],\n",
            "        [-1.6807,  0.4110,  1.0215],\n",
            "        [-1.4171,  1.6790, -0.4349],\n",
            "        [-1.5586,  1.8224, -0.1758],\n",
            "        [-1.8866,  1.0202,  0.7121],\n",
            "        [ 0.6805, -0.0520, -0.9430],\n",
            "        [-1.9756,  0.6376,  1.1185],\n",
            "        [-1.8111,  1.6867, -0.3451],\n",
            "        [-1.4822,  1.6758, -0.2560],\n",
            "        [-1.4308,  1.7800, -0.1697],\n",
            "        [-1.9471,  0.6508,  1.0770],\n",
            "        [-1.6767,  0.6382,  0.8834],\n",
            "        [-1.8228,  1.6268,  0.1539],\n",
            "        [-1.8647,  0.2842,  1.0481],\n",
            "        [-1.6240,  1.9044, -0.2203],\n",
            "        [-1.8761,  1.8542, -0.3398]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8532,  0.6356,  1.0969],\n",
            "        [-1.6807,  0.4110,  1.0215],\n",
            "        [-1.4171,  1.6790, -0.4349],\n",
            "        [-1.5586,  1.8224, -0.1758],\n",
            "        [-1.8866,  1.0202,  0.7121],\n",
            "        [ 0.6805, -0.0520, -0.9430],\n",
            "        [-1.9756,  0.6376,  1.1185],\n",
            "        [-1.8111,  1.6867, -0.3451],\n",
            "        [-1.4822,  1.6758, -0.2560],\n",
            "        [-1.4308,  1.7800, -0.1697],\n",
            "        [-1.9471,  0.6508,  1.0770],\n",
            "        [-1.6767,  0.6382,  0.8834],\n",
            "        [-1.8228,  1.6268,  0.1539],\n",
            "        [-1.8647,  0.2842,  1.0481],\n",
            "        [-1.6240,  1.9044, -0.2203],\n",
            "        [-1.8761,  1.8542, -0.3398]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8810,  1.9750, -0.3237],\n",
            "        [-1.4676,  1.5046, -0.1602],\n",
            "        [ 0.7168, -0.3869, -0.7781],\n",
            "        [ 0.7472, -0.1534, -1.1688],\n",
            "        [-1.5628,  1.6055, -0.2072],\n",
            "        [ 0.5185, -0.0114, -1.0760],\n",
            "        [-1.9196,  2.0299, -0.3580],\n",
            "        [-1.6262,  1.9538, -0.2008],\n",
            "        [-1.2698,  1.5683, -0.5064],\n",
            "        [-2.0569,  1.8267, -0.2379],\n",
            "        [-1.8383,  1.8866, -0.0169],\n",
            "        [ 0.5167, -0.0026, -1.0254],\n",
            "        [ 0.7509, -0.3103, -0.7018],\n",
            "        [-1.5739,  1.5021, -0.3466],\n",
            "        [-1.6032,  1.8305, -0.2602],\n",
            "        [-1.9017,  0.5542,  1.0930]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8810,  1.9750, -0.3237],\n",
            "        [-1.4676,  1.5046, -0.1602],\n",
            "        [ 0.7168, -0.3869, -0.7781],\n",
            "        [ 0.7472, -0.1534, -1.1688],\n",
            "        [-1.5628,  1.6055, -0.2072],\n",
            "        [ 0.5185, -0.0114, -1.0760],\n",
            "        [-1.9196,  2.0299, -0.3580],\n",
            "        [-1.6262,  1.9538, -0.2008],\n",
            "        [-1.2698,  1.5683, -0.5064],\n",
            "        [-2.0569,  1.8267, -0.2379],\n",
            "        [-1.8383,  1.8866, -0.0169],\n",
            "        [ 0.5167, -0.0026, -1.0254],\n",
            "        [ 0.7509, -0.3103, -0.7018],\n",
            "        [-1.5739,  1.5021, -0.3466],\n",
            "        [-1.6032,  1.8305, -0.2602],\n",
            "        [-1.9017,  0.5542,  1.0930]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9621,  1.6353, -0.1883],\n",
            "        [-2.1103,  0.7259,  1.0725],\n",
            "        [-1.9194,  1.8513, -0.1834],\n",
            "        [-1.8333,  0.8279,  0.6127],\n",
            "        [-1.9936,  1.9200, -0.1437],\n",
            "        [-1.8456,  0.6315,  1.1247],\n",
            "        [-1.7952,  0.7233,  0.8319],\n",
            "        [-1.7978,  1.4449,  0.0321],\n",
            "        [ 0.5661, -0.2404, -1.0037],\n",
            "        [-1.8980,  1.6257, -0.1360],\n",
            "        [-1.7854,  1.7362, -0.1798],\n",
            "        [-1.9499,  1.8857, -0.1898],\n",
            "        [-1.6396,  1.7487, -0.2008],\n",
            "        [ 0.8867, -0.2198, -0.9794],\n",
            "        [-1.6825,  1.7851, -0.2686],\n",
            "        [-1.6297,  1.6531, -0.3434]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9621,  1.6353, -0.1883],\n",
            "        [-2.1103,  0.7259,  1.0725],\n",
            "        [-1.9194,  1.8513, -0.1834],\n",
            "        [-1.8333,  0.8279,  0.6127],\n",
            "        [-1.9936,  1.9200, -0.1437],\n",
            "        [-1.8456,  0.6315,  1.1247],\n",
            "        [-1.7952,  0.7233,  0.8319],\n",
            "        [-1.7978,  1.4449,  0.0321],\n",
            "        [ 0.5661, -0.2404, -1.0037],\n",
            "        [-1.8980,  1.6257, -0.1360],\n",
            "        [-1.7854,  1.7362, -0.1798],\n",
            "        [-1.9499,  1.8857, -0.1898],\n",
            "        [-1.6396,  1.7487, -0.2008],\n",
            "        [ 0.8867, -0.2198, -0.9794],\n",
            "        [-1.6825,  1.7851, -0.2686],\n",
            "        [-1.6297,  1.6531, -0.3434]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5235, -0.1596, -1.0515],\n",
            "        [-2.0008,  0.9451,  0.8715],\n",
            "        [-1.7539,  0.6929,  1.1001],\n",
            "        [ 0.8715, -0.1971, -0.9206],\n",
            "        [-1.6089,  0.5519,  1.0736],\n",
            "        [-1.8643,  1.6061,  0.2204],\n",
            "        [-1.8333,  0.7118,  0.8698],\n",
            "        [-1.9142,  0.5792,  0.9814],\n",
            "        [ 0.6513, -0.2879, -1.0481],\n",
            "        [-1.9182,  1.8745, -0.1743],\n",
            "        [-1.7487,  1.8204, -0.1222],\n",
            "        [-1.9172,  0.6942,  1.0129],\n",
            "        [-1.4045,  1.6950, -0.2625],\n",
            "        [-1.8222,  0.7161,  1.0663],\n",
            "        [-1.9684,  1.9730, -0.0756],\n",
            "        [-1.9074,  1.0379,  0.8543]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.5235, -0.1596, -1.0515],\n",
            "        [-2.0008,  0.9451,  0.8715],\n",
            "        [-1.7539,  0.6929,  1.1001],\n",
            "        [ 0.8715, -0.1971, -0.9206],\n",
            "        [-1.6089,  0.5519,  1.0736],\n",
            "        [-1.8643,  1.6061,  0.2204],\n",
            "        [-1.8333,  0.7118,  0.8698],\n",
            "        [-1.9142,  0.5792,  0.9814],\n",
            "        [ 0.6513, -0.2879, -1.0481],\n",
            "        [-1.9182,  1.8745, -0.1743],\n",
            "        [-1.7487,  1.8204, -0.1222],\n",
            "        [-1.9172,  0.6942,  1.0129],\n",
            "        [-1.4045,  1.6950, -0.2625],\n",
            "        [-1.8222,  0.7161,  1.0663],\n",
            "        [-1.9684,  1.9730, -0.0756],\n",
            "        [-1.9074,  1.0379,  0.8543]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8043,  1.4222,  0.4072],\n",
            "        [-1.8394,  1.8430, -0.0921],\n",
            "        [-1.7488,  1.9878, -0.2635],\n",
            "        [-1.7205,  1.8745, -0.1225],\n",
            "        [ 0.6453, -0.2644, -0.9667],\n",
            "        [-1.8903,  1.8710, -0.1345],\n",
            "        [-1.6879,  1.6957, -0.4292],\n",
            "        [ 0.7391, -0.2162, -0.9965],\n",
            "        [-1.9949,  1.3117,  0.6322],\n",
            "        [-1.8026,  0.6047,  1.0032],\n",
            "        [-1.7605,  1.6384, -0.1381],\n",
            "        [-1.8710,  1.9479, -0.3150],\n",
            "        [-1.7161,  1.8010, -0.1628],\n",
            "        [ 0.7365, -0.3129, -1.0305],\n",
            "        [-1.8163,  0.8797,  0.9460],\n",
            "        [-1.7379,  2.0187, -0.2285]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8043,  1.4222,  0.4072],\n",
            "        [-1.8394,  1.8430, -0.0921],\n",
            "        [-1.7488,  1.9878, -0.2635],\n",
            "        [-1.7205,  1.8745, -0.1225],\n",
            "        [ 0.6453, -0.2644, -0.9667],\n",
            "        [-1.8903,  1.8710, -0.1345],\n",
            "        [-1.6879,  1.6957, -0.4292],\n",
            "        [ 0.7391, -0.2162, -0.9965],\n",
            "        [-1.9949,  1.3117,  0.6322],\n",
            "        [-1.8026,  0.6047,  1.0032],\n",
            "        [-1.7605,  1.6384, -0.1381],\n",
            "        [-1.8710,  1.9479, -0.3150],\n",
            "        [-1.7161,  1.8010, -0.1628],\n",
            "        [ 0.7365, -0.3129, -1.0305],\n",
            "        [-1.8163,  0.8797,  0.9460],\n",
            "        [-1.7379,  2.0187, -0.2285]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5363,  0.8037,  1.0379],\n",
            "        [-1.5958,  1.7429, -0.2484],\n",
            "        [ 0.1019,  0.3186, -0.9829],\n",
            "        [-1.2041,  1.3891, -0.6259],\n",
            "        [-2.0258,  1.7231,  0.1567],\n",
            "        [-1.7819,  2.1006, -0.0451],\n",
            "        [-1.7087,  0.6986,  1.1054],\n",
            "        [-1.9102,  1.9796, -0.3440],\n",
            "        [ 0.6092, -0.3236, -1.0250],\n",
            "        [-2.0549,  2.1289, -0.2932],\n",
            "        [-1.8667,  1.9664, -0.1882],\n",
            "        [-1.7628,  1.8203, -0.3026],\n",
            "        [ 0.6873, -0.2342, -1.0121],\n",
            "        [ 0.5485,  0.0840, -1.1087],\n",
            "        [-1.6487,  0.5817,  1.0979],\n",
            "        [-1.7331,  0.3608,  1.0780]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5363,  0.8037,  1.0379],\n",
            "        [-1.5958,  1.7429, -0.2484],\n",
            "        [ 0.1019,  0.3186, -0.9829],\n",
            "        [-1.2041,  1.3891, -0.6259],\n",
            "        [-2.0258,  1.7231,  0.1567],\n",
            "        [-1.7819,  2.1006, -0.0451],\n",
            "        [-1.7087,  0.6986,  1.1054],\n",
            "        [-1.9102,  1.9796, -0.3440],\n",
            "        [ 0.6092, -0.3236, -1.0250],\n",
            "        [-2.0549,  2.1289, -0.2932],\n",
            "        [-1.8667,  1.9664, -0.1882],\n",
            "        [-1.7628,  1.8203, -0.3026],\n",
            "        [ 0.6873, -0.2342, -1.0121],\n",
            "        [ 0.5485,  0.0840, -1.1087],\n",
            "        [-1.6487,  0.5817,  1.0979],\n",
            "        [-1.7331,  0.3608,  1.0780]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9948,  1.9368, -0.2455],\n",
            "        [-1.7885,  0.6167,  1.0646],\n",
            "        [-1.9992,  1.0577,  0.6305],\n",
            "        [-1.5985,  0.5400,  0.9923],\n",
            "        [-1.7078,  1.6505, -0.2339],\n",
            "        [-1.8000,  0.6082,  1.1183],\n",
            "        [-1.9069,  1.9383, -0.3338],\n",
            "        [-1.7136,  0.3185,  1.1017],\n",
            "        [-1.9949,  0.7659,  0.9898],\n",
            "        [-1.7494,  1.8751, -0.1034],\n",
            "        [-1.7357,  1.2080,  0.4848],\n",
            "        [-1.8502,  2.0241, -0.1058],\n",
            "        [-2.0025,  1.7446, -0.0969],\n",
            "        [-1.7503,  1.5864, -0.3508],\n",
            "        [-1.7135,  0.5060,  0.8229],\n",
            "        [-1.5174,  1.5608, -0.4459]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9948,  1.9368, -0.2455],\n",
            "        [-1.7885,  0.6167,  1.0646],\n",
            "        [-1.9992,  1.0577,  0.6305],\n",
            "        [-1.5985,  0.5400,  0.9923],\n",
            "        [-1.7078,  1.6505, -0.2339],\n",
            "        [-1.8000,  0.6082,  1.1183],\n",
            "        [-1.9069,  1.9383, -0.3338],\n",
            "        [-1.7136,  0.3185,  1.1017],\n",
            "        [-1.9949,  0.7659,  0.9898],\n",
            "        [-1.7494,  1.8751, -0.1034],\n",
            "        [-1.7357,  1.2080,  0.4848],\n",
            "        [-1.8502,  2.0241, -0.1058],\n",
            "        [-2.0025,  1.7446, -0.0969],\n",
            "        [-1.7503,  1.5864, -0.3508],\n",
            "        [-1.7135,  0.5060,  0.8229],\n",
            "        [-1.5174,  1.5608, -0.4459]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9985,  1.9334, -0.1613],\n",
            "        [ 0.6449, -0.1787, -1.0367],\n",
            "        [-1.9675,  1.9810, -0.3310],\n",
            "        [-2.1625,  1.9933,  0.0290],\n",
            "        [ 0.6959, -0.2525, -1.0309],\n",
            "        [-1.7788,  1.8224, -0.2060],\n",
            "        [-2.0087,  0.7627,  0.8727],\n",
            "        [-1.8200,  0.5623,  1.1437],\n",
            "        [-1.8746,  0.8377,  0.8682],\n",
            "        [ 0.6982, -0.2185, -0.9387],\n",
            "        [-1.8776,  0.6312,  1.0859],\n",
            "        [-1.6574,  0.6797,  1.2508],\n",
            "        [-0.8303,  0.9112, -0.6370],\n",
            "        [-2.0029,  2.1142, -0.2049],\n",
            "        [-1.2445,  1.4564, -0.6350],\n",
            "        [-1.9025,  1.8428, -0.2660]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9985,  1.9334, -0.1613],\n",
            "        [ 0.6449, -0.1787, -1.0367],\n",
            "        [-1.9675,  1.9810, -0.3310],\n",
            "        [-2.1625,  1.9933,  0.0290],\n",
            "        [ 0.6959, -0.2525, -1.0309],\n",
            "        [-1.7788,  1.8224, -0.2060],\n",
            "        [-2.0087,  0.7627,  0.8727],\n",
            "        [-1.8200,  0.5623,  1.1437],\n",
            "        [-1.8746,  0.8377,  0.8682],\n",
            "        [ 0.6982, -0.2185, -0.9387],\n",
            "        [-1.8776,  0.6312,  1.0859],\n",
            "        [-1.6574,  0.6797,  1.2508],\n",
            "        [-0.8303,  0.9112, -0.6370],\n",
            "        [-2.0029,  2.1142, -0.2049],\n",
            "        [-1.2445,  1.4564, -0.6350],\n",
            "        [-1.9025,  1.8428, -0.2660]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9331,  1.8951,  0.0260],\n",
            "        [-1.9143,  0.5682,  1.1036],\n",
            "        [-2.2658,  0.7452,  0.9485],\n",
            "        [-1.9132,  1.7708,  0.2336],\n",
            "        [ 0.8540, -0.3027, -0.8771],\n",
            "        [ 0.6811, -0.2801, -0.9377],\n",
            "        [-1.7594,  1.6779, -0.2618],\n",
            "        [-2.0207,  2.0585, -0.1383],\n",
            "        [-1.8358,  1.8685, -0.1637],\n",
            "        [-1.8149,  1.7743, -0.5307],\n",
            "        [-1.9150,  1.9905, -0.1883],\n",
            "        [-2.0198,  0.7238,  1.3172],\n",
            "        [ 0.7078, -0.0976, -0.9179],\n",
            "        [ 0.5613, -0.1360, -1.0317],\n",
            "        [-1.7236,  0.8144,  0.4899],\n",
            "        [-2.0421,  1.9673, -0.0661]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9331,  1.8951,  0.0260],\n",
            "        [-1.9143,  0.5682,  1.1036],\n",
            "        [-2.2658,  0.7452,  0.9485],\n",
            "        [-1.9132,  1.7708,  0.2336],\n",
            "        [ 0.8540, -0.3027, -0.8771],\n",
            "        [ 0.6811, -0.2801, -0.9377],\n",
            "        [-1.7594,  1.6779, -0.2618],\n",
            "        [-2.0207,  2.0585, -0.1383],\n",
            "        [-1.8358,  1.8685, -0.1637],\n",
            "        [-1.8149,  1.7743, -0.5307],\n",
            "        [-1.9150,  1.9905, -0.1883],\n",
            "        [-2.0198,  0.7238,  1.3172],\n",
            "        [ 0.7078, -0.0976, -0.9179],\n",
            "        [ 0.5613, -0.1360, -1.0317],\n",
            "        [-1.7236,  0.8144,  0.4899],\n",
            "        [-2.0421,  1.9673, -0.0661]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2643,  1.4606,  0.4810],\n",
            "        [-1.9675,  2.0419, -0.1965],\n",
            "        [-1.8861,  1.8589, -0.0607],\n",
            "        [-1.7365,  1.7852,  0.0699],\n",
            "        [-1.8199,  1.9517, -0.1840],\n",
            "        [-1.7506,  1.8294, -0.0604],\n",
            "        [-1.7295,  1.9404, -0.3671],\n",
            "        [-2.1371,  0.8673,  1.0982],\n",
            "        [-1.8983,  1.8786, -0.1018],\n",
            "        [ 0.5924, -0.0099, -0.9913],\n",
            "        [-2.0409,  1.5201,  0.0183],\n",
            "        [-1.9488,  0.8327,  0.9463],\n",
            "        [-1.8726,  1.6503, -0.0172],\n",
            "        [ 0.7219, -0.3011, -1.1746],\n",
            "        [-2.0859,  1.8900, -0.2327],\n",
            "        [-2.0462,  0.7094,  1.2329]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.2643,  1.4606,  0.4810],\n",
            "        [-1.9675,  2.0419, -0.1965],\n",
            "        [-1.8861,  1.8589, -0.0607],\n",
            "        [-1.7365,  1.7852,  0.0699],\n",
            "        [-1.8199,  1.9517, -0.1840],\n",
            "        [-1.7506,  1.8294, -0.0604],\n",
            "        [-1.7295,  1.9404, -0.3671],\n",
            "        [-2.1371,  0.8673,  1.0982],\n",
            "        [-1.8983,  1.8786, -0.1018],\n",
            "        [ 0.5924, -0.0099, -0.9913],\n",
            "        [-2.0409,  1.5201,  0.0183],\n",
            "        [-1.9488,  0.8327,  0.9463],\n",
            "        [-1.8726,  1.6503, -0.0172],\n",
            "        [ 0.7219, -0.3011, -1.1746],\n",
            "        [-2.0859,  1.8900, -0.2327],\n",
            "        [-2.0462,  0.7094,  1.2329]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0745,  1.6300,  0.0409],\n",
            "        [-1.8321,  1.9685, -0.1503],\n",
            "        [-2.2917,  1.6920,  0.1762],\n",
            "        [-2.1372,  1.4006,  0.6379],\n",
            "        [-1.9552,  1.6589, -0.2100],\n",
            "        [-1.9018,  0.6654,  1.1176],\n",
            "        [-1.8733,  1.9566, -0.3496],\n",
            "        [-1.9156,  0.4847,  1.1790],\n",
            "        [-1.7856,  1.3906,  0.4417],\n",
            "        [-2.1159,  1.9394, -0.2985],\n",
            "        [-2.0539,  0.5065,  1.0964],\n",
            "        [-1.6600,  0.5867,  1.1171],\n",
            "        [-1.9864,  1.8989, -0.1980],\n",
            "        [-1.8204,  0.6293,  0.9826],\n",
            "        [-1.6265,  1.8513, -0.4270],\n",
            "        [-1.9827,  1.8952,  0.1371]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0745,  1.6300,  0.0409],\n",
            "        [-1.8321,  1.9685, -0.1503],\n",
            "        [-2.2917,  1.6920,  0.1762],\n",
            "        [-2.1372,  1.4006,  0.6379],\n",
            "        [-1.9552,  1.6589, -0.2100],\n",
            "        [-1.9018,  0.6654,  1.1176],\n",
            "        [-1.8733,  1.9566, -0.3496],\n",
            "        [-1.9156,  0.4847,  1.1790],\n",
            "        [-1.7856,  1.3906,  0.4417],\n",
            "        [-2.1159,  1.9394, -0.2985],\n",
            "        [-2.0539,  0.5065,  1.0964],\n",
            "        [-1.6600,  0.5867,  1.1171],\n",
            "        [-1.9864,  1.8989, -0.1980],\n",
            "        [-1.8204,  0.6293,  0.9826],\n",
            "        [-1.6265,  1.8513, -0.4270],\n",
            "        [-1.9827,  1.8952,  0.1371]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0796,  1.5926, -0.0224],\n",
            "        [-2.0651,  1.2403,  0.7167],\n",
            "        [-2.0058,  1.5066, -0.1117],\n",
            "        [ 0.5904, -0.0757, -1.0497],\n",
            "        [-0.0826,  0.1991, -0.4146],\n",
            "        [ 0.6160, -0.0050, -0.9756],\n",
            "        [-1.6827,  1.7573, -0.4025],\n",
            "        [-1.9482,  0.7943,  0.9419],\n",
            "        [-1.8733,  0.5555,  1.0271],\n",
            "        [-1.4186,  0.6514,  0.4980],\n",
            "        [-1.8092,  1.7874, -0.3140],\n",
            "        [-1.6623,  0.4181,  0.9154],\n",
            "        [ 0.7885,  0.1250, -1.1220],\n",
            "        [-1.9577,  2.0901, -0.1548],\n",
            "        [-2.0241,  1.3183,  0.4962],\n",
            "        [ 0.5153,  0.1428, -1.1269]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0796,  1.5926, -0.0224],\n",
            "        [-2.0651,  1.2403,  0.7167],\n",
            "        [-2.0058,  1.5066, -0.1117],\n",
            "        [ 0.5904, -0.0757, -1.0497],\n",
            "        [-0.0826,  0.1991, -0.4146],\n",
            "        [ 0.6160, -0.0050, -0.9756],\n",
            "        [-1.6827,  1.7573, -0.4025],\n",
            "        [-1.9482,  0.7943,  0.9419],\n",
            "        [-1.8733,  0.5555,  1.0271],\n",
            "        [-1.4186,  0.6514,  0.4980],\n",
            "        [-1.8092,  1.7874, -0.3140],\n",
            "        [-1.6623,  0.4181,  0.9154],\n",
            "        [ 0.7885,  0.1250, -1.1220],\n",
            "        [-1.9577,  2.0901, -0.1548],\n",
            "        [-2.0241,  1.3183,  0.4962],\n",
            "        [ 0.5153,  0.1428, -1.1269]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.4671,  0.1615, -1.1710],\n",
            "        [-1.8458,  1.7932, -0.0938],\n",
            "        [ 0.5809, -0.1655, -1.1646],\n",
            "        [-1.8108,  0.5825,  1.0544],\n",
            "        [-1.8130,  1.8553, -0.4272],\n",
            "        [-1.9795,  1.9620, -0.3285],\n",
            "        [-2.1029,  1.9010, -0.0279],\n",
            "        [-1.9275,  0.7389,  1.0629],\n",
            "        [-1.7310,  1.6210, -0.1779],\n",
            "        [-1.6383,  1.9046, -0.1799],\n",
            "        [-1.8310,  1.7271, -0.1535],\n",
            "        [-2.1325,  1.7497,  0.1559],\n",
            "        [-2.0302,  0.5922,  1.1526],\n",
            "        [-1.8355,  1.9919, -0.2384],\n",
            "        [-1.8093,  0.6669,  1.0102],\n",
            "        [-2.0828,  0.6715,  1.3356]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.4671,  0.1615, -1.1710],\n",
            "        [-1.8458,  1.7932, -0.0938],\n",
            "        [ 0.5809, -0.1655, -1.1646],\n",
            "        [-1.8108,  0.5825,  1.0544],\n",
            "        [-1.8130,  1.8553, -0.4272],\n",
            "        [-1.9795,  1.9620, -0.3285],\n",
            "        [-2.1029,  1.9010, -0.0279],\n",
            "        [-1.9275,  0.7389,  1.0629],\n",
            "        [-1.7310,  1.6210, -0.1779],\n",
            "        [-1.6383,  1.9046, -0.1799],\n",
            "        [-1.8310,  1.7271, -0.1535],\n",
            "        [-2.1325,  1.7497,  0.1559],\n",
            "        [-2.0302,  0.5922,  1.1526],\n",
            "        [-1.8355,  1.9919, -0.2384],\n",
            "        [-1.8093,  0.6669,  1.0102],\n",
            "        [-2.0828,  0.6715,  1.3356]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5557, -0.0187, -1.1778],\n",
            "        [-1.8838,  0.7025,  1.0661],\n",
            "        [-1.6457,  2.0632, -0.4261],\n",
            "        [-0.6431,  0.8249, -0.7859],\n",
            "        [-1.9919,  2.0959, -0.1615],\n",
            "        [-2.2344,  1.8686,  0.2798],\n",
            "        [-1.8062,  0.5149,  1.1510],\n",
            "        [-2.1029,  1.8168, -0.0596],\n",
            "        [-1.9927,  2.0921, -0.2968],\n",
            "        [-1.8950,  1.8977, -0.2199],\n",
            "        [-2.0400,  1.7720,  0.2715],\n",
            "        [-2.0345,  0.8644,  0.9179],\n",
            "        [-1.6732,  0.4669,  0.9177],\n",
            "        [-2.0127,  1.8628, -0.0531],\n",
            "        [-1.9482,  1.8997, -0.2681],\n",
            "        [-1.6088,  2.0251, -0.2223]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.5557, -0.0187, -1.1778],\n",
            "        [-1.8838,  0.7025,  1.0661],\n",
            "        [-1.6457,  2.0632, -0.4261],\n",
            "        [-0.6431,  0.8249, -0.7859],\n",
            "        [-1.9919,  2.0959, -0.1615],\n",
            "        [-2.2344,  1.8686,  0.2798],\n",
            "        [-1.8062,  0.5149,  1.1510],\n",
            "        [-2.1029,  1.8168, -0.0596],\n",
            "        [-1.9927,  2.0921, -0.2968],\n",
            "        [-1.8950,  1.8977, -0.2199],\n",
            "        [-2.0400,  1.7720,  0.2715],\n",
            "        [-2.0345,  0.8644,  0.9179],\n",
            "        [-1.6732,  0.4669,  0.9177],\n",
            "        [-2.0127,  1.8628, -0.0531],\n",
            "        [-1.9482,  1.8997, -0.2681],\n",
            "        [-1.6088,  2.0251, -0.2223]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9254,  2.0005,  0.1956],\n",
            "        [-1.5915,  0.8454,  0.3890],\n",
            "        [-1.9672,  0.7178,  1.1267],\n",
            "        [-1.8844,  0.6469,  1.2281],\n",
            "        [-1.8604,  0.6910,  1.1672],\n",
            "        [-2.1329,  1.5915,  0.4905],\n",
            "        [-1.7216,  1.8991, -0.1237],\n",
            "        [-2.2119,  2.0331, -0.1073],\n",
            "        [-1.8929,  1.8185, -0.2363],\n",
            "        [-2.1119,  0.7799,  1.0951],\n",
            "        [-1.9394,  0.6678,  1.0131],\n",
            "        [-1.7652,  0.6905,  1.0078],\n",
            "        [-1.2849,  1.4521, -0.5854],\n",
            "        [-2.0793,  0.6894,  1.0519],\n",
            "        [-1.7161,  0.5865,  1.0966],\n",
            "        [-1.9144,  2.0329, -0.1774]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9254,  2.0005,  0.1956],\n",
            "        [-1.5915,  0.8454,  0.3890],\n",
            "        [-1.9672,  0.7178,  1.1267],\n",
            "        [-1.8844,  0.6469,  1.2281],\n",
            "        [-1.8604,  0.6910,  1.1672],\n",
            "        [-2.1329,  1.5915,  0.4905],\n",
            "        [-1.7216,  1.8991, -0.1237],\n",
            "        [-2.2119,  2.0331, -0.1073],\n",
            "        [-1.8929,  1.8185, -0.2363],\n",
            "        [-2.1119,  0.7799,  1.0951],\n",
            "        [-1.9394,  0.6678,  1.0131],\n",
            "        [-1.7652,  0.6905,  1.0078],\n",
            "        [-1.2849,  1.4521, -0.5854],\n",
            "        [-2.0793,  0.6894,  1.0519],\n",
            "        [-1.7161,  0.5865,  1.0966],\n",
            "        [-1.9144,  2.0329, -0.1774]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.0826,  0.2981, -0.5399],\n",
            "        [-1.7736,  2.1029, -0.2673],\n",
            "        [-2.1360,  1.9807, -0.0778],\n",
            "        [-1.8733,  1.8113, -0.1610],\n",
            "        [-1.7613,  0.5925,  0.8507],\n",
            "        [-1.8264,  1.8617, -0.2723],\n",
            "        [-1.7184,  1.7886, -0.3101],\n",
            "        [-2.2206,  2.1406, -0.0368],\n",
            "        [-0.4308,  0.4344, -0.3153],\n",
            "        [ 0.1238,  0.4892, -1.0032],\n",
            "        [-1.9525,  1.7108, -0.1503],\n",
            "        [-2.0103,  0.6943,  1.3172],\n",
            "        [ 0.5033, -0.0724, -1.0117],\n",
            "        [-1.9083,  0.7005,  1.0049],\n",
            "        [-1.7502,  2.0679, -0.2151],\n",
            "        [-1.8999,  0.4548,  0.9918]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-0.0826,  0.2981, -0.5399],\n",
            "        [-1.7736,  2.1029, -0.2673],\n",
            "        [-2.1360,  1.9807, -0.0778],\n",
            "        [-1.8733,  1.8113, -0.1610],\n",
            "        [-1.7613,  0.5925,  0.8507],\n",
            "        [-1.8264,  1.8617, -0.2723],\n",
            "        [-1.7184,  1.7886, -0.3101],\n",
            "        [-2.2206,  2.1406, -0.0368],\n",
            "        [-0.4308,  0.4344, -0.3153],\n",
            "        [ 0.1238,  0.4892, -1.0032],\n",
            "        [-1.9525,  1.7108, -0.1503],\n",
            "        [-2.0103,  0.6943,  1.3172],\n",
            "        [ 0.5033, -0.0724, -1.0117],\n",
            "        [-1.9083,  0.7005,  1.0049],\n",
            "        [-1.7502,  2.0679, -0.2151],\n",
            "        [-1.8999,  0.4548,  0.9918]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7566,  1.7137, -0.2125],\n",
            "        [-1.8541,  1.8175, -0.1628],\n",
            "        [-1.8411,  0.6855,  1.1414],\n",
            "        [-1.9004,  0.7318,  1.1909],\n",
            "        [-1.8060,  2.0779, -0.3169],\n",
            "        [-1.9212,  0.6279,  1.0897],\n",
            "        [ 0.5602,  0.1293, -1.3113],\n",
            "        [ 0.4189,  0.1106, -1.1237],\n",
            "        [ 0.4553,  0.0985, -1.2317],\n",
            "        [-2.0991,  1.0728,  0.7912],\n",
            "        [-1.7595,  0.5375,  1.1672],\n",
            "        [-2.0394,  1.8781, -0.1712],\n",
            "        [-2.0655,  1.7609, -0.0274],\n",
            "        [-1.8906,  2.1423, -0.1881],\n",
            "        [-1.7241,  1.8925, -0.2282],\n",
            "        [-1.9553,  1.9291, -0.3007]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7566,  1.7137, -0.2125],\n",
            "        [-1.8541,  1.8175, -0.1628],\n",
            "        [-1.8411,  0.6855,  1.1414],\n",
            "        [-1.9004,  0.7318,  1.1909],\n",
            "        [-1.8060,  2.0779, -0.3169],\n",
            "        [-1.9212,  0.6279,  1.0897],\n",
            "        [ 0.5602,  0.1293, -1.3113],\n",
            "        [ 0.4189,  0.1106, -1.1237],\n",
            "        [ 0.4553,  0.0985, -1.2317],\n",
            "        [-2.0991,  1.0728,  0.7912],\n",
            "        [-1.7595,  0.5375,  1.1672],\n",
            "        [-2.0394,  1.8781, -0.1712],\n",
            "        [-2.0655,  1.7609, -0.0274],\n",
            "        [-1.8906,  2.1423, -0.1881],\n",
            "        [-1.7241,  1.8925, -0.2282],\n",
            "        [-1.9553,  1.9291, -0.3007]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3327,  0.0657, -0.9827],\n",
            "        [ 0.2524,  0.2450, -0.8644],\n",
            "        [-1.9344,  1.9978, -0.2653],\n",
            "        [-1.9360,  0.5674,  1.2548],\n",
            "        [-1.7411,  1.4147, -0.0644],\n",
            "        [-1.8682,  1.7943, -0.0561],\n",
            "        [-1.8127,  1.8459, -0.2706],\n",
            "        [-2.0632,  0.6067,  1.2717],\n",
            "        [-2.0395,  1.6848, -0.0637],\n",
            "        [-1.9588,  1.6591,  0.3793],\n",
            "        [-2.1086,  0.8823,  0.9152],\n",
            "        [-0.7738,  0.8656, -0.6944],\n",
            "        [-1.9307,  2.1609, -0.1027],\n",
            "        [-1.9600,  0.6210,  1.1101],\n",
            "        [-1.7854,  1.8595, -0.0262],\n",
            "        [-2.2108,  0.6524,  1.3167]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.3327,  0.0657, -0.9827],\n",
            "        [ 0.2524,  0.2450, -0.8644],\n",
            "        [-1.9344,  1.9978, -0.2653],\n",
            "        [-1.9360,  0.5674,  1.2548],\n",
            "        [-1.7411,  1.4147, -0.0644],\n",
            "        [-1.8682,  1.7943, -0.0561],\n",
            "        [-1.8127,  1.8459, -0.2706],\n",
            "        [-2.0632,  0.6067,  1.2717],\n",
            "        [-2.0395,  1.6848, -0.0637],\n",
            "        [-1.9588,  1.6591,  0.3793],\n",
            "        [-2.1086,  0.8823,  0.9152],\n",
            "        [-0.7738,  0.8656, -0.6944],\n",
            "        [-1.9307,  2.1609, -0.1027],\n",
            "        [-1.9600,  0.6210,  1.1101],\n",
            "        [-1.7854,  1.8595, -0.0262],\n",
            "        [-2.2108,  0.6524,  1.3167]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8503,  2.1632, -0.3697],\n",
            "        [-1.9619,  2.0018, -0.3459],\n",
            "        [-1.9023,  0.5524,  1.0958],\n",
            "        [-1.8129,  1.9542, -0.0871],\n",
            "        [-2.0479,  1.9939, -0.0397],\n",
            "        [-1.9168,  0.5434,  1.1867],\n",
            "        [-2.1185,  0.7769,  1.2364],\n",
            "        [-2.1852,  1.3933,  0.4958],\n",
            "        [-1.8299,  0.9155,  1.1833],\n",
            "        [ 0.3837,  0.1428, -1.0104],\n",
            "        [-1.9828,  1.8744, -0.0676],\n",
            "        [-1.7872,  0.4926,  1.1663],\n",
            "        [-2.1824,  1.4461,  0.7026],\n",
            "        [-1.8039,  2.0001, -0.4501],\n",
            "        [-2.1301,  1.0021,  0.9937],\n",
            "        [-2.1378,  1.0090,  0.9102]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8503,  2.1632, -0.3697],\n",
            "        [-1.9619,  2.0018, -0.3459],\n",
            "        [-1.9023,  0.5524,  1.0958],\n",
            "        [-1.8129,  1.9542, -0.0871],\n",
            "        [-2.0479,  1.9939, -0.0397],\n",
            "        [-1.9168,  0.5434,  1.1867],\n",
            "        [-2.1185,  0.7769,  1.2364],\n",
            "        [-2.1852,  1.3933,  0.4958],\n",
            "        [-1.8299,  0.9155,  1.1833],\n",
            "        [ 0.3837,  0.1428, -1.0104],\n",
            "        [-1.9828,  1.8744, -0.0676],\n",
            "        [-1.7872,  0.4926,  1.1663],\n",
            "        [-2.1824,  1.4461,  0.7026],\n",
            "        [-1.8039,  2.0001, -0.4501],\n",
            "        [-2.1301,  1.0021,  0.9937],\n",
            "        [-2.1378,  1.0090,  0.9102]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7275,  1.7313, -0.0949],\n",
            "        [-1.8180,  1.9753, -0.1340],\n",
            "        [ 0.6250, -0.0320, -1.2301],\n",
            "        [ 0.4423,  0.0029, -1.0949],\n",
            "        [-1.6944,  1.7442, -0.0854],\n",
            "        [-2.0687,  1.9239, -0.0324],\n",
            "        [-2.1088,  0.6882,  1.0593],\n",
            "        [ 0.4419,  0.1162, -1.2379],\n",
            "        [-1.8308,  1.9377, -0.2260],\n",
            "        [-2.2489,  1.8917,  0.0177],\n",
            "        [-1.9923,  0.4695,  1.1762],\n",
            "        [-1.9127,  0.4606,  1.1979],\n",
            "        [-1.8810,  1.9025, -0.0628],\n",
            "        [-1.8478,  1.8017, -0.1080],\n",
            "        [-2.0642,  0.6261,  1.4164],\n",
            "        [-1.9741,  1.9668, -0.2414]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7275,  1.7313, -0.0949],\n",
            "        [-1.8180,  1.9753, -0.1340],\n",
            "        [ 0.6250, -0.0320, -1.2301],\n",
            "        [ 0.4423,  0.0029, -1.0949],\n",
            "        [-1.6944,  1.7442, -0.0854],\n",
            "        [-2.0687,  1.9239, -0.0324],\n",
            "        [-2.1088,  0.6882,  1.0593],\n",
            "        [ 0.4419,  0.1162, -1.2379],\n",
            "        [-1.8308,  1.9377, -0.2260],\n",
            "        [-2.2489,  1.8917,  0.0177],\n",
            "        [-1.9923,  0.4695,  1.1762],\n",
            "        [-1.9127,  0.4606,  1.1979],\n",
            "        [-1.8810,  1.9025, -0.0628],\n",
            "        [-1.8478,  1.8017, -0.1080],\n",
            "        [-2.0642,  0.6261,  1.4164],\n",
            "        [-1.9741,  1.9668, -0.2414]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7809,  2.0295, -0.1052],\n",
            "        [ 0.4364, -0.0335, -1.2444],\n",
            "        [-1.5566,  1.7285, -0.3304],\n",
            "        [-1.7899,  1.9207,  0.0244],\n",
            "        [-2.0351,  0.5662,  1.1117],\n",
            "        [-1.9323,  1.9571, -0.0746],\n",
            "        [-2.0376,  0.5108,  1.1411],\n",
            "        [ 0.2392,  0.1162, -0.9641],\n",
            "        [-1.7159,  1.7684, -0.3854],\n",
            "        [-1.6134,  1.7514,  0.0132],\n",
            "        [-1.8666,  1.9191, -0.2525],\n",
            "        [ 0.4375,  0.1347, -0.9495],\n",
            "        [-2.1186,  0.4415,  1.2985],\n",
            "        [-2.1430,  1.7494, -0.1386],\n",
            "        [-1.8504,  1.7735,  0.0040],\n",
            "        [-1.5533,  1.6128, -0.2640]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7809,  2.0295, -0.1052],\n",
            "        [ 0.4364, -0.0335, -1.2444],\n",
            "        [-1.5566,  1.7285, -0.3304],\n",
            "        [-1.7899,  1.9207,  0.0244],\n",
            "        [-2.0351,  0.5662,  1.1117],\n",
            "        [-1.9323,  1.9571, -0.0746],\n",
            "        [-2.0376,  0.5108,  1.1411],\n",
            "        [ 0.2392,  0.1162, -0.9641],\n",
            "        [-1.7159,  1.7684, -0.3854],\n",
            "        [-1.6134,  1.7514,  0.0132],\n",
            "        [-1.8666,  1.9191, -0.2525],\n",
            "        [ 0.4375,  0.1347, -0.9495],\n",
            "        [-2.1186,  0.4415,  1.2985],\n",
            "        [-2.1430,  1.7494, -0.1386],\n",
            "        [-1.8504,  1.7735,  0.0040],\n",
            "        [-1.5533,  1.6128, -0.2640]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8215,  1.7513, -0.1947],\n",
            "        [ 0.1932,  0.0130, -1.0550],\n",
            "        [-2.0594,  2.1237, -0.0990],\n",
            "        [-1.7716,  1.9001, -0.2644],\n",
            "        [-1.8631,  1.7267, -0.2309],\n",
            "        [-1.8023,  1.7048,  0.0990],\n",
            "        [-2.1135,  0.6028,  1.3238],\n",
            "        [-2.1086,  1.7615, -0.1856],\n",
            "        [-1.7989,  1.8151, -0.1777],\n",
            "        [-1.9772,  1.5553, -0.0837],\n",
            "        [-1.9153,  2.0506, -0.2425],\n",
            "        [-2.0310,  0.7364,  1.2464],\n",
            "        [-2.2202,  1.5177,  0.4931],\n",
            "        [-1.9266,  1.7495, -0.3333],\n",
            "        [-1.9102,  1.8009, -0.2471],\n",
            "        [ 0.6017,  0.0135, -1.2259]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8215,  1.7513, -0.1947],\n",
            "        [ 0.1932,  0.0130, -1.0550],\n",
            "        [-2.0594,  2.1237, -0.0990],\n",
            "        [-1.7716,  1.9001, -0.2644],\n",
            "        [-1.8631,  1.7267, -0.2309],\n",
            "        [-1.8023,  1.7048,  0.0990],\n",
            "        [-2.1135,  0.6028,  1.3238],\n",
            "        [-2.1086,  1.7615, -0.1856],\n",
            "        [-1.7989,  1.8151, -0.1777],\n",
            "        [-1.9772,  1.5553, -0.0837],\n",
            "        [-1.9153,  2.0506, -0.2425],\n",
            "        [-2.0310,  0.7364,  1.2464],\n",
            "        [-2.2202,  1.5177,  0.4931],\n",
            "        [-1.9266,  1.7495, -0.3333],\n",
            "        [-1.9102,  1.8009, -0.2471],\n",
            "        [ 0.6017,  0.0135, -1.2259]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6975,  0.4335,  1.2119],\n",
            "        [-1.9290,  0.5222,  1.2472],\n",
            "        [-1.9679,  1.9639, -0.3437],\n",
            "        [-1.6730,  1.6978, -0.1892],\n",
            "        [-1.8076,  1.7964, -0.3868],\n",
            "        [ 0.2066,  0.5087, -0.9622],\n",
            "        [-1.8121,  0.3997,  1.1456],\n",
            "        [-2.0202,  0.5095,  1.2686],\n",
            "        [-1.5328,  1.6806, -0.3851],\n",
            "        [-2.1234,  0.4300,  1.1480],\n",
            "        [-1.9365,  1.2286,  0.3637],\n",
            "        [-1.8164,  1.9562, -0.2235],\n",
            "        [-2.0357,  1.0766,  0.7682],\n",
            "        [-1.9753,  1.9451, -0.1288],\n",
            "        [-2.1667,  2.2285, -0.0254],\n",
            "        [-1.8376,  1.7090,  0.0773]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6975,  0.4335,  1.2119],\n",
            "        [-1.9290,  0.5222,  1.2472],\n",
            "        [-1.9679,  1.9639, -0.3437],\n",
            "        [-1.6730,  1.6978, -0.1892],\n",
            "        [-1.8076,  1.7964, -0.3868],\n",
            "        [ 0.2066,  0.5087, -0.9622],\n",
            "        [-1.8121,  0.3997,  1.1456],\n",
            "        [-2.0202,  0.5095,  1.2686],\n",
            "        [-1.5328,  1.6806, -0.3851],\n",
            "        [-2.1234,  0.4300,  1.1480],\n",
            "        [-1.9365,  1.2286,  0.3637],\n",
            "        [-1.8164,  1.9562, -0.2235],\n",
            "        [-2.0357,  1.0766,  0.7682],\n",
            "        [-1.9753,  1.9451, -0.1288],\n",
            "        [-2.1667,  2.2285, -0.0254],\n",
            "        [-1.8376,  1.7090,  0.0773]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.4715, -0.0064, -1.1706],\n",
            "        [-2.2563,  1.6240,  0.2857],\n",
            "        [-1.9192,  1.8391, -0.2681],\n",
            "        [-1.9211,  1.6706, -0.3614],\n",
            "        [-2.2233,  1.8817, -0.2774],\n",
            "        [-1.8016,  1.8822, -0.2646],\n",
            "        [ 0.5047,  0.1388, -1.1576],\n",
            "        [-2.0590,  0.4797,  1.2465],\n",
            "        [-1.9451,  2.0281, -0.1788],\n",
            "        [-2.0478,  0.7807,  1.0560],\n",
            "        [-1.8245,  1.4814, -0.0385],\n",
            "        [-1.7613,  1.8244, -0.3424],\n",
            "        [ 0.2713,  0.1487, -1.0883],\n",
            "        [-1.7263,  1.3389,  0.5039],\n",
            "        [-1.8256,  1.8975, -0.2311],\n",
            "        [-1.4520,  1.7376, -0.4782]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.4715, -0.0064, -1.1706],\n",
            "        [-2.2563,  1.6240,  0.2857],\n",
            "        [-1.9192,  1.8391, -0.2681],\n",
            "        [-1.9211,  1.6706, -0.3614],\n",
            "        [-2.2233,  1.8817, -0.2774],\n",
            "        [-1.8016,  1.8822, -0.2646],\n",
            "        [ 0.5047,  0.1388, -1.1576],\n",
            "        [-2.0590,  0.4797,  1.2465],\n",
            "        [-1.9451,  2.0281, -0.1788],\n",
            "        [-2.0478,  0.7807,  1.0560],\n",
            "        [-1.8245,  1.4814, -0.0385],\n",
            "        [-1.7613,  1.8244, -0.3424],\n",
            "        [ 0.2713,  0.1487, -1.0883],\n",
            "        [-1.7263,  1.3389,  0.5039],\n",
            "        [-1.8256,  1.8975, -0.2311],\n",
            "        [-1.4520,  1.7376, -0.4782]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9942,  2.0902, -0.1385],\n",
            "        [-1.8151,  1.8665, -0.3283],\n",
            "        [-1.9723,  0.7737,  1.1359],\n",
            "        [-2.0030,  1.0159,  1.0065],\n",
            "        [-1.9815,  1.9627, -0.2953],\n",
            "        [-2.3292,  1.3103,  0.9692],\n",
            "        [-1.9389,  1.0161,  0.9921],\n",
            "        [-1.7675,  0.6732,  1.3080],\n",
            "        [ 0.6022,  0.1074, -1.1962],\n",
            "        [-1.9939,  0.8230,  1.1158],\n",
            "        [-1.7097,  1.8474, -0.5112],\n",
            "        [-2.0390,  1.8111, -0.1452],\n",
            "        [-2.0634,  0.5636,  1.2759],\n",
            "        [-2.0481,  0.5969,  1.2108],\n",
            "        [-1.8675,  0.4968,  1.3224],\n",
            "        [-1.9135,  2.0842, -0.3527]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9942,  2.0902, -0.1385],\n",
            "        [-1.8151,  1.8665, -0.3283],\n",
            "        [-1.9723,  0.7737,  1.1359],\n",
            "        [-2.0030,  1.0159,  1.0065],\n",
            "        [-1.9815,  1.9627, -0.2953],\n",
            "        [-2.3292,  1.3103,  0.9692],\n",
            "        [-1.9389,  1.0161,  0.9921],\n",
            "        [-1.7675,  0.6732,  1.3080],\n",
            "        [ 0.6022,  0.1074, -1.1962],\n",
            "        [-1.9939,  0.8230,  1.1158],\n",
            "        [-1.7097,  1.8474, -0.5112],\n",
            "        [-2.0390,  1.8111, -0.1452],\n",
            "        [-2.0634,  0.5636,  1.2759],\n",
            "        [-2.0481,  0.5969,  1.2108],\n",
            "        [-1.8675,  0.4968,  1.3224],\n",
            "        [-1.9135,  2.0842, -0.3527]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7980,  1.8182, -0.1999],\n",
            "        [ 0.5378, -0.1084, -1.1419],\n",
            "        [-1.5799,  1.6470, -0.1904],\n",
            "        [ 0.3984,  0.1839, -1.0960],\n",
            "        [-1.9080,  1.8313, -0.3037],\n",
            "        [-1.7530,  1.9266, -0.2786],\n",
            "        [-1.7286,  1.6291, -0.3510],\n",
            "        [-1.9607,  0.6654,  1.2436],\n",
            "        [-2.0890,  2.0549, -0.0959],\n",
            "        [-2.0596,  0.4082,  1.2142],\n",
            "        [-1.8706,  1.6287, -0.3982],\n",
            "        [-1.7543,  0.3972,  1.5293],\n",
            "        [-1.3795,  1.6849, -0.4770],\n",
            "        [-1.9658,  0.6488,  1.1112],\n",
            "        [ 0.3569,  0.2318, -1.1292],\n",
            "        [-1.8302,  0.5873,  1.1921]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7980,  1.8182, -0.1999],\n",
            "        [ 0.5378, -0.1084, -1.1419],\n",
            "        [-1.5799,  1.6470, -0.1904],\n",
            "        [ 0.3984,  0.1839, -1.0960],\n",
            "        [-1.9080,  1.8313, -0.3037],\n",
            "        [-1.7530,  1.9266, -0.2786],\n",
            "        [-1.7286,  1.6291, -0.3510],\n",
            "        [-1.9607,  0.6654,  1.2436],\n",
            "        [-2.0890,  2.0549, -0.0959],\n",
            "        [-2.0596,  0.4082,  1.2142],\n",
            "        [-1.8706,  1.6287, -0.3982],\n",
            "        [-1.7543,  0.3972,  1.5293],\n",
            "        [-1.3795,  1.6849, -0.4770],\n",
            "        [-1.9658,  0.6488,  1.1112],\n",
            "        [ 0.3569,  0.2318, -1.1292],\n",
            "        [-1.8302,  0.5873,  1.1921]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8479,  2.0584, -0.0996],\n",
            "        [ 0.3623,  0.1438, -1.2882],\n",
            "        [-1.9347,  0.6443,  1.1041],\n",
            "        [-1.9370,  0.6789,  1.1821],\n",
            "        [-1.7790,  1.9675, -0.4425],\n",
            "        [-1.7972,  1.9402, -0.1043],\n",
            "        [-1.8331,  1.7018, -0.3202],\n",
            "        [-1.9154,  1.8921, -0.3182],\n",
            "        [-1.9189,  0.6953,  0.9784],\n",
            "        [-1.7494,  0.8724,  0.9901],\n",
            "        [-1.8227,  2.0763, -0.3115],\n",
            "        [-1.9983,  2.0407, -0.3671],\n",
            "        [-1.6868,  0.5475,  1.1710],\n",
            "        [-1.7702,  1.8537, -0.2858],\n",
            "        [-1.9552,  0.4888,  1.2935],\n",
            "        [-1.7566,  1.6489, -0.4958]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8479,  2.0584, -0.0996],\n",
            "        [ 0.3623,  0.1438, -1.2882],\n",
            "        [-1.9347,  0.6443,  1.1041],\n",
            "        [-1.9370,  0.6789,  1.1821],\n",
            "        [-1.7790,  1.9675, -0.4425],\n",
            "        [-1.7972,  1.9402, -0.1043],\n",
            "        [-1.8331,  1.7018, -0.3202],\n",
            "        [-1.9154,  1.8921, -0.3182],\n",
            "        [-1.9189,  0.6953,  0.9784],\n",
            "        [-1.7494,  0.8724,  0.9901],\n",
            "        [-1.8227,  2.0763, -0.3115],\n",
            "        [-1.9983,  2.0407, -0.3671],\n",
            "        [-1.6868,  0.5475,  1.1710],\n",
            "        [-1.7702,  1.8537, -0.2858],\n",
            "        [-1.9552,  0.4888,  1.2935],\n",
            "        [-1.7566,  1.6489, -0.4958]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9307,  2.0363, -0.3245],\n",
            "        [-1.6219,  1.8414, -0.0714],\n",
            "        [-1.9649,  2.1018, -0.2763],\n",
            "        [-1.6731,  1.9228, -0.3601],\n",
            "        [-1.7037,  1.5106,  0.0371],\n",
            "        [ 0.2599,  0.0743, -0.9675],\n",
            "        [ 0.2748,  0.0330, -1.0775],\n",
            "        [-1.7224,  2.1108, -0.2542],\n",
            "        [-1.8804,  0.8747,  0.9933],\n",
            "        [-1.6732,  2.0709, -0.2981],\n",
            "        [-1.6539,  1.8554, -0.4258],\n",
            "        [-1.8355,  0.5844,  0.6613],\n",
            "        [-2.0574,  0.7337,  1.2831],\n",
            "        [-1.4836,  1.8052, -0.6323],\n",
            "        [-1.7690,  1.9873, -0.4126],\n",
            "        [-1.6033,  0.4178,  1.0673]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9307,  2.0363, -0.3245],\n",
            "        [-1.6219,  1.8414, -0.0714],\n",
            "        [-1.9649,  2.1018, -0.2763],\n",
            "        [-1.6731,  1.9228, -0.3601],\n",
            "        [-1.7037,  1.5106,  0.0371],\n",
            "        [ 0.2599,  0.0743, -0.9675],\n",
            "        [ 0.2748,  0.0330, -1.0775],\n",
            "        [-1.7224,  2.1108, -0.2542],\n",
            "        [-1.8804,  0.8747,  0.9933],\n",
            "        [-1.6732,  2.0709, -0.2981],\n",
            "        [-1.6539,  1.8554, -0.4258],\n",
            "        [-1.8355,  0.5844,  0.6613],\n",
            "        [-2.0574,  0.7337,  1.2831],\n",
            "        [-1.4836,  1.8052, -0.6323],\n",
            "        [-1.7690,  1.9873, -0.4126],\n",
            "        [-1.6033,  0.4178,  1.0673]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8083,  1.7724, -0.5149],\n",
            "        [-1.9951,  1.8223, -0.4616],\n",
            "        [-1.7856,  2.1509, -0.2868],\n",
            "        [-1.7153,  1.9446, -0.3100],\n",
            "        [-1.5731,  1.9493, -0.2597],\n",
            "        [-1.5344,  0.4096,  1.0032],\n",
            "        [-1.7836,  0.3695,  1.1569],\n",
            "        [-1.9661,  2.0626, -0.3652],\n",
            "        [ 0.3497,  0.1991, -1.0877],\n",
            "        [-1.8292,  0.3440,  1.0992],\n",
            "        [-1.8191,  2.1167, -0.2409],\n",
            "        [-1.9803,  2.1936, -0.2413],\n",
            "        [-1.6985,  1.7885, -0.1567],\n",
            "        [-2.0966,  0.6443,  1.3144],\n",
            "        [-1.2531,  1.6932, -0.4243],\n",
            "        [-1.7668,  1.6846, -0.3559]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8083,  1.7724, -0.5149],\n",
            "        [-1.9951,  1.8223, -0.4616],\n",
            "        [-1.7856,  2.1509, -0.2868],\n",
            "        [-1.7153,  1.9446, -0.3100],\n",
            "        [-1.5731,  1.9493, -0.2597],\n",
            "        [-1.5344,  0.4096,  1.0032],\n",
            "        [-1.7836,  0.3695,  1.1569],\n",
            "        [-1.9661,  2.0626, -0.3652],\n",
            "        [ 0.3497,  0.1991, -1.0877],\n",
            "        [-1.8292,  0.3440,  1.0992],\n",
            "        [-1.8191,  2.1167, -0.2409],\n",
            "        [-1.9803,  2.1936, -0.2413],\n",
            "        [-1.6985,  1.7885, -0.1567],\n",
            "        [-2.0966,  0.6443,  1.3144],\n",
            "        [-1.2531,  1.6932, -0.4243],\n",
            "        [-1.7668,  1.6846, -0.3559]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7525,  1.9652, -0.3241],\n",
            "        [-1.8975,  0.4272,  1.1395],\n",
            "        [ 0.2629,  0.3665, -1.1191],\n",
            "        [-1.7567,  2.0205, -0.2698],\n",
            "        [-1.7571,  1.9874, -0.3876],\n",
            "        [ 0.1211,  0.1156, -0.8422],\n",
            "        [-1.8915,  1.9172, -0.3969],\n",
            "        [-1.6747,  1.6847, -0.4213],\n",
            "        [-1.6744,  0.3784,  1.1378],\n",
            "        [-1.6920,  1.7475, -0.2400],\n",
            "        [-1.8550,  2.1188, -0.3315],\n",
            "        [-1.9267,  0.5915,  1.1201],\n",
            "        [-1.8264,  1.8960, -0.3748],\n",
            "        [-1.7115,  1.9335, -0.5082],\n",
            "        [-1.7704,  1.8712, -0.0452],\n",
            "        [-1.9056,  0.5679,  0.9822]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7525,  1.9652, -0.3241],\n",
            "        [-1.8975,  0.4272,  1.1395],\n",
            "        [ 0.2629,  0.3665, -1.1191],\n",
            "        [-1.7567,  2.0205, -0.2698],\n",
            "        [-1.7571,  1.9874, -0.3876],\n",
            "        [ 0.1211,  0.1156, -0.8422],\n",
            "        [-1.8915,  1.9172, -0.3969],\n",
            "        [-1.6747,  1.6847, -0.4213],\n",
            "        [-1.6744,  0.3784,  1.1378],\n",
            "        [-1.6920,  1.7475, -0.2400],\n",
            "        [-1.8550,  2.1188, -0.3315],\n",
            "        [-1.9267,  0.5915,  1.1201],\n",
            "        [-1.8264,  1.8960, -0.3748],\n",
            "        [-1.7115,  1.9335, -0.5082],\n",
            "        [-1.7704,  1.8712, -0.0452],\n",
            "        [-1.9056,  0.5679,  0.9822]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8660,  1.8749, -0.5445],\n",
            "        [-1.8426,  0.5804,  1.2778],\n",
            "        [-1.8822,  1.9538, -0.2412],\n",
            "        [-1.8126,  1.9790, -0.4160],\n",
            "        [-1.7901,  2.0532, -0.2859],\n",
            "        [-1.8853,  1.8744, -0.1772],\n",
            "        [ 0.5135,  0.0567, -1.1155],\n",
            "        [-1.3910,  1.5509, -0.4953],\n",
            "        [-1.5115,  1.9066, -0.6829],\n",
            "        [-1.9470,  0.6888,  1.1584],\n",
            "        [-1.7721,  2.0210, -0.4484],\n",
            "        [-1.6924,  1.7740, -0.3983],\n",
            "        [ 0.4272,  0.0373, -1.0885],\n",
            "        [-1.7705,  0.3702,  1.2029],\n",
            "        [-1.7932,  1.7822, -0.4328],\n",
            "        [-1.5846,  1.8354, -0.3797]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8660,  1.8749, -0.5445],\n",
            "        [-1.8426,  0.5804,  1.2778],\n",
            "        [-1.8822,  1.9538, -0.2412],\n",
            "        [-1.8126,  1.9790, -0.4160],\n",
            "        [-1.7901,  2.0532, -0.2859],\n",
            "        [-1.8853,  1.8744, -0.1772],\n",
            "        [ 0.5135,  0.0567, -1.1155],\n",
            "        [-1.3910,  1.5509, -0.4953],\n",
            "        [-1.5115,  1.9066, -0.6829],\n",
            "        [-1.9470,  0.6888,  1.1584],\n",
            "        [-1.7721,  2.0210, -0.4484],\n",
            "        [-1.6924,  1.7740, -0.3983],\n",
            "        [ 0.4272,  0.0373, -1.0885],\n",
            "        [-1.7705,  0.3702,  1.2029],\n",
            "        [-1.7932,  1.7822, -0.4328],\n",
            "        [-1.5846,  1.8354, -0.3797]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6748,  1.9600, -0.4428],\n",
            "        [-1.6248,  0.4356,  1.0657],\n",
            "        [-2.0002,  1.1919,  0.7020],\n",
            "        [-1.6277,  1.8079, -0.4701],\n",
            "        [-1.8650,  1.7775, -0.3249],\n",
            "        [-1.9540,  2.0137, -0.1804],\n",
            "        [-1.7163,  1.8050, -0.1945],\n",
            "        [-2.0278,  1.9535, -0.4901],\n",
            "        [-1.0150,  1.5149, -0.6359],\n",
            "        [-1.8702,  1.8903, -0.2577],\n",
            "        [-1.7972,  1.9464, -0.3362],\n",
            "        [-1.7838,  0.3794,  1.1399],\n",
            "        [-2.0173,  1.7785, -0.3003],\n",
            "        [ 0.2677,  0.1241, -1.2268],\n",
            "        [-1.5758,  1.9435, -0.4023],\n",
            "        [-1.8451,  1.2023,  0.6505]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6748,  1.9600, -0.4428],\n",
            "        [-1.6248,  0.4356,  1.0657],\n",
            "        [-2.0002,  1.1919,  0.7020],\n",
            "        [-1.6277,  1.8079, -0.4701],\n",
            "        [-1.8650,  1.7775, -0.3249],\n",
            "        [-1.9540,  2.0137, -0.1804],\n",
            "        [-1.7163,  1.8050, -0.1945],\n",
            "        [-2.0278,  1.9535, -0.4901],\n",
            "        [-1.0150,  1.5149, -0.6359],\n",
            "        [-1.8702,  1.8903, -0.2577],\n",
            "        [-1.7972,  1.9464, -0.3362],\n",
            "        [-1.7838,  0.3794,  1.1399],\n",
            "        [-2.0173,  1.7785, -0.3003],\n",
            "        [ 0.2677,  0.1241, -1.2268],\n",
            "        [-1.5758,  1.9435, -0.4023],\n",
            "        [-1.8451,  1.2023,  0.6505]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9606,  2.1562, -0.3095],\n",
            "        [-1.6698,  0.5230,  1.1168],\n",
            "        [-2.0048,  1.9029, -0.3187],\n",
            "        [-0.6298,  0.8456, -0.6928],\n",
            "        [-1.9193,  0.6646,  1.1171],\n",
            "        [-1.8636,  1.7973, -0.5010],\n",
            "        [-0.9564,  0.5730,  0.1302],\n",
            "        [-1.6832,  1.7630, -0.1887],\n",
            "        [-1.9827,  2.0621, -0.3679],\n",
            "        [-1.8827,  1.9858, -0.3370],\n",
            "        [-1.7297,  1.8601, -0.5081],\n",
            "        [-2.0898,  1.5150,  0.6650],\n",
            "        [-1.6904,  1.9821, -0.6824],\n",
            "        [-1.7981,  0.7138,  0.9162],\n",
            "        [-2.0074,  2.1407, -0.4088],\n",
            "        [-1.9032,  0.5762,  1.3409]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9606,  2.1562, -0.3095],\n",
            "        [-1.6698,  0.5230,  1.1168],\n",
            "        [-2.0048,  1.9029, -0.3187],\n",
            "        [-0.6298,  0.8456, -0.6928],\n",
            "        [-1.9193,  0.6646,  1.1171],\n",
            "        [-1.8636,  1.7973, -0.5010],\n",
            "        [-0.9564,  0.5730,  0.1302],\n",
            "        [-1.6832,  1.7630, -0.1887],\n",
            "        [-1.9827,  2.0621, -0.3679],\n",
            "        [-1.8827,  1.9858, -0.3370],\n",
            "        [-1.7297,  1.8601, -0.5081],\n",
            "        [-2.0898,  1.5150,  0.6650],\n",
            "        [-1.6904,  1.9821, -0.6824],\n",
            "        [-1.7981,  0.7138,  0.9162],\n",
            "        [-2.0074,  2.1407, -0.4088],\n",
            "        [-1.9032,  0.5762,  1.3409]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2036,  0.9262,  0.7218],\n",
            "        [-1.7497,  0.4749,  1.1178],\n",
            "        [-1.9861,  1.5614,  0.6529],\n",
            "        [-1.9982,  0.3998,  1.0781],\n",
            "        [-1.9056,  1.9130, -0.3591],\n",
            "        [-1.0480,  1.7295, -0.8152],\n",
            "        [ 0.2646,  0.3166, -1.0304],\n",
            "        [-1.9406,  0.4069,  1.3602],\n",
            "        [ 0.4075,  0.2348, -1.1179],\n",
            "        [-1.7512,  0.4268,  0.9516],\n",
            "        [-2.0296,  1.6191,  0.3028],\n",
            "        [-2.0461,  2.1408, -0.3807],\n",
            "        [-1.7303,  1.9916, -0.3444],\n",
            "        [-1.7037,  1.8755, -0.4344],\n",
            "        [ 0.3611,  0.2053, -1.2159],\n",
            "        [-1.9134,  1.7118, -0.4952]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.2036,  0.9262,  0.7218],\n",
            "        [-1.7497,  0.4749,  1.1178],\n",
            "        [-1.9861,  1.5614,  0.6529],\n",
            "        [-1.9982,  0.3998,  1.0781],\n",
            "        [-1.9056,  1.9130, -0.3591],\n",
            "        [-1.0480,  1.7295, -0.8152],\n",
            "        [ 0.2646,  0.3166, -1.0304],\n",
            "        [-1.9406,  0.4069,  1.3602],\n",
            "        [ 0.4075,  0.2348, -1.1179],\n",
            "        [-1.7512,  0.4268,  0.9516],\n",
            "        [-2.0296,  1.6191,  0.3028],\n",
            "        [-2.0461,  2.1408, -0.3807],\n",
            "        [-1.7303,  1.9916, -0.3444],\n",
            "        [-1.7037,  1.8755, -0.4344],\n",
            "        [ 0.3611,  0.2053, -1.2159],\n",
            "        [-1.9134,  1.7118, -0.4952]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8400,  1.9085, -0.4476],\n",
            "        [ 0.3590,  0.1874, -1.3033],\n",
            "        [-1.7842,  1.9746, -0.2446],\n",
            "        [-1.8644,  2.0313, -0.2448],\n",
            "        [-1.6365,  1.8469, -0.2758],\n",
            "        [-1.8771,  2.0469, -0.0540],\n",
            "        [-1.8565,  0.2294,  1.2499],\n",
            "        [-1.5799,  1.8119, -0.6076],\n",
            "        [-1.9380,  0.4329,  1.0873],\n",
            "        [-2.0572,  0.3752,  1.3735],\n",
            "        [-1.5742,  2.1793, -0.3366],\n",
            "        [-1.7516,  1.7845, -0.4661],\n",
            "        [-1.8871,  2.1306, -0.3173],\n",
            "        [-1.9003,  1.9443, -0.4837],\n",
            "        [-2.0384,  0.4263,  1.2963],\n",
            "        [-1.7777,  2.0657, -0.5315]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8400,  1.9085, -0.4476],\n",
            "        [ 0.3590,  0.1874, -1.3033],\n",
            "        [-1.7842,  1.9746, -0.2446],\n",
            "        [-1.8644,  2.0313, -0.2448],\n",
            "        [-1.6365,  1.8469, -0.2758],\n",
            "        [-1.8771,  2.0469, -0.0540],\n",
            "        [-1.8565,  0.2294,  1.2499],\n",
            "        [-1.5799,  1.8119, -0.6076],\n",
            "        [-1.9380,  0.4329,  1.0873],\n",
            "        [-2.0572,  0.3752,  1.3735],\n",
            "        [-1.5742,  2.1793, -0.3366],\n",
            "        [-1.7516,  1.7845, -0.4661],\n",
            "        [-1.8871,  2.1306, -0.3173],\n",
            "        [-1.9003,  1.9443, -0.4837],\n",
            "        [-2.0384,  0.4263,  1.2963],\n",
            "        [-1.7777,  2.0657, -0.5315]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6279,  0.3681,  0.7816],\n",
            "        [-1.7392,  0.2851,  1.4885],\n",
            "        [-1.7766,  1.9113, -0.3439],\n",
            "        [-1.8943,  2.1135, -0.4690],\n",
            "        [-1.8135,  0.4560,  1.1208],\n",
            "        [ 0.1411,  0.0766, -0.6246],\n",
            "        [-1.9609,  2.0792, -0.5031],\n",
            "        [-1.6989,  1.8595, -0.5281],\n",
            "        [-2.0025,  2.0317, -0.4098],\n",
            "        [-1.7915,  0.8376,  0.5425],\n",
            "        [-1.7606,  2.1153, -0.3894],\n",
            "        [-1.7181,  1.7677, -0.4273],\n",
            "        [ 0.4513,  0.2618, -1.3077],\n",
            "        [-1.8550,  2.1785, -0.5276],\n",
            "        [-1.0710,  1.5008, -0.8776],\n",
            "        [-1.8953,  0.4994,  1.3044]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6279,  0.3681,  0.7816],\n",
            "        [-1.7392,  0.2851,  1.4885],\n",
            "        [-1.7766,  1.9113, -0.3439],\n",
            "        [-1.8943,  2.1135, -0.4690],\n",
            "        [-1.8135,  0.4560,  1.1208],\n",
            "        [ 0.1411,  0.0766, -0.6246],\n",
            "        [-1.9609,  2.0792, -0.5031],\n",
            "        [-1.6989,  1.8595, -0.5281],\n",
            "        [-2.0025,  2.0317, -0.4098],\n",
            "        [-1.7915,  0.8376,  0.5425],\n",
            "        [-1.7606,  2.1153, -0.3894],\n",
            "        [-1.7181,  1.7677, -0.4273],\n",
            "        [ 0.4513,  0.2618, -1.3077],\n",
            "        [-1.8550,  2.1785, -0.5276],\n",
            "        [-1.0710,  1.5008, -0.8776],\n",
            "        [-1.8953,  0.4994,  1.3044]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7692,  2.0139, -0.5853],\n",
            "        [-2.2589,  0.8491,  1.0181],\n",
            "        [-1.6896,  1.8707, -0.5687],\n",
            "        [ 0.1733,  0.4885, -1.2557],\n",
            "        [-1.9978,  1.8205, -0.4790],\n",
            "        [ 0.2456,  0.2832, -1.2197],\n",
            "        [-1.9085,  2.3048, -0.5203],\n",
            "        [-1.5187,  1.8405, -0.3895],\n",
            "        [-1.6126,  1.9507, -0.5983],\n",
            "        [-1.8174,  1.9137, -0.3143],\n",
            "        [-1.6296,  2.1305, -0.3006],\n",
            "        [-1.0601,  0.2419,  0.7057],\n",
            "        [-1.7427,  2.0598, -0.4237],\n",
            "        [ 0.0922,  0.3264, -1.1137],\n",
            "        [ 0.5191,  0.2044, -1.1542],\n",
            "        [ 0.4931,  0.1730, -1.2406]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7692,  2.0139, -0.5853],\n",
            "        [-2.2589,  0.8491,  1.0181],\n",
            "        [-1.6896,  1.8707, -0.5687],\n",
            "        [ 0.1733,  0.4885, -1.2557],\n",
            "        [-1.9978,  1.8205, -0.4790],\n",
            "        [ 0.2456,  0.2832, -1.2197],\n",
            "        [-1.9085,  2.3048, -0.5203],\n",
            "        [-1.5187,  1.8405, -0.3895],\n",
            "        [-1.6126,  1.9507, -0.5983],\n",
            "        [-1.8174,  1.9137, -0.3143],\n",
            "        [-1.6296,  2.1305, -0.3006],\n",
            "        [-1.0601,  0.2419,  0.7057],\n",
            "        [-1.7427,  2.0598, -0.4237],\n",
            "        [ 0.0922,  0.3264, -1.1137],\n",
            "        [ 0.5191,  0.2044, -1.1542],\n",
            "        [ 0.4931,  0.1730, -1.2406]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5252,  1.9213, -0.4386],\n",
            "        [-1.7096,  0.3284,  1.0872],\n",
            "        [-1.8320,  0.3441,  1.2749],\n",
            "        [-1.7152,  2.1213, -0.6461],\n",
            "        [-1.9038,  1.1141,  0.2633],\n",
            "        [-1.8664,  0.2175,  1.2378],\n",
            "        [-1.8154,  0.3972,  1.2893],\n",
            "        [-1.8493,  1.7756, -0.2249],\n",
            "        [-1.6412,  0.4445,  1.0318],\n",
            "        [-1.8875,  1.7912, -0.4217],\n",
            "        [-1.6430,  1.8705, -0.2933],\n",
            "        [-1.8030,  1.8756, -0.5596],\n",
            "        [-1.5716,  0.0380,  1.2243],\n",
            "        [-1.3696,  1.8191, -0.6861],\n",
            "        [-1.7434,  1.8284, -0.5765],\n",
            "        [-1.6973,  2.0750, -0.5175]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5252,  1.9213, -0.4386],\n",
            "        [-1.7096,  0.3284,  1.0872],\n",
            "        [-1.8320,  0.3441,  1.2749],\n",
            "        [-1.7152,  2.1213, -0.6461],\n",
            "        [-1.9038,  1.1141,  0.2633],\n",
            "        [-1.8664,  0.2175,  1.2378],\n",
            "        [-1.8154,  0.3972,  1.2893],\n",
            "        [-1.8493,  1.7756, -0.2249],\n",
            "        [-1.6412,  0.4445,  1.0318],\n",
            "        [-1.8875,  1.7912, -0.4217],\n",
            "        [-1.6430,  1.8705, -0.2933],\n",
            "        [-1.8030,  1.8756, -0.5596],\n",
            "        [-1.5716,  0.0380,  1.2243],\n",
            "        [-1.3696,  1.8191, -0.6861],\n",
            "        [-1.7434,  1.8284, -0.5765],\n",
            "        [-1.6973,  2.0750, -0.5175]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7745,  1.9660, -0.4560],\n",
            "        [-1.7890,  0.5788,  0.9748],\n",
            "        [-1.6745,  1.9331, -0.3726],\n",
            "        [-1.7952,  0.6676,  1.0400],\n",
            "        [-1.8383,  2.2814, -0.1828],\n",
            "        [-1.6925,  1.9567, -0.4894],\n",
            "        [-1.7349,  1.9645, -0.6530],\n",
            "        [ 0.5281,  0.0752, -1.1620],\n",
            "        [-1.5582,  1.8518, -0.6458],\n",
            "        [-1.9488,  2.0139, -0.3065],\n",
            "        [-1.8632,  1.9149, -0.5723],\n",
            "        [-1.6943,  1.9115, -0.4038],\n",
            "        [-1.7650,  2.0306, -0.4803],\n",
            "        [-1.6937,  1.9408, -0.5429],\n",
            "        [ 0.4106,  0.1429, -1.0923],\n",
            "        [-1.5688,  0.4863,  1.2578]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7745,  1.9660, -0.4560],\n",
            "        [-1.7890,  0.5788,  0.9748],\n",
            "        [-1.6745,  1.9331, -0.3726],\n",
            "        [-1.7952,  0.6676,  1.0400],\n",
            "        [-1.8383,  2.2814, -0.1828],\n",
            "        [-1.6925,  1.9567, -0.4894],\n",
            "        [-1.7349,  1.9645, -0.6530],\n",
            "        [ 0.5281,  0.0752, -1.1620],\n",
            "        [-1.5582,  1.8518, -0.6458],\n",
            "        [-1.9488,  2.0139, -0.3065],\n",
            "        [-1.8632,  1.9149, -0.5723],\n",
            "        [-1.6943,  1.9115, -0.4038],\n",
            "        [-1.7650,  2.0306, -0.4803],\n",
            "        [-1.6937,  1.9408, -0.5429],\n",
            "        [ 0.4106,  0.1429, -1.0923],\n",
            "        [-1.5688,  0.4863,  1.2578]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7736,  2.0627, -0.6058],\n",
            "        [-1.8352,  0.2005,  1.3048],\n",
            "        [-1.6112,  2.0560, -0.5609],\n",
            "        [ 0.3491,  0.4007, -1.2989],\n",
            "        [-1.7068,  0.2969,  1.3284],\n",
            "        [-1.7138,  2.1404, -0.8328],\n",
            "        [-1.6378,  0.4053,  1.2730],\n",
            "        [-1.6290,  1.8353, -0.4253],\n",
            "        [-1.7594,  1.8212, -0.4312],\n",
            "        [-1.5416,  1.8649, -0.3969],\n",
            "        [-2.0323,  0.2427,  1.3426],\n",
            "        [-1.8022,  0.4753,  1.0479],\n",
            "        [-1.8517,  1.9885, -0.3742],\n",
            "        [-1.8189,  1.0586,  0.6515],\n",
            "        [-1.5893,  1.7368, -0.5048],\n",
            "        [ 0.4434,  0.1376, -1.1964]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7736,  2.0627, -0.6058],\n",
            "        [-1.8352,  0.2005,  1.3048],\n",
            "        [-1.6112,  2.0560, -0.5609],\n",
            "        [ 0.3491,  0.4007, -1.2989],\n",
            "        [-1.7068,  0.2969,  1.3284],\n",
            "        [-1.7138,  2.1404, -0.8328],\n",
            "        [-1.6378,  0.4053,  1.2730],\n",
            "        [-1.6290,  1.8353, -0.4253],\n",
            "        [-1.7594,  1.8212, -0.4312],\n",
            "        [-1.5416,  1.8649, -0.3969],\n",
            "        [-2.0323,  0.2427,  1.3426],\n",
            "        [-1.8022,  0.4753,  1.0479],\n",
            "        [-1.8517,  1.9885, -0.3742],\n",
            "        [-1.8189,  1.0586,  0.6515],\n",
            "        [-1.5893,  1.7368, -0.5048],\n",
            "        [ 0.4434,  0.1376, -1.1964]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7739,  1.9923, -0.4330],\n",
            "        [-1.6601,  1.8789, -0.6610],\n",
            "        [-1.4216,  1.6801, -0.6932],\n",
            "        [-1.6464,  1.7489, -0.4276],\n",
            "        [-1.7079,  0.2054,  1.2793],\n",
            "        [-1.3162,  1.9006, -0.8569],\n",
            "        [-1.6132,  1.4584,  0.0099],\n",
            "        [-1.5550,  1.8305, -0.8419],\n",
            "        [-1.7375,  0.1700,  1.3359],\n",
            "        [-1.0377,  1.3860, -0.7167],\n",
            "        [ 0.0174,  0.5501, -1.1787],\n",
            "        [-1.7928,  1.6526, -0.1569],\n",
            "        [-1.7193,  0.3138,  1.2413],\n",
            "        [-1.4750,  1.9862, -0.4033],\n",
            "        [-1.6392,  0.3088,  1.1460],\n",
            "        [-1.3113,  1.8278, -0.4939]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7739,  1.9923, -0.4330],\n",
            "        [-1.6601,  1.8789, -0.6610],\n",
            "        [-1.4216,  1.6801, -0.6932],\n",
            "        [-1.6464,  1.7489, -0.4276],\n",
            "        [-1.7079,  0.2054,  1.2793],\n",
            "        [-1.3162,  1.9006, -0.8569],\n",
            "        [-1.6132,  1.4584,  0.0099],\n",
            "        [-1.5550,  1.8305, -0.8419],\n",
            "        [-1.7375,  0.1700,  1.3359],\n",
            "        [-1.0377,  1.3860, -0.7167],\n",
            "        [ 0.0174,  0.5501, -1.1787],\n",
            "        [-1.7928,  1.6526, -0.1569],\n",
            "        [-1.7193,  0.3138,  1.2413],\n",
            "        [-1.4750,  1.9862, -0.4033],\n",
            "        [-1.6392,  0.3088,  1.1460],\n",
            "        [-1.3113,  1.8278, -0.4939]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5794e+00,  1.8629e+00, -6.4519e-01],\n",
            "        [-1.9590e+00,  8.6451e-01,  8.5850e-01],\n",
            "        [-1.6082e+00,  9.3913e-01,  7.6599e-01],\n",
            "        [-1.7271e+00,  1.5440e+00, -3.8058e-02],\n",
            "        [-1.5898e+00,  5.1686e-01,  9.0137e-01],\n",
            "        [-1.2308e+00,  1.6780e+00, -8.7869e-01],\n",
            "        [ 2.0115e-01,  2.4193e-01, -1.3580e+00],\n",
            "        [-5.9021e-01,  1.3048e-03,  1.8510e-01],\n",
            "        [-1.6009e+00,  4.0568e-01,  1.1234e+00],\n",
            "        [-1.8636e-01,  2.1929e-01, -3.8122e-01],\n",
            "        [ 3.4342e-01,  3.2392e-01, -1.1749e+00],\n",
            "        [-1.4418e+00,  2.1783e+00, -7.1542e-01],\n",
            "        [-1.5751e+00,  2.0010e+00, -6.6718e-01],\n",
            "        [-1.7376e+00,  4.2319e-01,  1.1537e+00],\n",
            "        [-1.7375e+00,  2.0880e+00, -3.6358e-01],\n",
            "        [-1.7941e+00,  3.4722e-01,  1.3819e+00]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5794e+00,  1.8629e+00, -6.4519e-01],\n",
            "        [-1.9590e+00,  8.6451e-01,  8.5850e-01],\n",
            "        [-1.6082e+00,  9.3913e-01,  7.6599e-01],\n",
            "        [-1.7271e+00,  1.5440e+00, -3.8058e-02],\n",
            "        [-1.5898e+00,  5.1686e-01,  9.0137e-01],\n",
            "        [-1.2308e+00,  1.6780e+00, -8.7869e-01],\n",
            "        [ 2.0115e-01,  2.4193e-01, -1.3580e+00],\n",
            "        [-5.9021e-01,  1.3048e-03,  1.8510e-01],\n",
            "        [-1.6009e+00,  4.0568e-01,  1.1234e+00],\n",
            "        [-1.8636e-01,  2.1929e-01, -3.8122e-01],\n",
            "        [ 3.4342e-01,  3.2392e-01, -1.1749e+00],\n",
            "        [-1.4418e+00,  2.1783e+00, -7.1542e-01],\n",
            "        [-1.5751e+00,  2.0010e+00, -6.6718e-01],\n",
            "        [-1.7376e+00,  4.2319e-01,  1.1537e+00],\n",
            "        [-1.7375e+00,  2.0880e+00, -3.6358e-01],\n",
            "        [-1.7941e+00,  3.4722e-01,  1.3819e+00]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6248,  2.0606, -0.6565],\n",
            "        [-1.9503,  0.7815,  0.8621],\n",
            "        [-1.6487,  0.4016,  1.0643],\n",
            "        [-1.7697,  1.8451, -0.8832],\n",
            "        [-1.6866,  0.3014,  1.1326],\n",
            "        [-1.5357,  1.7199, -0.5801],\n",
            "        [-1.7184,  0.2217,  1.2624],\n",
            "        [-1.7445,  0.2814,  1.1862],\n",
            "        [-1.7794,  1.9634, -0.4928],\n",
            "        [-1.5544,  0.3562,  1.2622],\n",
            "        [-0.9092,  0.1428,  0.5464],\n",
            "        [-1.6405,  1.1909,  0.2435],\n",
            "        [-1.5503,  2.0247, -0.7061],\n",
            "        [ 0.3406,  0.2806, -1.4682],\n",
            "        [-1.4167,  1.3452,  0.0232],\n",
            "        [-1.6396,  1.7918, -0.4996]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6248,  2.0606, -0.6565],\n",
            "        [-1.9503,  0.7815,  0.8621],\n",
            "        [-1.6487,  0.4016,  1.0643],\n",
            "        [-1.7697,  1.8451, -0.8832],\n",
            "        [-1.6866,  0.3014,  1.1326],\n",
            "        [-1.5357,  1.7199, -0.5801],\n",
            "        [-1.7184,  0.2217,  1.2624],\n",
            "        [-1.7445,  0.2814,  1.1862],\n",
            "        [-1.7794,  1.9634, -0.4928],\n",
            "        [-1.5544,  0.3562,  1.2622],\n",
            "        [-0.9092,  0.1428,  0.5464],\n",
            "        [-1.6405,  1.1909,  0.2435],\n",
            "        [-1.5503,  2.0247, -0.7061],\n",
            "        [ 0.3406,  0.2806, -1.4682],\n",
            "        [-1.4167,  1.3452,  0.0232],\n",
            "        [-1.6396,  1.7918, -0.4996]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3056,  0.2184, -1.1431],\n",
            "        [-1.8521,  0.5970,  1.1491],\n",
            "        [-0.9147,  1.4155, -0.8999],\n",
            "        [-1.5910,  1.7953, -0.4507],\n",
            "        [-1.6338,  0.3119,  0.8881],\n",
            "        [-1.5992,  2.0259, -0.4318],\n",
            "        [-1.8064,  1.5130,  0.1901],\n",
            "        [-1.5522,  1.3344,  0.0151],\n",
            "        [-1.5733, -0.0253,  1.1056],\n",
            "        [-1.5026,  1.8396, -0.5730],\n",
            "        [-1.6040,  0.9658,  0.5994],\n",
            "        [-1.7762,  0.3203,  1.3648],\n",
            "        [-1.6016,  2.2204, -0.8538],\n",
            "        [-1.5378,  1.9459, -0.5111],\n",
            "        [-1.6948,  2.0717, -0.6386],\n",
            "        [-1.4851,  0.0417,  1.2058]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.3056,  0.2184, -1.1431],\n",
            "        [-1.8521,  0.5970,  1.1491],\n",
            "        [-0.9147,  1.4155, -0.8999],\n",
            "        [-1.5910,  1.7953, -0.4507],\n",
            "        [-1.6338,  0.3119,  0.8881],\n",
            "        [-1.5992,  2.0259, -0.4318],\n",
            "        [-1.8064,  1.5130,  0.1901],\n",
            "        [-1.5522,  1.3344,  0.0151],\n",
            "        [-1.5733, -0.0253,  1.1056],\n",
            "        [-1.5026,  1.8396, -0.5730],\n",
            "        [-1.6040,  0.9658,  0.5994],\n",
            "        [-1.7762,  0.3203,  1.3648],\n",
            "        [-1.6016,  2.2204, -0.8538],\n",
            "        [-1.5378,  1.9459, -0.5111],\n",
            "        [-1.6948,  2.0717, -0.6386],\n",
            "        [-1.4851,  0.0417,  1.2058]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2615,  1.7893, -0.6798],\n",
            "        [-1.2038,  0.3943,  0.9898],\n",
            "        [ 0.3647,  0.2040, -1.2812],\n",
            "        [-1.3794,  1.8432, -0.7378],\n",
            "        [-1.4748,  2.0703, -0.4477],\n",
            "        [ 0.4292,  0.2698, -1.1390],\n",
            "        [-1.4523,  1.7731, -0.7638],\n",
            "        [-1.2680,  1.6996, -0.9897],\n",
            "        [-1.6568,  0.9851,  0.9644],\n",
            "        [-0.0494,  0.8286, -1.1555],\n",
            "        [-1.3237,  1.7759, -0.7526],\n",
            "        [-1.6277,  1.7708, -0.3252],\n",
            "        [-1.3630,  1.7443, -0.7142],\n",
            "        [-1.6425,  2.1538, -0.7228],\n",
            "        [-1.4518,  1.7022, -0.5117],\n",
            "        [-1.7142,  0.5255,  1.0116]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2615,  1.7893, -0.6798],\n",
            "        [-1.2038,  0.3943,  0.9898],\n",
            "        [ 0.3647,  0.2040, -1.2812],\n",
            "        [-1.3794,  1.8432, -0.7378],\n",
            "        [-1.4748,  2.0703, -0.4477],\n",
            "        [ 0.4292,  0.2698, -1.1390],\n",
            "        [-1.4523,  1.7731, -0.7638],\n",
            "        [-1.2680,  1.6996, -0.9897],\n",
            "        [-1.6568,  0.9851,  0.9644],\n",
            "        [-0.0494,  0.8286, -1.1555],\n",
            "        [-1.3237,  1.7759, -0.7526],\n",
            "        [-1.6277,  1.7708, -0.3252],\n",
            "        [-1.3630,  1.7443, -0.7142],\n",
            "        [-1.6425,  2.1538, -0.7228],\n",
            "        [-1.4518,  1.7022, -0.5117],\n",
            "        [-1.7142,  0.5255,  1.0116]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6267,  1.8620, -0.7135],\n",
            "        [-1.7319,  1.9165, -0.8047],\n",
            "        [-1.6068,  1.8157, -0.8278],\n",
            "        [-1.3443,  1.8232, -0.5394],\n",
            "        [ 0.4261,  0.3012, -1.2540],\n",
            "        [-1.6045,  1.8891, -0.5859],\n",
            "        [-1.4978,  0.4510,  0.7023],\n",
            "        [-1.5168,  1.8771, -0.5920],\n",
            "        [-1.3977,  0.5728,  0.8956],\n",
            "        [-1.6626,  1.8852, -0.4590],\n",
            "        [-1.5667,  0.3138,  1.2589],\n",
            "        [-1.5358,  1.7222, -0.6250],\n",
            "        [-0.4269,  0.0951, -0.0748],\n",
            "        [-1.6538,  1.9351, -0.9336],\n",
            "        [ 0.3320,  0.0877, -1.1219],\n",
            "        [-1.7280,  0.5643,  0.8074]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6267,  1.8620, -0.7135],\n",
            "        [-1.7319,  1.9165, -0.8047],\n",
            "        [-1.6068,  1.8157, -0.8278],\n",
            "        [-1.3443,  1.8232, -0.5394],\n",
            "        [ 0.4261,  0.3012, -1.2540],\n",
            "        [-1.6045,  1.8891, -0.5859],\n",
            "        [-1.4978,  0.4510,  0.7023],\n",
            "        [-1.5168,  1.8771, -0.5920],\n",
            "        [-1.3977,  0.5728,  0.8956],\n",
            "        [-1.6626,  1.8852, -0.4590],\n",
            "        [-1.5667,  0.3138,  1.2589],\n",
            "        [-1.5358,  1.7222, -0.6250],\n",
            "        [-0.4269,  0.0951, -0.0748],\n",
            "        [-1.6538,  1.9351, -0.9336],\n",
            "        [ 0.3320,  0.0877, -1.1219],\n",
            "        [-1.7280,  0.5643,  0.8074]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5949,  1.6930, -0.7674],\n",
            "        [-1.7462,  2.0470, -0.6234],\n",
            "        [-1.6251,  0.2798,  1.1876],\n",
            "        [-0.6523,  1.1605, -1.0752],\n",
            "        [-1.2129,  1.4906, -0.7974],\n",
            "        [-1.5819,  0.2393,  1.2834],\n",
            "        [-1.7473,  1.6802, -0.4893],\n",
            "        [-1.4404,  1.7460, -0.6432],\n",
            "        [-1.6423,  0.2522,  1.1973],\n",
            "        [-1.4397,  1.9393, -0.3364],\n",
            "        [-1.7097,  2.2586, -0.6995],\n",
            "        [ 0.4146,  0.2640, -1.1856],\n",
            "        [-1.5266,  1.7317, -0.8354],\n",
            "        [-1.5846,  1.8581, -0.4835],\n",
            "        [-1.4187,  0.2568,  1.1044],\n",
            "        [-1.6695,  1.9573, -0.7799]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5949,  1.6930, -0.7674],\n",
            "        [-1.7462,  2.0470, -0.6234],\n",
            "        [-1.6251,  0.2798,  1.1876],\n",
            "        [-0.6523,  1.1605, -1.0752],\n",
            "        [-1.2129,  1.4906, -0.7974],\n",
            "        [-1.5819,  0.2393,  1.2834],\n",
            "        [-1.7473,  1.6802, -0.4893],\n",
            "        [-1.4404,  1.7460, -0.6432],\n",
            "        [-1.6423,  0.2522,  1.1973],\n",
            "        [-1.4397,  1.9393, -0.3364],\n",
            "        [-1.7097,  2.2586, -0.6995],\n",
            "        [ 0.4146,  0.2640, -1.1856],\n",
            "        [-1.5266,  1.7317, -0.8354],\n",
            "        [-1.5846,  1.8581, -0.4835],\n",
            "        [-1.4187,  0.2568,  1.1044],\n",
            "        [-1.6695,  1.9573, -0.7799]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4103,  1.5968, -0.4879],\n",
            "        [-1.4696,  1.9246, -0.8021],\n",
            "        [-1.4646,  1.3495, -0.1813],\n",
            "        [ 0.4882,  0.1416, -1.2658],\n",
            "        [-1.5987,  2.0709, -0.7942],\n",
            "        [-1.4347,  1.8536, -0.7757],\n",
            "        [-1.3382,  1.7154, -0.8256],\n",
            "        [ 0.7612,  0.0726, -1.4210],\n",
            "        [-1.4080,  1.9100, -0.7227],\n",
            "        [-1.3468,  0.2724,  1.1778],\n",
            "        [ 0.1371, -0.0344, -0.7152],\n",
            "        [ 0.7288,  0.2870, -1.4738],\n",
            "        [-1.6139,  1.6255, -0.5193],\n",
            "        [-1.1176,  1.7535, -0.8651],\n",
            "        [-1.7235,  0.3208,  1.0815],\n",
            "        [-1.7297,  1.5854,  0.0543]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4103,  1.5968, -0.4879],\n",
            "        [-1.4696,  1.9246, -0.8021],\n",
            "        [-1.4646,  1.3495, -0.1813],\n",
            "        [ 0.4882,  0.1416, -1.2658],\n",
            "        [-1.5987,  2.0709, -0.7942],\n",
            "        [-1.4347,  1.8536, -0.7757],\n",
            "        [-1.3382,  1.7154, -0.8256],\n",
            "        [ 0.7612,  0.0726, -1.4210],\n",
            "        [-1.4080,  1.9100, -0.7227],\n",
            "        [-1.3468,  0.2724,  1.1778],\n",
            "        [ 0.1371, -0.0344, -0.7152],\n",
            "        [ 0.7288,  0.2870, -1.4738],\n",
            "        [-1.6139,  1.6255, -0.5193],\n",
            "        [-1.1176,  1.7535, -0.8651],\n",
            "        [-1.7235,  0.3208,  1.0815],\n",
            "        [-1.7297,  1.5854,  0.0543]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.7386,  0.2022, -1.4592],\n",
            "        [-1.3748,  1.6102, -0.4933],\n",
            "        [-1.4840,  0.2022,  0.9567],\n",
            "        [-1.4508,  0.1528,  1.0912],\n",
            "        [-1.5023,  1.9587, -0.7293],\n",
            "        [-1.7127,  2.0166, -0.6973],\n",
            "        [-1.5687,  0.2689,  1.2111],\n",
            "        [-1.6104,  0.0478,  1.2185],\n",
            "        [-1.6073,  2.0078, -0.5508],\n",
            "        [-1.4382,  0.2937,  1.1345],\n",
            "        [-1.6299,  0.2200,  1.1629],\n",
            "        [-1.4824,  1.8311, -0.8161],\n",
            "        [-1.3948,  1.7578, -0.7826],\n",
            "        [ 0.6491,  0.0335, -1.3558],\n",
            "        [-1.2489,  1.6290, -0.6191],\n",
            "        [-1.3132,  1.8084, -0.7679]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.7386,  0.2022, -1.4592],\n",
            "        [-1.3748,  1.6102, -0.4933],\n",
            "        [-1.4840,  0.2022,  0.9567],\n",
            "        [-1.4508,  0.1528,  1.0912],\n",
            "        [-1.5023,  1.9587, -0.7293],\n",
            "        [-1.7127,  2.0166, -0.6973],\n",
            "        [-1.5687,  0.2689,  1.2111],\n",
            "        [-1.6104,  0.0478,  1.2185],\n",
            "        [-1.6073,  2.0078, -0.5508],\n",
            "        [-1.4382,  0.2937,  1.1345],\n",
            "        [-1.6299,  0.2200,  1.1629],\n",
            "        [-1.4824,  1.8311, -0.8161],\n",
            "        [-1.3948,  1.7578, -0.7826],\n",
            "        [ 0.6491,  0.0335, -1.3558],\n",
            "        [-1.2489,  1.6290, -0.6191],\n",
            "        [-1.3132,  1.8084, -0.7679]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3799,  1.7977, -1.0113],\n",
            "        [-1.5380,  0.3352,  1.1703],\n",
            "        [-1.5539,  1.6315, -0.2549],\n",
            "        [ 0.5410,  0.1600, -1.4159],\n",
            "        [-1.2713,  1.8928, -1.0063],\n",
            "        [ 0.4859,  0.0517, -1.0312],\n",
            "        [-1.2688,  1.5800, -0.5714],\n",
            "        [-1.5044,  0.6172,  0.5374],\n",
            "        [-1.5221,  1.8660, -0.8490],\n",
            "        [-1.4664,  0.2288,  1.0059],\n",
            "        [-1.4556,  1.8418, -0.5898],\n",
            "        [-1.5388,  1.9072, -0.6873],\n",
            "        [-1.7716,  1.2250,  0.1851],\n",
            "        [-1.3570,  0.2108,  1.0871],\n",
            "        [-1.3364,  0.3857,  0.9022],\n",
            "        [-1.2440,  1.6420, -0.6525]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3799,  1.7977, -1.0113],\n",
            "        [-1.5380,  0.3352,  1.1703],\n",
            "        [-1.5539,  1.6315, -0.2549],\n",
            "        [ 0.5410,  0.1600, -1.4159],\n",
            "        [-1.2713,  1.8928, -1.0063],\n",
            "        [ 0.4859,  0.0517, -1.0312],\n",
            "        [-1.2688,  1.5800, -0.5714],\n",
            "        [-1.5044,  0.6172,  0.5374],\n",
            "        [-1.5221,  1.8660, -0.8490],\n",
            "        [-1.4664,  0.2288,  1.0059],\n",
            "        [-1.4556,  1.8418, -0.5898],\n",
            "        [-1.5388,  1.9072, -0.6873],\n",
            "        [-1.7716,  1.2250,  0.1851],\n",
            "        [-1.3570,  0.2108,  1.0871],\n",
            "        [-1.3364,  0.3857,  0.9022],\n",
            "        [-1.2440,  1.6420, -0.6525]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5203,  2.0591, -0.7262],\n",
            "        [-1.3530,  1.7454, -0.3023],\n",
            "        [-1.6462,  0.3273,  1.1934],\n",
            "        [ 0.4648,  0.0441, -0.8740],\n",
            "        [-1.3356,  1.7325, -0.5925],\n",
            "        [-1.5208,  0.1323,  1.0710],\n",
            "        [ 0.4730,  0.1952, -1.4075],\n",
            "        [ 0.3835,  0.2111, -1.1877],\n",
            "        [ 0.5203,  0.1691, -1.4886],\n",
            "        [-1.3490,  1.6457, -0.5763],\n",
            "        [-1.3452,  1.9406, -0.7232],\n",
            "        [-1.4545,  0.3666,  1.0590],\n",
            "        [-1.6455,  0.3589,  1.2902],\n",
            "        [-1.5157,  0.4307,  1.0527],\n",
            "        [-1.1476,  1.7973, -0.4372],\n",
            "        [-0.5398,  0.9738, -0.7616]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5203,  2.0591, -0.7262],\n",
            "        [-1.3530,  1.7454, -0.3023],\n",
            "        [-1.6462,  0.3273,  1.1934],\n",
            "        [ 0.4648,  0.0441, -0.8740],\n",
            "        [-1.3356,  1.7325, -0.5925],\n",
            "        [-1.5208,  0.1323,  1.0710],\n",
            "        [ 0.4730,  0.1952, -1.4075],\n",
            "        [ 0.3835,  0.2111, -1.1877],\n",
            "        [ 0.5203,  0.1691, -1.4886],\n",
            "        [-1.3490,  1.6457, -0.5763],\n",
            "        [-1.3452,  1.9406, -0.7232],\n",
            "        [-1.4545,  0.3666,  1.0590],\n",
            "        [-1.6455,  0.3589,  1.2902],\n",
            "        [-1.5157,  0.4307,  1.0527],\n",
            "        [-1.1476,  1.7973, -0.4372],\n",
            "        [-0.5398,  0.9738, -0.7616]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3825,  0.1172,  1.0562],\n",
            "        [-1.4655,  1.8026, -0.6624],\n",
            "        [-1.4372,  1.6030, -0.3759],\n",
            "        [-1.3615,  1.7861, -0.7011],\n",
            "        [-1.3567,  1.6605, -0.6606],\n",
            "        [-1.2777,  0.2590,  1.3349],\n",
            "        [-1.2351,  1.7134, -0.5503],\n",
            "        [-1.4489,  2.0403, -0.6365],\n",
            "        [ 0.5084,  0.2767, -1.4762],\n",
            "        [-1.4086,  0.1320,  1.1090],\n",
            "        [-1.5139,  0.0936,  1.2530],\n",
            "        [-1.4328,  2.0239, -0.6811],\n",
            "        [-1.2275,  1.8282, -0.4705],\n",
            "        [-1.3115,  1.6697, -0.4534],\n",
            "        [-1.6287,  1.2476, -0.0276],\n",
            "        [-1.6095,  1.9414, -0.7518]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3825,  0.1172,  1.0562],\n",
            "        [-1.4655,  1.8026, -0.6624],\n",
            "        [-1.4372,  1.6030, -0.3759],\n",
            "        [-1.3615,  1.7861, -0.7011],\n",
            "        [-1.3567,  1.6605, -0.6606],\n",
            "        [-1.2777,  0.2590,  1.3349],\n",
            "        [-1.2351,  1.7134, -0.5503],\n",
            "        [-1.4489,  2.0403, -0.6365],\n",
            "        [ 0.5084,  0.2767, -1.4762],\n",
            "        [-1.4086,  0.1320,  1.1090],\n",
            "        [-1.5139,  0.0936,  1.2530],\n",
            "        [-1.4328,  2.0239, -0.6811],\n",
            "        [-1.2275,  1.8282, -0.4705],\n",
            "        [-1.3115,  1.6697, -0.4534],\n",
            "        [-1.6287,  1.2476, -0.0276],\n",
            "        [-1.6095,  1.9414, -0.7518]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.3109,  0.0459, -0.1618],\n",
            "        [ 0.6676,  0.1048, -1.5207],\n",
            "        [-1.3157,  1.6943, -0.5320],\n",
            "        [-1.3887,  1.6967, -0.6819],\n",
            "        [ 0.6619,  0.1586, -1.3338],\n",
            "        [-1.1960,  1.5851, -1.0348],\n",
            "        [-1.4252,  1.8601, -0.6515],\n",
            "        [-0.9092,  0.8444, -0.2248],\n",
            "        [-1.3498,  1.5254, -0.4306],\n",
            "        [-1.1085,  1.6578, -0.5767],\n",
            "        [-1.6576,  0.1724,  1.1046],\n",
            "        [ 0.5225,  0.2775, -1.6163],\n",
            "        [-1.5592,  1.4310,  0.1022],\n",
            "        [ 0.5173,  0.0580, -1.1858],\n",
            "        [-1.2131,  1.5440, -0.6539],\n",
            "        [ 0.5941,  0.1345, -1.1727]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-0.3109,  0.0459, -0.1618],\n",
            "        [ 0.6676,  0.1048, -1.5207],\n",
            "        [-1.3157,  1.6943, -0.5320],\n",
            "        [-1.3887,  1.6967, -0.6819],\n",
            "        [ 0.6619,  0.1586, -1.3338],\n",
            "        [-1.1960,  1.5851, -1.0348],\n",
            "        [-1.4252,  1.8601, -0.6515],\n",
            "        [-0.9092,  0.8444, -0.2248],\n",
            "        [-1.3498,  1.5254, -0.4306],\n",
            "        [-1.1085,  1.6578, -0.5767],\n",
            "        [-1.6576,  0.1724,  1.1046],\n",
            "        [ 0.5225,  0.2775, -1.6163],\n",
            "        [-1.5592,  1.4310,  0.1022],\n",
            "        [ 0.5173,  0.0580, -1.1858],\n",
            "        [-1.2131,  1.5440, -0.6539],\n",
            "        [ 0.5941,  0.1345, -1.1727]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.1355,  1.6822, -0.5649],\n",
            "        [ 0.6089,  0.2918, -1.3596],\n",
            "        [-1.5807,  1.8587, -0.6396],\n",
            "        [ 0.6209,  0.0448, -1.4529],\n",
            "        [-1.2228,  0.2301,  0.8638],\n",
            "        [-1.2344,  1.8206, -0.8925],\n",
            "        [-1.6178,  0.1937,  1.0392],\n",
            "        [-1.6848,  0.2575,  1.5137],\n",
            "        [-1.5763,  0.1411,  1.3872],\n",
            "        [-1.3950,  1.7899, -0.4985],\n",
            "        [ 0.5028,  0.2712, -1.4927],\n",
            "        [-1.3119,  1.7029, -0.8379],\n",
            "        [-1.2231,  1.5961, -0.9040],\n",
            "        [-1.2467,  1.5311, -0.8807],\n",
            "        [-0.0410,  0.6381, -1.2448],\n",
            "        [-1.0969,  0.0939,  1.1210]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.1355,  1.6822, -0.5649],\n",
            "        [ 0.6089,  0.2918, -1.3596],\n",
            "        [-1.5807,  1.8587, -0.6396],\n",
            "        [ 0.6209,  0.0448, -1.4529],\n",
            "        [-1.2228,  0.2301,  0.8638],\n",
            "        [-1.2344,  1.8206, -0.8925],\n",
            "        [-1.6178,  0.1937,  1.0392],\n",
            "        [-1.6848,  0.2575,  1.5137],\n",
            "        [-1.5763,  0.1411,  1.3872],\n",
            "        [-1.3950,  1.7899, -0.4985],\n",
            "        [ 0.5028,  0.2712, -1.4927],\n",
            "        [-1.3119,  1.7029, -0.8379],\n",
            "        [-1.2231,  1.5961, -0.9040],\n",
            "        [-1.2467,  1.5311, -0.8807],\n",
            "        [-0.0410,  0.6381, -1.2448],\n",
            "        [-1.0969,  0.0939,  1.1210]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.1015, -0.0791, -0.5682],\n",
            "        [-1.4496,  1.2071,  0.2258],\n",
            "        [-1.2926,  1.7848, -0.6999],\n",
            "        [-1.3898,  2.0598, -0.6635],\n",
            "        [-1.0368,  1.4346, -0.6629],\n",
            "        [-1.4257,  1.9277, -0.6955],\n",
            "        [-1.4471,  0.1549,  1.0357],\n",
            "        [-1.6673, -0.0069,  1.1014],\n",
            "        [-1.3951,  1.8729, -0.9035],\n",
            "        [-1.4167,  1.4086, -0.0978],\n",
            "        [-0.9548,  1.5123, -0.9383],\n",
            "        [-1.4987,  0.2732,  1.2893],\n",
            "        [ 0.0832,  0.0072, -0.5108],\n",
            "        [-0.2035,  0.6087, -0.6282],\n",
            "        [-1.4877,  1.8677, -0.7819],\n",
            "        [ 0.4547,  0.0710, -1.1075]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.1015, -0.0791, -0.5682],\n",
            "        [-1.4496,  1.2071,  0.2258],\n",
            "        [-1.2926,  1.7848, -0.6999],\n",
            "        [-1.3898,  2.0598, -0.6635],\n",
            "        [-1.0368,  1.4346, -0.6629],\n",
            "        [-1.4257,  1.9277, -0.6955],\n",
            "        [-1.4471,  0.1549,  1.0357],\n",
            "        [-1.6673, -0.0069,  1.1014],\n",
            "        [-1.3951,  1.8729, -0.9035],\n",
            "        [-1.4167,  1.4086, -0.0978],\n",
            "        [-0.9548,  1.5123, -0.9383],\n",
            "        [-1.4987,  0.2732,  1.2893],\n",
            "        [ 0.0832,  0.0072, -0.5108],\n",
            "        [-0.2035,  0.6087, -0.6282],\n",
            "        [-1.4877,  1.8677, -0.7819],\n",
            "        [ 0.4547,  0.0710, -1.1075]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4335,  1.7635, -0.5781],\n",
            "        [-1.5403,  0.2028,  1.1485],\n",
            "        [-1.4440,  1.7070, -0.5265],\n",
            "        [-0.9745,  1.2578, -0.8592],\n",
            "        [ 0.5543,  0.2315, -1.5743],\n",
            "        [-1.3201,  0.0085,  0.9301],\n",
            "        [-1.4946,  0.2491,  1.3389],\n",
            "        [-1.4221,  1.7834, -0.5965],\n",
            "        [ 0.3228,  0.1199, -1.3126],\n",
            "        [-1.2369,  1.6792, -1.0019],\n",
            "        [-1.2454,  1.9459, -0.5557],\n",
            "        [-1.3725,  0.0991,  0.7948],\n",
            "        [-1.4357,  1.4610, -0.6780],\n",
            "        [-1.1522,  1.7738, -0.9735],\n",
            "        [-1.5170,  1.5769, -0.6222],\n",
            "        [-1.6086,  1.3311, -0.0306]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4335,  1.7635, -0.5781],\n",
            "        [-1.5403,  0.2028,  1.1485],\n",
            "        [-1.4440,  1.7070, -0.5265],\n",
            "        [-0.9745,  1.2578, -0.8592],\n",
            "        [ 0.5543,  0.2315, -1.5743],\n",
            "        [-1.3201,  0.0085,  0.9301],\n",
            "        [-1.4946,  0.2491,  1.3389],\n",
            "        [-1.4221,  1.7834, -0.5965],\n",
            "        [ 0.3228,  0.1199, -1.3126],\n",
            "        [-1.2369,  1.6792, -1.0019],\n",
            "        [-1.2454,  1.9459, -0.5557],\n",
            "        [-1.3725,  0.0991,  0.7948],\n",
            "        [-1.4357,  1.4610, -0.6780],\n",
            "        [-1.1522,  1.7738, -0.9735],\n",
            "        [-1.5170,  1.5769, -0.6222],\n",
            "        [-1.6086,  1.3311, -0.0306]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.1963,  1.6856, -0.9892],\n",
            "        [-1.0162,  1.6072, -0.7000],\n",
            "        [-1.5281,  0.4235,  1.1448],\n",
            "        [-1.4515,  1.2750, -0.0723],\n",
            "        [-1.5489,  0.1243,  1.2082],\n",
            "        [-1.4524,  1.8045, -0.6957],\n",
            "        [ 0.5931, -0.0659, -1.2501],\n",
            "        [-1.3880,  1.7025, -0.8101],\n",
            "        [-1.7663,  0.3079,  1.0794],\n",
            "        [-1.5552, -0.0114,  1.2546],\n",
            "        [-1.3326,  1.6581, -0.6018],\n",
            "        [ 0.6136,  0.0422, -1.3259],\n",
            "        [-1.4624,  0.3513,  1.0680],\n",
            "        [-1.6199,  1.5937, -0.3617],\n",
            "        [-1.2831,  1.7142, -0.5520],\n",
            "        [ 0.1179,  0.5671, -1.3170]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.1963,  1.6856, -0.9892],\n",
            "        [-1.0162,  1.6072, -0.7000],\n",
            "        [-1.5281,  0.4235,  1.1448],\n",
            "        [-1.4515,  1.2750, -0.0723],\n",
            "        [-1.5489,  0.1243,  1.2082],\n",
            "        [-1.4524,  1.8045, -0.6957],\n",
            "        [ 0.5931, -0.0659, -1.2501],\n",
            "        [-1.3880,  1.7025, -0.8101],\n",
            "        [-1.7663,  0.3079,  1.0794],\n",
            "        [-1.5552, -0.0114,  1.2546],\n",
            "        [-1.3326,  1.6581, -0.6018],\n",
            "        [ 0.6136,  0.0422, -1.3259],\n",
            "        [-1.4624,  0.3513,  1.0680],\n",
            "        [-1.6199,  1.5937, -0.3617],\n",
            "        [-1.2831,  1.7142, -0.5520],\n",
            "        [ 0.1179,  0.5671, -1.3170]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2922,  1.8358, -0.6134],\n",
            "        [-1.6285,  0.2551,  1.1264],\n",
            "        [-1.6143,  0.3443,  1.2313],\n",
            "        [-1.7885,  0.2591,  1.4378],\n",
            "        [ 0.5870,  0.2995, -1.4366],\n",
            "        [-1.3282,  1.7712, -0.4586],\n",
            "        [-1.4702,  0.6737,  0.8617],\n",
            "        [-1.6681,  0.0759,  1.0732],\n",
            "        [ 0.1928,  0.1152, -0.7015],\n",
            "        [-1.5291,  0.7131,  0.6849],\n",
            "        [-1.3426,  1.6842, -0.6255],\n",
            "        [-1.6015,  1.4460, -0.3200],\n",
            "        [ 0.5159, -0.0474, -0.8355],\n",
            "        [-1.2997,  1.9418, -0.7393],\n",
            "        [-1.3190,  1.6278, -0.7281],\n",
            "        [-1.4806,  1.8468, -0.9451]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2922,  1.8358, -0.6134],\n",
            "        [-1.6285,  0.2551,  1.1264],\n",
            "        [-1.6143,  0.3443,  1.2313],\n",
            "        [-1.7885,  0.2591,  1.4378],\n",
            "        [ 0.5870,  0.2995, -1.4366],\n",
            "        [-1.3282,  1.7712, -0.4586],\n",
            "        [-1.4702,  0.6737,  0.8617],\n",
            "        [-1.6681,  0.0759,  1.0732],\n",
            "        [ 0.1928,  0.1152, -0.7015],\n",
            "        [-1.5291,  0.7131,  0.6849],\n",
            "        [-1.3426,  1.6842, -0.6255],\n",
            "        [-1.6015,  1.4460, -0.3200],\n",
            "        [ 0.5159, -0.0474, -0.8355],\n",
            "        [-1.2997,  1.9418, -0.7393],\n",
            "        [-1.3190,  1.6278, -0.7281],\n",
            "        [-1.4806,  1.8468, -0.9451]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2417,  1.5254, -0.9294],\n",
            "        [-1.2228,  1.5149, -0.9639],\n",
            "        [ 0.4531,  0.1601, -1.3969],\n",
            "        [-0.8141,  1.3136, -0.9984],\n",
            "        [-1.7057,  0.2720,  1.3606],\n",
            "        [-1.6049,  0.3677,  1.0359],\n",
            "        [-1.7258,  0.3267,  1.1487],\n",
            "        [-1.3552,  1.7970, -0.6789],\n",
            "        [-1.3838,  1.5128, -0.2224],\n",
            "        [ 0.6595,  0.0516, -1.2853],\n",
            "        [-1.5329,  0.1892,  1.1852],\n",
            "        [-1.2697,  1.4817, -0.7771],\n",
            "        [-1.2882,  1.9728, -0.7061],\n",
            "        [-1.4143,  1.8137, -0.3308],\n",
            "        [-1.7480,  0.7784,  0.6155],\n",
            "        [-1.1486,  1.5877, -0.9659]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2417,  1.5254, -0.9294],\n",
            "        [-1.2228,  1.5149, -0.9639],\n",
            "        [ 0.4531,  0.1601, -1.3969],\n",
            "        [-0.8141,  1.3136, -0.9984],\n",
            "        [-1.7057,  0.2720,  1.3606],\n",
            "        [-1.6049,  0.3677,  1.0359],\n",
            "        [-1.7258,  0.3267,  1.1487],\n",
            "        [-1.3552,  1.7970, -0.6789],\n",
            "        [-1.3838,  1.5128, -0.2224],\n",
            "        [ 0.6595,  0.0516, -1.2853],\n",
            "        [-1.5329,  0.1892,  1.1852],\n",
            "        [-1.2697,  1.4817, -0.7771],\n",
            "        [-1.2882,  1.9728, -0.7061],\n",
            "        [-1.4143,  1.8137, -0.3308],\n",
            "        [-1.7480,  0.7784,  0.6155],\n",
            "        [-1.1486,  1.5877, -0.9659]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4576e+00,  1.6023e+00, -4.6419e-01],\n",
            "        [-1.4374e+00,  1.8897e+00, -8.0234e-01],\n",
            "        [-7.1400e-01,  1.3387e+00, -1.0870e+00],\n",
            "        [ 6.6748e-01, -4.6221e-04, -1.2090e+00],\n",
            "        [-1.4645e+00,  4.8635e-01,  8.4276e-01],\n",
            "        [-1.4161e+00,  1.0349e-01,  1.0789e+00],\n",
            "        [-1.6499e+00,  1.4696e+00, -2.0077e-01],\n",
            "        [ 7.4780e-01, -8.8378e-02, -1.2785e+00],\n",
            "        [-1.3939e+00,  3.6623e-01,  9.5069e-01],\n",
            "        [-1.5226e+00,  4.3630e-01,  1.0196e+00],\n",
            "        [-1.5382e+00,  1.9669e+00, -6.1502e-01],\n",
            "        [-1.4587e+00,  1.7122e+00, -5.5338e-01],\n",
            "        [-1.4192e+00,  1.5667e+00, -4.3115e-01],\n",
            "        [-1.4178e+00,  1.9538e+00, -7.9360e-01],\n",
            "        [ 3.7171e-01, -3.9997e-02, -1.0199e+00],\n",
            "        [-1.4638e+00,  1.8624e+00, -3.9297e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4576e+00,  1.6023e+00, -4.6419e-01],\n",
            "        [-1.4374e+00,  1.8897e+00, -8.0234e-01],\n",
            "        [-7.1400e-01,  1.3387e+00, -1.0870e+00],\n",
            "        [ 6.6748e-01, -4.6221e-04, -1.2090e+00],\n",
            "        [-1.4645e+00,  4.8635e-01,  8.4276e-01],\n",
            "        [-1.4161e+00,  1.0349e-01,  1.0789e+00],\n",
            "        [-1.6499e+00,  1.4696e+00, -2.0077e-01],\n",
            "        [ 7.4780e-01, -8.8378e-02, -1.2785e+00],\n",
            "        [-1.3939e+00,  3.6623e-01,  9.5069e-01],\n",
            "        [-1.5226e+00,  4.3630e-01,  1.0196e+00],\n",
            "        [-1.5382e+00,  1.9669e+00, -6.1502e-01],\n",
            "        [-1.4587e+00,  1.7122e+00, -5.5338e-01],\n",
            "        [-1.4192e+00,  1.5667e+00, -4.3115e-01],\n",
            "        [-1.4178e+00,  1.9538e+00, -7.9360e-01],\n",
            "        [ 3.7171e-01, -3.9997e-02, -1.0199e+00],\n",
            "        [-1.4638e+00,  1.8624e+00, -3.9297e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3417,  1.5446, -0.7654],\n",
            "        [-1.0413,  0.6375,  0.0790],\n",
            "        [-1.2326,  0.9455,  0.4509],\n",
            "        [-1.4941,  1.5653, -0.3333],\n",
            "        [-1.1577,  1.4745, -0.6995],\n",
            "        [-0.4568, -0.0374,  0.1467],\n",
            "        [-1.3641,  1.8431, -0.8884],\n",
            "        [-0.8789,  1.6239, -0.8672],\n",
            "        [-1.1156,  1.4702, -0.8861],\n",
            "        [-1.4716,  0.3078,  1.0065],\n",
            "        [-1.7929,  1.5155, -0.0893],\n",
            "        [-1.4712,  0.3598,  1.0195],\n",
            "        [-1.4171,  0.8029,  0.4586],\n",
            "        [-1.4813,  0.3320,  1.1267],\n",
            "        [ 0.6059,  0.0780, -1.0289],\n",
            "        [-1.2983,  1.8623, -0.9578]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3417,  1.5446, -0.7654],\n",
            "        [-1.0413,  0.6375,  0.0790],\n",
            "        [-1.2326,  0.9455,  0.4509],\n",
            "        [-1.4941,  1.5653, -0.3333],\n",
            "        [-1.1577,  1.4745, -0.6995],\n",
            "        [-0.4568, -0.0374,  0.1467],\n",
            "        [-1.3641,  1.8431, -0.8884],\n",
            "        [-0.8789,  1.6239, -0.8672],\n",
            "        [-1.1156,  1.4702, -0.8861],\n",
            "        [-1.4716,  0.3078,  1.0065],\n",
            "        [-1.7929,  1.5155, -0.0893],\n",
            "        [-1.4712,  0.3598,  1.0195],\n",
            "        [-1.4171,  0.8029,  0.4586],\n",
            "        [-1.4813,  0.3320,  1.1267],\n",
            "        [ 0.6059,  0.0780, -1.0289],\n",
            "        [-1.2983,  1.8623, -0.9578]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.2119,  0.2462, -0.6488],\n",
            "        [-1.2307,  1.7435, -0.7185],\n",
            "        [-1.5547,  0.3314,  1.0488],\n",
            "        [-1.6391,  0.0851,  1.0881],\n",
            "        [ 0.5907,  0.2001, -1.5641],\n",
            "        [-1.2549,  2.0748, -0.7728],\n",
            "        [-1.1399,  0.3910,  0.4040],\n",
            "        [-1.8637,  0.4306,  1.2083],\n",
            "        [-1.3443,  1.8161, -0.6816],\n",
            "        [ 0.4937,  0.0664, -1.4163],\n",
            "        [-1.4613,  0.3224,  1.1623],\n",
            "        [-1.3855,  0.2755,  1.0289],\n",
            "        [-1.2958,  1.9038, -0.6679],\n",
            "        [ 0.2600,  0.1553, -0.9980],\n",
            "        [ 0.5854,  0.1408, -1.2969],\n",
            "        [-1.6955,  0.5448,  1.1167]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.2119,  0.2462, -0.6488],\n",
            "        [-1.2307,  1.7435, -0.7185],\n",
            "        [-1.5547,  0.3314,  1.0488],\n",
            "        [-1.6391,  0.0851,  1.0881],\n",
            "        [ 0.5907,  0.2001, -1.5641],\n",
            "        [-1.2549,  2.0748, -0.7728],\n",
            "        [-1.1399,  0.3910,  0.4040],\n",
            "        [-1.8637,  0.4306,  1.2083],\n",
            "        [-1.3443,  1.8161, -0.6816],\n",
            "        [ 0.4937,  0.0664, -1.4163],\n",
            "        [-1.4613,  0.3224,  1.1623],\n",
            "        [-1.3855,  0.2755,  1.0289],\n",
            "        [-1.2958,  1.9038, -0.6679],\n",
            "        [ 0.2600,  0.1553, -0.9980],\n",
            "        [ 0.5854,  0.1408, -1.2969],\n",
            "        [-1.6955,  0.5448,  1.1167]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3755,  2.1426, -0.8591],\n",
            "        [-1.7024,  0.1977,  1.0209],\n",
            "        [-1.0998,  1.6850, -0.9508],\n",
            "        [-1.3143,  1.9514, -0.8515],\n",
            "        [-1.4665,  1.9895, -0.8096],\n",
            "        [-1.6457,  1.0588,  0.3451],\n",
            "        [-1.5638,  0.3388,  1.0461],\n",
            "        [-1.3785,  1.0428, -0.4493],\n",
            "        [ 0.6410,  0.0329, -1.2636],\n",
            "        [-1.4141,  1.3365, -0.0209],\n",
            "        [-1.4173,  2.0378, -0.8283],\n",
            "        [-1.4215,  1.7516, -0.7433],\n",
            "        [-1.8719,  0.3129,  1.1311],\n",
            "        [-1.3583,  1.7656, -0.9557],\n",
            "        [-1.5827,  0.4618,  1.0369],\n",
            "        [-1.5609,  1.9494, -0.8546]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3755,  2.1426, -0.8591],\n",
            "        [-1.7024,  0.1977,  1.0209],\n",
            "        [-1.0998,  1.6850, -0.9508],\n",
            "        [-1.3143,  1.9514, -0.8515],\n",
            "        [-1.4665,  1.9895, -0.8096],\n",
            "        [-1.6457,  1.0588,  0.3451],\n",
            "        [-1.5638,  0.3388,  1.0461],\n",
            "        [-1.3785,  1.0428, -0.4493],\n",
            "        [ 0.6410,  0.0329, -1.2636],\n",
            "        [-1.4141,  1.3365, -0.0209],\n",
            "        [-1.4173,  2.0378, -0.8283],\n",
            "        [-1.4215,  1.7516, -0.7433],\n",
            "        [-1.8719,  0.3129,  1.1311],\n",
            "        [-1.3583,  1.7656, -0.9557],\n",
            "        [-1.5827,  0.4618,  1.0369],\n",
            "        [-1.5609,  1.9494, -0.8546]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4001,  0.8245,  0.2342],\n",
            "        [-0.9884,  1.0375, -0.1934],\n",
            "        [-1.1506,  1.7707, -0.7433],\n",
            "        [ 0.6634,  0.0987, -1.3583],\n",
            "        [ 0.6583,  0.0432, -1.5128],\n",
            "        [-1.7133,  0.4065,  1.1457],\n",
            "        [-1.4811,  0.5848,  1.0255],\n",
            "        [-1.5753,  0.4754,  0.9027],\n",
            "        [-1.5132,  0.4566,  1.1696],\n",
            "        [-1.5420,  1.5131, -0.0022],\n",
            "        [-1.7295,  0.6379,  0.8780],\n",
            "        [-1.7792,  1.8856, -0.3966],\n",
            "        [-1.4436,  2.0058, -0.8524],\n",
            "        [-1.3278,  1.8070, -0.9900],\n",
            "        [-1.5218,  1.8683, -0.6019],\n",
            "        [-1.6504,  0.1922,  1.0569]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4001,  0.8245,  0.2342],\n",
            "        [-0.9884,  1.0375, -0.1934],\n",
            "        [-1.1506,  1.7707, -0.7433],\n",
            "        [ 0.6634,  0.0987, -1.3583],\n",
            "        [ 0.6583,  0.0432, -1.5128],\n",
            "        [-1.7133,  0.4065,  1.1457],\n",
            "        [-1.4811,  0.5848,  1.0255],\n",
            "        [-1.5753,  0.4754,  0.9027],\n",
            "        [-1.5132,  0.4566,  1.1696],\n",
            "        [-1.5420,  1.5131, -0.0022],\n",
            "        [-1.7295,  0.6379,  0.8780],\n",
            "        [-1.7792,  1.8856, -0.3966],\n",
            "        [-1.4436,  2.0058, -0.8524],\n",
            "        [-1.3278,  1.8070, -0.9900],\n",
            "        [-1.5218,  1.8683, -0.6019],\n",
            "        [-1.6504,  0.1922,  1.0569]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2175,  1.9715, -0.7071],\n",
            "        [-1.2603,  1.9252, -0.7456],\n",
            "        [-1.6415,  1.7806, -0.4952],\n",
            "        [-1.3130,  1.9710, -0.8723],\n",
            "        [-0.8563,  1.1243, -0.5339],\n",
            "        [-1.4529,  1.7975, -0.7454],\n",
            "        [-1.3170,  0.4612,  0.7882],\n",
            "        [-1.4900,  2.1368, -0.7378],\n",
            "        [-1.3558,  2.2388, -0.7799],\n",
            "        [-1.2037,  0.3688,  0.6879],\n",
            "        [-1.2010,  1.9861, -0.7545],\n",
            "        [ 0.5371,  0.2026, -1.4832],\n",
            "        [-1.3543,  2.0418, -0.7401],\n",
            "        [-1.3245,  0.9768, -0.1486],\n",
            "        [-1.1121,  1.9512, -0.9604],\n",
            "        [-1.3170,  1.6960, -0.8716]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2175,  1.9715, -0.7071],\n",
            "        [-1.2603,  1.9252, -0.7456],\n",
            "        [-1.6415,  1.7806, -0.4952],\n",
            "        [-1.3130,  1.9710, -0.8723],\n",
            "        [-0.8563,  1.1243, -0.5339],\n",
            "        [-1.4529,  1.7975, -0.7454],\n",
            "        [-1.3170,  0.4612,  0.7882],\n",
            "        [-1.4900,  2.1368, -0.7378],\n",
            "        [-1.3558,  2.2388, -0.7799],\n",
            "        [-1.2037,  0.3688,  0.6879],\n",
            "        [-1.2010,  1.9861, -0.7545],\n",
            "        [ 0.5371,  0.2026, -1.4832],\n",
            "        [-1.3543,  2.0418, -0.7401],\n",
            "        [-1.3245,  0.9768, -0.1486],\n",
            "        [-1.1121,  1.9512, -0.9604],\n",
            "        [-1.3170,  1.6960, -0.8716]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4029,  2.0622, -0.7082],\n",
            "        [-1.4638,  1.8643, -0.6801],\n",
            "        [ 0.4506,  0.2929, -1.3440],\n",
            "        [-1.5895,  2.0558, -0.8189],\n",
            "        [-1.4097,  1.9663, -0.8746],\n",
            "        [-1.7344,  0.3991,  1.2450],\n",
            "        [-0.9928,  1.4634, -0.9376],\n",
            "        [-1.3864,  1.7020, -0.8766],\n",
            "        [-1.4991,  1.7649, -0.7658],\n",
            "        [-1.4777,  2.0567, -0.7492],\n",
            "        [-1.5208,  0.4017,  0.9290],\n",
            "        [ 0.6013,  0.1306, -1.4710],\n",
            "        [-1.5833,  0.9449,  0.2840],\n",
            "        [ 0.7714,  0.2124, -1.2911],\n",
            "        [-1.0549,  1.5221, -0.8980],\n",
            "        [ 0.4637,  0.2415, -1.4090]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4029,  2.0622, -0.7082],\n",
            "        [-1.4638,  1.8643, -0.6801],\n",
            "        [ 0.4506,  0.2929, -1.3440],\n",
            "        [-1.5895,  2.0558, -0.8189],\n",
            "        [-1.4097,  1.9663, -0.8746],\n",
            "        [-1.7344,  0.3991,  1.2450],\n",
            "        [-0.9928,  1.4634, -0.9376],\n",
            "        [-1.3864,  1.7020, -0.8766],\n",
            "        [-1.4991,  1.7649, -0.7658],\n",
            "        [-1.4777,  2.0567, -0.7492],\n",
            "        [-1.5208,  0.4017,  0.9290],\n",
            "        [ 0.6013,  0.1306, -1.4710],\n",
            "        [-1.5833,  0.9449,  0.2840],\n",
            "        [ 0.7714,  0.2124, -1.2911],\n",
            "        [-1.0549,  1.5221, -0.8980],\n",
            "        [ 0.4637,  0.2415, -1.4090]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7139,  0.5166,  1.0853],\n",
            "        [-1.2861,  1.9427, -0.6889],\n",
            "        [ 0.5856,  0.4499, -1.3838],\n",
            "        [-1.3056,  1.7392, -0.8025],\n",
            "        [-1.6417,  0.4594,  1.1702],\n",
            "        [-1.0730,  0.9632, -0.4872],\n",
            "        [-1.2339,  1.6243, -0.6305],\n",
            "        [-1.3659,  0.2778,  0.7450],\n",
            "        [ 0.7571,  0.0525, -1.2198],\n",
            "        [ 0.5672,  0.0484, -1.1781],\n",
            "        [-1.3518,  2.0425, -0.7243],\n",
            "        [-1.0750,  1.5528, -0.8247],\n",
            "        [-1.7656,  0.5283,  0.9852],\n",
            "        [-1.2574,  1.7568, -0.9513],\n",
            "        [-1.1523,  1.9111, -0.7708],\n",
            "        [-1.4027,  1.9454, -0.5638]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7139,  0.5166,  1.0853],\n",
            "        [-1.2861,  1.9427, -0.6889],\n",
            "        [ 0.5856,  0.4499, -1.3838],\n",
            "        [-1.3056,  1.7392, -0.8025],\n",
            "        [-1.6417,  0.4594,  1.1702],\n",
            "        [-1.0730,  0.9632, -0.4872],\n",
            "        [-1.2339,  1.6243, -0.6305],\n",
            "        [-1.3659,  0.2778,  0.7450],\n",
            "        [ 0.7571,  0.0525, -1.2198],\n",
            "        [ 0.5672,  0.0484, -1.1781],\n",
            "        [-1.3518,  2.0425, -0.7243],\n",
            "        [-1.0750,  1.5528, -0.8247],\n",
            "        [-1.7656,  0.5283,  0.9852],\n",
            "        [-1.2574,  1.7568, -0.9513],\n",
            "        [-1.1523,  1.9111, -0.7708],\n",
            "        [-1.4027,  1.9454, -0.5638]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.8244, -0.0040, -1.3400],\n",
            "        [-1.2400,  1.5875, -0.7870],\n",
            "        [ 0.8260,  0.1809, -1.4925],\n",
            "        [-1.7588,  1.8035, -0.4421],\n",
            "        [-1.3788,  1.6144, -0.4999],\n",
            "        [-1.4165,  1.7036, -0.1525],\n",
            "        [ 0.4129,  0.4180, -1.4293],\n",
            "        [-0.9009,  1.1251, -0.8897],\n",
            "        [-1.8918,  0.5480,  1.0961],\n",
            "        [-1.3496,  1.8576, -0.3212],\n",
            "        [-1.0245,  1.3502, -0.8247],\n",
            "        [ 0.5883,  0.1295, -1.3056],\n",
            "        [-1.1755,  1.4173, -0.7386],\n",
            "        [-1.8115,  2.1519, -0.4278],\n",
            "        [-1.6237,  0.8524,  0.6325],\n",
            "        [-1.3300,  1.8894, -0.7827]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.8244, -0.0040, -1.3400],\n",
            "        [-1.2400,  1.5875, -0.7870],\n",
            "        [ 0.8260,  0.1809, -1.4925],\n",
            "        [-1.7588,  1.8035, -0.4421],\n",
            "        [-1.3788,  1.6144, -0.4999],\n",
            "        [-1.4165,  1.7036, -0.1525],\n",
            "        [ 0.4129,  0.4180, -1.4293],\n",
            "        [-0.9009,  1.1251, -0.8897],\n",
            "        [-1.8918,  0.5480,  1.0961],\n",
            "        [-1.3496,  1.8576, -0.3212],\n",
            "        [-1.0245,  1.3502, -0.8247],\n",
            "        [ 0.5883,  0.1295, -1.3056],\n",
            "        [-1.1755,  1.4173, -0.7386],\n",
            "        [-1.8115,  2.1519, -0.4278],\n",
            "        [-1.6237,  0.8524,  0.6325],\n",
            "        [-1.3300,  1.8894, -0.7827]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2891,  1.6215, -0.6026],\n",
            "        [-1.4693,  1.8870, -0.7311],\n",
            "        [-1.4997,  1.9819, -0.7713],\n",
            "        [-1.3635,  1.7370, -0.8080],\n",
            "        [-1.5954,  0.4717,  1.0776],\n",
            "        [ 0.7926,  0.0195, -1.2602],\n",
            "        [-1.7552,  1.4484, -0.0934],\n",
            "        [-1.6099,  2.1477, -0.6080],\n",
            "        [-1.6572,  0.4813,  1.0995],\n",
            "        [-1.3083,  1.7832, -0.7599],\n",
            "        [-1.2363,  0.6589,  0.6643],\n",
            "        [-1.5687,  2.1094, -0.5933],\n",
            "        [-1.6854,  1.9311, -0.6741],\n",
            "        [-1.5044,  0.9432,  0.5045],\n",
            "        [-1.4201,  1.4569, -0.4298],\n",
            "        [-1.3526,  1.9568, -0.6230]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2891,  1.6215, -0.6026],\n",
            "        [-1.4693,  1.8870, -0.7311],\n",
            "        [-1.4997,  1.9819, -0.7713],\n",
            "        [-1.3635,  1.7370, -0.8080],\n",
            "        [-1.5954,  0.4717,  1.0776],\n",
            "        [ 0.7926,  0.0195, -1.2602],\n",
            "        [-1.7552,  1.4484, -0.0934],\n",
            "        [-1.6099,  2.1477, -0.6080],\n",
            "        [-1.6572,  0.4813,  1.0995],\n",
            "        [-1.3083,  1.7832, -0.7599],\n",
            "        [-1.2363,  0.6589,  0.6643],\n",
            "        [-1.5687,  2.1094, -0.5933],\n",
            "        [-1.6854,  1.9311, -0.6741],\n",
            "        [-1.5044,  0.9432,  0.5045],\n",
            "        [-1.4201,  1.4569, -0.4298],\n",
            "        [-1.3526,  1.9568, -0.6230]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7095,  0.4334,  0.9249],\n",
            "        [ 0.6885,  0.2463, -1.5198],\n",
            "        [-1.6300,  2.0085, -0.7299],\n",
            "        [-1.5544,  1.9036, -0.6925],\n",
            "        [-1.5291,  1.9167, -0.6296],\n",
            "        [-1.9399,  0.3681,  1.0831],\n",
            "        [-1.5308,  1.6939, -0.3995],\n",
            "        [-1.6676,  0.4751,  1.2548],\n",
            "        [-1.2068,  2.0238, -0.6176],\n",
            "        [-1.3593,  1.8026, -0.6377],\n",
            "        [-1.4652,  0.5336,  0.9022],\n",
            "        [-1.3420,  1.8630, -0.6212],\n",
            "        [-1.6077,  0.8356,  0.7451],\n",
            "        [-1.1318,  1.5482, -0.7127],\n",
            "        [-1.5538,  1.9178, -0.3412],\n",
            "        [-1.6497,  0.4507,  1.1263]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7095,  0.4334,  0.9249],\n",
            "        [ 0.6885,  0.2463, -1.5198],\n",
            "        [-1.6300,  2.0085, -0.7299],\n",
            "        [-1.5544,  1.9036, -0.6925],\n",
            "        [-1.5291,  1.9167, -0.6296],\n",
            "        [-1.9399,  0.3681,  1.0831],\n",
            "        [-1.5308,  1.6939, -0.3995],\n",
            "        [-1.6676,  0.4751,  1.2548],\n",
            "        [-1.2068,  2.0238, -0.6176],\n",
            "        [-1.3593,  1.8026, -0.6377],\n",
            "        [-1.4652,  0.5336,  0.9022],\n",
            "        [-1.3420,  1.8630, -0.6212],\n",
            "        [-1.6077,  0.8356,  0.7451],\n",
            "        [-1.1318,  1.5482, -0.7127],\n",
            "        [-1.5538,  1.9178, -0.3412],\n",
            "        [-1.6497,  0.4507,  1.1263]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6473,  0.4620,  1.2686],\n",
            "        [ 0.8450,  0.0983, -1.3506],\n",
            "        [-1.6728,  0.1528,  1.2231],\n",
            "        [-1.4401,  1.9492, -0.5027],\n",
            "        [-1.5525,  1.7651, -0.5591],\n",
            "        [-1.8010,  0.4792,  1.0024],\n",
            "        [-1.3711,  2.1025, -0.7178],\n",
            "        [ 0.7350,  0.1988, -1.6062],\n",
            "        [-1.2576,  1.9212, -0.6321],\n",
            "        [-1.4171,  1.4696, -0.2655],\n",
            "        [-1.1438,  1.7686, -0.6901],\n",
            "        [-1.4972,  1.8886, -0.5000],\n",
            "        [-1.5629,  1.5219, -0.4871],\n",
            "        [-1.4608,  1.6461, -0.4372],\n",
            "        [-2.0143,  0.7163,  0.9413],\n",
            "        [-1.4001,  1.9290, -0.6062]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6473,  0.4620,  1.2686],\n",
            "        [ 0.8450,  0.0983, -1.3506],\n",
            "        [-1.6728,  0.1528,  1.2231],\n",
            "        [-1.4401,  1.9492, -0.5027],\n",
            "        [-1.5525,  1.7651, -0.5591],\n",
            "        [-1.8010,  0.4792,  1.0024],\n",
            "        [-1.3711,  2.1025, -0.7178],\n",
            "        [ 0.7350,  0.1988, -1.6062],\n",
            "        [-1.2576,  1.9212, -0.6321],\n",
            "        [-1.4171,  1.4696, -0.2655],\n",
            "        [-1.1438,  1.7686, -0.6901],\n",
            "        [-1.4972,  1.8886, -0.5000],\n",
            "        [-1.5629,  1.5219, -0.4871],\n",
            "        [-1.4608,  1.6461, -0.4372],\n",
            "        [-2.0143,  0.7163,  0.9413],\n",
            "        [-1.4001,  1.9290, -0.6062]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.7027,  0.1738, -1.2151],\n",
            "        [-1.3655,  1.7956, -0.4924],\n",
            "        [-1.5089,  1.1715,  0.2042],\n",
            "        [-1.6320,  0.4241,  1.0641],\n",
            "        [-1.5793,  1.7394, -0.6562],\n",
            "        [-1.8198,  1.1233,  0.1745],\n",
            "        [-0.8322,  1.3384, -0.9552],\n",
            "        [-1.3792,  1.9466, -0.6534],\n",
            "        [-1.9490,  0.4166,  1.2242],\n",
            "        [ 0.9888,  0.1125, -1.3806],\n",
            "        [-1.7393,  0.2552,  1.0706],\n",
            "        [-1.6364,  0.3616,  1.2527],\n",
            "        [-1.5195,  1.7084, -0.7047],\n",
            "        [-1.7800,  0.3774,  1.1994],\n",
            "        [ 0.2113,  0.0318, -0.5539],\n",
            "        [-1.4287,  1.7224, -0.6043]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.7027,  0.1738, -1.2151],\n",
            "        [-1.3655,  1.7956, -0.4924],\n",
            "        [-1.5089,  1.1715,  0.2042],\n",
            "        [-1.6320,  0.4241,  1.0641],\n",
            "        [-1.5793,  1.7394, -0.6562],\n",
            "        [-1.8198,  1.1233,  0.1745],\n",
            "        [-0.8322,  1.3384, -0.9552],\n",
            "        [-1.3792,  1.9466, -0.6534],\n",
            "        [-1.9490,  0.4166,  1.2242],\n",
            "        [ 0.9888,  0.1125, -1.3806],\n",
            "        [-1.7393,  0.2552,  1.0706],\n",
            "        [-1.6364,  0.3616,  1.2527],\n",
            "        [-1.5195,  1.7084, -0.7047],\n",
            "        [-1.7800,  0.3774,  1.1994],\n",
            "        [ 0.2113,  0.0318, -0.5539],\n",
            "        [-1.4287,  1.7224, -0.6043]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5459,  1.6650, -0.4934],\n",
            "        [-1.7187,  0.1758,  1.1843],\n",
            "        [-1.4875,  1.8605, -0.5925],\n",
            "        [-1.5949,  1.7183, -0.3055],\n",
            "        [ 0.6792,  0.1213, -1.3478],\n",
            "        [-1.8636,  0.3727,  1.1609],\n",
            "        [-1.6305,  1.7894, -0.4831],\n",
            "        [-1.7897,  0.4873,  1.1632],\n",
            "        [-1.5504,  1.8542, -0.5438],\n",
            "        [-1.7510,  0.4013,  1.3636],\n",
            "        [-1.4110,  0.9130,  0.5523],\n",
            "        [-1.3371,  1.5955, -0.5680],\n",
            "        [-1.4083,  0.5924,  0.8303],\n",
            "        [-1.7175,  0.5844,  0.9764],\n",
            "        [-1.5571,  0.5173,  1.1168],\n",
            "        [-1.4275,  1.7007, -0.6844]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5459,  1.6650, -0.4934],\n",
            "        [-1.7187,  0.1758,  1.1843],\n",
            "        [-1.4875,  1.8605, -0.5925],\n",
            "        [-1.5949,  1.7183, -0.3055],\n",
            "        [ 0.6792,  0.1213, -1.3478],\n",
            "        [-1.8636,  0.3727,  1.1609],\n",
            "        [-1.6305,  1.7894, -0.4831],\n",
            "        [-1.7897,  0.4873,  1.1632],\n",
            "        [-1.5504,  1.8542, -0.5438],\n",
            "        [-1.7510,  0.4013,  1.3636],\n",
            "        [-1.4110,  0.9130,  0.5523],\n",
            "        [-1.3371,  1.5955, -0.5680],\n",
            "        [-1.4083,  0.5924,  0.8303],\n",
            "        [-1.7175,  0.5844,  0.9764],\n",
            "        [-1.5571,  0.5173,  1.1168],\n",
            "        [-1.4275,  1.7007, -0.6844]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8034,  0.2395,  1.3275],\n",
            "        [-1.8079,  1.5940,  0.0484],\n",
            "        [-1.5396,  1.3538, -0.1632],\n",
            "        [ 0.7580, -0.0599, -1.5609],\n",
            "        [-1.4607,  1.6629, -0.4104],\n",
            "        [-1.5727,  1.6355, -0.0752],\n",
            "        [ 0.5808, -0.0698, -1.2758],\n",
            "        [-1.8240,  1.6864, -0.2755],\n",
            "        [-0.9199,  0.0909,  0.5461],\n",
            "        [ 0.7999, -0.0422, -1.3758],\n",
            "        [ 0.7026,  0.2487, -1.3761],\n",
            "        [-1.4016,  1.9427, -0.6782],\n",
            "        [-1.0001,  1.2283, -0.6679],\n",
            "        [ 0.6146, -0.0242, -1.2572],\n",
            "        [-1.7645,  0.4519,  1.2560],\n",
            "        [-1.7405,  0.1380,  1.2996]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8034,  0.2395,  1.3275],\n",
            "        [-1.8079,  1.5940,  0.0484],\n",
            "        [-1.5396,  1.3538, -0.1632],\n",
            "        [ 0.7580, -0.0599, -1.5609],\n",
            "        [-1.4607,  1.6629, -0.4104],\n",
            "        [-1.5727,  1.6355, -0.0752],\n",
            "        [ 0.5808, -0.0698, -1.2758],\n",
            "        [-1.8240,  1.6864, -0.2755],\n",
            "        [-0.9199,  0.0909,  0.5461],\n",
            "        [ 0.7999, -0.0422, -1.3758],\n",
            "        [ 0.7026,  0.2487, -1.3761],\n",
            "        [-1.4016,  1.9427, -0.6782],\n",
            "        [-1.0001,  1.2283, -0.6679],\n",
            "        [ 0.6146, -0.0242, -1.2572],\n",
            "        [-1.7645,  0.4519,  1.2560],\n",
            "        [-1.7405,  0.1380,  1.2996]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6455,  0.1886,  1.0640],\n",
            "        [-1.5458,  1.8045, -0.2615],\n",
            "        [-1.6532,  0.2434,  1.3217],\n",
            "        [-1.6186,  1.9501, -0.4406],\n",
            "        [-1.6399,  0.4392,  1.1024],\n",
            "        [-1.4930,  1.9789, -0.6577],\n",
            "        [-1.6473,  1.5422, -0.2624],\n",
            "        [-1.8298,  0.2291,  1.2849],\n",
            "        [-1.9871,  0.3537,  1.5067],\n",
            "        [ 0.9793,  0.0645, -1.4696],\n",
            "        [-1.4897,  1.7856, -0.5882],\n",
            "        [-1.6052,  1.8514, -0.2483],\n",
            "        [-1.7691,  0.4550,  1.2486],\n",
            "        [-1.7933,  0.2627,  1.4026],\n",
            "        [-2.0153,  1.0213,  0.4209],\n",
            "        [-1.8164,  0.4155,  1.2177]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6455,  0.1886,  1.0640],\n",
            "        [-1.5458,  1.8045, -0.2615],\n",
            "        [-1.6532,  0.2434,  1.3217],\n",
            "        [-1.6186,  1.9501, -0.4406],\n",
            "        [-1.6399,  0.4392,  1.1024],\n",
            "        [-1.4930,  1.9789, -0.6577],\n",
            "        [-1.6473,  1.5422, -0.2624],\n",
            "        [-1.8298,  0.2291,  1.2849],\n",
            "        [-1.9871,  0.3537,  1.5067],\n",
            "        [ 0.9793,  0.0645, -1.4696],\n",
            "        [-1.4897,  1.7856, -0.5882],\n",
            "        [-1.6052,  1.8514, -0.2483],\n",
            "        [-1.7691,  0.4550,  1.2486],\n",
            "        [-1.7933,  0.2627,  1.4026],\n",
            "        [-2.0153,  1.0213,  0.4209],\n",
            "        [-1.8164,  0.4155,  1.2177]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.0919,  1.7538, -0.5675],\n",
            "        [-1.6216,  2.1356, -0.4738],\n",
            "        [-1.5571,  1.7949, -0.4672],\n",
            "        [-1.5770,  1.8049, -0.5080],\n",
            "        [ 0.6216, -0.0470, -1.2080],\n",
            "        [-1.3837,  1.6800, -0.5847],\n",
            "        [-1.7398,  0.4802,  1.0378],\n",
            "        [-1.6354,  1.3868,  0.0348],\n",
            "        [-1.7141,  1.9724, -0.4538],\n",
            "        [-1.6105,  1.8272, -0.4978],\n",
            "        [-1.6669,  0.1009,  1.3233],\n",
            "        [-1.7573,  0.2784,  1.2434],\n",
            "        [-1.5972,  1.9443, -0.5767],\n",
            "        [-1.6015,  1.7146, -0.4049],\n",
            "        [-1.6266,  0.5770,  1.0599],\n",
            "        [-2.0660,  0.5507,  1.1572]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.0919,  1.7538, -0.5675],\n",
            "        [-1.6216,  2.1356, -0.4738],\n",
            "        [-1.5571,  1.7949, -0.4672],\n",
            "        [-1.5770,  1.8049, -0.5080],\n",
            "        [ 0.6216, -0.0470, -1.2080],\n",
            "        [-1.3837,  1.6800, -0.5847],\n",
            "        [-1.7398,  0.4802,  1.0378],\n",
            "        [-1.6354,  1.3868,  0.0348],\n",
            "        [-1.7141,  1.9724, -0.4538],\n",
            "        [-1.6105,  1.8272, -0.4978],\n",
            "        [-1.6669,  0.1009,  1.3233],\n",
            "        [-1.7573,  0.2784,  1.2434],\n",
            "        [-1.5972,  1.9443, -0.5767],\n",
            "        [-1.6015,  1.7146, -0.4049],\n",
            "        [-1.6266,  0.5770,  1.0599],\n",
            "        [-2.0660,  0.5507,  1.1572]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5464,  1.8385, -0.4594],\n",
            "        [-1.3501,  1.5491, -0.5732],\n",
            "        [-1.3490,  1.7204, -0.7160],\n",
            "        [ 0.6794,  0.0073, -1.1780],\n",
            "        [-1.8336,  0.2308,  1.3461],\n",
            "        [-1.5248,  0.3249,  1.0236],\n",
            "        [-1.6908,  0.2290,  1.1632],\n",
            "        [-1.5703,  2.0337, -0.2422],\n",
            "        [-0.8586,  1.0797, -0.6997],\n",
            "        [ 0.6112, -0.0258, -1.4130],\n",
            "        [ 0.8219,  0.0567, -1.3081],\n",
            "        [-1.6577,  1.9785, -0.3628],\n",
            "        [-1.6415,  1.5055, -0.3960],\n",
            "        [-1.7240,  1.8019, -0.3301],\n",
            "        [-1.0213,  1.5120, -0.7697],\n",
            "        [-1.6562,  0.3776,  1.3218]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5464,  1.8385, -0.4594],\n",
            "        [-1.3501,  1.5491, -0.5732],\n",
            "        [-1.3490,  1.7204, -0.7160],\n",
            "        [ 0.6794,  0.0073, -1.1780],\n",
            "        [-1.8336,  0.2308,  1.3461],\n",
            "        [-1.5248,  0.3249,  1.0236],\n",
            "        [-1.6908,  0.2290,  1.1632],\n",
            "        [-1.5703,  2.0337, -0.2422],\n",
            "        [-0.8586,  1.0797, -0.6997],\n",
            "        [ 0.6112, -0.0258, -1.4130],\n",
            "        [ 0.8219,  0.0567, -1.3081],\n",
            "        [-1.6577,  1.9785, -0.3628],\n",
            "        [-1.6415,  1.5055, -0.3960],\n",
            "        [-1.7240,  1.8019, -0.3301],\n",
            "        [-1.0213,  1.5120, -0.7697],\n",
            "        [-1.6562,  0.3776,  1.3218]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7522,  0.4658,  1.2039],\n",
            "        [-1.5282,  1.8810, -0.4734],\n",
            "        [-1.6637,  0.3564,  1.1880],\n",
            "        [ 0.7965, -0.0178, -1.4016],\n",
            "        [-1.5581,  1.5529, -0.3182],\n",
            "        [ 0.2480,  0.5331, -1.2701],\n",
            "        [-1.4973,  1.7949, -0.4478],\n",
            "        [ 0.6830,  0.0677, -1.2549],\n",
            "        [-1.6149,  1.7741, -0.5555],\n",
            "        [-1.7031,  1.8922, -0.2977],\n",
            "        [-2.0023,  0.5494,  1.2646],\n",
            "        [-1.4397,  1.6573, -0.4108],\n",
            "        [-1.8357,  0.2906,  1.3492],\n",
            "        [-1.5441,  1.8804, -0.4184],\n",
            "        [ 0.6796,  0.0694, -1.4098],\n",
            "        [ 0.7784, -0.1055, -1.2022]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7522,  0.4658,  1.2039],\n",
            "        [-1.5282,  1.8810, -0.4734],\n",
            "        [-1.6637,  0.3564,  1.1880],\n",
            "        [ 0.7965, -0.0178, -1.4016],\n",
            "        [-1.5581,  1.5529, -0.3182],\n",
            "        [ 0.2480,  0.5331, -1.2701],\n",
            "        [-1.4973,  1.7949, -0.4478],\n",
            "        [ 0.6830,  0.0677, -1.2549],\n",
            "        [-1.6149,  1.7741, -0.5555],\n",
            "        [-1.7031,  1.8922, -0.2977],\n",
            "        [-2.0023,  0.5494,  1.2646],\n",
            "        [-1.4397,  1.6573, -0.4108],\n",
            "        [-1.8357,  0.2906,  1.3492],\n",
            "        [-1.5441,  1.8804, -0.4184],\n",
            "        [ 0.6796,  0.0694, -1.4098],\n",
            "        [ 0.7784, -0.1055, -1.2022]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7507,  1.6571,  0.0291],\n",
            "        [-2.0733,  0.1586,  1.3278],\n",
            "        [-1.8330,  0.7909,  0.8154],\n",
            "        [ 0.3982, -0.0283, -0.9428],\n",
            "        [-1.8733,  0.3891,  1.4908],\n",
            "        [-2.0145,  0.6037,  1.0451],\n",
            "        [-0.7829,  0.9784, -0.5348],\n",
            "        [-1.6619,  1.5335, -0.0339],\n",
            "        [ 0.6157,  0.0469, -1.4175],\n",
            "        [-1.6580,  1.8454, -0.2901],\n",
            "        [-1.5629,  1.6685, -0.6073],\n",
            "        [-1.6383,  1.7234, -0.4243],\n",
            "        [-2.0269,  0.2572,  1.1546],\n",
            "        [-1.5930,  1.5307, -0.0770],\n",
            "        [ 0.5570, -0.0698, -1.2617],\n",
            "        [ 0.8234,  0.0134, -1.3035]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7507,  1.6571,  0.0291],\n",
            "        [-2.0733,  0.1586,  1.3278],\n",
            "        [-1.8330,  0.7909,  0.8154],\n",
            "        [ 0.3982, -0.0283, -0.9428],\n",
            "        [-1.8733,  0.3891,  1.4908],\n",
            "        [-2.0145,  0.6037,  1.0451],\n",
            "        [-0.7829,  0.9784, -0.5348],\n",
            "        [-1.6619,  1.5335, -0.0339],\n",
            "        [ 0.6157,  0.0469, -1.4175],\n",
            "        [-1.6580,  1.8454, -0.2901],\n",
            "        [-1.5629,  1.6685, -0.6073],\n",
            "        [-1.6383,  1.7234, -0.4243],\n",
            "        [-2.0269,  0.2572,  1.1546],\n",
            "        [-1.5930,  1.5307, -0.0770],\n",
            "        [ 0.5570, -0.0698, -1.2617],\n",
            "        [ 0.8234,  0.0134, -1.3035]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7023,  1.8762, -0.4178],\n",
            "        [-1.8262,  0.4883,  1.1933],\n",
            "        [-1.6854,  0.9269,  0.5817],\n",
            "        [-1.3397,  0.1501,  1.1276],\n",
            "        [-1.4580,  1.6436, -0.3854],\n",
            "        [-1.4078,  1.6742, -0.4490],\n",
            "        [-1.7656,  0.5061,  1.1941],\n",
            "        [-1.8636,  0.4131,  1.4813],\n",
            "        [-1.6787,  1.5211, -0.5560],\n",
            "        [-1.9729,  0.3791,  1.3281],\n",
            "        [-1.4978,  1.6863, -0.3384],\n",
            "        [-1.6757,  1.8819, -0.3203],\n",
            "        [-1.5730,  1.7135, -0.3579],\n",
            "        [-1.5085,  1.9836, -0.5148],\n",
            "        [ 0.7745,  0.0888, -1.3172],\n",
            "        [-2.0499,  0.5274,  1.2990]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7023,  1.8762, -0.4178],\n",
            "        [-1.8262,  0.4883,  1.1933],\n",
            "        [-1.6854,  0.9269,  0.5817],\n",
            "        [-1.3397,  0.1501,  1.1276],\n",
            "        [-1.4580,  1.6436, -0.3854],\n",
            "        [-1.4078,  1.6742, -0.4490],\n",
            "        [-1.7656,  0.5061,  1.1941],\n",
            "        [-1.8636,  0.4131,  1.4813],\n",
            "        [-1.6787,  1.5211, -0.5560],\n",
            "        [-1.9729,  0.3791,  1.3281],\n",
            "        [-1.4978,  1.6863, -0.3384],\n",
            "        [-1.6757,  1.8819, -0.3203],\n",
            "        [-1.5730,  1.7135, -0.3579],\n",
            "        [-1.5085,  1.9836, -0.5148],\n",
            "        [ 0.7745,  0.0888, -1.3172],\n",
            "        [-2.0499,  0.5274,  1.2990]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4438,  1.5717, -0.2711],\n",
            "        [-1.6938,  1.7774, -0.8054],\n",
            "        [-1.6785,  1.6451, -0.3310],\n",
            "        [-1.9624,  0.4411,  1.3015],\n",
            "        [-1.4167,  1.6942, -0.7657],\n",
            "        [-0.3970,  0.5597, -0.4747],\n",
            "        [-1.9286,  0.5015,  1.0730],\n",
            "        [-1.4131,  1.6687, -0.3503],\n",
            "        [-1.9193,  0.4158,  1.4183],\n",
            "        [-1.6458,  1.9601, -0.6257],\n",
            "        [-1.5508,  2.0265, -0.4992],\n",
            "        [ 0.6662,  0.0779, -1.3082],\n",
            "        [-1.5208,  1.0605,  0.0285],\n",
            "        [-1.8825,  0.3795,  1.3196],\n",
            "        [-1.9240,  0.3686,  1.3401],\n",
            "        [-1.4243,  0.3740,  1.0102]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4438,  1.5717, -0.2711],\n",
            "        [-1.6938,  1.7774, -0.8054],\n",
            "        [-1.6785,  1.6451, -0.3310],\n",
            "        [-1.9624,  0.4411,  1.3015],\n",
            "        [-1.4167,  1.6942, -0.7657],\n",
            "        [-0.3970,  0.5597, -0.4747],\n",
            "        [-1.9286,  0.5015,  1.0730],\n",
            "        [-1.4131,  1.6687, -0.3503],\n",
            "        [-1.9193,  0.4158,  1.4183],\n",
            "        [-1.6458,  1.9601, -0.6257],\n",
            "        [-1.5508,  2.0265, -0.4992],\n",
            "        [ 0.6662,  0.0779, -1.3082],\n",
            "        [-1.5208,  1.0605,  0.0285],\n",
            "        [-1.8825,  0.3795,  1.3196],\n",
            "        [-1.9240,  0.3686,  1.3401],\n",
            "        [-1.4243,  0.3740,  1.0102]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6069,  0.3926,  1.0995],\n",
            "        [-1.4745,  1.7791, -0.3908],\n",
            "        [-1.3961,  1.9108, -0.3685],\n",
            "        [-1.9448,  0.5697,  0.7947],\n",
            "        [-1.6617,  1.8620, -0.4451],\n",
            "        [-1.9965,  0.3815,  1.3245],\n",
            "        [-1.7843,  1.7761, -0.4942],\n",
            "        [-1.7012,  1.8548, -0.2948],\n",
            "        [-1.6868,  1.8131, -0.4255],\n",
            "        [ 0.6640,  0.3154, -1.3067],\n",
            "        [-1.8786,  0.5361,  1.2429],\n",
            "        [ 0.8256,  0.1161, -1.1988],\n",
            "        [-1.9210,  0.2272,  1.2318],\n",
            "        [-1.6292,  0.4722,  1.0511],\n",
            "        [-1.6524,  1.7518, -0.5480],\n",
            "        [-1.9423,  0.2085,  1.0959]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6069,  0.3926,  1.0995],\n",
            "        [-1.4745,  1.7791, -0.3908],\n",
            "        [-1.3961,  1.9108, -0.3685],\n",
            "        [-1.9448,  0.5697,  0.7947],\n",
            "        [-1.6617,  1.8620, -0.4451],\n",
            "        [-1.9965,  0.3815,  1.3245],\n",
            "        [-1.7843,  1.7761, -0.4942],\n",
            "        [-1.7012,  1.8548, -0.2948],\n",
            "        [-1.6868,  1.8131, -0.4255],\n",
            "        [ 0.6640,  0.3154, -1.3067],\n",
            "        [-1.8786,  0.5361,  1.2429],\n",
            "        [ 0.8256,  0.1161, -1.1988],\n",
            "        [-1.9210,  0.2272,  1.2318],\n",
            "        [-1.6292,  0.4722,  1.0511],\n",
            "        [-1.6524,  1.7518, -0.5480],\n",
            "        [-1.9423,  0.2085,  1.0959]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5804,  1.7114, -0.5291],\n",
            "        [-1.7297,  0.4435,  1.2674],\n",
            "        [-1.7135,  1.8600, -0.2919],\n",
            "        [ 0.4671,  0.0904, -1.4157],\n",
            "        [-1.8131,  1.0950,  0.4617],\n",
            "        [-2.0207,  1.0031,  0.7179],\n",
            "        [-1.5826,  1.7008, -0.2709],\n",
            "        [-1.4558,  1.6556, -0.4091],\n",
            "        [-1.7128,  1.9352, -0.3810],\n",
            "        [-1.6940,  1.7948, -0.3865],\n",
            "        [-1.6078,  1.9552, -0.3185],\n",
            "        [-1.6114,  2.0067, -0.4547],\n",
            "        [-1.8916,  0.9744,  0.8120],\n",
            "        [-1.8574,  1.8731, -0.3732],\n",
            "        [-1.7258,  1.9779, -0.5259],\n",
            "        [-1.5270,  0.8065,  0.8539]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5804,  1.7114, -0.5291],\n",
            "        [-1.7297,  0.4435,  1.2674],\n",
            "        [-1.7135,  1.8600, -0.2919],\n",
            "        [ 0.4671,  0.0904, -1.4157],\n",
            "        [-1.8131,  1.0950,  0.4617],\n",
            "        [-2.0207,  1.0031,  0.7179],\n",
            "        [-1.5826,  1.7008, -0.2709],\n",
            "        [-1.4558,  1.6556, -0.4091],\n",
            "        [-1.7128,  1.9352, -0.3810],\n",
            "        [-1.6940,  1.7948, -0.3865],\n",
            "        [-1.6078,  1.9552, -0.3185],\n",
            "        [-1.6114,  2.0067, -0.4547],\n",
            "        [-1.8916,  0.9744,  0.8120],\n",
            "        [-1.8574,  1.8731, -0.3732],\n",
            "        [-1.7258,  1.9779, -0.5259],\n",
            "        [-1.5270,  0.8065,  0.8539]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3651,  1.5789, -0.4686],\n",
            "        [-1.7383,  1.9857, -0.6613],\n",
            "        [-1.7893,  0.5931,  1.2151],\n",
            "        [-1.6928,  0.5006,  1.2444],\n",
            "        [-1.9247,  1.4394, -0.2714],\n",
            "        [-1.5583,  1.8207, -0.5392],\n",
            "        [-1.7623,  1.7856, -0.5026],\n",
            "        [ 0.6991,  0.0085, -1.2759],\n",
            "        [-1.5495,  1.8663, -0.2933],\n",
            "        [-1.4705,  1.9420, -0.5475],\n",
            "        [ 0.6400,  0.2305, -1.2052],\n",
            "        [-1.9635,  0.5341,  1.2138],\n",
            "        [-1.7048,  0.5269,  1.2421],\n",
            "        [-1.5069,  1.5568, -0.4731],\n",
            "        [-1.6557,  1.5548, -0.3116],\n",
            "        [-1.7164,  0.2932,  1.1277]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3651,  1.5789, -0.4686],\n",
            "        [-1.7383,  1.9857, -0.6613],\n",
            "        [-1.7893,  0.5931,  1.2151],\n",
            "        [-1.6928,  0.5006,  1.2444],\n",
            "        [-1.9247,  1.4394, -0.2714],\n",
            "        [-1.5583,  1.8207, -0.5392],\n",
            "        [-1.7623,  1.7856, -0.5026],\n",
            "        [ 0.6991,  0.0085, -1.2759],\n",
            "        [-1.5495,  1.8663, -0.2933],\n",
            "        [-1.4705,  1.9420, -0.5475],\n",
            "        [ 0.6400,  0.2305, -1.2052],\n",
            "        [-1.9635,  0.5341,  1.2138],\n",
            "        [-1.7048,  0.5269,  1.2421],\n",
            "        [-1.5069,  1.5568, -0.4731],\n",
            "        [-1.6557,  1.5548, -0.3116],\n",
            "        [-1.7164,  0.2932,  1.1277]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5308,  1.7191, -0.4926],\n",
            "        [-1.7843,  0.4914,  1.2383],\n",
            "        [-1.5476,  1.8071, -0.5675],\n",
            "        [-1.6987,  1.8626, -0.1047],\n",
            "        [-1.7309,  1.5846, -0.0516],\n",
            "        [-1.7820,  0.4202,  1.2909],\n",
            "        [-1.6672,  1.5935, -0.3349],\n",
            "        [-1.7707,  1.7791, -0.2941],\n",
            "        [-1.6651,  0.6856,  0.9736],\n",
            "        [ 0.8488,  0.0603, -1.5295],\n",
            "        [-1.4901,  1.9290, -0.3152],\n",
            "        [-1.4345,  1.9456, -0.5165],\n",
            "        [-1.0372,  1.0187, -0.2431],\n",
            "        [-1.6460,  1.6608, -0.4080],\n",
            "        [-1.5725,  1.8314, -0.3613],\n",
            "        [-1.6476,  1.9416, -0.3492]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5308,  1.7191, -0.4926],\n",
            "        [-1.7843,  0.4914,  1.2383],\n",
            "        [-1.5476,  1.8071, -0.5675],\n",
            "        [-1.6987,  1.8626, -0.1047],\n",
            "        [-1.7309,  1.5846, -0.0516],\n",
            "        [-1.7820,  0.4202,  1.2909],\n",
            "        [-1.6672,  1.5935, -0.3349],\n",
            "        [-1.7707,  1.7791, -0.2941],\n",
            "        [-1.6651,  0.6856,  0.9736],\n",
            "        [ 0.8488,  0.0603, -1.5295],\n",
            "        [-1.4901,  1.9290, -0.3152],\n",
            "        [-1.4345,  1.9456, -0.5165],\n",
            "        [-1.0372,  1.0187, -0.2431],\n",
            "        [-1.6460,  1.6608, -0.4080],\n",
            "        [-1.5725,  1.8314, -0.3613],\n",
            "        [-1.6476,  1.9416, -0.3492]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5557,  1.8233, -0.5749],\n",
            "        [-1.7107,  0.5279,  1.1847],\n",
            "        [-1.7810,  1.6950, -0.3087],\n",
            "        [-1.8202,  2.0178, -0.4036],\n",
            "        [-1.6182,  1.6896, -0.4094],\n",
            "        [-1.1081,  0.6583,  0.2458],\n",
            "        [-1.7944,  2.0410, -0.5939],\n",
            "        [-1.6163,  1.6400, -0.6879],\n",
            "        [-1.6536,  0.2708,  1.1928],\n",
            "        [-1.7836,  0.7098,  1.1148],\n",
            "        [-1.6667,  2.1145, -0.5158],\n",
            "        [-1.8418,  1.9192, -0.2472],\n",
            "        [-1.4117,  1.3440, -0.6411],\n",
            "        [-1.8254,  0.4880,  1.1809],\n",
            "        [ 0.5255,  0.0505, -1.1031],\n",
            "        [ 0.8269,  0.1334, -1.2351]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5557,  1.8233, -0.5749],\n",
            "        [-1.7107,  0.5279,  1.1847],\n",
            "        [-1.7810,  1.6950, -0.3087],\n",
            "        [-1.8202,  2.0178, -0.4036],\n",
            "        [-1.6182,  1.6896, -0.4094],\n",
            "        [-1.1081,  0.6583,  0.2458],\n",
            "        [-1.7944,  2.0410, -0.5939],\n",
            "        [-1.6163,  1.6400, -0.6879],\n",
            "        [-1.6536,  0.2708,  1.1928],\n",
            "        [-1.7836,  0.7098,  1.1148],\n",
            "        [-1.6667,  2.1145, -0.5158],\n",
            "        [-1.8418,  1.9192, -0.2472],\n",
            "        [-1.4117,  1.3440, -0.6411],\n",
            "        [-1.8254,  0.4880,  1.1809],\n",
            "        [ 0.5255,  0.0505, -1.1031],\n",
            "        [ 0.8269,  0.1334, -1.2351]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0487,  0.9040,  0.8758],\n",
            "        [-1.3820,  1.8187, -0.6256],\n",
            "        [ 0.6354,  0.1135, -1.5327],\n",
            "        [-1.7750,  1.8456, -0.3785],\n",
            "        [-1.6498,  1.9944, -0.8008],\n",
            "        [-1.7756,  0.7491,  1.0773],\n",
            "        [-1.7728,  1.9088, -0.4357],\n",
            "        [ 0.7585,  0.0552, -1.1470],\n",
            "        [-1.5579,  1.9037, -0.3627],\n",
            "        [ 0.5625,  0.2470, -1.3716],\n",
            "        [-1.8735,  0.4256,  1.3263],\n",
            "        [-1.6555,  2.0711, -0.4466],\n",
            "        [-1.7173,  1.7544, -0.2349],\n",
            "        [-1.6711,  1.6774, -0.6403],\n",
            "        [-1.6809,  1.9038, -0.4187],\n",
            "        [-1.8792,  0.5876,  1.1580]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0487,  0.9040,  0.8758],\n",
            "        [-1.3820,  1.8187, -0.6256],\n",
            "        [ 0.6354,  0.1135, -1.5327],\n",
            "        [-1.7750,  1.8456, -0.3785],\n",
            "        [-1.6498,  1.9944, -0.8008],\n",
            "        [-1.7756,  0.7491,  1.0773],\n",
            "        [-1.7728,  1.9088, -0.4357],\n",
            "        [ 0.7585,  0.0552, -1.1470],\n",
            "        [-1.5579,  1.9037, -0.3627],\n",
            "        [ 0.5625,  0.2470, -1.3716],\n",
            "        [-1.8735,  0.4256,  1.3263],\n",
            "        [-1.6555,  2.0711, -0.4466],\n",
            "        [-1.7173,  1.7544, -0.2349],\n",
            "        [-1.6711,  1.6774, -0.6403],\n",
            "        [-1.6809,  1.9038, -0.4187],\n",
            "        [-1.8792,  0.5876,  1.1580]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.7255,  0.0351, -1.2764],\n",
            "        [-1.4233,  2.0236, -0.5373],\n",
            "        [-1.9027,  0.4506,  1.1572],\n",
            "        [-1.6005,  0.4272,  0.9914],\n",
            "        [-1.4734,  1.5211, -0.6165],\n",
            "        [-1.4728,  1.9523, -0.7107],\n",
            "        [-1.7896,  0.4629,  1.0447],\n",
            "        [ 0.2421,  0.6067, -1.4026],\n",
            "        [-1.9012,  0.5591,  1.1467],\n",
            "        [-1.7729,  1.8836, -0.2634],\n",
            "        [-1.6756,  1.7764, -0.7233],\n",
            "        [-1.7547,  0.6113,  1.3260],\n",
            "        [-1.7030,  1.2714,  0.1243],\n",
            "        [-1.5258,  2.1638, -0.5965],\n",
            "        [-1.9062,  0.9288,  1.1712],\n",
            "        [-2.0912,  0.4640,  1.2654]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.7255,  0.0351, -1.2764],\n",
            "        [-1.4233,  2.0236, -0.5373],\n",
            "        [-1.9027,  0.4506,  1.1572],\n",
            "        [-1.6005,  0.4272,  0.9914],\n",
            "        [-1.4734,  1.5211, -0.6165],\n",
            "        [-1.4728,  1.9523, -0.7107],\n",
            "        [-1.7896,  0.4629,  1.0447],\n",
            "        [ 0.2421,  0.6067, -1.4026],\n",
            "        [-1.9012,  0.5591,  1.1467],\n",
            "        [-1.7729,  1.8836, -0.2634],\n",
            "        [-1.6756,  1.7764, -0.7233],\n",
            "        [-1.7547,  0.6113,  1.3260],\n",
            "        [-1.7030,  1.2714,  0.1243],\n",
            "        [-1.5258,  2.1638, -0.5965],\n",
            "        [-1.9062,  0.9288,  1.1712],\n",
            "        [-2.0912,  0.4640,  1.2654]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7757,  0.4997,  1.1070],\n",
            "        [-1.6288,  2.1040, -0.5774],\n",
            "        [-1.6203,  1.7760, -0.6475],\n",
            "        [-1.3899,  1.7301, -0.5897],\n",
            "        [-1.5370,  1.9209, -0.4287],\n",
            "        [-1.5396,  2.0377, -0.4774],\n",
            "        [ 0.8348, -0.0071, -1.2058],\n",
            "        [ 0.7002,  0.0962, -1.2460],\n",
            "        [-1.8794,  0.9296,  0.8306],\n",
            "        [-1.9543,  0.6519,  0.8297],\n",
            "        [-1.8749,  0.8058,  0.9750],\n",
            "        [-1.8380,  0.5955,  0.9830],\n",
            "        [-1.8974,  0.5918,  1.0499],\n",
            "        [-1.6044,  1.8876, -0.7318],\n",
            "        [-1.7459,  2.1360, -0.3120],\n",
            "        [-1.9435,  0.4867,  1.0979]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7757,  0.4997,  1.1070],\n",
            "        [-1.6288,  2.1040, -0.5774],\n",
            "        [-1.6203,  1.7760, -0.6475],\n",
            "        [-1.3899,  1.7301, -0.5897],\n",
            "        [-1.5370,  1.9209, -0.4287],\n",
            "        [-1.5396,  2.0377, -0.4774],\n",
            "        [ 0.8348, -0.0071, -1.2058],\n",
            "        [ 0.7002,  0.0962, -1.2460],\n",
            "        [-1.8794,  0.9296,  0.8306],\n",
            "        [-1.9543,  0.6519,  0.8297],\n",
            "        [-1.8749,  0.8058,  0.9750],\n",
            "        [-1.8380,  0.5955,  0.9830],\n",
            "        [-1.8974,  0.5918,  1.0499],\n",
            "        [-1.6044,  1.8876, -0.7318],\n",
            "        [-1.7459,  2.1360, -0.3120],\n",
            "        [-1.9435,  0.4867,  1.0979]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8195,  0.6451,  1.2097],\n",
            "        [-1.7459,  2.0565, -0.3606],\n",
            "        [-1.5837,  1.8518, -0.4282],\n",
            "        [-1.8994,  2.1622, -0.3904],\n",
            "        [-1.7270,  2.0542, -0.4965],\n",
            "        [ 0.7423, -0.0185, -1.5195],\n",
            "        [-0.9011,  1.2041, -0.8398],\n",
            "        [-1.4977,  1.9091, -0.7911],\n",
            "        [-1.5794,  1.6663, -0.3449],\n",
            "        [-1.7349,  0.4339,  1.1143],\n",
            "        [-2.1054,  0.7233,  1.3639],\n",
            "        [-1.7421,  1.8770, -0.4021],\n",
            "        [-1.5239,  1.9101, -0.5482],\n",
            "        [-1.6650,  1.8157, -0.5112],\n",
            "        [-1.6452,  0.5393,  1.2356],\n",
            "        [-2.0148,  0.5833,  1.1433]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8195,  0.6451,  1.2097],\n",
            "        [-1.7459,  2.0565, -0.3606],\n",
            "        [-1.5837,  1.8518, -0.4282],\n",
            "        [-1.8994,  2.1622, -0.3904],\n",
            "        [-1.7270,  2.0542, -0.4965],\n",
            "        [ 0.7423, -0.0185, -1.5195],\n",
            "        [-0.9011,  1.2041, -0.8398],\n",
            "        [-1.4977,  1.9091, -0.7911],\n",
            "        [-1.5794,  1.6663, -0.3449],\n",
            "        [-1.7349,  0.4339,  1.1143],\n",
            "        [-2.1054,  0.7233,  1.3639],\n",
            "        [-1.7421,  1.8770, -0.4021],\n",
            "        [-1.5239,  1.9101, -0.5482],\n",
            "        [-1.6650,  1.8157, -0.5112],\n",
            "        [-1.6452,  0.5393,  1.2356],\n",
            "        [-2.0148,  0.5833,  1.1433]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6722,  1.6329, -0.1019],\n",
            "        [-1.1722,  1.6289, -0.8291],\n",
            "        [-1.5704,  2.0294, -0.4810],\n",
            "        [-1.6921,  2.1359, -0.4240],\n",
            "        [-1.7222,  2.0737, -0.4935],\n",
            "        [-1.2903,  1.5775, -0.7419],\n",
            "        [-2.0015,  2.0769, -0.6380],\n",
            "        [-1.5814,  1.8795, -0.5686],\n",
            "        [-1.8165,  1.6895,  0.1609],\n",
            "        [-1.7340,  2.1343, -0.6416],\n",
            "        [-1.6342,  1.9105, -0.4708],\n",
            "        [-1.9080,  0.9602,  0.7480],\n",
            "        [ 0.5413,  0.0230, -1.2732],\n",
            "        [ 0.7139,  0.0612, -1.2678],\n",
            "        [-1.7700,  1.9891, -0.4539],\n",
            "        [-1.4841,  1.9893, -0.6597]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6722,  1.6329, -0.1019],\n",
            "        [-1.1722,  1.6289, -0.8291],\n",
            "        [-1.5704,  2.0294, -0.4810],\n",
            "        [-1.6921,  2.1359, -0.4240],\n",
            "        [-1.7222,  2.0737, -0.4935],\n",
            "        [-1.2903,  1.5775, -0.7419],\n",
            "        [-2.0015,  2.0769, -0.6380],\n",
            "        [-1.5814,  1.8795, -0.5686],\n",
            "        [-1.8165,  1.6895,  0.1609],\n",
            "        [-1.7340,  2.1343, -0.6416],\n",
            "        [-1.6342,  1.9105, -0.4708],\n",
            "        [-1.9080,  0.9602,  0.7480],\n",
            "        [ 0.5413,  0.0230, -1.2732],\n",
            "        [ 0.7139,  0.0612, -1.2678],\n",
            "        [-1.7700,  1.9891, -0.4539],\n",
            "        [-1.4841,  1.9893, -0.6597]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3327,  0.3477, -1.2694],\n",
            "        [-1.8374,  2.1619, -0.4732],\n",
            "        [-1.5847,  2.0719, -0.5046],\n",
            "        [-1.6509,  1.5730,  0.0268],\n",
            "        [ 0.5978,  0.2561, -1.3653],\n",
            "        [-1.8778,  0.5912,  1.1558],\n",
            "        [-1.9848,  1.1704,  0.4827],\n",
            "        [ 0.6287,  0.2408, -1.2477],\n",
            "        [-1.8415,  2.1878, -0.5018],\n",
            "        [-1.9651,  0.5807,  1.2498],\n",
            "        [-1.9099,  1.5624,  0.1294],\n",
            "        [-1.4666,  1.7566, -0.4499],\n",
            "        [-1.9854,  0.5858,  1.1785],\n",
            "        [-1.7184,  1.9137, -0.6124],\n",
            "        [-1.6487,  1.9429, -0.5838],\n",
            "        [-1.8107,  0.7469,  1.0624]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.3327,  0.3477, -1.2694],\n",
            "        [-1.8374,  2.1619, -0.4732],\n",
            "        [-1.5847,  2.0719, -0.5046],\n",
            "        [-1.6509,  1.5730,  0.0268],\n",
            "        [ 0.5978,  0.2561, -1.3653],\n",
            "        [-1.8778,  0.5912,  1.1558],\n",
            "        [-1.9848,  1.1704,  0.4827],\n",
            "        [ 0.6287,  0.2408, -1.2477],\n",
            "        [-1.8415,  2.1878, -0.5018],\n",
            "        [-1.9651,  0.5807,  1.2498],\n",
            "        [-1.9099,  1.5624,  0.1294],\n",
            "        [-1.4666,  1.7566, -0.4499],\n",
            "        [-1.9854,  0.5858,  1.1785],\n",
            "        [-1.7184,  1.9137, -0.6124],\n",
            "        [-1.6487,  1.9429, -0.5838],\n",
            "        [-1.8107,  0.7469,  1.0624]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7317,  1.9326, -0.6166],\n",
            "        [-1.7011,  1.8649, -0.5151],\n",
            "        [ 0.8450,  0.0702, -1.1610],\n",
            "        [-1.9406,  2.1253, -0.3229],\n",
            "        [-1.7551,  1.8700, -0.5173],\n",
            "        [ 0.1062,  0.4213, -1.2552],\n",
            "        [-1.5909,  1.8254, -0.4415],\n",
            "        [-1.7534,  1.7412, -0.5265],\n",
            "        [-1.9532,  1.2859,  0.3727],\n",
            "        [-1.7730,  2.1216, -0.4484],\n",
            "        [-1.6444,  0.6261,  0.9356],\n",
            "        [-1.4789,  1.8165, -0.6542],\n",
            "        [-1.6212,  1.8046, -0.5208],\n",
            "        [-1.7119,  1.9953, -0.4593],\n",
            "        [-1.7461,  1.0742,  0.9680],\n",
            "        [-1.8195,  0.7085,  0.9962]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7317,  1.9326, -0.6166],\n",
            "        [-1.7011,  1.8649, -0.5151],\n",
            "        [ 0.8450,  0.0702, -1.1610],\n",
            "        [-1.9406,  2.1253, -0.3229],\n",
            "        [-1.7551,  1.8700, -0.5173],\n",
            "        [ 0.1062,  0.4213, -1.2552],\n",
            "        [-1.5909,  1.8254, -0.4415],\n",
            "        [-1.7534,  1.7412, -0.5265],\n",
            "        [-1.9532,  1.2859,  0.3727],\n",
            "        [-1.7730,  2.1216, -0.4484],\n",
            "        [-1.6444,  0.6261,  0.9356],\n",
            "        [-1.4789,  1.8165, -0.6542],\n",
            "        [-1.6212,  1.8046, -0.5208],\n",
            "        [-1.7119,  1.9953, -0.4593],\n",
            "        [-1.7461,  1.0742,  0.9680],\n",
            "        [-1.8195,  0.7085,  0.9962]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4373,  1.6606, -0.7549],\n",
            "        [ 0.6991,  0.0736, -1.1811],\n",
            "        [-1.7792,  1.8096, -0.1912],\n",
            "        [-1.8895,  2.2303, -0.4581],\n",
            "        [-1.8693,  0.6112,  1.1991],\n",
            "        [-1.9049,  2.1651, -0.4425],\n",
            "        [-1.6498,  1.8441, -0.5276],\n",
            "        [-1.7251,  2.0355, -0.1765],\n",
            "        [-1.9068,  1.8308, -0.3284],\n",
            "        [-1.7140,  2.1919, -0.4827],\n",
            "        [-0.1964,  0.1380, -0.0551],\n",
            "        [-1.7337,  1.9972, -0.1616],\n",
            "        [-1.9977,  1.9026, -0.3689],\n",
            "        [-0.9150,  0.9832, -0.2595],\n",
            "        [ 0.4115,  0.3721, -1.2370],\n",
            "        [-1.7578,  2.1462, -0.2832]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4373,  1.6606, -0.7549],\n",
            "        [ 0.6991,  0.0736, -1.1811],\n",
            "        [-1.7792,  1.8096, -0.1912],\n",
            "        [-1.8895,  2.2303, -0.4581],\n",
            "        [-1.8693,  0.6112,  1.1991],\n",
            "        [-1.9049,  2.1651, -0.4425],\n",
            "        [-1.6498,  1.8441, -0.5276],\n",
            "        [-1.7251,  2.0355, -0.1765],\n",
            "        [-1.9068,  1.8308, -0.3284],\n",
            "        [-1.7140,  2.1919, -0.4827],\n",
            "        [-0.1964,  0.1380, -0.0551],\n",
            "        [-1.7337,  1.9972, -0.1616],\n",
            "        [-1.9977,  1.9026, -0.3689],\n",
            "        [-0.9150,  0.9832, -0.2595],\n",
            "        [ 0.4115,  0.3721, -1.2370],\n",
            "        [-1.7578,  2.1462, -0.2832]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6763,  1.8265, -0.1588],\n",
            "        [-1.6873,  1.8795, -0.2076],\n",
            "        [-1.9277,  2.0164, -0.2334],\n",
            "        [-1.9864,  0.6595,  1.2173],\n",
            "        [-1.9131,  2.0158, -0.3602],\n",
            "        [-1.8218,  2.2156, -0.4340],\n",
            "        [-1.9476,  0.3979,  1.3566],\n",
            "        [-1.6817,  0.6824,  0.8414],\n",
            "        [-0.8951,  0.2385,  0.4339],\n",
            "        [ 0.6820, -0.0258, -1.3029],\n",
            "        [-1.9108,  0.7492,  0.9018],\n",
            "        [ 0.3497,  0.3666, -1.2674],\n",
            "        [-1.6154,  0.6201,  1.0551],\n",
            "        [-1.7613,  1.9504, -0.5131],\n",
            "        [-1.8337,  1.9556, -0.4623],\n",
            "        [-1.7802,  0.5540,  1.0855]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6763,  1.8265, -0.1588],\n",
            "        [-1.6873,  1.8795, -0.2076],\n",
            "        [-1.9277,  2.0164, -0.2334],\n",
            "        [-1.9864,  0.6595,  1.2173],\n",
            "        [-1.9131,  2.0158, -0.3602],\n",
            "        [-1.8218,  2.2156, -0.4340],\n",
            "        [-1.9476,  0.3979,  1.3566],\n",
            "        [-1.6817,  0.6824,  0.8414],\n",
            "        [-0.8951,  0.2385,  0.4339],\n",
            "        [ 0.6820, -0.0258, -1.3029],\n",
            "        [-1.9108,  0.7492,  0.9018],\n",
            "        [ 0.3497,  0.3666, -1.2674],\n",
            "        [-1.6154,  0.6201,  1.0551],\n",
            "        [-1.7613,  1.9504, -0.5131],\n",
            "        [-1.8337,  1.9556, -0.4623],\n",
            "        [-1.7802,  0.5540,  1.0855]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8691,  0.4217,  1.2451],\n",
            "        [-1.6632,  1.8353, -0.5453],\n",
            "        [-1.7847,  1.7751, -0.6337],\n",
            "        [-1.8457,  1.9820, -0.3666],\n",
            "        [-1.8512,  1.2753, -0.1182],\n",
            "        [-1.9249,  2.0611, -0.4450],\n",
            "        [-2.0094,  2.0412, -0.2788],\n",
            "        [-1.9102,  2.0468, -0.4424],\n",
            "        [-2.0633,  1.9927,  0.0126],\n",
            "        [-1.9006,  1.9916, -0.2442],\n",
            "        [-2.0110,  0.3897,  1.3906],\n",
            "        [-1.7183,  1.9864, -0.3620],\n",
            "        [-1.7831,  0.4924,  0.9242],\n",
            "        [-1.9033,  0.2918,  1.2245],\n",
            "        [-1.8436,  2.0797, -0.2759],\n",
            "        [ 0.4174,  0.1364, -1.0915]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8691,  0.4217,  1.2451],\n",
            "        [-1.6632,  1.8353, -0.5453],\n",
            "        [-1.7847,  1.7751, -0.6337],\n",
            "        [-1.8457,  1.9820, -0.3666],\n",
            "        [-1.8512,  1.2753, -0.1182],\n",
            "        [-1.9249,  2.0611, -0.4450],\n",
            "        [-2.0094,  2.0412, -0.2788],\n",
            "        [-1.9102,  2.0468, -0.4424],\n",
            "        [-2.0633,  1.9927,  0.0126],\n",
            "        [-1.9006,  1.9916, -0.2442],\n",
            "        [-2.0110,  0.3897,  1.3906],\n",
            "        [-1.7183,  1.9864, -0.3620],\n",
            "        [-1.7831,  0.4924,  0.9242],\n",
            "        [-1.9033,  0.2918,  1.2245],\n",
            "        [-1.8436,  2.0797, -0.2759],\n",
            "        [ 0.4174,  0.1364, -1.0915]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9879,  0.5597,  0.9520],\n",
            "        [-1.9962,  0.4625,  1.2609],\n",
            "        [-1.5605,  1.9254, -0.6015],\n",
            "        [-1.6635,  1.7280, -0.1433],\n",
            "        [-0.4384,  0.8482, -0.6554],\n",
            "        [-1.9267,  1.8285, -0.0203],\n",
            "        [-1.9462,  1.8914, -0.0023],\n",
            "        [-1.8420,  1.7357, -0.2649],\n",
            "        [-1.7875,  1.7952, -0.1895],\n",
            "        [-1.8563,  1.8065, -0.4250],\n",
            "        [-1.5707,  1.9382, -0.4355],\n",
            "        [-1.7045,  0.4510,  1.1551],\n",
            "        [-1.7194,  2.0423, -0.3846],\n",
            "        [-1.9755,  1.8985, -0.1840],\n",
            "        [-1.9988,  0.9602,  1.0584],\n",
            "        [-1.9449,  1.6991, -0.5313]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9879,  0.5597,  0.9520],\n",
            "        [-1.9962,  0.4625,  1.2609],\n",
            "        [-1.5605,  1.9254, -0.6015],\n",
            "        [-1.6635,  1.7280, -0.1433],\n",
            "        [-0.4384,  0.8482, -0.6554],\n",
            "        [-1.9267,  1.8285, -0.0203],\n",
            "        [-1.9462,  1.8914, -0.0023],\n",
            "        [-1.8420,  1.7357, -0.2649],\n",
            "        [-1.7875,  1.7952, -0.1895],\n",
            "        [-1.8563,  1.8065, -0.4250],\n",
            "        [-1.5707,  1.9382, -0.4355],\n",
            "        [-1.7045,  0.4510,  1.1551],\n",
            "        [-1.7194,  2.0423, -0.3846],\n",
            "        [-1.9755,  1.8985, -0.1840],\n",
            "        [-1.9988,  0.9602,  1.0584],\n",
            "        [-1.9449,  1.6991, -0.5313]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.2057,  0.5244, -0.8543],\n",
            "        [-2.0731,  0.5210,  1.4388],\n",
            "        [-1.8307,  1.8782, -0.1721],\n",
            "        [-1.3436,  0.3562,  0.6869],\n",
            "        [-1.9384,  2.0155, -0.3020],\n",
            "        [-1.8360,  2.0503, -0.1851],\n",
            "        [-2.0014,  1.8715, -0.1787],\n",
            "        [-1.8083,  1.6268, -0.4879],\n",
            "        [-1.5901,  1.4484, -0.2410],\n",
            "        [-1.7518,  0.4883,  1.4504],\n",
            "        [ 0.3946,  0.2292, -1.0262],\n",
            "        [-1.7876,  1.9363, -0.3977],\n",
            "        [-1.3405,  1.4671, -0.6984],\n",
            "        [-1.8567,  0.4720,  1.3346],\n",
            "        [ 0.3807,  0.1170, -1.2145],\n",
            "        [-1.5327,  1.5159, -0.5358]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-0.2057,  0.5244, -0.8543],\n",
            "        [-2.0731,  0.5210,  1.4388],\n",
            "        [-1.8307,  1.8782, -0.1721],\n",
            "        [-1.3436,  0.3562,  0.6869],\n",
            "        [-1.9384,  2.0155, -0.3020],\n",
            "        [-1.8360,  2.0503, -0.1851],\n",
            "        [-2.0014,  1.8715, -0.1787],\n",
            "        [-1.8083,  1.6268, -0.4879],\n",
            "        [-1.5901,  1.4484, -0.2410],\n",
            "        [-1.7518,  0.4883,  1.4504],\n",
            "        [ 0.3946,  0.2292, -1.0262],\n",
            "        [-1.7876,  1.9363, -0.3977],\n",
            "        [-1.3405,  1.4671, -0.6984],\n",
            "        [-1.8567,  0.4720,  1.3346],\n",
            "        [ 0.3807,  0.1170, -1.2145],\n",
            "        [-1.5327,  1.5159, -0.5358]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8740,  0.8700,  0.8148],\n",
            "        [-1.8562,  1.8292, -0.0321],\n",
            "        [-2.1010,  0.5203,  1.3121],\n",
            "        [-1.8823,  0.4829,  1.3651],\n",
            "        [-2.1102,  2.0130, -0.0768],\n",
            "        [-1.9537,  1.8670, -0.0439],\n",
            "        [-1.7489,  1.8758, -0.1677],\n",
            "        [-1.8115,  0.3728,  1.3072],\n",
            "        [-2.0284,  2.0139, -0.0646],\n",
            "        [-2.0507,  2.0190, -0.1588],\n",
            "        [-1.9507,  0.4631,  1.3114],\n",
            "        [-1.4185,  1.4056, -0.4911],\n",
            "        [-1.6939,  2.1446, -0.3872],\n",
            "        [-1.8209,  0.5939,  1.4228],\n",
            "        [ 0.3290,  0.1209, -0.9416],\n",
            "        [-1.8865,  1.8532, -0.3453]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8740,  0.8700,  0.8148],\n",
            "        [-1.8562,  1.8292, -0.0321],\n",
            "        [-2.1010,  0.5203,  1.3121],\n",
            "        [-1.8823,  0.4829,  1.3651],\n",
            "        [-2.1102,  2.0130, -0.0768],\n",
            "        [-1.9537,  1.8670, -0.0439],\n",
            "        [-1.7489,  1.8758, -0.1677],\n",
            "        [-1.8115,  0.3728,  1.3072],\n",
            "        [-2.0284,  2.0139, -0.0646],\n",
            "        [-2.0507,  2.0190, -0.1588],\n",
            "        [-1.9507,  0.4631,  1.3114],\n",
            "        [-1.4185,  1.4056, -0.4911],\n",
            "        [-1.6939,  2.1446, -0.3872],\n",
            "        [-1.8209,  0.5939,  1.4228],\n",
            "        [ 0.3290,  0.1209, -0.9416],\n",
            "        [-1.8865,  1.8532, -0.3453]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7383,  2.0587, -0.3185],\n",
            "        [ 0.4710,  0.0754, -1.1852],\n",
            "        [ 0.3884,  0.0420, -1.0366],\n",
            "        [-1.7863,  1.9678, -0.4613],\n",
            "        [-1.6527,  0.1995,  1.2141],\n",
            "        [-1.8422,  1.9382, -0.2011],\n",
            "        [-1.8949,  0.5160,  1.3732],\n",
            "        [-1.9924,  0.3475,  1.3819],\n",
            "        [-1.8420,  1.6634,  0.1326],\n",
            "        [-2.2595,  0.6571,  1.2025],\n",
            "        [-1.8006,  2.0131, -0.1350],\n",
            "        [-1.8221,  0.5256,  1.4274],\n",
            "        [-1.8541,  1.9623, -0.4101],\n",
            "        [-1.9208,  0.4464,  1.3851],\n",
            "        [-1.7281,  0.4506,  1.2819],\n",
            "        [-1.6267,  0.3400,  1.2386]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7383,  2.0587, -0.3185],\n",
            "        [ 0.4710,  0.0754, -1.1852],\n",
            "        [ 0.3884,  0.0420, -1.0366],\n",
            "        [-1.7863,  1.9678, -0.4613],\n",
            "        [-1.6527,  0.1995,  1.2141],\n",
            "        [-1.8422,  1.9382, -0.2011],\n",
            "        [-1.8949,  0.5160,  1.3732],\n",
            "        [-1.9924,  0.3475,  1.3819],\n",
            "        [-1.8420,  1.6634,  0.1326],\n",
            "        [-2.2595,  0.6571,  1.2025],\n",
            "        [-1.8006,  2.0131, -0.1350],\n",
            "        [-1.8221,  0.5256,  1.4274],\n",
            "        [-1.8541,  1.9623, -0.4101],\n",
            "        [-1.9208,  0.4464,  1.3851],\n",
            "        [-1.7281,  0.4506,  1.2819],\n",
            "        [-1.6267,  0.3400,  1.2386]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9923,  0.4221,  1.5908],\n",
            "        [-1.9327,  0.3432,  1.3778],\n",
            "        [-1.4619,  1.2780, -0.3722],\n",
            "        [-1.7509,  1.8744, -0.1978],\n",
            "        [-2.0400,  1.9242, -0.3459],\n",
            "        [ 0.3989,  0.2295, -1.1242],\n",
            "        [-1.7030,  2.0477, -0.3796],\n",
            "        [-1.8179,  1.5111, -0.2884],\n",
            "        [-2.0468,  1.7242, -0.2359],\n",
            "        [-1.9433,  1.8416, -0.2432],\n",
            "        [ 0.4092,  0.2770, -1.0528],\n",
            "        [-1.7491,  1.8192, -0.4979],\n",
            "        [-1.8987,  1.7093, -0.2601],\n",
            "        [-1.6674,  1.8643, -0.4544],\n",
            "        [-1.7656,  1.8057, -0.3400],\n",
            "        [-1.7728,  2.1707, -0.4045]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9923,  0.4221,  1.5908],\n",
            "        [-1.9327,  0.3432,  1.3778],\n",
            "        [-1.4619,  1.2780, -0.3722],\n",
            "        [-1.7509,  1.8744, -0.1978],\n",
            "        [-2.0400,  1.9242, -0.3459],\n",
            "        [ 0.3989,  0.2295, -1.1242],\n",
            "        [-1.7030,  2.0477, -0.3796],\n",
            "        [-1.8179,  1.5111, -0.2884],\n",
            "        [-2.0468,  1.7242, -0.2359],\n",
            "        [-1.9433,  1.8416, -0.2432],\n",
            "        [ 0.4092,  0.2770, -1.0528],\n",
            "        [-1.7491,  1.8192, -0.4979],\n",
            "        [-1.8987,  1.7093, -0.2601],\n",
            "        [-1.6674,  1.8643, -0.4544],\n",
            "        [-1.7656,  1.8057, -0.3400],\n",
            "        [-1.7728,  2.1707, -0.4045]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9141,  1.8931, -0.3712],\n",
            "        [-1.8635,  1.8140, -0.2104],\n",
            "        [-2.0377,  0.4276,  1.4773],\n",
            "        [-1.7822,  1.7588, -0.1738],\n",
            "        [-2.1666,  1.4898,  0.3832],\n",
            "        [-1.4473,  1.4518, -0.3012],\n",
            "        [-1.7606,  0.2567,  1.4162],\n",
            "        [-1.8178,  1.8971, -0.2399],\n",
            "        [-1.9810,  1.7994, -0.2907],\n",
            "        [-0.5045,  0.1949, -0.0131],\n",
            "        [-2.1901,  0.5085,  1.3893],\n",
            "        [-1.9178,  1.8767, -0.3194],\n",
            "        [ 0.3325,  0.0888, -1.0134],\n",
            "        [-2.0899,  2.0702, -0.3145],\n",
            "        [-1.9362,  1.7713, -0.2886],\n",
            "        [-2.0289,  2.0896, -0.1923]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9141,  1.8931, -0.3712],\n",
            "        [-1.8635,  1.8140, -0.2104],\n",
            "        [-2.0377,  0.4276,  1.4773],\n",
            "        [-1.7822,  1.7588, -0.1738],\n",
            "        [-2.1666,  1.4898,  0.3832],\n",
            "        [-1.4473,  1.4518, -0.3012],\n",
            "        [-1.7606,  0.2567,  1.4162],\n",
            "        [-1.8178,  1.8971, -0.2399],\n",
            "        [-1.9810,  1.7994, -0.2907],\n",
            "        [-0.5045,  0.1949, -0.0131],\n",
            "        [-2.1901,  0.5085,  1.3893],\n",
            "        [-1.9178,  1.8767, -0.3194],\n",
            "        [ 0.3325,  0.0888, -1.0134],\n",
            "        [-2.0899,  2.0702, -0.3145],\n",
            "        [-1.9362,  1.7713, -0.2886],\n",
            "        [-2.0289,  2.0896, -0.1923]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9805,  1.8570, -0.4737],\n",
            "        [-1.9727,  1.5154,  0.1020],\n",
            "        [-1.8098,  1.8231, -0.3744],\n",
            "        [-1.9216,  0.4555,  1.4634],\n",
            "        [-0.5851,  0.8404, -0.7767],\n",
            "        [-0.8561,  1.0293, -0.5875],\n",
            "        [-0.3291,  0.6837, -0.7065],\n",
            "        [ 0.4691,  0.1638, -1.0170],\n",
            "        [-0.1806,  0.6156, -1.0056],\n",
            "        [-1.7026,  1.8552, -0.2929],\n",
            "        [-1.5901,  2.0216, -0.5086],\n",
            "        [-1.8864,  2.1256, -0.4050],\n",
            "        [-2.1121,  0.3714,  1.4189],\n",
            "        [ 0.2073, -0.0924, -0.6375],\n",
            "        [-1.7921,  0.2760,  1.3852],\n",
            "        [-1.9544,  0.3481,  1.4150]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9805,  1.8570, -0.4737],\n",
            "        [-1.9727,  1.5154,  0.1020],\n",
            "        [-1.8098,  1.8231, -0.3744],\n",
            "        [-1.9216,  0.4555,  1.4634],\n",
            "        [-0.5851,  0.8404, -0.7767],\n",
            "        [-0.8561,  1.0293, -0.5875],\n",
            "        [-0.3291,  0.6837, -0.7065],\n",
            "        [ 0.4691,  0.1638, -1.0170],\n",
            "        [-0.1806,  0.6156, -1.0056],\n",
            "        [-1.7026,  1.8552, -0.2929],\n",
            "        [-1.5901,  2.0216, -0.5086],\n",
            "        [-1.8864,  2.1256, -0.4050],\n",
            "        [-2.1121,  0.3714,  1.4189],\n",
            "        [ 0.2073, -0.0924, -0.6375],\n",
            "        [-1.7921,  0.2760,  1.3852],\n",
            "        [-1.9544,  0.3481,  1.4150]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9241,  0.4027,  1.5263],\n",
            "        [-1.8742,  1.9079, -0.1939],\n",
            "        [-1.7426,  1.7714, -0.3346],\n",
            "        [-1.7801,  0.5130,  1.3330],\n",
            "        [ 0.2786,  0.2294, -0.9422],\n",
            "        [-1.8964,  1.9165, -0.2669],\n",
            "        [-1.7824,  0.2587,  1.2647],\n",
            "        [-2.0393,  1.9211, -0.5050],\n",
            "        [-1.9107,  1.8595, -0.2695],\n",
            "        [-1.8851,  1.8378, -0.3746],\n",
            "        [-1.8386,  1.8103, -0.5183],\n",
            "        [-1.9675,  0.5749,  1.2974],\n",
            "        [-1.9410,  0.4312,  1.1316],\n",
            "        [-2.0653,  1.5586,  0.2462],\n",
            "        [-2.0699,  2.0555, -0.2966],\n",
            "        [-1.9651,  1.7558, -0.2267]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9241,  0.4027,  1.5263],\n",
            "        [-1.8742,  1.9079, -0.1939],\n",
            "        [-1.7426,  1.7714, -0.3346],\n",
            "        [-1.7801,  0.5130,  1.3330],\n",
            "        [ 0.2786,  0.2294, -0.9422],\n",
            "        [-1.8964,  1.9165, -0.2669],\n",
            "        [-1.7824,  0.2587,  1.2647],\n",
            "        [-2.0393,  1.9211, -0.5050],\n",
            "        [-1.9107,  1.8595, -0.2695],\n",
            "        [-1.8851,  1.8378, -0.3746],\n",
            "        [-1.8386,  1.8103, -0.5183],\n",
            "        [-1.9675,  0.5749,  1.2974],\n",
            "        [-1.9410,  0.4312,  1.1316],\n",
            "        [-2.0653,  1.5586,  0.2462],\n",
            "        [-2.0699,  2.0555, -0.2966],\n",
            "        [-1.9651,  1.7558, -0.2267]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9243e+00,  2.0201e+00, -2.7529e-04],\n",
            "        [ 4.0648e-01, -5.0526e-02, -1.0596e+00],\n",
            "        [-1.8586e+00,  2.0384e+00, -2.6743e-01],\n",
            "        [-1.9800e+00,  1.8505e+00, -2.5116e-01],\n",
            "        [-2.0362e+00,  1.7284e+00, -5.0376e-02],\n",
            "        [-1.8175e+00,  3.5106e-01,  1.2551e+00],\n",
            "        [-2.1393e+00,  1.4056e+00,  4.2152e-01],\n",
            "        [-1.8125e+00,  1.9345e+00, -1.4473e-01],\n",
            "        [-2.0293e+00,  1.9887e+00, -1.8726e-01],\n",
            "        [-1.8354e+00,  1.8500e+00, -4.7082e-01],\n",
            "        [-1.8494e+00,  6.7606e-01,  9.4084e-01],\n",
            "        [-1.6984e+00,  1.9940e-01,  1.5212e+00],\n",
            "        [-1.9689e+00,  1.7836e+00, -1.1533e-01],\n",
            "        [-1.9915e+00,  1.9471e+00, -2.1317e-01],\n",
            "        [ 4.6435e-01,  1.4673e-01, -9.4451e-01],\n",
            "        [-1.9004e+00,  1.8552e+00, -1.8060e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9243e+00,  2.0201e+00, -2.7529e-04],\n",
            "        [ 4.0648e-01, -5.0526e-02, -1.0596e+00],\n",
            "        [-1.8586e+00,  2.0384e+00, -2.6743e-01],\n",
            "        [-1.9800e+00,  1.8505e+00, -2.5116e-01],\n",
            "        [-2.0362e+00,  1.7284e+00, -5.0376e-02],\n",
            "        [-1.8175e+00,  3.5106e-01,  1.2551e+00],\n",
            "        [-2.1393e+00,  1.4056e+00,  4.2152e-01],\n",
            "        [-1.8125e+00,  1.9345e+00, -1.4473e-01],\n",
            "        [-2.0293e+00,  1.9887e+00, -1.8726e-01],\n",
            "        [-1.8354e+00,  1.8500e+00, -4.7082e-01],\n",
            "        [-1.8494e+00,  6.7606e-01,  9.4084e-01],\n",
            "        [-1.6984e+00,  1.9940e-01,  1.5212e+00],\n",
            "        [-1.9689e+00,  1.7836e+00, -1.1533e-01],\n",
            "        [-1.9915e+00,  1.9471e+00, -2.1317e-01],\n",
            "        [ 4.6435e-01,  1.4673e-01, -9.4451e-01],\n",
            "        [-1.9004e+00,  1.8552e+00, -1.8060e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.1257,  0.1098,  0.8949],\n",
            "        [ 0.5837, -0.0302, -0.9735],\n",
            "        [-1.8824,  1.7903, -0.0869],\n",
            "        [-1.8434,  1.9029, -0.3108],\n",
            "        [-1.8122,  1.8639, -0.4094],\n",
            "        [-2.0626,  2.0204, -0.0123],\n",
            "        [-1.7932,  1.9576, -0.1914],\n",
            "        [-0.5929,  0.6735, -0.6719],\n",
            "        [-1.6748,  1.9334, -0.3212],\n",
            "        [-1.9617,  0.1623,  1.4695],\n",
            "        [ 0.3704,  0.1782, -0.9683],\n",
            "        [-1.8042,  0.3497,  1.2515],\n",
            "        [-2.0689,  1.5474,  0.0419],\n",
            "        [-1.9449,  2.0767, -0.3605],\n",
            "        [-1.9201,  1.9172, -0.4271],\n",
            "        [-1.7930,  0.3201,  1.3503]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.1257,  0.1098,  0.8949],\n",
            "        [ 0.5837, -0.0302, -0.9735],\n",
            "        [-1.8824,  1.7903, -0.0869],\n",
            "        [-1.8434,  1.9029, -0.3108],\n",
            "        [-1.8122,  1.8639, -0.4094],\n",
            "        [-2.0626,  2.0204, -0.0123],\n",
            "        [-1.7932,  1.9576, -0.1914],\n",
            "        [-0.5929,  0.6735, -0.6719],\n",
            "        [-1.6748,  1.9334, -0.3212],\n",
            "        [-1.9617,  0.1623,  1.4695],\n",
            "        [ 0.3704,  0.1782, -0.9683],\n",
            "        [-1.8042,  0.3497,  1.2515],\n",
            "        [-2.0689,  1.5474,  0.0419],\n",
            "        [-1.9449,  2.0767, -0.3605],\n",
            "        [-1.9201,  1.9172, -0.4271],\n",
            "        [-1.7930,  0.3201,  1.3503]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5448,  0.0398, -1.0448],\n",
            "        [-1.8408,  1.6728, -0.1624],\n",
            "        [-1.8978,  1.7510, -0.2684],\n",
            "        [-1.9146,  1.9266, -0.4000],\n",
            "        [ 0.1302,  0.2405, -0.9285],\n",
            "        [ 0.4086,  0.1507, -0.8838],\n",
            "        [-1.8856,  1.9209, -0.1492],\n",
            "        [-1.8886,  0.5613,  1.2272],\n",
            "        [-1.9127,  1.9610, -0.0852],\n",
            "        [-2.0772,  1.8242,  0.0405],\n",
            "        [-1.9955,  1.1712,  0.6832],\n",
            "        [-1.8982,  0.4868,  1.4455],\n",
            "        [-1.8274,  1.6199, -0.2403],\n",
            "        [-2.2332,  1.2862,  0.7597],\n",
            "        [-2.1439,  1.9219,  0.0255],\n",
            "        [-1.9576,  1.9356, -0.3643]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.5448,  0.0398, -1.0448],\n",
            "        [-1.8408,  1.6728, -0.1624],\n",
            "        [-1.8978,  1.7510, -0.2684],\n",
            "        [-1.9146,  1.9266, -0.4000],\n",
            "        [ 0.1302,  0.2405, -0.9285],\n",
            "        [ 0.4086,  0.1507, -0.8838],\n",
            "        [-1.8856,  1.9209, -0.1492],\n",
            "        [-1.8886,  0.5613,  1.2272],\n",
            "        [-1.9127,  1.9610, -0.0852],\n",
            "        [-2.0772,  1.8242,  0.0405],\n",
            "        [-1.9955,  1.1712,  0.6832],\n",
            "        [-1.8982,  0.4868,  1.4455],\n",
            "        [-1.8274,  1.6199, -0.2403],\n",
            "        [-2.2332,  1.2862,  0.7597],\n",
            "        [-2.1439,  1.9219,  0.0255],\n",
            "        [-1.9576,  1.9356, -0.3643]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8640,  1.2299,  0.3200],\n",
            "        [-1.8810,  0.3233,  1.2943],\n",
            "        [-1.8304,  1.7377, -0.1373],\n",
            "        [-1.7617,  0.3743,  1.4807],\n",
            "        [-1.2315,  1.3688, -0.3494],\n",
            "        [-1.9624,  2.1003, -0.2370],\n",
            "        [-1.8036,  1.7458, -0.4931],\n",
            "        [-1.7048,  0.2904,  1.4768],\n",
            "        [-1.7456,  0.5240,  1.2298],\n",
            "        [-2.0045,  0.4477,  1.4150],\n",
            "        [ 0.5596, -0.0950, -1.0451],\n",
            "        [-1.8300,  2.1026, -0.1087],\n",
            "        [-1.8981,  1.6425, -0.2123],\n",
            "        [ 0.4997, -0.0036, -0.9776],\n",
            "        [-1.7197,  0.5221,  0.9168],\n",
            "        [-1.7409,  1.7883, -0.2240]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8640,  1.2299,  0.3200],\n",
            "        [-1.8810,  0.3233,  1.2943],\n",
            "        [-1.8304,  1.7377, -0.1373],\n",
            "        [-1.7617,  0.3743,  1.4807],\n",
            "        [-1.2315,  1.3688, -0.3494],\n",
            "        [-1.9624,  2.1003, -0.2370],\n",
            "        [-1.8036,  1.7458, -0.4931],\n",
            "        [-1.7048,  0.2904,  1.4768],\n",
            "        [-1.7456,  0.5240,  1.2298],\n",
            "        [-2.0045,  0.4477,  1.4150],\n",
            "        [ 0.5596, -0.0950, -1.0451],\n",
            "        [-1.8300,  2.1026, -0.1087],\n",
            "        [-1.8981,  1.6425, -0.2123],\n",
            "        [ 0.4997, -0.0036, -0.9776],\n",
            "        [-1.7197,  0.5221,  0.9168],\n",
            "        [-1.7409,  1.7883, -0.2240]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8518,  1.3228,  0.1262],\n",
            "        [-1.6766,  1.5529, -0.3146],\n",
            "        [-1.9349,  1.9016, -0.1118],\n",
            "        [-1.7460,  1.6945, -0.2453],\n",
            "        [-1.7687,  2.0455, -0.3749],\n",
            "        [-1.8829,  1.9734, -0.2627],\n",
            "        [-1.8540,  0.0973,  1.5106],\n",
            "        [-2.0682,  1.4571,  0.3379],\n",
            "        [-1.8894,  1.4579,  0.1122],\n",
            "        [-1.7971,  1.8817, -0.2816],\n",
            "        [ 0.5028, -0.0645, -1.0324],\n",
            "        [-1.5756,  1.8807, -0.3775],\n",
            "        [-1.7317,  1.9557, -0.1770],\n",
            "        [-1.8254,  1.7926, -0.1031],\n",
            "        [-1.7801,  1.8193, -0.2530],\n",
            "        [ 0.5585,  0.0309, -0.9428]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8518,  1.3228,  0.1262],\n",
            "        [-1.6766,  1.5529, -0.3146],\n",
            "        [-1.9349,  1.9016, -0.1118],\n",
            "        [-1.7460,  1.6945, -0.2453],\n",
            "        [-1.7687,  2.0455, -0.3749],\n",
            "        [-1.8829,  1.9734, -0.2627],\n",
            "        [-1.8540,  0.0973,  1.5106],\n",
            "        [-2.0682,  1.4571,  0.3379],\n",
            "        [-1.8894,  1.4579,  0.1122],\n",
            "        [-1.7971,  1.8817, -0.2816],\n",
            "        [ 0.5028, -0.0645, -1.0324],\n",
            "        [-1.5756,  1.8807, -0.3775],\n",
            "        [-1.7317,  1.9557, -0.1770],\n",
            "        [-1.8254,  1.7926, -0.1031],\n",
            "        [-1.7801,  1.8193, -0.2530],\n",
            "        [ 0.5585,  0.0309, -0.9428]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.4165, -0.0663, -0.8988],\n",
            "        [-1.7113,  1.6931,  0.0357],\n",
            "        [-1.9683,  0.4164,  1.2978],\n",
            "        [-1.7403,  1.9792, -0.1809],\n",
            "        [-1.6791,  1.6203, -0.4058],\n",
            "        [-1.6609,  1.9044, -0.2626],\n",
            "        [-2.0157,  1.9090, -0.2034],\n",
            "        [-1.5206,  1.9431, -0.3505],\n",
            "        [ 0.5468, -0.2714, -0.8770],\n",
            "        [-1.8908,  1.7013, -0.2138],\n",
            "        [-1.9510,  1.8867, -0.2171],\n",
            "        [-1.9417,  0.3516,  1.5124],\n",
            "        [-1.6584,  1.6847, -0.2954],\n",
            "        [-1.9930,  1.9943, -0.3060],\n",
            "        [-1.6656,  1.8658, -0.1221],\n",
            "        [-1.8835,  0.2353,  1.5162]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.4165, -0.0663, -0.8988],\n",
            "        [-1.7113,  1.6931,  0.0357],\n",
            "        [-1.9683,  0.4164,  1.2978],\n",
            "        [-1.7403,  1.9792, -0.1809],\n",
            "        [-1.6791,  1.6203, -0.4058],\n",
            "        [-1.6609,  1.9044, -0.2626],\n",
            "        [-2.0157,  1.9090, -0.2034],\n",
            "        [-1.5206,  1.9431, -0.3505],\n",
            "        [ 0.5468, -0.2714, -0.8770],\n",
            "        [-1.8908,  1.7013, -0.2138],\n",
            "        [-1.9510,  1.8867, -0.2171],\n",
            "        [-1.9417,  0.3516,  1.5124],\n",
            "        [-1.6584,  1.6847, -0.2954],\n",
            "        [-1.9930,  1.9943, -0.3060],\n",
            "        [-1.6656,  1.8658, -0.1221],\n",
            "        [-1.8835,  0.2353,  1.5162]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0054,  1.8951, -0.4050],\n",
            "        [-1.5630,  1.6334, -0.2437],\n",
            "        [-1.8749,  1.8470, -0.2128],\n",
            "        [ 0.5250, -0.1564, -0.9510],\n",
            "        [-1.8374,  1.4756,  0.0801],\n",
            "        [-1.6833,  1.7356, -0.2341],\n",
            "        [-1.4137,  1.4736, -0.0405],\n",
            "        [-1.8965,  0.7879,  0.6743],\n",
            "        [-1.8199,  0.2572,  1.5067],\n",
            "        [-1.7111,  1.9917, -0.3263],\n",
            "        [-1.7870,  0.6871,  1.0470],\n",
            "        [-1.8504,  2.1161, -0.4138],\n",
            "        [-2.0856,  1.2355,  0.4115],\n",
            "        [-2.1256,  2.1089, -0.2169],\n",
            "        [-1.5461,  1.7565, -0.3036],\n",
            "        [ 0.0480,  0.0840, -0.4070]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.0054,  1.8951, -0.4050],\n",
            "        [-1.5630,  1.6334, -0.2437],\n",
            "        [-1.8749,  1.8470, -0.2128],\n",
            "        [ 0.5250, -0.1564, -0.9510],\n",
            "        [-1.8374,  1.4756,  0.0801],\n",
            "        [-1.6833,  1.7356, -0.2341],\n",
            "        [-1.4137,  1.4736, -0.0405],\n",
            "        [-1.8965,  0.7879,  0.6743],\n",
            "        [-1.8199,  0.2572,  1.5067],\n",
            "        [-1.7111,  1.9917, -0.3263],\n",
            "        [-1.7870,  0.6871,  1.0470],\n",
            "        [-1.8504,  2.1161, -0.4138],\n",
            "        [-2.0856,  1.2355,  0.4115],\n",
            "        [-2.1256,  2.1089, -0.2169],\n",
            "        [-1.5461,  1.7565, -0.3036],\n",
            "        [ 0.0480,  0.0840, -0.4070]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8777,  2.0038, -0.3692],\n",
            "        [-1.6344,  1.7876, -0.2548],\n",
            "        [-1.9122,  2.0029, -0.1439],\n",
            "        [-1.8236,  1.8698, -0.4406],\n",
            "        [-1.8161,  2.0304, -0.2420],\n",
            "        [-0.2041,  0.8572, -0.9469],\n",
            "        [-1.9374,  1.8808, -0.0437],\n",
            "        [-1.8660,  0.5609,  1.1173],\n",
            "        [-1.9835,  0.3973,  1.5065],\n",
            "        [ 0.2318, -0.1448, -0.6571],\n",
            "        [-1.5929,  1.8712,  0.0383],\n",
            "        [ 0.0950,  0.1611, -0.6625],\n",
            "        [-1.7173,  1.9023, -0.3754],\n",
            "        [-1.7379,  1.8014, -0.1776],\n",
            "        [-1.5227,  1.7978, -0.2974],\n",
            "        [-1.6687,  1.9548, -0.2660]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8777,  2.0038, -0.3692],\n",
            "        [-1.6344,  1.7876, -0.2548],\n",
            "        [-1.9122,  2.0029, -0.1439],\n",
            "        [-1.8236,  1.8698, -0.4406],\n",
            "        [-1.8161,  2.0304, -0.2420],\n",
            "        [-0.2041,  0.8572, -0.9469],\n",
            "        [-1.9374,  1.8808, -0.0437],\n",
            "        [-1.8660,  0.5609,  1.1173],\n",
            "        [-1.9835,  0.3973,  1.5065],\n",
            "        [ 0.2318, -0.1448, -0.6571],\n",
            "        [-1.5929,  1.8712,  0.0383],\n",
            "        [ 0.0950,  0.1611, -0.6625],\n",
            "        [-1.7173,  1.9023, -0.3754],\n",
            "        [-1.7379,  1.8014, -0.1776],\n",
            "        [-1.5227,  1.7978, -0.2974],\n",
            "        [-1.6687,  1.9548, -0.2660]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5635,  1.6368, -0.0535],\n",
            "        [-1.7626,  1.5450,  0.0491],\n",
            "        [-1.7770,  1.7240, -0.2160],\n",
            "        [-1.8965,  0.2247,  1.4817],\n",
            "        [ 0.2327,  0.1050, -0.7355],\n",
            "        [-1.6629,  1.8595, -0.3507],\n",
            "        [-1.7000,  0.4515,  1.2495],\n",
            "        [-1.6927,  0.0903,  1.3636],\n",
            "        [-2.0845,  0.3059,  1.5897],\n",
            "        [-1.9191,  1.8945, -0.2594],\n",
            "        [-1.9521,  1.3825,  0.2099],\n",
            "        [-2.0381,  0.5539,  1.2530],\n",
            "        [-1.8148,  1.8843,  0.0716],\n",
            "        [-1.7066,  1.7892, -0.3691],\n",
            "        [-1.9414,  2.2226, -0.3286],\n",
            "        [-1.8089,  0.4224,  1.4032]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5635,  1.6368, -0.0535],\n",
            "        [-1.7626,  1.5450,  0.0491],\n",
            "        [-1.7770,  1.7240, -0.2160],\n",
            "        [-1.8965,  0.2247,  1.4817],\n",
            "        [ 0.2327,  0.1050, -0.7355],\n",
            "        [-1.6629,  1.8595, -0.3507],\n",
            "        [-1.7000,  0.4515,  1.2495],\n",
            "        [-1.6927,  0.0903,  1.3636],\n",
            "        [-2.0845,  0.3059,  1.5897],\n",
            "        [-1.9191,  1.8945, -0.2594],\n",
            "        [-1.9521,  1.3825,  0.2099],\n",
            "        [-2.0381,  0.5539,  1.2530],\n",
            "        [-1.8148,  1.8843,  0.0716],\n",
            "        [-1.7066,  1.7892, -0.3691],\n",
            "        [-1.9414,  2.2226, -0.3286],\n",
            "        [-1.8089,  0.4224,  1.4032]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8081,  1.6825, -0.4677],\n",
            "        [-1.7754,  1.9143, -0.1710],\n",
            "        [-1.6164,  1.7248, -0.5588],\n",
            "        [-0.9869,  1.0634, -0.5330],\n",
            "        [-0.0692, -0.1453, -0.1931],\n",
            "        [-1.3699,  1.3482, -0.5587],\n",
            "        [-1.7993,  1.7925, -0.2658],\n",
            "        [-1.6448,  1.7564, -0.2158],\n",
            "        [-1.2564,  1.8014, -0.3753],\n",
            "        [-0.2458, -0.0686, -0.2005],\n",
            "        [ 0.0464,  0.2695, -0.9868],\n",
            "        [-1.4481,  1.7860, -0.2710],\n",
            "        [-1.8140,  1.7876, -0.1818],\n",
            "        [-1.7617,  1.9273, -0.2327],\n",
            "        [-1.8116,  0.3227,  1.4608],\n",
            "        [-0.5238,  0.5357, -0.5402]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8081,  1.6825, -0.4677],\n",
            "        [-1.7754,  1.9143, -0.1710],\n",
            "        [-1.6164,  1.7248, -0.5588],\n",
            "        [-0.9869,  1.0634, -0.5330],\n",
            "        [-0.0692, -0.1453, -0.1931],\n",
            "        [-1.3699,  1.3482, -0.5587],\n",
            "        [-1.7993,  1.7925, -0.2658],\n",
            "        [-1.6448,  1.7564, -0.2158],\n",
            "        [-1.2564,  1.8014, -0.3753],\n",
            "        [-0.2458, -0.0686, -0.2005],\n",
            "        [ 0.0464,  0.2695, -0.9868],\n",
            "        [-1.4481,  1.7860, -0.2710],\n",
            "        [-1.8140,  1.7876, -0.1818],\n",
            "        [-1.7617,  1.9273, -0.2327],\n",
            "        [-1.8116,  0.3227,  1.4608],\n",
            "        [-0.5238,  0.5357, -0.5402]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5765,  1.8257, -0.2812],\n",
            "        [-1.7000,  0.9791,  0.7323],\n",
            "        [ 0.3478, -0.0053, -0.8325],\n",
            "        [ 0.2581,  0.0240, -0.7967],\n",
            "        [-1.8627,  1.5502, -0.1767],\n",
            "        [-1.8549,  0.4450,  1.2964],\n",
            "        [-1.5620,  1.9172, -0.3785],\n",
            "        [-1.6410,  0.2102,  1.1755],\n",
            "        [-1.5910,  0.2007,  1.2438],\n",
            "        [-1.6445,  1.8768, -0.3851],\n",
            "        [-0.6337,  0.7073, -0.5349],\n",
            "        [-2.0221,  1.0691,  0.9594],\n",
            "        [-1.7770,  1.9053, -0.2010],\n",
            "        [-1.8042,  1.7516, -0.2204],\n",
            "        [-1.7916,  1.7003, -0.1132],\n",
            "        [-1.7869,  1.9354, -0.1854]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5765,  1.8257, -0.2812],\n",
            "        [-1.7000,  0.9791,  0.7323],\n",
            "        [ 0.3478, -0.0053, -0.8325],\n",
            "        [ 0.2581,  0.0240, -0.7967],\n",
            "        [-1.8627,  1.5502, -0.1767],\n",
            "        [-1.8549,  0.4450,  1.2964],\n",
            "        [-1.5620,  1.9172, -0.3785],\n",
            "        [-1.6410,  0.2102,  1.1755],\n",
            "        [-1.5910,  0.2007,  1.2438],\n",
            "        [-1.6445,  1.8768, -0.3851],\n",
            "        [-0.6337,  0.7073, -0.5349],\n",
            "        [-2.0221,  1.0691,  0.9594],\n",
            "        [-1.7770,  1.9053, -0.2010],\n",
            "        [-1.8042,  1.7516, -0.2204],\n",
            "        [-1.7916,  1.7003, -0.1132],\n",
            "        [-1.7869,  1.9354, -0.1854]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9113,  0.8653,  0.8500],\n",
            "        [-1.6522,  1.9270, -0.2064],\n",
            "        [ 0.2280, -0.1352, -0.7509],\n",
            "        [-1.8885,  0.1862,  1.6399],\n",
            "        [-1.8280,  1.7995, -0.2533],\n",
            "        [-1.6264,  1.7702, -0.1850],\n",
            "        [-1.6838,  1.8982, -0.3620],\n",
            "        [ 0.5057, -0.0807, -0.9469],\n",
            "        [-1.6749,  0.2578,  1.3248],\n",
            "        [-1.6872,  2.0467, -0.4152],\n",
            "        [ 0.1351,  0.1251, -0.7983],\n",
            "        [-1.5435,  1.8246, -0.5342],\n",
            "        [-1.5603,  0.2137,  1.5283],\n",
            "        [-0.0807, -0.0175, -0.2453],\n",
            "        [-2.0480,  0.2550,  1.5550],\n",
            "        [-0.8634,  0.8532, -0.4634]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9113,  0.8653,  0.8500],\n",
            "        [-1.6522,  1.9270, -0.2064],\n",
            "        [ 0.2280, -0.1352, -0.7509],\n",
            "        [-1.8885,  0.1862,  1.6399],\n",
            "        [-1.8280,  1.7995, -0.2533],\n",
            "        [-1.6264,  1.7702, -0.1850],\n",
            "        [-1.6838,  1.8982, -0.3620],\n",
            "        [ 0.5057, -0.0807, -0.9469],\n",
            "        [-1.6749,  0.2578,  1.3248],\n",
            "        [-1.6872,  2.0467, -0.4152],\n",
            "        [ 0.1351,  0.1251, -0.7983],\n",
            "        [-1.5435,  1.8246, -0.5342],\n",
            "        [-1.5603,  0.2137,  1.5283],\n",
            "        [-0.0807, -0.0175, -0.2453],\n",
            "        [-2.0480,  0.2550,  1.5550],\n",
            "        [-0.8634,  0.8532, -0.4634]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9986,  1.8901, -0.2439],\n",
            "        [ 0.4474,  0.0083, -0.9990],\n",
            "        [-1.7054,  1.9615, -0.0752],\n",
            "        [-1.5785,  1.7429, -0.3943],\n",
            "        [-1.7895,  0.5200,  1.1424],\n",
            "        [-1.8384,  0.5740,  1.1498],\n",
            "        [-1.9059,  0.3417,  1.5416],\n",
            "        [ 0.3843, -0.1603, -0.8261],\n",
            "        [-1.4177,  1.6929, -0.4598],\n",
            "        [-1.7478,  0.1479,  1.5194],\n",
            "        [-1.9804,  1.7378,  0.0889],\n",
            "        [-1.8510,  0.2773,  1.4960],\n",
            "        [-1.8036,  1.7226, -0.3566],\n",
            "        [-1.8003,  1.8233, -0.4454],\n",
            "        [-1.3177,  1.2995, -0.3749],\n",
            "        [-0.6449,  0.3396,  0.0827]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9986,  1.8901, -0.2439],\n",
            "        [ 0.4474,  0.0083, -0.9990],\n",
            "        [-1.7054,  1.9615, -0.0752],\n",
            "        [-1.5785,  1.7429, -0.3943],\n",
            "        [-1.7895,  0.5200,  1.1424],\n",
            "        [-1.8384,  0.5740,  1.1498],\n",
            "        [-1.9059,  0.3417,  1.5416],\n",
            "        [ 0.3843, -0.1603, -0.8261],\n",
            "        [-1.4177,  1.6929, -0.4598],\n",
            "        [-1.7478,  0.1479,  1.5194],\n",
            "        [-1.9804,  1.7378,  0.0889],\n",
            "        [-1.8510,  0.2773,  1.4960],\n",
            "        [-1.8036,  1.7226, -0.3566],\n",
            "        [-1.8003,  1.8233, -0.4454],\n",
            "        [-1.3177,  1.2995, -0.3749],\n",
            "        [-0.6449,  0.3396,  0.0827]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6908,  0.2476,  1.4550],\n",
            "        [ 0.3098,  0.0437, -0.7120],\n",
            "        [-1.7697,  2.1408, -0.4486],\n",
            "        [-1.5123,  1.6572, -0.2119],\n",
            "        [-1.7888,  0.2376,  1.4349],\n",
            "        [ 0.6351, -0.1173, -0.8078],\n",
            "        [-1.9401,  1.9095, -0.2201],\n",
            "        [ 0.6017, -0.0946, -0.9212],\n",
            "        [-1.5365,  1.7988, -0.3663],\n",
            "        [-1.7551,  1.6908, -0.1747],\n",
            "        [ 0.2796, -0.1451, -0.6615],\n",
            "        [ 0.5248, -0.2091, -0.9052],\n",
            "        [-1.6538,  1.8013, -0.2508],\n",
            "        [-1.2451,  1.4365, -0.4796],\n",
            "        [-1.8377,  0.2458,  1.3187],\n",
            "        [ 0.0188,  0.5292, -0.9993]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6908,  0.2476,  1.4550],\n",
            "        [ 0.3098,  0.0437, -0.7120],\n",
            "        [-1.7697,  2.1408, -0.4486],\n",
            "        [-1.5123,  1.6572, -0.2119],\n",
            "        [-1.7888,  0.2376,  1.4349],\n",
            "        [ 0.6351, -0.1173, -0.8078],\n",
            "        [-1.9401,  1.9095, -0.2201],\n",
            "        [ 0.6017, -0.0946, -0.9212],\n",
            "        [-1.5365,  1.7988, -0.3663],\n",
            "        [-1.7551,  1.6908, -0.1747],\n",
            "        [ 0.2796, -0.1451, -0.6615],\n",
            "        [ 0.5248, -0.2091, -0.9052],\n",
            "        [-1.6538,  1.8013, -0.2508],\n",
            "        [-1.2451,  1.4365, -0.4796],\n",
            "        [-1.8377,  0.2458,  1.3187],\n",
            "        [ 0.0188,  0.5292, -0.9993]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9176,  0.4157,  1.3244],\n",
            "        [-1.6961,  1.9250, -0.3460],\n",
            "        [-1.9261,  1.2330,  0.3473],\n",
            "        [ 0.6255, -0.0943, -0.8555],\n",
            "        [-1.8558,  0.1309,  1.3447],\n",
            "        [-1.7706,  0.2386,  1.4970],\n",
            "        [-1.9559,  0.4360,  1.4775],\n",
            "        [-1.6340,  0.2624,  1.1994],\n",
            "        [ 0.6791, -0.0944, -0.9856],\n",
            "        [-1.6055,  0.2586,  1.2666],\n",
            "        [-1.7663,  1.4022,  0.3640],\n",
            "        [-1.7906,  0.9032,  0.5223],\n",
            "        [-1.7950,  1.6553, -0.2443],\n",
            "        [-1.6749,  1.7167, -0.4042],\n",
            "        [-1.7289,  1.8866, -0.3532],\n",
            "        [-1.8979,  0.5415,  1.4347]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.9176,  0.4157,  1.3244],\n",
            "        [-1.6961,  1.9250, -0.3460],\n",
            "        [-1.9261,  1.2330,  0.3473],\n",
            "        [ 0.6255, -0.0943, -0.8555],\n",
            "        [-1.8558,  0.1309,  1.3447],\n",
            "        [-1.7706,  0.2386,  1.4970],\n",
            "        [-1.9559,  0.4360,  1.4775],\n",
            "        [-1.6340,  0.2624,  1.1994],\n",
            "        [ 0.6791, -0.0944, -0.9856],\n",
            "        [-1.6055,  0.2586,  1.2666],\n",
            "        [-1.7663,  1.4022,  0.3640],\n",
            "        [-1.7906,  0.9032,  0.5223],\n",
            "        [-1.7950,  1.6553, -0.2443],\n",
            "        [-1.6749,  1.7167, -0.4042],\n",
            "        [-1.7289,  1.8866, -0.3532],\n",
            "        [-1.8979,  0.5415,  1.4347]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-9.0192e-02, -1.8864e-01,  3.9097e-02],\n",
            "        [-1.8467e+00,  1.9717e+00, -3.6350e-01],\n",
            "        [ 4.9121e-01, -1.3774e-03, -8.9525e-01],\n",
            "        [-1.8257e+00,  3.7567e-01,  1.3213e+00],\n",
            "        [-2.0085e+00,  2.3903e-01,  1.5630e+00],\n",
            "        [ 4.5604e-01, -1.2460e-01, -9.1459e-01],\n",
            "        [-1.8392e+00,  1.0454e-01,  1.2805e+00],\n",
            "        [-1.8275e+00,  3.6443e-01,  1.5158e+00],\n",
            "        [-1.5396e+00,  1.6662e+00, -3.1371e-01],\n",
            "        [-1.6718e+00,  1.9670e+00, -2.2817e-01],\n",
            "        [-1.5411e+00,  1.6409e+00, -3.6564e-01],\n",
            "        [-2.0775e+00,  1.1086e+00,  7.6816e-01],\n",
            "        [-1.8350e+00,  3.6225e-01,  1.3617e+00],\n",
            "        [-1.7721e+00,  7.2044e-01,  1.2944e+00],\n",
            "        [-1.6895e+00,  1.8508e+00, -4.4230e-01],\n",
            "        [-1.6656e+00,  1.8983e+00, -5.1346e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-9.0192e-02, -1.8864e-01,  3.9097e-02],\n",
            "        [-1.8467e+00,  1.9717e+00, -3.6350e-01],\n",
            "        [ 4.9121e-01, -1.3774e-03, -8.9525e-01],\n",
            "        [-1.8257e+00,  3.7567e-01,  1.3213e+00],\n",
            "        [-2.0085e+00,  2.3903e-01,  1.5630e+00],\n",
            "        [ 4.5604e-01, -1.2460e-01, -9.1459e-01],\n",
            "        [-1.8392e+00,  1.0454e-01,  1.2805e+00],\n",
            "        [-1.8275e+00,  3.6443e-01,  1.5158e+00],\n",
            "        [-1.5396e+00,  1.6662e+00, -3.1371e-01],\n",
            "        [-1.6718e+00,  1.9670e+00, -2.2817e-01],\n",
            "        [-1.5411e+00,  1.6409e+00, -3.6564e-01],\n",
            "        [-2.0775e+00,  1.1086e+00,  7.6816e-01],\n",
            "        [-1.8350e+00,  3.6225e-01,  1.3617e+00],\n",
            "        [-1.7721e+00,  7.2044e-01,  1.2944e+00],\n",
            "        [-1.6895e+00,  1.8508e+00, -4.4230e-01],\n",
            "        [-1.6656e+00,  1.8983e+00, -5.1346e-01]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6553,  1.8761, -0.4093],\n",
            "        [-1.5961,  1.9471, -0.4401],\n",
            "        [-1.9486,  0.4220,  1.3454],\n",
            "        [-1.7603,  1.9892, -0.5095],\n",
            "        [-1.5238,  1.8894, -0.4471],\n",
            "        [-1.8555,  0.9604,  0.4033],\n",
            "        [-1.5553,  1.7212, -0.4351],\n",
            "        [-1.6172,  1.8027, -0.5336],\n",
            "        [-1.6166,  0.3960,  1.4168],\n",
            "        [-1.5616,  1.8339, -0.4058],\n",
            "        [ 0.3414, -0.0161, -1.0107],\n",
            "        [-1.6652,  1.8368, -0.6011],\n",
            "        [-1.5833,  1.7595, -0.3358],\n",
            "        [-1.4749,  1.6805, -0.2851],\n",
            "        [-1.9707,  1.6377, -0.1873],\n",
            "        [-1.5992,  1.8843, -0.3625]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6553,  1.8761, -0.4093],\n",
            "        [-1.5961,  1.9471, -0.4401],\n",
            "        [-1.9486,  0.4220,  1.3454],\n",
            "        [-1.7603,  1.9892, -0.5095],\n",
            "        [-1.5238,  1.8894, -0.4471],\n",
            "        [-1.8555,  0.9604,  0.4033],\n",
            "        [-1.5553,  1.7212, -0.4351],\n",
            "        [-1.6172,  1.8027, -0.5336],\n",
            "        [-1.6166,  0.3960,  1.4168],\n",
            "        [-1.5616,  1.8339, -0.4058],\n",
            "        [ 0.3414, -0.0161, -1.0107],\n",
            "        [-1.6652,  1.8368, -0.6011],\n",
            "        [-1.5833,  1.7595, -0.3358],\n",
            "        [-1.4749,  1.6805, -0.2851],\n",
            "        [-1.9707,  1.6377, -0.1873],\n",
            "        [-1.5992,  1.8843, -0.3625]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7829,  0.3453,  1.3632],\n",
            "        [-1.6124,  1.7628, -0.3869],\n",
            "        [-1.7431,  1.9179, -0.3997],\n",
            "        [-1.3706,  2.0909, -0.4809],\n",
            "        [-1.7700,  0.6874,  1.2249],\n",
            "        [-1.5808,  2.0584, -0.7261],\n",
            "        [-1.5576,  2.0662, -0.4316],\n",
            "        [-1.9599,  0.5795,  1.2953],\n",
            "        [ 0.5884, -0.1724, -0.9025],\n",
            "        [-1.9261,  0.3291,  1.4519],\n",
            "        [ 0.6929, -0.1672, -0.9888],\n",
            "        [ 0.4310, -0.0362, -1.0855],\n",
            "        [-1.5043,  1.8061, -0.5258],\n",
            "        [-2.0878,  0.4580,  1.3084],\n",
            "        [ 0.6782, -0.0523, -1.1670],\n",
            "        [-1.9611,  0.8349,  1.0047]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7829,  0.3453,  1.3632],\n",
            "        [-1.6124,  1.7628, -0.3869],\n",
            "        [-1.7431,  1.9179, -0.3997],\n",
            "        [-1.3706,  2.0909, -0.4809],\n",
            "        [-1.7700,  0.6874,  1.2249],\n",
            "        [-1.5808,  2.0584, -0.7261],\n",
            "        [-1.5576,  2.0662, -0.4316],\n",
            "        [-1.9599,  0.5795,  1.2953],\n",
            "        [ 0.5884, -0.1724, -0.9025],\n",
            "        [-1.9261,  0.3291,  1.4519],\n",
            "        [ 0.6929, -0.1672, -0.9888],\n",
            "        [ 0.4310, -0.0362, -1.0855],\n",
            "        [-1.5043,  1.8061, -0.5258],\n",
            "        [-2.0878,  0.4580,  1.3084],\n",
            "        [ 0.6782, -0.0523, -1.1670],\n",
            "        [-1.9611,  0.8349,  1.0047]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4828,  1.7958, -0.4858],\n",
            "        [-1.9804,  0.7324,  1.1154],\n",
            "        [-0.1015,  0.4377, -1.0351],\n",
            "        [-1.9543,  0.2148,  1.3795],\n",
            "        [ 0.1906,  0.1145, -0.7890],\n",
            "        [-1.7350,  0.2511,  1.2975],\n",
            "        [-1.6873,  0.2630,  1.2614],\n",
            "        [-1.6125,  0.5315,  1.3713],\n",
            "        [-1.6962,  0.1307,  1.4448],\n",
            "        [-1.8933,  0.6149,  1.0297],\n",
            "        [-1.8371,  1.8588, -0.4204],\n",
            "        [-1.9266,  0.6818,  1.1070],\n",
            "        [-1.6976,  1.8800, -0.5658],\n",
            "        [-1.5370,  1.6804, -0.3072],\n",
            "        [-1.7356,  1.7382, -0.4146],\n",
            "        [-1.4735,  2.1960, -0.4363]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4828,  1.7958, -0.4858],\n",
            "        [-1.9804,  0.7324,  1.1154],\n",
            "        [-0.1015,  0.4377, -1.0351],\n",
            "        [-1.9543,  0.2148,  1.3795],\n",
            "        [ 0.1906,  0.1145, -0.7890],\n",
            "        [-1.7350,  0.2511,  1.2975],\n",
            "        [-1.6873,  0.2630,  1.2614],\n",
            "        [-1.6125,  0.5315,  1.3713],\n",
            "        [-1.6962,  0.1307,  1.4448],\n",
            "        [-1.8933,  0.6149,  1.0297],\n",
            "        [-1.8371,  1.8588, -0.4204],\n",
            "        [-1.9266,  0.6818,  1.1070],\n",
            "        [-1.6976,  1.8800, -0.5658],\n",
            "        [-1.5370,  1.6804, -0.3072],\n",
            "        [-1.7356,  1.7382, -0.4146],\n",
            "        [-1.4735,  2.1960, -0.4363]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4781,  1.5416, -0.5765],\n",
            "        [-2.0512,  0.3748,  1.3397],\n",
            "        [-1.5235,  1.7714, -0.7433],\n",
            "        [-1.3267,  1.6331, -0.5894],\n",
            "        [-1.5142,  1.8837, -0.6773],\n",
            "        [-1.7607,  0.4831,  1.4365],\n",
            "        [-1.6342,  1.9061, -0.4290],\n",
            "        [-1.6445,  1.8376, -0.5774],\n",
            "        [-2.0364,  1.0147,  0.8008],\n",
            "        [-1.1159,  1.5718, -0.6881],\n",
            "        [-1.6908,  1.9197, -0.4856],\n",
            "        [ 0.5012,  0.1002, -1.1451],\n",
            "        [-1.1392,  1.7726, -0.7823],\n",
            "        [-1.5046,  1.8416, -0.5531],\n",
            "        [ 0.6975, -0.0660, -1.0283],\n",
            "        [ 0.5413, -0.0532, -1.0712]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4781,  1.5416, -0.5765],\n",
            "        [-2.0512,  0.3748,  1.3397],\n",
            "        [-1.5235,  1.7714, -0.7433],\n",
            "        [-1.3267,  1.6331, -0.5894],\n",
            "        [-1.5142,  1.8837, -0.6773],\n",
            "        [-1.7607,  0.4831,  1.4365],\n",
            "        [-1.6342,  1.9061, -0.4290],\n",
            "        [-1.6445,  1.8376, -0.5774],\n",
            "        [-2.0364,  1.0147,  0.8008],\n",
            "        [-1.1159,  1.5718, -0.6881],\n",
            "        [-1.6908,  1.9197, -0.4856],\n",
            "        [ 0.5012,  0.1002, -1.1451],\n",
            "        [-1.1392,  1.7726, -0.7823],\n",
            "        [-1.5046,  1.8416, -0.5531],\n",
            "        [ 0.6975, -0.0660, -1.0283],\n",
            "        [ 0.5413, -0.0532, -1.0712]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6964,  2.1559, -0.5362],\n",
            "        [-2.0269,  0.2502,  1.4536],\n",
            "        [-1.7119,  0.2654,  1.3533],\n",
            "        [-1.8283,  1.9092, -0.3885],\n",
            "        [-1.7925,  1.7350, -0.1231],\n",
            "        [-1.6540,  0.5832,  1.2898],\n",
            "        [-1.9305,  0.4167,  1.2988],\n",
            "        [-1.8283,  1.2928,  0.1757],\n",
            "        [-1.5962,  1.7162, -0.4312],\n",
            "        [ 0.1404,  0.2479, -0.9114],\n",
            "        [-1.5803,  1.7965, -0.5828],\n",
            "        [-1.1443,  0.0174,  1.0156],\n",
            "        [-2.0185,  0.4732,  1.4286],\n",
            "        [-1.0335, -0.0742,  0.9296],\n",
            "        [-1.7262,  1.9899, -0.6430],\n",
            "        [-1.6649,  1.9758, -0.3696]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6964,  2.1559, -0.5362],\n",
            "        [-2.0269,  0.2502,  1.4536],\n",
            "        [-1.7119,  0.2654,  1.3533],\n",
            "        [-1.8283,  1.9092, -0.3885],\n",
            "        [-1.7925,  1.7350, -0.1231],\n",
            "        [-1.6540,  0.5832,  1.2898],\n",
            "        [-1.9305,  0.4167,  1.2988],\n",
            "        [-1.8283,  1.2928,  0.1757],\n",
            "        [-1.5962,  1.7162, -0.4312],\n",
            "        [ 0.1404,  0.2479, -0.9114],\n",
            "        [-1.5803,  1.7965, -0.5828],\n",
            "        [-1.1443,  0.0174,  1.0156],\n",
            "        [-2.0185,  0.4732,  1.4286],\n",
            "        [-1.0335, -0.0742,  0.9296],\n",
            "        [-1.7262,  1.9899, -0.6430],\n",
            "        [-1.6649,  1.9758, -0.3696]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.1243,  0.2845, -0.9506],\n",
            "        [ 0.1603,  0.3390, -0.9878],\n",
            "        [-1.4425,  1.9317, -0.7428],\n",
            "        [ 0.6675, -0.1631, -1.0427],\n",
            "        [-1.5933,  1.8357, -0.3120],\n",
            "        [-1.9145,  0.2218,  1.6238],\n",
            "        [-2.0420,  0.1885,  1.3824],\n",
            "        [ 0.7380, -0.0959, -1.0379],\n",
            "        [-1.5096,  1.9890, -0.4044],\n",
            "        [-2.0117,  1.3146,  0.3765],\n",
            "        [-1.5487,  2.1263, -0.4547],\n",
            "        [-1.5890,  1.7981, -0.6710],\n",
            "        [-1.6280,  1.8128, -0.4526],\n",
            "        [-1.3729,  1.6309, -0.5848],\n",
            "        [-1.4001,  1.9410, -0.6137],\n",
            "        [-1.6151,  1.9406, -0.5164]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.1243,  0.2845, -0.9506],\n",
            "        [ 0.1603,  0.3390, -0.9878],\n",
            "        [-1.4425,  1.9317, -0.7428],\n",
            "        [ 0.6675, -0.1631, -1.0427],\n",
            "        [-1.5933,  1.8357, -0.3120],\n",
            "        [-1.9145,  0.2218,  1.6238],\n",
            "        [-2.0420,  0.1885,  1.3824],\n",
            "        [ 0.7380, -0.0959, -1.0379],\n",
            "        [-1.5096,  1.9890, -0.4044],\n",
            "        [-2.0117,  1.3146,  0.3765],\n",
            "        [-1.5487,  2.1263, -0.4547],\n",
            "        [-1.5890,  1.7981, -0.6710],\n",
            "        [-1.6280,  1.8128, -0.4526],\n",
            "        [-1.3729,  1.6309, -0.5848],\n",
            "        [-1.4001,  1.9410, -0.6137],\n",
            "        [-1.6151,  1.9406, -0.5164]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4871,  1.8067, -0.4771],\n",
            "        [ 0.6400, -0.0952, -0.9927],\n",
            "        [-1.1784,  1.6652, -0.5936],\n",
            "        [-1.7198,  1.8186, -0.5578],\n",
            "        [-1.9666,  0.9179,  0.5163],\n",
            "        [-1.6522,  2.2597, -0.4910],\n",
            "        [-1.5979,  2.0284, -0.6220],\n",
            "        [-1.7944,  0.2423,  1.2788],\n",
            "        [-1.5534,  1.9507, -0.5762],\n",
            "        [-1.5656,  1.7974, -0.5083],\n",
            "        [-1.5436,  1.9331, -0.5331],\n",
            "        [-1.4636,  1.5160, -0.3918],\n",
            "        [-1.7627,  0.4554,  1.0055],\n",
            "        [ 0.2888,  0.2379, -1.2570],\n",
            "        [-1.5113,  1.9860, -0.7450],\n",
            "        [ 0.0042,  0.4544, -0.8858]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4871,  1.8067, -0.4771],\n",
            "        [ 0.6400, -0.0952, -0.9927],\n",
            "        [-1.1784,  1.6652, -0.5936],\n",
            "        [-1.7198,  1.8186, -0.5578],\n",
            "        [-1.9666,  0.9179,  0.5163],\n",
            "        [-1.6522,  2.2597, -0.4910],\n",
            "        [-1.5979,  2.0284, -0.6220],\n",
            "        [-1.7944,  0.2423,  1.2788],\n",
            "        [-1.5534,  1.9507, -0.5762],\n",
            "        [-1.5656,  1.7974, -0.5083],\n",
            "        [-1.5436,  1.9331, -0.5331],\n",
            "        [-1.4636,  1.5160, -0.3918],\n",
            "        [-1.7627,  0.4554,  1.0055],\n",
            "        [ 0.2888,  0.2379, -1.2570],\n",
            "        [-1.5113,  1.9860, -0.7450],\n",
            "        [ 0.0042,  0.4544, -0.8858]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4602,  2.0343, -0.5661],\n",
            "        [-1.5394,  1.9852, -0.4787],\n",
            "        [-1.7189,  1.8133, -0.6063],\n",
            "        [-1.6122,  1.9488, -0.5634],\n",
            "        [-1.8595,  0.4398,  1.1182],\n",
            "        [-1.6601,  1.9522, -0.4564],\n",
            "        [ 0.7043, -0.1336, -1.0651],\n",
            "        [-1.4555,  1.7703, -0.9262],\n",
            "        [-1.5211,  2.0829, -0.4495],\n",
            "        [-1.4670,  1.7205, -0.6459],\n",
            "        [-1.9944,  0.1889,  1.5283],\n",
            "        [-1.6616,  1.9839, -0.3790],\n",
            "        [-1.0410,  1.3509, -0.8393],\n",
            "        [-1.3425,  1.8525, -0.6707],\n",
            "        [-1.9598,  0.3372,  1.4370],\n",
            "        [-1.5520,  1.9015, -0.6225]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4602,  2.0343, -0.5661],\n",
            "        [-1.5394,  1.9852, -0.4787],\n",
            "        [-1.7189,  1.8133, -0.6063],\n",
            "        [-1.6122,  1.9488, -0.5634],\n",
            "        [-1.8595,  0.4398,  1.1182],\n",
            "        [-1.6601,  1.9522, -0.4564],\n",
            "        [ 0.7043, -0.1336, -1.0651],\n",
            "        [-1.4555,  1.7703, -0.9262],\n",
            "        [-1.5211,  2.0829, -0.4495],\n",
            "        [-1.4670,  1.7205, -0.6459],\n",
            "        [-1.9944,  0.1889,  1.5283],\n",
            "        [-1.6616,  1.9839, -0.3790],\n",
            "        [-1.0410,  1.3509, -0.8393],\n",
            "        [-1.3425,  1.8525, -0.6707],\n",
            "        [-1.9598,  0.3372,  1.4370],\n",
            "        [-1.5520,  1.9015, -0.6225]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5316,  1.9995, -0.5348],\n",
            "        [-1.8606,  0.4009,  1.2354],\n",
            "        [-1.3704,  1.9425, -0.4774],\n",
            "        [-1.7963,  0.1884,  1.4166],\n",
            "        [-1.4975,  1.9718, -0.5033],\n",
            "        [-1.3554,  1.8975, -0.6647],\n",
            "        [-0.5774,  0.0285,  0.2801],\n",
            "        [-1.5251,  2.0347, -0.5148],\n",
            "        [-1.8619,  0.7364,  1.2584],\n",
            "        [-1.3689,  1.7333, -0.8782],\n",
            "        [-1.6154,  1.7507, -0.5872],\n",
            "        [-1.4411,  1.9082, -0.5157],\n",
            "        [-1.6538,  1.9698, -0.3498],\n",
            "        [-1.6071,  1.7585, -0.3484],\n",
            "        [-1.3669,  1.8464, -0.5818],\n",
            "        [-1.6725,  1.7900, -0.6453]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5316,  1.9995, -0.5348],\n",
            "        [-1.8606,  0.4009,  1.2354],\n",
            "        [-1.3704,  1.9425, -0.4774],\n",
            "        [-1.7963,  0.1884,  1.4166],\n",
            "        [-1.4975,  1.9718, -0.5033],\n",
            "        [-1.3554,  1.8975, -0.6647],\n",
            "        [-0.5774,  0.0285,  0.2801],\n",
            "        [-1.5251,  2.0347, -0.5148],\n",
            "        [-1.8619,  0.7364,  1.2584],\n",
            "        [-1.3689,  1.7333, -0.8782],\n",
            "        [-1.6154,  1.7507, -0.5872],\n",
            "        [-1.4411,  1.9082, -0.5157],\n",
            "        [-1.6538,  1.9698, -0.3498],\n",
            "        [-1.6071,  1.7585, -0.3484],\n",
            "        [-1.3669,  1.8464, -0.5818],\n",
            "        [-1.6725,  1.7900, -0.6453]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5504,  1.9559, -0.6604],\n",
            "        [-1.2806,  1.8095, -0.7027],\n",
            "        [-1.7515,  0.2140,  1.5019],\n",
            "        [-1.8201,  0.1742,  1.2969],\n",
            "        [-2.2380,  0.3346,  1.6523],\n",
            "        [-1.3969,  1.6827, -0.5620],\n",
            "        [-2.0351,  0.6621,  1.2414],\n",
            "        [-1.4968,  1.7139, -0.6330],\n",
            "        [-1.2904,  1.7889, -0.7413],\n",
            "        [-1.6709,  0.3247,  1.1757],\n",
            "        [-1.2996,  1.7338, -0.6664],\n",
            "        [-1.5700,  1.8662, -0.5001],\n",
            "        [-1.2744,  1.6015, -0.5503],\n",
            "        [-1.5073,  1.9557, -0.5257],\n",
            "        [-1.4321,  1.8895, -0.5517],\n",
            "        [-1.5701,  1.9670, -0.4707]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5504,  1.9559, -0.6604],\n",
            "        [-1.2806,  1.8095, -0.7027],\n",
            "        [-1.7515,  0.2140,  1.5019],\n",
            "        [-1.8201,  0.1742,  1.2969],\n",
            "        [-2.2380,  0.3346,  1.6523],\n",
            "        [-1.3969,  1.6827, -0.5620],\n",
            "        [-2.0351,  0.6621,  1.2414],\n",
            "        [-1.4968,  1.7139, -0.6330],\n",
            "        [-1.2904,  1.7889, -0.7413],\n",
            "        [-1.6709,  0.3247,  1.1757],\n",
            "        [-1.2996,  1.7338, -0.6664],\n",
            "        [-1.5700,  1.8662, -0.5001],\n",
            "        [-1.2744,  1.6015, -0.5503],\n",
            "        [-1.5073,  1.9557, -0.5257],\n",
            "        [-1.4321,  1.8895, -0.5517],\n",
            "        [-1.5701,  1.9670, -0.4707]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1107,  0.7541,  0.9032],\n",
            "        [-1.5725,  1.7693, -0.3009],\n",
            "        [-1.2456,  1.7466, -0.2587],\n",
            "        [-1.3986,  1.8542, -0.6781],\n",
            "        [ 0.5896, -0.2421, -1.0433],\n",
            "        [-1.9607,  0.6040,  1.1283],\n",
            "        [-1.3977,  1.8123, -0.3277],\n",
            "        [-1.4611,  1.9896, -0.4640],\n",
            "        [-1.5515,  1.8097, -0.5666],\n",
            "        [-0.9426,  1.2910, -0.7472],\n",
            "        [-1.5396,  2.2202, -0.6763],\n",
            "        [-1.6943,  0.2186,  1.3435],\n",
            "        [-1.6034,  1.8496, -0.5071],\n",
            "        [-1.4922,  1.7107, -0.4702],\n",
            "        [-0.9955,  1.3244, -0.6015],\n",
            "        [ 0.5762, -0.0064, -0.9862]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-2.1107,  0.7541,  0.9032],\n",
            "        [-1.5725,  1.7693, -0.3009],\n",
            "        [-1.2456,  1.7466, -0.2587],\n",
            "        [-1.3986,  1.8542, -0.6781],\n",
            "        [ 0.5896, -0.2421, -1.0433],\n",
            "        [-1.9607,  0.6040,  1.1283],\n",
            "        [-1.3977,  1.8123, -0.3277],\n",
            "        [-1.4611,  1.9896, -0.4640],\n",
            "        [-1.5515,  1.8097, -0.5666],\n",
            "        [-0.9426,  1.2910, -0.7472],\n",
            "        [-1.5396,  2.2202, -0.6763],\n",
            "        [-1.6943,  0.2186,  1.3435],\n",
            "        [-1.6034,  1.8496, -0.5071],\n",
            "        [-1.4922,  1.7107, -0.4702],\n",
            "        [-0.9955,  1.3244, -0.6015],\n",
            "        [ 0.5762, -0.0064, -0.9862]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4277,  1.6955, -0.5228],\n",
            "        [-1.5331,  1.8843, -0.3861],\n",
            "        [-1.9618,  0.5620,  1.2497],\n",
            "        [ 0.7276, -0.2360, -0.9927],\n",
            "        [-1.4198,  1.5218, -0.7435],\n",
            "        [-1.8211,  0.6153,  1.1392],\n",
            "        [-1.5430,  1.5612, -0.5177],\n",
            "        [-1.6793,  0.3901,  1.3988],\n",
            "        [ 0.5870, -0.2320, -1.1228],\n",
            "        [-1.2182,  1.5348, -0.3866],\n",
            "        [ 0.7051, -0.1133, -0.7675],\n",
            "        [-1.2342,  1.4084, -0.5264],\n",
            "        [-1.5681,  1.9724, -0.3387],\n",
            "        [-1.9018,  1.1384,  0.6627],\n",
            "        [-1.5666,  1.5453, -0.2164],\n",
            "        [-1.1865,  1.6887, -0.7650]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4277,  1.6955, -0.5228],\n",
            "        [-1.5331,  1.8843, -0.3861],\n",
            "        [-1.9618,  0.5620,  1.2497],\n",
            "        [ 0.7276, -0.2360, -0.9927],\n",
            "        [-1.4198,  1.5218, -0.7435],\n",
            "        [-1.8211,  0.6153,  1.1392],\n",
            "        [-1.5430,  1.5612, -0.5177],\n",
            "        [-1.6793,  0.3901,  1.3988],\n",
            "        [ 0.5870, -0.2320, -1.1228],\n",
            "        [-1.2182,  1.5348, -0.3866],\n",
            "        [ 0.7051, -0.1133, -0.7675],\n",
            "        [-1.2342,  1.4084, -0.5264],\n",
            "        [-1.5681,  1.9724, -0.3387],\n",
            "        [-1.9018,  1.1384,  0.6627],\n",
            "        [-1.5666,  1.5453, -0.2164],\n",
            "        [-1.1865,  1.6887, -0.7650]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.6836, -0.0335, -0.9997],\n",
            "        [-0.5459,  0.0864,  0.5291],\n",
            "        [-2.0522,  0.1867,  1.4373],\n",
            "        [-1.7678,  1.5657, -0.2154],\n",
            "        [-1.6855,  1.7425, -0.1267],\n",
            "        [-1.5123,  0.5061,  0.9716],\n",
            "        [-1.5642,  0.8790,  0.7507],\n",
            "        [-1.6581,  1.6855, -0.3167],\n",
            "        [-1.2908,  1.5837, -0.4276],\n",
            "        [-1.5972,  1.7026, -0.3393],\n",
            "        [ 0.6264, -0.0840, -0.8906],\n",
            "        [-2.0370,  0.2391,  1.6274],\n",
            "        [-1.1253,  1.6467, -0.6276],\n",
            "        [-1.5205,  1.9339, -0.7797],\n",
            "        [-1.6727,  1.7969, -0.4651],\n",
            "        [-1.3978,  1.5596, -0.3458]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.6836, -0.0335, -0.9997],\n",
            "        [-0.5459,  0.0864,  0.5291],\n",
            "        [-2.0522,  0.1867,  1.4373],\n",
            "        [-1.7678,  1.5657, -0.2154],\n",
            "        [-1.6855,  1.7425, -0.1267],\n",
            "        [-1.5123,  0.5061,  0.9716],\n",
            "        [-1.5642,  0.8790,  0.7507],\n",
            "        [-1.6581,  1.6855, -0.3167],\n",
            "        [-1.2908,  1.5837, -0.4276],\n",
            "        [-1.5972,  1.7026, -0.3393],\n",
            "        [ 0.6264, -0.0840, -0.8906],\n",
            "        [-2.0370,  0.2391,  1.6274],\n",
            "        [-1.1253,  1.6467, -0.6276],\n",
            "        [-1.5205,  1.9339, -0.7797],\n",
            "        [-1.6727,  1.7969, -0.4651],\n",
            "        [-1.3978,  1.5596, -0.3458]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8460,  0.2698,  1.4141],\n",
            "        [-1.3409,  1.6266, -0.6336],\n",
            "        [-1.7197,  1.2110,  0.3036],\n",
            "        [ 0.5367, -0.1700, -0.6313],\n",
            "        [-1.9630,  0.2902,  1.5499],\n",
            "        [-1.4621,  1.5395, -0.5295],\n",
            "        [-1.5067,  1.7500, -0.3390],\n",
            "        [-1.5406,  1.5841, -0.2806],\n",
            "        [-1.2605,  1.6773, -0.5092],\n",
            "        [-1.3035,  1.6245, -0.5641],\n",
            "        [-1.5280,  1.6336, -0.4062],\n",
            "        [-1.5767,  1.5025, -0.3611],\n",
            "        [-2.0935,  0.5304,  1.0619],\n",
            "        [-1.2439,  1.6771, -0.6385],\n",
            "        [-1.4383,  1.7111, -0.4163],\n",
            "        [-1.5622,  0.9784,  0.4099]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.8460,  0.2698,  1.4141],\n",
            "        [-1.3409,  1.6266, -0.6336],\n",
            "        [-1.7197,  1.2110,  0.3036],\n",
            "        [ 0.5367, -0.1700, -0.6313],\n",
            "        [-1.9630,  0.2902,  1.5499],\n",
            "        [-1.4621,  1.5395, -0.5295],\n",
            "        [-1.5067,  1.7500, -0.3390],\n",
            "        [-1.5406,  1.5841, -0.2806],\n",
            "        [-1.2605,  1.6773, -0.5092],\n",
            "        [-1.3035,  1.6245, -0.5641],\n",
            "        [-1.5280,  1.6336, -0.4062],\n",
            "        [-1.5767,  1.5025, -0.3611],\n",
            "        [-2.0935,  0.5304,  1.0619],\n",
            "        [-1.2439,  1.6771, -0.6385],\n",
            "        [-1.4383,  1.7111, -0.4163],\n",
            "        [-1.5622,  0.9784,  0.4099]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7938,  0.5203,  1.0582],\n",
            "        [-1.4707,  1.5231, -0.3321],\n",
            "        [-1.3508,  1.7176, -0.4472],\n",
            "        [ 0.6184, -0.1347, -0.9303],\n",
            "        [-1.5010,  1.4899, -0.3346],\n",
            "        [-1.7599, -0.0168,  1.5377],\n",
            "        [-1.9505,  0.0324,  1.5617],\n",
            "        [-1.3421,  1.5764, -0.4654],\n",
            "        [-1.5057,  1.6440, -0.6031],\n",
            "        [-1.5520,  1.6862, -0.3517],\n",
            "        [-1.4091,  1.7201, -0.3736],\n",
            "        [-1.8819,  0.1395,  1.5575],\n",
            "        [-1.8992,  0.8251,  0.6545],\n",
            "        [-0.8972,  1.2695, -0.4538],\n",
            "        [-1.2789,  1.3435, -0.3662],\n",
            "        [-1.5769,  1.6996, -0.3163]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7938,  0.5203,  1.0582],\n",
            "        [-1.4707,  1.5231, -0.3321],\n",
            "        [-1.3508,  1.7176, -0.4472],\n",
            "        [ 0.6184, -0.1347, -0.9303],\n",
            "        [-1.5010,  1.4899, -0.3346],\n",
            "        [-1.7599, -0.0168,  1.5377],\n",
            "        [-1.9505,  0.0324,  1.5617],\n",
            "        [-1.3421,  1.5764, -0.4654],\n",
            "        [-1.5057,  1.6440, -0.6031],\n",
            "        [-1.5520,  1.6862, -0.3517],\n",
            "        [-1.4091,  1.7201, -0.3736],\n",
            "        [-1.8819,  0.1395,  1.5575],\n",
            "        [-1.8992,  0.8251,  0.6545],\n",
            "        [-0.8972,  1.2695, -0.4538],\n",
            "        [-1.2789,  1.3435, -0.3662],\n",
            "        [-1.5769,  1.6996, -0.3163]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4631,  0.3698,  0.7497],\n",
            "        [-1.2596,  0.8889, -0.2507],\n",
            "        [-1.6230,  1.7153, -0.4997],\n",
            "        [-1.2876,  1.6176, -0.3535],\n",
            "        [-1.7417,  0.3541,  1.1434],\n",
            "        [-1.5828,  1.7548, -0.4249],\n",
            "        [-1.3276,  1.3376, -0.6841],\n",
            "        [-1.4152,  1.4735, -0.3687],\n",
            "        [-1.7391,  0.0995,  1.5912],\n",
            "        [ 0.3726, -0.0978, -0.7852],\n",
            "        [-1.6536,  0.0602,  1.5493],\n",
            "        [-1.9765,  0.0790,  1.5668],\n",
            "        [-1.6214,  1.6637, -0.2430],\n",
            "        [-1.5382,  1.2180, -0.2516],\n",
            "        [-1.4350,  1.0619,  0.0723],\n",
            "        [-1.5040,  1.6532, -0.4395]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4631,  0.3698,  0.7497],\n",
            "        [-1.2596,  0.8889, -0.2507],\n",
            "        [-1.6230,  1.7153, -0.4997],\n",
            "        [-1.2876,  1.6176, -0.3535],\n",
            "        [-1.7417,  0.3541,  1.1434],\n",
            "        [-1.5828,  1.7548, -0.4249],\n",
            "        [-1.3276,  1.3376, -0.6841],\n",
            "        [-1.4152,  1.4735, -0.3687],\n",
            "        [-1.7391,  0.0995,  1.5912],\n",
            "        [ 0.3726, -0.0978, -0.7852],\n",
            "        [-1.6536,  0.0602,  1.5493],\n",
            "        [-1.9765,  0.0790,  1.5668],\n",
            "        [-1.6214,  1.6637, -0.2430],\n",
            "        [-1.5382,  1.2180, -0.2516],\n",
            "        [-1.4350,  1.0619,  0.0723],\n",
            "        [-1.5040,  1.6532, -0.4395]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.2027,  0.0922, -1.0046],\n",
            "        [-1.3861,  1.7909, -0.4858],\n",
            "        [-1.3352,  1.7089, -0.2611],\n",
            "        [-1.4123,  1.5336, -0.4730],\n",
            "        [-1.0647,  1.4455, -0.5111],\n",
            "        [-1.3803,  1.6191, -0.1057],\n",
            "        [-1.7958,  0.4110,  1.2085],\n",
            "        [-1.7018,  1.7287, -0.3204],\n",
            "        [-1.3208,  1.3386, -0.6313],\n",
            "        [-1.8668,  1.0357,  0.6939],\n",
            "        [-1.5077,  1.5127, -0.5303],\n",
            "        [-1.4895,  1.9115, -0.3114],\n",
            "        [-1.3675,  1.7271, -0.4222],\n",
            "        [-1.4343,  1.5498, -0.4200],\n",
            "        [-1.4427,  1.6278, -0.3950],\n",
            "        [-1.5802,  1.4427, -0.3539]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.2027,  0.0922, -1.0046],\n",
            "        [-1.3861,  1.7909, -0.4858],\n",
            "        [-1.3352,  1.7089, -0.2611],\n",
            "        [-1.4123,  1.5336, -0.4730],\n",
            "        [-1.0647,  1.4455, -0.5111],\n",
            "        [-1.3803,  1.6191, -0.1057],\n",
            "        [-1.7958,  0.4110,  1.2085],\n",
            "        [-1.7018,  1.7287, -0.3204],\n",
            "        [-1.3208,  1.3386, -0.6313],\n",
            "        [-1.8668,  1.0357,  0.6939],\n",
            "        [-1.5077,  1.5127, -0.5303],\n",
            "        [-1.4895,  1.9115, -0.3114],\n",
            "        [-1.3675,  1.7271, -0.4222],\n",
            "        [-1.4343,  1.5498, -0.4200],\n",
            "        [-1.4427,  1.6278, -0.3950],\n",
            "        [-1.5802,  1.4427, -0.3539]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5011,  1.7644, -0.4681],\n",
            "        [-1.4366,  1.6425, -0.4171],\n",
            "        [-1.6107,  1.5914, -0.2049],\n",
            "        [-1.3660,  1.5885, -0.3565],\n",
            "        [-1.2221,  1.3517, -0.4149],\n",
            "        [ 0.6198, -0.1453, -1.0200],\n",
            "        [-1.7958,  0.1628,  1.5523],\n",
            "        [-1.0352,  1.2981, -0.5388],\n",
            "        [ 0.5695, -0.2342, -0.9824],\n",
            "        [-1.3867,  1.7647, -0.4827],\n",
            "        [-1.3859,  1.5541, -0.4123],\n",
            "        [-1.4833,  1.7728, -0.4953],\n",
            "        [-1.7991,  1.5650, -0.3153],\n",
            "        [-1.7404,  0.1453,  1.4043],\n",
            "        [-1.6624,  1.3810, -0.3594],\n",
            "        [-1.9378,  0.1614,  1.4533]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5011,  1.7644, -0.4681],\n",
            "        [-1.4366,  1.6425, -0.4171],\n",
            "        [-1.6107,  1.5914, -0.2049],\n",
            "        [-1.3660,  1.5885, -0.3565],\n",
            "        [-1.2221,  1.3517, -0.4149],\n",
            "        [ 0.6198, -0.1453, -1.0200],\n",
            "        [-1.7958,  0.1628,  1.5523],\n",
            "        [-1.0352,  1.2981, -0.5388],\n",
            "        [ 0.5695, -0.2342, -0.9824],\n",
            "        [-1.3867,  1.7647, -0.4827],\n",
            "        [-1.3859,  1.5541, -0.4123],\n",
            "        [-1.4833,  1.7728, -0.4953],\n",
            "        [-1.7991,  1.5650, -0.3153],\n",
            "        [-1.7404,  0.1453,  1.4043],\n",
            "        [-1.6624,  1.3810, -0.3594],\n",
            "        [-1.9378,  0.1614,  1.4533]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.0266,  1.2278, -0.5685],\n",
            "        [-1.2289,  1.2303, -0.2410],\n",
            "        [-1.9696,  0.7536,  0.5961],\n",
            "        [-1.7633,  0.0288,  1.3696],\n",
            "        [-1.6604,  1.4936,  0.1741],\n",
            "        [ 0.5983, -0.0927, -0.8577],\n",
            "        [ 0.6687, -0.3180, -1.0288],\n",
            "        [-1.6461,  1.5647, -0.3293],\n",
            "        [-1.4266,  1.5834, -0.3965],\n",
            "        [-1.6118,  1.5512, -0.4619],\n",
            "        [-1.6664, -0.0600,  1.5299],\n",
            "        [ 0.3889, -0.0400, -0.9475],\n",
            "        [-1.2325,  1.5985, -0.4364],\n",
            "        [-1.6023,  1.2629,  0.0970],\n",
            "        [-1.8984,  0.1106,  1.3693],\n",
            "        [-1.6511,  1.5696, -0.1433]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.0266,  1.2278, -0.5685],\n",
            "        [-1.2289,  1.2303, -0.2410],\n",
            "        [-1.9696,  0.7536,  0.5961],\n",
            "        [-1.7633,  0.0288,  1.3696],\n",
            "        [-1.6604,  1.4936,  0.1741],\n",
            "        [ 0.5983, -0.0927, -0.8577],\n",
            "        [ 0.6687, -0.3180, -1.0288],\n",
            "        [-1.6461,  1.5647, -0.3293],\n",
            "        [-1.4266,  1.5834, -0.3965],\n",
            "        [-1.6118,  1.5512, -0.4619],\n",
            "        [-1.6664, -0.0600,  1.5299],\n",
            "        [ 0.3889, -0.0400, -0.9475],\n",
            "        [-1.2325,  1.5985, -0.4364],\n",
            "        [-1.6023,  1.2629,  0.0970],\n",
            "        [-1.8984,  0.1106,  1.3693],\n",
            "        [-1.6511,  1.5696, -0.1433]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5359,  1.4930, -0.2885],\n",
            "        [-1.7452,  1.2754, -0.0896],\n",
            "        [ 0.4857, -0.0256, -1.0623],\n",
            "        [-1.8966,  0.0337,  1.6270],\n",
            "        [-1.5174,  1.5216, -0.2373],\n",
            "        [-1.6931,  1.4604, -0.1243],\n",
            "        [-1.4577,  1.6078, -0.0807],\n",
            "        [-1.2655,  1.2049, -0.4688],\n",
            "        [-1.5377,  1.0889,  0.1840],\n",
            "        [-1.5028,  1.6695, -0.3068],\n",
            "        [-2.0396,  0.1633,  1.8461],\n",
            "        [-1.8389,  0.1442,  1.4587],\n",
            "        [-1.1731,  1.5212, -0.4052],\n",
            "        [-1.7428,  0.0661,  1.5917],\n",
            "        [-1.6029,  1.7827, -0.3283],\n",
            "        [-1.6521,  1.5976, -0.3155]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5359,  1.4930, -0.2885],\n",
            "        [-1.7452,  1.2754, -0.0896],\n",
            "        [ 0.4857, -0.0256, -1.0623],\n",
            "        [-1.8966,  0.0337,  1.6270],\n",
            "        [-1.5174,  1.5216, -0.2373],\n",
            "        [-1.6931,  1.4604, -0.1243],\n",
            "        [-1.4577,  1.6078, -0.0807],\n",
            "        [-1.2655,  1.2049, -0.4688],\n",
            "        [-1.5377,  1.0889,  0.1840],\n",
            "        [-1.5028,  1.6695, -0.3068],\n",
            "        [-2.0396,  0.1633,  1.8461],\n",
            "        [-1.8389,  0.1442,  1.4587],\n",
            "        [-1.1731,  1.5212, -0.4052],\n",
            "        [-1.7428,  0.0661,  1.5917],\n",
            "        [-1.6029,  1.7827, -0.3283],\n",
            "        [-1.6521,  1.5976, -0.3155]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.9774,  1.1985, -0.3307],\n",
            "        [-1.9082, -0.0305,  1.5502],\n",
            "        [-1.9258,  0.1996,  1.5931],\n",
            "        [-1.6509,  0.8745,  0.7009],\n",
            "        [-1.8073,  1.6377, -0.0614],\n",
            "        [-1.3432,  1.6849, -0.3895],\n",
            "        [-1.3780,  1.2580, -0.2515],\n",
            "        [-1.4896,  1.7920, -0.4362],\n",
            "        [-1.4005,  1.5798, -0.2223],\n",
            "        [-1.8642,  0.0202,  1.5417],\n",
            "        [-1.1802,  1.6094, -0.5512],\n",
            "        [-1.2839,  1.3985, -0.8567],\n",
            "        [-1.4117,  1.6224, -0.3257],\n",
            "        [-1.5844,  1.8185, -0.4506],\n",
            "        [-1.2371,  0.9872, -0.1560],\n",
            "        [-1.6566,  1.3506,  0.1629]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-0.9774,  1.1985, -0.3307],\n",
            "        [-1.9082, -0.0305,  1.5502],\n",
            "        [-1.9258,  0.1996,  1.5931],\n",
            "        [-1.6509,  0.8745,  0.7009],\n",
            "        [-1.8073,  1.6377, -0.0614],\n",
            "        [-1.3432,  1.6849, -0.3895],\n",
            "        [-1.3780,  1.2580, -0.2515],\n",
            "        [-1.4896,  1.7920, -0.4362],\n",
            "        [-1.4005,  1.5798, -0.2223],\n",
            "        [-1.8642,  0.0202,  1.5417],\n",
            "        [-1.1802,  1.6094, -0.5512],\n",
            "        [-1.2839,  1.3985, -0.8567],\n",
            "        [-1.4117,  1.6224, -0.3257],\n",
            "        [-1.5844,  1.8185, -0.4506],\n",
            "        [-1.2371,  0.9872, -0.1560],\n",
            "        [-1.6566,  1.3506,  0.1629]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5984, -0.2042, -0.9114],\n",
            "        [-1.9704, -0.0744,  1.5916],\n",
            "        [-1.6587,  0.1854,  1.5456],\n",
            "        [-2.3908,  0.3783,  1.4024],\n",
            "        [-1.8944,  0.2217,  1.6885],\n",
            "        [-1.2998,  1.6704, -0.6875],\n",
            "        [-1.7855,  1.6289, -0.3826],\n",
            "        [-1.3735,  1.6330, -0.4435],\n",
            "        [-1.7542,  0.3450,  1.4565],\n",
            "        [ 0.5670, -0.1573, -0.8802],\n",
            "        [-1.9298,  0.3248,  1.4286],\n",
            "        [-1.6652,  1.5455,  0.0402],\n",
            "        [-1.5259,  0.3482,  0.8457],\n",
            "        [-1.5956,  1.5147, -0.5915],\n",
            "        [-1.8300,  0.4984,  1.0924],\n",
            "        [-1.7097,  0.2654,  1.3818]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.5984, -0.2042, -0.9114],\n",
            "        [-1.9704, -0.0744,  1.5916],\n",
            "        [-1.6587,  0.1854,  1.5456],\n",
            "        [-2.3908,  0.3783,  1.4024],\n",
            "        [-1.8944,  0.2217,  1.6885],\n",
            "        [-1.2998,  1.6704, -0.6875],\n",
            "        [-1.7855,  1.6289, -0.3826],\n",
            "        [-1.3735,  1.6330, -0.4435],\n",
            "        [-1.7542,  0.3450,  1.4565],\n",
            "        [ 0.5670, -0.1573, -0.8802],\n",
            "        [-1.9298,  0.3248,  1.4286],\n",
            "        [-1.6652,  1.5455,  0.0402],\n",
            "        [-1.5259,  0.3482,  0.8457],\n",
            "        [-1.5956,  1.5147, -0.5915],\n",
            "        [-1.8300,  0.4984,  1.0924],\n",
            "        [-1.7097,  0.2654,  1.3818]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.2718, -0.0917,  0.0131],\n",
            "        [-2.0866,  0.3825,  1.3793],\n",
            "        [-1.6381,  1.5498,  0.2192],\n",
            "        [-1.4212,  1.4908, -0.3300],\n",
            "        [-1.5640,  1.6591, -0.4896],\n",
            "        [-1.6968,  1.6984, -0.2670],\n",
            "        [-1.5070,  1.6089, -0.4354],\n",
            "        [-2.1066,  0.1439,  1.3011],\n",
            "        [-1.5824,  1.4989, -0.1865],\n",
            "        [-1.4263,  1.4758, -0.1077],\n",
            "        [ 0.2541,  0.1852, -0.9216],\n",
            "        [-1.7732,  1.7051, -0.0126],\n",
            "        [-0.1251,  0.6436, -0.8905],\n",
            "        [-1.6186,  0.4789,  1.0381],\n",
            "        [-1.6639,  1.7927, -0.3864],\n",
            "        [-1.8207,  0.1310,  1.3350]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-0.2718, -0.0917,  0.0131],\n",
            "        [-2.0866,  0.3825,  1.3793],\n",
            "        [-1.6381,  1.5498,  0.2192],\n",
            "        [-1.4212,  1.4908, -0.3300],\n",
            "        [-1.5640,  1.6591, -0.4896],\n",
            "        [-1.6968,  1.6984, -0.2670],\n",
            "        [-1.5070,  1.6089, -0.4354],\n",
            "        [-2.1066,  0.1439,  1.3011],\n",
            "        [-1.5824,  1.4989, -0.1865],\n",
            "        [-1.4263,  1.4758, -0.1077],\n",
            "        [ 0.2541,  0.1852, -0.9216],\n",
            "        [-1.7732,  1.7051, -0.0126],\n",
            "        [-0.1251,  0.6436, -0.8905],\n",
            "        [-1.6186,  0.4789,  1.0381],\n",
            "        [-1.6639,  1.7927, -0.3864],\n",
            "        [-1.8207,  0.1310,  1.3350]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6527,  1.8988, -0.3722],\n",
            "        [-1.6108,  1.6965, -0.3344],\n",
            "        [-1.7274,  1.0561,  0.7153],\n",
            "        [-2.1973,  0.7409,  1.2353],\n",
            "        [-1.5991,  1.8405, -0.4064],\n",
            "        [-1.3063,  1.7953, -0.5863],\n",
            "        [-1.5627,  1.6342, -0.2224],\n",
            "        [-1.7027,  0.3472,  1.1719],\n",
            "        [ 0.6142, -0.1686, -1.0016],\n",
            "        [-1.4692,  1.6791, -0.5717],\n",
            "        [-1.9029,  0.4243,  1.2380],\n",
            "        [-1.6661,  1.6761, -0.1058],\n",
            "        [-1.6256,  1.7435, -0.2348],\n",
            "        [-1.9685,  0.2749,  1.5566],\n",
            "        [-0.0995,  0.5842, -0.7112],\n",
            "        [-1.9515,  0.5789,  1.2155]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6527,  1.8988, -0.3722],\n",
            "        [-1.6108,  1.6965, -0.3344],\n",
            "        [-1.7274,  1.0561,  0.7153],\n",
            "        [-2.1973,  0.7409,  1.2353],\n",
            "        [-1.5991,  1.8405, -0.4064],\n",
            "        [-1.3063,  1.7953, -0.5863],\n",
            "        [-1.5627,  1.6342, -0.2224],\n",
            "        [-1.7027,  0.3472,  1.1719],\n",
            "        [ 0.6142, -0.1686, -1.0016],\n",
            "        [-1.4692,  1.6791, -0.5717],\n",
            "        [-1.9029,  0.4243,  1.2380],\n",
            "        [-1.6661,  1.6761, -0.1058],\n",
            "        [-1.6256,  1.7435, -0.2348],\n",
            "        [-1.9685,  0.2749,  1.5566],\n",
            "        [-0.0995,  0.5842, -0.7112],\n",
            "        [-1.9515,  0.5789,  1.2155]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5753,  1.5919, -0.3470],\n",
            "        [-1.9287,  0.2991,  1.5794],\n",
            "        [ 0.7051, -0.0620, -0.9708],\n",
            "        [-1.8993,  0.6992,  1.3054],\n",
            "        [ 0.5905, -0.2382, -1.1695],\n",
            "        [ 0.5321, -0.0342, -1.0210],\n",
            "        [-1.7508,  1.8046, -0.3695],\n",
            "        [-1.8073,  0.3664,  1.5389],\n",
            "        [-1.6107,  0.0889,  1.4752],\n",
            "        [-1.7366,  1.8709, -0.4153],\n",
            "        [-1.6324,  1.6228, -0.2278],\n",
            "        [-1.8421,  0.2941,  1.4548],\n",
            "        [ 0.4606, -0.0716, -1.0681],\n",
            "        [-1.5917,  1.6135, -0.3281],\n",
            "        [-1.3715,  1.6926, -0.1184],\n",
            "        [-1.6574,  1.7950, -0.1488]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5753,  1.5919, -0.3470],\n",
            "        [-1.9287,  0.2991,  1.5794],\n",
            "        [ 0.7051, -0.0620, -0.9708],\n",
            "        [-1.8993,  0.6992,  1.3054],\n",
            "        [ 0.5905, -0.2382, -1.1695],\n",
            "        [ 0.5321, -0.0342, -1.0210],\n",
            "        [-1.7508,  1.8046, -0.3695],\n",
            "        [-1.8073,  0.3664,  1.5389],\n",
            "        [-1.6107,  0.0889,  1.4752],\n",
            "        [-1.7366,  1.8709, -0.4153],\n",
            "        [-1.6324,  1.6228, -0.2278],\n",
            "        [-1.8421,  0.2941,  1.4548],\n",
            "        [ 0.4606, -0.0716, -1.0681],\n",
            "        [-1.5917,  1.6135, -0.3281],\n",
            "        [-1.3715,  1.6926, -0.1184],\n",
            "        [-1.6574,  1.7950, -0.1488]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5904,  1.6026, -0.3453],\n",
            "        [-1.6720,  0.2103,  1.3394],\n",
            "        [-1.5424,  1.7124, -0.4197],\n",
            "        [-1.4412,  1.4953, -0.2314],\n",
            "        [-1.5529,  1.6576, -0.2414],\n",
            "        [-1.9824,  0.4372,  1.4038],\n",
            "        [-1.7128,  1.6640, -0.3327],\n",
            "        [-1.5315,  1.5956,  0.0156],\n",
            "        [-1.7267,  1.6995, -0.3062],\n",
            "        [-1.7847,  1.7900, -0.0903],\n",
            "        [-1.8678,  1.6795, -0.2344],\n",
            "        [ 0.6316, -0.0664, -0.9992],\n",
            "        [-1.7248,  1.8216, -0.4188],\n",
            "        [ 0.4941,  0.1548, -0.9808],\n",
            "        [-1.8783,  1.9020, -0.5593],\n",
            "        [-1.7526,  1.7582, -0.3414]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5904,  1.6026, -0.3453],\n",
            "        [-1.6720,  0.2103,  1.3394],\n",
            "        [-1.5424,  1.7124, -0.4197],\n",
            "        [-1.4412,  1.4953, -0.2314],\n",
            "        [-1.5529,  1.6576, -0.2414],\n",
            "        [-1.9824,  0.4372,  1.4038],\n",
            "        [-1.7128,  1.6640, -0.3327],\n",
            "        [-1.5315,  1.5956,  0.0156],\n",
            "        [-1.7267,  1.6995, -0.3062],\n",
            "        [-1.7847,  1.7900, -0.0903],\n",
            "        [-1.8678,  1.6795, -0.2344],\n",
            "        [ 0.6316, -0.0664, -0.9992],\n",
            "        [-1.7248,  1.8216, -0.4188],\n",
            "        [ 0.4941,  0.1548, -0.9808],\n",
            "        [-1.8783,  1.9020, -0.5593],\n",
            "        [-1.7526,  1.7582, -0.3414]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4705,  1.8632, -0.3427],\n",
            "        [-1.5807,  1.6545, -0.4404],\n",
            "        [-1.7260,  1.7518, -0.3072],\n",
            "        [-0.0900,  0.4747, -0.7164],\n",
            "        [-1.8752,  1.8228, -0.2371],\n",
            "        [-1.7877,  0.3039,  1.3044],\n",
            "        [-1.6640,  0.3890,  1.2999],\n",
            "        [-2.0168,  0.7112,  0.7501],\n",
            "        [-1.5551,  1.5331, -0.4438],\n",
            "        [-1.5536,  1.8043, -0.5052],\n",
            "        [-1.5446,  1.5750, -0.2240],\n",
            "        [-1.9769,  0.1804,  1.5225],\n",
            "        [-1.7943,  0.4715,  1.4298],\n",
            "        [-2.0415,  0.2763,  1.2905],\n",
            "        [ 0.4799, -0.0289, -0.9092],\n",
            "        [-1.5379,  1.6719, -0.3580]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4705,  1.8632, -0.3427],\n",
            "        [-1.5807,  1.6545, -0.4404],\n",
            "        [-1.7260,  1.7518, -0.3072],\n",
            "        [-0.0900,  0.4747, -0.7164],\n",
            "        [-1.8752,  1.8228, -0.2371],\n",
            "        [-1.7877,  0.3039,  1.3044],\n",
            "        [-1.6640,  0.3890,  1.2999],\n",
            "        [-2.0168,  0.7112,  0.7501],\n",
            "        [-1.5551,  1.5331, -0.4438],\n",
            "        [-1.5536,  1.8043, -0.5052],\n",
            "        [-1.5446,  1.5750, -0.2240],\n",
            "        [-1.9769,  0.1804,  1.5225],\n",
            "        [-1.7943,  0.4715,  1.4298],\n",
            "        [-2.0415,  0.2763,  1.2905],\n",
            "        [ 0.4799, -0.0289, -0.9092],\n",
            "        [-1.5379,  1.6719, -0.3580]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5908,  1.8622, -0.3754],\n",
            "        [-1.5765,  1.9586, -0.1905],\n",
            "        [-1.6290,  1.7030, -0.5104],\n",
            "        [-1.2783,  1.2663, -0.1975],\n",
            "        [-1.8536,  0.3330,  1.1624],\n",
            "        [ 0.6610, -0.1702, -1.0067],\n",
            "        [-1.8001,  1.8834, -0.2607],\n",
            "        [-1.6258,  0.0779,  1.0620],\n",
            "        [-1.5284,  1.3909, -0.0609],\n",
            "        [ 0.2122,  0.1825, -0.9090],\n",
            "        [-1.5827,  1.7312, -0.5191],\n",
            "        [-1.8353,  0.5358,  1.2073],\n",
            "        [-1.5530,  1.6898, -0.2679],\n",
            "        [ 0.6225, -0.0670, -0.9569],\n",
            "        [-1.8203,  0.4291,  1.3837],\n",
            "        [-1.9496,  1.2752,  0.0108]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5908,  1.8622, -0.3754],\n",
            "        [-1.5765,  1.9586, -0.1905],\n",
            "        [-1.6290,  1.7030, -0.5104],\n",
            "        [-1.2783,  1.2663, -0.1975],\n",
            "        [-1.8536,  0.3330,  1.1624],\n",
            "        [ 0.6610, -0.1702, -1.0067],\n",
            "        [-1.8001,  1.8834, -0.2607],\n",
            "        [-1.6258,  0.0779,  1.0620],\n",
            "        [-1.5284,  1.3909, -0.0609],\n",
            "        [ 0.2122,  0.1825, -0.9090],\n",
            "        [-1.5827,  1.7312, -0.5191],\n",
            "        [-1.8353,  0.5358,  1.2073],\n",
            "        [-1.5530,  1.6898, -0.2679],\n",
            "        [ 0.6225, -0.0670, -0.9569],\n",
            "        [-1.8203,  0.4291,  1.3837],\n",
            "        [-1.9496,  1.2752,  0.0108]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7652,  1.6823, -0.3007],\n",
            "        [ 0.7295, -0.0304, -0.9476],\n",
            "        [ 0.5511, -0.0242, -0.8950],\n",
            "        [-1.8886,  0.2856,  1.4000],\n",
            "        [-1.7292,  0.2434,  1.4292],\n",
            "        [-1.5560,  1.7354, -0.3468],\n",
            "        [-1.3621,  0.4228,  0.7244],\n",
            "        [-0.3478,  0.6715, -0.8331],\n",
            "        [-1.5982,  1.6701, -0.3963],\n",
            "        [ 0.5913, -0.0551, -0.9789],\n",
            "        [-1.7132,  1.9469, -0.3190],\n",
            "        [-1.4194,  0.9642,  0.0160],\n",
            "        [-1.8236,  0.5445,  1.0881],\n",
            "        [ 0.3002,  0.0724, -1.1330],\n",
            "        [-1.7939,  1.8332, -0.4893],\n",
            "        [-1.7143,  1.8388, -0.2548]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7652,  1.6823, -0.3007],\n",
            "        [ 0.7295, -0.0304, -0.9476],\n",
            "        [ 0.5511, -0.0242, -0.8950],\n",
            "        [-1.8886,  0.2856,  1.4000],\n",
            "        [-1.7292,  0.2434,  1.4292],\n",
            "        [-1.5560,  1.7354, -0.3468],\n",
            "        [-1.3621,  0.4228,  0.7244],\n",
            "        [-0.3478,  0.6715, -0.8331],\n",
            "        [-1.5982,  1.6701, -0.3963],\n",
            "        [ 0.5913, -0.0551, -0.9789],\n",
            "        [-1.7132,  1.9469, -0.3190],\n",
            "        [-1.4194,  0.9642,  0.0160],\n",
            "        [-1.8236,  0.5445,  1.0881],\n",
            "        [ 0.3002,  0.0724, -1.1330],\n",
            "        [-1.7939,  1.8332, -0.4893],\n",
            "        [-1.7143,  1.8388, -0.2548]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.6688, -0.0458, -1.1081],\n",
            "        [-1.4815,  1.7775, -0.3050],\n",
            "        [-1.6768,  1.5791, -0.1425],\n",
            "        [-1.7525,  1.7342, -0.2913],\n",
            "        [ 0.6500, -0.1521, -0.8573],\n",
            "        [-1.8324,  0.4200,  1.1154],\n",
            "        [-1.7712,  1.9482, -0.3266],\n",
            "        [-1.7463,  1.6192, -0.0486],\n",
            "        [-1.6389,  1.8073, -0.4070],\n",
            "        [-1.6331,  0.5900,  0.8006],\n",
            "        [ 0.6017, -0.0661, -0.9134],\n",
            "        [-1.7764,  1.7649, -0.4721],\n",
            "        [-1.6125,  1.8302, -0.4661],\n",
            "        [-1.5867,  1.9661, -0.3646],\n",
            "        [-1.7637,  1.7083, -0.0241],\n",
            "        [-1.8084,  0.6933,  0.9213]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.6688, -0.0458, -1.1081],\n",
            "        [-1.4815,  1.7775, -0.3050],\n",
            "        [-1.6768,  1.5791, -0.1425],\n",
            "        [-1.7525,  1.7342, -0.2913],\n",
            "        [ 0.6500, -0.1521, -0.8573],\n",
            "        [-1.8324,  0.4200,  1.1154],\n",
            "        [-1.7712,  1.9482, -0.3266],\n",
            "        [-1.7463,  1.6192, -0.0486],\n",
            "        [-1.6389,  1.8073, -0.4070],\n",
            "        [-1.6331,  0.5900,  0.8006],\n",
            "        [ 0.6017, -0.0661, -0.9134],\n",
            "        [-1.7764,  1.7649, -0.4721],\n",
            "        [-1.6125,  1.8302, -0.4661],\n",
            "        [-1.5867,  1.9661, -0.3646],\n",
            "        [-1.7637,  1.7083, -0.0241],\n",
            "        [-1.8084,  0.6933,  0.9213]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7269,  1.8875, -0.4091],\n",
            "        [-0.3605,  0.8021, -0.8920],\n",
            "        [ 0.2353,  0.2919, -0.7564],\n",
            "        [-1.9105,  1.9644, -0.3887],\n",
            "        [-1.6476,  1.6330, -0.1919],\n",
            "        [-1.5179,  1.6656, -0.4188],\n",
            "        [-1.6743,  1.8838, -0.2536],\n",
            "        [-1.6183,  1.9832, -0.4043],\n",
            "        [-1.7295,  1.6691, -0.7331],\n",
            "        [-1.7967,  1.9753, -0.5295],\n",
            "        [-1.6461,  0.2220,  1.2743],\n",
            "        [-1.6213,  1.6441, -0.0469],\n",
            "        [-1.5461,  1.6746, -0.3810],\n",
            "        [-1.5851,  0.0422,  1.3658],\n",
            "        [-1.8474,  1.8932, -0.4008],\n",
            "        [-1.4667,  1.7897, -0.2977]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7269,  1.8875, -0.4091],\n",
            "        [-0.3605,  0.8021, -0.8920],\n",
            "        [ 0.2353,  0.2919, -0.7564],\n",
            "        [-1.9105,  1.9644, -0.3887],\n",
            "        [-1.6476,  1.6330, -0.1919],\n",
            "        [-1.5179,  1.6656, -0.4188],\n",
            "        [-1.6743,  1.8838, -0.2536],\n",
            "        [-1.6183,  1.9832, -0.4043],\n",
            "        [-1.7295,  1.6691, -0.7331],\n",
            "        [-1.7967,  1.9753, -0.5295],\n",
            "        [-1.6461,  0.2220,  1.2743],\n",
            "        [-1.6213,  1.6441, -0.0469],\n",
            "        [-1.5461,  1.6746, -0.3810],\n",
            "        [-1.5851,  0.0422,  1.3658],\n",
            "        [-1.8474,  1.8932, -0.4008],\n",
            "        [-1.4667,  1.7897, -0.2977]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7694,  0.3766,  1.3129],\n",
            "        [-1.8961,  1.3396,  0.3743],\n",
            "        [-1.5768,  1.9346, -0.3470],\n",
            "        [-0.4516,  0.4301, -0.1245],\n",
            "        [-1.5034,  1.7692, -0.2533],\n",
            "        [ 0.5266,  0.1466, -0.9684],\n",
            "        [-1.5140,  1.8981, -0.5870],\n",
            "        [-1.5791,  0.1971,  1.0522],\n",
            "        [-1.5455,  0.7659,  0.5889],\n",
            "        [-1.8019,  0.6635,  1.0309],\n",
            "        [-1.6662,  1.6283, -0.3776],\n",
            "        [-1.8076,  1.5971,  0.1623],\n",
            "        [-1.6898,  1.5734, -0.3694],\n",
            "        [-1.5584,  0.1542,  0.9975],\n",
            "        [-1.8541,  1.9661, -0.2706],\n",
            "        [-1.6183,  0.2288,  1.1784]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7694,  0.3766,  1.3129],\n",
            "        [-1.8961,  1.3396,  0.3743],\n",
            "        [-1.5768,  1.9346, -0.3470],\n",
            "        [-0.4516,  0.4301, -0.1245],\n",
            "        [-1.5034,  1.7692, -0.2533],\n",
            "        [ 0.5266,  0.1466, -0.9684],\n",
            "        [-1.5140,  1.8981, -0.5870],\n",
            "        [-1.5791,  0.1971,  1.0522],\n",
            "        [-1.5455,  0.7659,  0.5889],\n",
            "        [-1.8019,  0.6635,  1.0309],\n",
            "        [-1.6662,  1.6283, -0.3776],\n",
            "        [-1.8076,  1.5971,  0.1623],\n",
            "        [-1.6898,  1.5734, -0.3694],\n",
            "        [-1.5584,  0.1542,  0.9975],\n",
            "        [-1.8541,  1.9661, -0.2706],\n",
            "        [-1.6183,  0.2288,  1.1784]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6900,  0.3371,  1.2815],\n",
            "        [-1.9261,  0.8159,  0.7435],\n",
            "        [-1.6045,  0.7663,  0.5138],\n",
            "        [-1.5067,  0.2615,  1.0794],\n",
            "        [-1.5304,  0.3808,  1.2986],\n",
            "        [-1.7000,  1.7639, -0.0310],\n",
            "        [-1.8483,  1.3212,  0.1753],\n",
            "        [-1.6315,  1.5986, -0.1736],\n",
            "        [-1.8157,  1.7521, -0.1005],\n",
            "        [-1.7193,  1.6844, -0.4083],\n",
            "        [-1.5445,  0.1870,  1.3575],\n",
            "        [-2.0432,  1.4816,  0.1328],\n",
            "        [-1.6614,  1.9138, -0.5506],\n",
            "        [-1.5042,  1.6607, -0.3198],\n",
            "        [-1.6838,  1.8228, -0.2694],\n",
            "        [-1.8405,  0.6152,  1.1892]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6900,  0.3371,  1.2815],\n",
            "        [-1.9261,  0.8159,  0.7435],\n",
            "        [-1.6045,  0.7663,  0.5138],\n",
            "        [-1.5067,  0.2615,  1.0794],\n",
            "        [-1.5304,  0.3808,  1.2986],\n",
            "        [-1.7000,  1.7639, -0.0310],\n",
            "        [-1.8483,  1.3212,  0.1753],\n",
            "        [-1.6315,  1.5986, -0.1736],\n",
            "        [-1.8157,  1.7521, -0.1005],\n",
            "        [-1.7193,  1.6844, -0.4083],\n",
            "        [-1.5445,  0.1870,  1.3575],\n",
            "        [-2.0432,  1.4816,  0.1328],\n",
            "        [-1.6614,  1.9138, -0.5506],\n",
            "        [-1.5042,  1.6607, -0.3198],\n",
            "        [-1.6838,  1.8228, -0.2694],\n",
            "        [-1.8405,  0.6152,  1.1892]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5960,  1.8744, -0.2667],\n",
            "        [-1.2183,  1.4037, -0.2962],\n",
            "        [-1.8017,  1.7048, -0.1935],\n",
            "        [-1.4963,  0.2456,  1.0822],\n",
            "        [-1.7256,  1.7706, -0.4663],\n",
            "        [-1.6970,  1.8942, -0.3300],\n",
            "        [-1.6192,  0.1870,  1.1355],\n",
            "        [-1.6949,  1.6736, -0.3787],\n",
            "        [-1.7211,  1.7254, -0.3436],\n",
            "        [-1.7626,  1.7002, -0.1029],\n",
            "        [-1.5900,  1.0375,  0.6037],\n",
            "        [-1.2332,  0.1896,  0.9287],\n",
            "        [-1.6258,  1.5614, -0.5203],\n",
            "        [-1.6720,  1.6674, -0.4245],\n",
            "        [-0.6651,  1.0302, -0.7870],\n",
            "        [ 0.3961,  0.2232, -0.9419]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5960,  1.8744, -0.2667],\n",
            "        [-1.2183,  1.4037, -0.2962],\n",
            "        [-1.8017,  1.7048, -0.1935],\n",
            "        [-1.4963,  0.2456,  1.0822],\n",
            "        [-1.7256,  1.7706, -0.4663],\n",
            "        [-1.6970,  1.8942, -0.3300],\n",
            "        [-1.6192,  0.1870,  1.1355],\n",
            "        [-1.6949,  1.6736, -0.3787],\n",
            "        [-1.7211,  1.7254, -0.3436],\n",
            "        [-1.7626,  1.7002, -0.1029],\n",
            "        [-1.5900,  1.0375,  0.6037],\n",
            "        [-1.2332,  0.1896,  0.9287],\n",
            "        [-1.6258,  1.5614, -0.5203],\n",
            "        [-1.6720,  1.6674, -0.4245],\n",
            "        [-0.6651,  1.0302, -0.7870],\n",
            "        [ 0.3961,  0.2232, -0.9419]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6348,  1.7146, -0.0274],\n",
            "        [-0.6267,  0.3351, -0.0459],\n",
            "        [ 0.4604,  0.2440, -1.1488],\n",
            "        [-1.3685,  0.2006,  1.2154],\n",
            "        [-1.7159,  1.6796, -0.4582],\n",
            "        [-1.8361,  1.8602, -0.1213],\n",
            "        [-1.5057,  1.5421, -0.0298],\n",
            "        [-1.6648,  1.6957, -0.1017],\n",
            "        [-1.7859,  0.5795,  1.0017],\n",
            "        [-1.4215,  1.5844, -0.3613],\n",
            "        [-1.8659,  1.3192,  0.5305],\n",
            "        [-1.6569,  1.6563, -0.3999],\n",
            "        [ 0.6247, -0.0773, -1.1961],\n",
            "        [ 0.5174,  0.0394, -0.8637],\n",
            "        [-1.6941,  0.5058,  1.0828],\n",
            "        [-1.6233,  1.1237,  0.5099]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.6348,  1.7146, -0.0274],\n",
            "        [-0.6267,  0.3351, -0.0459],\n",
            "        [ 0.4604,  0.2440, -1.1488],\n",
            "        [-1.3685,  0.2006,  1.2154],\n",
            "        [-1.7159,  1.6796, -0.4582],\n",
            "        [-1.8361,  1.8602, -0.1213],\n",
            "        [-1.5057,  1.5421, -0.0298],\n",
            "        [-1.6648,  1.6957, -0.1017],\n",
            "        [-1.7859,  0.5795,  1.0017],\n",
            "        [-1.4215,  1.5844, -0.3613],\n",
            "        [-1.8659,  1.3192,  0.5305],\n",
            "        [-1.6569,  1.6563, -0.3999],\n",
            "        [ 0.6247, -0.0773, -1.1961],\n",
            "        [ 0.5174,  0.0394, -0.8637],\n",
            "        [-1.6941,  0.5058,  1.0828],\n",
            "        [-1.6233,  1.1237,  0.5099]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4448,  0.1487,  1.1634],\n",
            "        [-1.6787,  0.3040,  0.9905],\n",
            "        [-1.5594,  0.3308,  0.8515],\n",
            "        [-1.6461,  1.5714, -0.3130],\n",
            "        [-1.4789,  1.6253, -0.4473],\n",
            "        [-1.4878,  1.6445, -0.4260],\n",
            "        [-1.5000,  0.9964,  0.2860],\n",
            "        [ 0.5937,  0.0130, -1.0076],\n",
            "        [-1.7316,  1.6905, -0.2864],\n",
            "        [-1.5370,  1.4628,  0.1152],\n",
            "        [ 0.4922, -0.0418, -0.9172],\n",
            "        [-1.4844,  0.3627,  0.9908],\n",
            "        [-1.4602,  1.7543, -0.3979],\n",
            "        [-1.4721,  0.4359,  1.0118],\n",
            "        [-1.6573,  1.5585, -0.1363],\n",
            "        [-1.7792,  1.7464, -0.3287]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4448,  0.1487,  1.1634],\n",
            "        [-1.6787,  0.3040,  0.9905],\n",
            "        [-1.5594,  0.3308,  0.8515],\n",
            "        [-1.6461,  1.5714, -0.3130],\n",
            "        [-1.4789,  1.6253, -0.4473],\n",
            "        [-1.4878,  1.6445, -0.4260],\n",
            "        [-1.5000,  0.9964,  0.2860],\n",
            "        [ 0.5937,  0.0130, -1.0076],\n",
            "        [-1.7316,  1.6905, -0.2864],\n",
            "        [-1.5370,  1.4628,  0.1152],\n",
            "        [ 0.4922, -0.0418, -0.9172],\n",
            "        [-1.4844,  0.3627,  0.9908],\n",
            "        [-1.4602,  1.7543, -0.3979],\n",
            "        [-1.4721,  0.4359,  1.0118],\n",
            "        [-1.6573,  1.5585, -0.1363],\n",
            "        [-1.7792,  1.7464, -0.3287]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3471,  0.1170, -0.9647],\n",
            "        [-1.6264,  0.3735,  1.1964],\n",
            "        [-1.4290,  0.4286,  1.0558],\n",
            "        [ 0.5000,  0.1439, -1.1011],\n",
            "        [-1.6438,  1.8665, -0.3086],\n",
            "        [ 0.1827,  0.3169, -0.8351],\n",
            "        [-1.8890,  0.7749,  0.6123],\n",
            "        [-1.6767,  1.5628, -0.2041],\n",
            "        [-1.4672,  1.7445, -0.3222],\n",
            "        [-1.4328,  1.5076, -0.3981],\n",
            "        [-1.6713,  1.5354, -0.2951],\n",
            "        [-1.5674,  0.4086,  1.0326],\n",
            "        [-1.6388,  0.2560,  1.0937],\n",
            "        [-1.9343,  1.3217,  0.3733],\n",
            "        [-1.6573,  1.9229, -0.3677],\n",
            "        [-1.8724,  1.7934, -0.0407]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[ 0.3471,  0.1170, -0.9647],\n",
            "        [-1.6264,  0.3735,  1.1964],\n",
            "        [-1.4290,  0.4286,  1.0558],\n",
            "        [ 0.5000,  0.1439, -1.1011],\n",
            "        [-1.6438,  1.8665, -0.3086],\n",
            "        [ 0.1827,  0.3169, -0.8351],\n",
            "        [-1.8890,  0.7749,  0.6123],\n",
            "        [-1.6767,  1.5628, -0.2041],\n",
            "        [-1.4672,  1.7445, -0.3222],\n",
            "        [-1.4328,  1.5076, -0.3981],\n",
            "        [-1.6713,  1.5354, -0.2951],\n",
            "        [-1.5674,  0.4086,  1.0326],\n",
            "        [-1.6388,  0.2560,  1.0937],\n",
            "        [-1.9343,  1.3217,  0.3733],\n",
            "        [-1.6573,  1.9229, -0.3677],\n",
            "        [-1.8724,  1.7934, -0.0407]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7263,  1.8643, -0.2403],\n",
            "        [-1.7341,  1.6876, -0.3402],\n",
            "        [-1.5843,  1.5029, -0.3794],\n",
            "        [-1.4383,  1.7001, -0.2300],\n",
            "        [-1.4460,  1.6466, -0.3005],\n",
            "        [-1.6582,  1.7930, -0.1590],\n",
            "        [-1.3220,  1.6586, -0.3956],\n",
            "        [-1.5860,  1.9300, -0.2967],\n",
            "        [-1.5526,  1.4357, -0.1229],\n",
            "        [-1.5931,  1.5511, -0.1470],\n",
            "        [-1.4632,  1.8600, -0.4679],\n",
            "        [-1.5536,  1.5602, -0.3404],\n",
            "        [-1.6923,  1.6959, -0.1784],\n",
            "        [-1.5898,  1.4057, -0.2376],\n",
            "        [-1.7930,  1.1820,  0.3083],\n",
            "        [-1.7853,  1.6991,  0.0072]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7263,  1.8643, -0.2403],\n",
            "        [-1.7341,  1.6876, -0.3402],\n",
            "        [-1.5843,  1.5029, -0.3794],\n",
            "        [-1.4383,  1.7001, -0.2300],\n",
            "        [-1.4460,  1.6466, -0.3005],\n",
            "        [-1.6582,  1.7930, -0.1590],\n",
            "        [-1.3220,  1.6586, -0.3956],\n",
            "        [-1.5860,  1.9300, -0.2967],\n",
            "        [-1.5526,  1.4357, -0.1229],\n",
            "        [-1.5931,  1.5511, -0.1470],\n",
            "        [-1.4632,  1.8600, -0.4679],\n",
            "        [-1.5536,  1.5602, -0.3404],\n",
            "        [-1.6923,  1.6959, -0.1784],\n",
            "        [-1.5898,  1.4057, -0.2376],\n",
            "        [-1.7930,  1.1820,  0.3083],\n",
            "        [-1.7853,  1.6991,  0.0072]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7781,  1.6776, -0.3891],\n",
            "        [-1.6848,  0.9007,  0.5949],\n",
            "        [-1.6612,  1.7163, -0.1788],\n",
            "        [-1.6617,  1.7431, -0.2806],\n",
            "        [-1.5978,  1.6266, -0.0033],\n",
            "        [-1.7084,  1.8098, -0.2892],\n",
            "        [ 0.5929,  0.0727, -1.0570],\n",
            "        [-1.6752,  0.4400,  1.2325],\n",
            "        [-1.6331,  1.7308, -0.3018],\n",
            "        [-1.4294,  0.2760,  0.9524],\n",
            "        [-1.5105,  0.4527,  1.0807],\n",
            "        [ 0.8050,  0.0723, -1.0144],\n",
            "        [-1.6712,  0.4501,  0.8262],\n",
            "        [-1.7644,  1.5457, -0.2476],\n",
            "        [-1.5884,  1.2573, -0.3231],\n",
            "        [-1.5774,  1.7106, -0.3524]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.7781,  1.6776, -0.3891],\n",
            "        [-1.6848,  0.9007,  0.5949],\n",
            "        [-1.6612,  1.7163, -0.1788],\n",
            "        [-1.6617,  1.7431, -0.2806],\n",
            "        [-1.5978,  1.6266, -0.0033],\n",
            "        [-1.7084,  1.8098, -0.2892],\n",
            "        [ 0.5929,  0.0727, -1.0570],\n",
            "        [-1.6752,  0.4400,  1.2325],\n",
            "        [-1.6331,  1.7308, -0.3018],\n",
            "        [-1.4294,  0.2760,  0.9524],\n",
            "        [-1.5105,  0.4527,  1.0807],\n",
            "        [ 0.8050,  0.0723, -1.0144],\n",
            "        [-1.6712,  0.4501,  0.8262],\n",
            "        [-1.7644,  1.5457, -0.2476],\n",
            "        [-1.5884,  1.2573, -0.3231],\n",
            "        [-1.5774,  1.7106, -0.3524]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3340,  0.2475,  1.0498],\n",
            "        [-1.5015,  1.8946, -0.4029],\n",
            "        [-1.4378,  1.5722, -0.2757],\n",
            "        [-1.7209,  0.2763,  1.2484],\n",
            "        [-1.6681,  1.6548, -0.1526],\n",
            "        [-1.6009,  0.3508,  1.2056],\n",
            "        [-1.5544,  0.4218,  1.0207],\n",
            "        [-1.3410,  0.3680,  1.0890],\n",
            "        [-1.6400,  1.8856, -0.1719],\n",
            "        [-1.5782,  1.6095, -0.5622],\n",
            "        [-1.3865,  1.3211, -0.0649],\n",
            "        [-1.5642,  0.4749,  0.7556],\n",
            "        [-1.3643,  1.5086, -0.3650],\n",
            "        [-1.4130,  1.5314, -0.4230],\n",
            "        [-1.3336,  1.7197, -0.3795],\n",
            "        [ 0.5488,  0.1200, -1.1779]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3340,  0.2475,  1.0498],\n",
            "        [-1.5015,  1.8946, -0.4029],\n",
            "        [-1.4378,  1.5722, -0.2757],\n",
            "        [-1.7209,  0.2763,  1.2484],\n",
            "        [-1.6681,  1.6548, -0.1526],\n",
            "        [-1.6009,  0.3508,  1.2056],\n",
            "        [-1.5544,  0.4218,  1.0207],\n",
            "        [-1.3410,  0.3680,  1.0890],\n",
            "        [-1.6400,  1.8856, -0.1719],\n",
            "        [-1.5782,  1.6095, -0.5622],\n",
            "        [-1.3865,  1.3211, -0.0649],\n",
            "        [-1.5642,  0.4749,  0.7556],\n",
            "        [-1.3643,  1.5086, -0.3650],\n",
            "        [-1.4130,  1.5314, -0.4230],\n",
            "        [-1.3336,  1.7197, -0.3795],\n",
            "        [ 0.5488,  0.1200, -1.1779]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5170,  1.4860, -0.1381],\n",
            "        [-1.5138,  0.4933,  1.0186],\n",
            "        [-1.5544,  1.7353, -0.2917],\n",
            "        [-1.5279,  1.5616, -0.1058],\n",
            "        [ 0.5185,  0.0446, -1.0836],\n",
            "        [-1.4472,  1.7223, -0.2911],\n",
            "        [-1.5247,  1.8692, -0.3429],\n",
            "        [-1.4944,  0.2515,  1.2327],\n",
            "        [-1.5445,  1.5678, -0.0997],\n",
            "        [-1.7331,  0.3365,  1.1597],\n",
            "        [-1.4496,  1.4994, -0.0485],\n",
            "        [-1.6820,  0.3528,  0.8254],\n",
            "        [-1.3130,  1.3185, -0.4286],\n",
            "        [ 0.2018,  0.3863, -0.8537],\n",
            "        [-1.3808,  1.6151, -0.3824],\n",
            "        [-1.5000,  1.7891, -0.3363]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5170,  1.4860, -0.1381],\n",
            "        [-1.5138,  0.4933,  1.0186],\n",
            "        [-1.5544,  1.7353, -0.2917],\n",
            "        [-1.5279,  1.5616, -0.1058],\n",
            "        [ 0.5185,  0.0446, -1.0836],\n",
            "        [-1.4472,  1.7223, -0.2911],\n",
            "        [-1.5247,  1.8692, -0.3429],\n",
            "        [-1.4944,  0.2515,  1.2327],\n",
            "        [-1.5445,  1.5678, -0.0997],\n",
            "        [-1.7331,  0.3365,  1.1597],\n",
            "        [-1.4496,  1.4994, -0.0485],\n",
            "        [-1.6820,  0.3528,  0.8254],\n",
            "        [-1.3130,  1.3185, -0.4286],\n",
            "        [ 0.2018,  0.3863, -0.8537],\n",
            "        [-1.3808,  1.6151, -0.3824],\n",
            "        [-1.5000,  1.7891, -0.3363]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5013,  1.6873, -0.4179],\n",
            "        [ 0.5317, -0.0429, -1.0068],\n",
            "        [-1.4257,  1.4159, -0.4107],\n",
            "        [-1.6991,  0.4957,  0.8584],\n",
            "        [-1.4957,  1.4673, -0.3208],\n",
            "        [-1.5311,  1.7125, -0.5634],\n",
            "        [-1.4768,  0.3422,  1.0785],\n",
            "        [-1.3431,  1.6234, -0.1267],\n",
            "        [-0.0154,  0.0352, -0.3170],\n",
            "        [-1.4979,  1.5009, -0.1536],\n",
            "        [-1.6371,  0.3258,  1.0804],\n",
            "        [-1.6734,  0.8548,  0.7584],\n",
            "        [-1.4166,  1.4332, -0.1956],\n",
            "        [-0.4346,  0.5480, -0.4018],\n",
            "        [-1.6873,  1.7211, -0.2654],\n",
            "        [-1.2692,  1.4011, -0.2785]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5013,  1.6873, -0.4179],\n",
            "        [ 0.5317, -0.0429, -1.0068],\n",
            "        [-1.4257,  1.4159, -0.4107],\n",
            "        [-1.6991,  0.4957,  0.8584],\n",
            "        [-1.4957,  1.4673, -0.3208],\n",
            "        [-1.5311,  1.7125, -0.5634],\n",
            "        [-1.4768,  0.3422,  1.0785],\n",
            "        [-1.3431,  1.6234, -0.1267],\n",
            "        [-0.0154,  0.0352, -0.3170],\n",
            "        [-1.4979,  1.5009, -0.1536],\n",
            "        [-1.6371,  0.3258,  1.0804],\n",
            "        [-1.6734,  0.8548,  0.7584],\n",
            "        [-1.4166,  1.4332, -0.1956],\n",
            "        [-0.4346,  0.5480, -0.4018],\n",
            "        [-1.6873,  1.7211, -0.2654],\n",
            "        [-1.2692,  1.4011, -0.2785]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4040,  1.5268, -0.5456],\n",
            "        [-1.4222,  1.6385, -0.1872],\n",
            "        [-1.4597,  1.6597, -0.2795],\n",
            "        [-1.4870,  0.2310,  1.0737],\n",
            "        [-1.3280,  1.6431, -0.2444],\n",
            "        [-1.6424,  0.2541,  1.0804],\n",
            "        [ 0.1065,  0.3598, -0.9507],\n",
            "        [-1.3947,  0.9821,  0.2667],\n",
            "        [-1.4973,  1.5287, -0.4676],\n",
            "        [-1.6321,  1.5310, -0.2922],\n",
            "        [-1.6678,  1.4418, -0.1084],\n",
            "        [-1.3002,  0.4042,  1.0101],\n",
            "        [-1.4168,  1.5392, -0.1181],\n",
            "        [-1.6414,  1.6850, -0.0916],\n",
            "        [ 0.5678,  0.0065, -0.9925],\n",
            "        [-1.5730,  0.3551,  0.8914]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.4040,  1.5268, -0.5456],\n",
            "        [-1.4222,  1.6385, -0.1872],\n",
            "        [-1.4597,  1.6597, -0.2795],\n",
            "        [-1.4870,  0.2310,  1.0737],\n",
            "        [-1.3280,  1.6431, -0.2444],\n",
            "        [-1.6424,  0.2541,  1.0804],\n",
            "        [ 0.1065,  0.3598, -0.9507],\n",
            "        [-1.3947,  0.9821,  0.2667],\n",
            "        [-1.4973,  1.5287, -0.4676],\n",
            "        [-1.6321,  1.5310, -0.2922],\n",
            "        [-1.6678,  1.4418, -0.1084],\n",
            "        [-1.3002,  0.4042,  1.0101],\n",
            "        [-1.4168,  1.5392, -0.1181],\n",
            "        [-1.6414,  1.6850, -0.0916],\n",
            "        [ 0.5678,  0.0065, -0.9925],\n",
            "        [-1.5730,  0.3551,  0.8914]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3492,  0.3854,  1.0430],\n",
            "        [-1.2769,  1.1808, -0.2621],\n",
            "        [-1.5569,  1.4124, -0.1578],\n",
            "        [-1.4628,  0.2512,  1.0403],\n",
            "        [-1.4587,  1.2687, -0.2983],\n",
            "        [-1.5177,  0.3102,  0.9383],\n",
            "        [-1.4066,  0.2493,  0.7468],\n",
            "        [-1.4343,  1.4563, -0.4108],\n",
            "        [-1.3917,  1.4297, -0.2719],\n",
            "        [-1.3603,  0.5734,  0.8681],\n",
            "        [-1.3011,  0.2968,  0.8114],\n",
            "        [-1.6817,  0.3457,  1.0138],\n",
            "        [-1.3601,  1.5290, -0.4923],\n",
            "        [ 0.4808, -0.0446, -0.9527],\n",
            "        [ 0.3850,  0.0056, -1.0371],\n",
            "        [-1.2284,  1.1715, -0.0551]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3492,  0.3854,  1.0430],\n",
            "        [-1.2769,  1.1808, -0.2621],\n",
            "        [-1.5569,  1.4124, -0.1578],\n",
            "        [-1.4628,  0.2512,  1.0403],\n",
            "        [-1.4587,  1.2687, -0.2983],\n",
            "        [-1.5177,  0.3102,  0.9383],\n",
            "        [-1.4066,  0.2493,  0.7468],\n",
            "        [-1.4343,  1.4563, -0.4108],\n",
            "        [-1.3917,  1.4297, -0.2719],\n",
            "        [-1.3603,  0.5734,  0.8681],\n",
            "        [-1.3011,  0.2968,  0.8114],\n",
            "        [-1.6817,  0.3457,  1.0138],\n",
            "        [-1.3601,  1.5290, -0.4923],\n",
            "        [ 0.4808, -0.0446, -0.9527],\n",
            "        [ 0.3850,  0.0056, -1.0371],\n",
            "        [-1.2284,  1.1715, -0.0551]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5685,  0.3051,  1.0314],\n",
            "        [ 0.5795,  0.0766, -0.9267],\n",
            "        [-1.3333,  1.8146, -0.4403],\n",
            "        [-1.2514,  1.0615, -0.0609],\n",
            "        [-1.3476,  1.2567, -0.0174],\n",
            "        [-1.5160,  1.5341, -0.2548],\n",
            "        [-1.3930,  1.2445, -0.2616],\n",
            "        [-1.4860,  0.2568,  0.9675],\n",
            "        [-1.4447,  1.2879, -0.1665],\n",
            "        [-1.3972,  0.3875,  1.0630],\n",
            "        [-1.4406,  0.5085,  0.8037],\n",
            "        [-1.5890,  0.3457,  0.8699],\n",
            "        [-1.1562,  1.4347, -0.4919],\n",
            "        [-1.3505,  1.4066, -0.2282],\n",
            "        [-1.4619,  0.2109,  1.1091],\n",
            "        [-1.9056,  0.5437,  0.9625]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5685,  0.3051,  1.0314],\n",
            "        [ 0.5795,  0.0766, -0.9267],\n",
            "        [-1.3333,  1.8146, -0.4403],\n",
            "        [-1.2514,  1.0615, -0.0609],\n",
            "        [-1.3476,  1.2567, -0.0174],\n",
            "        [-1.5160,  1.5341, -0.2548],\n",
            "        [-1.3930,  1.2445, -0.2616],\n",
            "        [-1.4860,  0.2568,  0.9675],\n",
            "        [-1.4447,  1.2879, -0.1665],\n",
            "        [-1.3972,  0.3875,  1.0630],\n",
            "        [-1.4406,  0.5085,  0.8037],\n",
            "        [-1.5890,  0.3457,  0.8699],\n",
            "        [-1.1562,  1.4347, -0.4919],\n",
            "        [-1.3505,  1.4066, -0.2282],\n",
            "        [-1.4619,  0.2109,  1.1091],\n",
            "        [-1.9056,  0.5437,  0.9625]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3957,  0.3404,  0.9754],\n",
            "        [-1.2289,  1.3999, -0.2691],\n",
            "        [-1.3235,  1.2462, -0.3382],\n",
            "        [-1.5394,  1.5512, -0.1080],\n",
            "        [-1.3764,  1.4105, -0.1028],\n",
            "        [ 0.2267,  0.1374, -1.0262],\n",
            "        [-0.4290,  0.9049, -0.8689],\n",
            "        [-1.6070,  0.8167,  0.5263],\n",
            "        [-1.3826,  1.2735, -0.1764],\n",
            "        [-1.3788,  0.1284,  1.0581],\n",
            "        [-1.4710,  0.2328,  0.9580],\n",
            "        [ 0.1666,  0.2828, -0.9136],\n",
            "        [-1.3440,  1.3285, -0.0941],\n",
            "        [-0.9266,  0.4953,  0.3197],\n",
            "        [-1.1933,  1.3228, -0.2218],\n",
            "        [-1.2973,  1.2484, -0.0901]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3957,  0.3404,  0.9754],\n",
            "        [-1.2289,  1.3999, -0.2691],\n",
            "        [-1.3235,  1.2462, -0.3382],\n",
            "        [-1.5394,  1.5512, -0.1080],\n",
            "        [-1.3764,  1.4105, -0.1028],\n",
            "        [ 0.2267,  0.1374, -1.0262],\n",
            "        [-0.4290,  0.9049, -0.8689],\n",
            "        [-1.6070,  0.8167,  0.5263],\n",
            "        [-1.3826,  1.2735, -0.1764],\n",
            "        [-1.3788,  0.1284,  1.0581],\n",
            "        [-1.4710,  0.2328,  0.9580],\n",
            "        [ 0.1666,  0.2828, -0.9136],\n",
            "        [-1.3440,  1.3285, -0.0941],\n",
            "        [-0.9266,  0.4953,  0.3197],\n",
            "        [-1.1933,  1.3228, -0.2218],\n",
            "        [-1.2973,  1.2484, -0.0901]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3466,  1.4175, -0.3357],\n",
            "        [-1.2287,  1.3166, -0.1256],\n",
            "        [-1.3960,  1.4081, -0.3106],\n",
            "        [-1.3770,  0.1579,  0.9522],\n",
            "        [ 0.2824,  0.0866, -0.8626],\n",
            "        [-1.7690,  1.5137, -0.1101],\n",
            "        [-1.3629,  1.1939, -0.2811],\n",
            "        [-1.3734,  1.3678, -0.1126],\n",
            "        [-1.4241,  1.3607, -0.0994],\n",
            "        [-1.2695,  1.3516, -0.4101],\n",
            "        [-1.6401,  0.3225,  1.0145],\n",
            "        [-1.2180,  1.1245, -0.3592],\n",
            "        [-1.3309,  0.2053,  0.9533],\n",
            "        [-1.3378,  1.1508, -0.1783],\n",
            "        [-1.2947,  1.3188, -0.2506],\n",
            "        [-1.5695,  0.3038,  1.0871]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3466,  1.4175, -0.3357],\n",
            "        [-1.2287,  1.3166, -0.1256],\n",
            "        [-1.3960,  1.4081, -0.3106],\n",
            "        [-1.3770,  0.1579,  0.9522],\n",
            "        [ 0.2824,  0.0866, -0.8626],\n",
            "        [-1.7690,  1.5137, -0.1101],\n",
            "        [-1.3629,  1.1939, -0.2811],\n",
            "        [-1.3734,  1.3678, -0.1126],\n",
            "        [-1.4241,  1.3607, -0.0994],\n",
            "        [-1.2695,  1.3516, -0.4101],\n",
            "        [-1.6401,  0.3225,  1.0145],\n",
            "        [-1.2180,  1.1245, -0.3592],\n",
            "        [-1.3309,  0.2053,  0.9533],\n",
            "        [-1.3378,  1.1508, -0.1783],\n",
            "        [-1.2947,  1.3188, -0.2506],\n",
            "        [-1.5695,  0.3038,  1.0871]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3795,  1.3732,  0.0242],\n",
            "        [-0.9787,  1.1819, -0.4855],\n",
            "        [-1.1587,  1.3849, -0.5612],\n",
            "        [-1.4169,  0.3960,  0.8290],\n",
            "        [-1.5296,  1.3925,  0.1022],\n",
            "        [-1.4573,  1.1148,  0.2004],\n",
            "        [ 0.4709,  0.1489, -1.1488],\n",
            "        [-1.5392,  0.9715,  0.3721],\n",
            "        [-1.3822,  0.4325,  0.7672],\n",
            "        [-1.4373,  1.3130, -0.1127],\n",
            "        [-1.7889,  0.6452,  0.7279],\n",
            "        [-1.4171,  0.4085,  0.9705],\n",
            "        [-1.4233,  0.1478,  0.9794],\n",
            "        [-1.4506,  1.3461, -0.4794],\n",
            "        [-1.3911,  1.3756, -0.2130],\n",
            "        [-1.4667,  0.6717,  0.7668]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3795,  1.3732,  0.0242],\n",
            "        [-0.9787,  1.1819, -0.4855],\n",
            "        [-1.1587,  1.3849, -0.5612],\n",
            "        [-1.4169,  0.3960,  0.8290],\n",
            "        [-1.5296,  1.3925,  0.1022],\n",
            "        [-1.4573,  1.1148,  0.2004],\n",
            "        [ 0.4709,  0.1489, -1.1488],\n",
            "        [-1.5392,  0.9715,  0.3721],\n",
            "        [-1.3822,  0.4325,  0.7672],\n",
            "        [-1.4373,  1.3130, -0.1127],\n",
            "        [-1.7889,  0.6452,  0.7279],\n",
            "        [-1.4171,  0.4085,  0.9705],\n",
            "        [-1.4233,  0.1478,  0.9794],\n",
            "        [-1.4506,  1.3461, -0.4794],\n",
            "        [-1.3911,  1.3756, -0.2130],\n",
            "        [-1.4667,  0.6717,  0.7668]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2650,  1.3903, -0.1470],\n",
            "        [-1.2733,  1.3943, -0.0205],\n",
            "        [-1.6884,  0.1709,  1.1976],\n",
            "        [ 0.5233,  0.1151, -1.0862],\n",
            "        [-1.4755,  1.5673, -0.1216],\n",
            "        [-1.4003,  1.4200, -0.0830],\n",
            "        [ 0.1920,  0.4006, -1.0904],\n",
            "        [-1.3175,  1.4323, -0.2620],\n",
            "        [-1.3598,  1.3721, -0.1932],\n",
            "        [-1.3147,  1.3153, -0.0608],\n",
            "        [-1.4254,  1.5412, -0.2912],\n",
            "        [-1.2796,  1.2944, -0.4216],\n",
            "        [-1.5130,  1.2695, -0.1459],\n",
            "        [-1.4358,  1.1635, -0.1306],\n",
            "        [-1.4238,  1.2684, -0.2205],\n",
            "        [ 0.6317,  0.0194, -1.2710]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.2650,  1.3903, -0.1470],\n",
            "        [-1.2733,  1.3943, -0.0205],\n",
            "        [-1.6884,  0.1709,  1.1976],\n",
            "        [ 0.5233,  0.1151, -1.0862],\n",
            "        [-1.4755,  1.5673, -0.1216],\n",
            "        [-1.4003,  1.4200, -0.0830],\n",
            "        [ 0.1920,  0.4006, -1.0904],\n",
            "        [-1.3175,  1.4323, -0.2620],\n",
            "        [-1.3598,  1.3721, -0.1932],\n",
            "        [-1.3147,  1.3153, -0.0608],\n",
            "        [-1.4254,  1.5412, -0.2912],\n",
            "        [-1.2796,  1.2944, -0.4216],\n",
            "        [-1.5130,  1.2695, -0.1459],\n",
            "        [-1.4358,  1.1635, -0.1306],\n",
            "        [-1.4238,  1.2684, -0.2205],\n",
            "        [ 0.6317,  0.0194, -1.2710]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5855,  0.1628,  1.2013],\n",
            "        [-1.1385,  1.5414, -0.2419],\n",
            "        [-1.4008,  1.4636, -0.4019],\n",
            "        [-1.2866,  1.4169, -0.2155],\n",
            "        [-1.2277,  1.4692, -0.4315],\n",
            "        [-1.1951,  1.1825, -0.2904],\n",
            "        [-1.7073,  0.6953,  0.5601],\n",
            "        [ 0.3515,  0.2281, -1.0343],\n",
            "        [-1.3647,  0.4809,  0.9393],\n",
            "        [-1.6215,  0.3888,  0.9679],\n",
            "        [-1.2823,  1.1843, -0.0806],\n",
            "        [-1.2827,  1.3214, -0.3155],\n",
            "        [-0.9298,  0.8576, -0.2620],\n",
            "        [-1.5876,  0.3846,  1.0366],\n",
            "        [ 0.4738,  0.1127, -1.2489],\n",
            "        [-1.3593,  1.3880, -0.3450]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.5855,  0.1628,  1.2013],\n",
            "        [-1.1385,  1.5414, -0.2419],\n",
            "        [-1.4008,  1.4636, -0.4019],\n",
            "        [-1.2866,  1.4169, -0.2155],\n",
            "        [-1.2277,  1.4692, -0.4315],\n",
            "        [-1.1951,  1.1825, -0.2904],\n",
            "        [-1.7073,  0.6953,  0.5601],\n",
            "        [ 0.3515,  0.2281, -1.0343],\n",
            "        [-1.3647,  0.4809,  0.9393],\n",
            "        [-1.6215,  0.3888,  0.9679],\n",
            "        [-1.2823,  1.1843, -0.0806],\n",
            "        [-1.2827,  1.3214, -0.3155],\n",
            "        [-0.9298,  0.8576, -0.2620],\n",
            "        [-1.5876,  0.3846,  1.0366],\n",
            "        [ 0.4738,  0.1127, -1.2489],\n",
            "        [-1.3593,  1.3880, -0.3450]], grad_fn=<AddmmBackward0>)\n",
            "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3280,  0.2643,  1.0397],\n",
            "        [-1.3828,  1.3660, -0.2644],\n",
            "        [-1.4650,  1.2303, -0.3299],\n",
            "        [-1.4290,  0.9939,  0.1496],\n",
            "        [-1.4727,  1.0039,  0.3342],\n",
            "        [-1.4573,  0.3789,  0.9871],\n",
            "        [-1.6132,  0.2944,  1.2294],\n",
            "        [-1.3493,  1.3592, -0.1101],\n",
            "        [-1.3368,  1.4265, -0.2145],\n",
            "        [-1.4603,  1.4539, -0.3017],\n",
            "        [-1.4661,  0.3666,  0.9550],\n",
            "        [-1.5135,  0.3873,  0.9126],\n",
            "        [-1.5073,  1.4797, -0.2143],\n",
            "        [-1.5975,  0.3499,  0.9059],\n",
            "        [-1.5099,  1.4472,  0.0490],\n",
            "        [-1.4847,  1.5136, -0.1943]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Student logits: tensor([[-1.3280,  0.2643,  1.0397],\n",
            "        [-1.3828,  1.3660, -0.2644],\n",
            "        [-1.4650,  1.2303, -0.3299],\n",
            "        [-1.4290,  0.9939,  0.1496],\n",
            "        [-1.4727,  1.0039,  0.3342],\n",
            "        [-1.4573,  0.3789,  0.9871],\n",
            "        [-1.6132,  0.2944,  1.2294],\n",
            "        [-1.3493,  1.3592, -0.1101],\n",
            "        [-1.3368,  1.4265, -0.2145],\n",
            "        [-1.4603,  1.4539, -0.3017],\n",
            "        [-1.4661,  0.3666,  0.9550],\n",
            "        [-1.5135,  0.3873,  0.9126],\n",
            "        [-1.5073,  1.4797, -0.2143],\n",
            "        [-1.5975,  0.3499,  0.9059],\n",
            "        [-1.5099,  1.4472,  0.0490],\n",
            "        [-1.4847,  1.5136, -0.1943]], grad_fn=<AddmmBackward0>)\n",
            "Epoch 3/3, Loss: 0.5899\n"
          ]
        }
      ],
      "source": [
        "# Now, distill the knowledge into the student model\n",
        "student_model = distillation_train_loop(student_model, teacher_model, train_dataset, val_dataset, tokenizer, epochs=3, batch_size=16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLc5yF0LNxL0"
      },
      "source": [
        "#### After the student model is trained, HuggingFace Trainer is used for evaluation. evaluate() method in Trainer does not perform training again, it only uses the student model in evaluation mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QItGe7pbNxL0",
        "outputId": "77bcba0d-5eab-4f9e-9aca-296a8673b32a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/kv/563b5k8n4xg24_t9kd2d72c40000gn/T/ipykernel_56174/4119820128.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_student = Trainer(\n",
            "100%|██████████| 61/61 [00:07<00:00,  7.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Results: {'eval_loss': 0.5431520938873291, 'eval_model_preparation_time': 0.0042, 'eval_runtime': 8.9747, 'eval_samples_per_second': 108.081, 'eval_steps_per_second': 6.797}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "trainer_student = Trainer(\n",
        "    model=student_model,\n",
        "    args=training_args,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "# Evaluate the student model\n",
        "results = trainer_student.evaluate()\n",
        "print(f\"Evaluation Results: {results}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qps1JiOnNxL0",
        "outputId": "62e593c8-e3d7-4cdd-8d60-267d16ad4ffd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 61/61 [00:07<00:00,  8.04it/s]\n"
          ]
        }
      ],
      "source": [
        "predictions = trainer_student.predict(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_4TEabMNxL0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "predicted_labels = np.argmax(predictions.predictions, axis=-1)\n",
        "\n",
        "true_labels = predictions.label_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "tL-48wM2NxL1",
        "outputId": "a80cec1c-8dfa-4f51-c9d0-595906f4d497"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'true_labels' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-8212b68ecbec>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'true_labels' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRuGcVRYNxL1"
      },
      "source": [
        "#### Student model as ROBERTA student model as DISTILBERT"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ROBERTA Robustly optimized BERT approach"
      ],
      "metadata": {
        "id": "L54d-8AZXvd7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473,
          "referenced_widgets": [
            "cc796ed43f0943aa87252c0ee28b1b3b",
            "4caa9a6ac69442f9ab0450b139e95eb4",
            "b6e2fd8d96634fb2a534dd6b15698a22",
            "39f2c80e1ab64616b439f7471fb962e2",
            "87c5899cbb49454d916dae5e538d6921",
            "821fe3969ecf4a8fa16fcf41f4b63245",
            "7883f670814a4fc2ab8721f045a546d2",
            "73a815c952694f95a4f24e87e976fe99",
            "3d829106523a44d88f2e601b678afd57",
            "2b047f99e112447293c61a5d18867c6e",
            "39cb6c79f830421c9e06680d7201a622",
            "d81f9632fad842c887e5ebce1392e53b",
            "d5a5293c7aaa49809d0cbccee172c90d",
            "6ad9f4feedad413ca632291d1d895ad4",
            "eca94c24ef4e47c488e2d44591afaece",
            "e45987e26c0f4e19a619290cab11808d",
            "926d2ba251ef4bcb8f50152d9ee19c38",
            "876eaa5fe2c647aa821dcb8062041949",
            "7cd2fe7dc1634194ab987946ae653747",
            "8d630aaa0c8b4ac9bff69fea11fd255d",
            "f660affabaf84b459014f70e73a34b9b",
            "3349b25fbfd4470b956bcb3212860bf6",
            "bbc9867e30d7467a892112c3c2c8e09d",
            "b7dd3edd50534299a182a285d6013b4c",
            "562fc31aeed049eb8340d025a576117a",
            "5c3fe3a6bb2540a29ed1feb34349d2ae",
            "4737cbd82ae04d74884f215ebdfb8ef9",
            "1bff35083e0142f28078382a022497ac",
            "fd9443e8355c4ae1ae01e028e971892c",
            "c434b8b0737f4c2ba5226716160ad782",
            "d4a79af63bd2468689126bbc6f6f6113",
            "f50848b024fc4f1eb0ee542573f43087",
            "29e5a64c98374e85a56b3377fd1d87bc",
            "d79c869da18043c0b8c27085f5a29836",
            "45c9c5010e694b519dc97c3d5b55204d",
            "a70465acb10f404ab2bc9ba8900dfde8",
            "7774a68a9968421aabf3e6d34fa0b768",
            "f68c7b588b4a42688ff5f45474bfdf00",
            "f9f8a9fd69a14fd4a639876e73482aa5",
            "9a6139027be348fbba8b6f64274de1e2",
            "9e6cdad9b4724431b5f7d39790fd8cb9",
            "2353661821054aeba24849371f6985db",
            "e309a6b4f66a4347bb4b59a9738562da",
            "f99da6587a6d40acb9305185fb2b1ec0",
            "e153c3bd81314717a4c02e4a25fdfd60",
            "89de1ef691a34a6c9f55f549770e82ef",
            "28d1fad381bd4e9b9cc5b8a39f8ad255",
            "e596e4c1a48f46f8a59442db31f8710c",
            "4e099c39b232403080aca190a85959f6",
            "4b78131d92594522a303bf353040286f",
            "f96dd57c31994d9fb6a40898413770ce",
            "15dca22ec4a349599849ee4fc12fe033",
            "4ac57e43c32b4dfebdf6b127d54d55c0",
            "f873926761b64924be7b31365092bd7f",
            "8248227f066a41cc92b43ee29b07c5fd",
            "8a99bd5d16594921b88726fabdee3047",
            "a28662be162f487e9e6175680b73c594",
            "e6c92df1dcbe4e62add2b4f04ac13752",
            "505e79841d764987baa5dd3ab00cb42a",
            "a69528d258384126bd9c3cbec914fdf5",
            "274a9f52ca444217ad4379bdfdfb1a97",
            "27fc02adf68c450fa172ebd2ee916740",
            "ec564c5b86104bc79ff1fdfe99e03d2e",
            "ecc9eb27efc4485fb9d84fa24769ed02",
            "65f13d5a86d2477e9c5e9b3aa0b34e23",
            "884c1ca35e164ba5a4e67fa8ebcda63b",
            "62b3fbe25259427e9b674341dcdd80bc",
            "b2b2f55792224161a6738eb145010acc",
            "c552bebb00cc436f9d9278955d030293",
            "a2a617f4fc7b44e3840a925beecda7a6",
            "ad00167ee8594ab98799b1865b216cc9",
            "265d98f0242948329451992c679864b5",
            "058b1b45489b4a85a45a6f319a8a7a84",
            "04ec2d2c4ac74de1acdb7431c80b44c4",
            "98c7049693644a73be336f38cd2f49d5",
            "ee88361a171d4ae38677013b92e2c6a3",
            "2f86dd6ad16d41ac817e9f4b0f70e3fe",
            "cf962cd2832c4275ab9e70e26d8c3b84",
            "1bca41cf53be44ad959c43396c3fef27",
            "03cf4f590ed1429585c6c2f811d200d9",
            "389725306482434d809a23e4213bc8f8",
            "c27ebb7aaa1e4c228d19ca56ec2c19e4",
            "1769cc70a8b54a57a1dccc0769ea3a44",
            "58bb73b9b5dd4a6e87e3c3e34028ac9d",
            "42232a169fd54cd5b5a7ef83314f30fd",
            "217983543e6b4f47a1096eeb931c14db",
            "ae60d05e58ff451aa827f3404deb994e",
            "5dc51965848e4a95b41c46f81cdd9b05",
            "c63b143d48c04736bddec5d4692d183b",
            "af0a1e42cd2b468ab52ac1616e2884dc",
            "b584dc8c36af40918c805f18550c4875",
            "173dd2ddf3d54579b9022035911f22ca",
            "0ec5234cb16f47fbb61d465f6611e765",
            "2ff323a4c3114eb694260f9cb4860cfb",
            "331cd4c22798444488d66f7301ed4326",
            "1e2563da59fb42a6bbf0f8e564c7352c",
            "a9378634621c4d41b857c3d655800e37",
            "8fac7def1d71488cbad4ce368025ce3d",
            "a99e1eec140b406dadbb1729c9ddeb38",
            "9d85b0cc11484bcda21566076a60fa29",
            "278b189d17a94d4c8716baef51231c87",
            "f9236505fbe44772a54f09e513214078",
            "32c5677db4dd40188a33758612ff0a8c",
            "ced1bb07e627446e9d5252dd92a8663b",
            "575e915229e646b6a35b5d00264be8b3",
            "fdbc28683ee6412db019ad2c5038dc81",
            "310256286b164c9b9c1bfffd903c5b80",
            "a64840cdccd049af8369d207e763c509",
            "e132e29eeb2944a6a4d42f741934c625",
            "d99acc8c08154dc283fbb1870b54b932",
            "01d53c5f9598484abcab0a7dd80ffb01",
            "8d6aaa788f8f418ba11df208451f523d",
            "a246421c572b43888dd14eef599b1848",
            "f9ec5142a0894d628f6b0f26956b135c",
            "82aa938087b94aa8831197ed5da1d360",
            "4880d7d55ee54702b1c506bc9536500b",
            "bbdc303c78824e969cdf91e7ab84837c",
            "d88bcedeedd8498cb7dd20a8e20eda6d",
            "679dbae97378472182c801bccc9457eb",
            "52d8f1ccfa7e45b2b1e7ab8988de53d7",
            "6550b6603f954c69900ed76f3943518f"
          ]
        },
        "id": "0DYlzXgENxL1",
        "outputId": "9c22d08b-57b9-4bb6-9c42-b7ffb10245b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc796ed43f0943aa87252c0ee28b1b3b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d81f9632fad842c887e5ebce1392e53b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bbc9867e30d7467a892112c3c2c8e09d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d79c869da18043c0b8c27085f5a29836"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/8.88k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e153c3bd81314717a4c02e4a25fdfd60"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "financial_phrasebank.py:   0%|          | 0.00/6.04k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a99bd5d16594921b88726fabdee3047"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FinancialPhraseBank-v1.0.zip:   0%|          | 0.00/682k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62b3fbe25259427e9b674341dcdd80bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/4846 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf962cd2832c4275ab9e70e26d8c3b84"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3488 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c63b143d48c04736bddec5d4692d183b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/388 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d85b0cc11484bcda21566076a60fa29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/970 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01d53c5f9598484abcab0a7dd80ffb01"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Initialize tokenizer and dataset\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "train_dataset, val_dataset, test_dataset = prepare_datasets(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "teacher_model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=3).to(device)\n",
        "student_model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3).to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234,
          "referenced_widgets": [
            "20f5d028c0474a0ba2e98e25860a1205",
            "fb9272a925454d6c9036b0f3d4353377",
            "b70ab834986b41038fba0ef72162ee7f",
            "89e92096d1c14a7e94beaa1495f67fb1",
            "2cd80a9c588a41c787485c9b50d1ee9b",
            "999600f2818945baa68c0848207ba7bc",
            "c9edfce94baa40c5860b3847b563973a",
            "49b290f52aeb44c686d9ccbbd82760c7",
            "4fb75c2b5e1645e28192942e7c79b221",
            "4a3bd7c145574917a529f93350b88ba5",
            "f07b4f9816ba465d9831442b525f8b06",
            "81b25174d3644dcfac081f38af483cd2",
            "45231c986ad54f8eac9e8228c37a9776",
            "f80c54e62e534506ae549e8c19cc3701",
            "acfb661688eb4efab919ac27e32f0169",
            "80d130db141b4eb8984cec34bd77e8c5",
            "6b26eef2f5c647aab835415befde3a1f",
            "040ba087a9604a8494d1cd16596ddfe0",
            "bc2dabcb3b2646c0b96a9ac1b173d172",
            "be182ae473034bf491987e53eac901ab",
            "05f16056c7f14e1abeae593038b0b47f",
            "591d341703684ddd9e066399e4792631",
            "022576b7c25f4b5a84fea8074889484e",
            "dde60a783f9041099d4fbf482e0e01fb",
            "85ca7b3567bc48b88b0a532ed5515ed0",
            "69a30cf114f946a48ed22ab4641fce2a",
            "cc9fb406f44d4d2aa7f99ce38a786666",
            "8a7a8a907ad44651897541d18369e4ba",
            "36ea293eb9f648deb45ef977f4cb7f4c",
            "0b16be197f1240c38ae8ed0d161b64b6",
            "756edbc5bd7249c3af4886b37de8ad51",
            "d71dbc2a17e94cec9bf62ac655edd997",
            "c30c05619ce8415fb9986e78fcda886c",
            "234bb7d87c0c4b73bf404a6a6dfa4765",
            "8ea25629432643dca574a27c2df44a90",
            "b8233f50a2af422aae48fae3c3690694",
            "9be476d492f74863b04b80f8ea5e0116",
            "5e510af2a5364f7e80c9e871ab594123",
            "9fb6133eafa74502a37fd94cbb680791",
            "f55e1c1e69d64f72bb26de4c5bb882cf",
            "17867e8ec4f444fab52efd318a8c6c7c",
            "f96e9c42190345cb92fbea40570c3c60",
            "788eaa03a52348c1af36d3c4b93e2b97",
            "9ef9949f227a444d8898d500e8c063fd"
          ]
        },
        "id": "p3woTZeaSRFK",
        "outputId": "75f5f735-1d3e-4c10-db75-b8ee02f89b54"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "20f5d028c0474a0ba2e98e25860a1205"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "81b25174d3644dcfac081f38af483cd2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "022576b7c25f4b5a84fea8074889484e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "234bb7d87c0c4b73bf404a6a6dfa4765"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_model = teacher_model.to(device)\n",
        "student_model = student_model.to(device)"
      ],
      "metadata": {
        "id": "wcbGSRFcTRVD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "tXA0JICmNxL1",
        "outputId": "032ebf53-0fbc-421d-c74b-d614ff3ecb2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "<ipython-input-14-f8fe41ae71b8>:20: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_teacher = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='654' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [654/654 02:11, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.938400</td>\n",
              "      <td>0.926514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.911400</td>\n",
              "      <td>0.926700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.909500</td>\n",
              "      <td>0.857801</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "import os\n",
        "\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "training_args_teacher = TrainingArguments(\n",
        "    output_dir=\"/content/results_knowledge_distill/teacher_model_ROBERTA\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"/content/logs_knowledge_distill/teacher_model_ROBERTA\",\n",
        "    logging_steps=10,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=False\n",
        ")\n",
        "\n",
        "trainer_teacher = Trainer(\n",
        "    model=teacher_model,\n",
        "    args=training_args_teacher,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "trainer_teacher.train()\n",
        "\n",
        "teacher_model.save_pretrained(\"/content/checkpoints/teacher_model_ROBERTA\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "DbFcNRK1NxL2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "\n",
        "def distillation_loss(student_logits, teacher_logits, true_labels, temperature, alpha):\n",
        "    device = student_logits.device\n",
        "    true_labels = true_labels.to(device)\n",
        "    teacher_logits = teacher_logits.to(device)\n",
        "\n",
        "    soft_labels = F.softmax(teacher_logits / temperature, dim=-1)\n",
        "\n",
        "    hard_loss = F.cross_entropy(student_logits, true_labels)\n",
        "\n",
        "    soft_loss = F.kl_div(\n",
        "        F.log_softmax(student_logits / temperature, dim=-1),\n",
        "        soft_labels,\n",
        "        reduction=\"batchmean\"\n",
        "    )\n",
        "\n",
        "    return alpha * soft_loss + (1 - alpha) * hard_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=16)\n",
        "\n",
        "optimizer = Adam(student_model.parameters(), lr=2e-5)"
      ],
      "metadata": {
        "id": "sy8GBPv7Vds6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "epochs = 3\n",
        "temperature = 2.0\n",
        "alpha = 0.5\n",
        "\n",
        "teacher_model.to(\"cuda\")\n",
        "teacher_model.eval()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    student_model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        inputs = {k: v.to(\"cuda\") for k, v in batch.items() if k in [\"input_ids\", \"attention_mask\"]}\n",
        "        labels = batch[\"labels\"].to(\"cuda\")\n",
        "\n",
        "        # Get teacher logits (soft labels)\n",
        "        with torch.no_grad():\n",
        "            teacher_logits = teacher_model(**inputs).logits\n",
        "\n",
        "        # Get student logits\n",
        "        student_outputs = student_model(**inputs)\n",
        "        student_logits = student_outputs.logits\n",
        "\n",
        "        # Calculate distillation loss\n",
        "        loss = distillation_loss(student_logits, teacher_logits, labels, temperature, alpha)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_dataloader)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16pvhTohVvnn",
        "outputId": "244a4331-d5e5-4274-b4b5-ba04c2cfca4a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.3367614353058535\n",
            "Epoch 2/3, Loss: 0.21890916695835394\n",
            "Epoch 3/3, Loss: 0.17549574200850016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "student_model.save_pretrained(\"/content/checkpoints/student_model\")"
      ],
      "metadata": {
        "id": "OMuUP4KgW1xw"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iX4GmkO_NxL2",
        "outputId": "24f79f93-c57d-4319-a4c7-5f419b877290"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Metrics: {'accuracy': 0.8530927835051546, 'precision': 0.8533877790196023, 'recall': 0.8530927835051546, 'f1': 0.8488220784681562}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs = {k: v.to(\"cuda\") for k, v in batch.items() if k in [\"input_ids\", \"attention_mask\"]}\n",
        "            labels = batch[\"labels\"].to(\"cuda\")\n",
        "\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits\n",
        "            preds = torch.argmax(logits, axis=-1).cpu().numpy()\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "            predictions.extend(preds)\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    precision = precision_score(true_labels, predictions, average=\"weighted\")\n",
        "    recall = recall_score(true_labels, predictions, average=\"weighted\")\n",
        "    f1 = f1_score(true_labels, predictions, average=\"weighted\")\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "val_metrics = evaluate_model(student_model, val_dataloader)\n",
        "print(f\"Validation Metrics: {val_metrics}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/checkpoints.zip /content/checkpoints"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T22RDXnvagoA",
        "outputId": "c7609876-15ca-449f-f9d0-39a4d6df4bbb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/checkpoints/ (stored 0%)\n",
            "  adding: content/checkpoints/teacher_model_ROBERTA/ (stored 0%)\n",
            "  adding: content/checkpoints/teacher_model_ROBERTA/model.safetensors (deflated 16%)\n",
            "  adding: content/checkpoints/teacher_model_ROBERTA/config.json (deflated 52%)\n",
            "  adding: content/checkpoints/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: content/checkpoints/student_model/ (stored 0%)\n",
            "  adding: content/checkpoints/student_model/model.safetensors (deflated 8%)\n",
            "  adding: content/checkpoints/student_model/config.json (deflated 47%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/logs_knowledge_distill.zip /content/logs_knowledge_distill"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvxaQeqYalJB",
        "outputId": "c7d82b47-0bbc-404f-8eb7-305a37433e3e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/logs_knowledge_distill/ (stored 0%)\n",
            "  adding: content/logs_knowledge_distill/teacher_model_ROBERTA/ (stored 0%)\n",
            "  adding: content/logs_knowledge_distill/teacher_model_ROBERTA/events.out.tfevents.1735121717.9c95ddbc12f4.631.1 (deflated 66%)\n",
            "  adding: content/logs_knowledge_distill/teacher_model_ROBERTA/events.out.tfevents.1735121576.9c95ddbc12f4.631.0 (deflated 62%)\n",
            "  adding: content/logs_knowledge_distill/.ipynb_checkpoints/ (stored 0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/results_knowledge_distill.zip /content/results_knowledge_distill"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlDxneaNaqp-",
        "outputId": "6f51d466-a47f-4c5a-e70f-f13082a79fb3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/results_knowledge_distill/ (stored 0%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/ (stored 0%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-218/ (stored 0%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-218/vocab.txt (deflated 53%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-218/tokenizer.json (deflated 71%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-218/scheduler.pt (deflated 56%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-218/trainer_state.json (deflated 72%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-218/optimizer.pt (deflated 32%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-218/tokenizer_config.json (deflated 75%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-218/model.safetensors (deflated 16%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-218/training_args.bin (deflated 52%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-218/rng_state.pth (deflated 25%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-218/special_tokens_map.json (deflated 42%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-218/config.json (deflated 52%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-654/ (stored 0%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-654/vocab.txt (deflated 53%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-654/tokenizer.json (deflated 71%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-654/scheduler.pt (deflated 56%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-654/trainer_state.json (deflated 78%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-654/optimizer.pt (deflated 32%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-654/tokenizer_config.json (deflated 75%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-654/model.safetensors (deflated 16%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-654/training_args.bin (deflated 52%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-654/rng_state.pth (deflated 25%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-654/special_tokens_map.json (deflated 42%)\n",
            "  adding: content/results_knowledge_distill/teacher_model_ROBERTA/checkpoint-654/config.json (deflated 52%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Parameter Search on Knowledge Distillation Model (alpha and temperature) initialization with the huggingface pretrained"
      ],
      "metadata": {
        "id": "hCb5ePWca5M9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=3).to(\"cuda\")\n",
        "teacher_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEyxZ1w5bnD2",
        "outputId": "4ff2341e-e2ff-426c-fc94-96d2dbc1be27"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temperature_values = [1.0, 2.0, 3.0]\n",
        "alpha_values = [0.3, 0.5, 0.7, 0.9]"
      ],
      "metadata": {
        "id": "Rktkmw0ha3un"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = None\n",
        "best_accuracy = float(\"-inf\")\n",
        "best_metrics = None"
      ],
      "metadata": {
        "id": "wb_wjVcqcp71"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grid search on combinations of temperature and alpha\n",
        "for temperature in temperature_values:\n",
        "    for alpha in alpha_values:\n",
        "        print(f\"Training with temperature={temperature}, alpha={alpha}...\")\n",
        "\n",
        "        # reinitialize student model for grid search\n",
        "        student_model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3).to(\"cuda\")\n",
        "        optimizer = Adam(student_model.parameters(), lr=2e-5)\n",
        "\n",
        "        # Using distillation loss, train the student model\n",
        "        epochs = 3 # use same epoch number on student model to comparasion\n",
        "        student_model.train()\n",
        "        for epoch in range(epochs):\n",
        "            total_loss = 0.0\n",
        "            for batch in train_dataloader:\n",
        "                inputs = {k: v.to(\"cuda\") for k, v in batch.items() if k in [\"input_ids\", \"attention_mask\"]}\n",
        "                labels = batch[\"labels\"].to(\"cuda\")\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    teacher_logits = teacher_model(**inputs).logits\n",
        "\n",
        "                student_outputs = student_model(**inputs)\n",
        "                student_logits = student_outputs.logits\n",
        "\n",
        "                loss = distillation_loss(student_logits, teacher_logits, labels, temperature, alpha)\n",
        "                total_loss += loss.item()\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        val_metrics = evaluate_model(student_model, val_dataloader)\n",
        "\n",
        "        print(f\"Validation Metrics: {val_metrics}\")\n",
        "\n",
        "        if val_metrics[\"accuracy\"] > best_accuracy:\n",
        "            best_accuracy = val_metrics[\"accuracy\"]\n",
        "            best_params = {\"temperature\": temperature, \"alpha\": alpha}\n",
        "            best_metrics = val_metrics\n",
        "\n",
        "print(f\"Best Hyperparameters: {best_params}\")\n",
        "print(f\"Best Validation Metrics: {best_metrics}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8ttS_nqcr4f",
        "outputId": "56f5840f-75fa-4c7e-e5a5-f07761aba96f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with temperature=1.0, alpha=0.3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Metrics: {'accuracy': 0.8298969072164949, 'precision': 0.8277090767909066, 'recall': 0.8298969072164949, 'f1': 0.8272837322500177}\n",
            "Training with temperature=1.0, alpha=0.5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Metrics: {'accuracy': 0.8350515463917526, 'precision': 0.8333853096865418, 'recall': 0.8350515463917526, 'f1': 0.8329165832696697}\n",
            "Training with temperature=1.0, alpha=0.7...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Metrics: {'accuracy': 0.8376288659793815, 'precision': 0.83652262516548, 'recall': 0.8376288659793815, 'f1': 0.8341876298292671}\n",
            "Training with temperature=1.0, alpha=0.9...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Metrics: {'accuracy': 0.7268041237113402, 'precision': 0.8252335533592452, 'recall': 0.7268041237113402, 'f1': 0.7438818285221023}\n",
            "Training with temperature=2.0, alpha=0.3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Metrics: {'accuracy': 0.8195876288659794, 'precision': 0.8193024880196635, 'recall': 0.8195876288659794, 'f1': 0.8183060526143721}\n",
            "Training with temperature=2.0, alpha=0.5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Metrics: {'accuracy': 0.8247422680412371, 'precision': 0.8286647536750384, 'recall': 0.8247422680412371, 'f1': 0.8258265651621475}\n",
            "Training with temperature=2.0, alpha=0.7...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Metrics: {'accuracy': 0.8273195876288659, 'precision': 0.8265293717175646, 'recall': 0.8273195876288659, 'f1': 0.8265522501139326}\n",
            "Training with temperature=2.0, alpha=0.9...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Metrics: {'accuracy': 0.8376288659793815, 'precision': 0.8363712992348918, 'recall': 0.8376288659793815, 'f1': 0.83396148679333}\n",
            "Training with temperature=3.0, alpha=0.3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Metrics: {'accuracy': 0.8195876288659794, 'precision': 0.8185384013102601, 'recall': 0.8195876288659794, 'f1': 0.8186497605684431}\n",
            "Training with temperature=3.0, alpha=0.5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Metrics: {'accuracy': 0.8324742268041238, 'precision': 0.8358861601546772, 'recall': 0.8324742268041238, 'f1': 0.8336759006449497}\n",
            "Training with temperature=3.0, alpha=0.7...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Metrics: {'accuracy': 0.8247422680412371, 'precision': 0.8267686221714032, 'recall': 0.8247422680412371, 'f1': 0.8184031965831681}\n",
            "Training with temperature=3.0, alpha=0.9...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Metrics: {'accuracy': 0.8273195876288659, 'precision': 0.8365388168347929, 'recall': 0.8273195876288659, 'f1': 0.8295179670912656}\n",
            "Best Hyperparameters: {'temperature': 1.0, 'alpha': 0.7}\n",
            "Best Validation Metrics: {'accuracy': 0.8376288659793815, 'precision': 0.83652262516548, 'recall': 0.8376288659793815, 'f1': 0.8341876298292671}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "42FeqQOPeiE0"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = {\n",
        "    (1.0, 0.3): {'accuracy': 0.8298969072164949, 'precision': 0.8277090767909066, 'recall': 0.8298969072164949, 'f1': 0.8272837322500177},\n",
        "    (1.0, 0.5): {'accuracy': 0.8350515463917526, 'precision': 0.8333853096865418, 'recall': 0.8350515463917526, 'f1': 0.8329165832696697},\n",
        "    (1.0, 0.7): {'accuracy': 0.8376288659793815, 'precision': 0.83652262516548, 'recall': 0.8376288659793815, 'f1': 0.8341876298292671},\n",
        "    (1.0, 0.9): {'accuracy': 0.7268041237113402, 'precision': 0.8252335533592452, 'recall': 0.7268041237113402, 'f1': 0.7438818285221023},\n",
        "    (2.0, 0.3): {'accuracy': 0.8195876288659794, 'precision': 0.8193024880196635, 'recall': 0.8195876288659794, 'f1': 0.8183060526143721},\n",
        "    (2.0, 0.5): {'accuracy': 0.8247422680412371, 'precision': 0.8286647536750384, 'recall': 0.8247422680412371, 'f1': 0.8258265651621475},\n",
        "    (2.0, 0.7): {'accuracy': 0.8273195876288659, 'precision': 0.8265293717175646, 'recall': 0.8273195876288659, 'f1': 0.8265522501139326},\n",
        "    (2.0, 0.9): {'accuracy': 0.8376288659793815, 'precision': 0.8363712992348918, 'recall': 0.8376288659793815, 'f1': 0.83396148679333},\n",
        "    (3.0, 0.3): {'accuracy': 0.8195876288659794, 'precision': 0.8185384013102601, 'recall': 0.8195876288659794, 'f1': 0.8186497605684431},\n",
        "    (3.0, 0.5): {'accuracy': 0.8324742268041238, 'precision': 0.8358861601546772, 'recall': 0.8324742268041238, 'f1': 0.8336759006449497},\n",
        "    (3.0, 0.7): {'accuracy': 0.8247422680412371, 'precision': 0.8267686221714032, 'recall': 0.8247422680412371, 'f1': 0.8184031965831681},\n",
        "    (3.0, 0.9): {'accuracy': 0.8273195876288659, 'precision': 0.8365388168347929, 'recall': 0.8273195876288659, 'f1': 0.8295179670912656},\n",
        "}\n",
        "\n",
        "data = []\n",
        "\n",
        "for (temperature, alpha), metrics in results.items():\n",
        "    row = {'temperature': temperature, 'alpha': alpha}\n",
        "    row.update(metrics)\n",
        "    data.append(row)\n",
        "\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "JxNwocEalSZP"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the figure\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.subplot(2, 2, 1)\n",
        "sns.heatmap(df.pivot(index=\"alpha\", columns=\"temperature\", values=\"accuracy\"), annot=True, cmap=\"Blues\", fmt=\".3f\", cbar_kws={'label': 'Accuracy'})\n",
        "plt.title(\"Accuracy vs Temperature and Alpha\")\n",
        "plt.xlabel(\"Temperature\")\n",
        "plt.ylabel(\"Alpha\")\n",
        "\n",
        "# Plot Precision\n",
        "plt.subplot(2, 2, 2)\n",
        "sns.heatmap(df.pivot(index=\"alpha\", columns=\"temperature\", values=\"precision\"), annot=True, cmap=\"Blues\", fmt=\".3f\", cbar_kws={'label': 'Precision'})\n",
        "plt.title(\"Precision vs Temperature and Alpha\")\n",
        "plt.xlabel(\"Temperature\")\n",
        "plt.ylabel(\"Alpha\")\n",
        "\n",
        "# Plot Recall\n",
        "plt.subplot(2, 2, 3)\n",
        "sns.heatmap(df.pivot(index=\"alpha\", columns=\"temperature\", values=\"recall\"), annot=True, cmap=\"Blues\", fmt=\".3f\", cbar_kws={'label': 'Recall'})\n",
        "plt.title(\"Recall vs Temperature and Alpha\")\n",
        "plt.xlabel(\"Temperature\")\n",
        "plt.ylabel(\"Alpha\")\n",
        "\n",
        "# Plot F1 Score\n",
        "plt.subplot(2, 2, 4)\n",
        "sns.heatmap(df.pivot(index=\"alpha\", columns=\"temperature\", values=\"f1\"), annot=True, cmap=\"Blues\", fmt=\".3f\", cbar_kws={'label': 'F1 Score'})\n",
        "plt.title(\"F1 Score vs Temperature and Alpha\")\n",
        "plt.xlabel(\"Temperature\")\n",
        "plt.ylabel(\"Alpha\")\n",
        "\n",
        "# Show the plots\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "h_-6ypocn4Gk",
        "outputId": "f56be17d-77dd-4c45-e273-9ffa871e941a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 8 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    {'temperature': 1.0, 'alpha': 0.3, 'accuracy': 0.8298969072164949, 'precision': 0.8277090767909066, 'recall': 0.8298969072164949, 'f1': 0.8272837322500177},\n",
        "    {'temperature': 1.0, 'alpha': 0.5, 'accuracy': 0.8350515463917526, 'precision': 0.8333853096865418, 'recall': 0.8350515463917526, 'f1': 0.8329165832696697},\n",
        "    {'temperature': 1.0, 'alpha': 0.7, 'accuracy': 0.8376288659793815, 'precision': 0.83652262516548, 'recall': 0.8376288659793815, 'f1': 0.8341876298292671},\n",
        "    {'temperature': 1.0, 'alpha': 0.9, 'accuracy': 0.7268041237113402, 'precision': 0.8252335533592452, 'recall': 0.7268041237113402, 'f1': 0.7438818285221023},\n",
        "    {'temperature': 2.0, 'alpha': 0.3, 'accuracy': 0.8195876288659794, 'precision': 0.8193024880196635, 'recall': 0.8195876288659794, 'f1': 0.8183060526143721},\n",
        "    {'temperature': 2.0, 'alpha': 0.5, 'accuracy': 0.825, 'precision': 0.829, 'recall': 0.825, 'f1': 0.826},\n",
        "    {'temperature': 2.0, 'alpha': 0.7, 'accuracy': 0.827, 'precision': 0.827, 'recall': 0.827, 'f1': 0.827},\n",
        "    {'temperature': 2.0, 'alpha': 0.9, 'accuracy': 0.838, 'precision': 0.836, 'recall': 0.838, 'f1': 0.834},\n",
        "    {'temperature': 3.0, 'alpha': 0.3, 'accuracy': 0.820, 'precision': 0.819, 'recall': 0.820, 'f1': 0.819},\n",
        "    {'temperature': 3.0, 'alpha': 0.5, 'accuracy': 0.832, 'precision': 0.836, 'recall': 0.832, 'f1': 0.834},\n",
        "    {'temperature': 3.0, 'alpha': 0.7, 'accuracy': 0.825, 'precision': 0.827, 'recall': 0.825, 'f1': 0.818},\n",
        "    {'temperature': 3.0, 'alpha': 0.9, 'accuracy': 0.827, 'precision': 0.837, 'recall': 0.827, 'f1': 0.830},\n",
        "]\n",
        "\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "-buvG1EPoRVB"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the figure\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.subplot(2, 2, 1)\n",
        "sns.barplot(x=\"temperature\", y=\"accuracy\", hue=\"alpha\", data=df,palette=\"Set1\")\n",
        "plt.title(\"Accuracy vs Temperature and Alpha\")\n",
        "plt.xlabel(\"Temperature\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "\n",
        "# Plot Precision\n",
        "plt.subplot(2, 2, 2)\n",
        "sns.barplot(x=\"temperature\", y=\"precision\", hue=\"alpha\", data=df,palette=\"Set1\")\n",
        "plt.title(\"Precision vs Temperature and Alpha\")\n",
        "plt.xlabel(\"Temperature\")\n",
        "plt.ylabel(\"Precision\")\n",
        "\n",
        "# Plot Recall\n",
        "plt.subplot(2, 2, 3)\n",
        "sns.barplot(x=\"temperature\", y=\"recall\", hue=\"alpha\", data=df,palette=\"Set1\")\n",
        "plt.title(\"Recall vs Temperature and Alpha\")\n",
        "plt.xlabel(\"Temperature\")\n",
        "plt.ylabel(\"Recall\")\n",
        "\n",
        "# Plot F1 Score\n",
        "plt.subplot(2, 2, 4)\n",
        "sns.barplot(x=\"temperature\", y=\"f1\", hue=\"alpha\", data=df,palette=\"Set1\")\n",
        "plt.title(\"F1 Score vs Temperature and Alpha\")\n",
        "plt.xlabel(\"Temperature\")\n",
        "plt.ylabel(\"F1 Score\")\n",
        "\n",
        "# Show the plots\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "Dc2LyPu9ob0G",
        "outputId": "229d18da-aebd-4026-cddf-1df4dbfe1597"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For gird search, train from strach for consistency"
      ],
      "metadata": {
        "id": "kwvDKamZplGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "train_dataset, val_dataset, test_dataset = prepare_datasets(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "294c99943cab4105bc8a5ade3389d09c",
            "66a116dee8d44d178eb4358d6f9333cf",
            "103662d5926849e9928d41f69229c04d",
            "99ebd88c07264ffead77a8f50e61146d",
            "865ef4d76507474eb339acda1e55b887",
            "64b889fd48c5413e95a310c3512f57e2",
            "baee1b71d81a4e99b392a21b25d2fef9",
            "d985874c44ad4ab49a2ab1f129bd1ed9",
            "5f5d7921c43949b88acd7f3c825baf24",
            "abf15fdde69041929a3a7a87f985717e",
            "423065e3030348a88d7915722956fa58",
            "2b38bb367b5e431d8a6940eca9c6acc9",
            "0d4ca7b2650f456aa0ffadbc9ad003dc",
            "6b5f145a4e8044b883d49d160b870a3b",
            "e7a70e69173d4e59b295686b118792b7",
            "95c9323911954e5e991ccd8100776b67",
            "0ad55f7095af4aa8883b4dac12ebbf5a",
            "59ae9eeb9b6049669c4c1283d2685587",
            "4ea8b9abeeb841519a902e9340be8204",
            "61a55d4bfdf8478fa6231ceb4b8a0a9f",
            "b020010c15c1497e8efa22228f664462",
            "a2e8b0cb0b794f0fa287a43cc9499693",
            "d57268467ef84fa29faecf1e0c5d0bc4",
            "c803c231c9ae42879e8c38f1e10f1e02",
            "d47e28a16f4f4934b5043d2da49cd131",
            "47eb3a97ceee4dcdb30c90f9b36e2b93",
            "25c78e76003f4ea0909117ed4328f7fb",
            "cdff912ba66d496db14eabbb454839d0",
            "c323c880909b4db1bd748634f0be8b4e",
            "0a5d0d786b4545b1995c367f36d5c556",
            "ed967468b2314992ab6da4383e9d4e5a",
            "ec36fb810f2045f7b2d1ded34b00b33b",
            "9f222d2ae8ea42728e20c41b73f04fe2"
          ]
        },
        "id": "MNqdMw-kjkqE",
        "outputId": "12182294-71f3-41df-eba8-6518a7ca9f74"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3488 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "294c99943cab4105bc8a5ade3389d09c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/388 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b38bb367b5e431d8a6940eca9c6acc9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/970 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d57268467ef84fa29faecf1e0c5d0bc4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args_teacher = TrainingArguments(\n",
        "    output_dir=\"/content/results_knowledge_distill/teacher_model_ROBERTA_grid_seach\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"/content/logs_knowledge_distill/teacher_model_ROBERTA_grid_search\",\n",
        "    logging_steps=10,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzFAU-EFptJx",
        "outputId": "c0106693-f466-44f2-d00f-213600e0ad15"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def distillation_loss(student_logits, teacher_logits, true_labels, temperature, alpha):\n",
        "    device = student_logits.device\n",
        "    true_labels = true_labels.to(device)\n",
        "    teacher_logits = teacher_logits.to(device)\n",
        "\n",
        "    soft_labels = F.softmax(teacher_logits / temperature, dim=-1)\n",
        "\n",
        "    hard_loss = F.cross_entropy(student_logits, true_labels)\n",
        "\n",
        "    soft_loss = F.kl_div(\n",
        "        F.log_softmax(student_logits / temperature, dim=-1),\n",
        "        soft_labels,\n",
        "        reduction=\"batchmean\"\n",
        "    )\n",
        "\n",
        "    return alpha * soft_loss + (1 - alpha) * hard_loss"
      ],
      "metadata": {
        "id": "qvBFXdORp0MZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation function\n",
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs = {k: v.to(\"cuda\") for k, v in batch.items() if k in [\"input_ids\", \"attention_mask\"]}\n",
        "            labels = batch[\"labels\"].to(\"cuda\")\n",
        "\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits\n",
        "            preds = torch.argmax(logits, axis=-1).cpu().numpy()\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "            predictions.extend(preds)\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    precision = precision_score(true_labels, predictions, average=\"weighted\")\n",
        "    recall = recall_score(true_labels, predictions, average=\"weighted\")\n",
        "    f1 = f1_score(true_labels, predictions, average=\"weighted\")\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n"
      ],
      "metadata": {
        "id": "SRAKrmfap4ZR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform grid search\n",
        "temperatures = [1.0, 2.0, 3.0]\n",
        "alphas = [0.3, 0.5, 0.7, 0.9]"
      ],
      "metadata": {
        "id": "B42BVjGWp6u5"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_metrics = {}\n",
        "best_params = {}"
      ],
      "metadata": {
        "id": "fVa_UV1Kp9TV"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start grid search\n",
        "for temperature in temperatures:\n",
        "    for alpha in alphas:\n",
        "        print(f\"Training with temperature={temperature}, alpha={alpha}...\")\n",
        "\n",
        "        teacher_model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=3).to(\"cuda\")\n",
        "        student_model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3).to(\"cuda\")\n",
        "\n",
        "        trainer_teacher = Trainer(\n",
        "            model=teacher_model,\n",
        "            args=training_args_teacher,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=val_dataset,\n",
        "            tokenizer=tokenizer\n",
        "        )\n",
        "        trainer_teacher.train()\n",
        "\n",
        "        teacher_model.save_pretrained(f\"/content/checkpoints/teacher_model_ROBERTA_{temperature}_{alpha}\")\n",
        "\n",
        "        train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "        val_dataloader = DataLoader(val_dataset, batch_size=16)\n",
        "\n",
        "        optimizer = Adam(student_model.parameters(), lr=2e-5)\n",
        "\n",
        "        student_model.train()\n",
        "        for epoch in range(3):  # training for 3 epochs\n",
        "            total_loss = 0.0\n",
        "            for batch in train_dataloader:\n",
        "                inputs = {k: v.to(\"cuda\") for k, v in batch.items() if k in [\"input_ids\", \"attention_mask\"]}\n",
        "                labels = batch[\"labels\"].to(\"cuda\")\n",
        "\n",
        "                # Get teacher logits (soft labels)\n",
        "                with torch.no_grad():\n",
        "                    teacher_logits = teacher_model(**inputs).logits\n",
        "\n",
        "                # Get student logits\n",
        "                student_outputs = student_model(**inputs)\n",
        "                student_logits = student_outputs.logits\n",
        "\n",
        "                # Calculate distillation loss\n",
        "                loss = distillation_loss(student_logits, teacher_logits, labels, temperature, alpha)\n",
        "                total_loss += loss.item()\n",
        "\n",
        "                # Backpropagation\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            print(f\"Epoch {epoch + 1}/3, Loss: {total_loss / len(train_dataloader)}\")\n",
        "\n",
        "        val_metrics = evaluate_model(student_model, val_dataloader)\n",
        "        print(f\"Validation Metrics: {val_metrics}\")\n",
        "\n",
        "        if best_metrics.get(\"f1\", 0) < val_metrics[\"f1\"]:\n",
        "            best_metrics = val_metrics\n",
        "            best_params = {\"temperature\": temperature, \"alpha\": alpha}\n",
        "\n",
        "print(f\"Best Hyperparameters: {best_params}\")\n",
        "print(f\"Best Metrics: {best_metrics}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3ZoxUVubp_R2",
        "outputId": "275de74a-0596-4f8e-f3ba-51300f773da5"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with temperature=1.0, alpha=0.3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-51-5219ad9dabdf>:9: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_teacher = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='654' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [654/654 02:15, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.844600</td>\n",
              "      <td>0.900884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.823600</td>\n",
              "      <td>0.825296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.808400</td>\n",
              "      <td>0.788450</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.46957809122603966\n",
            "Epoch 2/3, Loss: 0.3139647369127755\n",
            "Epoch 3/3, Loss: 0.26214407780848514\n",
            "Validation Metrics: {'accuracy': 0.8376288659793815, 'precision': 0.8398862824463537, 'recall': 0.8376288659793815, 'f1': 0.8310263073315738}\n",
            "Training with temperature=1.0, alpha=0.5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-51-5219ad9dabdf>:9: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_teacher = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='654' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [654/654 02:11, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.841100</td>\n",
              "      <td>0.879826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.793100</td>\n",
              "      <td>0.803001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.765800</td>\n",
              "      <td>0.790243</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.38276030704242375\n",
            "Epoch 2/3, Loss: 0.27664949922660076\n",
            "Epoch 3/3, Loss: 0.2400041089965663\n",
            "Validation Metrics: {'accuracy': 0.8170103092783505, 'precision': 0.837305730113012, 'recall': 0.8170103092783505, 'f1': 0.8050978025712996}\n",
            "Training with temperature=1.0, alpha=0.7...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-51-5219ad9dabdf>:9: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_teacher = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='654' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [654/654 02:14, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.841100</td>\n",
              "      <td>0.879826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.793100</td>\n",
              "      <td>0.803001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.765800</td>\n",
              "      <td>0.790243</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.2780301862763702\n",
            "Epoch 2/3, Loss: 0.20553818348487582\n",
            "Epoch 3/3, Loss: 0.1834566878547909\n",
            "Validation Metrics: {'accuracy': 0.7731958762886598, 'precision': 0.8038614148685745, 'recall': 0.7731958762886598, 'f1': 0.7499013506711274}\n",
            "Training with temperature=1.0, alpha=0.9...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-51-5219ad9dabdf>:9: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_teacher = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='654' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [654/654 02:12, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.841100</td>\n",
              "      <td>0.879826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.793100</td>\n",
              "      <td>0.803001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.765800</td>\n",
              "      <td>0.790243</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.15711717574148004\n",
            "Epoch 2/3, Loss: 0.10079986070615983\n",
            "Epoch 3/3, Loss: 0.08658158755220405\n",
            "Validation Metrics: {'accuracy': 0.7268041237113402, 'precision': 0.7564079141529226, 'recall': 0.7268041237113402, 'f1': 0.679571193818801}\n",
            "Training with temperature=2.0, alpha=0.3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-51-5219ad9dabdf>:9: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_teacher = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='654' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [654/654 02:14, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.841100</td>\n",
              "      <td>0.879826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.793100</td>\n",
              "      <td>0.803001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.765800</td>\n",
              "      <td>0.790243</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.43246159299251136\n",
            "Epoch 2/3, Loss: 0.2407882811347826\n",
            "Epoch 3/3, Loss: 0.17087770762656807\n",
            "Validation Metrics: {'accuracy': 0.8402061855670103, 'precision': 0.8446246537928913, 'recall': 0.8402061855670103, 'f1': 0.8337970427200434}\n",
            "Training with temperature=2.0, alpha=0.5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-51-5219ad9dabdf>:9: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_teacher = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='654' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [654/654 02:12, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.841100</td>\n",
              "      <td>0.879826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.793100</td>\n",
              "      <td>0.803001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.765800</td>\n",
              "      <td>0.790243</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.32840735608831456\n",
            "Epoch 2/3, Loss: 0.20358471411767357\n",
            "Epoch 3/3, Loss: 0.15899113712644358\n",
            "Validation Metrics: {'accuracy': 0.8479381443298969, 'precision': 0.8537685309654318, 'recall': 0.8479381443298969, 'f1': 0.8415580370495922}\n",
            "Training with temperature=2.0, alpha=0.7...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-51-5219ad9dabdf>:9: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_teacher = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='654' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [654/654 02:11, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.841100</td>\n",
              "      <td>0.879826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.793100</td>\n",
              "      <td>0.803001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.765800</td>\n",
              "      <td>0.790243</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.21858785745747591\n",
            "Epoch 2/3, Loss: 0.15075211585798395\n",
            "Epoch 3/3, Loss: 0.12697655259879356\n",
            "Validation Metrics: {'accuracy': 0.8427835051546392, 'precision': 0.8565280707269036, 'recall': 0.8427835051546392, 'f1': 0.8344957649991004}\n",
            "Training with temperature=2.0, alpha=0.9...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-51-5219ad9dabdf>:9: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_teacher = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='654' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [654/654 02:11, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.841100</td>\n",
              "      <td>0.879826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.793100</td>\n",
              "      <td>0.803001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.765800</td>\n",
              "      <td>0.790243</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.09844845671787722\n",
            "Epoch 2/3, Loss: 0.07122124693946007\n",
            "Epoch 3/3, Loss: 0.06378683687076656\n",
            "Validation Metrics: {'accuracy': 0.770618556701031, 'precision': 0.79751215618348, 'recall': 0.770618556701031, 'f1': 0.7470662566380434}\n",
            "Training with temperature=3.0, alpha=0.3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-51-5219ad9dabdf>:9: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_teacher = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='654' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [654/654 02:12, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.841100</td>\n",
              "      <td>0.879826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.793100</td>\n",
              "      <td>0.803001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.765800</td>\n",
              "      <td>0.790243</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.41921555661006804\n",
            "Epoch 2/3, Loss: 0.21598331165423088\n",
            "Epoch 3/3, Loss: 0.13979856992875217\n",
            "Validation Metrics: {'accuracy': 0.8350515463917526, 'precision': 0.839932334589111, 'recall': 0.8350515463917526, 'f1': 0.8276403683666697}\n",
            "Training with temperature=3.0, alpha=0.5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-51-5219ad9dabdf>:9: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_teacher = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='654' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [654/654 02:12, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.841100</td>\n",
              "      <td>0.879826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.793100</td>\n",
              "      <td>0.803001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.765800</td>\n",
              "      <td>0.790243</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.3105423928605854\n",
            "Epoch 2/3, Loss: 0.1741138709657783\n",
            "Epoch 3/3, Loss: 0.12415652197503715\n",
            "Validation Metrics: {'accuracy': 0.8376288659793815, 'precision': 0.8422299593421195, 'recall': 0.8376288659793815, 'f1': 0.830817962471834}\n",
            "Training with temperature=3.0, alpha=0.7...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-51-5219ad9dabdf>:9: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_teacher = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='654' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [654/654 02:13, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.841100</td>\n",
              "      <td>0.879826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.793100</td>\n",
              "      <td>0.803001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.765800</td>\n",
              "      <td>0.790243</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.19870037500054463\n",
            "Epoch 2/3, Loss: 0.12368139388774513\n",
            "Epoch 3/3, Loss: 0.09687098079796778\n",
            "Validation Metrics: {'accuracy': 0.8530927835051546, 'precision': 0.8584148108106562, 'recall': 0.8530927835051546, 'f1': 0.8474563176496248}\n",
            "Training with temperature=3.0, alpha=0.9...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-51-5219ad9dabdf>:9: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_teacher = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='654' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [654/654 02:12, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.841100</td>\n",
              "      <td>0.879826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.793100</td>\n",
              "      <td>0.803001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.765800</td>\n",
              "      <td>0.790243</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.08095941760944664\n",
            "Epoch 2/3, Loss: 0.05820950544481977\n",
            "Epoch 3/3, Loss: 0.0506890488771397\n",
            "Validation Metrics: {'accuracy': 0.8118556701030928, 'precision': 0.8387543611377265, 'recall': 0.8118556701030928, 'f1': 0.797773794031129}\n",
            "Best Hyperparameters: {'temperature': 3.0, 'alpha': 0.7}\n",
            "Best Metrics: {'accuracy': 0.8530927835051546, 'precision': 0.8584148108106562, 'recall': 0.8530927835051546, 'f1': 0.8474563176496248}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_from_new_training = [\n",
        "    {'temperature': 1.0, 'alpha': 0.3, 'accuracy': 0.8376288659793815, 'precision': 0.8398862824463537, 'recall': 0.8376288659793815, 'f1': 0.8310263073315738},\n",
        "    {'temperature': 1.0, 'alpha': 0.5, 'accuracy': 0.8170103092783, 'precision':0.83730573, 'recall':0.8170103, 'f1':0.805097 },\n",
        "    {'temperature': 1.0, 'alpha': 0.7, 'accuracy': 0.7731958762, 'precision': 0.8038614, 'recall': 0.7731958, 'f1': 0.7499013},\n",
        "    {'temperature': 1.0, 'alpha': 0.9, 'accuracy': 0.726804123, 'precision': 0.75640791, 'recall': 0.7268041, 'f1': 0.679571193},\n",
        "    {'temperature': 2.0, 'alpha': 0.3, 'accuracy': 0.84020618, 'precision': 0.84462465, 'recall': 0.84020618, 'f1': 0.833797},\n",
        "    {'temperature': 2.0, 'alpha': 0.5, 'accuracy': 0.84793814, 'precision': 0.8537685, 'recall': 0.8479381, 'f1': 0.84155},\n",
        "    {'temperature': 2.0, 'alpha': 0.7, 'accuracy': 0.8427835, 'precision': 0.856528, 'recall': 0.842783, 'f1': 0.834495},\n",
        "    {'temperature': 2.0, 'alpha': 0.9, 'accuracy': 0.7706185, 'precision': 0.797512, 'recall': 0.770618, 'f1': 0.7470662},\n",
        "    {'temperature': 3.0, 'alpha': 0.3, 'accuracy': 0.835051, 'precision': 0.8399, 'recall': 0.835051, 'f1': 0.82764},\n",
        "    {'temperature': 3.0, 'alpha': 0.5, 'accuracy': 0.8376288, 'precision': 0.84222, 'recall': 0.83762, 'f1': 0.830817},\n",
        "    {'temperature': 3.0, 'alpha': 0.7, 'accuracy': 0.853092, 'precision': 0.858414, 'recall': 0.8530927, 'f1': 0.847456},\n",
        "    {'temperature': 3.0, 'alpha': 0.9, 'accuracy': 0.8118556, 'precision': 0.838754, 'recall': 0.81185, 'f1': 0.79777},\n",
        "]\n",
        "\n",
        "df = pd.DataFrame(data_from_new_training)"
      ],
      "metadata": {
        "id": "mxipnYTxrgLQ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the figure\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.subplot(2, 2, 1)\n",
        "sns.barplot(x=\"temperature\", y=\"accuracy\", hue=\"alpha\", data=df,palette=\"Set1\")\n",
        "plt.title(\"Accuracy vs Temperature and Alpha\")\n",
        "plt.xlabel(\"Temperature\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "\n",
        "# Plot Precision\n",
        "plt.subplot(2, 2, 2)\n",
        "sns.barplot(x=\"temperature\", y=\"precision\", hue=\"alpha\", data=df,palette=\"Set1\")\n",
        "plt.title(\"Precision vs Temperature and Alpha\")\n",
        "plt.xlabel(\"Temperature\")\n",
        "plt.ylabel(\"Precision\")\n",
        "\n",
        "# Plot Recall\n",
        "plt.subplot(2, 2, 3)\n",
        "sns.barplot(x=\"temperature\", y=\"recall\", hue=\"alpha\", data=df,palette=\"Set1\")\n",
        "plt.title(\"Recall vs Temperature and Alpha\")\n",
        "plt.xlabel(\"Temperature\")\n",
        "plt.ylabel(\"Recall\")\n",
        "\n",
        "# Plot F1 Score\n",
        "plt.subplot(2, 2, 4)\n",
        "sns.barplot(x=\"temperature\", y=\"f1\", hue=\"alpha\", data=df,palette=\"Set1\")\n",
        "plt.title(\"F1 Score vs Temperature and Alpha\")\n",
        "plt.xlabel(\"Temperature\")\n",
        "plt.ylabel(\"F1 Score\")\n",
        "\n",
        "# Show the plots\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "89cXwG792CZl",
        "outputId": "1cb2eac4-ad0f-4a36-f7e4-d12467e08f65"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training knowledge distillation model with AdamW instead of Adam vis using best hyperparameters from grid search."
      ],
      "metadata": {
        "id": "Ri3DiBOKxiHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import AdamW\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "YAexGl11x5SW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "train_dataset, val_dataset, test_dataset = prepare_datasets(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473,
          "referenced_widgets": [
            "3ea94f93be2c47c3b327efeac6d63f46",
            "d251ef5062a04bb7be5bd692eec06537",
            "a50add41e3ba46c28422c841d84bc17f",
            "ae391878469d4cbca62735a3c9e3593a",
            "847a54bfba374d378db4f1433735b33a",
            "5493798603a84237ac575217159ee510",
            "dce04ac9f4ef4d4fbbea6626de54d595",
            "a620dc94421942c181ba2787e9b2116f",
            "045ad72477f94e818248f2213a0b9af0",
            "6ffaf54a38c745f5b458d84faf0a7d19",
            "3265b21e3ee24d3c8f3bb72722457805",
            "0cf46776d9fa45fd90eab28abed5dba9",
            "71adfc022bad4e518159bb16dc7f37a9",
            "6d5718ce15294efe9ac0f8202712fc67",
            "697467891e3c42d8b9f5a8b344d087c7",
            "f65fa75d374c444fa711f80a60781d74",
            "1c9dd3edc0204093b93865e1c953403d",
            "76a9bff016264784b57adf0ef30645d3",
            "321b024a316a4704b766a5c32d68c331",
            "d8210acd437c4ceaae1b0955991e462e",
            "5f4ec26e966841a68dcfd89872b8cc14",
            "9eb380d1a6d349679723d30f27624423",
            "35e79b41cf0b40a881c1d57be34187db",
            "d54c19c940a04f4eaeeda807e666ddf8",
            "33f9af79073f44259c6047009f38dad9",
            "b32a4e3f46c040fda479fe8529f7cdb7",
            "4631fa655457411eb7a0079d4e11b8a8",
            "c606831e2302431bac132233c793384d",
            "24ac7df9555a43ceb7f6260beab0e53e",
            "b01a7222d9944c2b96a6259bb212323a",
            "fe7fa85e337143829833404cd8ea7f3d",
            "69f82d11fa2e42ceb68769b70c261b23",
            "d852ad7b01364d418ae320eb4cf665b1",
            "5ce2455d893c47ae9d6f9554875395b2",
            "eebdced070f24a6da579ba5b68f8e1cc",
            "c221ae700bc24f17864790cd7ae65ca7",
            "e0d264c0dd634a50b34e07d5d07656cc",
            "93d3a53f1b1c425189357b10471ce9b5",
            "d2a367f85f424a91a2e5439d5b5f30fb",
            "f6483b02c1ef40e0be4d293255fda36c",
            "3b29616046914588b60e5ef2261cc57c",
            "b5ff000441834eb7b8f93ad5ad20c053",
            "4562b6000e5043cc9bd73d17dea84bfb",
            "f07f664ba51d454788761647e7e74dc2",
            "1d870f134ac244d29cc41ca0174a4151",
            "c6478ff659674af7b09dc6f11aee55fa",
            "fd6d62285dcd4412b00904ac833547ef",
            "82b5ea39072a4650a3bf3f3789f78804",
            "50575a756d3349748630a52089d471ed",
            "d9446adb28394b979e56dc5a670ad1c5",
            "9d829383f23f4418afecdbef6274defc",
            "cef517f1cae74f5d886ac7a732c8df11",
            "f2b4c65e7a63481a9ae7cca6cb29f5da",
            "7a6bffeda969445a9d83b8fe5d316814",
            "d48161278bc1401da52510783636fca4",
            "ef7650a97873452f91d39890435a98ad",
            "c66e2d9eaf814eeba86570f63c7af27c",
            "7088b7797d5a4a89b064260d168b6613",
            "8cbfd630ab7a45d2b6b022ac11809cde",
            "7af6e332f6bc4c6ea77650da1e7b1e64",
            "182ac60eac024a98975ccec3a757c881",
            "e41ea1032ad441439ba408988a28b1c1",
            "28a58a777917448c8fffbea11f3cce13",
            "5b746737162d4667979f59078922c133",
            "38eca8f68883437aac3709eb102b2985",
            "7c478921dd8648929223f3114a4148a4",
            "1cdc185ddb7a465da56816ae45f1cf7b",
            "c53be57a31004ecb9a85844f6d830e7d",
            "18962701146e48969d85fb2e527d9e3b",
            "79441464bf644c9587859709ba7b0e4c",
            "441bf149b2d441ce8f29b1f0c326a260",
            "00b4010ef7454da897ac9817ef82995d",
            "a7d03e3ea02447c89f317eca0bf95410",
            "c42e9c3b17d34b638051819e1be9d1f6",
            "0dfc9209147a4a73a25d7e631a164670",
            "bf9ebf70c7e8481a9905cec9e9b96cbd",
            "b03884a9939c4216a298b4667e842362",
            "9cbb25d7b591417ea41587c8e5abcf6d",
            "a8054768334544ae88bedab1fd845f81",
            "208912e528784fc290069c8825f63689",
            "be6f733b4b454462a94a16721b23375c",
            "2799434cdeca4deea94ba55d90cb0c02",
            "3d0e7e567c69492db343e871f79e209e",
            "8c05cffe4b71446c9f5da76cbe26e9c0",
            "eb3337a6fb6d4faaa27086cff730f25a",
            "f388c6f42b974a17b3b71d62640bc07c",
            "2aa7c80e422f4b0489f8182c1e8fb174",
            "940b5c639e0340b1a22f8f2c415c6521",
            "8303c0f9983a4dc8824b13c5fd848a47",
            "bb9e2147edba4440b317ae5ef367633e",
            "e1a71e2ebfb84795a312ce69ec7952c1",
            "f6995bf8da5143a9b910e8e7ab5802d1",
            "d76087cf48c84132a217d6b9c49f81f4",
            "7a033f75cb1f4c3ca68e4b42f81e7e46",
            "96e71d0f93a84271a70d9d1fbefb93dd",
            "c09e80640b764822aa2c7619b5b51ff5",
            "0cfb6b4b7de64b69a057de732f570da0",
            "802962e0bb9c45eaa01ab45ca8a44e4b",
            "129b3bff1fe4476c8cd1c60658eb5db2",
            "54d90c60be5b444090640bb64f92e1b8",
            "918ff5ed1e154bd0a1dfae717202cb1f",
            "a44dd9186dc64df5bc5c733e768de16e",
            "14d34f9037cf4752af7a4d15e58dc3e2",
            "7e64d77b302147d189f7734444b8f528",
            "7973da519d244ebe8b454db0e83cc782",
            "7035433411134808add473ceaf3e9042",
            "c2e7113e410a44769be9fa3525acbb6f",
            "cc15d8e664a0466ebb999a041363799c",
            "0b056c63972b4147b6970d532a118ee4",
            "0fe4340bab814c59ba546bfd88629b78",
            "30fc8368fe114f3d926b8b678ea83134",
            "f4a79859b5d1463593af1be3136ea600",
            "292e5d84fbc743de974a7e23b69c1924",
            "c25718c6a56643e1a68974e739b86d79",
            "dc91cf645ad745b68bfc0ec20f1eaf34",
            "01e415e354084d8a911f83fcee186fbb",
            "2c1c4c0699a24bfe8b772f7102714d98",
            "375d1ed18766409f8c5d6068b009fac8",
            "4967fdc80dcf437494fa0398475c8c75",
            "a92578d806174717b1c6c72751ff70a3",
            "b6ffced1184c4ac9bc6fbff42fe764b0"
          ]
        },
        "id": "4PCOJkwn2PUX",
        "outputId": "fbd4fb74-4635-47be-9a20-274ae93f2285"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ea94f93be2c47c3b327efeac6d63f46"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0cf46776d9fa45fd90eab28abed5dba9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35e79b41cf0b40a881c1d57be34187db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ce2455d893c47ae9d6f9554875395b2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/8.88k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d870f134ac244d29cc41ca0174a4151"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "financial_phrasebank.py:   0%|          | 0.00/6.04k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef7650a97873452f91d39890435a98ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FinancialPhraseBank-v1.0.zip:   0%|          | 0.00/682k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1cdc185ddb7a465da56816ae45f1cf7b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/4846 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9cbb25d7b591417ea41587c8e5abcf6d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3488 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8303c0f9983a4dc8824b13c5fd848a47"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/388 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54d90c60be5b444090640bb64f92e1b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/970 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30fc8368fe114f3d926b8b678ea83134"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=3).to(\"cuda\")\n",
        "student_model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3).to(\"cuda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234,
          "referenced_widgets": [
            "60d3a594358b466db95388d2f4a8dff7",
            "1aee4f3317414e299f7fa16840084eb0",
            "ff52808c6f604e24ae3bf22b4a0ac1a1",
            "a2dfccc8aed7479a8e1528604c6a3928",
            "8d653f5fe9694dad8d944183c85ed049",
            "db89d8754d784f70a2d8b07032c78059",
            "da2eec3efa734ce0963894f12ac19cd3",
            "649dfb9e88a245a78f69389504d02aa9",
            "af40086a735b4c92b28e189217ae0924",
            "bf4fae3e0b7f4f368cdf4fa73018b3f5",
            "3f3908468d6945c28baf0b3f9513bb83",
            "d8fd87db63084027bb9e9400cb054f2c",
            "f9bc1b1167b64a7e98950f5b3a58858b",
            "668cb65bce494fb2978fda9944f9b0c5",
            "9f100e4e254f4cc4ac263276e25e5039",
            "1c8000d24b5f411dad234c9939cd853f",
            "62627d28a87b4ae8a54363c7f218d993",
            "41d2b118411d4e388f5742ccfb6c5d37",
            "60b68694694b431c9a3b33419b24a51a",
            "51402aefc5ae44f0aaff296522588b3a",
            "a2fcf238f2a34603935f5f59c86c8de6",
            "5a481181d95b4267b108ec097c08665a",
            "af32c1ca1a9b4ea49cce948190b289db",
            "01afd12bd01f48acaa83232755262378",
            "30c63fd1711148c9ac1ba71ffcd0a31b",
            "fe779f86209c46d897e957963d427fb8",
            "5364f8537d184223898d702633d7366a",
            "217c64f050c7420da78849e65dc9adab",
            "c8b2668160b34bd5a1f3e39475749d69",
            "cf563f4cb3b843039a647111fa384aa7",
            "ab1f469244724fddb4a3e50374647f88",
            "09c1c7241a434aadace4c74ba51d522f",
            "bc859d3841ea48d98663dc2fae197317",
            "6621c65327df4f43a61d5342d9b9b5f5",
            "75c977beee554d2cbec5ef2feb911ed7",
            "85b848c3139b43ca87a07fac9f6c970c",
            "43a3731694d84095b4c9080ef65a80ef",
            "041c5c476e4f40578e4d7bb2b03b46c1",
            "ec7b5bf2fb0041a4ab2ac03ac9417cf8",
            "c77d14a9d6b64389834039a2e9315bb7",
            "f212c7f48083499b8538629a10329b28",
            "4fcad4750734436b99bfc4aed4ce63d2",
            "c21ffed75e66498a80422599bceefa2c",
            "d0ca6d3cf8ce437f88db40c144cf98af"
          ]
        },
        "id": "VPHFRguwxs24",
        "outputId": "65e64792-8588-4462-b388-90180a32fd2e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "60d3a594358b466db95388d2f4a8dff7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8fd87db63084027bb9e9400cb054f2c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af32c1ca1a9b4ea49cce948190b289db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6621c65327df4f43a61d5342d9b9b5f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args_teacher = TrainingArguments(\n",
        "    output_dir=\"/content/teacher_model\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"/content/logs_teacher\",\n",
        "    logging_steps=10,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=False,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlXzYp-szUSc",
        "outputId": "c3f8c0d0-06fd-4bc9-d081-714f078704aa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "trainer_teacher = Trainer(\n",
        "    model=teacher_model,\n",
        "    args=training_args_teacher,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "trainer_teacher.train()\n",
        "\n",
        "teacher_model.save_pretrained(\"./teacher_model\")\n",
        "print(\"Teacher model training completed and saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "6Ha1wnTnztxf",
        "outputId": "9109d092-ef13-4778-9807-57b8601e3450"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-4ce791a62616>:5: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_teacher = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='654' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [654/654 02:11, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.819600</td>\n",
              "      <td>0.863598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.817700</td>\n",
              "      <td>0.887446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.824100</td>\n",
              "      <td>0.823151</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher model training completed and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=16)"
      ],
      "metadata": {
        "id": "5Bb_PkvxxxNA"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(student_model.parameters(), lr=2e-5)"
      ],
      "metadata": {
        "id": "QySdiQHfxz21"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temperature = 3.0\n",
        "alpha = 0.7\n",
        "epochs = 3"
      ],
      "metadata": {
        "id": "z3x5EUSO0qJE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_model.eval()\n",
        "for epoch in range(epochs):\n",
        "    student_model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        inputs = {k: v.to(\"cuda\") for k, v in batch.items() if k in [\"input_ids\", \"attention_mask\"]}\n",
        "        labels = batch[\"labels\"].to(\"cuda\")\n",
        "\n",
        "        # Get teacher logits (soft labels)\n",
        "        with torch.no_grad():\n",
        "            teacher_logits = teacher_model(**inputs).logits\n",
        "\n",
        "        # Get student logits\n",
        "        student_outputs = student_model(**inputs)\n",
        "        student_logits = student_outputs.logits\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = distillation_loss(student_logits, teacher_logits, labels, temperature, alpha)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_dataloader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oq3QAGKoyGYD",
        "outputId": "f1eff1da-fe0a-4625-95fd-550ddf45b7c2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.20505645566987335\n",
            "Epoch 2/3, Loss: 0.12929951218426775\n",
            "Epoch 3/3, Loss: 0.10490229590838655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "val_metrics = evaluate_model(student_model, val_dataloader)\n",
        "print(f\"Validation Metrics with AdamW: {val_metrics}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yd_va3VKyLBH",
        "outputId": "24b0112c-512f-4394-fd80-22343fd1a08a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Metrics with AdamW: {'accuracy': 0.8402061855670103, 'precision': 0.8423849425605004, 'recall': 0.8402061855670103, 'f1': 0.8354557587007766}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "student_model.save_pretrained(\"/content/student_model\")\n",
        "print(\"Student model training completed and saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOyF4Su601SW",
        "outputId": "0f401d84-0e96-4a35-917d-1dfd9d0b9967"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student model training completed and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training with RMSProp"
      ],
      "metadata": {
        "id": "Dz1i-1s92c_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_model = AutoModelForSequenceClassification.from_pretrained(\"./teacher_model\").to(\"cuda\")\n",
        "teacher_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UyfQlOZ2lHD",
        "outputId": "79507aa1-2aba-4211-a3da-08dceb657c6d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=16)"
      ],
      "metadata": {
        "id": "DRzxVHkS3ZY9"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3).to(\"cuda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuZVbtun3Zv8",
        "outputId": "d296ff3e-0fe3-4f75-c3c1-8bb5481dca2d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import RMSprop\n",
        "\n",
        "lr = 2e-5\n",
        "weight_decay = 1e-2\n",
        "optimizer = RMSprop(student_model.parameters(), lr=lr, weight_decay=weight_decay)"
      ],
      "metadata": {
        "id": "kfEmI_KE3cgj"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 3\n",
        "temperature = 3.0\n",
        "alpha = 0.7"
      ],
      "metadata": {
        "id": "xS8LW6Zm3jSd"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    student_model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        inputs = {k: v.to(\"cuda\") for k, v in batch.items() if k in [\"input_ids\", \"attention_mask\"]}\n",
        "        labels = batch[\"labels\"].to(\"cuda\")\n",
        "\n",
        "        # Get teacher logits\n",
        "        with torch.no_grad():\n",
        "            teacher_logits = teacher_model(**inputs).logits\n",
        "\n",
        "        # Get student logits\n",
        "        student_outputs = student_model(**inputs)\n",
        "        student_logits = student_outputs.logits\n",
        "\n",
        "        # Calculate distillation loss\n",
        "        loss = distillation_loss(student_logits, teacher_logits, labels, temperature, alpha)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_dataloader)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqrsTtVp3sV7",
        "outputId": "b144abed-eca4-4071-e293-7d5287a7ba35"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.20615704227751547\n",
            "Epoch 2/3, Loss: 0.15681191127097935\n",
            "Epoch 3/3, Loss: 0.14590958153846068\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_metrics = evaluate_model(student_model, val_dataloader)\n",
        "print(f\"Validation Metrics with RMSProp: {val_metrics}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALRlla3j3vPy",
        "outputId": "0b6ba5af-bd82-4315-cb4f-8c5075822535"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Metrics with RMSProp: {'accuracy': 0.8170103092783505, 'precision': 0.8250155837928553, 'recall': 0.8170103092783505, 'f1': 0.8194498555951912}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "adam_metrics = {'accuracy': 0.8530927835051546, 'precision': 0.8584148108106562, 'recall': 0.8530927835051546, 'f1': 0.8474563176496248}\n",
        "adamw_metrics = {'accuracy': 0.8402061855670103, 'precision': 0.8423849425605004, 'recall': 0.8402061855670103, 'f1': 0.8354557587007766}\n",
        "rmsprop_metrics = {'accuracy': 0.8170103092783505, 'precision': 0.8250155837928553, 'recall': 0.8170103092783505, 'f1': 0.8194498555951912}\n",
        "\n",
        "labels = list(adam_metrics.keys())\n",
        "adam_values = list(adam_metrics.values())\n",
        "adamw_values = list(adamw_metrics.values())\n",
        "rmsprop_values = list(rmsprop_metrics.values())\n",
        "\n",
        "x = np.arange(len(labels))\n",
        "width = 0.25\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Adam\n",
        "plt.bar(x - width, adam_values, width, label='Adam', color='skyblue')\n",
        "\n",
        "# AdamW\n",
        "plt.bar(x, adamw_values, width, label='AdamW', color='orange')\n",
        "\n",
        "# RMSProp\n",
        "plt.bar(x + width, rmsprop_values, width, label='RMSProp', color='green')\n",
        "\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Values')\n",
        "plt.title('Comparison of Metrics for Adam, AdamW, and RMSProp')\n",
        "plt.xticks(x, labels)\n",
        "plt.ylim(0.8, 0.9)\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "VUyblb3s1yME",
        "outputId": "769826a8-61d1-48b3-ee6f-14f006d99452"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cvs5EjedLqEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "train_dataset, val_dataset, test_dataset = prepare_datasets(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "1e9c1c46e5e047bd8cb684d13886013f",
            "e2cdbbd4a3424520a6ebb09bc74c7af2",
            "a5dcc0c182724a3bae001e0deb4a4d7c",
            "29a102965c204875b5bec85f9bba3604",
            "421bea71d3b048ecbd9115b834b09b9f",
            "6ee1fa012c154d05b4a2d345971147ce",
            "e5bdbf0c24df4f89b9d7a1f8b6d2a830",
            "9be71a1bed124b8e89cf80f54b7c6df9",
            "2102f42f71474f8183d2a6194eb40e8a",
            "c8311b90d5dc49f58df4928b364f0c66",
            "31931c560c1a4b3ab1aedfaf43f60746",
            "cb385cd3a657465f887eb9636e4d1e61",
            "ba2f4e81d9da481fb2cb3296216bc86b",
            "b0896aa404174af2bc3649de7189a8bc",
            "7bdf7505592e47b196e38ac8ac648dbb",
            "db551e3a1b324f488482235a1cc1642d",
            "3b7065d6f22740a8a8e89bb09a8f89a5",
            "5144aa490b864c03aefb4922f2139874",
            "5c7415e3372b46a79265cc4ea87abf7c",
            "54e41e5e061d47cd816d4522e2d41c36",
            "89b517e41a1d4d44a87113867d742581",
            "de1ccc808f5d49a09cd1a4409e22e98c",
            "61b0064a987c4eaaab1de4d2d6b0839f",
            "97ed1e74a10c4f419c721fef78ddfb38",
            "c6a9c659220b424196e6afa62c8f15a9",
            "76e894c5636642ef9749c8ccd6bfe95e",
            "9b0eb44785844238aee578d9eee7c05b",
            "2d1806828cb84eb7b4df71de972ef186",
            "ce5da91bb4364a4b978eb17a58483e90",
            "616f7eff1f1242e3b9d504596391b1dd",
            "89108ebaf3e14c618c9bcda81101892a",
            "60705742dd534de99dcaf5dbab7c2268",
            "8b14967666e54795bc7f49b8752c36e7"
          ]
        },
        "id": "Gh33H0jLMLOz",
        "outputId": "28798104-26f7-4489-fea5-98f6c265536a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3488 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e9c1c46e5e047bd8cb684d13886013f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/388 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb385cd3a657465f887eb9636e4d1e61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/970 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61b0064a987c4eaaab1de4d2d6b0839f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=3).to(\"cuda\")\n",
        "student_model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3).to(\"cuda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWuTkshsMLg7",
        "outputId": "1282d04b-32fe-41c9-e6c1-954be7028026"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args_teacher = TrainingArguments(\n",
        "    output_dir=\"/content/teacher_model\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"/content/logs_teacher\",\n",
        "    logging_steps=10,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\",\n",
        ")"
      ],
      "metadata": {
        "id": "BntQxFfmMPk8"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_teacher = Trainer(\n",
        "    model=teacher_model,\n",
        "    args=training_args_teacher,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "trainer_teacher.train()\n",
        "teacher_model.save_pretrained(\"/content/teacher_model\")\n",
        "print(\"Teacher model training completed and saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "3YDjdD-5MTIM",
        "outputId": "660badb0-7063-47ce-84a4-794090bbd38b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-d8957b978b70>:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_teacher = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='654' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [654/654 02:18, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.819100</td>\n",
              "      <td>0.872136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.778600</td>\n",
              "      <td>0.798452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.780900</td>\n",
              "      <td>0.775193</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher model training completed and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments, AutoTokenizer\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import torch\n",
        "from torch.optim import Adam\n",
        "import os"
      ],
      "metadata": {
        "id": "JSqMmsAwM42D"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(student_model.parameters(), lr=2e-5)"
      ],
      "metadata": {
        "id": "u0BviMZWMgwB"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scheduler = CosineAnnealingLR(optimizer, T_max=3)"
      ],
      "metadata": {
        "id": "r9-PdaPpMmPD"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=16)"
      ],
      "metadata": {
        "id": "yiflTDaLMmzJ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_model.eval()\n",
        "epochs = 3\n",
        "temperature = 3.0\n",
        "alpha = 0.7"
      ],
      "metadata": {
        "id": "um4ws_BnMovw"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "lr_values = []\n",
        "for epoch in range(epochs):\n",
        "    student_model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        inputs = {k: v.to(\"cuda\") for k, v in batch.items() if k in [\"input_ids\", \"attention_mask\"]}\n",
        "        labels = batch[\"labels\"].to(\"cuda\")\n",
        "\n",
        "        # Get teacher's logits (soft labels)\n",
        "        with torch.no_grad():\n",
        "            teacher_outputs = teacher_model(**inputs)\n",
        "            teacher_logits = teacher_outputs.logits\n",
        "\n",
        "        # Get student's logits\n",
        "        student_outputs = student_model(**inputs)\n",
        "        student_logits = student_outputs.logits\n",
        "\n",
        "        # Calculate the distillation loss\n",
        "        loss = distillation_loss(student_logits, teacher_logits, labels, temperature, alpha)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "        lr_values.append(optimizer.param_groups[0]['lr'])\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_dataloader)}\")\n",
        "\n",
        "# Plot the learning rate vs. training step\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(lr_values, label=\"Learning Rate (Cosine Annealing)\")\n",
        "plt.title(\"Learning Rate Schedule (Cosine Annealing)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Save the trained student model\n",
        "student_model.save_pretrained(\"/content/student_model_with_teacher_and_cosine_annealing\")\n",
        "print(\"Student model training completed and saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "e8c1P5GuMzeB",
        "outputId": "d947be76-c986-4a22-b4d0-bc652a0ebdaa"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.22757045890486569\n",
            "Epoch 2/3, Loss: 0.13817361202261863\n",
            "Epoch 3/3, Loss: 0.11139411561259437\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student model training completed and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "\n",
        "val_metrics = evaluate_model(student_model, val_dataloader)\n",
        "print(f\"Validation Metrics with Cosine Annealing: {val_metrics}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvrKKQTMNlnY",
        "outputId": "855c9f36-81b8-4c4a-f933-dd305d384560"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Metrics with Cosine Annealing: {'accuracy': 0.8324742268041238, 'precision': 0.8307641957126493, 'recall': 0.8324742268041238, 'f1': 0.8304944620333393}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "cosine_annealing_metrics = {\n",
        "    'accuracy': 0.8324742268041238,\n",
        "    'precision': 0.8307641957126493,\n",
        "    'recall': 0.8324742268041238,\n",
        "    'f1': 0.8304944620333393\n",
        "}\n",
        "\n",
        "no_cosine_annealing_metrics = {\n",
        "    'accuracy': 0.8530927835051546,\n",
        "    'precision': 0.8584148108106562,\n",
        "    'recall': 0.8530927835051546,\n",
        "    'f1': 0.8474563176496248\n",
        "}\n",
        "\n",
        "labels = list(cosine_annealing_metrics.keys())\n",
        "\n",
        "cosine_annealing_values = list(cosine_annealing_metrics.values())\n",
        "no_cosine_annealing_values = list(no_cosine_annealing_metrics.values())\n",
        "\n",
        "x = np.arange(len(labels))\n",
        "width = 0.35\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.bar(x - width/2, cosine_annealing_values, width, label='Cosine Annealing', color='skyblue')\n",
        "plt.bar(x + width/2, no_cosine_annealing_values, width, label='No Cosine Annealing', color='orange')\n",
        "\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Values')\n",
        "plt.title('Comparison of Evaluation Metrics: Cosine Annealing vs No Cosine Annealing')\n",
        "plt.xticks(x, labels)\n",
        "plt.ylim(0.8, 0.9)\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "i37YM9-gOACb",
        "outputId": "0e5a088d-ee19-4208-e533-8f0d41da321d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Metrics for each model\n",
        "metrics = {\n",
        "    'DistilBERT': {'accuracy': 0.832268, 'f1': 0.832058, 'precision': 0.834176, 'recall': 0.832268},\n",
        "    'BERT Base': {'accuracy': 0.816495, 'f1': 0.818883, 'precision': 0.825575, 'recall': 0.816495},\n",
        "    'LoRA BERT': {'accuracy': 0.680412, 'f1': 0.650444, 'precision': 0.655943, 'recall': 0.680412},\n",
        "    'ModernBert': {'accuracy': 0.831237, 'f1': 0.831361, 'precision': 0.832849, 'recall': 0.831237},\n",
        "    'GPT 3.5': {'accuracy': 0.693814, 'f1': 0.699329, 'precision': 0.768728, 'recall': 0.693814},\n",
        "    'GPT 4': {'accuracy': 0.827835, 'f1': 0.824299, 'precision': 0.826397, 'recall': 0.827835},\n",
        "    'Knowledge Distillation': {'accuracy': 0.8530927835051546, 'f1': 0.8488220784681562,\n",
        "                               'precision': 0.8533877790196023, 'recall': 0.8530927835051546}\n",
        "}\n",
        "\n",
        "labels = list(metrics['DistilBERT'].keys())\n",
        "models = list(metrics.keys())\n",
        "\n",
        "values = {metric: [] for metric in labels}\n",
        "for model in models:\n",
        "    for metric in labels:\n",
        "        values[metric].append(metrics[model][metric])\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "colors = plt.cm.get_cmap('tab10', len(models))\n",
        "color_list = [colors(i) for i in range(len(models))]\n",
        "\n",
        "for i, metric in enumerate(labels):\n",
        "    ax = axes[i//2, i%2]\n",
        "    ax.bar(models, values[metric], color=color_list)\n",
        "    ax.set_title(f'{metric.capitalize()} Comparison')\n",
        "    ax.set_xlabel('Models')\n",
        "    ax.set_ylabel(f'{metric.capitalize()} Score')\n",
        "\n",
        "    y_max = max(values[metric])\n",
        "    ax.set_ylim(0, y_max + 0.05)\n",
        "\n",
        "    ax.set_xticklabels(models, rotation=45, ha=\"right\")\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aUp9W4fpPdYx",
        "outputId": "6e47e0e5-4b4a-4239-8cf4-07b078f2b837"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-44-c07633f50181>:30: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
            "  colors = plt.cm.get_cmap('tab10', len(models))  # Use a colormap to get distinct colors\n",
            "<ipython-input-44-c07633f50181>:45: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
            "  ax.set_xticklabels(models, rotation=45, ha=\"right\")\n",
            "<ipython-input-44-c07633f50181>:45: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
            "  ax.set_xticklabels(models, rotation=45, ha=\"right\")\n",
            "<ipython-input-44-c07633f50181>:45: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
            "  ax.set_xticklabels(models, rotation=45, ha=\"right\")\n",
            "<ipython-input-44-c07633f50181>:45: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
            "  ax.set_xticklabels(models, rotation=45, ha=\"right\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x1000 with 4 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABW0AAAPdCAYAAADxjUr8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdeVhU5fvH8XtAWVVcAUUEt0QzRVHIPRX3JC3LVpDKLNfCyjAVd9TKLCtNcym1pMz6WpplpFZmWiouqYj7Ci4lKCoi3L8//HFiBA1kYAZ5v65rrkuec87MPcdh5sM95zzHpKoqAAAAAAAAAACbYGftAgAAAAAAAAAA/6JpCwAAAAAAAAA2hKYtAAAAAAAAANgQmrYAAAAAAAAAYENo2gIAAAAAAACADaFpCwAAAAAAAAA2hKYtAAAAAAAAANgQmrYAAAAAAAAAYENo2gIAAAAAAACADaFpCwAolnx9faVfv37WLgMAAAB3kH79+omvr6+1ywAAmrYArOeDDz4Qk8kkQUFB1i6lWEpKSpKXX35Z/Pz8xMXFRVxdXSUgIEAmTpwo58+ft3Z5AAAAsJCFCxeKyWTK9fbaa68Z6/3www/yzDPPSMOGDcXe3v62mo9XrlyRt99+W4KCgsTNzU2cnJzkrrvuksGDB8u+ffss+KwAALdiUlW1dhEASqZWrVrJyZMn5fDhw5KQkCB16tSxdknFxh9//CHdu3eXixcvypNPPikBAQEiIvLnn3/K0qVLpWXLlvLDDz9YucrClZaWJnZ2dlK6dGlrlwIAAFCoFi5cKOHh4TJ+/HipWbOm2bKGDRuKv7+/iFw/SjQmJkaaNm0qR48eFXt7ezl8+HCeH+fs2bPStWtX2bJli9x///0SHBwsZcqUkfj4eFm6dKkkJibK1atXLfjMbE96erpkZmaKo6OjtUsBUMKVsnYBAEqmQ4cOyW+//SbLly+XAQMGyJIlSyQqKsraZeUqNTVVXF1drV2G4fz589K7d2+xt7eXbdu2iZ+fn9nySZMmydy5c61UXeFSVbly5Yo4OzsTpAEAQInTrVs3adas2U2XT548WebOnSulS5eW+++/X3bt2pWv++/Xr59s27ZNli1bJg899JDZsgkTJsjrr79+W3UXB1mZnwMCANgKpkcAYBVLliyRChUqSI8ePaRPnz6yZMmSXNc7f/68vPTSS+Lr6yuOjo5SvXp1CQ0NlbNnzxrrXLlyRcaOHSt33XWXODk5SdWqVeXBBx+UAwcOiIjIunXrxGQyybp168zu+/Dhw2IymWThwoXGWL9+/aRMmTJy4MAB6d69u5QtW1aeeOIJERH55Zdf5OGHH5YaNWqIo6OjeHt7y0svvSSXL1/OUffevXvlkUcekSpVqoizs7PUq1fPCLlr164Vk8kkX331VY7tPv30UzGZTLJx48ab7rsPP/xQTpw4IdOnT8/RsBUR8fDwkFGjRpmNffDBB3L33XeLo6OjVKtWTQYNGpRjCoX77rtPGjZsKDt27JB27dqJi4uL1KlTR5YtWyYiIuvXr5egoCDj+fz4449m248dO1ZMJpPx3MuVKyeVKlWSYcOGyZUrV8zWXbBggXTo0EHc3d3F0dFRGjRoILNmzcrxXHx9feX++++X77//Xpo1aybOzs7y4YcfGsuyz2mbnp4u48aNk7p164qTk5NUqlRJWrduLWvWrDG7z59++knatGkjrq6uUr58eXnggQdkz549uT6X/fv3S79+/aR8+fLi5uYm4eHhcunSpVz+VwAAAKyvWrVqt9103LRpk6xcuVKeeeaZHA1bERFHR0d58803zcbyk6v27dsnTz75pLi5uUmVKlVk9OjRoqpy7NgxeeCBB6RcuXLi6ekpb731ltn2WVk+JiZGRo4cKZ6enuLq6iohISFy7Ngxs3Xzmtdvlflzm9N26dKlEhAQIGXLlpVy5crJPffcI++8847ZOgcPHpSHH35YKlasKC4uLnLvvffKypUrc30un3/+uUyaNEmqV68uTk5O0rFjR9m/f/9N/mcAlFQcaQvAKpYsWSIPPvigODg4yGOPPSazZs2SP/74Q5o3b26sc/HiRWnTpo3s2bNHnn76aWnatKmcPXtWVqxYIcePH5fKlStLRkaG3H///RIbGyuPPvqoDBs2TC5cuCBr1qyRXbt2Se3atfNd27Vr16RLly7SunVrefPNN8XFxUVERL744gu5dOmSvPDCC1KpUiXZvHmzzJw5U44fPy5ffPGFsf2OHTukTZs2Urp0aXnuuefE19dXDhw4IN98841MmjRJ7rvvPvH29pYlS5ZI7969c+yX2rVrS4sWLW5a34oVK8TZ2Vn69OmTp+czduxYGTdunAQHB8sLL7wg8fHxxv7esGGDWbD/559/5P7775dHH31UHn74YZk1a5Y8+uijsmTJEnnxxRfl+eefl8cff1zeeOMN6dOnjxw7dkzKli1r9niPPPKI+Pr6SnR0tPz+++/y7rvvyj///COffPKJsc6sWbPk7rvvlpCQEClVqpR88803MnDgQMnMzJRBgwaZ3V98fLw89thjMmDAAOnfv7/Uq1fvps8zOjpann32WQkMDJSUlBT5888/ZevWrdKpUycREfnxxx+lW7duUqtWLRk7dqxcvnxZZs6cKa1atZKtW7fmCOiPPPKI1KxZU6Kjo2Xr1q3y0Ucfibu7u0ydOjVP+x4AAMCSkpOTzQ5eEBGpXLmyRe57xYoVIiLy1FNP5Wn9/Oaqvn37Sv369WXKlCmycuVKmThxolSsWFE+/PBD6dChg0ydOlWWLFkiL7/8sjRv3lzatm1rtv2kSZPEZDLJiBEj5PTp0zJjxgwJDg6WuLg4cXZ2FpG853WRm2f+G61Zs0Yee+wx6dixo5EB9+zZIxs2bJBhw4aJyPVrTbRs2VIuXbokQ4cOlUqVKsnHH38sISEhsmzZshyZf8qUKWJnZycvv/yyJCcny7Rp0+SJJ56QTZs25WnfAyghFACK2J9//qkiomvWrFFV1czMTK1evboOGzbMbL0xY8aoiOjy5ctz3EdmZqaqqs6fP19FRKdPn37TddauXasiomvXrjVbfujQIRURXbBggTEWFhamIqKvvfZajvu7dOlSjrHo6Gg1mUx65MgRY6xt27ZatmxZs7Hs9aiqRkZGqqOjo54/f94YO336tJYqVUqjoqJyPE52FSpU0MaNG99ynez36eDgoJ07d9aMjAxj/L333lMR0fnz5xtj7dq1UxHRTz/91Bjbu3evioja2dnp77//box///33OfZdVFSUioiGhISY1TBw4EAVEd2+fbsxltu+7NKli9aqVctszMfHR0VEV69enWN9Hx8fDQsLM35u3Lix9ujR4xZ7Q9Xf31/d3d313Llzxtj27dvVzs5OQ0NDczyXp59+2mz73r17a6VKlW75GAAAAJa2YMECFZFcbzfTo0cP9fHxyfNj9O7dW0VE//nnnzytn99c9dxzzxlj165d0+rVq6vJZNIpU6YY4//88486OzubZbysLO/l5aUpKSnG+Oeff64iou+8844xlte8fqvMHxYWZrbfhg0bpuXKldNr167ddF+8+OKLKiL6yy+/GGMXLlzQmjVrqq+vr5HDs55L/fr1NS0tzVj3nXfeURHRnTt33vQxAJQ8TI8AoMgtWbJEPDw8pH379iIiYjKZpG/fvrJ06VLJyMgw1vvyyy+lcePGOb6Zztoma53KlSvLkCFDbrrO7XjhhRdyjGV9gy9yfc6rs2fPSsuWLUVVZdu2bSIicubMGfn555/l6aeflho1aty0ntDQUElLSzOmHhARiYmJkWvXrsmTTz55y9pSUlJyHN16Mz/++KNcvXpVXnzxRbGz+/ctv3///lKuXLkcp2yVKVNGHn30UePnevXqSfny5aV+/foSFBRkjGf9++DBgzke88YjZbP+b1atWmWMZd+XWUeMtGvXTg4ePCjJyclm29esWVO6dOnyn8+1fPny8tdff0lCQkKuy0+dOiVxcXHSr18/qVixojHeqFEj6dSpk1l9WZ5//nmzn9u0aSPnzp2TlJSU/6wHAADA0t5//31Zs2aN2c1SsvJNXnLm7eSqZ5991vi3vb29NGvWTFRVnnnmGWO8fPnyUq9evVwzZmhoqFltffr0kapVq940Y94sr2eXW+a/Ufny5SU1NfWW+3rVqlUSGBgorVu3NsbKlCkjzz33nBw+fFh2795ttn54eLg4ODgYP7dp00ZEcs/WAEoumrYAilRGRoYsXbpU2rdvL4cOHZL9+/fL/v37JSgoSJKSkiQ2NtZY98CBA9KwYcNb3t+BAwekXr16UqqU5WZ7KVWqlFSvXj3H+NGjR41gWqZMGalSpYq0a9dORMRoNGYFrf+q28/PT5o3b242l++SJUvk3nvvlTp16txy23LlysmFCxfy9FyOHDkiIpJjSgEHBwepVauWsTxL9erVczS73dzcxNvbO8eYyPXpFG5Ut25ds59r164tdnZ2Zlcu3rBhgwQHBxvzn1WpUkVGjhwpIpJr0zYvxo8fL+fPn5e77rpL7rnnHnnllVdkx44dxvKb7QsRkfr168vZs2clNTXVbPzGxnuFChVEJPfnDQAAUNgCAwMlODjY7GYp5cqVExHJU860RK5yc3MTJyenHNM7uLm55SljmkwmqVOnjlnGzEtez3KzzH+jgQMHyl133SXdunWT6tWry9NPPy2rV682W+fIkSM33RdZy7MjYwLIC5q2AIrUTz/9JKdOnZKlS5dK3bp1jdsjjzwiInLTC5IVxM2OuM1+VG92jo6OZkelZq3bqVMnWblypYwYMUK+/vprWbNmjXERs8zMzHzXFRoaKuvXr5fjx4/LgQMH5Pfff//Po2xFrjd89+3bJ1evXs33Y/4Xe3v7fI2r6n/e5437/8CBA9KxY0c5e/asTJ8+XVauXClr1qyRl156SURy7svsR0zcStu2beXAgQMyf/58adiwoXz00UfStGlT+eijj/K0fW4K8rwBAACKk6wL3O7cubNQ7j+3XGXJrJXfvJ5b5s+Nu7u7xMXFyYoVKyQkJETWrl0r3bp1k7CwsHzXmIWMCSAvuBAZgCK1ZMkScXd3l/fffz/HsuXLl8tXX30ls2fPFmdnZ6ldu7bs2rXrlvdXu3Zt2bRpk6Snp9/0SrlZ31yfP3/ebPzGb7xvZefOnbJv3z75+OOPJTQ01Bi/8TSpWrVqiYj8Z90iIo8++qhERETIZ599JpcvX5bSpUtL3759/3O7nj17ysaNG+XLL7+Uxx577Jbr+vj4iMj1i3ll1SYicvXqVTl06JBFj87IkpCQYHZ07P79+yUzM9O4GMU333wjaWlpsmLFCrOjDNauXVvgx65YsaKEh4dLeHi4XLx4Udq2bStjx46VZ5991mxf3Gjv3r1SuXJlcXV1LXANAAAAxVHPnj0lOjpaFi9ebJyufzPWyFU3ToGlqrJ//35p1KiRiOQ9r98OBwcH6dmzp/Ts2VMyMzNl4MCB8uGHH8ro0aOlTp064uPjc9N9IfLv/gKA/OBIWwBF5vLly7J8+XK5//77pU+fPjlugwcPlgsXLhhXrn3ooYdk+/bt8tVXX+W4r6xvoR966CE5e/asvPfeezddx8fHR+zt7eXnn382W/7BBx/kufasb8Ozf/utqvLOO++YrVelShVp27atzJ8/X44ePZprPVkqV64s3bp1k8WLF8uSJUuka9euebr67/PPPy9Vq1aV4cOHy759+3IsP336tEycOFFERIKDg8XBwUHeffdds8efN2+eJCcnS48ePf7z8fLrxob8zJkzRUSkW7duIpL7vkxOTpYFCxYU6HHPnTtn9nOZMmWkTp06kpaWJiIiVatWFX9/f/n444/NGvi7du2SH374Qbp3716gxwcAACjOWrRoIV27dpWPPvpIvv766xzLr169Ki+//LKIWCdXffLJJ2ZTNyxbtkxOnTp1y4yZW17Prxszpp2dndEozsqZ3bt3l82bN8vGjRuN9VJTU2XOnDni6+srDRo0KFANAEomjrQFUGRWrFghFy5ckJCQkFyX33vvvVKlShVZsmSJ9O3bV1555RVZtmyZPPzww/L0009LQECA/P3337JixQqZPXu2NG7cWEJDQ+WTTz6RiIgI2bx5s7Rp00ZSU1Plxx9/lIEDB8oDDzwgbm5u8vDDD8vMmTPFZDJJ7dq15dtvv5XTp0/nuXY/Pz+pXbu2vPzyy3LixAkpV66cfPnll7nOO/Xuu+9K69atpWnTpvLcc89JzZo15fDhw7Jy5UqJi4szWzc0NFT69OkjIiITJkzIUy0VKlSQr776Srp37y7+/v7y5JNPSkBAgIiIbN26VT777DNp0aKFiFxvIkdGRsq4ceOka9euEhISIvHx8fLBBx9I8+bN8zQdQ34dOnRIQkJCpGvXrrJx40ZZvHixPP7449K4cWMREencubNxtMKAAQPk4sWLMnfuXHF3d5dTp07d9uM2aNBA7rvvPgkICJCKFSvKn3/+KcuWLZPBgwcb67zxxhvSrVs3adGihTzzzDNy+fJlmTlzpri5ucnYsWML+tQBAACsaseOHcYBEPv375fk5GTjy/zGjRtLz549b7n9J598Ip07d5YHH3xQevbsKR07dhRXV1dJSEiQpUuXyqlTp+TNN98UkaLPVRUrVpTWrVtLeHi4JCUlyYwZM6ROnTrSv39/EclfXs+PZ599Vv7++2/p0KGDVK9eXY4cOSIzZ84Uf39/Y87a1157TT777DPp1q2bDB06VCpWrCgff/yxHDp0SL788ss8TcMAADkoABSRnj17qpOTk6ampt50nX79+mnp0qX17Nmzqqp67tw5HTx4sHp5eamDg4NWr15dw8LCjOWqqpcuXdLXX39da9asqaVLl1ZPT0/t06ePHjhwwFjnzJkz+tBDD6mLi4tWqFBBBwwYoLt27VIR0QULFhjrhYWFqaura6617d69W4ODg7VMmTJauXJl7d+/v27fvj3Hfaiq7tq1S3v37q3ly5dXJycnrVevno4ePTrHfaalpWmFChXUzc1NL1++nJfdaDh58qS+9NJLetddd6mTk5O6uLhoQECATpo0SZOTk83Wfe+999TPz09Lly6tHh4e+sILL+g///xjtk67du307rvvzvE4Pj4+2qNHjxzjIqKDBg0yfo6KilIR0d27d2ufPn20bNmyWqFCBR08eHCO57ZixQpt1KiROjk5qa+vr06dOlXnz5+vIqKHDh36z8fOWhYWFmb8PHHiRA0MDNTy5curs7Oz+vn56aRJk/Tq1atm2/3444/aqlUrdXZ21nLlymnPnj119+7dZutkPZczZ86YjS9YsCBHjQAAAIUtK4P88ccfeVovt1v23HQrly5d0jfffFObN2+uZcqUUQcHB61bt64OGTJE9+/fb7ZuQXLVzXL3jZl07dq1KiL62WefaWRkpLq7u6uzs7P26NFDjxw5YrZtXvP6rTJ/WFiY+vj4GD8vW7ZMO3furO7u7urg4KA1atTQAQMG6KlTp8y2O3DggPbp08fI/4GBgfrtt9+arZP1XL744guz8UOHDuX6NwWAks2kykzXAGAt165dk2rVqknPnj1l3rx51i6nQMaOHSvjxo2TM2fO5GmaBwAAAOC/rFu3Ttq3by9ffPGFcYYaAJQEHKMPAFb09ddfy5kzZ8wulgAAAAAAAEo25rQFACvYtGmT7NixQyZMmCBNmjSRdu3aWbskAAAAAABgIzjSFgCsYNasWfLCCy+Iu7u7fPLJJ9YuBwAAAAAA2BDmtAUAAAAAAAAAG8KRtgAAAAAAAABgQ0rcnLaZmZly8uRJKVu2rJhMJmuXAwAAgHxQVblw4YJUq1ZN7OxK7vEHZFoAAIDiKa95tsQ1bU+ePCne3t7WLgMAAAAFcOzYMalevbq1y7AaMi0AAEDx9l95tsQ1bcuWLSsi13dMuXLlrFwNAAAA8iMlJUW8vb2NTFdSkWkBAACKp7zm2RLXtM06faxcuXIEXAAAgGKqpE8JQKYFAAAo3v4rz5bcicAAAAAAAAAAwAbRtAUAAAAAAAAAG0LTFgAAAAAAAABsCE1bAAAAAAAAALAhNG0BAAAAAAAAwIbQtAUAAAAAAAAAG0LTFgAAAAAAAABsCE1bAAAAAAAAALAhNG0BAAAAAAAAwIbQtAUAAAAAAAAAG0LTFgAAAAAAAABsCE1bAAAAAAAAALAhNG0BAAAAAAAAwIbQtAUAAAAAAAAAG1LK2gUAAAAUN55r46xdgs1IbO9v7RIAAABwG8i0/7LFTMuRtgAAAAAAAABgQ2jaAgAAAAAAAIANoWkLAAAAAAAAADaEpi0AAAAAAAAA2BCatgAAAAAAAABgQ0pZuwAAAAAAts/3tZXWLsFmHJ7Sw9olAIXmrb73W7sEmzE85ltrlwCgBKNpW0QIuf8i5AIAAAAAAAA3R9MWACyIIxP+xZEJAAAAAADcHpq2AACUALE/1bZ2CTajY4cD1i4BAAAAt4FM+y8y7Z2PC5EBAAAAAAAAgA3hSFsAAAAAKGpj3axdge0Ym2ztCgAAsDkcaQsAAAAAAAAANoQjbVH8cFTCvzgqAQAAAAAA4I7DkbYAAABAAb3//vvi6+srTk5OEhQUJJs3b77l+jNmzJB69eqJs7OzeHt7y0svvSRXrlwpomoBAABg66zetCXgAgAAoDiLiYmRiIgIiYqKkq1bt0rjxo2lS5cucvr06VzX//TTT+W1116TqKgo2bNnj8ybN09iYmJk5MiRRVw5AAAAbJVVm7YEXAAAABR306dPl/79+0t4eLg0aNBAZs+eLS4uLjJ//vxc1//tt9+kVatW8vjjj4uvr6907txZHnvssVsevJCWliYpKSlmNwAAANy5rNq0JeACAACgOLt69aps2bJFgoODjTE7OzsJDg6WjRs35rpNy5YtZcuWLUaGPXjwoKxatUq6d+9+08eJjo4WNzc34+bt7W3ZJwIAAACbYrWmLQEXAAAAxd3Zs2clIyNDPDw8zMY9PDwkMTEx120ef/xxGT9+vLRu3VpKly4ttWvXlvvuu++WZ49FRkZKcnKycTt27JhFnwcAAABsi9WatgRcAAAAlETr1q2TyZMnywcffCBbt26V5cuXy8qVK2XChAk33cbR0VHKlStndgMAAMCdq5S1C8iP7AE3KChI9u/fL8OGDZMJEybI6NGjc93G0dFRHB0di7hSAAAAlASVK1cWe3t7SUpKMhtPSkoST0/PXLcZPXq0PPXUU/Lss8+KiMg999wjqamp8txzz8nrr78udnZWv1YwAAAArMxqibCgAfeee+6R3r17y+TJkyU6OloyMzOLomwAAADA4ODgIAEBARIbG2uMZWZmSmxsrLRo0SLXbS5dupSjMWtvby8iIqpaeMUCAACg2LBa05aACwAAgDtBRESEzJ07Vz7++GPZs2ePvPDCC5Kamirh4eEiIhIaGiqRkZHG+j179pRZs2bJ0qVL5dChQ7JmzRoZPXq09OzZ08i2AAAAKNmsOj1CRESEhIWFSbNmzSQwMFBmzJiRI+B6eXlJdHS0iFwPuNOnT5cmTZoY0yMQcAEAAGBNffv2lTNnzsiYMWMkMTFR/P39ZfXq1ca1G44ePWp24MGoUaPEZDLJqFGj5MSJE1KlShXp2bOnTJo0yVpPAQAAADbGqk1bAi4AAADuBIMHD5bBgwfnumzdunVmP5cqVUqioqIkKiqqCCoDAABAcWT1C5ERcAEAAAAAAADgX1yaFgAAAAAAAABsCE1bAAAAAAAAALAhNG0BAAAAAAAAwIbQtAUAAAAAAAAAG0LTFgAAAAAAAABsCE1bAAAAAAAAALAhNG0BAAAAAAAAwIbQtAUAAAAAAAAAG0LTFgAAAAAAAABsCE1bAAAAAAAAALAhNG0BAAAAAAAAwIbQtAUAAAAAAAAAG0LTFgAAAAAAAABsCE1bAAAAAAAAALAhNG0BAAAAAAAAwIbQtAUAAAAAAAAAG0LTFgAAAAAAAABsCE1bAAAAAAAAALAhNG0BAAAAAAAAwIbQtAUAAAAAAAAAG0LTFgAAAAAAAABsCE1bAAAAAAAAALAhNG0BAACAAnr//ffF19dXnJycJCgoSDZv3nzTde+77z4xmUw5bj169CjCigEAAGDLaNoCAAAABRATEyMRERESFRUlW7dulcaNG0uXLl3k9OnTua6/fPlyOXXqlHHbtWuX2Nvby8MPP1zElQMAAMBW0bQFAAAACmD69OnSv39/CQ8PlwYNGsjs2bPFxcVF5s+fn+v6FStWFE9PT+O2Zs0acXFxuWXTNi0tTVJSUsxuAAAAuHOVsnYBAAAAQHF19epV2bJli0RGRhpjdnZ2EhwcLBs3bszTfcybN08effRRcXV1vek60dHRMm7cuALXCwAoWsdf+8XaJdiM6lPaWLsEoFjhSFsAAADgNp09e1YyMjLEw8PDbNzDw0MSExP/c/vNmzfLrl275Nlnn73lepGRkZKcnGzcjh07VqC6AQAAYNs40hYAAACwknnz5sk999wjgYGBt1zP0dFRHB0di6gqAAAAWBtNWwCAzeJ0sn9xOhlgmypXriz29vaSlJRkNp6UlCSenp633DY1NVWWLl0q48ePL8wSAQAAUAwxPQIAAABwmxwcHCQgIEBiY2ONsczMTImNjZUWLVrcctsvvvhC0tLS5MknnyzsMgEAAFDMcKQtAAAAUAARERESFhYmzZo1k8DAQJkxY4akpqZKeHi4iIiEhoaKl5eXREdHm203b9486dWrl1SqVMkaZQMAAMCG0bQFAAAACqBv375y5swZGTNmjCQmJoq/v7+sXr3auDjZ0aNHxc7O/AS3+Ph4+fXXX+WHH36wRskAAACwcTRtAQAAgAIaPHiwDB48ONdl69atyzFWr149UdVCrgoAAADFFU1boITb41ff2iXYjPp791i7BAAAAAAAAC5EBgAAAAAAAAC2hKYtAAAAAAAAANgQmrYAAAAAAAAAYENo2gIAAAAAAACADaFpCwAAAAAAAAA2hKYtAAAAAAAAANgQmrYAAAAAAAAAYENo2gIAAAAAAACADSll7QIAAAAAACiIPX71rV2Czai/d4+1SwAAWABH2gIAAAAAAACADaFpCwAAAAAAAAA2hKYtAAAAAAAAANgQmrYAAAAAAAAAYENo2gIAAAAAAACADaFpCwAAAAAAAAA2hKYtAAAAAAAAANgQmrYAAAAAAAAAYENo2gIAAAAAAACADaFpCwAAAAAAAAA2hKYtAAAAAAAAANgQmrYAAAAAAAAAYENo2gIAAAAAAACADaFpCwAAABTQ+++/L76+vuLk5CRBQUGyefPmW65//vx5GTRokFStWlUcHR3lrrvuklWrVhVRtQAAALB1Vm/aEnABAABQnMXExEhERIRERUXJ1q1bpXHjxtKlSxc5ffp0rutfvXpVOnXqJIcPH5Zly5ZJfHy8zJ07V7y8vIq4cgAAANiqUtZ88KyAO3v2bAkKCpIZM2ZIly5dJD4+Xtzd3XOsnxVw3d3dZdmyZeLl5SVHjhyR8uXLF33xAAAAgIhMnz5d+vfvL+Hh4SIiMnv2bFm5cqXMnz9fXnvttRzrz58/X/7++2/57bffpHTp0iIi4uvre8vHSEtLk7S0NOPnlJQUyz0BAAAA2JwCHWl75cqVAj149oDboEEDmT17tri4uMj8+fNzXT8r4H799dfSqlUr8fX1lXbt2knjxo1v+hhpaWmSkpJidgMAAAAs4erVq7JlyxYJDg42xuzs7CQ4OFg2btyY6zYrVqyQFi1ayKBBg8TDw0MaNmwokydPloyMjJs+TnR0tLi5uRk3b29viz8XAAAA2I58N20zMzNlwoQJ4uXlJWXKlJGDBw+KiMjo0aNl3rx5eb4fAi4AAACKu7Nnz0pGRoZ4eHiYjXt4eEhiYmKu2xw8eFCWLVsmGRkZsmrVKhk9erS89dZbMnHixJs+TmRkpCQnJxu3Y8eOWfR5AAAAwLbku2k7ceJEWbhwoUybNk0cHByM8YYNG8pHH32U5/sh4AIAAKAkyszMFHd3d5kzZ44EBARI37595fXXX5fZs2ffdBtHR0cpV66c2Q0AAAB3rnzPafvJJ5/InDlzpGPHjvL8888b440bN5a9e/datLgbZQ+49vb2EhAQICdOnJA33nhDoqKict3G0dFRHB0dC7UuAAAAlEyVK1cWe3t7SUpKMhtPSkoST0/PXLepWrWqlC5dWuzt7Y2x+vXrS2Jioly9etXswAgAAACUTPk+0vbEiRNSp06dHOOZmZmSnp6e5/u53YB711133TTgAgAAAEXJwcFBAgICJDY21hjLzMyU2NhYadGiRa7btGrVSvbv3y+ZmZnG2L59+6Rq1ao0bAEAACAit9G0bdCggfzyyy85xpctWyZNmjTJ8/0QcAEAAHAniIiIkLlz58rHH38se/bskRdeeEFSU1MlPDxcRERCQ0MlMjLSWP+FF16Qv//+W4YNGyb79u2TlStXyuTJk2XQoEHWegoAAACwMfmeHmHMmDESFhYmJ06ckMzMTFm+fLnEx8fLJ598It9++22+7isiIkLCwsKkWbNmEhgYKDNmzMgRcL28vCQ6OlpErgfc9957T4YNGyZDhgyRhIQEmTx5sgwdOjS/TwMAAACwiL59+8qZM2dkzJgxkpiYKP7+/rJ69Wrj2g1Hjx4VO7t/j5Xw9vaW77//Xl566SVp1KiReHl5ybBhw2TEiBHWegoAAACwMflu2j7wwAPyzTffyPjx48XV1VXGjBkjTZs2lW+++UY6deqUr/si4AIAAOBOMHjwYBk8eHCuy9atW5djrEWLFvL7778XclUAAAAorvLVtL127ZpMnjxZnn76aVmzZo1FCiDgAgAAAAAAAMC/8jWnbalSpWTatGly7dq1wqoHAAAAAAAAAEq0fF+IrGPHjrJ+/frCqAUAAAAAAAAASrx8z2nbrVs3ee2112Tnzp0SEBAgrq6uZstDQkIsVhwAAAAAAAAAlDT5btoOHDhQRESmT5+eY5nJZJKMjIyCVwUAAAAAAAAAJVS+m7aZmZmFUQcAAAAAAAAAQG5jTlsAAAAAAAAAQOG5rabt+vXrpWfPnlKnTh2pU6eOhISEyC+//GLp2gAAAAAAAACgxMl303bx4sUSHBwsLi4uMnToUBk6dKg4OztLx44d5dNPPy2MGgEAAAAAAACgxMj3nLaTJk2SadOmyUsvvWSMDR06VKZPny4TJkyQxx9/3KIFAgAAAAAAAEBJku8jbQ8ePCg9e/bMMR4SEiKHDh2ySFEAAAAAAAAAUFLlu2nr7e0tsbGxOcZ//PFH8fb2tkhRAAAAAAAAAFBS5Xt6hOHDh8vQoUMlLi5OWrZsKSIiGzZskIULF8o777xj8QIBAAAAAAAAoCTJd9P2hRdeEE9PT3nrrbfk888/FxGR+vXrS0xMjDzwwAMWLxAAAAAAAAAASpJ8N21FRHr37i29e/e2dC0AAAAAAAAAUOLle07bP/74QzZt2pRjfNOmTfLnn39apCgAAAAAAAAAKKny3bQdNGiQHDt2LMf4iRMnZNCgQRYpCgAAAChs165dkx9//FE+/PBDuXDhgoiInDx5Ui5evGjlygAAAFDS5Xt6hN27d0vTpk1zjDdp0kR2795tkaIAAACAwnTkyBHp2rWrHD16VNLS0qRTp05StmxZmTp1qqSlpcns2bOtXSIAAABKsHwfaevo6ChJSUk5xk+dOiWlSt3WFLkAAABAkRo2bJg0a9ZM/vnnH3F2djbGe/fuLbGxsVasDAAAALiNpm3nzp0lMjJSkpOTjbHz58/LyJEjpVOnThYtDgAAACgMv/zyi4waNUocHBzMxn19feXEiRNWqgoAAAC4Lt+Hxr755pvStm1b8fHxkSZNmoiISFxcnHh4eMiiRYssXiAAAABgaZmZmZKRkZFj/Pjx41K2bFkrVAQAAAD8K99H2np5ecmOHTtk2rRp0qBBAwkICJB33nlHdu7cKd7e3oVRIwAAAGBRnTt3lhkzZhg/m0wmuXjxokRFRUn37t2tVxgAAAAgt3GkrYiIq6urPPfcc5auBQAAACgSb775pnTt2lUaNGggV65ckccff1wSEhKkcuXK8tlnn1m7PAAAAJRweT7Sdt++fbJ582azsdjYWGnfvr0EBgbK5MmTLV4cAAAAUBi8vb1l+/bt8vrrr8tLL70kTZo0kSlTpsi2bdvE3d093/f3/vvvi6+vrzg5OUlQUFCO3JzdwoULxWQymd2cnJwK8nQAAABwh8nzkbYjRoyQe+65RwIDA0VE5NChQ9KzZ09p06aNNGrUSKKjo8XFxUVefPHFwqoVAAAAKLD09HTx8/OTb7/9Vp544gl54oknCnR/MTExEhERIbNnz5agoCCZMWOGdOnSReLj42/aAC5XrpzEx8cbP5tMpgLVAAAAgDtLno+0/fPPP6Vbt27Gz0uWLJG77rpLvv/+e3nnnXdkxowZsnDhwsKoEQAAALCY0qVLy5UrVyx2f9OnT5f+/ftLeHi4NGjQQGbPni0uLi4yf/78m25jMpnE09PTuHl4eNzyMdLS0iQlJcXsBgAAgDtXnpu2Z8+elerVqxs/r127Vnr27Gn8fN9998nhw4ctWhwAAABQGAYNGiRTp06Va9euFeh+rl69Klu2bJHg4GBjzM7OToKDg2Xjxo033e7ixYvi4+Mj3t7e8sADD8hff/11y8eJjo4WNzc348YFgAEAAO5seZ4eoWLFinLq1Cnx9vaWzMxM+fPPPyUiIsJYfvXqVVHVQikSAAAAsKQ//vhDYmNj5YcffpB77rlHXF1dzZYvX748T/dz9uxZycjIyHGkrIeHh+zduzfXberVqyfz58+XRo0aSXJysrz55pvSsmVL+euvv8wOksguMjLSLHunpKTQuAUAALiD5blpe99998mECRPkgw8+kC+++EIyMzPlvvvuM5bv3r1bfH19C6FEAAAAwLLKly8vDz30kFUeu0WLFtKiRQvj55YtW0r9+vXlww8/lAkTJuS6jaOjozg6OhZViQAAALCyPDdtJ02aJJ06dRIfHx+xt7eXd9991+yIhEWLFkmHDh0KpUgAAADAkhYsWGCR+6lcubLY29tLUlKS2XhSUpJ4enrm6T5Kly4tTZo0kf3791ukJgAAABR/eW7a+vr6yp49e+Svv/6SKlWqSLVq1cyWjxs37qancwEAAAC26MyZMxIfHy8i16ctqFKlSr62d3BwkICAAImNjZVevXqJiEhmZqbExsbK4MGD83QfGRkZsnPnTunevXu+HhsAAAB3rjw3bUVESpUqJY0bN8512c3GAQAAAFuTmpoqQ4YMkU8++UQyMzNFRMTe3l5CQ0Nl5syZ4uLikuf7ioiIkLCwMGnWrJkEBgbKjBkzJDU1VcLDw0VEJDQ0VLy8vCQ6OlpERMaPHy/33nuv1KlTR86fPy9vvPGGHDlyRJ599lnLP1EAAAAUS/lq2gIAAAB3goiICFm/fr1888030qpVKxER+fXXX2Xo0KEyfPhwmTVrVp7vq2/fvnLmzBkZM2aMJCYmir+/v6xevdq4ONnRo0fFzs7OWP+ff/6R/v37S2JiolSoUEECAgLkt99+kwYNGlj2SQIAAKDYomkLAACAEufLL7+UZcuWmV1Yt3v37uLs7CyPPPJIvpq2IiKDBw++6XQI69atM/v57bfflrfffju/JQMAAKAEsfvvVQAAAIA7y6VLl4wjYbNzd3eXS5cuWaEiAAAA4F80bQEAAFDitGjRQqKiouTKlSvG2OXLl2XcuHHSokULK1YGAAAA3Mb0CL6+vvL0009Lv379pEaNGoVREwAAAFCo3nnnHenSpYtUr17duKDu9u3bxcnJSb7//nsrVwcAAICSLt9H2r744ouyfPlyqVWrlnTq1EmWLl0qaWlphVEbAAAAUCgaNmwoCQkJEh0dLf7+/uLv7y9TpkyRhIQEufvuu61dHgAAAEq4fB9p++KLL8qLL74oW7dulYULF8qQIUNk4MCB8vjjj8vTTz8tTZs2LYw6AQAAAItycXGR/v37W7sMAAAAIIfbntO2adOm8u6778rJkyclKipKPvroI2nevLn4+/vL/PnzRVUtWScAAABgMdHR0TJ//vwc4/Pnz5epU6daoSIAAADgX7fdtE1PT5fPP/9cQkJCZPjw4dKsWTP56KOP5KGHHpKRI0fKE088Yck6AQAAAIv58MMPxc/PL8f43XffLbNnz7ZCRQAAAMC/8j09wtatW2XBggXy2WefiZ2dnYSGhsrbb79tFnp79+4tzZs3t2ihAAAAgKUkJiZK1apVc4xXqVJFTp06ZYWKAAAAgH/lu2nbvHlz6dSpk8yaNUt69eolpUuXzrFOzZo15dFHH7VIgQAAAICleXt7y4YNG6RmzZpm4xs2bJBq1apZqSoAAADgunw3bQ8ePCg+Pj63XMfV1VUWLFhw20UBAAAAhal///7y4osvSnp6unTo0EFERGJjY+XVV1+V4cOHW7k6AAAAlHT5btqePn1aEhMTJSgoyGx806ZNYm9vL82aNbNYcQAAAEBheOWVV+TcuXMycOBAuXr1qoiIODk5yYgRIyQyMtLK1QEAAKCky/eFyAYNGiTHjh3LMX7ixAkZNGiQRYoCAAAACpPJZJKpU6fKmTNn5Pfff5ft27fL33//LWPGjLF2aQAAAED+m7a7d++Wpk2b5hhv0qSJ7N692yJFAQAAAEWhTJky0rx5cylbtqwcOHBAMjMzrV0SAAAAkP+mraOjoyQlJeUYP3XqlJQqle/ZFgAAAIAiM3/+fJk+fbrZ2HPPPSe1atWSe+65Rxo2bJjrWWUAAABAUcp307Zz584SGRkpycnJxtj58+dl5MiR0qlTJ4sWBwAAAFjSnDlzpEKFCsbPq1evlgULFsgnn3wif/zxh5QvX17GjRtnxQoBAACA27gQ2Ztvvilt27YVHx8fadKkiYiIxMXFiYeHhyxatMjiBQIAAACWkpCQYHbh3P/973/ywAMPyBNPPCEiIpMnT5bw8HBrlQcAAACIyG00bb28vGTHjh2yZMkS2b59uzg7O0t4eLg89thjUrp06cKoEQAAALCIy5cvS7ly5Yyff/vtN3nmmWeMn2vVqiWJiYnWKA0AAAAw3NYktK6urvLcc89ZuhYAAACgUPn4+MiWLVvEx8dHzp49K3/99Ze0atXKWJ6YmChubm5WrBAAAAC4zaatiMju3bvl6NGjcvXqVbPxkJCQAhcFAAAAFIawsDAZNGiQ/PXXX/LTTz+Jn5+fBAQEGMt/++03adiwoRUrBAAAAG6jaXvw4EHp3bu37Ny5U0wmk6iqiIiYTCYREcnIyLBshQAAAICFvPrqq3Lp0iVZvny5eHp6yhdffGG2fMOGDfLYY49ZqToAAADgOrv8bjBs2DCpWbOmnD59WlxcXOSvv/6Sn3/+WZo1aybr1q0rhBIBAAAAy7Czs5Px48fLtm3b5LvvvpP69eubLf/iiy/M5rgFAAAArCHfR9pu3LhRfvrpJ6lcubLY2dmJnZ2dtG7dWqKjo2Xo0KGybdu2wqgTAAAAAAAAAEqEfB9pm5GRIWXLlhURkcqVK8vJkydF5PpFHeLj4y1bHQAAAAAAAACUMPlu2jZs2FC2b98uIiJBQUEybdo02bBhg4wfP15q1apl8QIBAAAAW/f++++Lr6+vODk5SVBQkGzevDlP2y1dulRMJpP06tWrcAsEAABAsZLvpu2oUaMkMzNTRETGjx8vhw4dkjZt2siqVavk3Xffva0iCLkAAAAormJiYiQiIkKioqJk69at0rhxY+nSpYucPn36ltsdPnxYXn75ZWnTpk0RVQoAAIDiIt9N2y5dusiDDz4oIiJ16tSRvXv3ytmzZ+X06dPSoUOHfBdAyAUAAEBxNn36dOnfv7+Eh4dLgwYNZPbs2eLi4iLz58+/6TYZGRnyxBNPyLhx4/J0tlpaWpqkpKSY3QAAAHDnylfTNj09XUqVKiW7du0yG69YsaKYTKbbKqCwQy4BFwAAAHl17Ngxefrpp/O8/tWrV2XLli0SHBxsjNnZ2UlwcLBs3LjxptuNHz9e3N3d5ZlnnsnT40RHR4ubm5tx8/b2znONAAAAKH7y1bQtXbq01KhRQzIyMizy4EURcgm4AAAAyKu///5bPv744zyvf/bsWcnIyBAPDw+zcQ8PD0lMTMx1m19//VXmzZsnc+fOzfPjREZGSnJysnE7duxYnrcFAABA8VMqvxu8/vrrMnLkSFm0aJFUrFixQA9+q5C7d+/eXLfJCrlxcXF5eozIyEiJiIgwfk5JSaFxCwAAUEKtWLHilssPHjxYqI9/4cIFeeqpp2Tu3LlSuXLlPG/n6Ogojo6OhVgZAAAAbEm+m7bvvfee7N+/X6pVqyY+Pj7i6upqtnzr1q0WK+5GtxNyCbgAAADI0qtXLzGZTKKqN10nP9N+Va5cWezt7SUpKclsPCkpSTw9PXOsf+DAATl8+LD07NnTGMu6yG+pUqUkPj5eateunefHBwAAwJ0p303bXr16WezBCbkAAAAoSlWrVpUPPvhAHnjggVyXx8XFSUBAQJ7vz8HBQQICAiQ2NtbIyZmZmRIbGyuDBw/Osb6fn5/s3LnTbGzUqFFy4cIFeeeddzgjDAAAACJyG03bqKgoiz04IRcAAABFKSAgQLZs2XLTpu1/HYWbm4iICAkLC5NmzZpJYGCgzJgxQ1JTUyU8PFxEREJDQ8XLy0uio6PFyclJGjZsaLZ9+fLlRURyjAMAAKDkynfT1tIIuQAAACgqr7zyiqSmpt50eZ06dWTt2rX5us++ffvKmTNnZMyYMZKYmCj+/v6yevVq47oNR48eFTu7fF3/FwAAACVcvpu2dnZ2t5znKyMjI1/3R8gFAABAUWnTps0tl7u6ukq7du3yfb+DBw/O9UwxEZF169bdctuFCxfm+/EAAABwZ8t30/arr74y+zk9PV22bdsmH3/8sYwbN+62iiDkAgAAoCgcPHhQatasma+LjQEAAABFLd9N29zm/+rTp4/cfffdEhMTI88884xFCgMAAAAsrW7dunLq1Clxd3cXketnfb377rvGWV4AAACALbDYvAP33nuvxMbGWuruAAAAAIu78SJjq1atuuUctwAAAIA1WKRpe/nyZXn33XfFy8vLEncHAAAAAAAAACVWvqdHqFChgtkcYKoqFy5cEBcXF1m8eLFFiwMAAAAsyWQy5ZjPlvltAQAAYGvy3bR9++23zYKtnZ2dVKlSRYKCgqRChQoWLQ4AAACwJFWVfv36iaOjo4iIXLlyRZ5//nlxdXU1W2/58uXWKA8AAAAQkdto2vbr168QygAAAAAKX1hYmNnPTz75pJUqAQAAAG4u303bBQsWSJkyZeThhx82G//iiy/k0qVLOYIwAAAAYCsWLFhg7RIAAACA/5TvC5FFR0dL5cqVc4y7u7vL5MmTLVIUAAAAAAAAAJRU+W7aHj16VGrWrJlj3MfHR44ePWqRogAAAAAAAACgpMp309bd3V127NiRY3z79u1SqVIlixQFAAAAAAAAACVVvpu2jz32mAwdOlTWrl0rGRkZkpGRIT/99JMMGzZMHn300cKoEQAAAAAAAABKjHxfiGzChAly+PBh6dixo5QqdX3zzMxMCQ0NZU5bAAAAAAAAACigfDdtHRwcJCYmRiZOnChxcXHi7Ows99xzj/j4+BRGfQAAAAAAAABQouS7aZulbt26UrduXUvWAgAAAAAAAAAlXr7ntH3ooYdk6tSpOcanTZsmDz/8sEWKAgAAAAAAAICSKt9N259//lm6d++eY7xbt27y888/W6QoAAAAAAAAACip8t20vXjxojg4OOQYL126tKSkpFikKAAAAAAAAAAoqfLdtL3nnnskJiYmx/jSpUulQYMGFikKAAAAAAAAAEqqfF+IbPTo0fLggw/KgQMHpEOHDiIiEhsbK5999pl88cUXFi8QAAAAAAAAAEqSfDdte/bsKV9//bVMnjxZli1bJs7OztKoUSP58ccfpV27doVRIwAAAAAAAACUGPlu2oqI9OjRQ3r06JFjfNeuXdKwYcMCFwUAAAAAAAAAJVW+57S90YULF2TOnDkSGBgojRs3tkRNAAAAAAAAAFBi3XbT9ueff5bQ0FCpWrWqvPnmm9KhQwf5/fffLVkbAAAAUCy8//774uvrK05OThIUFCSbN2++6brLly+XZs2aSfny5cXV1VX8/f1l0aJFRVgtAAAAbF2+pkdITEyUhQsXyrx58yQlJUUeeeQRSUtLk6+//loaNGhQWDUCAAAANismJkYiIiJk9uzZEhQUJDNmzJAuXbpIfHy8uLu751i/YsWK8vrrr4ufn584ODjIt99+K+Hh4eLu7i5dunSxwjMAAACArcnzkbY9e/aUevXqyY4dO2TGjBly8uRJmTlzZmHWBgAAANi86dOnS//+/SU8PFwaNGggs2fPFhcXF5k/f36u6993333Su3dvqV+/vtSuXVuGDRsmjRo1kl9//bWIKwcAAICtynPT9rvvvpNnnnlGxo0bJz169BB7e/vCrAsAAACweVevXpUtW7ZIcHCwMWZnZyfBwcGycePG/9xeVSU2Nlbi4+Olbdu2N10vLS1NUlJSzG4AAAC4c+W5afvrr7/KhQsXJCAgQIKCguS9996Ts2fPFmZtAAAAgE07e/asZGRkiIeHh9m4h4eHJCYm3nS75ORkKVOmjDg4OEiPHj1k5syZ0qlTp5uuHx0dLW5ubsbN29vbYs8BAAAAtifPTdt7771X5s6dK6dOnZIBAwbI0qVLpVq1apKZmSlr1qyRCxcuFGadAAAAwB2jbNmyEhcXJ3/88YdMmjRJIiIiZN26dTddPzIyUpKTk43bsWPHiq5YAAAAFLk8N22zuLq6ytNPPy2//vqr7Ny5U4YPHy5TpkwRd3d3CQkJKYwaAQAAAJtUuXJlsbe3l6SkJLPxpKQk8fT0vOl2dnZ2UqdOHfH395fhw4dLnz59JDo6+qbrOzo6Srly5cxuAAAAuHPlu2mbXb169WTatGly/Phx+eyzzyxVEwAAAFAsODg4SEBAgMTGxhpjmZmZEhsbKy1atMjz/WRmZkpaWlphlAgAAIBiqJQl7sTe3l569eolvXr1ssTdAQAAAMVGRESEhIWFSbNmzSQwMFBmzJghqampEh4eLiIioaGh4uXlZRxJGx0dLc2aNZPatWtLWlqarFq1ShYtWiSzZs2y5tMAAACADbFI0xYAAAAoqfr27StnzpyRMWPGSGJiovj7+8vq1auNi5MdPXpU7Oz+PcEtNTVVBg4cKMePHxdnZ2fx8/OTxYsXS9++fa31FAAAAGBjaNoCAAAABTR48GAZPHhwrstuvMDYxIkTZeLEiUVQFQAAAIqrAs1pCwAAAAAAAACwLJq2AAAAAAAAAGBDaNoCAAAAAAAAgA2haQsAAAAAAAAANoSmLQAAAAAAAADYEJq2AAAAAAAAAGBDaNoCAAAAAAAAgA2haQsAAAAAAAAANoSmLQAAAAAAAADYEJq2AAAAAAAAAGBDaNoCAAAAAAAAgA2haQsAAAAAAAAANoSmLQAAAAAAAADYEJq2AAAAAAAAAGBDaNoCAAAAAAAAgA2haQsAAAAAAAAANoSmLQAAAAAAAADYEJq2AAAAAAAAAGBDaNoCAAAAAAAAgA2haQsAAAAAAAAANoSmLQAAAAAAAADYEJq2AAAAAAAAAGBDaNoCAAAAAAAAgA2haQsAAAAU0Pvvvy++vr7i5OQkQUFBsnnz5puuO3fuXGnTpo1UqFBBKlSoIMHBwbdcHwAAACWPTTRtCbkAAAAormJiYiQiIkKioqJk69at0rhxY+nSpYucPn061/XXrVsnjz32mKxdu1Y2btwo3t7e0rlzZzlx4kQRVw4AAABbZfWmLSEXAAAAxdn06dOlf//+Eh4eLg0aNJDZs2eLi4uLzJ8/P9f1lyxZIgMHDhR/f3/x8/OTjz76SDIzMyU2NraIKwcAAICtsnrTtrBDblpamqSkpJjdAAAAAEu4evWqbNmyRYKDg40xOzs7CQ4Olo0bN+bpPi5duiTp6elSsWLFm65DpgUAAChZrNq0LYqQGx0dLW5ubsbN29vbIrUDAAAAZ8+elYyMDPHw8DAb9/DwkMTExDzdx4gRI6RatWpmmfhGZFoAAICSxapN26IIuZGRkZKcnGzcjh07VuC6AQAAAEuYMmWKLF26VL766itxcnK66XpkWgAAgJKllLULKIiskLtu3bqbhlxHR0dxdHQs4soAAABQElSuXFns7e0lKSnJbDwpKUk8PT1vue2bb74pU6ZMkR9//FEaNWp0y3XJtAAAACWLVY+0tUTI/eGHH/4z5AIAAACFwcHBQQICAsyur5B1vYUWLVrcdLtp06bJhAkTZPXq1dKsWbOiKBUAAADFiFWbtoRcAAAAFHcREREyd+5c+fjjj2XPnj3ywgsvSGpqqoSHh4uISGhoqERGRhrrT506VUaPHi3z588XX19fSUxMlMTERLl48aK1ngIAAABsjNWnR4iIiJCwsDBp1qyZBAYGyowZM3KEXC8vL4mOjhaR6yF3zJgx8umnnxohV0SkTJkyUqZMGas9DwAAAJRMffv2lTNnzsiYMWMkMTFR/P39ZfXq1cZ1G44ePSp2dv8eKzFr1iy5evWq9OnTx+x+oqKiZOzYsUVZOgAAAGyU1Zu2hFwAAAAUd4MHD5bBgwfnumzdunVmPx8+fLjwCwIAAECxZvWmrQghFwAAAAAAAACyWHVOWwAAAAAAAACAOZq2AAAAAAAAAGBDaNoCAAAAAAAAgA2haQsAAAAAAAAANoSmLQAAAAAAAADYEJq2AAAAAAAAAGBDaNoCAAAAAAAAgA2haQsAAAAAAAAANoSmLQAAAAAAAADYEJq2AAAAAAAAAGBDaNoCAAAAAAAAgA2haQsAAAAAAAAANoSmLQAAAAAAAADYEJq2AAAAAAAAAGBDaNoCAAAAAAAAgA2haQsAAAAAAAAANoSmLQAAAAAAAADYEJq2AAAAAAAAAGBDaNoCAAAAAAAAgA2haQsAAAAAAAAANoSmLQAAAAAAAADYEJq2AAAAAAAAAGBDaNoCAAAABfT++++Lr6+vODk5SVBQkGzevPmm6/7111/y0EMPia+vr5hMJpkxY0bRFQoAAIBigaYtAAAAUAAxMTESEREhUVFRsnXrVmncuLF06dJFTp8+nev6ly5dklq1asmUKVPE09OziKsFAABAcUDTFgAAACiA6dOnS//+/SU8PFwaNGggs2fPFhcXF5k/f36u6zdv3lzeeOMNefTRR8XR0bGIqwUAAEBxQNMWAAAAuE1Xr16VLVu2SHBwsDFmZ2cnwcHBsnHjRos9TlpamqSkpJjdAAAAcOeiaQsAAADcprNnz0pGRoZ4eHiYjXt4eEhiYqLFHic6Olrc3NyMm7e3t8XuGwAAALaHpi0AAABg4yIjIyU5Odm4HTt2zNolAQAAoBCVsnYBAAAAQHFVuXJlsbe3l6SkJLPxpKQki15kzNHRkflvAQAAShCOtAUAAABuk4ODgwQEBEhsbKwxlpmZKbGxsdKiRQsrVgYAAIDijCNtAQAAgAKIiIiQsLAwadasmQQGBsqMGTMkNTVVwsPDRUQkNDRUvLy8JDo6WkSuX7xs9+7dxr9PnDghcXFxUqZMGalTp47VngcAAABsB01bAAAAoAD69u0rZ86ckTFjxkhiYqL4+/vL6tWrjYuTHT16VOzs/j3B7eTJk9KkSRPj5zfffFPefPNNadeunaxbt66oywcAAIANomkLAAAAFNDgwYNl8ODBuS67sRHr6+srqloEVQEAAKC4Yk5bAAAAAAAAALAhNG0BAAAAAAAAwIbQtAUAAAAAAAAAG0LTFgAAAAAAAABsCE1bAAAAAAAAALAhNG0BAAAAAAAAwIbQtAUAAAAAAAAAG0LTFgAAAAAAAABsCE1bAAAAAAAAALAhNG0BAAAAAAAAwIbQtAUAAAAAAAAAG0LTFgAAAAAAAABsCE1bAAAAAAAAALAhNG0BAAAAAAAAwIbQtAUAAAAAAAAAG0LTFgAAAAAAAABsCE1bAAAAAAAAALAhNG0BAAAAAAAAwIbQtAUAAAAAAAAAG0LTFgAAAAAAAABsCE1bAAAAAAAAALAhNG0BAAAAAAAAwIbQtAUAAAAAAAAAG2ITTdv3339ffH19xcnJSYKCgmTz5s23XP+LL74QPz8/cXJyknvuuUdWrVpVRJUCAAAAOZFnAQAAYElWb9rGxMRIRESEREVFydatW6Vx48bSpUsXOX36dK7r//bbb/LYY4/JM888I9u2bZNevXpJr169ZNeuXUVcOQAAAECeBQAAgOVZvWk7ffp06d+/v4SHh0uDBg1k9uzZ4uLiIvPnz891/XfeeUe6du0qr7zyitSvX18mTJggTZs2lffee6+IKwcAAADIswAAALC8UtZ88KtXr8qWLVskMjLSGLOzs5Pg4GDZuHFjrtts3LhRIiIizMa6dOkiX3/9da7rp6WlSVpamvFzcnKyiIikpKQUsPr8yUy7VKSPZ8sKvO/T1DKF3Aks8Dq+mJFhgULuDJZ4X7iSnm6BSu4MltifF9JSLVDJnaGg+zM1NdNClRR/lnhtZqZetEAld4aizlRZj6dqG3mgKPKsiG1kWvLsvyyy38m0/yLTWlRBX5/k2X+RZy3LEvuTTPsvMq1lFWWmymuetWrT9uzZs5KRkSEeHh5m4x4eHrJ3795ct0lMTMx1/cTExFzXj46OlnHjxuUY9/b2vs2qUVBuM6xdwR1kipu1K7izuLE/LWnUV+xPi5ph7QLuJLw2Lclae/PChQviZgPv20WRZ0XItLaGPGthZFrLsoH3xjsFedbCZli7gDsNr09Lssbe/K88a9WmbVGIjIw0O5IhMzNT/v77b6lUqZKYTCYrVla0UlJSxNvbW44dOyblypWzdjnFHvvTstiflsO+tCz2p2WxPy2rpO5PVZULFy5ItWrVrF1KkSLTXldSX/eFgX1pWexPy2J/Whb703LYl5ZVUvdnXvOsVZu2lStXFnt7e0lKSjIbT0pKEk9Pz1y38fT0zNf6jo6O4ujoaDZWvnz52y+6mCtXrlyJ+kUobOxPy2J/Wg770rLYn5bF/rSskrg/beEI2yxFkWdFyLQ3Komv+8LCvrQs9qdlsT8ti/1pOexLyyqJ+zMvedaqFyJzcHCQgIAAiY2NNcYyMzMlNjZWWrRokes2LVq0MFtfRGTNmjU3XR8AAAAoLORZAAAAFAarT48QEREhYWFh0qxZMwkMDJQZM2ZIamqqhIeHi4hIaGioeHl5SXR0tIiIDBs2TNq1aydvvfWW9OjRQ5YuXSp//vmnzJkzx5pPAwAAACUUeRYAAACWZvWmbd++feXMmTMyZswYSUxMFH9/f1m9erVxcYajR4+Knd2/BwS3bNlSPv30Uxk1apSMHDlS6tatK19//bU0bNjQWk+hWHB0dJSoqKgcp9Xh9rA/LYv9aTnsS8tif1oW+9Oy2J+2gzxbdHjdWw770rLYn5bF/rQs9qflsC8ti/15ayZVVWsXAQAAAAAAAAC4zqpz2gIAAAAAAAAAzNG0BQAAAAAAAAAbQtMWAAAAAAAAAGwITVsAAAAAAAAAsCE0bYu57NeR45pysDVHjhyRzZs3W7sMIFeZmZnWLuGOwmcQgNtFnoUtI8/ClpFnLYvPINgamrbFWGZmpphMJjl79qykpKSIyWSydkmAYdu2bXL33XfLoUOHrF0KYGb37t1y5MgRsbPjI9ASLl26JCIiJpOJoAsg38izsGXkWdgq8qxlkWdhq/gNL6YyMzPFzs5Otm3bJu3bt5ddu3ZZu6Q7Bm/SBbd9+3Zp3bq1PP/889K3b19rl3PH4LVZcDt27JCGDRtKTEyMtUu5I+zdu1ceeugh+eKLL0SEoFtQN+479iXudOTZwsP7R8GRZwsPr8+CIc9aFnnW8si0lkPTthjKCrhxcXHSqlUr6dKli7Rs2dLaZRV7N3sj4ZST/Nm7d6906NBBBgwYIG+++aZcu3bN2iUVW1mvvStXrojI9QBx+PBhK1ZUvMXFxcm9994rr7zyirz66qvWLqfYy8jIkHfffVd++ukn+fLLL+Wrr74SkeuvU9438y/raEMRkWPHjsnFixcJuLijkWcLB3nWMsizlkWmtRzyrGWRZy2PTGtZNG2LmayAGx8fL+3atZOxY8fKm2++yRtKAamqmEwmWb9+vbz66qsycOBAmTp1qoiI2NnZ8SaTR9u3b5fmzZvLlStX5LfffpOUlBQpVaoUQfc22dnZyZEjRyQiIkKOHTsmy5cvl1q1asn+/futXVqxk5CQIAEBATJ69GiZOnWqXLt2Tf73v//J9OnT5bvvvpOEhARrl1js2NvbS40aNSQgIEDOnj0rs2fPli+//FJExDhVj8+mvMvaZ6NHj5aQkBBp2LChREdHy969e61cGWB55NnCQZ61DPKs5ZFpLYM8a3nkWcsj01oWTdtiJCvgbt++XYKCguTChQtSrlw5Ebn+i8Gbye0zmUyyfPly6dmzpyQnJ0vp0qXlgw8+kPbt25t9U4Sb27Jli7Rt21YGDx4s69evF1WVdu3aEXQLaOvWrbJ+/XoJCwuTJ554Qj755BOpU6cOf3jlQ0ZGhnzzzTeiqlK3bl0REenWrZuMGjVK3n33XQkNDZVhw4bJ6tWrrVxp8ZH1+vPx8ZH27dvLRx99JOnp6TJv3jxZv369DBkyRBISEphnLQ+yf3YvWbJE5s6dK6+++qqEhITI119/LRMnTpQdO3ZYsULAssizhYc8W3Dk2cJDpi0Y8qzlkWcti0xbSBTFQmZmpqqqxsXFqaurqw4ZMkTfeOMNLVeunL711lvGehkZGdYqsVg7duyY1q9fX2fOnKmqqgcPHlR3d3ft37+/2XpZ/w/4V2ZmpqampmrZsmV1yJAhqnr9dbhu3ToNDAzUJk2aaHJysqqqpqenW7PUYiX7ay06OlpNJpO2bNlS9+3bl+s6uLVjx47p2LFjtWzZsurl5aUPPvig7t69W1VV161bp506ddI+ffrohQsXrFxp8bJr1y5t166dqqru3LlTu3btqjVq1FCTyaR79uxRVT6X8urXX3/VoUOH6uLFi42xRYsWaevWrfWxxx7T7du3W7E6wDLIs4WLPHv7yLOFh0xrOeTZwkGetSwyrWXRtC1Gjhw5oiaTSUeOHKmqqklJSTp+/HgtV66cTp8+3ViPN5T827Fjh/r5+anq9Q/D6tWr64ABA4zla9assVZpNi/r9Xb+/Pkc4+vXr88RdK9du1bkNRZnMTEx+vDDD+uECRM0KChIn3rqKd2yZYuxnJCbd6dOndLRo0drcHCwxsXFmS1bunSp2tvba3x8vJWqK34yMzN137596ufnZ/z+9+zZUx0dHbVVq1a6cuVKK1dYfPz2229aq1YtrVixoi5YsMBsWVbIffLJJ/XPP/+0ToGABZFnCw959vaRZwsfmdYyyLOWRZ61LDKt5dG0tXE3BtbVq1eb/ZyYmKgTJkwg6BbQ0aNHtU2bNrpixQqtUaOGDhgwwPgWfc+ePfrkk0/qH3/8YeUqbc++fft04MCBev/99+vYsWM1NTVVVf99/d0YdFNSUlSVoJtX27ZtU5PJpDNmzFDV60GsWbNm+tRTT+nWrVuN9W4MbLi548eP6++//65Xr15V1X9fq2vWrNH69evrqVOnrFmeTbvZH1MPP/ywnjx5UsPCwtTLy0uXLl2qXbt21XvvvZegmw8zZszQGjVqaK9evfTgwYNmy5YsWaL16tXTqKgo6xQHFBB5tmiQZ28PebbwkWktizx7+8izhY9Ma1k0bW1Y1pvv4cOH9cMPP9To6GhNSEhQVfM3m6SkJIJuPmTtu82bN+uWLVs0PT1dz507p61atdJSpUrpU089Zbb+yy+/rK1atdKkpCRrlGuz4uLi1N3dXUNCQrRXr17q4OBgdjRH1n7OCrotW7ZUX19fI+ji1rZt26azZ8/W8ePHm40vXbpUmzdvrk899ZT+8MMPOn78eHVwcNBz585ZqdLiJ7ew9vLLL2vbtm1zHGGD638Y3Oz9LzMzU7t06aIODg5arVo141vzrVu36gMPPKBHjhwpylKLhVt9Nr/11lvauHFjfemll/Tw4cNmy77//nsaBCiWyLOFgzxrGeTZwkemLRzk2fwhz1oembZo0LS1UVm/ANu3b1dfX19t1qyZuru7a6VKlTQ2NlZVzb/dzQq6lSpV0okTJ1ql5uIg68Nt+fLlWqVKFR01apQmJiaqquoff/yh5cqV04ceekg///xzXbdunQ4dOlTd3NyYd+UG27dvV1dXV+PUxosXL+rTTz+tpUqVMjuCI+s1mpmZqWvWrNGOHTvm+LYNOZ04cUJbt26trq6u+tprr6mqalpamrF82bJl2rZtW61Tp476+Pjo5s2brVVqsZeQkKCvvPKKli9fXnfs2GHtcmzO1q1b1dvbW7/55pscy7LeT7/77jsNCQkxAm7W+JUrV4qu0GIie7idPXu2hoWF6bPPPqtvvPGGMf7GG2+ov79/riFXlSO7ULyQZwsHedYyyLOFj0xbNMizt0aetTwybdGhaWuDsn4B4uLi1MXFRV9//XU9d+6c7t69W319fTUgIMD4sMv+Qj99+rSOHDlSa9SooefOnWNeoJtYvXq1urq66rx58/Sff/4xW7Zx40Zt3bq1Vq1aVRs0aKBt2rThNJ0bJCcnq6+vrzZu3NhsPDQ0VB0cHHTjxo25fhuZkZGhly5dKqIqi7e0tDSdPXu23nPPPdqwYUNjv2UPufv27dMtW7bo8ePHrVWmzTl06JAuWLBAx40bp9u2bfvPkLVr1y7t27evNmrUSLdt21Y0RRYj27ZtU2dnZ33llVduuV5qaqoxx192fAbd3KuvvqpVqlTRZ599Vh966CEtU6aM9uzZ09hnU6dO1WbNmml4eDinOKLYIs8WLvJswZBniwaZNv/Is5ZFni1cZNrCR9PWRp08eVLt7e110KBBZuNZ30RmzV9zo6SkJD1z5kxRlFgsZWRk6HPPPacDBw5U1etvztu3b9fhw4fr9OnT9fDhw5qenq7Hjh3TEydOcOpTLq5evarTp09XR0dHnTJliqpevxKsg4ODtm3bVh9++GGtXr269u7dW6Ojo3XXrl1cwfQ/ZA8DWcEsPT1dP/vsM23QoIE+8MADevHiRVXVm/7ul3Q7duzQ6tWra8eOHdXDw0Pr1q2rO3fuNFsnt1N4fv/9d/5IyMXevXvVzc1NJ0yYoKoEVkvavHmzenl56U8//aSq1/ft77//rtWqVdM+ffoY60VFRWm/fv04NRzFGnm2cJBnC448WzjItAVDnrUs8mzhItMWDZq2NiT7m8iBAwc0MDBQ/fz8jG8kpkyZoiaTSatVq6bh4eHarFkzXbBggf7555/8AuRRenq6du3aVXv27Km7du3Sp59+Wjt27Kh+fn7asGFDDQsLMy4+AHPx8fG6atUqVb3+7fjMmTPVZDJp+/bt1dPTU1etWqWZmZmanJysu3fv1v79+2uDBg3Ux8dH//77bytXb7uyfu+///57ffbZZ7Vly5Y6YcIE4xTGRYsWaVBQkPbu3dsIuZxKYi4+Pl49PT119OjRxhEcPj4+OmvWrFzXnzFjhr7zzjtFWWKxEhcXp2XLllWTyaSjR482xgm6+RcSEqJ//fWX2djq1avVy8vLeF/M2q9r1qzRSpUq6XfffWesm30uRaC4IM8WPvLs7SPPFh4ybcGQZy2LPGtZZFrroWlrI7JevCdOnDDm+zhw4IC2atVK69Wrp5GRkerh4aHLli3TI0eO6NatW3XEiBHasmVLNZlM+thjj+nly5et+RSKjfXr12uFChW0UqVK2qdPH/38889VVXX69OkaFBRkdroOrouLi1OTyaTvvfeeMZaWlqazZs3SsmXLamhoqDGeFb7S09M1IyNDT5w4UeT1Fjdff/21lilTRocNG6YzZ87UmjVrasuWLfXw4cN69epVXbhwobZs2VI7duzIH2E3SE1N1UGDBunAgQM1LS3NeP098sgjOnLkSB04cKB++umnxlx/Z86c0TZt2mjHjh1znE6K67/rzs7OOmLECF22bJk6ODjo8OHDjeUE3bxLS0szXpfZJSQkqJubm/HZk+XIkSPq5eWVY5x9juKEPFt0yLP5R54tfGTa20OetSzyrGWRaa2Lpq0NyAq4W7duVWdnZ125cqWxbP/+/dq5c2c1mUz62Wef5dj29OnTun79et27d2+R1VtcZL0pJCQk6Nq1a3X79u16+vRpVb3+RpI10X3WehEREXr//fcb3/ziuqy56LIu0pDdhQsX9IMPPlA7OzudPHmyMZ6RkcGbch6dOnVKmzVrpjNnzlTV638kVKxYUYcPH27sw/T0dP3www+1Y8eOeuzYMWuWa5NWrlypW7ZsMX4eN26clipVSsPDw7VDhw7apEkTHTp0qHHUwqFDh/To0aPWKtdmJSYmqqOjo/G7np6erp988ok6ODjoyy+/bKzH73b+vf3227px40ZVVf3nn3+0b9++2qNHD/3hhx+Mdc6fP6+NGjXSmJgYa5UJFAh5tnCQZy2DPFv4yLQFQ561DPJs4SLTFj2atlaW/SINZcqUyXWC7L1792r79u21du3axre8fHt+a1lvwl9++aXWrl1bfX191d/fXx9++GHdt2+f2bp//vmnRkZGarly5biq7g127Nihrq6uOmrUKLPxmJgYPXfunKpefy2+9957amdnZ8wJhrw7e/asBgQE6NmzZ3X//v1arVo17d+/v7F8/fr1evnyZb169aqeP3/eipXantzCVkJCgt511126YsUKY2zUqFFap04dTUpKKsryiqWsq7lnSU9P10WLFhF0CyA9PV1bt26tVapUMa5I/PPPP2unTp20RYsWOnbsWF26dKkGBwerv78/p4qiWCLPFg7yrGWQZ4sGmfb2kGctjzxbOMi01kHT1oqyAu727dvV2dk5xze/2Scd379/v7Zq1Upr1aqlJ0+eNNseufvhhx+0fPnyxre9H3zwgZYpU0Zbt25tHMmxe/dufeSRR7Rx48ZcVfcGx48fV5PJpE888YTZeNZcdNm/CU5LS9MPPvhATSaTTp8+vahLtXlZv6tpaWk5jnw5cuSI1qhRQ2NiYrROnTrav39/4wNu7969+tBDD+n69euLvGZbd6uQdfbsWVW9HixUVZctW6YNGjTgojY3kZCQoMOHD9dHH31U33vvPY2Pjzdbnp6erosXL1ZHR0dOLcuD7PN9ffjhh7p//369dOmS3n///Vq1alX9448/VPX6RUNGjBihnp6e2qJFC+3Zs6dxURZCLooT8mzhIs8WDHnWssi0lkWetRzyrOWRaW0DTVsr27Nnj9rZ2WlERITZ+Lhx47RixYpGoFW9HnTbtWun5cuXN+azQU5ZFw946KGHdOzYsap6/TSJGjVqaNeuXbVly5baqlUrPXjwoKpe/2OCeapy17BhQ23YsKH+9ttvqqo6depUrVy5snH6Q/YPuYyMDP3www919+7dVqnVVmWF2927d2ufPn00KChIn3jiCbNvyYcPH64mk0l79uxptu3IkSO1SZMmXA02m+PHj//nEQY3hq+hQ4dqSEgIc6flIi4uTqtUqaLt27fXgIAALVWqlPbt21ePHDlitl5W0C1TpowOGDDAStXavi1btqi/v7++9dZb+tJLL6nJZNKEhARVVb106ZJ269ZNPT09jZCrqnrx4kVNTk42O3UUKG7Is5ZHnrUc8qxlkGkthzxrWeRZyyPT2g6atla2atUqNZlMGhUVZZyeM2XKFHV3dzeubJr9DTshIUE7d+5s/MLg5r7//nv97bff9Ny5c3rPPfcYb8zTpk1Tk8mkd999N3On3UT2b8SaNWumDRs21IEDB2qlSpVynG6iqrpp0ya9cOFCUZZYLGQ/XbR8+fIaGhqqkydP1qpVq+pjjz1mrLdjxw596KGHtFq1arpo0SJdsGCBDh06VMuWLcsRM9ls3bpVvb299ZtvvsnT+hcuXNCRI0dqpUqVdNeuXYVcXfGza9cudXV11QkTJhi/87Nnz1aTyaTLly9XVfPPn/T0dP3oo4/Uw8ODU/Nu4vTp0zp8+HD19PTUcuXKGUcYZh1tcPnyZe3evbtWq1bNOK0sO472QHFFni085NnbR561HDKt5ZBnLYs8WzjItLaDpq0NWLJkiZpMJp00aZJGRUVpxYoVzSZyzpL17TnfWJjbv3+/jho1SocOHaqLFi3KsXzRokXavn1742iOr7/+Wlu2bKn9+vXTQ4cOFXG1tu3ChQt67tw5Y4L7LK1bt1aTyaTvvPNOjm1ee+01bdCggXFRDFyX9UG1fft2dXFx0ddff91YtnDhQu3du7ceP37c+OMgISFBhwwZou7u7tqkSRO9//77dceOHVap3RZt27ZNnZ2dc50nMTcrV67UBx54QGvVqqVbt24t5OqKn3/++Uc9PT21efPmmpKSYoynp6drnTp19M0338x1u2vXrmlycnJRlVmsZP1BO2/ePC1Xrpw2bNjQbD9mfXZfvnxZe/bsqSaTSffs2WOVWoHCQJ4tGPKs5ZBnLYtMaznkWcsizxYOMq1toWlbhLJe/NeuXcsxt8cnn3yiJpNJTSaTfvnllzm2HTNmjD755JOcDnGDuLg49fT01M6dO2v79u3VyckpR9B966231MPDw/gjYcSIEfrSSy/xRn2Dv/76S++77z719/dXHx+fHN+G33vvvern56e//vqr8VoePXq0Ojk5GVcuhrmkpCT19fXVNm3amI0PGDBAPT091dvbW+vVq6fDhw/Xy5cvq+r1Ux/T09P5Xc9m79696ubmphMmTFDVvH1zm5GRoR988IEeOHCgsMsrtkaNGqW1atXSSZMmGVcf/uuvv7RUqVL6v//9z8rVFR9Zr8fsf9Ru3bpVX375ZQ0MDNRJkybl2ObixYv66quvMs8XiiXyrOWRZy2HPFs4yLQFR54tHORZyyHT2iaatkUkKxTEx8frs88+q927d89xoYavvvpKTSaTjho1ymyC8TFjxqjJZMr1sPOSLOuCF5GRkZqZmamnT5/WXr166RtvvGG23oYNG7RVq1baqFEjDQkJURcXF7NJtXH9W9+yZcvq0KFDdeHChfrAAw9ozZo1NS0tzewCIU2bNtW6detqXFycjh49Wh0dHXld3kJCQoKGh4frPffcox999JGqXj9dtEyZMjp79mxdv369hoaGqoeHhy5atEgzMzONDzxOKbkuLi5Oy5YtqyaTSUePHm2M32r/cFGbvBs3bpxWr15d3333Xd20aZNWr15dhwwZYu2yio3sr7Xz589rRkaGcfTBiRMndOjQoRoYGGh2JfKoqChjDkpVLtCA4oU8a3nkWcshzxYeMm3BkGcLF3m24Mi0toumbRHIPgdQpUqVtE+fPvrss8+qq6trjqCbdYTCiBEj9MqVKzp27Fh1dHQ0u7IpVA8cOKAVKlTQ8PBws/GQkBBt166dBgYGanh4uG7YsEFVr19tc+jQodqvXz8C7g127dqlzs7OOn78eGNszZo12qVLF01ISNB9+/aZnSoWGBioJpNJy5Yty+syD+Lj43XIkCHaoEEDDQkJUXd3d12zZo2xPC0tTatUqWJ2FVNcFxcXp87OzjpixAhdtmyZOjg4cLXXAjh27JguXrxY58yZY3YqbVRUlFarVk3LlSunYWFhxjjB69ayh9s33nhDe/Tooc2aNdPXX3/dmKfzxIkTOmzYMG3WrJk++uij2r17d3V3d2ffolgiz1oeedZyyLOFj0x7e8izlkWetTwyrW2jaVvIsn4Bsr5Fzx5qIyMj9YUXXtCLFy+arfvxxx9r6dKltUGDBlq2bFm++c3FF198oVWrVtUhQ4YY86dMnjxZnZyc9OWXX9Zx48ZppUqVNDAw0Oy0MeZPM3fu3Dn19/fX+vXrm42PGDFCHRwctF69elqqVCl95JFHdNu2bcby3r17m/2MnLJ/+P311186ZMgQLV++vA4dOtQYT0tL09TUVO3QoYMxTxDB7brExER1dHQ03jPT09P1k08+UQcHB3355ZeN9dhfebNr1y5t3LixPvnkk/rqq6/mWD516lR1c3PTiRMncjX3PMj+uouMjNTKlSvrrFmzdOLEiRoUFKQdO3Y0PptOnTqlb7zxhvbq1UsfffRR4wIOHEGD4oQ8WzjIs5ZBni1cZNrbR561LPKs5ZFpbR9N2yJw/Phx9fDw0AceeMBs/Mknn9R69epp3bp1tVWrVvree+9pWlqaql4/QsHV1ZUgcQvz5s3Tpk2b6ksvvaQvvviiVqlSRb///ntj+aZNm9RkMumyZcuMMT4QzV2+fFlfeeUVbd26tfGN79tvv61ubm66ZMkSPXLkiH744YdaunRpfeONN/gmLQ+yXmPJycnGB5mq6s6dO3XIkCHq5+enc+fONcZHjx6t1apV0/379xd5rbbuxis7p6en66JFiwi6+bRr1y6tUKGCjho1yuyP/hUrVhhX1VW9foSCt7e3RkdH6/Hjx61Rqs3L/jutev2oNz8/P/3jjz9UVfW7775TR0dHbdCggbZs2VLj4+NVVY3P9iw0XFAckWcLB3m24MizhYNMaxnkWcsgz1oWmbb4oGlbBDZs2KBt2rTRrl276urVq1VVNTo6Wl1dXXXq1KkaExOjgYGB6u3trb/99puxXdYVOGEu+zc5c+bM0bvvvludnZ11zpw5qqrGHEo7duzQu+66S9euXWulSm1b1n68dOmSjhkzRlu2bKktW7bU8uXL66+//mq2bsuWLXP8kYabW7FihfHN5IABA4zxrJBbr149/fTTT/WNN95QJycnTsvLJiEhQYcPH66PPvqovvfee0ZAyJKenq6LFy9WR0dHTi3Lg3Pnzmnbtm118ODBZuNTpkxRk8mkHTp0MAu648aNUxcXF33rrbf4o/YGffv21b59+xoXWFG9furtiy++qKrXf+8rVaqks2bN0i+++EIrVaqk7du31127dpndD69VFFfkWcsiz1oGebZwkWlvD3nWssizlkWmLV5o2haSBQsW6KhRo4yfY2NjNSQkRLt27aqhoaHq7u6uP/zwg7H877//VpPJpG+99ZYxxi/Bv65cuWL2c/agu2jRIm3UqJG+8MILZvN7jRo1Sv38/PTkyZNFVmdxk7UfU1NTdezYsVqzZk198MEHjeVpaWmanp6uXbt21REjRnDqwy1k/b7+8ccf6ujoqJGRkTpw4EC9++67tXnz5sZ6O3fu1BdffFGdnZ3V3t6e00WziYuL0ypVqmj79u01ICBAS5UqpX379tUjR46YrZcVdMuUKWP2BwRy2r17t9auXVt/+ukn4/d31qxZWrp0aX3//fe1U6dO2r17d7OgO3XqVN23b5+1SrZZy5cvVxcXF33hhRf00qVLxvjp06f1woUL2qZNG+OquleuXFF/f3+tVq2aPvfcc9YqGSgw8qxlkWcLB3nWssi0BUOetTzyrGWRaYsXmrYWlpGRoRcuXNDw8HANCAjQyZMnG8vWrFmj999/v7q6uuqECROM8bS0NE1KStKmTZvq4sWLrVG2TduxY4cOHTrU7OIBquZBd+7cudqkSRN97rnn9MiRI8Z8YJyO99+yH6EQFRWl9957r0ZERBh/WIwZM0bd3d1179691iyzWNi2bZuuXr1ap02bpqrXTzvZsGGD1q1bVwMCAszWGzFihDE/EK6f8pT13pj1jfjs2bPVZDIZASz7H/7p6en60UcfqYeHhyYlJVml5uJg0aJFam9vb7bvjh07pj///LOqXv+Dq2PHjhoYGMj75U1s377dOIXsu+++U2dnZx0wYICmpqYa6+zbt0+rVq2q3333nape38d9+/bV5cuX0xxAsUSetTzybOEiz1oWmfb2kGcLB3nWMsi0xRNNWwvLerM9deqUvvjiixoUFKQTJ040lq9bt0579uypwcHBumrVKmN8zJgx6uPjo4cPHy7ymm1ZXFycmkwmHTt2bK7Lbwy6QUFBWq9ePXVycuLb3nzIfoTCmDFjNCgoSEeNGqWvvfYapzr9h6zwcPLkSW3UqFGO12tGRoZu2LBB77rrLg0KCjLGb5wPqCT7559/1NPTU5s3b64pKSnGeHp6utapU8e4oMWNrl27ZjanFXL65Zdf1NHRUb/88ktVNf9DIev3fs6cOdq8eXM9deqUVWq0ZWPHjlWTyaRr1qwxQu6qVauMkJt1dMLJkye1TZs22qdPH/3222+1c+fO2qVLF2MfE3JR3JBnLYs8WzTIswVDpi0Y8mzhIc8WHJm2+KJpa0GzZs3Sjh07Gi/4U6dO6ZAhQ3IE3R9//FFDQkK0Q4cO+vPPP+uUKVPU0dFRt27daq3SbdLu3bvV2dnZ7CiO3GR/45g1a5Y2adJEd+zYUdjl3XFuPLXMy8uLPxby6Ntvv9XRo0frokWLtGHDhtqmTRuz5RkZGbpx40atXLmy3nfffarK6aI3GjVqlNaqVUsnTZqkR48eVdXrVyguVaqU/u9//7NydcXXsWPH1N3dXUNCQm7aRBk+fLg+/PDDZn9g4F9du3ZVLy8v/eGHH8xCrpOTkw4YMMD4Y3Xu3LnasmVL9fHx0fbt23NFXRRb5FnLIs8WLfJswZBpC4Y8WzjIs5ZBpi2eaNpa0OrVq42rZWa9WRw/fvymQffBBx/UKlWqaOnSpQkSN9ixY4dWqlRJq1SpYozdeIXD7LK/gfBNpbmDBw8ap45kudmE7NmD7rRp05gHKA+2bNmilSpV0piYGE1JSdEvv/xSvby8clzoIiMjQzdt2sQVdW9h3LhxWr16dX333Xd106ZNWr16dR0yZIi1yyr2li1bpg4ODvrUU0+ZzZOYnJysr7zyilaoUCHHhQVKurffftvsd7Vz585atWrVHCHX2dlZ+/fvb6z3zz//6P79+433Uq6oi+KIPGs55FnLIc8WPjKtZZBnCwd59vaQaYs/mraF4Pfff9d7773XeNO4WdBdvXq1PvLII7y53CAuLk6dnZ21Z8+e2qBBA+3Ro4ex7FZXf+Rb3pzOnDmjdnZ2ajKZdPjw4fruu++aLc9tn/ENWt7Fx8frtGnT9OWXXzbGrly5ol9++aXWrFlTe/XqZcXqbNuxY8d08eLFOmfOHD106JAxHhUVpdWqVdNy5cppWFiYMc6VX2/ftWvXdPbs2VqqVCn18/PTp59+WgcMGKD333+/enp6clTcDb7//nsNDg7O8Zrr1KlTriHXxcVFBwwYYHYFXlXeS1H8kWcLhjxrOeTZwkemvT3k2aJDns0/Mu2dgaZtAWS9eG8MCr/88ou2aNFC27Zta0zKnj3oRkdHG+tmv1ofVLdu3Wo2f9LXX3+ttWvX1u7duxvr8GGXPwMGDNBXXnlFJ02apPfee682atRIZ82apbt37zZbj/2ad5mZmfrPP/+or6+vli5dWp944gmz5ZcvX9Yvv/xS69atq+3bt7dSlbZr165d2rhxY33yySf11VdfzbF86tSp6ubmphMnTtTExEQrVHhn+v333/XBBx/Uxo0ba+vWrfW1117ThIQEa5dlk7I+31evXm12enJuIfe7775Tk8lkXKwFKG7Is5ZHnrU88mzhINPePvKsdZBn84dMW/zRtC2ggwcP6qZNm1RVNSYmxvigW7lypXbu3FlbtmxpFnRffPFFveuuu4yJyPk23VxMTIxGREQYP1++fFm//vprrVOnTp6PUMC/MjIydOTIkRoaGqqq1/fbhAkTNDw8XCtXrqwzZ87UtWvXWrfIYib77+yGDRvUz89P77777hyn7F25ckU//fRTbdy4sR47dqyoy7RZu3bt0goVKuioUaPMTv1csWKFcVVd1etHKHh7e2t0dLQeP37cGqXekXjvvLnMzEyzi6nEx8erg4ODDho0yKwpkBVys1/IYePGjZw2hmKNPGtZ5FnLIs8WDjLt7SPPWhfvnbdGpr2z0LQtgMzMTL3vvvvUy8tLJ02apPb29jpv3jxjedbV9rIH3aNHj+qrr75qdvoEVM+ePasJCQlmH2ZZQeLKlSu5Bl3eTG4ta//9888/6u3trW+//baxrHv37urm5qYtW7bUBg0aaMeOHZmH7j9k7c8LFy5oRkaGXrx4UVWvh9zatWvrww8/rH/88YfZNleuXGEy/GzOnTunbdu21cGDB5uNT5kyRU0mk3bo0MEs6I4bN05dXFz0rbfeIpxZSPY/0GiymLtw4YLx71WrVqmq6uLFi9XHx0eHDh1qNn9a586dtXr16vrNN9+YvTb5XEJxRJ61HPKs5ZFnLY9MWzDkWesjz94amfbOQtPWAmrXrq329vY6evToHMuygm7btm11586dqso3QzfauXOnNmvWTOvWrat2dnY6fvz4HFcozB50Q0JCrFlusZL1DVt0dLQOGjRIVVXDwsLU09NTDx06pEePHtVvv/1WAwMDuZjALWSFge+++05DQkK0Xbt22rFjR922bZuqqv72229aq1YtfeSRR/hj4RZ2796ttWvX1p9++sn43Z41a5aWLl1a33//fe3UqZN2797dLOhOnTqVC4ig0P3000/q7e2tV69e1Zdffllr165tnMq4ePFi9fLyyhFymzRpwucR7ijk2YIhzxYe8qzlkGkLjjwLW0amvfPQtC2A9PR0TU9PVx8fH61evbrWr19fN2zYkGOi5pUrV2rz5s21c+fOmpaWxrdB2cTFxamLi4uOGDFCv/32W3399dfVZDLpp59+aqyT/QiFFStWaMWKFfWRRx6xVsk268iRI/rhhx/q+++/rz/99JPZsrVr12rlypW1efPm6u3tnePbc16T/+1///ufOjs764QJE3TZsmXatWtXdXR0NI462rBhg9arV0+7detmBF+YW7Rokdrb25u93o4dO2achrdz507t2LGjBgYGsg9RpDZt2qTt27dXDw8PrVChgh49etRsefaQm/20Mi7MgDsBebbgyLOWQ54tfGTagiHPwpaRae88NG1vQ9Yb9J49e/T8+fPGeNOmTbVevXq5Bt1Nmzbp4cOHi7ROW7d37161t7c3u5DF9u3btXz58vrss88aY9k/EC9fvqwrV65ksvEbbN++XWvUqKH33nuvVq5cWWvWrKlLliwxW2fYsGFapUqVHPNU4b9dvHhRO3fubLxWjx49qjVr1tTnnntOVf99jcbGxmqTJk2Ys+omfvnlF3V0dNQvv/xSVc1/t7PeM+fMmaPNmzfXU6dOWaVGlCzZX4PDhg1Tk8mkPj4+xmd79vnAFi9erDVq1NDQ0FCzU8IJuSiuyLOWQZ61HPJs4SPTFhx5FraITHvnshPki6qKyWSSr776Sh566CGZNWuWnDhxQkRE/vzzT3FxcZFnn31WNm7cKCIiEyZMkLCwMAkMDBQfHx9rlm5TVFVWrVolmZmZUr9+fWP8m2++keTkZImPj5dZs2bJ559/LqdOnTKWOzk5Sffu3aVOnTrWKNsm7dixQ1q0aCGPP/64rF27VpYtWyYZGRnyySefSGpqqly7dk1ERNq0aSNVq1YVV1dXERHJyMiwZtk2a/LkyfLuu++ajaWlpUlCQoKEhITIuXPnpEWLFtKpUyf58MMPRUTk448/lrNnz0qHDh1kw4YN4uXlZY3SbZ6vr6+4ubnJxx9/LEeOHBGTyWQss7O7/nEUHx8vvr6+xusUKCyZmZnGa/Dy5cvSq1cvWbZsmdx1113SvHlzOXHihDg4OMjly5dFROSJJ56QiRMnyvnz56VGjRrG/WS9doHihDxrGeRZyyHPWh6ZtnCQZ2FryLR3OOv2jIunb775Rp2dnXXmzJl67ty5HMuzTtm57777tGzZsrp582YrVGm7UlNTNTMzU5OTkzUyMlLt7Ox0zZo1OnPmTC1fvry+8847OnPmTI2MjNRKlSppYGCgtmzZUr///ntOe7rBsWPH1N3dXR988EGz8RYtWmitWrX07NmzZuPt2rXTdu3aFWGFxUt6erpGRkaqyWTSuXPnmi178MEHdfTo0ert7a3PP/+8MU/dmTNn9MEHH9RFixapKqfm/Zdly5apg4ODPvXUU2ZzKSUnJ+srr7yiFSpU0F27dlmxQpQE2Y8kmD59us6YMUNPnjypqtevmtu+fXutW7eu2REyixYtMtuOoxFQ3JFnC4Y8aznkWcsj0xYu8ixsBZn2zkfT9j+sWbNGk5OTVfX6B9fff/+tHTp00ClTpqjq9cCWNfdSTEyMsd3EiRN1/PjxZvOEQHXLli3ao0cPPXLkiKpev7Lhq6++qiaTSe3s7HLMTXXw4EH9+uuvtUuXLhofH2+Nkm3ar7/+qi1atNAePXoY835NnjxZTSaTNm/eXLt3765PPvmkTp48WU+fPq1z587VNm3a6OnTp61cue26ePGiTpw4UU0mk86ZM0dVr3+Qvfrqq+rm5qadO3c2C7Gvvfaa1q9f33hN49auXbums2fP1lKlSqmfn58+/fTTOmDAAL3//vvV09NTt27dau0ScQe78Q/QV155RT08PHTOnDlmYXbTpk3arl07rVGjhq5atUqDg4M1KCiIUItiizxrWeRZyyLPFg4ybeEhz8LayLQlB03bm8jIyND169drmTJlNCkpyRjPzMzU++67T4cPH67nzp3TiIgIbdu2rfr4+Ki9vb1OnjzZbF38Ky4uTh0dHXX48OFm4+fPn9dJkyapnZ2d2dxA6enp1iiz2Pnxxx+1R48e2qNHDw0PD9cqVaro8uXL9dixY/rdd9/ptGnT1MvLS2vVqqX33HNPjsnIcV32D66DBw/qiBEj1GQyGUcbXLx4UUNCQrRx48b6wgsv6Ntvv61hYWHq5ubGRQZuw++//64PPvigNm7cWFu3bq2vvfYac/uhSM2bN0/d3d11x44dxtilS5c0JSVFVVUTEhK0Z8+eWrNmTe3UqZNxJBKf7ShOyLOWR54tHORZyyHTFh3yLGwBmfbORtP2P5w5c0ZVVQ8cOKB///23Xrt2TUeMGKFNmzbVUqVKae/evXX+/PmakpKiAwcO1JCQEMJZLuLi4tTZ2VlHjhxpNp4VKpKTk3XEiBFqZ2enS5cuVVXeRP5L9tfZ6tWrtVu3buri4mJ2IYwsycnJ+uWXX5pNNI7cLV++XP39/fWRRx5RJycnNZlMOmvWLFVVTUlJ0cjISA0ODtbAwEB96qmnOPWpAK5du2btElBCBAcH68cff2w2Nm7cOH3yySdVVXXfvn06a9Ys9fPz0/bt25u9jx44cMD4rOLzHcUVedYyyLOWR54tPGTaokGeRVEi05Y8NG1vkFuwOnTokJpMJh09erRxStmmTZv0q6++MlvviSee0Oeff55DzW+wY8cOdXNzyxFwx4wZoy+++KLx84ULF3TEiBHq6OioCxcuLOoyi42s1+iNr9UffvhBu3Xrpp07d9bY2FhjPOubNPy3bdu2qbOzs3744Yd67tw53bFjhw4fPtws5Gb9fqelpRHSCij7a5g/alFY/vnnH507d67ZVXNVVYcPH66enp4aGRmp/v7++uCDD+qIESP0+eef16ZNm+qJEyfM1uezHcUJedbyyLOWRZ4tXGTaokOeRVEh05ZMNG2zyXrxpqam6pkzZ3Tt2rV6/PhxVVWdM2eO2tnZ6YQJE/TChQtm2x0/flxfffVVrVixotlE5Li+T++99141mUx64MABY3zKlClavnx5/fbbb83WT0lJ0UGDBmnFihWNw/nxr6wg8NNPP+mQIUN04MCBOnHiRGP5Dz/8oD169NDg4GBjTjDk3YoVK/Tuu+825v1Tvf7h+NJLL6nJZNIlS5ZYsToABTVt2jSNiooyfu7Xr5927txZZ86caczZuXbtWg0ICMgRcIHigjxreeRZyyLPFj4yLXBnI9OWHDRt/19WwI2Pj9fQ0FD18/NTJycnLVu2rD722GOamJioMTExajKZdNKkSXr+/HlVVf322281LCxM69atyxxAN5GYmKg+Pj7atm1bPXPmjEZHR2vFihX1+++/z7Fu1txf2eddg7nly5erk5OTPv7449qlSxf18vLSgIAAY5+tWrVKH3jgAW3evLn+/PPPVq62ePnxxx/Vzs5Od+7cqar//lGxefNmLVWqlJpMJp0/f741SwSQRzce7ZKSkqKvv/66Ojs7m50qlv0P2rS0NO3evbvef//9HC2DYok8W3jIs5ZFni1cZFrgzkGmLdlo2uq/AXf79u1atWpVff7553XhwoW6Z88eHTFihNasWVPr1aunR48e1U8//VRNJpNOnjxZ09LS9Ny5c7ps2TKusvkfEhMTtWrVqlqlShWtXLmyEXCzH5o/a9YsY/4v5C4xMVEbNGigb7zxhqpen0MpPj5emzRpos2aNTPW++abb7Rv3768LvPp3Llz2r59ew0NDdV9+/YZ48ePH9fHHntMp06dyhW0gWLi2rVr+vfffxtHGKqq/v333zp58mQtW7asTpkyxRg/f/68zpgxQ7t166aNGjUyTsPl9DEUJ+TZwkeetQzybOEj0wJ3DjJtyVbim7bZA66Li4tGRkbmmJQ5JiZGGzVqpIGBgXrlyhWdPXu2li5dWkeOHJljPhGoHjlyRGNiYvSdd97Ry5cvG+OnT5/WevXq6V133aUJCQlm3/iMHj1aTSaT7tmzxxolFxsHDx5Ub29v/e2338zGd+/erdWqVdN33nnHGEtNTS3q8oqNrNfen3/+qTExMTpr1iw9duyYqqp+9tlnGhQUpI8//rj+8ccfeuLECY2MjNTAwECzby8B2K7Vq1frCy+8oNWqVVNvb29t1qyZfvPNN3r58mW9ePGiTpw4UcuWLWs0DDIzM/WVV17Rfv36GRmACzSgOCHPWh55tvCQZy2HTAvc2ci0KPFNW1XVo0ePauXKlfXhhx82xrJOa8oyZ84cdXV11Tlz5qiq6qRJk7R8+fJ69uzZIq/Xlm3fvl1r1qypTZs21fLly6ufn59eunTJWJ6UlKTVqlXTNm3aGPOlRUVFqbOzs/7555/WKrvYuHz5staoUUMnTJiQYzwoKEhff/11K1VW/HzxxRfq5uam9957r7q6umqDBg00OjpaMzMzdenSpdq5c2c1mUzq5+enFStW5HRRoJiYP3++ent76+DBg/Wtt97SGTNmaFBQkLq4uOi0adM0NTVVk5OTddKkSerm5qbTpk0zts3645cLsqA4Is9aDnm2cJFnLYtMC9yZyLRQpWmrqtevptu8eXMNCQnRX375xWxZ9m/P27Ztq7169TJ+/vvvv4usxuIgLi5OnZ2d9fXXX9fExERNSEjQ6tWr6+eff2623qlTp7RatWrauXNnff7559XJyYmAexPZT2PIzMzUa9euaUREhLZp00ZjYmLM1u3evbsxGTnz1vwrt1NBdu7cqVWrVtV58+bpxYsX9dq1a/rSSy9py5YtjQ+7ixcv6oYNG3T9+vXGEQsAbNucOXO0dOnSGhMTY3ZknKrqI488og4ODvrxxx+r6vXPoujoaDWZTLpo0SJjPd4/UVyRZy2DPGt55FnLINMCJQeZFllo2v6/ffv2adeuXbVLly5mQTf7C/2+++7Txx9/PNdlJV1CQoI6OTnpqFGjzMZbtWqlr7/+uoaFhemnn36q+/fvV9Xrc1mVK1dOTSYT3/be4MiRI2anhd0Y0Pbs2aO9evXSli1bamRkpK5cuVKHDBmibm5uGh8fX9Tl2rSsfXfo0CH93//+Z4yvWLFCa9WqZTYvUGpqqg4dOlQbNmzIH7BAMbRw4UI1mUw5GivZjzLs2rWr+vr66pUrV1T1esj9+OOPOW0MdwzybMGQZy2HPGtZZFqg5CDTIjs7gYiI1K1bV959910xmUwyceJE2bBhg4iImEwmyczMlOPHj4uzs7N07txZRERUVUwmkzVLthmZmZkyf/58KVu2rFSqVMkYnzJlimzcuFEOHjwoe/fulX79+sl7770n58+fFw8PDzl06JDs379f/P39rVe8jcnIyJAPPvhA3n//fXnjjTdERMTOzk4yMzNF5Prrzs/PT6ZOnSrt27eXzz//XCIiImTz5s2ybt06ueuuu6xZvs2xs7OTkydPSvPmzeW1116TxYsXi4iIi4uLpKWlyeXLl0VEJD09XVxcXGTy5Mmyb98++f77761ZNoDbsHPn/7F3n9FRVe/bx69JD4QOSQQCkW6kCoIUBQSpAiKIIB1FpHcpUqWJdKSrVFH40RRUQEDhLwLSg0hXOiSA9ABps58XPBkZEzSBSWZCvp+1Zi1nnzMz9xwnycU95+z9myTJy8tLd+7csY17eHjYfof27t1bly5d0rZt2yRJgYGBatWqlTw8PBQTE5PyRQMORp59dORZxyHPOh6ZFkg7yLSw49yeset52BkK/fr1MyVKlOCSkoc4f/686d69uylXrpyZOXOmGTt2rMmRI4dZu3at7QyOLl26mAwZMpiTJ086t1gXd+7cOduxfHAlyNjYWLuzYWJjY01UVJS5efOmuXnzpjNKTRV++ukn4+bmZp5//nnToEED89VXX5m7d++a3Llzm+bNm9vtGx4ebkqWLGk2bNjgpGoBPI7OnTsbX19f88UXX9hdShb3u/PIkSPGYrHYVnwHnlTk2UdDnnUc8qzjkWmBtINMizicafsP/zxDYd++ffr44481ffp0LViwQLlz53Z2iS4pZ86c6t+/v55//nlNnjxZAwcO1JIlS1SrVi3du3dPklS7dm3lyJFDkZGRTq7WteXKlct2LFetWqWxY8dKuv8NuzFGkhQVFaWRI0dq/vz5ypAhgzJkyODMkl1alSpV1KZNG0VHR8vDw0MzZ87Ujz/+qGXLlmn9+vVq1qyZ9u/frxMnTuiTTz5ReHg4Z3gAqUxsbKwkadq0aWrTpo3at2+vFStW2P7+xJ1leODAAVWqVEnFixd3ZrlAsiPPPhryrOOQZx2PTAs8+ci0+CcPZxfgiuKCbq9evVSrVi1du3ZN27dvV4kSJZxdmksLDAzUoEGD5ObmJm9vb+3bt08vv/yyfH19JUk//PCDcuTIIX9/fydX6voCAwP1wQcfaNSoUVq1apWMMerfv7/c3Nx09+5d9enTR59++qlCQ0OdXapLsVqtcnP7+7uoyMhIeXt7q1GjRrJarWrWrJlmz56tsWPH6t1339XatWvVtGlT1a1bV97e3pKkb7/9Vnny5HHWWwDwCNzd3RUbGyt3d3fNmDFDktS+fXtJUsOGDZUuXTpFRUVpwYIFKlCggAICApxZLpAiyLOPhjzrOOTZR0emBdImMi3ice6Jvq7tyJEjpn79+ubgwYPOLiVVuXjxounSpYvd5VAjRowwfn5+JjQ01MnVpS7/PJaxsbGmZ8+eJn369GbPnj3OLs+lxC3QcObMGbNy5Uq7bZcuXTJFihQx06ZNM+Hh4eb11183lStXNt9//72Jiooyu3fvNlu2bDEXLlxwRukAHCQmJsb23x07djS+vr5myZIl5u7du+bVV181JUqUsC3QwOJLSCvIs4+GPOs45NmkIdMCINMijsWY/399ChIUHR0tT09PZ5eR6oSFhWnUqFEKDQ1VZGSkDhw4oK1bt6p06dLOLi3ViTuWe/fu1c2bN/XHH39o69ateu6555xdmss5e/asSpUqpatXr6p27dpq3bq1SpYsqUKFCmnNmjUaN26cVqxYoStXrmjQoEG6du2a2rRpo1atWjm7dAAOEnd2giR16tRJixYtUmBgoLy8vLR//355enra7QOkBeTZR0OedRzybNKQaQGQaSFJzGn7Hwi4jybucqgCBQro6tWr2r59OwH3EcUdy8KFCysyMlLbt28n4D6E1WrV008/rRdeeEFhYWHasGGDatSooTlz5uju3bvKlCmTdu/erWeeeUYjRoyQu7u7li9frhs3bji7dACJELdibkLivoOOu6xMkmbMmKGmTZvK3d3dFm5jYmIIt0hzyLOPhjzrOOTZpCHTAk82Mi0SizNtkawuX74sq9XKXCsOwLFMnOPHj6t///6yWq1q1aqVLBaLpkyZosyZM+ubb75R2bJl9X//93/y8vLS0aNHlT59ehZkAVKBB+f3W7JkiS5evKjLly+rVatWevrpp21z+MV58MwDY4wsFotiYmLk4cF0/gCShgzmOBzLxCPTAk8mMi2SgqYtgCfO0aNH1bNnT8XGxuqTTz5Rrly59Ntvv2nUqFF688031aJFC9sfPACpy/vvv68vvvhC1atX15EjR3Tz5k116dJFHTt2jHe2wYOhmJ95AEBqQ6YFnlxkWiQGTVsAT6Tjx4+rS5cukqQhQ4aoYsWKTq4IwONatmyZevXqpW+//VYlSpTQ2rVrVbduXa1atUoNGjRwdnkAADgcmRZ48pBpkVjMaQvgiVSwYEFNmzZNbm5uGjFihLZu3erskgA8pgsXLqhChQoqUaKEvvrqKzVt2lTTp09XgwYNdOfOHZ08edLZJQIA4FBkWuDJQ6ZFYtG0BfDEKliwoKZOnSpPT0/17dtXO3bscHZJABIpoQUazp07J19fX+3Zs0cdOnTQRx99pI4dO0qSvvjiC3355Ze6d+9eSpcKAECyItMCqReZFo+Dpi2AJ1rBggU1btw45c6dWzlz5nR2OQASKW7erl9//VUXL16UJDVt2lSrV6/W888/r5kzZ9rC7d27d/X1118rLCxMPj4+TqsZAIDkQqYFUicyLR4HTVsAT7wiRYpo8eLFypMnj7NLAfAfHjwbYePGjapbt66++OILXblyRc8995x69+6tnDlz6syZMwoPD9evv/6qRo0a6cKFC5o0aZKk+ws0AADwpCHTAqkHmRaO4OHsAgAgJXh5eTm7BAD/wRhjOxth+vTpioiI0J07dzR27FhZLBZ17NhR77zzjiRp3LhxmjhxonLmzKnAwEDt2rVLHh4eio2NjbfiLgAATwoyLeD6yLRwFIuhdQ8AAJzMGCOLxSJJ+vDDDzVp0iR9/vnncnNz0+rVq/X1119r4MCB6tixo9KnT69Lly7pyJEjCggIUMGCBeXm5qaYmBh5ePB9NAAAAJyDTAtH4lMAAACc5vfff9ezzz4ri8Wi2NhY3bp1S6tWrdLQoUP1+uuvS5Jee+01Zc6cWUOHDpUktWjRQoGBgfL397c9j9VqJdwCAADAKci0SA7MaQsAAJxi4MCB6tKli7Zs2SJJtkvAHrwcLG7l3IkTJ6pChQqaOnWqlixZohs3btg9V9wlaAAAAEBKItMiufBpAAAATlGpUiVFR0frk08+0U8//SRJypw5swoUKKBPP/1UkuTj46Po6GhJ0tNPP60sWbJo3Lhx2rZtmyT7RR4AAACAlEamRXKhaQsAAFJcbGys6tSpozFjxujKlSuaNWuWfvzxR0nShAkTdOfOHVWtWlXR0dG2Mw5u3LihuXPn6oUXXtCAAQMkcTYCAAAAnIdMi+TERBkAACBFWa1W26Vi3t7eKly4sFatWqWbN2/Kx8dHFSpU0Ny5c/Xuu+8qf/78evbZZ3XhwgVFRESodOnSqlSpks6cOSOr1UrABQAAgFOQaZHc+FQAAIAUFRdKe/furTfeeEOZMmVSgwYNtH37dn300Uf65Zdf9NJLL2nXrl1q06aNQkJC9Oqrr+rw4cOSpAMHDihXrlyKjo6WMcaZbwUAAABpFJkWyc1i+GQAAIAUtnv3btWvX19LlizRSy+9JElav369BgwYoMDAQH3wwQeqWLGi3WMuXbqkUaNGafHixdqyZYueffZZZ5QOAAAASCLTInkxPQIAAEhxPj4+MsbYXQpWs2ZNGWNUr149eXt768aNG6pTp44k6dy5c1q5cqV++eUXbdy4kXALAAAApyPTIjkxPQIAAEhWcRf1PHhxT9x///nnn5KkmJgYSVKtWrUUEhKibdu2aceOHbb9c+fOrcaNG2v9+vUqWbJkClUOAAAA3EemRUrjTFsAAJBsHlxY4erVq5KkbNmyqVixYmrXrp3ee+895cmTR1WqVJEkXb9+XSVLllTNmjXVtGlTu+fImTOnU94DAAAA0jYyLZyBpi0AAEgWD14qNmbMGK1Zs0a3bt1S+vTpNXXqVPXt21eXL19W9erV1atXL2XKlEk//vijIiIiNH/+fFksFsXGxtpW5QUAAABSGpkWzsJCZAAAIFkNHTpUs2bN0qRJk1S2bFnVrl1b6dKl0/fff69cuXJp8uTJWrNmje7cuaOcOXNqyZIl8vT0tDujAQAAAHAmMi1SGk1bAACQLIwxCgsLU8OGDfXBBx+oXr16WrdunZo2baoxY8aoY8eOtn1v3rwpX19feXh4yGKxKCYmRh4eXBAEAAAA5yLTwllo9QMAAIdo0qSJPv30U9t9i8WiGzdu6Ny5c6pdu7bWr1+vN954Qx999JE6duyoW7duadKkSTLGKGPGjPL09JTFYpExhnALAAAApyDTwlXQtAUAAA6RI0cOde3aVYsXL7aNFSlSRAULFlT79u3VuHFjTZo0Se+9954k6eLFi1q2bJk2bNhg9zwWiyVF6wYAAADikGnhKmj5AwAAh5g+fbqyZMmitm3bSpLeeustxcTE6IUXXtCnn36q119/Xe+8844k6e7du7aFGqpXr+7MsgEAAAAbMi1cBU1bAADwWB5cXGHkyJGKjIxU27ZtZbVa1bJlS3Xt2lXHjh1TaGio3njjDQUHB+vXX3/V9evXtWfPHrm5ubFAAwAAAJyKTAtXwycJAAA8lrhgumjRIlmtVo0bN049e/ZUu3bttHDhQuXMmVNTpkxRhw4ddOPGDZ0/f14VKlTQ3r175enpqZiYGMItAAAAnIpMC1djMcYYZxcBAABSt3Pnzql69epq3LixRo4cKUkaMGCAxo8fr88//1ytWrVK8HGxsbFyd3dPyVIBAACABJFp4UqYHgEAACTZP4NptmzZ1LRpU/366686cuSIihQpojFjxshisah9+/Zyd3dX8+bN4z0P4RYAAADOQqaFK+O8bQAAkGRxwXTp0qUKDQ2Vr6+vOnfurJMnT2rixIm2/UaPHq2+ffuqZcuW+uGHH5xVLgAAABAPmRaujOkRAADAI1m/fr1q166tdOnSafr06apXr55Onjyp2rVra8KECWrZsqVt39mzZ+vtt9+WhwcX+QAAAMB1kGnhqmjaAgCAREloNdw333xT27dvV5EiRZQ3b14VKFBA0dHROnz4sD788EPlz5/fbv+YmBhCLgAAAJyGTIvUgk8YAABIlLhwe/DgQeXLl0/p0qVTu3bt5O/vr+LFi8tisWj27Nk6ceKEMmbMqK1bt8YLuIRbAAAAOBOZFqkFc9oCAIBE2759u4oXL67+/ftr06ZNqlGjhm7cuKHTp0/rnXfe0fr16/Xqq6/q7NmzWr58ubPLBQAAAOIh0yI1YHoEAADwUMYYWSwWu7GlS5dqxYoVOnz4sFq2bKmaNWuqcuXKmjNnjpo0aSJjjDZu3KiXX36ZlXQBAADgdGRapEY0bQEAQIIenO8rLCxMxhgFBgbKYrHo7Nmz2rx5s7p27aoaNWro2rVrio2N1axZs1SoUCHbc8TGxhJyAQAA4DRkWqRWTI8AAADiMcbYwu3w4cNVs2ZNVaxYUcWKFdOaNWuUPXt2tWzZUidOnJCnp6cuXryozZs3a9++fXbPQ7gFAACAs5BpkZpxpi0AAHiokSNHavLkyZoyZYrSp0+v5cuX64cfftDw4cPVsmVL+fn5KSoqSj/++KM2btyojz76iIUZAAAA4FLItEiNaNoCAIAE3bhxQzVr1lSrVq3UqVMn23jfvn31+eefa8OGDSpdunS8x8XExBByAQAA4BLItEitmB4BAADEY4xRTEyMLl26pMyZM0uS7t27J0kaN26cihUrpokTJ0q6P0/Ygwi3AAAAcAVkWqRmNG0BAEC8kGqxWJQtWzbly5dPs2fPliT5+PgoKipKkvT000/Ly8tLkmzzhAEAAADORKbFk4RPJAAAadyDK+oeOnRIf/75p27duiVJGjx4sK5cuaLmzZtLki3U/vnnn8qSJYtzCgYAAAD+gUyLJw1z2gIAAElSv379tGrVKp0/f15vvvmmWrVqpSpVqmjx4sX68MMPZbVaVbJkSZ05c0a3bt3SgQMHuGwMAAAALoVMiycFTVsAANKoB89GWL16tXr06KGZM2fq3LlzWrRokby8vNSnTx/VqFFDf/zxh6ZOnSqr1arMmTNr6NCh8vDwYIEGAAAAOBWZFk8qmrYAAKRBkZGR8vb2liRt3LhR33zzjQoVKqSuXbtKknbs2KERI0YoKipK3bt316uvvhrvOWJjY+Xu7p6idQMAAABxyLR4kjGnLQAAacwXX3yh6dOnyxijo0ePqkuXLpo7d67Cw8Nt+7zwwgsaMmSIvL29NX36dH311VfxnodwCwAAAGch0+JJR9MWAIA0whijmJgYTZgwQenSpZPFYlHhwoU1bdo0PfPMM9q0aZN+/vln2/7lypXTkCFDdO3aNe3cudOJlQMAAAD3kWmRVtC0BQAgjbBYLIqJidH169dtl5FJUvXq1TVq1ChZrVbNmDFD27Zts20rW7as5s6dqwkTJjijZAAAAMAOmRZpBbMsAwCQxmTIkEEBAQGS/p7Dq2bNmoqNjdWHH36oqVOnymKxqHz58pKkkJAQSfaLPAAAAADORKbFk45PKQAAT7hNmzZp5MiRkiRPT09FREQoQ4YMtu1xa5LWqVNHgwcP1tmzZzVkyBD99ttvds9DuAUAAICzkGmR1nCmLQAAT7DIyEj973//044dO5Q+fXq9/fbbioyMVHR0tKT4Cy/UrVtXxhh98803evbZZ51RMgAAAGCHTIu0yGLivooAAABPpAsXLujjjz/Wr7/+qgoVKmjNmjVq3ry5MmTIIKvVapsL7M6dO7p06ZI6dOigQoUKSeLyMQAAALgGMi3SGpq2AACkARcvXtSoUaO0efNmHTp0SPnz51eGDBkUEREhq9Uqi8UiHx8fZc6cWT/++KM8PLgYBwAAAK6FTIu0hE8vAABpwFNPPaVBgwbJ3d1dmTNnVpUqVWxzgkVFRcnDw0Nubm4yxshisdgWcwAAAABcBZkWaQnnhgMAkEYEBgaqf//+KlWqlH744QeNGTNGkuTl5aXY2FhJksVikTGGcAsAAACXRKZFWsH0CAAApDFhYWEaPXq09uzZo6pVq9rOTgAAAABSCzItnnScaQsAQBoTGBiogQMHKn/+/Lp06ZL4/hYAAACpDZkWTzrOtAUAII26evWqMmfObDfvFwAAAJCakGnxpKJpCwBAGme1WuXmxsU3AAAASL3ItHjS0LQFAAAAAAAAABfCVxAAAAAAAAAA4EJo2gIAAAAAAACAC6FpCwAAAAAAAAAuhKYtAAAAAAAAALgQmrYAAAAAAAAA4EJo2gLAE2jz5s2yWCy6fv16oh8THBysyZMnJ1tNAAAAQFKQaQGkZTRtAcAJ2rRpI4vFovfeey/ets6dO8tisahNmzYpXxgAAACQSGRaAEg+NG0BwEmCgoK0ZMkS3b171zZ27949ffnll8qTJ48TKwMAAAASh0wLAMmDpi0AOMlzzz2noKAgrVy50ja2cuVK5cmTR6VKlbKNRUZGqlu3bvL395ePj48qVaqkXbt22T3X999/r0KFCsnX11dVq1bVqVOn4r3e1q1b9eKLL8rX11dBQUHq1q2bIiIiEqzNGKNhw4YpT5488vb2Vs6cOdWtWzfHvHEAAAA8Mci0AJA8aNoCgBO1a9dO8+bNs92fO3eu2rZta7fP+++/rxUrVmjBggXau3evChQooJo1a+rq1auSpLNnz+r1119XvXr1tH//fr3zzjvq37+/3XP88ccfqlWrlho1aqQDBw5o6dKl2rp1q7p06ZJgXStWrNCkSZM0e/ZsHT9+XF9//bWKFSvm4HcPAACAJwGZFgAcj6YtADhRixYttHXrVp0+fVqnT5/WL7/8ohYtWti2R0REaObMmRo3bpxq166tkJAQffrpp/L19dXnn38uSZo5c6by58+vCRMmqHDhwmrevHm8ucPGjBmj5s2bq0ePHipYsKAqVKigqVOnauHChbp37168us6cOaPAwEBVr15defLkUdmyZdW+fftkPRYAAABInci0AOB4NG0BwIly5MihunXrav78+Zo3b57q1q2r7Nmz27b/8ccfio6OVsWKFW1jnp6eKlu2rA4fPixJOnz4sMqVK2f3vOXLl7e7Hxoaqvnz58vPz892q1mzpqxWq06ePBmvrjfeeEN3795Vvnz51L59e61atUoxMTGOfOsAAAB4QpBpAcDxPJxdAACkde3atbNd0jV9+vRkeY3bt2+rQ4cOCc7hldACEUFBQTp69Kg2btyoDRs2qFOnTho3bpy2bNkiT0/PZKkRAAAAqReZFgAcizNtAcDJatWqpaioKEVHR6tmzZp22/Lnzy8vLy/98ssvtrHo6Gjt2rVLISEhkqRnnnlGO3futHvcjh077O4/99xzOnTokAoUKBDv5uXllWBdvr6+qlevnqZOnarNmzdr+/bt+u233xzxlgEAAPCEIdMCgGNxpi0AOJm7u7vtsjB3d3e7benTp1fHjh3Vt29fZc2aVXny5NHHH3+sO3fu6O2335Ykvffee5owYYL69u2rd955R3v27NH8+fPtnqdfv3564YUX1KVLF73zzjtKnz69Dh06pA0bNmjatGnxapo/f75iY2NVrlw5pUuXTl988YV8fX2VN2/e5DkIAAAASNXItADgWJxpCwAuIGPGjMqYMWOC2z766CM1atRILVu21HPPPacTJ05o/fr1ypIli6T7l4KtWLFCX3/9tUqUKKFZs2Zp9OjRds9RvHhxbdmyRceOHdOLL76oUqVKaciQIcqZM2eCr5k5c2Z9+umnqlixoooXL66NGzdqzZo1ypYtm2PfOAAAAJ4YZFoAcByLMcY4uwgAAAAAAAAAwH2caQsAAAAAAAAALoSmLQAAAAAAAAC4EJq2AAAAAAAAAOBCaNoCAAAAAAAAgAuhaQsAAAAAAAAALoSmLQAAAAAAAAC4EJq2AAAAAAAAAOBCaNoCAAAAAAAAgAuhaQsAAAAAAAAALoSmLQAAAAAAAAC4EJq2AAAAAAAAAOBCaNoCAAAAAAAAgAuhaQsAAAAAAAAALoSmLQAAAAAAAAC4EJq2AAAAAAAAAOBCaNoCAAAAAAAAgAuhaQsAAAAAAAAALoSmLYA0r02bNgoODk7SYzZv3iyLxaLNmzcnS034d/Pnz5fFYtGpU6ecXQoAAMATw2KxaNiwYbb7ZK7EO3XqlCwWi+bPn+/sUgA8IWjaAkhxceEv7ubj46NChQqpS5cuCg8Pd3Z5qcaqVatUu3ZtZc+eXV5eXsqZM6eaNGmiH3/80dmlAQAA4B/+mYE9PDyUK1cutWnTRufPn3d2eQ6xf/9+tWjRQkFBQfL29lbWrFlVvXp1zZs3T7Gxsc4uDwBSFQ9nFwAg7frwww/19NNP6969e9q6datmzpyp77//XgcPHlS6dOlSrI5PP/1UVqs1SY956aWXdPfuXXl5eSVTVQ9njFG7du00f/58lSpVSr169VJgYKAuXryoVatWqVq1avrll19UoUKFFK8tpbRs2VJNmzaVt7e3s0sBAABIkgcz8I4dOzR//nxt3bpVBw8elI+Pj7PLe2SfffaZ3nvvPQUEBKhly5YqWLCgbt26pU2bNuntt9/WxYsXNXDgQGeXmWzy5s2ru3fvytPT09mlAHhC0LQF4DS1a9dWmTJlJEnvvPOOsmXLpokTJ+qbb75Rs2bNEnxMRESE0qdP79A6HiVYubm5OS1UT5gwQfPnz1ePHj00ceJEWSwW27YPPvhAixYtkofHk/nrPe7/v7u7u9zd3Z1dDgAAQJL9MwNnz55dY8eO1erVq9WkSRMnV/doduzYoffee0/ly5fX999/rwwZMti29ejRQ7t379bBgwedWGHyiYmJkdVqlZeXV6puugNwPUyPAMBlvPzyy5KkkydPSro/16yfn5/++OMP1alTRxkyZFDz5s0lSVarVZMnT9azzz4rHx8fBQQEqEOHDrp27Vq85127dq0qV66sDBkyKGPGjHr++ef15Zdf2rYnNKftkiVLVLp0adtjihUrpilTpti2P2xO22XLlql06dLy9fVV9uzZ1aJFi3iXu8W9r/Pnz+u1116Tn5+fcuTIoT59+vznZWN3797VmDFjVKRIEY0fP96uYRunZcuWKlu2rO3+n3/+qTfeeENZs2ZVunTp9MILL+i7776ze0zc+/nf//6n4cOHK1euXMqQIYMaN26sGzduKDIyUj169JC/v7/8/PzUtm1bRUZG2j2HxWJRly5dtHjxYhUuXFg+Pj4qXbq0/u///s9uv9OnT6tTp04qXLiwfH19lS1bNr3xxhvx5kqLu4Rwy5Yt6tSpk/z9/ZU7d267bQ8+Zvfu3apZs6ayZ88uX19fPf3002rXrp3dc0ZERKh37962S/YKFy6s8ePHyxiT4Hv5+uuvVbRoUXl7e+vZZ5/VunXr/vX/DwAAQFK9+OKLkqQ//vjDbvzIkSNq3LixsmbNKh8fH5UpU0arV6+O9/jr16+rZ8+eCg4Olre3t3Lnzq1WrVrpypUrkqSoqCgNGTJEpUuXVqZMmZQ+fXq9+OKL+umnnxz2HoYPHy6LxaLFixfbNWzjlClTRm3atLHdT2omW7ZsmUJCQuTr66vy5cvrt99+kyTNnj1bBQoUkI+Pj6pUqRIvT1apUkVFixbVnj17VKFCBVtGnDVrlt1+iT1GcfPWjh8/XpMnT1b+/Pnl7e2tQ4cOJTinbVhYmNq2bavcuXPL29tbTz31lBo0aBCvzhkzZujZZ5+Vt7e3cubMqc6dO+v69esJvpdDhw6patWqSpcunXLlyqWPP/74X/7PAEjNnsxTsQCkSnFBNVu2bLaxmJgY1axZU5UqVdL48eNt0yZ06NBB8+fPV9u2bdWtWzedPHlS06ZN0759+/TLL7/Yzp6dP3++2rVrp2effVYDBgxQ5syZtW/fPq1bt05vvfVWgnVs2LBBzZo1U7Vq1TR27FhJ0uHDh/XLL7+oe/fuD60/rp7nn39eY8aMUXh4uKZMmaJffvlF+/btU+bMmW37xsbGqmbNmipXrpzGjx+vjRs3asKECcqfP786duz40NfYunWrrl69qh49eiTqTNPw8HBVqFBBd+7cUbdu3ZQtWzYtWLBA9evX1/Lly9WwYUO7/ceMGSNfX1/1799fJ06c0CeffCJPT0+5ubnp2rVrGjZsmO0yvqefflpDhgyxe/yWLVu0dOlSdevWTd7e3poxY4Zq1aqlnTt3qmjRopKkXbt2adu2bWratKly586tU6dOaebMmapSpYoOHToUb2qMTp06KUeOHBoyZIgiIiISfJ+XLl1SjRo1lCNHDvXv31+ZM2fWqVOntHLlSts+xhjVr19fP/30k95++22VLFlS69evV9++fXX+/HlNmjQp3rFeuXKlOnXqpAwZMmjq1Klq1KiRzpw5Y/cZBQAAeBxxDbwsWbLYxn7//XdVrFhRuXLlUv/+/ZU+fXr973//02uvvaYVK1bYMtzt27f14osv6vDhw2rXrp2ee+45XblyRatXr9a5c+eUPXt23bx5U5999pmaNWum9u3b69atW/r8889Vs2ZN7dy5UyVLlnys+u/cuaNNmzbppZdeUp48ef5z/6Rmsp9//lmrV69W586dJd3Pq6+++qref/99zZgxQ506ddK1a9f08ccfq127dvHWd7h27Zrq1KmjJk2aqFmzZvrf//6njh07ysvLy/YFf1KP0bx583Tv3j29++67trl7E5purVGjRvr999/VtWtXBQcH69KlS9qwYYPOnDljO2lk2LBhGj58uKpXr66OHTvq6NGjmjlzpnbt2mX375q491KrVi29/vrratKkiZYvX65+/fqpWLFiql279n8eewCpjAGAFDZv3jwjyWzcuNFcvnzZnD171ixZssRky5bN+Pr6mnPnzhljjGndurWRZPr372/3+J9//tlIMosXL7YbX7dund349evXTYYMGUy5cuXM3bt37fa1Wq22/27durXJmzev7X737t1NxowZTUxMzEPfw08//WQkmZ9++skYY0xUVJTx9/c3RYsWtXutb7/91kgyQ4YMsXs9SebDDz+0e85SpUqZ0qVLP/Q1jTFmypQpRpJZtWrVv+4Xp0ePHkaS+fnnn21jt27dMk8//bQJDg42sbGxdu+naNGiJioqyrZvs2bNjMViMbVr17Z73vLly9sdM2OMkWQkmd27d9vGTp8+bXx8fEzDhg1tY3fu3IlX5/bt240ks3DhQttY3OekUqVK8f5fxG07efKkMcaYVatWGUlm165dDz0WX3/9tZFkRo4caTfeuHFjY7FYzIkTJ+zei5eXl91YaGiokWQ++eSTh74GAADAwySUgZcvX25y5MhhvL29zdmzZ237VqtWzRQrVszcu3fPNma1Wk2FChVMwYIFbWNDhgwxkszKlSvjvV5c3o2JiTGRkZF2265du2YCAgJMu3bt7MYlmaFDh8arOS5zJSQuI3Xv3j0xhyHJmczb29vu9WfPnm0kmcDAQHPz5k3b+IABA+LVWrlyZSPJTJgwwTYWGRlpSpYsafz9/W25N7HH6OTJk0aSyZgxo7l06ZLd/nHb5s2bZ3u8JDNu3LiHHotLly4ZLy8vU6NGDVsuN8aYadOmGUlm7ty58d7Lg3k5MjLSBAYGmkaNGj30NQCkXkyPAMBpqlevrhw5cigoKEhNmzaVn5+fVq1apVy5ctnt988zT5ctW6ZMmTLplVde0ZUrV2y30qVLy8/Pz3YZ04YNG3Tr1i31798/3vxSCU0rECdz5syKiIjQhg0bEv1edu/erUuXLqlTp052r1W3bl0VKVIk3nQEkvTee+/Z3X/xxRf1559//uvr3Lx5U5ISvOwsId9//73Kli2rSpUq2cb8/Pz07rvv6tSpUzp06JDd/q1atbL7Nr9cuXK2hc8eVK5cOZ09e1YxMTF24+XLl1fp0qVt9/PkyaMGDRpo/fr1tqkffH19bdujo6P1119/qUCBAsqcObP27t0b7z20b9/+P88qjjuL+dtvv1V0dHSC+3z//fdyd3dXt27d7MZ79+4tY4zWrl1rN169enXlz5/fdr948eLKmDHjf/4/AgAA+DcPZuDGjRsrffr0Wr16tW0aqKtXr+rHH39UkyZNdOvWLVvW/euvv1SzZk0dP37cNv3WihUrVKJEiXhXT0l/5113d3fb4rlWq1VXr15VTEyMypQpk2D2SqpHyadJyWTVqlWzm8qsXLlyku6fxfrga8aN/zOreXh4qEOHDrb7Xl5e6tChgy5duqQ9e/ZISvoxatSokXLkyPGv79PX11deXl7avHlzglO4SdLGjRsVFRWlHj16yM3t7/ZM+/btlTFjxnj/hvDz81OLFi3s3kvZsmXJp8ATiqYtAKeZPn26NmzYoJ9++kmHDh3Sn3/+qZo1a9rt4+HhYQuwcY4fP64bN27I399fOXLksLvdvn1bly5dkvT3dAtxl+UnVqdOnVSoUCHVrl1buXPnVrt27f5zLtPTp09LkgoXLhxvW5EiRWzb4/j4+MQLelmyZHlooIuTMWNGSdKtW7f+833E1ZVQTc8884xd3XH+eUlbpkyZJElBQUHxxq1Wq27cuGE3XrBgwXivVahQId25c0eXL1+WdH9e3iFDhtjmMMuePbty5Mih69evx3s+SXr66af/622qcuXKatSokYYPH67s2bOrQYMGmjdvnt28u6dPn1bOnDnj/YMiscdCStz/IwAAgH8Tl4GXL1+uOnXq6MqVK/L29rZtP3HihIwxGjx4cLysO3ToUEmyy7uJyboLFixQ8eLF5ePjo2zZsilHjhz67rvvEsxeSfUo+fRxMtm/5VNJ8bJazpw54y1kXKhQIUmym1s2KccoMfnU29tbY8eO1dq1axUQEKCXXnpJH3/8scLCwmz7POzfEF5eXsqXL1+8Y5E7d+54J5+QT4EnF3PaAnCasmXL2lbOfRhvb2+7b52l+99++/v7a/HixQk+5r++9f4v/v7+2r9/v9avX6+1a9dq7dq1mjdvnlq1aqUFCxY81nPHScx8tAkpUqSIJOm3337Ta6+95pBaHvSwuh42bv6xWERidO3aVfPmzVOPHj1Uvnx5ZcqUSRaLRU2bNk1wLrAHz8x9GIvFouXLl2vHjh1as2aN1q9fr3bt2mnChAnasWOH/Pz8klynI98zAABAnAcz8GuvvaZKlSrprbfe0tGjR+Xn52fLQ3369Il3QkOcAgUKJPr1vvjiC7Vp00avvfaa+vbtK39/f7m7u2vMmDHxFj97FAUKFJCHh4dtcTBHS4l8mtRjlJh8Kkk9evRQvXr19PXXX2v9+vUaPHiwxowZox9//FGlSpVKcp3kUyBtoWkLINXJnz+/Nm7cqIoVK/5rYIq7tP3gwYNJCrbS/W+369Wrp3r16slqtapTp06aPXu2Bg8enOBz5c2bV5J09OhRvfzyy3bbjh49atv+uCpVqqQsWbLoq6++0sCBA/+z+Zs3b14dPXo03viRI0fs6naU48ePxxs7duyY0qVLZ2umL1++XK1bt9aECRNs+9y7dy/eCrmP4oUXXtALL7ygUaNG6csvv1Tz5s21ZMkSvfPOO8qbN682btyoW7du2Z3ZkVzHAgAA4L/ENQarVq2qadOmqX///sqXL58kydPTU9WrV//Xx+fPn18HDx78132WL1+ufPnyaeXKlXZnacadtfu40qVLp5dfflk//vijzp49G+8M2H9K6Ux24cIFRURE2J1te+zYMUmyTbuQnMcof/786t27t3r37q3jx4+rZMmSmjBhgr744gu7f0PE/X+XpKioKJ08efI///8DeLIxPQKAVKdJkyaKjY3ViBEj4m2LiYmxNf9q1KihDBkyaMyYMbp3757dfv/2bfRff/1ld9/NzU3FixeXJLvL7R9UpkwZ+fv7a9asWXb7rF27VocPH1bdunUT9d7+S7p06dSvXz8dPnxY/fr1S/B9fPHFF9q5c6ckqU6dOtq5c6e2b99u2x4REaE5c+YoODhYISEhDqkrzvbt2+3m/Tp79qy++eYb1ahRw9Zgdnd3j1f3J598Ypvz9lFcu3Yt3nPGrfIb9/+jTp06io2N1bRp0+z2mzRpkiwWCyvuAgAAp6hSpYrKli2ryZMn6969e/L391eVKlU0e/ZsXbx4Md7+cVNOSffnVg0NDdWqVavi7ReXjeIy2INZ6ddff7XLh49r6NChMsaoZcuWun37drzte/bssV2xltKZLCYmRrNnz7bdj4qK0uzZs5UjRw7bWgzJcYzu3LkT798g+fPnV4YMGWz5tHr16vLy8tLUqVPtXvvzzz/XjRs3HPZvCACpE2faAkh1KleurA4dOmjMmDHav3+/atSoIU9PTx0/flzLli3TlClT1LhxY2XMmFGTJk3SO++8o+eff15vvfWWsmTJotDQUN25c+ehUx288847unr1ql5++WXlzp1bp0+f1ieffKKSJUva5tr6J09PT40dO1Zt27ZV5cqV1axZM4WHh2vKlCkKDg5Wz549Hfb++/btq99//10TJkzQTz/9pMaNGyswMFBhYWH6+uuvtXPnTm3btk2S1L9/f3311VeqXbu2unXrpqxZs2rBggU6efKkVqxYEW/qicdVtGhR1axZU926dZO3t7dmzJghSRo+fLhtn1dffVWLFi1SpkyZFBISou3bt2vjxo3Kli3bI7/uggULNGPGDDVs2FD58+fXrVu39OmnnypjxoyqU6eOJKlevXqqWrWqPvjgA506dUolSpTQDz/8oG+++UY9evSwW3QMAAAgJfXt21dvvPGG5s+fr/fee0/Tp09XpUqVVKxYMbVv31758uVTeHi4tm/frnPnzik0NNT2uOXLl+uNN95Qu3btVLp0aV29elWrV6/WrFmzVKJECb366qtauXKlGjZsqLp16+rkyZOaNWuWQkJCEmywPooKFSpo+vTp6tSpk4oUKaKWLVuqYMGCunXrljZv3qzVq1dr5MiRklI+k+XMmVNjx47VqVOnVKhQIS1dulT79+/XnDlzbAvwJscxOnbsmKpVq6YmTZooJCREHh4eWrVqlcLDw9W0aVNJ96d1GzBggIYPH65atWqpfv36Onr0qGbMmKHnn3/ebtExAGkPTVsAqdKsWbNUunRpzZ49WwMHDpSHh4eCg4PVokULVaxY0bbf22+/LX9/f3300UcaMWKEPD09VaRIkX9torZo0UJz5szRjBkzdP36dQUGBurNN9/UsGHD/rXJ2aZNG6VLl04fffSR+vXrp/Tp06thw4YaO3asMmfO7LD37ubmpoULF6pBgwaaM2eOxo8fr5s3bypHjhy2BQ7Kly8vSQoICNC2bdvUr18/ffLJJ7p3756KFy+uNWvWJMs395UrV1b58uU1fPhwnTlzRiEhIZo/f77tTGVJmjJlitzd3bV48WLdu3dPFStW1MaNGx86Z1tiX3fnzp1asmSJwsPDlSlTJpUtW1aLFy+2LRTh5uam1atXa8iQIVq6dKnmzZun4OBgjRs3Tr17937s9w4AAPCoXn/9deXPn1/jx49X+/btFRISot27d2v48OGaP3++/vrrL/n7+6tUqVIaMmSI7XF+fn76+eefNXToUK1atUoLFiyQv7+/qlWrZlvMt02bNgoLC9Ps2bO1fv16hYSE6IsvvtCyZcu0efNmh72HDh066Pnnn9eECRO0cOFCXb58WX5+fnruuec0b948WwMypTNZlixZtGDBAnXt2lWffvqpAgICNG3aNLVv3962T3Ico6CgIDVr1kybNm3SokWL5OHhoSJFiuh///ufGjVqZNtv2LBhypEjh6ZNm6aePXsqa9asevfddzV69GhbUxlA2mQxzFgNAHAAi8Wizp07x7vUDQAAAHCGKlWq6MqVK/857y8AuCLmtAUAAAAAAAAAF0LTFgAAAAAAAABcCE1bAAAAAAAAAHAhzGkLAAAAAAAAAC6EM20BAAAAAAAAwIXQtAUAAAAAAAAAF+Lh7AJSmtVq1YULF5QhQwZZLBZnlwMAAIAkMMbo1q1bypkzp9zc0u75B2RaAACA1CmxeTbNNW0vXLigoKAgZ5cBAACAx3D27Fnlzp3b2WU4DZkWAAAgdfuvPJvmmrYZMmSQdP/AZMyY0cnVAAAAIClu3rypoKAgW6ZLq8i0AAAAqVNi82yaa9rGXT6WMWNGAi4AAEAqldanBCDTAgAApG7/lWfT7kRgAAAAAAAAAOCCaNoCAAAAAAAAgAuhaQsAAAAAAAAALoSmLQAAAAAAAAC4EJq2AAAAAAAAAOBCaNoCAAAAAAAAgAuhaQsAAAAAAAAALoSmLQAAAAAAAAC4EJq2AAAAAAAAAOBCaNoCAAAAAAAAgAuhaQsAAAAAAAAALoSmLQAAAAAAAAC4EJq2AAAAAAAAAOBCaNoCAAAAAAAAgAvxcHYBAAAAqU3gT/udXYLLCKta0tklAAAA4BGQaf/mipmWM20BAAAAAAAAwIXQtAUAAAAAAAAAF0LTFgAAAAAAAABcCE1bAAAAAAAAAHAhNG0BAAAAAAAAwIV4OLuAtCK4/3fOLsFlnPqorrNLAAAAAAAAAFwWTVsAcKAJb77q7BJcRu+l3zq7BACAA3ESwt84CQFPMvLs38izAJyJpi0AAAAAAABc3qYf8zu7BJdR7eU/nF0CkhlNW6Q+wzI5uwLXMeyGsysAkEoQcP9GwAUAAADg6liIDAAAAAAAAABcCE1bAAAAAAAAAHAhTI8AAAAAACmNKb/+xpRfAADEw5m2AAAAAAAAAOBCnN60nT59uoKDg+Xj46Ny5cpp586d/7r/5MmTVbhwYfn6+iooKEg9e/bUvXv3UqhaAAAAID4yLQAAABzJqU3bpUuXqlevXho6dKj27t2rEiVKqGbNmrp06VKC+3/55Zfq37+/hg4dqsOHD+vzzz/X0qVLNXDgwBSuHAAAALiPTAsAAABHc2rTduLEiWrfvr3atm2rkJAQzZo1S+nSpdPcuXMT3H/btm2qWLGi3nrrLQUHB6tGjRpq1qzZf57JAAAAACQXMi0AAAAczWlN26ioKO3Zs0fVq1f/uxg3N1WvXl3bt29P8DEVKlTQnj17bIH2zz//1Pfff686deo89HUiIyN18+ZNuxsAAADgCGRaAAAAJAcPZ73wlStXFBsbq4CAALvxgIAAHTlyJMHHvPXWW7py5YoqVaokY4xiYmL03nvv/eulZGPGjNHw4cMdWjsAAAAgkWkBAACQPJy+EFlSbN68WaNHj9aMGTO0d+9erVy5Ut99951GjBjx0McMGDBAN27csN3Onj2bghUDAAAA9si0AAAA+C9OO9M2e/bscnd3V3h4uN14eHi4AgMDE3zM4MGD1bJlS73zzjuSpGLFiikiIkLvvvuuPvjgA7m5xe9Be3t7y9vb2/FvAAAAAGkemRYAAADJwWln2np5eal06dLatGmTbcxqtWrTpk0qX758go+5c+dOvBDr7u4uSTLGJF+xAAAAQALItAAAAEgOTjvTVpJ69eql1q1bq0yZMipbtqwmT56siIgItW3bVpLUqlUr5cqVS2PGjJEk1atXTxMnTlSpUqVUrlw5nThxQoMHD1a9evVsQRcAAABISWRaAAAAOJpTm7ZvvvmmLl++rCFDhigsLEwlS5bUunXrbAs5nDlzxu4shEGDBslisWjQoEE6f/68cuTIoXr16mnUqFHOegsAAABI48i0AAAAcDSnNm0lqUuXLurSpUuC2zZv3mx338PDQ0OHDtXQoUNToDIAAAAgcci0AAAAcCSnzWkLAAAAAAAAAIiPpi0AAAAAAAAAuBCatgAAAAAAAADgQmjaAgAAAAAAAIALcfpCZAAAPMy5/j87uwSXkfujF51dAgAAAAAghXCmLQAAAAAAAAC4EJq2AAAAAAAAAOBCaNoCAAAAAAAAgAuhaQsAAAAAAAAALoSmLQAAAAAAAAC4EJq2AAAAAAAAAOBCaNoCAAAAAAAAgAuhaQsAAAAAAAAALoSmLQAAAAAAAAC4EJq2AAAAAAAAAOBCaNoCAAAAAAAAgAuhaQsAAAAAAAAALoSmLQAAAAAAAAC4EJq2AAAAAAAAAOBCaNoCAAAAAAAAgAuhaQsAAAAAAAAALoSmLQAAAAAAAAC4EJq2AAAAAAAAAOBCaNoCAAAAAAAAgAuhaQsAAAAAAAAALoSmLQAAAAAAAAC4EJq2AAAAAAAAAOBCaNoCAAAAAAAAgAuhaQsAAAAAAAAALsTD2QUAAAAAAAA8ic71/9nZJbiM3B+96OwSgFSFM20BAAAAAAAAwIXQtAUAAAAAAAAAF0LTFgAAAAAAAABcCHPaAgAAAABStcNFnnF2CS7jmSOHnV0CAMABONMWAAAAAAAAAFwITVsAAAAAAAAAcCE0bQEAAAAAAADAhdC0BQAAAAAAAAAXQtMWAAAAAAAAAFwITVsAAAAAAAAAcCE0bQEAAAAAAADAhdC0BQAAAAAAAAAX4uHsAgA41+Eizzi7BJfxzJHDzi4BAAAAAACAM20BAAAAAAAAwJXQtAUAAAAAAAAAF0LTFgAAAAAAAABcCE1bAAAAAAAAAHAhNG0BAAAAAAAAwIXQtAUAAAAAAAAAF0LTFgAAAAAAAABcCE1bAAAAAAAAAHAhNG0BAAAAAAAAwIXQtAUAAAAAAAAAF0LTFgAAAAAAAABcCE1bAAAAAAAAAHAhNG0BAAAAAAAAwIXQtAUAAAAAAAAAF+L0pu306dMVHBwsHx8flStXTjt37vzX/a9fv67OnTvrqaeekre3twoVKqTvv/8+haoFAAAA4iPTAgAAwJE8nPniS5cuVa9evTRr1iyVK1dOkydPVs2aNXX06FH5+/vH2z8qKkqvvPKK/P39tXz5cuXKlUunT59W5syZU754AAAAQGRaAAAAOJ5Tm7YTJ05U+/bt1bZtW0nSrFmz9N1332nu3Lnq379/vP3nzp2rq1evatu2bfL09JQkBQcHp2TJAAAAgB0yLQAAABzNadMjREVFac+ePapevfrfxbi5qXr16tq+fXuCj1m9erXKly+vzp07KyAgQEWLFtXo0aMVGxv70NeJjIzUzZs37W4AAACAI5BpAQAAkBweqWkbExOjjRs3avbs2bp165Yk6cKFC7p9+3ain+PKlSuKjY1VQECA3XhAQIDCwsISfMyff/6p5cuXKzY2Vt9//70GDx6sCRMmaOTIkQ99nTFjxihTpky2W1BQUKJrBAAAAP4NmRYAAADJIclN29OnT6tYsWJq0KCBOnfurMuXL0uSxo4dqz59+ji8wAdZrVb5+/trzpw5Kl26tN5880198MEHmjVr1kMfM2DAAN24ccN2O3v2bLLWCAAAAPwbMi0AAAD+S5LntO3evbvKlCmj0NBQZcuWzTbesGFDtW/fPtHPkz17drm7uys8PNxuPDw8XIGBgQk+5qmnnpKnp6fc3d1tY88884zCwsIUFRUlLy+veI/x9vaWt7d3ousCAAAAEotMCwAAgOSQ5DNtf/75Zw0aNChemAwODtb58+cT/TxeXl4qXbq0Nm3aZBuzWq3atGmTypcvn+BjKlasqBMnTshqtdrGjh07pqeeeirBcAsAAAAkJzItAAAAkkOSm7ZWqzXBRRLOnTunDBkyJOm5evXqpU8//VQLFizQ4cOH1bFjR0VERNhW3m3VqpUGDBhg279jx466evWqunfvrmPHjum7777T6NGj1blz56S+DQAAAMAhyLQAAABwtCRPj1CjRg1NnjxZc+bMkSRZLBbdvn1bQ4cOVZ06dZL0XG+++aYuX76sIUOGKCwsTCVLltS6detsCzmcOXNGbm5/95WDgoK0fv169ezZU8WLF1euXLnUvXt39evXL6lvAwAAAHAIMi0AAAAcLclN2/Hjx6tWrVoKCQnRvXv39NZbb+n48ePKnj27vvrqqyQX0KVLF3Xp0iXBbZs3b443Vr58ee3YsSPJrwMAAAAkFzItAAAAHCnJTdugoCCFhoZq6dKlCg0N1e3bt/X222+refPm8vX1TY4aAQAAAAAAACDNSFLTNjo6WkWKFNG3336r5s2bq3nz5slVFwAAAAAAAACkSUlaiMzT01P37t1LrloAAACAFEe+BQAAgKtJUtNWkjp37qyxY8cqJiYmOeoBAAAAkp3VatWIESOUK1cu+fn56c8//5QkDR48WJ9//rmTqwMAAEBal+Q5bXft2qVNmzbphx9+ULFixZQ+fXq77StXrnRYcQAAAEByGDlypBYsWKCPP/5Y7du3t40XLVpUkydP1ttvv+3E6gAAAJDWJblpmzlzZjVq1Cg5agEAAABSxMKFCzVnzhxVq1ZN7733nm28RIkSOnLkiBMrAwAAAB6haTtv3rzkqAMAAABIMefPn1eBAgXijVutVkVHRzuhIgAAAOBvSW7axrl8+bKOHj0qSSpcuLBy5MjhsKIAAACA5BQSEqKff/5ZefPmtRtfvny5SpUq5aSqAAAAgPuS3LSNiIhQ165dtXDhQlmtVkmSu7u7WrVqpU8++UTp0qVzeJEAAACAIw0ZMkStW7fW+fPnZbVatXLlSh09elQLFy7Ut99+6+zyAAAAkMa5JfUBvXr10pYtW7RmzRpdv35d169f1zfffKMtW7aod+/eyVEjAAAA4FANGjTQmjVrtHHjRqVPn15DhgzR4cOHtWbNGr3yyivOLg8AAABpXJLPtF2xYoWWL1+uKlWq2Mbq1KkjX19fNWnSRDNnznRkfQAAAIBDxcTEaPTo0WrXrp02bNjg7HIAAACAeJJ8pu2dO3cUEBAQb9zf31937txxSFEAAABAcvHw8NDHH3+smJgYZ5cCAAAAJCjJTdvy5ctr6NChunfvnm3s7t27Gj58uMqXL+/Q4gAAAIDkUK1aNW3ZssXZZQAAAAAJSvL0CFOmTFHNmjWVO3dulShRQpIUGhoqHx8frV+/3uEFAgAAAI5Wu3Zt9e/fX7/99ptKly6t9OnT222vX7++kyoDAAAAHqFpW7RoUR0/flyLFy/WkSNHJEnNmjVT8+bN5evr6/ACAQAAAEfr1KmTJGnixInxtlksFsXGxqZ0SQAAAIBNkpu2kpQuXTq1b9/e0bUAAAAAKcJqtTq7BAAAAOChkjyn7ZgxYzR37tx443PnztXYsWMdUhQAAAAAAAAApFVJbtrOnj1bRYoUiTf+7LPPatasWQ4pCgAAAEhuW7ZsUb169VSgQAEVKFBA9evX188//+zssgAAAICkN23DwsL01FNPxRvPkSOHLl686JCiAAAAgOT0xRdfqHr16kqXLp26deumbt26ydfXV9WqVdOXX37p7PIAAACQxiV5TtugoCD98ssvevrpp+3Gf/nlF+XMmdNhhQEAAADJZdSoUfr444/Vs2dP21i3bt00ceJEjRgxQm+99ZYTqwMAAEBal+Smbfv27dWjRw9FR0fr5ZdfliRt2rRJ77//vnr37u3wAgEAAABH+/PPP1WvXr144/Xr19fAgQOdUBEAAADwtyQ3bfv27au//vpLnTp1UlRUlCTJx8dH/fr104ABAxxeIAAAAOBoQUFB2rRpkwoUKGA3vnHjRgUFBTmpKgAAAOC+JDdtLRaLxo4dq8GDB+vw4cPy9fVVwYIF5e3tnRz1AQAAAA7Xu3dvdevWTfv371eFChUk3Z/ua/78+ZoyZYqTqwMAAEBal+SmbRw/Pz89//zzOn36tP744w8VKVJEbm5JXtcMAAAASHEdO3ZUYGCgJkyYoP/973+SpGeeeUZLly5VgwYNnFwdAAAA0rpEN23nzp2r69evq1evXraxd999V59//rkkqXDhwlq/fj2XkwEAACBVaNiwoRo2bOjsMgAAAIB4En1q7Jw5c5QlSxbb/XXr1mnevHlauHChdu3apcyZM2v48OHJUiQAAADgSLt27dKvv/4ab/zXX3/V7t27nVARAAAA8LdEN22PHz+uMmXK2O5/8803atCggZo3b67nnntOo0eP1qZNm5KlSAAAAMCROnfurLNnz8YbP3/+vDp37uyEigAAAIC/Jbppe/fuXWXMmNF2f9u2bXrppZds9/Ply6ewsDDHVgcAAAAkg0OHDum5556LN16qVCkdOnTICRUBAAAAf0t00zZv3rzas2ePJOnKlSv6/fffVbFiRdv2sLAwZcqUyfEVAgAAAA7m7e2t8PDweOMXL16Uh8cjr9ULAAAAOESiE2nr1q3VuXNn/f777/rxxx9VpEgRlS5d2rZ927ZtKlq0aLIUCQAAADhSjRo1NGDAAH3zzTe2Ew+uX7+ugQMH6pVXXnFydQAAAEjrEt20ff/993Xnzh2tXLlSgYGBWrZsmd32X375Rc2aNXN4gQAAAICjjR8/Xi+99JLy5s2rUqVKSZL279+vgIAALVq0yMnVAQAAIK1LdNPWzc1NH374oT788MMEt/+ziQsAAAC4qly5cunAgQNavHixQkND5evrq7Zt26pZs2by9PR0dnkAAABI45iwCwAAAGlS+vTp9e677zq7DAAAACCeRC9EBgAAAKR2x44d086dO+3GNm3apKpVq6ps2bIaPXq0kyoDAAAA/kbTFgAAAGlGv3799O2339runzx5UvXq1ZOXl5fKly+vMWPGaPLkyc4rEAAAABDTIwAAACAN2b17t95//33b/cWLF6tQoUJav369JKl48eL65JNP1KNHDydVCAAAAHCmLQAAANKQK1euKHfu3Lb7P/30k+rVq2e7X6VKFZ06dcoJlQEAAAB/S/KZtrGxsZo/f742bdqkS5cuyWq12m3/8ccfHVYcAAAA4EhZs2bVxYsXFRQUJKvVqt27d6tXr1627VFRUTLGOLFCAAAA4BGatt27d9f8+fNVt25dFS1aVBaLJTnqAgAAAByuSpUqGjFihGbMmKFly5bJarWqSpUqtu2HDh1ScHCw0+oDAAAApEdo2i5ZskT/+9//VKdOneSoBwAAAEg2o0aN0iuvvKK8efPK3d1dU6dOVfr06W3bFy1apJdfftmJFQIAAACP0LT18vJSgQIFkqMWAAAAIFkFBwfr8OHD+v3335UjRw7lzJnTbvvw4cPt5rwFAAAAnCHJC5H17t1bU6ZMYa4vAAAApEoeHh4qUaJEvIatJJUoUULZsmVzQlUAAADA35J8pu3WrVv1008/ae3atXr22Wfl6elpt33lypUOKw4AAAAAAAAA0pokN20zZ86shg0bJkctAAAAAAAAAJDmJblpO2/evOSoAwAAAAAAAACgR2jaxrl8+bKOHj0qSSpcuLBy5MjhsKIAAAAAAAAAIK1KctM2IiJCXbt21cKFC2W1WiVJ7u7uatWqlT755BOlS5fO4UUCAAAAj+vAgQOJ3rd48eLJWAkAAADw75LctO3Vq5e2bNmiNWvWqGLFipLuL07WrVs39e7dWzNnznR4kQAAAMDjKlmypCwWi4wxCW6P22axWBQbG5vC1QEAAAB/S3LTdsWKFVq+fLmqVKliG6tTp458fX3VpEkTmrYAAABwSSdPnnR2CQAAAECiJLlpe+fOHQUEBMQb9/f31507dxxSFAAAAOBoefPmdXYJAAAAQKIkuWlbvnx5DR06VAsXLpSPj48k6e7duxo+fLjKly/v8AIBAAAAR1i9enWi961fv34yVgIAAAD8uyQ3badMmaKaNWsqd+7cKlGihCQpNDRUPj4+Wr9+vcMLBAAAABzhtddeS9R+zGkLAAAAZ0ty07Zo0aI6fvy4Fi9erCNHjkiSmjVrpubNm8vX19fhBQIAAACOYLVanV0CAAAAkChJbtpKUrp06dS+fXtH1wIAAAAAAAAAaV6imrarV69W7dq15enp+Z9zgTH/FwAAAFKDiIgIbdmyRWfOnFFUVJTdtm7dujmpKgAAACCRTdvXXntNYWFh8vf3/9e5wJj/CwAAAKnBvn37VKdOHd25c0cRERHKmjWrrly5onTp0snf35+mLQAAAJzKLTE7Wa1W+fv72/77YTcatgAAAEgNevbsqXr16unatWvy9fXVjh07dPr0aZUuXVrjx493dnkAAABI4xLVtP0v169ff6zHT58+XcHBwfLx8VG5cuW0c+fORD1uyZIlslgsiV4JGAAAAJCk/fv3q3fv3nJzc5O7u7siIyMVFBSkjz/+WAMHDkzy85FnAQAA4EhJbtqOHTtWS5cutd1/4403lDVrVuXKlUuhoaFJLmDp0qXq1auXhg4dqr1796pEiRKqWbOmLl269K+PO3XqlPr06aMXX3wxya8JAACAtM3T01NubvejsL+/v86cOSNJypQpk86ePZuk5yLPAgAAwNGS3LSdNWuWgoKCJEkbNmzQxo0btW7dOtWuXVt9+/ZNcgETJ05U+/bt1bZtW4WEhGjWrFlKly6d5s6d+9DHxMbGqnnz5ho+fLjy5cuX5NcEAABA2laqVCnt2rVLklS5cmUNGTJEixcvVo8ePVS0aNEkPRd5FgAAAI6W5KZtWFiYrWn77bffqkmTJqpRo4bef/99W/BNrKioKO3Zs0fVq1f/uyA3N1WvXl3bt29/6OM+/PBD+fv76+233/7P14iMjNTNmzftbgAAAEjbRo8eraeeekqSNGrUKGXJkkUdO3bU5cuXNXv27EQ/T0rkWYlMCwAAkNZ4JPUBWbJk0dmzZxUUFKR169Zp5MiRkiRjTJIXIrty5YpiY2MVEBBgNx4QEKAjR44k+JitW7fq888/1/79+xP1GmPGjNHw4cOTVBcAAACebGXKlLH9t7+/v9atW/dIz5MSeVYi0wIAAKQ1ST7T9vXXX9dbb72lV155RX/99Zdq164tSdq3b58KFCjg8AIfdOvWLbVs2VKffvqpsmfPnqjHDBgwQDdu3LDdkjpHGQAAAJ48J0+e1PHjx+ONHz9+XKdOnUq2132UPCuRaQEAANKaJJ9pO2nSJAUHB+vs2bP6+OOP5efnJ0m6ePGiOnXqlKTnyp49u9zd3RUeHm43Hh4ersDAwHj7//HHHzp16pTq1atnG7NarfffiIeHjh49qvz589s9xtvbW97e3kmqCwAAAE+2Nm3aqF27dipYsKDd+K+//qrPPvtMmzdvTtTzpESelci0AAAAaU2Sm7aenp7q06dPvPGePXsm+cW9vLxUunRpbdq0Sa+99pqk+6F106ZN6tKlS7z9ixQpot9++81ubNCgQbp165amTJlim2sXAAAA+Df79u1TxYoV442/8MILCebQhyHPAgAAIDkkqmm7evVq1a5dW56enlq9evW/7lu/fv0kFdCrVy+1bt1aZcqUUdmyZTV58mRFRESobdu2kqRWrVopV65cGjNmjHx8fOKt5ps5c2ZJSvIqvwAAAEi7LBaLbt26FW/8xo0bSV6ngTwLAAAAR0tU0/a1115TWFiY/P39bWcQJMRisSQ55L755pu6fPmyhgwZorCwMJUsWVLr1q2zLeZw5swZubkleepdAAAA4KFeeukljRkzRl999ZXc3d0lSbGxsRozZowqVaqUpOcizwIAAMDREtW0jZtn65//7ShdunR56GVo/zWf2Pz58x1eDwAAAJ5sY8eO1UsvvaTChQvrxRdflCT9/PPPunnzpn788cckPx95FgAAAI7EV/4AAABIc0JCQnTgwAE1adJEly5d0q1bt9SqVSsdOXKEaQoAAADgdEleiKxbt24qUKCAunXrZjc+bdo0nThxQpMnT3ZUbQAAAECyyZkzp0aPHu3sMgAAAIB4knym7YoVKxJcabdChQpavny5Q4oCAAAAktvPP/+sFi1aqEKFCjp//rwkadGiRdq6dauTKwMAAEBal+Sm7V9//aVMmTLFG8+YMaOuXLnikKIAAACA5LRixQrVrFlTvr6+2rt3ryIjIyVJN27c4OxbAAAAOF2Sm7YFChTQunXr4o2vXbtW+fLlc0hRAAAAQHIaOXKkZs2apU8//VSenp628YoVK2rv3r1OrAwAAAB4hDlte/XqpS5duujy5ct6+eWXJUmbNm3ShAkTmM8WAAAAqcLRo0f10ksvxRvPlCmTrl+/nvIFAQAAAA9IctO2Xbt2ioyM1KhRozRixAhJUnBwsGbOnKlWrVo5vEAAAADA0QIDA3XixAkFBwfbjW/dupWrxwAAAOB0SW7aSlLHjh3VsWNHXb58Wb6+vvLz83N0XQAAAECyad++vbp37665c+fKYrHowoUL2r59u/r06aPBgwc7uzwAAACkcY/UtI2JidHmzZv1xx9/6K233pIkXbhwQRkzZqSBCwAAAJfXv39/Wa1WVatWTXfu3NFLL70kb29v9enTR127dnV2eQAAAEjjkty0PX36tGrVqqUzZ84oMjJSr7zyijJkyKCxY8cqMjJSs2bNSo46AQAAAIexWCz64IMP1LdvX504cUK3b99WSEiI/Pz8dPfuXfn6+jq7RAAAAKRhbkl9QPfu3VWmTBldu3bNLsw2bNhQmzZtcmhxAAAAQHLy8vJSSEiIypYtK09PT02cOFFPP/20s8sCAABAGpfkpu3PP/+sQYMGycvLy248ODhY58+fd1hhAAAAgKNFRkZqwIABKlOmjCpUqKCvv/5akjRv3jw9/fTTmjRpknr27OncIgEAAJDmJXl6BKvVqtjY2Hjj586dU4YMGRxSFAAAAJAchgwZotmzZ6t69eratm2b3njjDbVt21Y7duzQxIkT9cYbb8jd3d3ZZQIAACCNS/KZtjVq1NDkyZNt9y0Wi27fvq2hQ4eqTp06jqwNAAAAcKhly5Zp4cKFWr58uX744QfFxsYqJiZGoaGhatq0KQ1bAAAAuIQkn2k7fvx41apVSyEhIbp3757eeustHT9+XNmzZ9dXX32VHDUCAAAADnHu3DmVLl1aklS0aFF5e3urZ8+eslgsTq4MAAAA+FuSm7ZBQUEKDQ3V0qVLFRoaqtu3b+vtt99W8+bNWWUXAAAALi02NtZubQYPDw/5+fk5sSIAAAAgviQ1baOjo1WkSBF9++23at68uZo3b55cdQEAAAAOZ4xRmzZt5O3tLUm6d++e3nvvPaVPn95uv5UrVzqjPAAAAEBSEpu2np6eunfvXnLVAgAAACSr1q1b291v0aKFkyoBAAAAHi7J0yN07txZY8eO1WeffSYPjyQ/HAAAAHCaefPmObsEAAAA4D8lueu6a9cubdq0ST/88IOKFSvGpWQAAAAAAAAA4EBJbtpmzpxZjRo1So5aAAAAAAAAACDNS3LTlkvKAAAAAAAAACD5uCV2R6vVqrFjx6pixYp6/vnn1b9/f929ezc5awMAAAAAAACANCfRTdtRo0Zp4MCB8vPzU65cuTRlyhR17tw5OWsDAAAAAAAAgDQn0U3bhQsXasaMGVq/fr2+/vprrVmzRosXL5bVak3O+gAAAAAAAAAgTUl00/bMmTOqU6eO7X716tVlsVh04cKFZCkMAAAAAAAAANKiRDdtY2Ji5OPjYzfm6emp6OhohxcFAAAAAAAAAGmVR2J3NMaoTZs28vb2to3du3dP7733ntKnT28bW7lypWMrBAAAAAAAAIA0JNFN29atW8cba9GihUOLAQAAAAAAAIC0LtFN23nz5iVnHQAAAAAAAAAAJWFOWwAAAAAAAABA8qNpCwAAAAAAAAAuhKYtAAAAAAAAALgQmrYAAAAAAAAA4EJo2gIAAAAAAACAC6FpCwAAAAAAAAAuhKYtAAAAAAAAALgQmrYAAAAAAAAA4EJo2gIAAAAAAACAC6FpCwAAAAAAAAAuhKYtAAAAAAAAALgQmrYAAAAAAAAA4EJo2gIAAAAAAACAC6FpCwAAAAAAAAAuhKYtAAAAAAAAALgQmrYAAAAAAAAA4EJo2gIAAAAAAACAC6FpCwAAAAAAAAAuhKYtAAAAAAAAALgQmrYAAAAAAAAA4EJo2gIAAAAAAACAC6FpCwAAAAAAAAAuhKYtAAAAAAAAALgQmrYAAAAAAAAA4EJo2gIAAAAAAACAC6FpCwAAAAAAAAAuhKYtAAAAAAAAALgQl2jaTp8+XcHBwfLx8VG5cuW0c+fOh+776aef6sUXX1SWLFmUJUsWVa9e/V/3BwAAAJIbeRYAAACO5PSm7dKlS9WrVy8NHTpUe/fuVYkSJVSzZk1dunQpwf03b96sZs2a6aefftL27dsVFBSkGjVq6Pz58ylcOQAAAECeBQAAgOM5vWk7ceJEtW/fXm3btlVISIhmzZqldOnSae7cuQnuv3jxYnXq1EklS5ZUkSJF9Nlnn8lqtWrTpk0pXDkAAABAngUAAIDjObVpGxUVpT179qh69eq2MTc3N1WvXl3bt29P1HPcuXNH0dHRypo1a4LbIyMjdfPmTbsbAAAA4AgpkWclMi0AAEBa49Sm7ZUrVxQbG6uAgAC78YCAAIWFhSXqOfr166ecOXPaBeUHjRkzRpkyZbLdgoKCHrtuAAAAQEqZPCuRaQEAANIap0+P8Dg++ugjLVmyRKtWrZKPj0+C+wwYMEA3btyw3c6ePZvCVQIAAAAJS0yelci0AAAAaY2HM188e/bscnd3V3h4uN14eHi4AgMD//Wx48eP10cffaSNGzeqePHiD93P29tb3t7eDqkXAAAAeFBK5FmJTAsAAJDWOPVMWy8vL5UuXdpu0YW4RRjKly//0Md9/PHHGjFihNatW6cyZcqkRKkAAABAPORZAAAAJAennmkrSb169VLr1q1VpkwZlS1bVpMnT1ZERITatm0rSWrVqpVy5cqlMWPGSJLGjh2rIUOG6Msvv1RwcLBtrjA/Pz/5+fk57X0AAAAgbSLPAgAAwNGc3rR98803dfnyZQ0ZMkRhYWEqWbKk1q1bZ1vM4cyZM3Jz+/uE4JkzZyoqKkqNGze2e56hQ4dq2LBhKVk6AAAAQJ4FAACAwzm9aStJXbp0UZcuXRLctnnzZrv7p06dSv6CAAAAgCQgzwIAAMCRnDqnLQAAAAAAAADAHk1bAAAAAAAAAHAhNG0BAAAAAAAAwIXQtAUAAAAAAAAAF0LTFgAAAAAAAABcCE1bAAAAAAAAAHAhNG0BAAAAAAAAwIXQtAUAAAAAAAAAF0LTFgAAAAAAAABcCE1bAAAAAAAAAHAhNG0BAAAAAAAAwIXQtAUAAAAAAAAAF0LTFgAAAAAAAABcCE1bAAAAAAAAAHAhNG0BAAAAAAAAwIXQtAUAAAAAAAAAF0LTFgAAAAAAAABcCE1bAAAAAAAAAHAhNG0BAAAAAAAAwIXQtAUAAAAAAAAAF0LTFgAAAAAAAABcCE1bAAAAAAAAAHAhNG0BAAAAAAAAwIXQtAUAAAAAAAAAF0LTFgAAAAAAAABcCE1bAAAAAAAAAHAhNG0BAAAAAAAAwIXQtAUAAAAAAAAAF0LTFgAAAAAAAABcCE1bAAAAAAAAAHAhNG0BAAAAAAAAwIXQtAUAAAAAAAAAF0LTFgAAAAAAAABcCE1bAAAAAAAAAHAhNG0BAAAAAAAAwIXQtAUAAAAAAAAAF0LTFgAAAAAAAABcCE1bAAAAAAAAAHAhNG0BAAAAAAAAwIXQtAUAAAAAAAAAF0LTFgAAAAAAAABcCE1bAAAAAAAAAHAhNG0BAAAAAAAAwIXQtAUAAAAAAAAAF0LTFgAAAAAAAABcCE1bAAAAAAAAAHAhNG0BAAAAAAAAwIXQtAUAAAAAAAAAF0LTFgAAAAAAAABcCE1bAAAAAAAAAHAhNG0BAAAAAAAAwIXQtAUAAAAAAAAAF0LTFgAAAAAAAABcCE1bAAAAAAAAAHAhNG0BAAAAAAAAwIXQtAUAAAAAAAAAF0LTFgAAAAAAAABciEs0badPn67g4GD5+PioXLly2rlz57/uv2zZMhUpUkQ+Pj4qVqyYvv/++xSqFAAAAIiPPAsAAABHcnrTdunSperVq5eGDh2qvXv3qkSJEqpZs6YuXbqU4P7btm1Ts2bN9Pbbb2vfvn167bXX9Nprr+ngwYMpXDkAAABAngUAAIDjeTi7gIkTJ6p9+/Zq27atJGnWrFn67rvvNHfuXPXv3z/e/lOmTFGtWrXUt29fSdKIESO0YcMGTZs2TbNmzYq3f2RkpCIjI233b9y4IUm6efNmcrydh7JG3knR13Nlj33sI41jCnkSOOBzfDs21gGFPBkc8XvhXnS0Ayp5MjjieN6KjHBAJU+Gxz2eERFWB1WS+jnis2mNuO2ASp4MKZ2p4l7PGNfJA8mdZyXXyLTk2b855LiTaf9GpnWox/18kmf/Rp51LEccTzLt38i0jpWSmSrRedY4UWRkpHF3dzerVq2yG2/VqpWpX79+go8JCgoykyZNshsbMmSIKV68eIL7Dx061Ejixo0bN27cuHHj9gTdzp4964g4+thSIs8aQ6blxo0bN27cuHF70m7/lWedeqbtlStXFBsbq4CAALvxgIAAHTlyJMHHhIWFJbh/WFhYgvsPGDBAvXr1st23Wq26evWqsmXLJovF8pjvIPW4efOmgoKCdPbsWWXMmNHZ5aR6HE/H4ng6DsfSsTiejsXxdKy0ejyNMbp165Zy5szp7FIkpUyelci0cdLq5z45cCwdi+PpWBxPx+J4Og7H0rHS6vFMbJ51+vQIyc3b21ve3t52Y5kzZ3ZOMS4gY8aMaeoHIblxPB2L4+k4HEvH4ng6FsfTsdLi8cyUKZOzS0hxZFp7afFzn1w4lo7F8XQsjqdjcTwdh2PpWGnxeCYmzzp1IbLs2bPL3d1d4eHhduPh4eEKDAxM8DGBgYFJ2h8AAABILuRZAAAAJAenNm29vLxUunRpbdq0yTZmtVq1adMmlS9fPsHHlC9f3m5/SdqwYcND9wcAAACSC3kWAAAAycHp0yP06tVLrVu3VpkyZVS2bFlNnjxZERERttV3W7VqpVy5cmnMmDGSpO7du6ty5cqaMGGC6tatqyVLlmj37t2aM2eOM9+Gy/P29tbQoUPjXVaHR8PxdCyOp+NwLB2L4+lYHE/H4ni6DvJsyuFz7zgcS8fieDoWx9OxOJ6Ow7F0LI7nv7MYY4yzi5g2bZrGjRunsLAwlSxZUlOnTlW5cuUkSVWqVFFwcLDmz59v23/ZsmUaNGiQTp06pYIFC+rjjz9WnTp1nFQ9AAAA0jryLAAAABzJJZq2AAAAAAAAAID7nDqnLQAAAAAAAADAHk1bAAAAAAAAAHAhNG0BAAAAAAAAwIXQtAUAAAAAAAAAF0LTNpV7cB051pSDqzl9+rR27tzp7DKABFmtVmeX8EThbxCAR0WehSsjz8KVkWcdi79BcDU0bVMxq9Uqi8WiK1eu6ObNm7JYLM4u6YnAL2rH2Ldvn5599lmdPHnS2aUAdg4dOqTTp0/LzY0/gY5w584dSZLFYuH352P65/HjeCItIM8mD35/OAZ5Fq6KPOtY5FnHItM6Dj/hqZTVapWbm5v27dunqlWr6uDBg84uKdV72C8Svr1MutDQUFWqVEnvvfee3nzzTWeX88Tgj93jO3DggIoWLaqlS5c6u5QnwpEjR9SoUSMtW7ZMEkH3ccQ1riTp7Nmzun37NscSTzzyrOORZx2HPJt8+Pv2eMizjkWedSwyrWN5OLsAJF1cwN2/f78qVqyoTp06qUKFCs4uK1UzxshisWjLli369ttvFRERobx586pfv35yc3Ozbcd/O3LkiF5++WV16NBB48ePV0xMjDw8+FXzKOJ+1u/duycfHx9ZLBadOnVKwcHBzi4tVdq/f78qVKigvn376v3333d2OalebGyspk6dqh9//FGZMmWSh4eHGjZsKIvFYvvsIvHijtfgwYP17bff6tq1a2rfvr0aNWqkIkWKOLk6wPHIs45HnnUc8qxjkWkdhzzrWORZxyPTOhafwFQm7hfH0aNHVblyZQ0bNkzjx4/n2/PHZLFYtHLlStWrV083btyQp6enZsyYoapVq9p9U4R/Fxoaqueff1737t3Ttm3bdPPmTXl4eCgmJsbZpaVKbm5uOn36tHr16qWzZ89q5cqVypcvn06cOOHs0lKd48ePq3Tp0ho8eLDGjh2rmJgYffPNN5o4caLWrl2r48ePO7vEVMfd3V158uRR6dKldeXKFc2aNUsrVqyQ9HdY42/Tf3vwGC1evFiffvqp3n//fdWvX19ff/21Ro4cqQMHDjixQsDxyLPJgzzrGORZxyPTOgZ51vHIs45Dpk0eNG1TkbiAGxoaqnLlyunWrVvKmDGjpPu/UPhl8ujOnTunQYMGafTo0ZozZ4569Oihe/fuqWDBgnbfrnFa/8Pt2bNHL730krp06aItW7bIGKPKlSsTdB/T3r17tWXLFrVu3VrNmzfXwoULVaBAAT6LSRAbG6s1a9bIGKOCBQtKkmrXrq1BgwZp6tSpatWqlbp3765169Y5udLUI+7zlzdvXlWtWlWfffaZoqOj9fnnn2vLli3q2rWrjh8/ztkJiRB3jH755Rft3LlTEyZMULNmzTR16lR1795dp0+f1kcffUTIxRODPJt8yLOPjzybfMi0j4c863jkWcci0yYTg1TBarUaY4zZv3+/SZ8+venatasZN26cyZgxo5kwYYJtv9jYWGeVmKodOHDAFClSxBhjzNmzZ03u3LlNhw4dbNs3bNjgrNJcntVqNRERESZDhgyma9euxpj7n8PNmzebsmXLmlKlSpkbN24YY4yJjo52ZqmpStzPvDHGjBkzxlgsFlOhQgVz7NixBPfBvzt79qwZNmyYyZAhg8mVK5d5/fXXzaFDh4wxxmzevNm88sorpnHjxubWrVtOrjR1OXjwoKlcubIxxpjffvvN1KpVy+TJk8dYLBZz+PBhYwx/lxJj27ZtJl++fCZr1qxm3rx5dtsWLVpkKlWqZFq0aGF2797tnAIBByHPJi/y7KMjzyYfMq3jkGeTB3nWcci0jsdXBqmExWLRmTNnVKpUKXXv3t32bVqfPn00fPhwTZo0SRJnKDyqzJkzK0eOHFqzZo0qVqyounXratq0aZLuz2m1YMEC7d6928lVuiZjjNKlS6ezZ89q6tSpku5/Dl988UWNGzdOnp6eqlKliu0MhdjYWCdXnDrEXcL4v//9T3v37tWHH36o2NhYjRgxQnv37rXtYzg7IVFy586tDh06qEePHnrmmWc0ZMgQPfPMM5KkypUr6+2339aqVat04cIFJ1eaehhj5OXlpfDwcN24cUNFixaVp6enwsPDVaFCBf3555+SxNkJiVC+fHl169ZNfn5++uabb+xWKW/RooU6duyoXbt2ac2aNU6sEnh85NnkRZ59dOTZ5EOmdRzyrOORZx2LTJsMnNkxxn/75zc669ats7sfFhZmRowYYTJmzGgmTpz40Mfhb3Hf5O7cudPs2bPHREdHm7/++stUrFjReHh4mJYtW9rt36dPH1OxYkUTHh7ujHJd2rFjx0ynTp3Mq6++aoYNG2YiIiKMMX9//mJjY82WLVtsZyjcvHnTGGNMTEyM02pOTfbt22csFouZPHmyMcaYJUuWmDJlypiWLVuavXv32vbbv3+/s0pMdc6dO2d27NhhoqKijDF/f1Y3bNhgnnnmGXPx4kVnlufSHnYWzBtvvGEuXLhgWrdubXLlymWWLFliatWqZV544QXz3XffpXCVru/f/j5PmDDBlChRwvTs2dOcOnXKbtv69ev53YlUizzreORZxyHPJj8yrWORZx8dedZxyLQpgyUwXVjcnF+nT5/W+vXrdfXqVTVu3FjS36vDBgQE6N1335UkDRs2TJLUs2dP2xkKfCNkL+64rVq1Sh06dFCHDh2UK1cuBQQEaPLkyapWrZru3LmjZcuWyd/fXytXrtSCBQv0f//3f/L393d2+S4lNDRUNWrU0AsvvCAPDw+NHj1aFy9e1KxZs2wrFLu5ualSpUoaN26cBgwYoOLFi+vAgQPKkCGDs8t3efv379evv/6q4cOHq3v37pKkN998U5I0YcIETZo0SS1bttSOHTs0cuRIXbx4UVmzZnVmyalCrly5lDNnTttZH3G/I9evX68cOXLI19fXmeW5pPPnz8vT0zPB34HGGN28eVPBwcHKnj27Vq9erdKlS6tQoUIaPny4ihYt6oSKXdeDf5dnz56t7du3y9PTU4ULF1afPn3Uq1cvWa1WLV68WJLUvXt35c2bV5JUo0YNSffntHN3d3fOGwAeAXnW8cizjkOeTX5kWscjzyYdedaxyLQpyHn9YvybuG8tQkNDTXBwsClTpozx9/c32bJlM5s2bTLG2H+7Gx4ebkaMGGGyZctmRo4c6ZSaU4t169aZ9OnTm88//9xcu3bNbtv27dtNpUqVzFNPPWVCQkLMiy++yDe+CQgNDTXp06c3AwcONMYYc/v2bdOuXTvj4eFhdu3aZdsv7jNqtVrNhg0bTLVq1cyff/7plJpTk/Pnz5tKlSqZ9OnTm/79+xtjjImMjLRtX758uXnppZdMgQIFTN68ec3OnTudVWqqd/z4cdO3b1+TOXNmc+DAAWeX43L27t1rgoKCzJo1a+JtiztTYe3ataZ+/fq2uanixu/du5dyhaYy77//vsmRI4d55513TKNGjYyfn5+pV6+e7diNHTvWlClTxrRt25azZZCqkWeTD3n28ZFnkx+ZNmWQZ/8deTb5kGmTH01bFxQXcPfv32/SpUtnPvjgA/PXX3+ZQ4cOmeDgYFO6dGnbH7sHg+6lS5fMwIEDTZ48ecxff/3FhO4JiI2NNe+++67p1KmTMcaYiIgIExoaanr37m0mTpxoTp06ZaKjo83Zs2fN+fPnbZc/4W83btwwwcHBpkSJEnbjrVq1Ml5eXmb79u3m9OnT8R4XGxtr7ty5k0JVpm6RkZFm1qxZplixYqZo0aK24/ZgyD127JjZs2ePOXfunLPKdDknT5408+bNM8OHDzf79u37z5B18OBB8+abb5rixYubffv2pUyRqci+ffuMr6+v6du377/uFxERYVuc5UH8DUrYzp07Ta5cucyPP/5ojLl/nHbs2GFy5sxpGjdubNtv6NChpk2bNlwejlSLPJt8yLOPjzybMsi0SUeedSzybPIh06YMmrYu6sKFC8bd3d107tzZbjzum8i4+Wv+KTw83Fy+fDklSkyVoqOjTa1atUy9evXMwYMHTbt27Uy1atVMkSJFTNGiRU3r1q1t81ghYVFRUWbixInG29vbfPTRR8aY+yvBenl5mZdeesm88cYbJnfu3KZhw4ZmzJgx5uDBg6xg+h8eDANxwSw6Otp89dVXJiQkxDRo0MDcvn3bGGMe+rOf1h04cMDkzp3bVKtWzQQEBJiCBQua3377zW6fhILCjh07+EdCAo4cOWIyZcpkRowYYYwhsD6q+vXrm99//91ubN26dSZXrlzm6tWrxpi/j+2GDRtMtmzZzNq1a237xm0j5CK1Is8mD/Ls4yPPJg8y7eMhzzoWedZxyLTOwwRRLsQ8sGLm3bt3Vbp0aW3atElhYWGSpLFjx+rnn3/WnTt31KFDBz3//POaP3++9uzZY1th19/fX9mzZ3dK/amBh4eHBgwYoK1bt6py5cq6efOmOnTooMOHD6tdu3Y6cuSIPDyY6jkhx44d09q1a+Xp6anOnTtr/PjxGjBggF5++WVNmTJFX3/9tTZv3qzPPvtMP/zwg7Jnz65Fixapbt26io6Odnb5Lsv8/3npfvjhB7Vv314vv/yyRo4cqUOHDqlp06YaMGCAwsLC1LJlS0VERMjT05MVi//h2LFjqlGjhtq2bas1a9YoLCxMUVFR2rp1q91+cfMuTZkyxbYydLly5ZQrV64Ur9mVhYaG6vnnn9fNmzcVFRUliVWdH0VUVJRy586tAgUK2I3nz59ft2/f1saNGyX9vap2oUKF5OPjo1u3btn2jTvuzOeJ1IQ8m/zIs4+OPJt8yLSPhzzrWORZxyHTOpnz+sV4UNw3DufPn7etrvfHH3+YihUrmsKFC5sBAwaYgIAAs3z5cnP69Gmzd+9e069fP1OhQgVjsVhMs2bNzN27d535FlxO3Lc5x48fNz/99JMJDQ01ly5dMsYYc/r0aducSXH79erVy7z66qu2b3/xt/379xuLxWKmTZtmG4uMjDQzZ840GTJkMK1atbKNx13iGB0dbWJjY8358+dTvN7U5uuvvzZ+fn6me/fu5pNPPjFPP/20qVChgjl16pSJiooy8+fPNxUqVDDVqlXjzJl/iIiIMJ07dzadOnUykZGRts9fkyZNzMCBA02nTp3Ml19+acLCwowxxly+fNm8+OKLplq1avHmAMT9n3VfX1/Tr18/s3z5cuPl5WV69+5t284ZCo9m0qRJZvv27cYYY65du2befPNNU7duXfPDDz/Y9rl+/bopXry4Wbp0qbPKBB4bedbxyLOOQ55NfmTaR0OedSzybPIh06Y8mrYuIC7g7t271/j6+prvvvvOtu3EiROmRo0axmKxmK+++ireYy9dumS2bNlijhw5kmL1pgZxv4hXrFhh8ufPb4KDg03JkiXNG2+8YY4dO2a37+7du82AAQNMxowZTWhoqDPKdWlxc9HFLdLwoFu3bpkZM2YYNzc3M3r0aNt4bGwsfwwT6eLFi6ZMmTLmk08+Mcbc/0dC1qxZTe/evW3HMDo62syePdtUq1bNnD171pnluqTvvvvO7Nmzx3Z/+PDhxsPDw7Rt29a8/PLLplSpUqZbt262edROnjxpzpw546xyXVZYWJjx9va2/axHR0ebhQsXGi8vL9OnTx/bfvxsJ010dLSpVKmSyZEjh21xi//7v/8zr7zyiilfvrwZNmyYWbJkialevbopWbKk3dyeQGpCnnU88qzjkGeTH5n28ZBnHYM8m3zItM5B09bJHlykwc/PL8EJso8cOWKqVq1q8ufPb/uW98HJ25GwH374wWTOnNkWHGbMmGH8/PxMpUqVbP8oOHTokGnSpIkpUaIEq+om4MCBAyZ9+vRm0KBBduNLly41f/31lzHm/mdx2rRpxs3NzTYnGBLvypUrpnTp0ubKlSvmxIkTJmfOnKZ9+/a27Vu2bDF37941UVFR5vr1606s1PUkFLaOHz9uChUqZFavXm0bGzRokClQoIAJDw9PyfJSpbjV3ONER0ebRYsWEXST4MH5vmbPnm1OnDhh7ty5Y1599VXz1FNP2VYk37Fjh+nXr58JDAw05cuXN/Xq1bPN70fIRWpDnk0+5NnHR55NGWTaR0OedTzyrGOQaV0DTVsnigu4oaGhxtfXN943vw9OOn7ixAlTsWJFky9fPnPhwgW7x8Oe1Wo1N27cMI0aNTLDhg0zxtz/xi1PnjymVq1apkKFCqZixYrmzz//NMbcP85c8hTfuXPnjMViMc2bN7cb/+ijj4zFYrH7JjgyMtLMmDHDWCwWM3HixJQu1eXF/axGRkbGu1zx9OnTJk+ePGbp0qWmQIECpn379rY/bkeOHDGNGjUyW7ZsSfGaXd2/hawrV64YY+4HNGOMWb58uQkJCWFRm4c4fvy46d27t2natKmZNm2aOXr0qN326Oho88UXXxhvb28uLfsPe/bsMSVLljQTJkwwPXv2NBaLxRw/ftwYY8ydO3dM7dq1TWBgoC3kGmPM7du3zY0bN+zOQgJSE/Js8iDPOgZ51rHItI5FnnUc8qxjkWldB01bJzt8+LBxc3MzvXr1shsfPny4yZo1qy3QGnM/6FauXNlkzpzZNp8NHm79+vVm27Zt5q+//jLFihUzHTp0MMYY8/HHHxuLxWKeffZZLsP7D0WLFjVFixY127ZtM8YYM3bsWJM9e3bbnDUP/pGLjY01s2fPNocOHXJKra4qLtweOnTING7c2JQrV840b97c7lvy3r17G4vFYurVq2f32IEDB5pSpUqxGuwDzp07959nGPwzfHXr1s3Ur1+fudMSsH//fpMjRw5TtWpVU7p0aePh4WHefPNNc/r0abv94oKun5+f7Xcp4rt06ZLp3bu3CQwMNBkzZrQ1q+LONrh7966pU6eOyZkzp+2ysgfxDwekVuTZ5EOefXzkWccg0zoOedaxyLOOR6Z1HTRtnez77783FovFDB061HZ5zkcffWT8/f3N999/b4yx/8AfP37c1KhRw/YtB+6H/0GDBplu3bqZRYsWxdu+aNEiU7VqVds/DL7++mtToUIF06ZNG3Py5MkUrjZ1ePAyhjJlypiiRYuaTp06mWzZssW73MQYY3799Vdz69atlCwxVXjwctHMmTObVq1amdGjR5unnnrKNGvWzLbfgQMHTKNGjUzOnDnNokWLzLx580y3bt1MhgwZuMzxAXv37jVBQUFmzZo1idr/1q1bZuDAgSZbtmzm4MGDyVxd6nPw4EGTPn16M2LECNvP/KxZs4zFYjErV640xtj//YmOjjafffaZCQgI4NK8BMT9vH/++ecmY8aMpmjRomb8+PG27XFnG9y9e9fUq1fPWCwWc/jwYafUCjgaefbxkWcdjzzrOGRaxyHPOhZ51vHItK6Fpq0LWLx4sbFYLGbUqFFm6NChJmvWrHar78WJu+SJ08z/tn//fhMYGGhq1Khhqlatanx8fOIF3QkTJpiAgADb8evXr5/p2bOnuXHjhjNKdmm3bt0yf/31l22C+ziVKlUyFovFTJkyJd5j+vfvb0JCQmwrGeO+uHAQGhpq0qVLZz744APbtvnz55uGDRuac+fO2f5xcPz4cdO1a1fj7+9vSpUqZV599VVz4MABp9Tuivbt22d8fX0TnCcxId99951p0KCByZcvn9m7d28yV5f6XLt2zQQGBprnn3/e3Lx50zYeHR1tChQoYBfMHhQTE8Pvzn+I+1l/8Gd+7969pk+fPqZs2bJm1KhR8R5z+/Zt8/777zPPF54o5NlHR551LPKsY5FpHYc861jkWcci07ommrYpKO4bi5iYmHgf6oULFxqLxWIsFotZsWJFvMcOGTLEtGjRgsshHhA3d9qAAQOM1Wo1ly5dMq+99poZN26c3X6//PKLqVixoilevLipX7++SZcund2k2rjv999/N1WqVDElS5Y0efPmjfdt+AsvvGCKFClitm7davssDx482Pj4+JidO3c6o2SXFx4eboKDg82LL75oN96hQwcTGBhogoKCTOHChU3v3r3N3bt3jTH356uLjo7mZ/0BR44cMZkyZTIjRowwxiTucpvY2FgzY8YM88cffyR3eanWoEGDTL58+cyoUaNsqw///vvvxsPDw3zzzTdOri51eHAuzuvXr5vY2FhbI+r8+fOmW7dupmzZsnaL2gwdOtQ2B6UxLNCA1Ic861jkWccizyYPMu3jI88mD/KsY5BpXRdN2xQS90Nw9OhR884775g6derEW6hh1apVxmKxmEGDBtlNMD5kyBBjsVgSnCskrfrjjz9MlixZTNu2be3G69evbypXrmzKli1r2rZta3755RdjzP2J27t162batGlDwE3Avn37TIYMGUy3bt3M/PnzTYMGDczTTz9tIiMj7X6BP/fcc6ZgwYJm//79ZvDgwcbb25vP5b84fvy4adu2rSlWrJj57LPPjDH3Lxf18/Mzs2bNMlu2bDGtWrUyAQEBZtGiRcZqtdr+2DEP0H379+83GTJkMBaLxQwePNg2/m/Hh0VtEm/48OEmd+7cZurUqebXX381uXPnNl27dnV2WanCg5+zcePGmbp165oyZcqYDz74wHbJ9/nz50337t1NmTJlTNOmTU2dOnWMv78/oRapFnnWscizjkWeTT5k2sdDnk1e5NnHQ6Z1bTRtU8CDcwBly5bNNG7c2Lzzzjsmffr08YJu3BkK/fr1M/fu3TPDhg0z3t7ediubwphly5aZp556ynTt2tU2f8ro0aONj4+P6dOnjxk+fLjJli2bKVu2rN2lD1yKF9/BgweNr6+v+fDDD21jGzZsMDVr1jTHjx83x44ds7tUrGzZssZisZgMGTLwuUyEo0ePmq5du5qQkBBTv3594+/vbzZs2GDbHhkZaXLkyGG3iinu279/v/H19TX9+vUzy5cvN15eXqz2+hjOnj1rvvjiCzNnzhy7+Q+HDh1qcubMaTJmzGhat25tGyeEPdyDn70BAwaY7Nmzm5kzZ5qRI0eacuXKmWrVqtn+Nl28eNGMGzfOvPbaa6Zp06a2BRz4xxhSG/Ks45FnHYc8m/zItI+GPOtY5FnHItO6Ppq2ySzuAxx36dODoXbAgAGmY8eO5vbt23b7LliwwHh6epqQkBCTIUMGvvl9iM8//9w899xzpmfPnqZHjx4mR44cZv369bbtv/76q7FYLGb58uW2Mf4o2vvrr79MyZIlzTPPPGM33q9fP+Pl5WUKFy5sPDw8TJMmTcy+ffts2xs2bGh3H/E9+Mfr999/N127djWZM2c23bp1s41HRkaaiIgI8/LLL9vmXOIzel9YWJjx9va2/c6Mjo42CxcuNF5eXqZPnz62/TheiXPw4EFTokQJ06JFC/P+++/H2z527FiTKVMmM3LkSFZz/xdx4TTO8uXLTZEiRcyuXbuMMcasXbvWeHt7m5CQEFOhQgVz9OhRY8z9n/UH0XBBakOeTT7k2cdHnk1eZNpHR551LPKs45BpUw+ating3LlzJiAgwDRo0MBuvEWLFqZw4cKmYMGCpmLFimbatGm2H4KFCxea9OnTEyQS8GBwmDNnjnn22WeNr6+vmTNnjjHG2C7HOXDggCn0/9q787Cqqr0P4N/NPGRiToiiISKmb44JRmlaBM7dvKndHDJvppiWZYiz5YTDa6ZmOFzNAk2uYqbmPJU4ZZZD13lIMecJJ0TgfN8/eNmXI1amBw7D9/M8PU+svTn+OM8++3z32nutVbUqN2zYYKdK87+UlBRGRkby2WefNe/4Tpw4kcWLF+fcuXN54sQJTp8+nc7Ozhw/frzuVN6HrNCVnJxs9WW4d+9e9u7dm9WqVePMmTPN9iFDhtDHx4dHjhzJ81rzu7tXdk5LS2NsbKyC7l/0yy+/sESJEhw8eLDVk1pLliwxV9UlM59Q8PX1ZXR0NE+dOmWPUvO19u3bs3379uZcfWTmU1x9+vQhmfl+lixZkjExMVywYAFLlizJJk2a5FjpWcerFFTKs7alPGs7yrO5Q5nWNpRnbUN51naUaQsWddrmgc2bN7Nhw4Zs2rQpV65cSZKMjo6mp6cnx44dy/j4eAYFBdHX15dbtmwxfy9rBU4hb9++bfVz9qAbGxvLmjVrMiIiwmp+r8GDB7NatWo8ffp0ntVZkGS9h7du3eLQoUMZEhLCkJAQenl5MTEx0WrfkJCQHBdp8vuWLFliDifp3r272Z4VcgMDAzlv3jyOHz+ebm5uGpaXzeHDh9m3b1+++uqr/PTTT827ulnS0tIYFxdHV1dXDS27D5cuXWKjRo3Yq1cvq/YxY8bQMAw+//zzVkH3o48+ooeHBydMmKCL2rssWrSIHh4ejIiIsFqR/Pz587x+/TobNmxorqp7+/Zt1q5dmz4+PnzrrbfsVbKITSnPPjzlWdtTns1dyrQPRnnWtpRnbUuZtmBRp20u+fzzzzl48GDz53Xr1rF169Zs2rQpO3fuzDJlynD16tXm9suXL9MwDE6YMMFs00k70549e/jOO+9YzUNFWgfdmTNnsk6dOnzrrbd44sQJcz4wPdnxx7Lew5s3b/LDDz+kn58f27RpY25PTU1lWloamzZtyqioKM1X8weyPq87duygq6srBwwYwJ49e7JGjRqsX7++ud/evXvZp08furu709HRUcNFs9m1axdLly7NJk2asF69enRycmL79u154sQJq/2ygu4jjzxidQEhOe3bt4/+/v5cv369+fmNiYmhs7Mzp06dyhdffJHNmze3Crpjx47loUOH7FVyvrN7927zCaMVK1bQ3d2d3bt3t1oN+9ChQyxXrhxXrFhBMnO+tfbt23PRokU6b0qBpjxrO8qzuUd51raUaR+O8qztKc/ahjJtwaROWxvLyMjg9evX+cYbb7BevXocPXq0uW3NmjVs2bIlPT09OWLECLM9NTWV586dY926dRkXF2ePsvOtXbt20TAMfvjhh/fcfnfQDQ4OZmBgIN3c3BQc7lP2JxSGDRvGBg0a8P333zefBhk6dCjLlCnDAwcO2LPMAuHnn3/mypUrOW7cOJKZcwVt3ryZAQEBrFevntV+UVFR5qTukjnkKevcmHVHfNq0aTQMwwxg2S/809LS+K9//Ytly5bluXPn7FJzQRAbG0tHR0er9y4pKYnff/89ycwLrhdeeIFBQUHqFLiHDz/8kIZhcM2aNWbIXb58uRlys55OOH36NBs2bMhXXnmFy5YtY1hYGMPDw83zq0KuFDTKs7alPJv7lGdtS5n2wSjP5g7l2YenTFtwqdPWxrJOtmfOnGGfPn0YHBzMkSNHmts3btzIVq1aMTQ0lMuXLzfbhw4dykqVKvHXX3/N85rzq3379tHd3d3qguBesp84YmJiWKdOHe7Zsye3yytUsj+hMHToUAYHB3Pw4MHs37+/hjr9iazwcPr0adasWTPHRVlGRgY3b97MqlWrMjg42Gy/exL3ouzKlSv09vZm/fr1ee3aNbM9LS2NVapUMRe0uFt6errVnFaS06ZNm+jq6sqEhASS1hcKWZ/7GTNmsH79+jxz5oxdaszvmjZtyvLly3P16tVWIdfNzY3du3c3P8szZ85kSEgIK1WqxCZNmmhFXSnQlGdtR3k27yjPPhxl2oejPJt7lGdtQ5m2YFKnrQ3FxMTwhRdeMO9SnDlzhr17984RdNeuXcvWrVvz+eef5/fff88x6zQoRwAAL8NJREFUY8bQ1dWVP/30k71Kz3f27NnDkiVLsnTp0mbb3SscZpf9BKIvvQdz99Cy8uXL6wmP+7Rs2TIOGTKEsbGx/J//+R82bNjQantGRga3bt3KUqVKsXHjxiQ1XPRugwcPZuXKlTlq1CiePHmSZOYKxU5OTvzmm2/sXF3BlZSUxDJlyrB169a/24nSt29ftm3b1uoCo6ibOHGi1UIqYWFhLFeuXI6Q6+7uzm7dupn7XblyhUeOHDHPp1pRVwoi5VnbUZ7Ne8qzD0eZ9uEoz+YO5dkHp0xb8KnT1oZWrlxpfiCyThanTp363aDbpk0bli5dms7OzgoS2ezatYvu7u5s1aoVq1evzhYtWpjb/mgicQWGezt27Jg5dCTL772P2YPuuHHjNA/Qfdi5cydLlizJ+Ph4Xrt2jQkJCSxfvnyOhS4yMjK4fft2raj7Bz766CNWqFCBkydP5vbt21mhQgX27t3b3mUVeAsXLqSLiws7depktbhNcnIyIyMjWaJEiRyrwRZlq1atYmhoaI7z5IsvvnjPkOvh4cHu3btbrcBL6mkEKbiUZ21Deda2lGdznzKtbSjP5g7l2b9OmbZwUKdtLti2bRsbNGhgnjR+L+iuXLmS7dq108klm59++slqKM7ixYvp7+/P5s2bm/toBcj7d+HCBTo4ONAwDPbt25eTJ0+22n6vCwOdlO/fwYMHOW7cOH7wwQdm2+3bt5mQkEA/Pz/+7W9/s2N1+VtSUhLj4uI4Y8YMHj9+3GwfNmwYfXx8+Oijj/L111832/W5f3Dp6emcNm0anZycWK1aNXbt2pXdu3dny5Yt6e3trafi7iHrPLhy5Uqr4cn3CrkrVqygYRjmvH8ihYXy7INTnrUt5dncp0z7YJRn847y7INRpi341Gn7ELI+AHcHhU2bNvHpp59mo0aNzEnZswfd6Ohoc9+soWeSKT4+nu+//775c0pKChcvXswqVarc9xMKYq179+6MjIzkqFGj2KBBA9asWZMxMTHct2+f1X56T++fxWLhlStX+Pjjj9PZ2ZkdOnSw2p6SksKEhAQGBASwSZMmdqoy//rll19Yq1YtduzYkf369cuxfezYsSxevDhHjhzJs2fP2qHCwmnbtm1s06YNa9WqxWeffZb9+/fn4cOH7V1WvmGxWKzm5Tt48CBdXFz49ttvW50vs0Ju9oUctm7dqmFjUmApz9qe8qztKc/mDmXaB6c8ax/Ks39OmbZwUaftQzp27Bi3b99OMjOgZX3RffvttwwLC2NISIhV0O3Tpw+rVq1qTkSuIVCZLl68yMOHD/PUqVNmW9Z7c/v27XsGXZ1M/lxGRgYHDhzIzp07k8wMsiNGjOAbb7zBUqVKccqUKdywYYN9iyxgsn9mN2/ezGrVqrFGjRo5huzdvn2b8+bNY61atZiUlJTXZeZbv/zyC0uUKMHBgwdbzde3ZMkSc1VdMvMJBV9fX0ZHR1udF+Th6GL2912/ft38/6yFleLi4lipUiW+8847VkPxwsLCWKFCBS5dutTqPdX3khRUyrO2oTybO5Rnc4cy7YNTnrUv5dk/pkxbuKjT9iFYLBY2btyY5cuX56hRo+jo6MhZs2aZ25ctW5Yj6J48eZL9+vWzGj5R1O3du5dPPfUUAwIC6ODgwOHDh+dYoTB70G3durU9yy0wsoLYlStX6Ovry4kTJ5rbmjdvzuLFizMkJITVq1fnCy+8oHno/kTW+3n9+nVmZGTwxo0bJDNDrr+/P9u2bcsdO3ZY/c7t27c1GX42ly5dYqNGjdirVy+r9jFjxtAwDD7//PNWQfejjz6ih4cHJ0yYoHBmI9kv0NTJ8l/r16+nr68v79y5ww8++ID+/v7mUzFxcXEsX758jpBbp04dfR9JoaA8axvKs7lDedb2lGkfjvKs/SnP/j5l2sJHnbY24O/vT0dHRw4ZMiTHtqyg26hRI+7du5ek7gxlt2vXLnp4eDAqKorLli3joEGDaBgG582bZ+6T/QmFJUuW8LHHHmO7du3sVXKBkjUsIjo6mm+//TZJ8vXXX6e3tzePHz/OkydPctmyZQwKCtJiAn8g6xhcsWIFW7duzeeee44vvPACf/75Z5Lkli1bWLlyZbZr104XC39g37599Pf35/r1680L2JiYGDo7O3Pq1Kl88cUX2bx5c6ugO3bsWC0gIrlu+/btbNKkCcuWLcsSJUqYKz5nyR5ysw8r05yJUpgozz445dncpTxrO8q0D095VvIzZdrCR522DyEtLY1paWmsVKkSK1SowCeeeIKbN2/OccB/++23rF+/PsPCwpiamqq7Qf/vwIEDdHR0tJoTbffu3fTy8uKbb75ptmV/v1JSUvjtt99q3pp7OHHiBKdPn86pU6dy/fr1Vts2bNjAUqVKsX79+vT19c1x91zH5J/75ptv6O7uzhEjRnDhwoVs2rQpXV1dzaeONm/ezMDAQDZr1swMvmItNjaWjo6OVsdbUlKSOQxv7969fOGFFxgUFKT3UPJE9mPx3XffpWEYrFSpEq9evUqSVvOBxcXFsWLFiuzcubPV04UKuVLQKc8+HOVZ21KezX3KtA9HeVbyI2Xawkudtg8g6wOxf/9+80NAknXr1mVgYOA9g+727dv566+/5mmd+ZnFYuHHH39MwzC4ePFis33kyJE0DIMNGzbkZ599xvj4eP722292rLRg2L17NytWrMgGDRqwVKlS9PPz49y5c632effdd1m6dOkc81TJn7tx4wbDwsLMC7KTJ0/Sz8+Pb731Fsn/nhPWrVvHOnXqaM6q37Fp0ya6uroyISGBpHW4yDpnzpgxg/Xr1+eZM2fsUqMUHdm/p2/dusUNGzYwISGBL774IgMCAszPcfYFlr788ku2bt1aoVYKBeXZh6c8a1vKs7lPmfbhKc9KfqNMW7ip0/YvyjopL1q0iNWrV7eaVNxisbBOnTp84oknmJiYSJIcPny4OWm+ZLp58yYtFguTk5M5YMAAOjg4cM2aNZwyZQq9vLw4adIkTpkyhQMGDGDJkiUZFBTEkJAQrlq1SnfQ72H37t308PBg//79mZKSwo0bN7JixYoMDw/njRs3zEnEFy5cyJo1a3Lnzp0kNazx94waNYqTJk2yart06RL9/Pz4n//8hxcvXmT58uXNcEuSn3/+OS9cuEBSK2j/kaSkJJYpU4atW7f+3Yv+vn37sm3btpo3TXJV9oD68ccf85NPPuHp06dJZq6a26RJEwYEBFhdbMXGxlr9nkKuFGTKsw9Peda2lGdtT5k2dyjPSn6iTFv4qdP2ASxdupTu7u6cMmUKL126lGN71pCdxo0bs1ixYvzhhx/sUGX+tHPnTrZo0YInTpwgmTkBfr9+/WgYBh0cHHIMczp27BgXL17M8PBwHjx40B4l52tZoaFNmzZW7U8//TQrV67MixcvWrU/99xzfO655/KwwoIlLS2NAwYMoGEYnDlzptW2Nm3acMiQIfT19WWPHj3MxUUuXLjANm3aMDY2lqSG5v2ZhQsX0sXFhZ06dbKaAD85OZmRkZEsUaIEf/nlFztWKIXZ3Z/PyMhIli1bljNmzLAKs9u3b+dzzz3HihUrcvny5QwNDWVwcLBCrRQqyrMPTnnWtpRnbU+ZNncpz4q9KdMWHeq0/RNr1qxhcnIyycwPxuXLl/n8889zzJgxJDPvsmfNvRQfH2/+3siRIzl8+HCryZ2Lul27dtHV1ZV9+/a1ar969SpHjRpFBwcHq2EmWXfU5fclJiby6aefZosWLcx5v0aPHk3DMFi/fn02b96cHTt25OjRo3n+/HnOnDmTDRs25Pnz5+1cef5148YNc1jjjBkzSGbefezXrx+LFy/OsLAwqy/J/v3784knnjAv3OSPpaenc9q0aXRycmK1atXYtWtXdu/enS1btqS3tzd/+ukne5coRcSsWbNYpkwZ7tmzx2y7deuW+VTM4cOH2apVK/r5+fHFF180L2p1ESsFkfKs7SjP2p7ybO5Qps09yrOSnyjTFm7qtP0dGRkZ/O677/jII4/w3LlzZrvFYmHjxo3Zt29fXrp0ie+//z4bNWrESpUq0dHRkaNHj7baVzLt2rWL7u7uHDhwoFV71h2e5ORkRkVF0cHBgfPnzyep9+9+rV27li1atGCLFi34xhtvsHTp0ly0aBGTkpK4YsUKjhs3juXLl2flypX55JNP5lhBUjJlv9t47NgxRkVF0TAM82mDGzdusHXr1qxVqxYjIiI4ceJEvv766yxevLgWGXgA27ZtY5s2bVirVi0+++yz7N+/vxZkkVwTGhrKL774wqrto48+YseOHUmShw4dYkxMDKtVq8YmTZpYLSh09OhR8/ygzhcpaJRnbUt5Nvcoz9qOMm3eUZ6VvKZMW/So0/ZPZM3pc/ToUV6+fJnp6emMiopi3bp16eTkxJdffpmzZ8/mtWvX2LNnT7Zu3VofgLvs2bOHxYsXzxFwhw4dyj59+pg/X79+nVFRUXR1deWcOXPyuswCJ/txtnLlSjZr1oweHh5WJ+YsycnJTEhIsFodUu5t0aJFrF27Ntu1a0c3NzcahsGYmBiS5LVr1zhgwACGhoYyKCiInTp10tCnh6B56CQvXLlyhTNnzrRaNZfMnG/O29ubAwYMYO3atdmmTRtGRUWxR48erFu3bo5FgzSMTAoy5dmHpzybO5Rnc48ybd5QnpW8okxbNKnT9i73uht+/PhxGobBIUOGmEPKtm/fzq+//tpqvw4dOrBHjx76EGSTkZHBBg0a0DAMHj161GwfM2YMvby8uGzZMqv9r127xrfffpuPPfaYJm7/HVnH6N3H6urVq9msWTOGhYVx3bp1ZnvW8Af5cz///DPd3d05ffp0Xrp0iXv27GHfvn2tQm7W5zs1NVUh7SFlP4b1JJLkhXHjxnHYsGHmz126dGFYWBinTJliDv/esGED69Wrp5XepUBTnrUt5VnbU57NXcq0eUd5VuxBmbboUKdtNllfXDdv3uSFCxe4YcMGcyXdGTNm0MHBgSNGjOD169etfu/UqVPs168fH3vsMauJyCXT2bNnWalSJTZq1IgXLlxgdHQ0H3vsMa5atSrHvllzf2Ufwif/lRUE1q9fz969e7Nnz54cOXKkuX316tVs0aIFQ0NDzTnB5P4tWbKENWrUMOf9IzPvaL733ns0DINz5861Y3Ui8lfcfeF07do1Dho0iO7u7lZPcGX/vKemprJ58+Zs2bKlLrykwFKezR3Ks7ajPJv7lGlFCg9l2qJNnbb/LyvgHjx4kJ07d2a1atXo5ubGYsWK8R//+AfPnj3L+Ph4GobBUaNG8erVqyTJZcuW8fXXX2dAQIDmAPoDZ8+eZbly5Vi6dGmWKlXKDLjZn+KIiYkx5/+S37do0SK6ubnxtddeY3h4OMuXL8969eqZFwbLly/nSy+9xPr16/P777+3c7UFy9q1a+ng4MC9e/eS/O8X5A8//EAnJycahsHZs2fbs0QRuU/p6em8fPmy2VlFkpcvX+bo0aNZrFgxcwEmMnMBoU8++YTNmjVjzZo1zSe69KShFDTKs7lLedZ2lGdzlzKtSOGhTFu0qdOW/z2Ad+/ezXLlyrFHjx6cM2cO9+/fz6ioKPr5+TEwMJAnT57kvHnzaBgGR48ezdTUVF66dIkLFy7UKpvZnDhxgvHx8Zw0aRJTUlLM9vPnzzMwMJBVq1bl4cOHre74DBkyhIZhcP/+/fYoucA4e/Ysq1evzvHjx5PMPIEfPHiQderU4VNPPWXut3TpUrZv317H5V906dIlNmnShJ07d+ahQ4fM9lOnTvEf//gHx44dqxW0RQqAlStXMiIigj4+PvT19eVTTz3FpUuXMiUlxVxNu1ixYua51GKxMDIykl26dDHnV9R8nlLQKM/alvJs7lGezX3KtCKFgzKtFPlO2+wB18PDgwMGDMhxUMfHx7NmzZoMCgri7du3OW3aNDo7O3PgwIE5JoEu6nbv3k0/Pz/WrVuXXl5erFatGm/dumVuP3fuHH18fNiwYUNz6N2wYcPo7u7OH3/80V5lFxjHjh2jr68vt2zZYtW+b98++vj4cNKkSWbbzZs387q8AiPrAuvHH39kfHw8Y2JimJSURJL86quvGBwczNdee407duzgb7/9xgEDBjAoKMhqyImI5E+zZ8+mr68ve/XqxQkTJvCTTz5hcHAwPTw8OG7cON68eZPJyckcNWoUixcvznHjxpm/m3Vu0Nx+UtAoz9qW8mzuUp61HWVakcJLmVZIddqSJE+ePMlSpUqxbdu2ZlvWXFRZZsyYQU9PT86YMYMkOWrUKHp5efHixYt5Xm9+tWvXLrq7u3PQoEE8e/YsDx8+zAoVKvDf//631X5nzpyhj48Pw8LC2KNHD7q5uSng3qeUlBRWrFiRI0aMyNEeHBzMQYMG2amygmfBggUsXrw4GzRoQE9PT1avXp3R0dG0WCycP38+w8LCaBgGq1Wrxscee0zDRUUKgBkzZtDZ2Znx8fFWT8aRZLt27eji4sIvvviCZOZ3UXR0NA3DYGxsrLmf5v2Sgkp51jaUZ3Of8qxtKdOKFD7KtJJFnbbMXE23fv36bN26NTdt2mS1LfuB3qhRI/7tb38zf758+XKe1ZjfHT58mG5ubhw8eLBV+zPPPMNBgwbx9ddf57x583jkyBGSmcOiHn30URqGoeDwB7LPPWOxWJiens7333+fDRs2ZHx8vNW+zZs3N1eQ1An6v+41f8/evXtZrlw5zpo1izdu3GB6ejrfe+89hoSEmHcob9y4wc2bN/O7774zn1gQkfxrzpw5NAwjR8dK9g6rpk2b8vHHH+ft27dJZobcL774QsPGpFBQnn14yrO5Q3nWNpRpRYoGZVrJzgGCxx9/HHPnzsWdO3cwcuRIJCYm3nM/BwcHeHh4mD97eXnlUYX5m8ViwezZs1GsWDGULFnSbB8zZgy2bt2KY8eO4cCBA+jSpQs+/fRTXL16FWXLlsXx48dx5MgR1K5d237F50MnT57E5MmTAWQecxaLBQBgGAYcHR3RrVs3lCxZEpMmTcLAgQOxfPlyvPPOO9i8eTNee+01c1/JPDYdHBzw66+/YsmSJWb78ePH4e7ujvDwcHh6esLR0REjR47EU089hS+//BJXrlyBp6cnQkJC0KhRI1SoUMGOf4WI3I+9e/cCAFxcXHDr1i2z3cnJyTyP9u3bF+fPn8eWLVsAAN7e3ujcuTOcnJyQnp6e90WL2JDy7MNRnrUt5VnbUqYVKTqUacWKvXuN85NDhw6xadOmDA8PZ2JiotmekZHBpKQkNmvWjHPmzCGpO793++233/juu+8yODiYMTExHDt2LEuXLs0VK1aY71WvXr1YrFgxHj9+3L7F5mPp6emMiopi1apVreakybqznvVeHjx4kIMGDaK/vz8DAwMZHBysJzx+x2+//cZSpUrxiSeeMIeLrF27luXLl+fhw4dJ0lxV88aNG3RxceFXX31lt3pF5MG9/fbbdHd3Z1xcnNVQsqxz54EDB2gYhrniu0hhpDz74JRnbUN5Nnco04oUHcq0kkWdtnfJHnSzDy2LiopirVq1NKTkD5w5c4a9evViYGAgHR0duW7dOpI0F2749ttvWblyZR44cMCeZeZ7p06dMi8YxowZY7ZnZGRYXVxlZGTwzp07vHbtGq9du2aPUguEDRs20MHBgfXr1+dLL73Er776iikpKaxQoQI7dOhgte+5c+dYu3Ztrlmzxk7VisiDyL7IQkRExD1DbkZGBv/973+zYcOGPHPmjD3KFMkzyrMPTnnWNpRnbU+ZVqTwU6aVu2l6hLsEBARg8uTJMAwDI0eOxM8//4xx48Zh6tSp+OKLLzSk5A94e3tj8ODBCA8PR40aNfDzzz8DANzd3QEAq1evRunSpVGmTBl7lpnvlS9fHv3790f9+vXx9ddfY+zYsQAyh5aRBABz6OOcOXNQrFgxFCtWzJ4l52uNGzdGly5dkJaWBicnJ8TExGD9+vVYsGABVq1ahX/84x/YtWsXjhw5gilTpuDcuXOoWrWqvcsWkb/A0dERGRkZAIDPPvsMXbp0Qbdu3ZCQkGAOK7tz5w6++OILVKlSBWXLlrVnuSK5Tnn2wSnP2obyrO0p04oUfsq0koO9e43zq0OHDrFly5YsU6YMnZ2dtRrsX5D1hEL2O+sjRozgI488wt27d9u5uoIj+/sYHR1ttt+6dYs9e/aks7Mz9+3bZ8cK85+7F2jImpj922+/ZZcuXbhq1Sq2adOGjRo1YlxcHHfs2EF/f3/6+PjQz8+Pfn5+3Llzpz1KFxEbuNfTCfPnz2dKSgpbtmzJWrVqmQs0aFi4FAXKsw9OedY2lGcfjDKtSNGmTCtZDPL/b3VKDgcPHkS/fv0wevRo1KhRw97lFChnz57FqFGjsHv3bqSmpmLPnj1ITExEvXr17F1agZL1Pu7YsQMvv/wyIiMj8cEHH2DGjBn4/vvvUbduXXuXmG9kLdCQlJSEH3/8ES+//LK57cKFC2jUqBF69eqFtm3bIiIiApcuXUJUVBRCQ0OxZ88e3Lx5EwEBAShXrpwd/woReVgZGRlwdHQEAPTs2ROxsbHw9vaGi4sLdu3aBWdnZ6t9RAo75dkHpzxrG8qzf40yrYgAyrSSSZ22fyItLQ3Ozs72LqNAOnv2LAYOHIhNmzZhwYIFWlX3AWUF3Z9++gnXrl3D0aNHkZiYqIB7D0lJSahTpw4uX76MZs2a4fXXX0ft2rVRtWpVLF26FOPHj0dCQgIuXryIwYMH48qVK+jSpQs6d+5s79JF5D5kXcjeC0lzpfHsAbZbt27YtGkT9u7dC2dnZ6Snp8PJySnPahbJD5RnH5zyrG0oz/41yrQihZsyrdwvddpKrrpw4QIsFovmWnlIWRcMiYmJWLBgAWrVqmXvkvKlEydO4JVXXoGzszNSU1NRt25drFmzBgMHDoSXlxdiY2PRs2dPNGvWDPv27cO7774Ld3d3xMbGonjx4vYuX0T+QPZwO3/+fJw5cwYXLlxA586d4efnB1dXV6v9s4fcrPCrcCsiD0J51jaUZ++fMq1I4aVMK3+FOm1FCghdMNyfw4cPo3///rBYLOjcuTMMw8CkSZPg5eWFb775BkFBQfj+++/h4uKCgwcPwtPTUwuyiBQg/fr1Q1xcHEJDQ3HgwAFcu3YNvXr1QkRERI7hYdlDcfanFkRExD6UZ++fMq1I4aZMK/dDXfMiBUTp0qXtXUKBEBAQgNGjR+O9997DtGnTMGXKFCxbtgx79+5Feno62rdvDxcXF5BEYGCgvcsVkb9gwYIF+Oqrr7BixQrUqlULK1asQIsWLeDr63vP+byyDztTuBURsT/l2funTCtSeCnTyv269yQaIiIFWGBgICZNmgQA6N27N3bt2oUGDRpg6dKl6NixIwB92YkURKdPn0ZISAhq1aqFr776Cq+++iqmTp2Kl156Cbdu3cLx48ftXaKIiIjNKNOKFE7KtHK/1GkrIoVSQEAAPv30Uzg4OGDEiBFITEy0d0ki8hdYLJYcbadOnYK7uzt27tyJ7t27Y8yYMYiIiAAAxMXFYd68ebh9+3ZelyoiIpJrlGlFCjZlWnkY6rQVkUIrICAAkydPhrOzMyIjI7Ft2zZ7lyQi9ylrGNj27dtx5swZAMCrr76KJUuWoH79+oiJiTHDbUpKChYvXoyzZ8/Czc3NbjWLiIjkBmVakYJLmVYehjptRaRQCwgIwPjx41GhQgX4+PjYuxwR+RPZn0ZYu3YtWrRogbi4OFy8eBF169ZF37594ePjg5MnT+LcuXPYvn07/v73v+P06dOYOHEigMwFGkRERAoTZVqRgkWZVmzBoI4CESkC7ty5AxcXF3uXISJ/IPtquFOnTsXNmzfx4YcfwsPDA/3790dERARu3LiBf/3rX5gwYQIcHR3h4+MDb29vLFu2DM7OzsjIyLjnAg4iIiKFgTKtSP6nTCu2ok5bERERsbvs4Xb48OGYOHEiZs2aBQcHByxZsgSLFy/GwIEDERERAU9PT5w/fx4HDhxA2bJlERAQAAcHB6Snp8PJycnOf4mIiIiIFFXKtGJLOgpERETEbv7zn/+gRo0aMAwDGRkZuH79Or7++msMGzYMbdq0AQD87W9/g5eXF4YNGwYA6NixI7y9vVGmTBnzdSwWi8KtiIiIiNiFMq3kBs1pKyIiInYxcOBA9OrVC9999x0AmEPAsg8Hy1o59+OPP0ZISAgmT56M+fPnIzk52eq1shZ5EBERERHJS8q0klt0NIiIiIhdPPvss0hLS8OUKVOwYcMGAICXlxeqVKmCmTNnAgDc3NyQlpYGAPDz80OJEiUwfvx4bNmyBYD1Ig8iIiIiInlNmVZyizptRUREJM9lZGSgefPmiI6OxsWLFzFt2jSsX78eADBhwgTcunULTZo0QVpamvnEQXJyMmbPno0GDRpgwIABAPQ0goiIiIjYjzKt5CZNlCEiIiJ5ymKxmEPFXF1dERgYiK+//hrXrl2Dm5sbQkJCMHv2bLz11lvw9/dHjRo1cPr0ady8eRP16tXDs88+i5MnT8JisSjgioiIiIhdKNNKbtNRISIiInkqK5T27dsXbdu2RfHixfHSSy9h69atGDNmDDZv3oxGjRphx44d6NKlC6pXr46WLVti//79AIA9e/agfPnySEtLA0l7/ikiIiIiUkQp00puM6gjQ0RERPLYjz/+iNatW2P+/Plo1KgRAGDVqlUYMGAAvL29MWjQIDzzzDNWv3P+/HmMGjUKc+fOxXfffYcaNWrYo3QREREREQDKtJK7ND2CiIiI5Dk3NzeQtBoKFh4eDpJo1aoVXF1dkZycjObNmwMATp06hUWLFmHz5s1Yu3atwq2IiIiI2J0yreQmTY8gIiIiuSprUE/2wT1Z/3/s2DEAQHp6OgCgadOmqF69OrZs2YJt27aZ+1eoUAGvvPIKVq1ahdq1a+dR5SIiIiIimZRpJa/pSVsRERHJNdkXVrh8+TIAoGTJknjyySfRtWtX9OjRAxUrVkTjxo0BAFevXkXt2rURHh6OV1991eo1fHx87PI3iIiIiEjRpkwr9qBOWxEREckV2YeKRUdHY+nSpbh+/To8PT0xefJkREZG4sKFCwgNDcX777+P4sWLY/369bh58ybmzJkDwzCQkZFhrsorIiIiIpLXlGnFXrQQmYiIiOSqYcOGYdq0aZg4cSKCgoLQrFkzeHh4YPny5Shfvjw++eQTLF26FLdu3YKPjw/mz58PZ2dnqycaRERERETsSZlW8po6bUVERCRXkMTZs2fx8ssvY9CgQWjVqhVWrlyJV199FdHR0YiIiDD3vXbtGtzd3eHk5ATDMJCeng4nJw0IEhERERH7UqYVe1FXv4iIiNhEu3btMHPmTPNnwzCQnJyMU6dOoVmzZli1ahXatm2LMWPGICIiAtevX8fEiRNBEo8++iicnZ1hGAZIKtyKiIiIiF0o00p+oU5bERERsYnSpUujd+/emDt3rtlWrVo1BAQEoFu3bnjllVcwceJE9OjRAwBw5swZLFiwAGvWrLF6HcMw8rRuEREREZEsyrSSX6jLX0RERGxi6tSpKFGiBN544w0AwGuvvYb09HQ0aNAAM2fORJs2bfDmm28CAFJSUsyFGkJDQ+1ZtoiIiIiISZlW8gt12oqIiMhDyb64wsiRI5Gamoo33ngDFosFnTp1Qu/evXHo0CHs3r0bbdu2xeOPP47t27fj6tWr2LlzJxwcHLRAg4iIiIjYlTKt5Dc6kkREROShZAXT2NhYWCwWjB8/Hu+99x66du2KL7/8Ej4+Ppg0aRK6d++O5ORk/PbbbwgJCcFPP/0EZ2dnpKenK9yKiIiIiF0p00p+Y5CkvYsQERGRgu3UqVMIDQ3FK6+8gpEjRwIABgwYgP/93//FrFmz0Llz53v+XkZGBhwdHfOyVBERERGRe1KmlfxE0yOIiIjIX3Z3MC1ZsiReffVVbN++HQcOHEC1atUQHR0NwzDQrVs3ODo6okOHDjleR+FWREREROxFmVbyMz23LSIiIn9ZVjCNj4/H7t274e7ujrfffhvHjx/Hxx9/bO43evRoREZGolOnTli9erW9yhURERERyUGZVvIzTY8gIiIiD2TVqlVo1qwZPDw8MHXqVLRq1QrHjx9Hs2bNMGHCBHTq1Mncd/r06fjnP/8JJycN8hERERGR/EOZVvIrddqKiIjIfbnXarjt27fH1q1bUa1aNVSqVAlVqlRBWloa9u/fj+HDh8Pf399q//T0dIVcEREREbEbZVopKHSEiYiIyH3JCre//PILKleuDA8PD3Tt2hVlypRBzZo1YRgGpk+fjiNHjuDRRx9FYmJijoCrcCsiIiIi9qRMKwWF5rQVERGR+7Z161bUrFkT/fv3x7p16xAWFobk5GScOHECb775JlatWoWWLVsiKSkJCxcutHe5IiIiIiI5KNNKQaDpEUREROR3kYRhGFZt8fHxSEhIwP79+9GpUyeEh4fjueeew4wZM9CuXTuQxNq1a/H8889rJV0RERERsTtlWimI1GkrIiIi95R9vq+zZ8+CJLy9vWEYBpKSkrBx40b07t0bYWFhuHLlCjIyMjBt2jRUrVrVfI2MjAyFXBERERGxG2VaKag0PYKIiIjkQNIMtx999BHCw8PxzDPP4Mknn8TSpUtRqlQpdOrUCUeOHIGzszPOnDmDjRs34ueff7Z6HYVbEREREbEXZVopyPSkrYiIiPyukSNH4pNPPsGkSZPg6emJhQsXYvXq1fjoo4/QqVMnPPLII7hz5w7Wr1+PtWvXYsyYMVqYQURERETyFWVaKYjUaSsiIiL3lJycjPDwcHTu3Bk9e/Y02yMjIzFr1iysWbMG9erVy/F76enpCrkiIiIiki8o00pBpekRREREJAeSSE9Px/nz5+Hl5QUAuH37NgBg/PjxePLJJ/Hxxx8DyJwnLDuFWxERERHJD5RppSBTp62IiIjkCKmGYaBkyZKoXLkypk+fDgBwc3PDnTt3AAB+fn5wcXEBAHOeMBERERERe1KmlcJER6SIiEgRl31F3X379uHYsWO4fv06AGDIkCG4ePEiOnToAABmqD127BhKlChhn4JFRERERO6iTCuFjea0FREREQBAVFQUvv76a/z2229o3749OnfujMaNG2Pu3LkYPnw4LBYLateujZMnT+L69evYs2ePho2JiIiISL6iTCuFhTptRUREiqjsTyMsWbIEffr0QUxMDE6dOoXY2Fi4uLjggw8+QFhYGI4ePYrJkyfDYrHAy8sLw4YNg5OTkxZoEBERERG7UqaVwkqdtiIiIkVQamoqXF1dAQBr167FN998g6pVq6J3794AgG3btmHEiBG4c+cO3n33XbRs2TLHa2RkZMDR0TFP6xYRERERyaJMK4WZ5rQVEREpYuLi4jB16lSQxMGDB9GrVy/Mnj0b586dM/dp0KABhg4dCldXV0ydOhVfffVVjtdRuBURERERe1GmlcJOnbYiIiJFBEmkp6djwoQJ8PDwgGEYCAwMxKeffoonnngC69atw6ZNm8z9g4ODMXToUFy5cgU//PCDHSsXEREREcmkTCtFhTptRUREigjDMJCeno6rV6+aw8gAIDQ0FKNGjYLFYsFnn32GLVu2mNuCgoIwe/ZsTJgwwR4li4iIiIhYUaaVokKzLIuIiBQxxYoVQ9myZQH8dw6v8PBwZGRkYPjw4Zg8eTIMw8DTTz8NAKhevToA60UeRERERETsSZlWCjsdpSIiIoXcunXrMHLkSACAs7Mzbt68iWLFipnbs9Ykbd68OYYMGYKkpCQMHToUe/futXodhVsRERERsRdlWilq9KStiIhIIZaamop///vf2LZtGzw9PfHPf/4TqampSEtLA5Bz4YUWLVqAJL755hvUqFHDHiWLiIiIiFhRppWiyGDWrQgREREplE6fPo1x48Zh+/btCAkJwdKlS9GhQwcUK1YMFovFnAvs1q1bOH/+PLp3746qVasC0PAxEREREckflGmlqFGnrYiISBFw5swZjBo1Chs3bsS+ffvg7++PYsWK4ebNm7BYLDAMA25ubvDy8sL69evh5KTBOCIiIiKSvyjTSlGio1dERKQIKFeuHAYPHgxHR0d4eXmhcePG5pxgd+7cgZOTExwcHEAShmGYizmIiIiIiOQXyrRSlOjZcBERkSLC29sb/fv3R506dbB69WpER0cDAFxcXJCRkQEAMAwDJBVuRURERCRfUqaVokLTI4iIiBQxZ8+exejRo7Fz5040adLEfDpBRERERKSgUKaVwk5P2oqIiBQx3t7eGDhwIPz9/XH+/Hno/q2IiIiIFDTKtFLY6UlbERGRIury5cvw8vKymvdLRERERKQgUaaVwkqdtiIiIkWcxWKBg4MG34iIiIhIwaVMK4WNOm1FRERERERERERE8hHdghARERERERERERHJR9RpKyIiIiIiIiIiIpKPqNNWREREREREREREJB9Rp62IiIiIiIiIiIhIPqJOWxEREREREREREZF8RJ22IiIiIiIiIiIiIvmIOm1FRAqhjRs3wjAMXL169b5/5/HHH8cnn3ySazWJiIiIiPwVyrQiUpSp01ZExA66dOkCwzDQo0ePHNvefvttGIaBLl265H1hIiIiIiL3SZlWRCT3qNNWRMROfH19MX/+fKSkpJhtt2/fxrx581CxYkU7ViYiIiIicn+UaUVEcoc6bUVE7KRu3brw9fXFokWLzLZFixahYsWKqFOnjtmWmpqKd955B2XKlIGbmxueffZZ7Nixw+q1li9fjqpVq8Ld3R1NmjTBr7/+muPfS0xMRMOGDeHu7g5fX1+88847uHnz5j1rI4kPP/wQFStWhKurK3x8fPDOO+/Y5g8XERERkUJDmVZEJHeo01ZExI66du2Kzz//3Px59uzZeOONN6z26devHxISEvDFF1/gp59+QpUqVRAeHo7Lly8DAJKSktCmTRu0atUKu3btwptvvon+/ftbvcbRo0fRtGlT/P3vf8eePXsQHx+PxMRE9OrV6551JSQkYOLEiZg+fToOHz6MxYsX48knn7TxXy8iIiIihYEyrYiI7anTVkTEjjp27IjExEScOHECJ06cwObNm9GxY0dz+82bNxETE4Px48ejWbNmqF69OmbOnAl3d3fMmjULABATEwN/f39MmDABgYGB6NChQ465w6Kjo9GhQwf06dMHAQEBCAkJweTJk/Hll1/i9u3bOeo6efIkvL29ERoaiooVKyIoKAjdunXL1fdCRERERAomZVoREdtTp62IiB2VLl0aLVq0wJw5c/D555+jRYsWKFWqlLn96NGjSEtLwzPPPGO2OTs7IygoCPv37wcA7N+/H8HBwVav+/TTT1v9vHv3bsyZMwePPPKI+V94eDgsFguOHz+eo662bdsiJSUFlStXRrdu3fD1118jPT3dln+6iIiIiBQSyrQiIrbnZO8CRESKuq5du5pDuqZOnZor/8aNGzfQvXv3e87hda8FInx9fXHw4EGsXbsWa9asQc+ePTF+/Hh89913cHZ2zpUaRURERKTgUqYVEbEtPWkrImJnTZs2xZ07d5CWlobw8HCrbf7+/nBxccHmzZvNtrS0NOzYsQPVq1cHADzxxBP44YcfrH5v27ZtVj/XrVsX+/btQ5UqVXL85+Lics+63N3d0apVK0yePBkbN27E1q1bsXfvXlv8ySIiIiJSyCjTiojYlp60FRGxM0dHR3NYmKOjo9U2T09PREREIDIyEo899hgqVqyIcePG4datW/jnP/8JAOjRowcmTJiAyMhIvPnmm9i5cyfmzJlj9TpRUVFo0KABevXqhTfffBOenp7Yt28f1qxZg08//TRHTXPmzEFGRgaCg4Ph4eGBuLg4uLu7o1KlSrnzJoiIiIhIgaZMKyJiW3rSVkQkH3j00Ufx6KOP3nPbmDFj8Pe//x2dOnVC3bp1ceTIEaxatQolSpQAkDkULCEhAYsXL0atWrUwbdo0jB492uo1atasie+++w6HDh1Cw4YNUadOHQwdOhQ+Pj73/De9vLwwc+ZMPPPMM6hZsybWrl2LpUuXomTJkrb9w0VERESk0FCmFRGxHYMk7V2EiIiIiIiIiIiIiGTSk7YiIiIiIiIiIiIi+Yg6bUVERERERERERETyEXXaioiIiIiIiIiIiOQj6rQVERERERERERERyUfUaSsiIiIiIiIiIiKSj6jTVkRERERERERERCQfUaetiIiIiIiIiIiISD6iTlsRERERERERERGRfESdtiIiIiIiIiIiIiL5iDptRURERERERERERPIRddqKiIiIiIiIiIiI5CP/ByYWU3TNDBA9AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O-txODa2Q2N0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cc796ed43f0943aa87252c0ee28b1b3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4caa9a6ac69442f9ab0450b139e95eb4",
              "IPY_MODEL_b6e2fd8d96634fb2a534dd6b15698a22",
              "IPY_MODEL_39f2c80e1ab64616b439f7471fb962e2"
            ],
            "layout": "IPY_MODEL_87c5899cbb49454d916dae5e538d6921"
          }
        },
        "4caa9a6ac69442f9ab0450b139e95eb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_821fe3969ecf4a8fa16fcf41f4b63245",
            "placeholder": "​",
            "style": "IPY_MODEL_7883f670814a4fc2ab8721f045a546d2",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "b6e2fd8d96634fb2a534dd6b15698a22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73a815c952694f95a4f24e87e976fe99",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d829106523a44d88f2e601b678afd57",
            "value": 48
          }
        },
        "39f2c80e1ab64616b439f7471fb962e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b047f99e112447293c61a5d18867c6e",
            "placeholder": "​",
            "style": "IPY_MODEL_39cb6c79f830421c9e06680d7201a622",
            "value": " 48.0/48.0 [00:00&lt;00:00, 3.59kB/s]"
          }
        },
        "87c5899cbb49454d916dae5e538d6921": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "821fe3969ecf4a8fa16fcf41f4b63245": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7883f670814a4fc2ab8721f045a546d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73a815c952694f95a4f24e87e976fe99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d829106523a44d88f2e601b678afd57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b047f99e112447293c61a5d18867c6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39cb6c79f830421c9e06680d7201a622": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d81f9632fad842c887e5ebce1392e53b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5a5293c7aaa49809d0cbccee172c90d",
              "IPY_MODEL_6ad9f4feedad413ca632291d1d895ad4",
              "IPY_MODEL_eca94c24ef4e47c488e2d44591afaece"
            ],
            "layout": "IPY_MODEL_e45987e26c0f4e19a619290cab11808d"
          }
        },
        "d5a5293c7aaa49809d0cbccee172c90d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_926d2ba251ef4bcb8f50152d9ee19c38",
            "placeholder": "​",
            "style": "IPY_MODEL_876eaa5fe2c647aa821dcb8062041949",
            "value": "config.json: 100%"
          }
        },
        "6ad9f4feedad413ca632291d1d895ad4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cd2fe7dc1634194ab987946ae653747",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d630aaa0c8b4ac9bff69fea11fd255d",
            "value": 570
          }
        },
        "eca94c24ef4e47c488e2d44591afaece": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f660affabaf84b459014f70e73a34b9b",
            "placeholder": "​",
            "style": "IPY_MODEL_3349b25fbfd4470b956bcb3212860bf6",
            "value": " 570/570 [00:00&lt;00:00, 35.7kB/s]"
          }
        },
        "e45987e26c0f4e19a619290cab11808d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "926d2ba251ef4bcb8f50152d9ee19c38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "876eaa5fe2c647aa821dcb8062041949": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7cd2fe7dc1634194ab987946ae653747": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d630aaa0c8b4ac9bff69fea11fd255d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f660affabaf84b459014f70e73a34b9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3349b25fbfd4470b956bcb3212860bf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbc9867e30d7467a892112c3c2c8e09d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b7dd3edd50534299a182a285d6013b4c",
              "IPY_MODEL_562fc31aeed049eb8340d025a576117a",
              "IPY_MODEL_5c3fe3a6bb2540a29ed1feb34349d2ae"
            ],
            "layout": "IPY_MODEL_4737cbd82ae04d74884f215ebdfb8ef9"
          }
        },
        "b7dd3edd50534299a182a285d6013b4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bff35083e0142f28078382a022497ac",
            "placeholder": "​",
            "style": "IPY_MODEL_fd9443e8355c4ae1ae01e028e971892c",
            "value": "vocab.txt: 100%"
          }
        },
        "562fc31aeed049eb8340d025a576117a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c434b8b0737f4c2ba5226716160ad782",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d4a79af63bd2468689126bbc6f6f6113",
            "value": 231508
          }
        },
        "5c3fe3a6bb2540a29ed1feb34349d2ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f50848b024fc4f1eb0ee542573f43087",
            "placeholder": "​",
            "style": "IPY_MODEL_29e5a64c98374e85a56b3377fd1d87bc",
            "value": " 232k/232k [00:00&lt;00:00, 7.70MB/s]"
          }
        },
        "4737cbd82ae04d74884f215ebdfb8ef9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bff35083e0142f28078382a022497ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd9443e8355c4ae1ae01e028e971892c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c434b8b0737f4c2ba5226716160ad782": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4a79af63bd2468689126bbc6f6f6113": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f50848b024fc4f1eb0ee542573f43087": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29e5a64c98374e85a56b3377fd1d87bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d79c869da18043c0b8c27085f5a29836": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_45c9c5010e694b519dc97c3d5b55204d",
              "IPY_MODEL_a70465acb10f404ab2bc9ba8900dfde8",
              "IPY_MODEL_7774a68a9968421aabf3e6d34fa0b768"
            ],
            "layout": "IPY_MODEL_f68c7b588b4a42688ff5f45474bfdf00"
          }
        },
        "45c9c5010e694b519dc97c3d5b55204d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9f8a9fd69a14fd4a639876e73482aa5",
            "placeholder": "​",
            "style": "IPY_MODEL_9a6139027be348fbba8b6f64274de1e2",
            "value": "tokenizer.json: 100%"
          }
        },
        "a70465acb10f404ab2bc9ba8900dfde8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e6cdad9b4724431b5f7d39790fd8cb9",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2353661821054aeba24849371f6985db",
            "value": 466062
          }
        },
        "7774a68a9968421aabf3e6d34fa0b768": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e309a6b4f66a4347bb4b59a9738562da",
            "placeholder": "​",
            "style": "IPY_MODEL_f99da6587a6d40acb9305185fb2b1ec0",
            "value": " 466k/466k [00:00&lt;00:00, 29.2MB/s]"
          }
        },
        "f68c7b588b4a42688ff5f45474bfdf00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9f8a9fd69a14fd4a639876e73482aa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a6139027be348fbba8b6f64274de1e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e6cdad9b4724431b5f7d39790fd8cb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2353661821054aeba24849371f6985db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e309a6b4f66a4347bb4b59a9738562da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f99da6587a6d40acb9305185fb2b1ec0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e153c3bd81314717a4c02e4a25fdfd60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89de1ef691a34a6c9f55f549770e82ef",
              "IPY_MODEL_28d1fad381bd4e9b9cc5b8a39f8ad255",
              "IPY_MODEL_e596e4c1a48f46f8a59442db31f8710c"
            ],
            "layout": "IPY_MODEL_4e099c39b232403080aca190a85959f6"
          }
        },
        "89de1ef691a34a6c9f55f549770e82ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b78131d92594522a303bf353040286f",
            "placeholder": "​",
            "style": "IPY_MODEL_f96dd57c31994d9fb6a40898413770ce",
            "value": "README.md: 100%"
          }
        },
        "28d1fad381bd4e9b9cc5b8a39f8ad255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15dca22ec4a349599849ee4fc12fe033",
            "max": 8878,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ac57e43c32b4dfebdf6b127d54d55c0",
            "value": 8878
          }
        },
        "e596e4c1a48f46f8a59442db31f8710c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f873926761b64924be7b31365092bd7f",
            "placeholder": "​",
            "style": "IPY_MODEL_8248227f066a41cc92b43ee29b07c5fd",
            "value": " 8.88k/8.88k [00:00&lt;00:00, 737kB/s]"
          }
        },
        "4e099c39b232403080aca190a85959f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b78131d92594522a303bf353040286f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f96dd57c31994d9fb6a40898413770ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15dca22ec4a349599849ee4fc12fe033": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ac57e43c32b4dfebdf6b127d54d55c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f873926761b64924be7b31365092bd7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8248227f066a41cc92b43ee29b07c5fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a99bd5d16594921b88726fabdee3047": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a28662be162f487e9e6175680b73c594",
              "IPY_MODEL_e6c92df1dcbe4e62add2b4f04ac13752",
              "IPY_MODEL_505e79841d764987baa5dd3ab00cb42a"
            ],
            "layout": "IPY_MODEL_a69528d258384126bd9c3cbec914fdf5"
          }
        },
        "a28662be162f487e9e6175680b73c594": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_274a9f52ca444217ad4379bdfdfb1a97",
            "placeholder": "​",
            "style": "IPY_MODEL_27fc02adf68c450fa172ebd2ee916740",
            "value": "financial_phrasebank.py: 100%"
          }
        },
        "e6c92df1dcbe4e62add2b4f04ac13752": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec564c5b86104bc79ff1fdfe99e03d2e",
            "max": 6036,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ecc9eb27efc4485fb9d84fa24769ed02",
            "value": 6036
          }
        },
        "505e79841d764987baa5dd3ab00cb42a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65f13d5a86d2477e9c5e9b3aa0b34e23",
            "placeholder": "​",
            "style": "IPY_MODEL_884c1ca35e164ba5a4e67fa8ebcda63b",
            "value": " 6.04k/6.04k [00:00&lt;00:00, 520kB/s]"
          }
        },
        "a69528d258384126bd9c3cbec914fdf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "274a9f52ca444217ad4379bdfdfb1a97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27fc02adf68c450fa172ebd2ee916740": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec564c5b86104bc79ff1fdfe99e03d2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecc9eb27efc4485fb9d84fa24769ed02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "65f13d5a86d2477e9c5e9b3aa0b34e23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "884c1ca35e164ba5a4e67fa8ebcda63b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62b3fbe25259427e9b674341dcdd80bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2b2f55792224161a6738eb145010acc",
              "IPY_MODEL_c552bebb00cc436f9d9278955d030293",
              "IPY_MODEL_a2a617f4fc7b44e3840a925beecda7a6"
            ],
            "layout": "IPY_MODEL_ad00167ee8594ab98799b1865b216cc9"
          }
        },
        "b2b2f55792224161a6738eb145010acc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_265d98f0242948329451992c679864b5",
            "placeholder": "​",
            "style": "IPY_MODEL_058b1b45489b4a85a45a6f319a8a7a84",
            "value": "FinancialPhraseBank-v1.0.zip: 100%"
          }
        },
        "c552bebb00cc436f9d9278955d030293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04ec2d2c4ac74de1acdb7431c80b44c4",
            "max": 681890,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_98c7049693644a73be336f38cd2f49d5",
            "value": 681890
          }
        },
        "a2a617f4fc7b44e3840a925beecda7a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee88361a171d4ae38677013b92e2c6a3",
            "placeholder": "​",
            "style": "IPY_MODEL_2f86dd6ad16d41ac817e9f4b0f70e3fe",
            "value": " 682k/682k [00:00&lt;00:00, 28.0MB/s]"
          }
        },
        "ad00167ee8594ab98799b1865b216cc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "265d98f0242948329451992c679864b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "058b1b45489b4a85a45a6f319a8a7a84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04ec2d2c4ac74de1acdb7431c80b44c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98c7049693644a73be336f38cd2f49d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee88361a171d4ae38677013b92e2c6a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f86dd6ad16d41ac817e9f4b0f70e3fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf962cd2832c4275ab9e70e26d8c3b84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1bca41cf53be44ad959c43396c3fef27",
              "IPY_MODEL_03cf4f590ed1429585c6c2f811d200d9",
              "IPY_MODEL_389725306482434d809a23e4213bc8f8"
            ],
            "layout": "IPY_MODEL_c27ebb7aaa1e4c228d19ca56ec2c19e4"
          }
        },
        "1bca41cf53be44ad959c43396c3fef27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1769cc70a8b54a57a1dccc0769ea3a44",
            "placeholder": "​",
            "style": "IPY_MODEL_58bb73b9b5dd4a6e87e3c3e34028ac9d",
            "value": "Generating train split: 100%"
          }
        },
        "03cf4f590ed1429585c6c2f811d200d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42232a169fd54cd5b5a7ef83314f30fd",
            "max": 4846,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_217983543e6b4f47a1096eeb931c14db",
            "value": 4846
          }
        },
        "389725306482434d809a23e4213bc8f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae60d05e58ff451aa827f3404deb994e",
            "placeholder": "​",
            "style": "IPY_MODEL_5dc51965848e4a95b41c46f81cdd9b05",
            "value": " 4846/4846 [00:00&lt;00:00, 30454.83 examples/s]"
          }
        },
        "c27ebb7aaa1e4c228d19ca56ec2c19e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1769cc70a8b54a57a1dccc0769ea3a44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58bb73b9b5dd4a6e87e3c3e34028ac9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42232a169fd54cd5b5a7ef83314f30fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "217983543e6b4f47a1096eeb931c14db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae60d05e58ff451aa827f3404deb994e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dc51965848e4a95b41c46f81cdd9b05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c63b143d48c04736bddec5d4692d183b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_af0a1e42cd2b468ab52ac1616e2884dc",
              "IPY_MODEL_b584dc8c36af40918c805f18550c4875",
              "IPY_MODEL_173dd2ddf3d54579b9022035911f22ca"
            ],
            "layout": "IPY_MODEL_0ec5234cb16f47fbb61d465f6611e765"
          }
        },
        "af0a1e42cd2b468ab52ac1616e2884dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ff323a4c3114eb694260f9cb4860cfb",
            "placeholder": "​",
            "style": "IPY_MODEL_331cd4c22798444488d66f7301ed4326",
            "value": "Map: 100%"
          }
        },
        "b584dc8c36af40918c805f18550c4875": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e2563da59fb42a6bbf0f8e564c7352c",
            "max": 3488,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a9378634621c4d41b857c3d655800e37",
            "value": 3488
          }
        },
        "173dd2ddf3d54579b9022035911f22ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fac7def1d71488cbad4ce368025ce3d",
            "placeholder": "​",
            "style": "IPY_MODEL_a99e1eec140b406dadbb1729c9ddeb38",
            "value": " 3488/3488 [00:00&lt;00:00, 10250.78 examples/s]"
          }
        },
        "0ec5234cb16f47fbb61d465f6611e765": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ff323a4c3114eb694260f9cb4860cfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "331cd4c22798444488d66f7301ed4326": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e2563da59fb42a6bbf0f8e564c7352c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9378634621c4d41b857c3d655800e37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8fac7def1d71488cbad4ce368025ce3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a99e1eec140b406dadbb1729c9ddeb38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d85b0cc11484bcda21566076a60fa29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_278b189d17a94d4c8716baef51231c87",
              "IPY_MODEL_f9236505fbe44772a54f09e513214078",
              "IPY_MODEL_32c5677db4dd40188a33758612ff0a8c"
            ],
            "layout": "IPY_MODEL_ced1bb07e627446e9d5252dd92a8663b"
          }
        },
        "278b189d17a94d4c8716baef51231c87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_575e915229e646b6a35b5d00264be8b3",
            "placeholder": "​",
            "style": "IPY_MODEL_fdbc28683ee6412db019ad2c5038dc81",
            "value": "Map: 100%"
          }
        },
        "f9236505fbe44772a54f09e513214078": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_310256286b164c9b9c1bfffd903c5b80",
            "max": 388,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a64840cdccd049af8369d207e763c509",
            "value": 388
          }
        },
        "32c5677db4dd40188a33758612ff0a8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e132e29eeb2944a6a4d42f741934c625",
            "placeholder": "​",
            "style": "IPY_MODEL_d99acc8c08154dc283fbb1870b54b932",
            "value": " 388/388 [00:00&lt;00:00, 7172.37 examples/s]"
          }
        },
        "ced1bb07e627446e9d5252dd92a8663b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "575e915229e646b6a35b5d00264be8b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdbc28683ee6412db019ad2c5038dc81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "310256286b164c9b9c1bfffd903c5b80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a64840cdccd049af8369d207e763c509": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e132e29eeb2944a6a4d42f741934c625": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d99acc8c08154dc283fbb1870b54b932": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01d53c5f9598484abcab0a7dd80ffb01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d6aaa788f8f418ba11df208451f523d",
              "IPY_MODEL_a246421c572b43888dd14eef599b1848",
              "IPY_MODEL_f9ec5142a0894d628f6b0f26956b135c"
            ],
            "layout": "IPY_MODEL_82aa938087b94aa8831197ed5da1d360"
          }
        },
        "8d6aaa788f8f418ba11df208451f523d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4880d7d55ee54702b1c506bc9536500b",
            "placeholder": "​",
            "style": "IPY_MODEL_bbdc303c78824e969cdf91e7ab84837c",
            "value": "Map: 100%"
          }
        },
        "a246421c572b43888dd14eef599b1848": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d88bcedeedd8498cb7dd20a8e20eda6d",
            "max": 970,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_679dbae97378472182c801bccc9457eb",
            "value": 970
          }
        },
        "f9ec5142a0894d628f6b0f26956b135c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52d8f1ccfa7e45b2b1e7ab8988de53d7",
            "placeholder": "​",
            "style": "IPY_MODEL_6550b6603f954c69900ed76f3943518f",
            "value": " 970/970 [00:00&lt;00:00, 9511.20 examples/s]"
          }
        },
        "82aa938087b94aa8831197ed5da1d360": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4880d7d55ee54702b1c506bc9536500b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbdc303c78824e969cdf91e7ab84837c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d88bcedeedd8498cb7dd20a8e20eda6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "679dbae97378472182c801bccc9457eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "52d8f1ccfa7e45b2b1e7ab8988de53d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6550b6603f954c69900ed76f3943518f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20f5d028c0474a0ba2e98e25860a1205": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb9272a925454d6c9036b0f3d4353377",
              "IPY_MODEL_b70ab834986b41038fba0ef72162ee7f",
              "IPY_MODEL_89e92096d1c14a7e94beaa1495f67fb1"
            ],
            "layout": "IPY_MODEL_2cd80a9c588a41c787485c9b50d1ee9b"
          }
        },
        "fb9272a925454d6c9036b0f3d4353377": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_999600f2818945baa68c0848207ba7bc",
            "placeholder": "​",
            "style": "IPY_MODEL_c9edfce94baa40c5860b3847b563973a",
            "value": "config.json: 100%"
          }
        },
        "b70ab834986b41038fba0ef72162ee7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49b290f52aeb44c686d9ccbbd82760c7",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4fb75c2b5e1645e28192942e7c79b221",
            "value": 481
          }
        },
        "89e92096d1c14a7e94beaa1495f67fb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a3bd7c145574917a529f93350b88ba5",
            "placeholder": "​",
            "style": "IPY_MODEL_f07b4f9816ba465d9831442b525f8b06",
            "value": " 481/481 [00:00&lt;00:00, 39.6kB/s]"
          }
        },
        "2cd80a9c588a41c787485c9b50d1ee9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "999600f2818945baa68c0848207ba7bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9edfce94baa40c5860b3847b563973a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49b290f52aeb44c686d9ccbbd82760c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fb75c2b5e1645e28192942e7c79b221": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a3bd7c145574917a529f93350b88ba5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f07b4f9816ba465d9831442b525f8b06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81b25174d3644dcfac081f38af483cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_45231c986ad54f8eac9e8228c37a9776",
              "IPY_MODEL_f80c54e62e534506ae549e8c19cc3701",
              "IPY_MODEL_acfb661688eb4efab919ac27e32f0169"
            ],
            "layout": "IPY_MODEL_80d130db141b4eb8984cec34bd77e8c5"
          }
        },
        "45231c986ad54f8eac9e8228c37a9776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b26eef2f5c647aab835415befde3a1f",
            "placeholder": "​",
            "style": "IPY_MODEL_040ba087a9604a8494d1cd16596ddfe0",
            "value": "model.safetensors: 100%"
          }
        },
        "f80c54e62e534506ae549e8c19cc3701": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc2dabcb3b2646c0b96a9ac1b173d172",
            "max": 498818054,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be182ae473034bf491987e53eac901ab",
            "value": 498818054
          }
        },
        "acfb661688eb4efab919ac27e32f0169": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05f16056c7f14e1abeae593038b0b47f",
            "placeholder": "​",
            "style": "IPY_MODEL_591d341703684ddd9e066399e4792631",
            "value": " 499M/499M [00:02&lt;00:00, 214MB/s]"
          }
        },
        "80d130db141b4eb8984cec34bd77e8c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b26eef2f5c647aab835415befde3a1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "040ba087a9604a8494d1cd16596ddfe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc2dabcb3b2646c0b96a9ac1b173d172": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be182ae473034bf491987e53eac901ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "05f16056c7f14e1abeae593038b0b47f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "591d341703684ddd9e066399e4792631": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "022576b7c25f4b5a84fea8074889484e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dde60a783f9041099d4fbf482e0e01fb",
              "IPY_MODEL_85ca7b3567bc48b88b0a532ed5515ed0",
              "IPY_MODEL_69a30cf114f946a48ed22ab4641fce2a"
            ],
            "layout": "IPY_MODEL_cc9fb406f44d4d2aa7f99ce38a786666"
          }
        },
        "dde60a783f9041099d4fbf482e0e01fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a7a8a907ad44651897541d18369e4ba",
            "placeholder": "​",
            "style": "IPY_MODEL_36ea293eb9f648deb45ef977f4cb7f4c",
            "value": "config.json: 100%"
          }
        },
        "85ca7b3567bc48b88b0a532ed5515ed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b16be197f1240c38ae8ed0d161b64b6",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_756edbc5bd7249c3af4886b37de8ad51",
            "value": 483
          }
        },
        "69a30cf114f946a48ed22ab4641fce2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d71dbc2a17e94cec9bf62ac655edd997",
            "placeholder": "​",
            "style": "IPY_MODEL_c30c05619ce8415fb9986e78fcda886c",
            "value": " 483/483 [00:00&lt;00:00, 41.5kB/s]"
          }
        },
        "cc9fb406f44d4d2aa7f99ce38a786666": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a7a8a907ad44651897541d18369e4ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36ea293eb9f648deb45ef977f4cb7f4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b16be197f1240c38ae8ed0d161b64b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "756edbc5bd7249c3af4886b37de8ad51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d71dbc2a17e94cec9bf62ac655edd997": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c30c05619ce8415fb9986e78fcda886c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "234bb7d87c0c4b73bf404a6a6dfa4765": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ea25629432643dca574a27c2df44a90",
              "IPY_MODEL_b8233f50a2af422aae48fae3c3690694",
              "IPY_MODEL_9be476d492f74863b04b80f8ea5e0116"
            ],
            "layout": "IPY_MODEL_5e510af2a5364f7e80c9e871ab594123"
          }
        },
        "8ea25629432643dca574a27c2df44a90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fb6133eafa74502a37fd94cbb680791",
            "placeholder": "​",
            "style": "IPY_MODEL_f55e1c1e69d64f72bb26de4c5bb882cf",
            "value": "model.safetensors: 100%"
          }
        },
        "b8233f50a2af422aae48fae3c3690694": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17867e8ec4f444fab52efd318a8c6c7c",
            "max": 267954768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f96e9c42190345cb92fbea40570c3c60",
            "value": 267954768
          }
        },
        "9be476d492f74863b04b80f8ea5e0116": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_788eaa03a52348c1af36d3c4b93e2b97",
            "placeholder": "​",
            "style": "IPY_MODEL_9ef9949f227a444d8898d500e8c063fd",
            "value": " 268M/268M [00:01&lt;00:00, 213MB/s]"
          }
        },
        "5e510af2a5364f7e80c9e871ab594123": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fb6133eafa74502a37fd94cbb680791": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f55e1c1e69d64f72bb26de4c5bb882cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17867e8ec4f444fab52efd318a8c6c7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f96e9c42190345cb92fbea40570c3c60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "788eaa03a52348c1af36d3c4b93e2b97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ef9949f227a444d8898d500e8c063fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "294c99943cab4105bc8a5ade3389d09c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66a116dee8d44d178eb4358d6f9333cf",
              "IPY_MODEL_103662d5926849e9928d41f69229c04d",
              "IPY_MODEL_99ebd88c07264ffead77a8f50e61146d"
            ],
            "layout": "IPY_MODEL_865ef4d76507474eb339acda1e55b887"
          }
        },
        "66a116dee8d44d178eb4358d6f9333cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64b889fd48c5413e95a310c3512f57e2",
            "placeholder": "​",
            "style": "IPY_MODEL_baee1b71d81a4e99b392a21b25d2fef9",
            "value": "Map: 100%"
          }
        },
        "103662d5926849e9928d41f69229c04d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d985874c44ad4ab49a2ab1f129bd1ed9",
            "max": 3488,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f5d7921c43949b88acd7f3c825baf24",
            "value": 3488
          }
        },
        "99ebd88c07264ffead77a8f50e61146d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abf15fdde69041929a3a7a87f985717e",
            "placeholder": "​",
            "style": "IPY_MODEL_423065e3030348a88d7915722956fa58",
            "value": " 3488/3488 [00:00&lt;00:00, 5104.49 examples/s]"
          }
        },
        "865ef4d76507474eb339acda1e55b887": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64b889fd48c5413e95a310c3512f57e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baee1b71d81a4e99b392a21b25d2fef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d985874c44ad4ab49a2ab1f129bd1ed9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f5d7921c43949b88acd7f3c825baf24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "abf15fdde69041929a3a7a87f985717e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "423065e3030348a88d7915722956fa58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b38bb367b5e431d8a6940eca9c6acc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d4ca7b2650f456aa0ffadbc9ad003dc",
              "IPY_MODEL_6b5f145a4e8044b883d49d160b870a3b",
              "IPY_MODEL_e7a70e69173d4e59b295686b118792b7"
            ],
            "layout": "IPY_MODEL_95c9323911954e5e991ccd8100776b67"
          }
        },
        "0d4ca7b2650f456aa0ffadbc9ad003dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ad55f7095af4aa8883b4dac12ebbf5a",
            "placeholder": "​",
            "style": "IPY_MODEL_59ae9eeb9b6049669c4c1283d2685587",
            "value": "Map: 100%"
          }
        },
        "6b5f145a4e8044b883d49d160b870a3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ea8b9abeeb841519a902e9340be8204",
            "max": 388,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61a55d4bfdf8478fa6231ceb4b8a0a9f",
            "value": 388
          }
        },
        "e7a70e69173d4e59b295686b118792b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b020010c15c1497e8efa22228f664462",
            "placeholder": "​",
            "style": "IPY_MODEL_a2e8b0cb0b794f0fa287a43cc9499693",
            "value": " 388/388 [00:00&lt;00:00, 7519.21 examples/s]"
          }
        },
        "95c9323911954e5e991ccd8100776b67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ad55f7095af4aa8883b4dac12ebbf5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59ae9eeb9b6049669c4c1283d2685587": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ea8b9abeeb841519a902e9340be8204": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61a55d4bfdf8478fa6231ceb4b8a0a9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b020010c15c1497e8efa22228f664462": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2e8b0cb0b794f0fa287a43cc9499693": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d57268467ef84fa29faecf1e0c5d0bc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c803c231c9ae42879e8c38f1e10f1e02",
              "IPY_MODEL_d47e28a16f4f4934b5043d2da49cd131",
              "IPY_MODEL_47eb3a97ceee4dcdb30c90f9b36e2b93"
            ],
            "layout": "IPY_MODEL_25c78e76003f4ea0909117ed4328f7fb"
          }
        },
        "c803c231c9ae42879e8c38f1e10f1e02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdff912ba66d496db14eabbb454839d0",
            "placeholder": "​",
            "style": "IPY_MODEL_c323c880909b4db1bd748634f0be8b4e",
            "value": "Map: 100%"
          }
        },
        "d47e28a16f4f4934b5043d2da49cd131": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a5d0d786b4545b1995c367f36d5c556",
            "max": 970,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed967468b2314992ab6da4383e9d4e5a",
            "value": 970
          }
        },
        "47eb3a97ceee4dcdb30c90f9b36e2b93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec36fb810f2045f7b2d1ded34b00b33b",
            "placeholder": "​",
            "style": "IPY_MODEL_9f222d2ae8ea42728e20c41b73f04fe2",
            "value": " 970/970 [00:00&lt;00:00, 9750.97 examples/s]"
          }
        },
        "25c78e76003f4ea0909117ed4328f7fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdff912ba66d496db14eabbb454839d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c323c880909b4db1bd748634f0be8b4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a5d0d786b4545b1995c367f36d5c556": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed967468b2314992ab6da4383e9d4e5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec36fb810f2045f7b2d1ded34b00b33b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f222d2ae8ea42728e20c41b73f04fe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ea94f93be2c47c3b327efeac6d63f46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d251ef5062a04bb7be5bd692eec06537",
              "IPY_MODEL_a50add41e3ba46c28422c841d84bc17f",
              "IPY_MODEL_ae391878469d4cbca62735a3c9e3593a"
            ],
            "layout": "IPY_MODEL_847a54bfba374d378db4f1433735b33a"
          }
        },
        "d251ef5062a04bb7be5bd692eec06537": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5493798603a84237ac575217159ee510",
            "placeholder": "​",
            "style": "IPY_MODEL_dce04ac9f4ef4d4fbbea6626de54d595",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "a50add41e3ba46c28422c841d84bc17f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a620dc94421942c181ba2787e9b2116f",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_045ad72477f94e818248f2213a0b9af0",
            "value": 48
          }
        },
        "ae391878469d4cbca62735a3c9e3593a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ffaf54a38c745f5b458d84faf0a7d19",
            "placeholder": "​",
            "style": "IPY_MODEL_3265b21e3ee24d3c8f3bb72722457805",
            "value": " 48.0/48.0 [00:00&lt;00:00, 2.84kB/s]"
          }
        },
        "847a54bfba374d378db4f1433735b33a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5493798603a84237ac575217159ee510": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dce04ac9f4ef4d4fbbea6626de54d595": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a620dc94421942c181ba2787e9b2116f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "045ad72477f94e818248f2213a0b9af0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ffaf54a38c745f5b458d84faf0a7d19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3265b21e3ee24d3c8f3bb72722457805": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0cf46776d9fa45fd90eab28abed5dba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_71adfc022bad4e518159bb16dc7f37a9",
              "IPY_MODEL_6d5718ce15294efe9ac0f8202712fc67",
              "IPY_MODEL_697467891e3c42d8b9f5a8b344d087c7"
            ],
            "layout": "IPY_MODEL_f65fa75d374c444fa711f80a60781d74"
          }
        },
        "71adfc022bad4e518159bb16dc7f37a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c9dd3edc0204093b93865e1c953403d",
            "placeholder": "​",
            "style": "IPY_MODEL_76a9bff016264784b57adf0ef30645d3",
            "value": "config.json: 100%"
          }
        },
        "6d5718ce15294efe9ac0f8202712fc67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_321b024a316a4704b766a5c32d68c331",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8210acd437c4ceaae1b0955991e462e",
            "value": 570
          }
        },
        "697467891e3c42d8b9f5a8b344d087c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f4ec26e966841a68dcfd89872b8cc14",
            "placeholder": "​",
            "style": "IPY_MODEL_9eb380d1a6d349679723d30f27624423",
            "value": " 570/570 [00:00&lt;00:00, 38.3kB/s]"
          }
        },
        "f65fa75d374c444fa711f80a60781d74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c9dd3edc0204093b93865e1c953403d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76a9bff016264784b57adf0ef30645d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "321b024a316a4704b766a5c32d68c331": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8210acd437c4ceaae1b0955991e462e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f4ec26e966841a68dcfd89872b8cc14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9eb380d1a6d349679723d30f27624423": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35e79b41cf0b40a881c1d57be34187db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d54c19c940a04f4eaeeda807e666ddf8",
              "IPY_MODEL_33f9af79073f44259c6047009f38dad9",
              "IPY_MODEL_b32a4e3f46c040fda479fe8529f7cdb7"
            ],
            "layout": "IPY_MODEL_4631fa655457411eb7a0079d4e11b8a8"
          }
        },
        "d54c19c940a04f4eaeeda807e666ddf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c606831e2302431bac132233c793384d",
            "placeholder": "​",
            "style": "IPY_MODEL_24ac7df9555a43ceb7f6260beab0e53e",
            "value": "vocab.txt: 100%"
          }
        },
        "33f9af79073f44259c6047009f38dad9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b01a7222d9944c2b96a6259bb212323a",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe7fa85e337143829833404cd8ea7f3d",
            "value": 231508
          }
        },
        "b32a4e3f46c040fda479fe8529f7cdb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69f82d11fa2e42ceb68769b70c261b23",
            "placeholder": "​",
            "style": "IPY_MODEL_d852ad7b01364d418ae320eb4cf665b1",
            "value": " 232k/232k [00:00&lt;00:00, 1.09MB/s]"
          }
        },
        "4631fa655457411eb7a0079d4e11b8a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c606831e2302431bac132233c793384d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24ac7df9555a43ceb7f6260beab0e53e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b01a7222d9944c2b96a6259bb212323a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe7fa85e337143829833404cd8ea7f3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "69f82d11fa2e42ceb68769b70c261b23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d852ad7b01364d418ae320eb4cf665b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ce2455d893c47ae9d6f9554875395b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eebdced070f24a6da579ba5b68f8e1cc",
              "IPY_MODEL_c221ae700bc24f17864790cd7ae65ca7",
              "IPY_MODEL_e0d264c0dd634a50b34e07d5d07656cc"
            ],
            "layout": "IPY_MODEL_93d3a53f1b1c425189357b10471ce9b5"
          }
        },
        "eebdced070f24a6da579ba5b68f8e1cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2a367f85f424a91a2e5439d5b5f30fb",
            "placeholder": "​",
            "style": "IPY_MODEL_f6483b02c1ef40e0be4d293255fda36c",
            "value": "tokenizer.json: 100%"
          }
        },
        "c221ae700bc24f17864790cd7ae65ca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b29616046914588b60e5ef2261cc57c",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5ff000441834eb7b8f93ad5ad20c053",
            "value": 466062
          }
        },
        "e0d264c0dd634a50b34e07d5d07656cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4562b6000e5043cc9bd73d17dea84bfb",
            "placeholder": "​",
            "style": "IPY_MODEL_f07f664ba51d454788761647e7e74dc2",
            "value": " 466k/466k [00:00&lt;00:00, 1.08MB/s]"
          }
        },
        "93d3a53f1b1c425189357b10471ce9b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2a367f85f424a91a2e5439d5b5f30fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6483b02c1ef40e0be4d293255fda36c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b29616046914588b60e5ef2261cc57c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5ff000441834eb7b8f93ad5ad20c053": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4562b6000e5043cc9bd73d17dea84bfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f07f664ba51d454788761647e7e74dc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d870f134ac244d29cc41ca0174a4151": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6478ff659674af7b09dc6f11aee55fa",
              "IPY_MODEL_fd6d62285dcd4412b00904ac833547ef",
              "IPY_MODEL_82b5ea39072a4650a3bf3f3789f78804"
            ],
            "layout": "IPY_MODEL_50575a756d3349748630a52089d471ed"
          }
        },
        "c6478ff659674af7b09dc6f11aee55fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9446adb28394b979e56dc5a670ad1c5",
            "placeholder": "​",
            "style": "IPY_MODEL_9d829383f23f4418afecdbef6274defc",
            "value": "README.md: 100%"
          }
        },
        "fd6d62285dcd4412b00904ac833547ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cef517f1cae74f5d886ac7a732c8df11",
            "max": 8878,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2b4c65e7a63481a9ae7cca6cb29f5da",
            "value": 8878
          }
        },
        "82b5ea39072a4650a3bf3f3789f78804": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a6bffeda969445a9d83b8fe5d316814",
            "placeholder": "​",
            "style": "IPY_MODEL_d48161278bc1401da52510783636fca4",
            "value": " 8.88k/8.88k [00:00&lt;00:00, 700kB/s]"
          }
        },
        "50575a756d3349748630a52089d471ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9446adb28394b979e56dc5a670ad1c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d829383f23f4418afecdbef6274defc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cef517f1cae74f5d886ac7a732c8df11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2b4c65e7a63481a9ae7cca6cb29f5da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a6bffeda969445a9d83b8fe5d316814": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d48161278bc1401da52510783636fca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef7650a97873452f91d39890435a98ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c66e2d9eaf814eeba86570f63c7af27c",
              "IPY_MODEL_7088b7797d5a4a89b064260d168b6613",
              "IPY_MODEL_8cbfd630ab7a45d2b6b022ac11809cde"
            ],
            "layout": "IPY_MODEL_7af6e332f6bc4c6ea77650da1e7b1e64"
          }
        },
        "c66e2d9eaf814eeba86570f63c7af27c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_182ac60eac024a98975ccec3a757c881",
            "placeholder": "​",
            "style": "IPY_MODEL_e41ea1032ad441439ba408988a28b1c1",
            "value": "financial_phrasebank.py: 100%"
          }
        },
        "7088b7797d5a4a89b064260d168b6613": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28a58a777917448c8fffbea11f3cce13",
            "max": 6036,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b746737162d4667979f59078922c133",
            "value": 6036
          }
        },
        "8cbfd630ab7a45d2b6b022ac11809cde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38eca8f68883437aac3709eb102b2985",
            "placeholder": "​",
            "style": "IPY_MODEL_7c478921dd8648929223f3114a4148a4",
            "value": " 6.04k/6.04k [00:00&lt;00:00, 531kB/s]"
          }
        },
        "7af6e332f6bc4c6ea77650da1e7b1e64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "182ac60eac024a98975ccec3a757c881": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e41ea1032ad441439ba408988a28b1c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28a58a777917448c8fffbea11f3cce13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b746737162d4667979f59078922c133": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "38eca8f68883437aac3709eb102b2985": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c478921dd8648929223f3114a4148a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1cdc185ddb7a465da56816ae45f1cf7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c53be57a31004ecb9a85844f6d830e7d",
              "IPY_MODEL_18962701146e48969d85fb2e527d9e3b",
              "IPY_MODEL_79441464bf644c9587859709ba7b0e4c"
            ],
            "layout": "IPY_MODEL_441bf149b2d441ce8f29b1f0c326a260"
          }
        },
        "c53be57a31004ecb9a85844f6d830e7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00b4010ef7454da897ac9817ef82995d",
            "placeholder": "​",
            "style": "IPY_MODEL_a7d03e3ea02447c89f317eca0bf95410",
            "value": "FinancialPhraseBank-v1.0.zip: 100%"
          }
        },
        "18962701146e48969d85fb2e527d9e3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c42e9c3b17d34b638051819e1be9d1f6",
            "max": 681890,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0dfc9209147a4a73a25d7e631a164670",
            "value": 681890
          }
        },
        "79441464bf644c9587859709ba7b0e4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf9ebf70c7e8481a9905cec9e9b96cbd",
            "placeholder": "​",
            "style": "IPY_MODEL_b03884a9939c4216a298b4667e842362",
            "value": " 682k/682k [00:00&lt;00:00, 19.1MB/s]"
          }
        },
        "441bf149b2d441ce8f29b1f0c326a260": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00b4010ef7454da897ac9817ef82995d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7d03e3ea02447c89f317eca0bf95410": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c42e9c3b17d34b638051819e1be9d1f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dfc9209147a4a73a25d7e631a164670": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf9ebf70c7e8481a9905cec9e9b96cbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b03884a9939c4216a298b4667e842362": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9cbb25d7b591417ea41587c8e5abcf6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8054768334544ae88bedab1fd845f81",
              "IPY_MODEL_208912e528784fc290069c8825f63689",
              "IPY_MODEL_be6f733b4b454462a94a16721b23375c"
            ],
            "layout": "IPY_MODEL_2799434cdeca4deea94ba55d90cb0c02"
          }
        },
        "a8054768334544ae88bedab1fd845f81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d0e7e567c69492db343e871f79e209e",
            "placeholder": "​",
            "style": "IPY_MODEL_8c05cffe4b71446c9f5da76cbe26e9c0",
            "value": "Generating train split: 100%"
          }
        },
        "208912e528784fc290069c8825f63689": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb3337a6fb6d4faaa27086cff730f25a",
            "max": 4846,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f388c6f42b974a17b3b71d62640bc07c",
            "value": 4846
          }
        },
        "be6f733b4b454462a94a16721b23375c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2aa7c80e422f4b0489f8182c1e8fb174",
            "placeholder": "​",
            "style": "IPY_MODEL_940b5c639e0340b1a22f8f2c415c6521",
            "value": " 4846/4846 [00:00&lt;00:00, 31264.43 examples/s]"
          }
        },
        "2799434cdeca4deea94ba55d90cb0c02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d0e7e567c69492db343e871f79e209e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c05cffe4b71446c9f5da76cbe26e9c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb3337a6fb6d4faaa27086cff730f25a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f388c6f42b974a17b3b71d62640bc07c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2aa7c80e422f4b0489f8182c1e8fb174": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "940b5c639e0340b1a22f8f2c415c6521": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8303c0f9983a4dc8824b13c5fd848a47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb9e2147edba4440b317ae5ef367633e",
              "IPY_MODEL_e1a71e2ebfb84795a312ce69ec7952c1",
              "IPY_MODEL_f6995bf8da5143a9b910e8e7ab5802d1"
            ],
            "layout": "IPY_MODEL_d76087cf48c84132a217d6b9c49f81f4"
          }
        },
        "bb9e2147edba4440b317ae5ef367633e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a033f75cb1f4c3ca68e4b42f81e7e46",
            "placeholder": "​",
            "style": "IPY_MODEL_96e71d0f93a84271a70d9d1fbefb93dd",
            "value": "Map: 100%"
          }
        },
        "e1a71e2ebfb84795a312ce69ec7952c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c09e80640b764822aa2c7619b5b51ff5",
            "max": 3488,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0cfb6b4b7de64b69a057de732f570da0",
            "value": 3488
          }
        },
        "f6995bf8da5143a9b910e8e7ab5802d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_802962e0bb9c45eaa01ab45ca8a44e4b",
            "placeholder": "​",
            "style": "IPY_MODEL_129b3bff1fe4476c8cd1c60658eb5db2",
            "value": " 3488/3488 [00:00&lt;00:00, 10381.64 examples/s]"
          }
        },
        "d76087cf48c84132a217d6b9c49f81f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a033f75cb1f4c3ca68e4b42f81e7e46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96e71d0f93a84271a70d9d1fbefb93dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c09e80640b764822aa2c7619b5b51ff5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cfb6b4b7de64b69a057de732f570da0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "802962e0bb9c45eaa01ab45ca8a44e4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "129b3bff1fe4476c8cd1c60658eb5db2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54d90c60be5b444090640bb64f92e1b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_918ff5ed1e154bd0a1dfae717202cb1f",
              "IPY_MODEL_a44dd9186dc64df5bc5c733e768de16e",
              "IPY_MODEL_14d34f9037cf4752af7a4d15e58dc3e2"
            ],
            "layout": "IPY_MODEL_7e64d77b302147d189f7734444b8f528"
          }
        },
        "918ff5ed1e154bd0a1dfae717202cb1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7973da519d244ebe8b454db0e83cc782",
            "placeholder": "​",
            "style": "IPY_MODEL_7035433411134808add473ceaf3e9042",
            "value": "Map: 100%"
          }
        },
        "a44dd9186dc64df5bc5c733e768de16e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2e7113e410a44769be9fa3525acbb6f",
            "max": 388,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc15d8e664a0466ebb999a041363799c",
            "value": 388
          }
        },
        "14d34f9037cf4752af7a4d15e58dc3e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b056c63972b4147b6970d532a118ee4",
            "placeholder": "​",
            "style": "IPY_MODEL_0fe4340bab814c59ba546bfd88629b78",
            "value": " 388/388 [00:00&lt;00:00, 7321.09 examples/s]"
          }
        },
        "7e64d77b302147d189f7734444b8f528": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7973da519d244ebe8b454db0e83cc782": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7035433411134808add473ceaf3e9042": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2e7113e410a44769be9fa3525acbb6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc15d8e664a0466ebb999a041363799c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b056c63972b4147b6970d532a118ee4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fe4340bab814c59ba546bfd88629b78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30fc8368fe114f3d926b8b678ea83134": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4a79859b5d1463593af1be3136ea600",
              "IPY_MODEL_292e5d84fbc743de974a7e23b69c1924",
              "IPY_MODEL_c25718c6a56643e1a68974e739b86d79"
            ],
            "layout": "IPY_MODEL_dc91cf645ad745b68bfc0ec20f1eaf34"
          }
        },
        "f4a79859b5d1463593af1be3136ea600": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01e415e354084d8a911f83fcee186fbb",
            "placeholder": "​",
            "style": "IPY_MODEL_2c1c4c0699a24bfe8b772f7102714d98",
            "value": "Map: 100%"
          }
        },
        "292e5d84fbc743de974a7e23b69c1924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_375d1ed18766409f8c5d6068b009fac8",
            "max": 970,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4967fdc80dcf437494fa0398475c8c75",
            "value": 970
          }
        },
        "c25718c6a56643e1a68974e739b86d79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a92578d806174717b1c6c72751ff70a3",
            "placeholder": "​",
            "style": "IPY_MODEL_b6ffced1184c4ac9bc6fbff42fe764b0",
            "value": " 970/970 [00:00&lt;00:00, 9729.89 examples/s]"
          }
        },
        "dc91cf645ad745b68bfc0ec20f1eaf34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01e415e354084d8a911f83fcee186fbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c1c4c0699a24bfe8b772f7102714d98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "375d1ed18766409f8c5d6068b009fac8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4967fdc80dcf437494fa0398475c8c75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a92578d806174717b1c6c72751ff70a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6ffced1184c4ac9bc6fbff42fe764b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60d3a594358b466db95388d2f4a8dff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1aee4f3317414e299f7fa16840084eb0",
              "IPY_MODEL_ff52808c6f604e24ae3bf22b4a0ac1a1",
              "IPY_MODEL_a2dfccc8aed7479a8e1528604c6a3928"
            ],
            "layout": "IPY_MODEL_8d653f5fe9694dad8d944183c85ed049"
          }
        },
        "1aee4f3317414e299f7fa16840084eb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db89d8754d784f70a2d8b07032c78059",
            "placeholder": "​",
            "style": "IPY_MODEL_da2eec3efa734ce0963894f12ac19cd3",
            "value": "config.json: 100%"
          }
        },
        "ff52808c6f604e24ae3bf22b4a0ac1a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_649dfb9e88a245a78f69389504d02aa9",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af40086a735b4c92b28e189217ae0924",
            "value": 481
          }
        },
        "a2dfccc8aed7479a8e1528604c6a3928": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf4fae3e0b7f4f368cdf4fa73018b3f5",
            "placeholder": "​",
            "style": "IPY_MODEL_3f3908468d6945c28baf0b3f9513bb83",
            "value": " 481/481 [00:00&lt;00:00, 40.9kB/s]"
          }
        },
        "8d653f5fe9694dad8d944183c85ed049": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db89d8754d784f70a2d8b07032c78059": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da2eec3efa734ce0963894f12ac19cd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "649dfb9e88a245a78f69389504d02aa9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af40086a735b4c92b28e189217ae0924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf4fae3e0b7f4f368cdf4fa73018b3f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f3908468d6945c28baf0b3f9513bb83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8fd87db63084027bb9e9400cb054f2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9bc1b1167b64a7e98950f5b3a58858b",
              "IPY_MODEL_668cb65bce494fb2978fda9944f9b0c5",
              "IPY_MODEL_9f100e4e254f4cc4ac263276e25e5039"
            ],
            "layout": "IPY_MODEL_1c8000d24b5f411dad234c9939cd853f"
          }
        },
        "f9bc1b1167b64a7e98950f5b3a58858b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62627d28a87b4ae8a54363c7f218d993",
            "placeholder": "​",
            "style": "IPY_MODEL_41d2b118411d4e388f5742ccfb6c5d37",
            "value": "model.safetensors: 100%"
          }
        },
        "668cb65bce494fb2978fda9944f9b0c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60b68694694b431c9a3b33419b24a51a",
            "max": 498818054,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51402aefc5ae44f0aaff296522588b3a",
            "value": 498818054
          }
        },
        "9f100e4e254f4cc4ac263276e25e5039": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2fcf238f2a34603935f5f59c86c8de6",
            "placeholder": "​",
            "style": "IPY_MODEL_5a481181d95b4267b108ec097c08665a",
            "value": " 499M/499M [00:02&lt;00:00, 236MB/s]"
          }
        },
        "1c8000d24b5f411dad234c9939cd853f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62627d28a87b4ae8a54363c7f218d993": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41d2b118411d4e388f5742ccfb6c5d37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60b68694694b431c9a3b33419b24a51a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51402aefc5ae44f0aaff296522588b3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2fcf238f2a34603935f5f59c86c8de6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a481181d95b4267b108ec097c08665a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af32c1ca1a9b4ea49cce948190b289db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_01afd12bd01f48acaa83232755262378",
              "IPY_MODEL_30c63fd1711148c9ac1ba71ffcd0a31b",
              "IPY_MODEL_fe779f86209c46d897e957963d427fb8"
            ],
            "layout": "IPY_MODEL_5364f8537d184223898d702633d7366a"
          }
        },
        "01afd12bd01f48acaa83232755262378": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_217c64f050c7420da78849e65dc9adab",
            "placeholder": "​",
            "style": "IPY_MODEL_c8b2668160b34bd5a1f3e39475749d69",
            "value": "config.json: 100%"
          }
        },
        "30c63fd1711148c9ac1ba71ffcd0a31b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf563f4cb3b843039a647111fa384aa7",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab1f469244724fddb4a3e50374647f88",
            "value": 483
          }
        },
        "fe779f86209c46d897e957963d427fb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09c1c7241a434aadace4c74ba51d522f",
            "placeholder": "​",
            "style": "IPY_MODEL_bc859d3841ea48d98663dc2fae197317",
            "value": " 483/483 [00:00&lt;00:00, 45.5kB/s]"
          }
        },
        "5364f8537d184223898d702633d7366a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "217c64f050c7420da78849e65dc9adab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8b2668160b34bd5a1f3e39475749d69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf563f4cb3b843039a647111fa384aa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab1f469244724fddb4a3e50374647f88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09c1c7241a434aadace4c74ba51d522f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc859d3841ea48d98663dc2fae197317": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6621c65327df4f43a61d5342d9b9b5f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75c977beee554d2cbec5ef2feb911ed7",
              "IPY_MODEL_85b848c3139b43ca87a07fac9f6c970c",
              "IPY_MODEL_43a3731694d84095b4c9080ef65a80ef"
            ],
            "layout": "IPY_MODEL_041c5c476e4f40578e4d7bb2b03b46c1"
          }
        },
        "75c977beee554d2cbec5ef2feb911ed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec7b5bf2fb0041a4ab2ac03ac9417cf8",
            "placeholder": "​",
            "style": "IPY_MODEL_c77d14a9d6b64389834039a2e9315bb7",
            "value": "model.safetensors: 100%"
          }
        },
        "85b848c3139b43ca87a07fac9f6c970c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f212c7f48083499b8538629a10329b28",
            "max": 267954768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4fcad4750734436b99bfc4aed4ce63d2",
            "value": 267954768
          }
        },
        "43a3731694d84095b4c9080ef65a80ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c21ffed75e66498a80422599bceefa2c",
            "placeholder": "​",
            "style": "IPY_MODEL_d0ca6d3cf8ce437f88db40c144cf98af",
            "value": " 268M/268M [00:01&lt;00:00, 239MB/s]"
          }
        },
        "041c5c476e4f40578e4d7bb2b03b46c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec7b5bf2fb0041a4ab2ac03ac9417cf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c77d14a9d6b64389834039a2e9315bb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f212c7f48083499b8538629a10329b28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fcad4750734436b99bfc4aed4ce63d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c21ffed75e66498a80422599bceefa2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0ca6d3cf8ce437f88db40c144cf98af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e9c1c46e5e047bd8cb684d13886013f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2cdbbd4a3424520a6ebb09bc74c7af2",
              "IPY_MODEL_a5dcc0c182724a3bae001e0deb4a4d7c",
              "IPY_MODEL_29a102965c204875b5bec85f9bba3604"
            ],
            "layout": "IPY_MODEL_421bea71d3b048ecbd9115b834b09b9f"
          }
        },
        "e2cdbbd4a3424520a6ebb09bc74c7af2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ee1fa012c154d05b4a2d345971147ce",
            "placeholder": "​",
            "style": "IPY_MODEL_e5bdbf0c24df4f89b9d7a1f8b6d2a830",
            "value": "Map: 100%"
          }
        },
        "a5dcc0c182724a3bae001e0deb4a4d7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9be71a1bed124b8e89cf80f54b7c6df9",
            "max": 3488,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2102f42f71474f8183d2a6194eb40e8a",
            "value": 3488
          }
        },
        "29a102965c204875b5bec85f9bba3604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8311b90d5dc49f58df4928b364f0c66",
            "placeholder": "​",
            "style": "IPY_MODEL_31931c560c1a4b3ab1aedfaf43f60746",
            "value": " 3488/3488 [00:00&lt;00:00, 10738.94 examples/s]"
          }
        },
        "421bea71d3b048ecbd9115b834b09b9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ee1fa012c154d05b4a2d345971147ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5bdbf0c24df4f89b9d7a1f8b6d2a830": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9be71a1bed124b8e89cf80f54b7c6df9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2102f42f71474f8183d2a6194eb40e8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8311b90d5dc49f58df4928b364f0c66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31931c560c1a4b3ab1aedfaf43f60746": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb385cd3a657465f887eb9636e4d1e61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba2f4e81d9da481fb2cb3296216bc86b",
              "IPY_MODEL_b0896aa404174af2bc3649de7189a8bc",
              "IPY_MODEL_7bdf7505592e47b196e38ac8ac648dbb"
            ],
            "layout": "IPY_MODEL_db551e3a1b324f488482235a1cc1642d"
          }
        },
        "ba2f4e81d9da481fb2cb3296216bc86b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b7065d6f22740a8a8e89bb09a8f89a5",
            "placeholder": "​",
            "style": "IPY_MODEL_5144aa490b864c03aefb4922f2139874",
            "value": "Map: 100%"
          }
        },
        "b0896aa404174af2bc3649de7189a8bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c7415e3372b46a79265cc4ea87abf7c",
            "max": 388,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_54e41e5e061d47cd816d4522e2d41c36",
            "value": 388
          }
        },
        "7bdf7505592e47b196e38ac8ac648dbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89b517e41a1d4d44a87113867d742581",
            "placeholder": "​",
            "style": "IPY_MODEL_de1ccc808f5d49a09cd1a4409e22e98c",
            "value": " 388/388 [00:00&lt;00:00, 7390.11 examples/s]"
          }
        },
        "db551e3a1b324f488482235a1cc1642d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b7065d6f22740a8a8e89bb09a8f89a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5144aa490b864c03aefb4922f2139874": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c7415e3372b46a79265cc4ea87abf7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54e41e5e061d47cd816d4522e2d41c36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89b517e41a1d4d44a87113867d742581": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de1ccc808f5d49a09cd1a4409e22e98c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61b0064a987c4eaaab1de4d2d6b0839f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97ed1e74a10c4f419c721fef78ddfb38",
              "IPY_MODEL_c6a9c659220b424196e6afa62c8f15a9",
              "IPY_MODEL_76e894c5636642ef9749c8ccd6bfe95e"
            ],
            "layout": "IPY_MODEL_9b0eb44785844238aee578d9eee7c05b"
          }
        },
        "97ed1e74a10c4f419c721fef78ddfb38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d1806828cb84eb7b4df71de972ef186",
            "placeholder": "​",
            "style": "IPY_MODEL_ce5da91bb4364a4b978eb17a58483e90",
            "value": "Map: 100%"
          }
        },
        "c6a9c659220b424196e6afa62c8f15a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_616f7eff1f1242e3b9d504596391b1dd",
            "max": 970,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_89108ebaf3e14c618c9bcda81101892a",
            "value": 970
          }
        },
        "76e894c5636642ef9749c8ccd6bfe95e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60705742dd534de99dcaf5dbab7c2268",
            "placeholder": "​",
            "style": "IPY_MODEL_8b14967666e54795bc7f49b8752c36e7",
            "value": " 970/970 [00:00&lt;00:00, 9485.95 examples/s]"
          }
        },
        "9b0eb44785844238aee578d9eee7c05b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d1806828cb84eb7b4df71de972ef186": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce5da91bb4364a4b978eb17a58483e90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "616f7eff1f1242e3b9d504596391b1dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89108ebaf3e14c618c9bcda81101892a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "60705742dd534de99dcaf5dbab7c2268": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b14967666e54795bc7f49b8752c36e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}