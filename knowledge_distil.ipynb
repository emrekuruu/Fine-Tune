{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beyzakaya/miniforge3/envs/DLprojectenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(tokenizer, dataset_name=\"financial_phrasebank\", subset_name=\"sentences_50agree\", max_length=128, random_state=42):\n",
    "    dataset = load_dataset(dataset_name, subset_name, trust_remote_code=True)\n",
    "    \n",
    "    df = pd.DataFrame(dataset['train'])\n",
    "\n",
    "    # Stratify split into train, validation, and test\n",
    "    train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "        df['sentence'], df['label'], test_size=0.2, stratify=df['label'], random_state=random_state\n",
    "    )\n",
    "    train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "        train_texts, train_labels, test_size=0.1, stratify=train_labels, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Create DataFrames for each split\n",
    "    train_df = pd.DataFrame({'sentence': train_texts, 'label': train_labels})\n",
    "    val_df = pd.DataFrame({'sentence': val_texts, 'label': val_labels})\n",
    "    test_df = pd.DataFrame({'sentence': test_texts, 'label': test_labels})\n",
    "\n",
    "    # Convert DataFrames to Hugging Face Dataset format\n",
    "    train_dataset = Dataset.from_pandas(train_df)\n",
    "    val_dataset = Dataset.from_pandas(val_df)\n",
    "    test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "    # Define tokenization function\n",
    "    def tokenize_function(example):\n",
    "        return tokenizer(\n",
    "            example[\"sentence\"], \n",
    "            padding=\"max_length\", \n",
    "            truncation=True, \n",
    "            max_length=max_length\n",
    "        )\n",
    "     # Tokenize datasets\n",
    "    train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "    val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "    test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "    # Remove raw text and prepare for Hugging Face Trainer\n",
    "    train_dataset = train_dataset.remove_columns([\"sentence\"])\n",
    "    val_dataset = val_dataset.remove_columns([\"sentence\"])\n",
    "    test_dataset = test_dataset.remove_columns([\"sentence\"])\n",
    "\n",
    "    train_dataset = train_dataset.rename_column(\"label\", \"labels\")\n",
    "    val_dataset = val_dataset.rename_column(\"label\", \"labels\")\n",
    "    test_dataset = test_dataset.rename_column(\"label\", \"labels\")\n",
    "\n",
    "    train_dataset.set_format(\"torch\")\n",
    "    val_dataset.set_format(\"torch\")\n",
    "    test_dataset.set_format(\"torch\")\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Load the tokenizer for BERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Load the Teacher model (BERT)\n",
    "teacher_model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
    "\n",
    "# Load the Student model (DistilBERT)\n",
    "student_model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3488/3488 [00:00<00:00, 24431.47 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 388/388 [00:00<00:00, 22940.69 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 970/970 [00:00<00:00, 22919.05 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset, test_dataset = prepare_datasets(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def distillation_loss(student_logits, teacher_logits, true_labels, temperature=2.0, alpha=0.7):\n",
    "    # Soft labels from teacher model\n",
    "    soft_labels = F.softmax(teacher_logits / temperature, dim=-1)\n",
    "\n",
    "    # Hard loss using true labels\n",
    "    hard_loss = F.cross_entropy(student_logits, true_labels)\n",
    "\n",
    "    # Soft loss between teacher and student logits\n",
    "    soft_loss = F.kl_div(\n",
    "        F.log_softmax(student_logits / temperature, dim=-1),\n",
    "        soft_labels,\n",
    "        reduction='batchmean'\n",
    "    )\n",
    "\n",
    "    # Weighted combination of soft and hard loss\n",
    "    return alpha * soft_loss + (1.0 - alpha) * hard_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def get_teacher_logits(model, dataset, batch_size=16, device='cpu'):\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "    logits = []\n",
    "\n",
    "    model.eval()  # Set teacher model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            inputs = {k: v.to(device) for k, v in batch.items() if k in ['input_ids', 'attention_mask']}\n",
    "            outputs = model(**inputs)\n",
    "            logits.append(outputs.logits.cpu())\n",
    "\n",
    "    return torch.cat(logits, dim=0)  # Concatenate all logits into one tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distillation_train_loop(student_model, teacher_model, train_dataset, val_dataset, tokenizer, epochs=3, batch_size=16, learning_rate=5e-5, device='cpu'):\n",
    "    student_model = student_model.to(device)\n",
    "    teacher_model = teacher_model.to(device)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(student_model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Teacher logits for the entire training dataset\n",
    "    teacher_logits = get_teacher_logits(teacher_model, train_dataset, batch_size=batch_size, device=device)\n",
    "    print(f\"Teacher logits: {teacher_logits}\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        student_model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for i, batch in enumerate(train_dataloader):\n",
    "            inputs = {k: v.to(device) for k, v in batch.items() if k in ['input_ids', 'attention_mask']}\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            # Select corresponding teacher logits for this batch\n",
    "            batch_teacher_logits = teacher_logits[i * batch_size:(i + 1) * batch_size].to(device)\n",
    "\n",
    "            # Forward pass of student model\n",
    "            student_outputs = student_model(**inputs)\n",
    "            print(f\"Student outputs: {student_outputs}\")\n",
    "            student_logits = student_outputs.logits\n",
    "            print(f\"Student logits: {student_logits}\")\n",
    "\n",
    "            # Compute loss\n",
    "            loss = distillation_loss(student_logits, batch_teacher_logits, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_dataloader):.4f}\")\n",
    "\n",
    "    return student_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beyzakaya/miniforge3/envs/DLprojectenv/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/folders/kv/563b5k8n4xg24_t9kd2d72c40000gn/T/ipykernel_56174/2655727639.py:14: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_teacher = Trainer(\n",
      "  2%|â–         | 10/654 [00:22<15:48,  1.47s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8957, 'grad_norm': 4.335817337036133, 'learning_rate': 4.923547400611621e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 20/654 [00:35<11:03,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7797, 'grad_norm': 3.726905584335327, 'learning_rate': 4.847094801223242e-05, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–         | 30/654 [00:55<19:18,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7911, 'grad_norm': 3.6768481731414795, 'learning_rate': 4.7706422018348626e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–Œ         | 40/654 [01:14<20:44,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7659, 'grad_norm': 6.559085845947266, 'learning_rate': 4.694189602446483e-05, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 50/654 [01:34<14:28,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6494, 'grad_norm': 5.637365341186523, 'learning_rate': 4.617737003058104e-05, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|â–‰         | 60/654 [02:01<34:59,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5958, 'grad_norm': 7.2245049476623535, 'learning_rate': 4.541284403669725e-05, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|â–ˆ         | 70/654 [02:44<33:00,  3.39s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5212, 'grad_norm': 9.817317008972168, 'learning_rate': 4.4648318042813456e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|â–ˆâ–        | 80/654 [03:20<37:59,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5809, 'grad_norm': 14.302302360534668, 'learning_rate': 4.3883792048929664e-05, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|â–ˆâ–        | 90/654 [03:51<25:06,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4667, 'grad_norm': 4.403275012969971, 'learning_rate': 4.311926605504588e-05, 'epoch': 0.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–Œ        | 100/654 [04:09<13:33,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4744, 'grad_norm': 2.98917293548584, 'learning_rate': 4.235474006116208e-05, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|â–ˆâ–‹        | 110/654 [04:27<14:55,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4692, 'grad_norm': 13.180750846862793, 'learning_rate': 4.159021406727829e-05, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|â–ˆâ–Š        | 120/654 [04:39<08:44,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.451, 'grad_norm': 4.209173679351807, 'learning_rate': 4.0825688073394495e-05, 'epoch': 0.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–‰        | 130/654 [04:47<07:08,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3658, 'grad_norm': 13.522235870361328, 'learning_rate': 4.00611620795107e-05, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|â–ˆâ–ˆâ–       | 140/654 [04:56<08:09,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4707, 'grad_norm': 6.981060981750488, 'learning_rate': 3.929663608562692e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|â–ˆâ–ˆâ–Ž       | 150/654 [05:05<07:03,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.394, 'grad_norm': 3.078388214111328, 'learning_rate': 3.8532110091743125e-05, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|â–ˆâ–ˆâ–       | 160/654 [05:15<08:03,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4116, 'grad_norm': 11.815357208251953, 'learning_rate': 3.7767584097859326e-05, 'epoch': 0.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|â–ˆâ–ˆâ–Œ       | 170/654 [05:26<07:30,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4293, 'grad_norm': 8.353646278381348, 'learning_rate': 3.7003058103975534e-05, 'epoch': 0.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|â–ˆâ–ˆâ–Š       | 180/654 [05:34<06:24,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4091, 'grad_norm': 3.852647542953491, 'learning_rate': 3.623853211009174e-05, 'epoch': 0.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|â–ˆâ–ˆâ–‰       | 190/654 [05:47<11:29,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3439, 'grad_norm': 8.242115020751953, 'learning_rate': 3.5474006116207956e-05, 'epoch': 0.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|â–ˆâ–ˆâ–ˆ       | 200/654 [05:57<07:18,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4478, 'grad_norm': 11.006133079528809, 'learning_rate': 3.4709480122324164e-05, 'epoch': 0.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|â–ˆâ–ˆâ–ˆâ–      | 210/654 [06:07<07:36,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4146, 'grad_norm': 3.8564493656158447, 'learning_rate': 3.394495412844037e-05, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 218/654 [06:22<06:04,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.39951249957084656, 'eval_runtime': 7.9863, 'eval_samples_per_second': 48.583, 'eval_steps_per_second': 3.13, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 220/654 [06:25<20:41,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4293, 'grad_norm': 5.919196605682373, 'learning_rate': 3.318042813455658e-05, 'epoch': 1.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 230/654 [06:35<06:36,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2745, 'grad_norm': 12.205646514892578, 'learning_rate': 3.241590214067278e-05, 'epoch': 1.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 240/654 [06:44<05:46,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2492, 'grad_norm': 19.635948181152344, 'learning_rate': 3.1651376146788995e-05, 'epoch': 1.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 250/654 [06:52<05:59,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2927, 'grad_norm': 13.9088716506958, 'learning_rate': 3.08868501529052e-05, 'epoch': 1.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–‰      | 260/654 [07:01<05:22,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2574, 'grad_norm': 12.238587379455566, 'learning_rate': 3.012232415902141e-05, 'epoch': 1.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 270/654 [07:09<05:22,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2473, 'grad_norm': 4.494692802429199, 'learning_rate': 2.9357798165137618e-05, 'epoch': 1.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 280/654 [07:18<05:12,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2933, 'grad_norm': 5.556410789489746, 'learning_rate': 2.8593272171253826e-05, 'epoch': 1.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 290/654 [07:26<05:01,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2478, 'grad_norm': 15.016253471374512, 'learning_rate': 2.782874617737003e-05, 'epoch': 1.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 300/654 [07:35<04:48,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2413, 'grad_norm': 10.48573112487793, 'learning_rate': 2.7064220183486238e-05, 'epoch': 1.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 310/654 [07:43<04:30,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2933, 'grad_norm': 8.468277931213379, 'learning_rate': 2.629969418960245e-05, 'epoch': 1.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 320/654 [07:51<04:33,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2082, 'grad_norm': 11.91784954071045, 'learning_rate': 2.5535168195718656e-05, 'epoch': 1.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 330/654 [08:00<04:21,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1717, 'grad_norm': 6.597239017486572, 'learning_rate': 2.4770642201834864e-05, 'epoch': 1.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 340/654 [08:08<04:10,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2109, 'grad_norm': 6.263698577880859, 'learning_rate': 2.4006116207951072e-05, 'epoch': 1.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 350/654 [08:16<04:01,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2668, 'grad_norm': 3.51605486869812, 'learning_rate': 2.324159021406728e-05, 'epoch': 1.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 360/654 [08:25<03:58,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2358, 'grad_norm': 6.929905891418457, 'learning_rate': 2.2477064220183487e-05, 'epoch': 1.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 370/654 [08:32<03:38,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1737, 'grad_norm': 13.150646209716797, 'learning_rate': 2.1712538226299695e-05, 'epoch': 1.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 380/654 [08:59<08:46,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1887, 'grad_norm': 2.7542884349823, 'learning_rate': 2.0948012232415903e-05, 'epoch': 1.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 390/654 [09:17<08:21,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2438, 'grad_norm': 7.993503093719482, 'learning_rate': 2.018348623853211e-05, 'epoch': 1.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 400/654 [09:43<07:55,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2273, 'grad_norm': 1.731151819229126, 'learning_rate': 1.9418960244648318e-05, 'epoch': 1.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 410/654 [09:51<03:25,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.189, 'grad_norm': 10.786277770996094, 'learning_rate': 1.8654434250764526e-05, 'epoch': 1.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 420/654 [10:00<03:27,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2369, 'grad_norm': 24.436796188354492, 'learning_rate': 1.7889908256880737e-05, 'epoch': 1.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 430/654 [10:09<03:13,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2379, 'grad_norm': 10.953409194946289, 'learning_rate': 1.712538226299694e-05, 'epoch': 1.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 436/654 [10:20<03:09,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.42221856117248535, 'eval_runtime': 5.1733, 'eval_samples_per_second': 75.001, 'eval_steps_per_second': 4.833, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 440/654 [10:25<05:57,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1247, 'grad_norm': 0.48542287945747375, 'learning_rate': 1.636085626911315e-05, 'epoch': 2.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 450/654 [10:35<03:32,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1219, 'grad_norm': 4.878985404968262, 'learning_rate': 1.559633027522936e-05, 'epoch': 2.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 460/654 [10:44<02:38,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0529, 'grad_norm': 0.5471055507659912, 'learning_rate': 1.4831804281345565e-05, 'epoch': 2.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 470/654 [10:56<04:36,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.094, 'grad_norm': 2.234342336654663, 'learning_rate': 1.4067278287461774e-05, 'epoch': 2.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 480/654 [11:10<03:11,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0941, 'grad_norm': 2.1173996925354004, 'learning_rate': 1.3302752293577984e-05, 'epoch': 2.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 490/654 [11:23<03:31,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1095, 'grad_norm': 8.039071083068848, 'learning_rate': 1.253822629969419e-05, 'epoch': 2.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 500/654 [11:50<09:03,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0603, 'grad_norm': 0.2917783856391907, 'learning_rate': 1.1773700305810397e-05, 'epoch': 2.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 510/654 [12:28<06:34,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.058, 'grad_norm': 3.5893125534057617, 'learning_rate': 1.1009174311926607e-05, 'epoch': 2.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 520/654 [12:48<04:15,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0454, 'grad_norm': 0.35865363478660583, 'learning_rate': 1.0244648318042814e-05, 'epoch': 2.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 530/654 [12:58<01:46,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0929, 'grad_norm': 1.6767597198486328, 'learning_rate': 9.480122324159022e-06, 'epoch': 2.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 540/654 [13:06<01:33,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.065, 'grad_norm': 0.4124130606651306, 'learning_rate': 8.71559633027523e-06, 'epoch': 2.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 550/654 [13:59<06:46,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1427, 'grad_norm': 7.561567783355713, 'learning_rate': 7.951070336391438e-06, 'epoch': 2.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 560/654 [14:19<03:21,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1231, 'grad_norm': 0.09226620942354202, 'learning_rate': 7.186544342507645e-06, 'epoch': 2.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 570/654 [14:48<03:34,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0902, 'grad_norm': 2.3611152172088623, 'learning_rate': 6.422018348623854e-06, 'epoch': 2.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 580/654 [15:07<02:04,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1019, 'grad_norm': 0.11030992120504379, 'learning_rate': 5.657492354740062e-06, 'epoch': 2.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 590/654 [15:25<01:34,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0148, 'grad_norm': 0.17759627103805542, 'learning_rate': 4.892966360856269e-06, 'epoch': 2.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 600/654 [15:37<00:56,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.127, 'grad_norm': 0.4788254201412201, 'learning_rate': 4.128440366972477e-06, 'epoch': 2.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 610/654 [16:06<01:00,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1061, 'grad_norm': 13.228991508483887, 'learning_rate': 3.363914373088685e-06, 'epoch': 2.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 620/654 [16:22<00:40,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1632, 'grad_norm': 16.87421417236328, 'learning_rate': 2.599388379204893e-06, 'epoch': 2.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 630/654 [16:33<00:28,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1102, 'grad_norm': 2.434553861618042, 'learning_rate': 1.8348623853211011e-06, 'epoch': 2.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 640/654 [16:47<00:24,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0989, 'grad_norm': 0.21832436323165894, 'learning_rate': 1.0703363914373088e-06, 'epoch': 2.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 650/654 [16:58<00:04,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1114, 'grad_norm': 0.08660129457712173, 'learning_rate': 3.0581039755351683e-07, 'epoch': 2.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 654/654 [17:20<00:00,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6311530470848083, 'eval_runtime': 7.7797, 'eval_samples_per_second': 49.873, 'eval_steps_per_second': 3.213, 'epoch': 3.0}\n",
      "{'train_runtime': 1040.5886, 'train_samples_per_second': 10.056, 'train_steps_per_second': 0.628, 'train_loss': 0.2857098263611487, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=654, training_loss=0.2857098263611487, metrics={'train_runtime': 1040.5886, 'train_samples_per_second': 10.056, 'train_steps_per_second': 0.628, 'total_flos': 688304700776448.0, 'train_loss': 0.2857098263611487, 'epoch': 3.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the training arguments for the teacher model\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_knowledge_distill/teacher_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir=\"./logs_knowledge_distill/teacher_model\",\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "# Trainer for the teacher model\n",
    "trainer_teacher = Trainer(\n",
    "    model=teacher_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Fine-tune the teacher model\n",
    "trainer_teacher.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This function ensures the student model is trained using the logits from the teacher model in addition to the ground truth labels, combining hard and soft losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher logits: tensor([[-2.6213,  4.1635, -2.3194],\n",
      "        [-1.5190, -1.7753,  4.8557],\n",
      "        [-2.5256,  4.1303, -2.2848],\n",
      "        ...,\n",
      "        [-1.7173,  3.6361, -2.9695],\n",
      "        [-1.8634, -1.4155,  4.7208],\n",
      "        [-2.6480,  4.1266, -2.2814]])\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4568,  1.6938, -0.6216],\n",
      "        [-1.4918,  1.5309, -0.0303],\n",
      "        [-1.6417,  1.1014,  0.4621],\n",
      "        [-1.2778,  1.1750, -0.1223],\n",
      "        [-1.7693,  0.3149,  1.4295],\n",
      "        [-1.8186,  1.1852,  0.1105],\n",
      "        [ 0.1959,  0.1122, -0.8044],\n",
      "        [-2.2644,  0.2283,  1.6057],\n",
      "        [-1.8654,  0.4816,  0.9782],\n",
      "        [-0.0396,  0.2007, -0.8431],\n",
      "        [-1.1631,  1.3751, -0.3029],\n",
      "        [-1.7715,  1.5458,  0.2369],\n",
      "        [-1.1664,  1.3201, -0.6355],\n",
      "        [-1.6168, -0.0067,  1.1921],\n",
      "        [-1.7620,  0.3772,  1.1147],\n",
      "        [-1.8191,  1.2931,  0.3181]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4568,  1.6938, -0.6216],\n",
      "        [-1.4918,  1.5309, -0.0303],\n",
      "        [-1.6417,  1.1014,  0.4621],\n",
      "        [-1.2778,  1.1750, -0.1223],\n",
      "        [-1.7693,  0.3149,  1.4295],\n",
      "        [-1.8186,  1.1852,  0.1105],\n",
      "        [ 0.1959,  0.1122, -0.8044],\n",
      "        [-2.2644,  0.2283,  1.6057],\n",
      "        [-1.8654,  0.4816,  0.9782],\n",
      "        [-0.0396,  0.2007, -0.8431],\n",
      "        [-1.1631,  1.3751, -0.3029],\n",
      "        [-1.7715,  1.5458,  0.2369],\n",
      "        [-1.1664,  1.3201, -0.6355],\n",
      "        [-1.6168, -0.0067,  1.1921],\n",
      "        [-1.7620,  0.3772,  1.1147],\n",
      "        [-1.8191,  1.2931,  0.3181]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5808,  1.6886, -0.0567],\n",
      "        [-1.5757,  1.7930, -0.4598],\n",
      "        [-1.2112,  1.0803, -0.2517],\n",
      "        [-1.9942,  1.0192,  0.6077],\n",
      "        [-1.4595,  1.4458, -0.1002],\n",
      "        [-1.7656,  0.1432,  1.3050],\n",
      "        [-1.6312,  1.5670, -0.0466],\n",
      "        [-1.6714,  1.6358, -0.0982],\n",
      "        [-1.9927,  0.2996,  1.4402],\n",
      "        [-1.3640,  1.4469, -0.2880],\n",
      "        [-1.6073,  1.7372, -0.1742],\n",
      "        [-1.8234,  1.4073,  0.0721],\n",
      "        [-1.8748,  1.2589,  0.2262],\n",
      "        [-1.5140,  1.9485, -0.1832],\n",
      "        [-1.8572,  1.1929,  0.5277],\n",
      "        [-1.9547,  1.0560,  0.4281]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5808,  1.6886, -0.0567],\n",
      "        [-1.5757,  1.7930, -0.4598],\n",
      "        [-1.2112,  1.0803, -0.2517],\n",
      "        [-1.9942,  1.0192,  0.6077],\n",
      "        [-1.4595,  1.4458, -0.1002],\n",
      "        [-1.7656,  0.1432,  1.3050],\n",
      "        [-1.6312,  1.5670, -0.0466],\n",
      "        [-1.6714,  1.6358, -0.0982],\n",
      "        [-1.9927,  0.2996,  1.4402],\n",
      "        [-1.3640,  1.4469, -0.2880],\n",
      "        [-1.6073,  1.7372, -0.1742],\n",
      "        [-1.8234,  1.4073,  0.0721],\n",
      "        [-1.8748,  1.2589,  0.2262],\n",
      "        [-1.5140,  1.9485, -0.1832],\n",
      "        [-1.8572,  1.1929,  0.5277],\n",
      "        [-1.9547,  1.0560,  0.4281]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8969,  0.2397,  1.0902],\n",
      "        [-0.1880,  0.9118, -0.9832],\n",
      "        [-2.0599,  0.2623,  1.3519],\n",
      "        [-1.4655,  1.8053, -0.4308],\n",
      "        [-2.0229,  0.8996,  0.8102],\n",
      "        [-1.5829,  1.8561, -0.2814],\n",
      "        [-1.2304,  1.8818, -0.4453],\n",
      "        [-1.7999,  1.6950, -0.2052],\n",
      "        [ 0.2999,  0.1976, -0.7324],\n",
      "        [-1.2648,  1.6260, -0.4516],\n",
      "        [-1.7086,  0.7986,  0.5704],\n",
      "        [-1.4620,  1.8107, -0.3460],\n",
      "        [-1.9785,  0.1820,  1.0779],\n",
      "        [-1.7401,  0.5852,  0.8561],\n",
      "        [-1.3896,  1.4953, -0.5455],\n",
      "        [-1.9561,  1.2152,  0.2842]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8969,  0.2397,  1.0902],\n",
      "        [-0.1880,  0.9118, -0.9832],\n",
      "        [-2.0599,  0.2623,  1.3519],\n",
      "        [-1.4655,  1.8053, -0.4308],\n",
      "        [-2.0229,  0.8996,  0.8102],\n",
      "        [-1.5829,  1.8561, -0.2814],\n",
      "        [-1.2304,  1.8818, -0.4453],\n",
      "        [-1.7999,  1.6950, -0.2052],\n",
      "        [ 0.2999,  0.1976, -0.7324],\n",
      "        [-1.2648,  1.6260, -0.4516],\n",
      "        [-1.7086,  0.7986,  0.5704],\n",
      "        [-1.4620,  1.8107, -0.3460],\n",
      "        [-1.9785,  0.1820,  1.0779],\n",
      "        [-1.7401,  0.5852,  0.8561],\n",
      "        [-1.3896,  1.4953, -0.5455],\n",
      "        [-1.9561,  1.2152,  0.2842]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7141,  1.8761, -0.5925],\n",
      "        [-1.5706,  1.1415,  0.3156],\n",
      "        [-1.4402,  1.4088, -0.3472],\n",
      "        [-1.4057,  1.0404,  0.1290],\n",
      "        [-1.6380,  1.5460, -0.1893],\n",
      "        [-1.9334,  1.8076, -0.1668],\n",
      "        [-1.9521,  0.3418,  1.0511],\n",
      "        [-1.4147,  1.7655, -0.3826],\n",
      "        [-1.5983,  1.2245,  0.1235],\n",
      "        [-1.2994,  1.5697, -0.5744],\n",
      "        [-1.6341,  1.9706, -0.4236],\n",
      "        [-1.3460,  1.7099, -0.7192],\n",
      "        [-1.8432, -0.0081,  1.1590],\n",
      "        [-1.0330, -0.1063,  0.4977],\n",
      "        [-1.2093,  1.5753, -0.7494],\n",
      "        [-1.7473,  0.0451,  1.3275]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7141,  1.8761, -0.5925],\n",
      "        [-1.5706,  1.1415,  0.3156],\n",
      "        [-1.4402,  1.4088, -0.3472],\n",
      "        [-1.4057,  1.0404,  0.1290],\n",
      "        [-1.6380,  1.5460, -0.1893],\n",
      "        [-1.9334,  1.8076, -0.1668],\n",
      "        [-1.9521,  0.3418,  1.0511],\n",
      "        [-1.4147,  1.7655, -0.3826],\n",
      "        [-1.5983,  1.2245,  0.1235],\n",
      "        [-1.2994,  1.5697, -0.5744],\n",
      "        [-1.6341,  1.9706, -0.4236],\n",
      "        [-1.3460,  1.7099, -0.7192],\n",
      "        [-1.8432, -0.0081,  1.1590],\n",
      "        [-1.0330, -0.1063,  0.4977],\n",
      "        [-1.2093,  1.5753, -0.7494],\n",
      "        [-1.7473,  0.0451,  1.3275]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8880,  0.5797,  1.0462],\n",
      "        [-1.1565,  1.7072, -0.6239],\n",
      "        [-0.4670,  0.3878, -0.2553],\n",
      "        [-1.1267,  0.0882,  0.5977],\n",
      "        [-1.4539,  1.6303, -0.2260],\n",
      "        [-1.4307,  1.8323, -0.6772],\n",
      "        [-1.6197,  1.7431, -0.5176],\n",
      "        [ 0.3151,  0.0745, -0.8056],\n",
      "        [-1.7548,  1.7354, -0.3265],\n",
      "        [-1.6265,  1.9403, -0.5851],\n",
      "        [-1.3482,  1.4719, -0.4669],\n",
      "        [-1.6000,  1.8708, -0.3454],\n",
      "        [-1.2566,  1.5660, -0.6674],\n",
      "        [-1.5996,  1.3574,  0.0147],\n",
      "        [-1.4978,  0.5757,  0.3773],\n",
      "        [-1.7697,  0.0973,  1.1830]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8880,  0.5797,  1.0462],\n",
      "        [-1.1565,  1.7072, -0.6239],\n",
      "        [-0.4670,  0.3878, -0.2553],\n",
      "        [-1.1267,  0.0882,  0.5977],\n",
      "        [-1.4539,  1.6303, -0.2260],\n",
      "        [-1.4307,  1.8323, -0.6772],\n",
      "        [-1.6197,  1.7431, -0.5176],\n",
      "        [ 0.3151,  0.0745, -0.8056],\n",
      "        [-1.7548,  1.7354, -0.3265],\n",
      "        [-1.6265,  1.9403, -0.5851],\n",
      "        [-1.3482,  1.4719, -0.4669],\n",
      "        [-1.6000,  1.8708, -0.3454],\n",
      "        [-1.2566,  1.5660, -0.6674],\n",
      "        [-1.5996,  1.3574,  0.0147],\n",
      "        [-1.4978,  0.5757,  0.3773],\n",
      "        [-1.7697,  0.0973,  1.1830]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2173,  1.6854, -0.7218],\n",
      "        [-1.4920,  1.7671, -0.6350],\n",
      "        [ 0.3513,  0.0959, -1.0022],\n",
      "        [-1.3255,  1.8228, -0.3550],\n",
      "        [ 0.2836,  0.1714, -0.8218],\n",
      "        [-0.1668,  0.5345, -0.8727],\n",
      "        [-1.8353,  2.0175, -0.5865],\n",
      "        [ 0.2520,  0.0674, -0.7655],\n",
      "        [-1.4565,  1.9292, -0.4260],\n",
      "        [-1.6304,  0.4388,  1.0338],\n",
      "        [-1.3879,  0.9916, -0.0966],\n",
      "        [-0.1588,  0.6567, -0.7677],\n",
      "        [-1.2565,  1.5755, -0.5490],\n",
      "        [-1.2649,  1.6284, -0.5473],\n",
      "        [-1.4908,  1.8048, -0.7164],\n",
      "        [-1.7832,  2.1890, -0.4949]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.2173,  1.6854, -0.7218],\n",
      "        [-1.4920,  1.7671, -0.6350],\n",
      "        [ 0.3513,  0.0959, -1.0022],\n",
      "        [-1.3255,  1.8228, -0.3550],\n",
      "        [ 0.2836,  0.1714, -0.8218],\n",
      "        [-0.1668,  0.5345, -0.8727],\n",
      "        [-1.8353,  2.0175, -0.5865],\n",
      "        [ 0.2520,  0.0674, -0.7655],\n",
      "        [-1.4565,  1.9292, -0.4260],\n",
      "        [-1.6304,  0.4388,  1.0338],\n",
      "        [-1.3879,  0.9916, -0.0966],\n",
      "        [-0.1588,  0.6567, -0.7677],\n",
      "        [-1.2565,  1.5755, -0.5490],\n",
      "        [-1.2649,  1.6284, -0.5473],\n",
      "        [-1.4908,  1.8048, -0.7164],\n",
      "        [-1.7832,  2.1890, -0.4949]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4473, -0.0038,  0.9192],\n",
      "        [-0.5547,  0.6509, -0.4672],\n",
      "        [-0.9378,  1.2056, -0.4954],\n",
      "        [-1.2899,  0.1189,  0.8748],\n",
      "        [-1.6029,  2.0654, -0.5146],\n",
      "        [-1.5999,  1.8809, -0.5239],\n",
      "        [-1.4438,  1.9209, -0.3122],\n",
      "        [-1.0144,  1.3347, -0.6797],\n",
      "        [-1.8773,  2.1005, -0.4372],\n",
      "        [-1.6271,  0.4022,  0.7778],\n",
      "        [-2.0181,  1.4072,  0.1399],\n",
      "        [-1.7730,  1.0972, -0.0378],\n",
      "        [ 0.0349,  0.2952, -0.8624],\n",
      "        [-1.3738,  1.7125, -0.5301],\n",
      "        [-1.4603,  1.9760, -0.3511],\n",
      "        [-0.9744,  1.4929, -0.7590]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4473, -0.0038,  0.9192],\n",
      "        [-0.5547,  0.6509, -0.4672],\n",
      "        [-0.9378,  1.2056, -0.4954],\n",
      "        [-1.2899,  0.1189,  0.8748],\n",
      "        [-1.6029,  2.0654, -0.5146],\n",
      "        [-1.5999,  1.8809, -0.5239],\n",
      "        [-1.4438,  1.9209, -0.3122],\n",
      "        [-1.0144,  1.3347, -0.6797],\n",
      "        [-1.8773,  2.1005, -0.4372],\n",
      "        [-1.6271,  0.4022,  0.7778],\n",
      "        [-2.0181,  1.4072,  0.1399],\n",
      "        [-1.7730,  1.0972, -0.0378],\n",
      "        [ 0.0349,  0.2952, -0.8624],\n",
      "        [-1.3738,  1.7125, -0.5301],\n",
      "        [-1.4603,  1.9760, -0.3511],\n",
      "        [-0.9744,  1.4929, -0.7590]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.5201,  0.3785, -0.4718],\n",
      "        [-1.2962,  1.5986, -0.4343],\n",
      "        [ 0.1818,  0.0055, -0.8860],\n",
      "        [-1.7050,  1.6695, -0.2703],\n",
      "        [-1.4208, -0.1215,  0.9247],\n",
      "        [ 0.4385, -0.0335, -0.8810],\n",
      "        [-1.5586,  1.7617, -0.3256],\n",
      "        [-1.7066,  1.6914, -0.5316],\n",
      "        [-2.0845,  1.0420,  0.6715],\n",
      "        [-1.4831,  1.0806,  0.2099],\n",
      "        [-1.4429,  1.7936, -0.5431],\n",
      "        [-1.8366,  0.5299,  0.7811],\n",
      "        [-1.4471,  1.6804, -0.4279],\n",
      "        [-1.3845,  0.1014,  0.7955],\n",
      "        [ 0.0970,  0.3794, -0.7938],\n",
      "        [-1.9072,  0.6539,  0.8181]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-0.5201,  0.3785, -0.4718],\n",
      "        [-1.2962,  1.5986, -0.4343],\n",
      "        [ 0.1818,  0.0055, -0.8860],\n",
      "        [-1.7050,  1.6695, -0.2703],\n",
      "        [-1.4208, -0.1215,  0.9247],\n",
      "        [ 0.4385, -0.0335, -0.8810],\n",
      "        [-1.5586,  1.7617, -0.3256],\n",
      "        [-1.7066,  1.6914, -0.5316],\n",
      "        [-2.0845,  1.0420,  0.6715],\n",
      "        [-1.4831,  1.0806,  0.2099],\n",
      "        [-1.4429,  1.7936, -0.5431],\n",
      "        [-1.8366,  0.5299,  0.7811],\n",
      "        [-1.4471,  1.6804, -0.4279],\n",
      "        [-1.3845,  0.1014,  0.7955],\n",
      "        [ 0.0970,  0.3794, -0.7938],\n",
      "        [-1.9072,  0.6539,  0.8181]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5584,  1.7904, -0.3210],\n",
      "        [-1.4272,  1.7838, -0.5500],\n",
      "        [-1.5076,  1.7006, -0.5693],\n",
      "        [-1.3787,  0.1077,  0.8029],\n",
      "        [-1.9888,  0.7693,  1.0535],\n",
      "        [-1.3906,  1.8703, -0.3374],\n",
      "        [-1.3968, -0.0687,  0.7893],\n",
      "        [-1.1569,  1.5628, -0.7887],\n",
      "        [-1.4318,  0.1253,  0.9321],\n",
      "        [-1.2737,  1.6697, -0.6392],\n",
      "        [-1.7873,  0.2935,  0.9819],\n",
      "        [-1.4592,  0.1470,  0.8396],\n",
      "        [-1.4940,  1.8155, -0.5937],\n",
      "        [-1.0518,  0.8756, -0.1353],\n",
      "        [-1.8676,  0.1120,  1.1754],\n",
      "        [-1.4071,  0.0181,  0.8922]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5584,  1.7904, -0.3210],\n",
      "        [-1.4272,  1.7838, -0.5500],\n",
      "        [-1.5076,  1.7006, -0.5693],\n",
      "        [-1.3787,  0.1077,  0.8029],\n",
      "        [-1.9888,  0.7693,  1.0535],\n",
      "        [-1.3906,  1.8703, -0.3374],\n",
      "        [-1.3968, -0.0687,  0.7893],\n",
      "        [-1.1569,  1.5628, -0.7887],\n",
      "        [-1.4318,  0.1253,  0.9321],\n",
      "        [-1.2737,  1.6697, -0.6392],\n",
      "        [-1.7873,  0.2935,  0.9819],\n",
      "        [-1.4592,  0.1470,  0.8396],\n",
      "        [-1.4940,  1.8155, -0.5937],\n",
      "        [-1.0518,  0.8756, -0.1353],\n",
      "        [-1.8676,  0.1120,  1.1754],\n",
      "        [-1.4071,  0.0181,  0.8922]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4765,  1.8344, -0.4541],\n",
      "        [ 0.3183, -0.0887, -0.8284],\n",
      "        [-1.8266,  1.2304,  0.1374],\n",
      "        [-1.7662,  1.7618, -0.3422],\n",
      "        [-1.7449,  1.4021, -0.0907],\n",
      "        [-1.5072,  1.8590, -0.5322],\n",
      "        [-1.1289,  1.5206, -0.5161],\n",
      "        [-1.6403,  1.6249, -0.2184],\n",
      "        [-1.9604,  1.4893,  0.2569],\n",
      "        [-1.4178,  1.5459, -0.4688],\n",
      "        [-1.8111,  0.9545,  0.6346],\n",
      "        [-1.7611,  1.3625, -0.0725],\n",
      "        [-2.0322,  0.4491,  0.9949],\n",
      "        [-2.1114,  1.0166,  0.5607],\n",
      "        [-1.8647,  0.4941,  0.8324],\n",
      "        [-1.8858,  1.6332, -0.0103]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4765,  1.8344, -0.4541],\n",
      "        [ 0.3183, -0.0887, -0.8284],\n",
      "        [-1.8266,  1.2304,  0.1374],\n",
      "        [-1.7662,  1.7618, -0.3422],\n",
      "        [-1.7449,  1.4021, -0.0907],\n",
      "        [-1.5072,  1.8590, -0.5322],\n",
      "        [-1.1289,  1.5206, -0.5161],\n",
      "        [-1.6403,  1.6249, -0.2184],\n",
      "        [-1.9604,  1.4893,  0.2569],\n",
      "        [-1.4178,  1.5459, -0.4688],\n",
      "        [-1.8111,  0.9545,  0.6346],\n",
      "        [-1.7611,  1.3625, -0.0725],\n",
      "        [-2.0322,  0.4491,  0.9949],\n",
      "        [-2.1114,  1.0166,  0.5607],\n",
      "        [-1.8647,  0.4941,  0.8324],\n",
      "        [-1.8858,  1.6332, -0.0103]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1501,  0.8308,  0.9894],\n",
      "        [ 0.0816,  0.1146, -0.6804],\n",
      "        [-1.6468,  1.6523, -0.3956],\n",
      "        [-0.4358,  0.7952, -0.9513],\n",
      "        [-2.0343,  1.9148, -0.0294],\n",
      "        [ 0.3067,  0.1947, -0.8112],\n",
      "        [-1.4048,  0.1876,  1.1138],\n",
      "        [ 0.1607,  0.0883, -0.8433],\n",
      "        [-1.3767,  1.6757, -0.4643],\n",
      "        [-0.8140,  0.0965,  0.2266],\n",
      "        [-1.9513,  1.8642, -0.2587],\n",
      "        [-1.9456,  2.1230, -0.2895],\n",
      "        [-0.9125,  0.7586, -0.1862],\n",
      "        [ 0.4059, -0.1091, -0.9392],\n",
      "        [-1.7820,  1.4136, -0.0967],\n",
      "        [-1.4014,  1.6458, -0.4302]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.1501,  0.8308,  0.9894],\n",
      "        [ 0.0816,  0.1146, -0.6804],\n",
      "        [-1.6468,  1.6523, -0.3956],\n",
      "        [-0.4358,  0.7952, -0.9513],\n",
      "        [-2.0343,  1.9148, -0.0294],\n",
      "        [ 0.3067,  0.1947, -0.8112],\n",
      "        [-1.4048,  0.1876,  1.1138],\n",
      "        [ 0.1607,  0.0883, -0.8433],\n",
      "        [-1.3767,  1.6757, -0.4643],\n",
      "        [-0.8140,  0.0965,  0.2266],\n",
      "        [-1.9513,  1.8642, -0.2587],\n",
      "        [-1.9456,  2.1230, -0.2895],\n",
      "        [-0.9125,  0.7586, -0.1862],\n",
      "        [ 0.4059, -0.1091, -0.9392],\n",
      "        [-1.7820,  1.4136, -0.0967],\n",
      "        [-1.4014,  1.6458, -0.4302]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1397e+00,  1.5334e+00,  3.6656e-01],\n",
      "        [-1.5806e+00,  9.4443e-02,  9.5022e-01],\n",
      "        [-1.7965e+00,  8.3183e-02,  1.2819e+00],\n",
      "        [-2.0434e+00,  7.9573e-01,  5.5927e-01],\n",
      "        [-1.5749e+00,  3.6432e-01,  8.8442e-01],\n",
      "        [ 1.9667e-01,  7.3335e-02, -9.4493e-01],\n",
      "        [-1.5946e+00,  1.5603e+00, -2.0114e-01],\n",
      "        [-1.0464e+00,  1.0204e+00, -4.5841e-01],\n",
      "        [-1.4966e+00,  1.7984e+00, -5.4026e-01],\n",
      "        [-1.3123e+00,  1.1718e+00, -3.4633e-01],\n",
      "        [-1.2636e+00,  2.3403e-01,  7.2084e-01],\n",
      "        [-1.6755e+00,  1.4961e+00, -1.3193e-01],\n",
      "        [-1.7290e+00,  1.1583e+00,  2.9804e-01],\n",
      "        [-2.0875e+00,  1.6509e+00, -1.1191e-03],\n",
      "        [-1.8971e+00,  1.7920e+00, -1.5188e-01],\n",
      "        [-1.7845e+00,  1.8361e+00, -1.5329e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.1397e+00,  1.5334e+00,  3.6656e-01],\n",
      "        [-1.5806e+00,  9.4443e-02,  9.5022e-01],\n",
      "        [-1.7965e+00,  8.3183e-02,  1.2819e+00],\n",
      "        [-2.0434e+00,  7.9573e-01,  5.5927e-01],\n",
      "        [-1.5749e+00,  3.6432e-01,  8.8442e-01],\n",
      "        [ 1.9667e-01,  7.3335e-02, -9.4493e-01],\n",
      "        [-1.5946e+00,  1.5603e+00, -2.0114e-01],\n",
      "        [-1.0464e+00,  1.0204e+00, -4.5841e-01],\n",
      "        [-1.4966e+00,  1.7984e+00, -5.4026e-01],\n",
      "        [-1.3123e+00,  1.1718e+00, -3.4633e-01],\n",
      "        [-1.2636e+00,  2.3403e-01,  7.2084e-01],\n",
      "        [-1.6755e+00,  1.4961e+00, -1.3193e-01],\n",
      "        [-1.7290e+00,  1.1583e+00,  2.9804e-01],\n",
      "        [-2.0875e+00,  1.6509e+00, -1.1191e-03],\n",
      "        [-1.8971e+00,  1.7920e+00, -1.5188e-01],\n",
      "        [-1.7845e+00,  1.8361e+00, -1.5329e-01]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2680,  1.2873, -0.0575],\n",
      "        [-1.6775,  0.3889,  1.0493],\n",
      "        [-1.8963,  0.4460,  0.9678],\n",
      "        [-1.9677,  1.5980,  0.0842],\n",
      "        [-2.0162,  0.4283,  1.1752],\n",
      "        [-1.4565,  0.0893,  0.9317],\n",
      "        [ 0.3339,  0.0505, -0.7772],\n",
      "        [-1.6001,  1.7563, -0.3555],\n",
      "        [-1.7633,  0.2872,  1.1554],\n",
      "        [-1.5450,  1.7104, -0.0072],\n",
      "        [-0.0197,  0.4424, -0.9216],\n",
      "        [-2.0893,  1.3294,  0.4043],\n",
      "        [-2.1290,  1.9618, -0.2788],\n",
      "        [-1.8640,  1.6078, -0.0457],\n",
      "        [-2.0188,  0.9139,  0.6380],\n",
      "        [-1.7744,  0.3510,  0.9486]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.2680,  1.2873, -0.0575],\n",
      "        [-1.6775,  0.3889,  1.0493],\n",
      "        [-1.8963,  0.4460,  0.9678],\n",
      "        [-1.9677,  1.5980,  0.0842],\n",
      "        [-2.0162,  0.4283,  1.1752],\n",
      "        [-1.4565,  0.0893,  0.9317],\n",
      "        [ 0.3339,  0.0505, -0.7772],\n",
      "        [-1.6001,  1.7563, -0.3555],\n",
      "        [-1.7633,  0.2872,  1.1554],\n",
      "        [-1.5450,  1.7104, -0.0072],\n",
      "        [-0.0197,  0.4424, -0.9216],\n",
      "        [-2.0893,  1.3294,  0.4043],\n",
      "        [-2.1290,  1.9618, -0.2788],\n",
      "        [-1.8640,  1.6078, -0.0457],\n",
      "        [-2.0188,  0.9139,  0.6380],\n",
      "        [-1.7744,  0.3510,  0.9486]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.0282,  1.3471, -0.5169],\n",
      "        [-1.8294,  1.8399, -0.2557],\n",
      "        [-1.5882,  0.1801,  0.9642],\n",
      "        [-1.8569,  1.8524, -0.2316],\n",
      "        [-1.9657,  1.8344, -0.2300],\n",
      "        [-2.4348,  0.9898,  1.0129],\n",
      "        [-1.9226,  1.7134,  0.1648],\n",
      "        [-1.9125,  2.0559, -0.4284],\n",
      "        [-0.2810,  0.6755, -0.7247],\n",
      "        [-1.8789,  0.3384,  1.1373],\n",
      "        [-1.7875,  0.3358,  1.2439],\n",
      "        [-1.9016,  1.8626,  0.0937],\n",
      "        [-1.0248,  1.2165, -0.5676],\n",
      "        [-1.7765,  1.6915, -0.3748],\n",
      "        [-1.7048,  1.9291, -0.3737],\n",
      "        [-1.5646,  1.2691, -0.1334]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.0282,  1.3471, -0.5169],\n",
      "        [-1.8294,  1.8399, -0.2557],\n",
      "        [-1.5882,  0.1801,  0.9642],\n",
      "        [-1.8569,  1.8524, -0.2316],\n",
      "        [-1.9657,  1.8344, -0.2300],\n",
      "        [-2.4348,  0.9898,  1.0129],\n",
      "        [-1.9226,  1.7134,  0.1648],\n",
      "        [-1.9125,  2.0559, -0.4284],\n",
      "        [-0.2810,  0.6755, -0.7247],\n",
      "        [-1.8789,  0.3384,  1.1373],\n",
      "        [-1.7875,  0.3358,  1.2439],\n",
      "        [-1.9016,  1.8626,  0.0937],\n",
      "        [-1.0248,  1.2165, -0.5676],\n",
      "        [-1.7765,  1.6915, -0.3748],\n",
      "        [-1.7048,  1.9291, -0.3737],\n",
      "        [-1.5646,  1.2691, -0.1334]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0195,  0.6617,  0.9426],\n",
      "        [-1.7519,  1.6056, -0.0421],\n",
      "        [-1.6624,  1.0689,  0.0477],\n",
      "        [-1.9956,  1.4005,  0.0821],\n",
      "        [-1.9263,  0.2883,  1.0516],\n",
      "        [ 0.2455,  0.0966, -0.9458],\n",
      "        [-1.8336,  1.8750, -0.0494],\n",
      "        [-1.9564,  0.5724,  1.0470],\n",
      "        [-2.1272,  1.2094,  0.3707],\n",
      "        [-2.1567,  1.7640, -0.0174],\n",
      "        [-1.3445,  1.4774, -0.5061],\n",
      "        [-1.7895,  1.7644, -0.0460],\n",
      "        [-1.3003,  1.2155, -0.3857],\n",
      "        [ 0.0726,  0.4491, -1.0450],\n",
      "        [-1.5117,  1.4972, -0.1928],\n",
      "        [ 0.0702,  0.4610, -0.8497]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.0195,  0.6617,  0.9426],\n",
      "        [-1.7519,  1.6056, -0.0421],\n",
      "        [-1.6624,  1.0689,  0.0477],\n",
      "        [-1.9956,  1.4005,  0.0821],\n",
      "        [-1.9263,  0.2883,  1.0516],\n",
      "        [ 0.2455,  0.0966, -0.9458],\n",
      "        [-1.8336,  1.8750, -0.0494],\n",
      "        [-1.9564,  0.5724,  1.0470],\n",
      "        [-2.1272,  1.2094,  0.3707],\n",
      "        [-2.1567,  1.7640, -0.0174],\n",
      "        [-1.3445,  1.4774, -0.5061],\n",
      "        [-1.7895,  1.7644, -0.0460],\n",
      "        [-1.3003,  1.2155, -0.3857],\n",
      "        [ 0.0726,  0.4491, -1.0450],\n",
      "        [-1.5117,  1.4972, -0.1928],\n",
      "        [ 0.0702,  0.4610, -0.8497]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9680,  1.0076,  0.7110],\n",
      "        [-2.0108,  1.7003,  0.1266],\n",
      "        [-2.1008,  0.5764,  1.2419],\n",
      "        [-0.1937,  0.4258, -0.6580],\n",
      "        [-1.4765,  1.4540, -0.2391],\n",
      "        [-1.6448,  1.4945, -0.0344],\n",
      "        [-2.0368,  0.3880,  0.9560],\n",
      "        [-1.8123,  1.7368,  0.0339],\n",
      "        [-2.0459,  1.7589, -0.0740],\n",
      "        [-1.8791,  1.6231, -0.0909],\n",
      "        [-1.6988,  1.9049, -0.2524],\n",
      "        [-1.7572,  1.3740,  0.0399],\n",
      "        [-1.8872,  1.6421, -0.0355],\n",
      "        [-2.2634,  1.2957,  0.3201],\n",
      "        [-1.9051,  1.9290,  0.0443],\n",
      "        [-1.9209,  0.5007,  1.1036]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9680,  1.0076,  0.7110],\n",
      "        [-2.0108,  1.7003,  0.1266],\n",
      "        [-2.1008,  0.5764,  1.2419],\n",
      "        [-0.1937,  0.4258, -0.6580],\n",
      "        [-1.4765,  1.4540, -0.2391],\n",
      "        [-1.6448,  1.4945, -0.0344],\n",
      "        [-2.0368,  0.3880,  0.9560],\n",
      "        [-1.8123,  1.7368,  0.0339],\n",
      "        [-2.0459,  1.7589, -0.0740],\n",
      "        [-1.8791,  1.6231, -0.0909],\n",
      "        [-1.6988,  1.9049, -0.2524],\n",
      "        [-1.7572,  1.3740,  0.0399],\n",
      "        [-1.8872,  1.6421, -0.0355],\n",
      "        [-2.2634,  1.2957,  0.3201],\n",
      "        [-1.9051,  1.9290,  0.0443],\n",
      "        [-1.9209,  0.5007,  1.1036]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6825,  1.5395, -0.0678],\n",
      "        [-2.2996,  1.4369,  0.2242],\n",
      "        [-1.8487,  1.2347,  0.5672],\n",
      "        [ 0.3789, -0.0330, -0.9931],\n",
      "        [-1.6918,  1.8080, -0.1860],\n",
      "        [-1.8046,  1.5112, -0.2935],\n",
      "        [-1.6130,  1.0512,  0.3293],\n",
      "        [-2.1008,  1.3963,  0.3071],\n",
      "        [ 0.2869,  0.1972, -0.8933],\n",
      "        [-2.0431,  1.1523,  0.5678],\n",
      "        [-2.1712,  1.0084,  0.9933],\n",
      "        [-1.9742,  0.5090,  0.9714],\n",
      "        [-2.0596,  1.2941,  0.5765],\n",
      "        [-1.5263,  1.0797,  0.0525],\n",
      "        [-1.8429,  1.3291,  0.0243],\n",
      "        [-0.8968,  1.0144, -0.6456]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6825,  1.5395, -0.0678],\n",
      "        [-2.2996,  1.4369,  0.2242],\n",
      "        [-1.8487,  1.2347,  0.5672],\n",
      "        [ 0.3789, -0.0330, -0.9931],\n",
      "        [-1.6918,  1.8080, -0.1860],\n",
      "        [-1.8046,  1.5112, -0.2935],\n",
      "        [-1.6130,  1.0512,  0.3293],\n",
      "        [-2.1008,  1.3963,  0.3071],\n",
      "        [ 0.2869,  0.1972, -0.8933],\n",
      "        [-2.0431,  1.1523,  0.5678],\n",
      "        [-2.1712,  1.0084,  0.9933],\n",
      "        [-1.9742,  0.5090,  0.9714],\n",
      "        [-2.0596,  1.2941,  0.5765],\n",
      "        [-1.5263,  1.0797,  0.0525],\n",
      "        [-1.8429,  1.3291,  0.0243],\n",
      "        [-0.8968,  1.0144, -0.6456]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2506,  1.3120,  0.4991],\n",
      "        [-1.9895,  1.1160,  0.2085],\n",
      "        [-1.6726,  0.4690,  0.8600],\n",
      "        [-2.0388,  1.2898,  0.5152],\n",
      "        [-1.9939,  1.3771,  0.2646],\n",
      "        [-1.5869,  1.5342, -0.3130],\n",
      "        [-1.8967,  0.1897,  1.1269],\n",
      "        [-1.7729,  0.2877,  1.0380],\n",
      "        [-1.7016,  0.3462,  1.0169],\n",
      "        [-1.7091,  1.6189,  0.0821],\n",
      "        [ 0.4552,  0.2810, -1.1331],\n",
      "        [-2.1216,  1.3714,  0.1336],\n",
      "        [-1.4630,  1.4112, -0.1254],\n",
      "        [ 0.4686, -0.0261, -0.8961],\n",
      "        [-1.8095,  1.6762, -0.0553],\n",
      "        [-2.0339,  0.8945,  0.9589]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.2506,  1.3120,  0.4991],\n",
      "        [-1.9895,  1.1160,  0.2085],\n",
      "        [-1.6726,  0.4690,  0.8600],\n",
      "        [-2.0388,  1.2898,  0.5152],\n",
      "        [-1.9939,  1.3771,  0.2646],\n",
      "        [-1.5869,  1.5342, -0.3130],\n",
      "        [-1.8967,  0.1897,  1.1269],\n",
      "        [-1.7729,  0.2877,  1.0380],\n",
      "        [-1.7016,  0.3462,  1.0169],\n",
      "        [-1.7091,  1.6189,  0.0821],\n",
      "        [ 0.4552,  0.2810, -1.1331],\n",
      "        [-2.1216,  1.3714,  0.1336],\n",
      "        [-1.4630,  1.4112, -0.1254],\n",
      "        [ 0.4686, -0.0261, -0.8961],\n",
      "        [-1.8095,  1.6762, -0.0553],\n",
      "        [-2.0339,  0.8945,  0.9589]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5531,  1.7348, -0.3591],\n",
      "        [ 0.3054, -0.0077, -0.9494],\n",
      "        [-0.2666,  0.6412, -0.8432],\n",
      "        [-1.7674,  1.4206, -0.1860],\n",
      "        [-2.0025,  1.1007,  0.6408],\n",
      "        [-2.0228,  0.4424,  1.0205],\n",
      "        [-1.7104,  1.7505, -0.1631],\n",
      "        [-1.8808,  1.6186, -0.0944],\n",
      "        [ 0.3867, -0.1134, -0.9485],\n",
      "        [-2.1851,  1.0836,  0.6771],\n",
      "        [-1.9213,  0.5509,  0.9053],\n",
      "        [-0.0534,  0.3766, -0.8946],\n",
      "        [-1.8776,  1.5840, -0.1584],\n",
      "        [ 0.0284,  0.2467, -0.9474],\n",
      "        [ 0.3481,  0.0124, -0.7146],\n",
      "        [-1.8992,  0.9368,  0.4645]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5531,  1.7348, -0.3591],\n",
      "        [ 0.3054, -0.0077, -0.9494],\n",
      "        [-0.2666,  0.6412, -0.8432],\n",
      "        [-1.7674,  1.4206, -0.1860],\n",
      "        [-2.0025,  1.1007,  0.6408],\n",
      "        [-2.0228,  0.4424,  1.0205],\n",
      "        [-1.7104,  1.7505, -0.1631],\n",
      "        [-1.8808,  1.6186, -0.0944],\n",
      "        [ 0.3867, -0.1134, -0.9485],\n",
      "        [-2.1851,  1.0836,  0.6771],\n",
      "        [-1.9213,  0.5509,  0.9053],\n",
      "        [-0.0534,  0.3766, -0.8946],\n",
      "        [-1.8776,  1.5840, -0.1584],\n",
      "        [ 0.0284,  0.2467, -0.9474],\n",
      "        [ 0.3481,  0.0124, -0.7146],\n",
      "        [-1.8992,  0.9368,  0.4645]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6481,  1.6352, -0.2957],\n",
      "        [-1.9631,  1.4994,  0.2981],\n",
      "        [-1.5491,  1.1086,  0.2300],\n",
      "        [-1.8973,  1.5566, -0.0588],\n",
      "        [-1.7790,  1.5539,  0.1366],\n",
      "        [-0.9257,  1.0216, -0.4392],\n",
      "        [-1.9018,  1.4440,  0.2721],\n",
      "        [-1.6586,  0.3714,  1.0444],\n",
      "        [-1.6601,  1.7457, -0.2582],\n",
      "        [ 0.4393, -0.0611, -0.9682],\n",
      "        [-1.9924,  1.4067,  0.1905],\n",
      "        [-1.5189,  1.5694, -0.3049],\n",
      "        [-1.8023,  1.5746, -0.2943],\n",
      "        [-1.8835,  1.3636, -0.0769],\n",
      "        [-2.1459,  1.1378,  0.4839],\n",
      "        [-2.1272,  1.4915,  0.2959]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6481,  1.6352, -0.2957],\n",
      "        [-1.9631,  1.4994,  0.2981],\n",
      "        [-1.5491,  1.1086,  0.2300],\n",
      "        [-1.8973,  1.5566, -0.0588],\n",
      "        [-1.7790,  1.5539,  0.1366],\n",
      "        [-0.9257,  1.0216, -0.4392],\n",
      "        [-1.9018,  1.4440,  0.2721],\n",
      "        [-1.6586,  0.3714,  1.0444],\n",
      "        [-1.6601,  1.7457, -0.2582],\n",
      "        [ 0.4393, -0.0611, -0.9682],\n",
      "        [-1.9924,  1.4067,  0.1905],\n",
      "        [-1.5189,  1.5694, -0.3049],\n",
      "        [-1.8023,  1.5746, -0.2943],\n",
      "        [-1.8835,  1.3636, -0.0769],\n",
      "        [-2.1459,  1.1378,  0.4839],\n",
      "        [-2.1272,  1.4915,  0.2959]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7030,  1.5949, -0.2490],\n",
      "        [-1.7295,  1.8265, -0.1417],\n",
      "        [-1.9773,  1.2351,  0.4184],\n",
      "        [-1.5281,  0.5793,  0.5152],\n",
      "        [-2.2141,  0.9186,  0.8656],\n",
      "        [ 0.3650,  0.0457, -1.0428],\n",
      "        [-1.4780,  1.2289, -0.1320],\n",
      "        [-1.4170,  1.7169, -0.2941],\n",
      "        [-1.6790,  1.5279, -0.1742],\n",
      "        [ 0.4215,  0.1363, -0.8381],\n",
      "        [ 0.5759, -0.0372, -1.1097],\n",
      "        [-2.1263,  0.6578,  0.7944],\n",
      "        [-2.3422,  1.6028,  0.2962],\n",
      "        [ 0.3367, -0.0103, -0.8541],\n",
      "        [-0.8324,  0.4251, -0.0777],\n",
      "        [-2.1144,  0.6001,  1.0192]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7030,  1.5949, -0.2490],\n",
      "        [-1.7295,  1.8265, -0.1417],\n",
      "        [-1.9773,  1.2351,  0.4184],\n",
      "        [-1.5281,  0.5793,  0.5152],\n",
      "        [-2.2141,  0.9186,  0.8656],\n",
      "        [ 0.3650,  0.0457, -1.0428],\n",
      "        [-1.4780,  1.2289, -0.1320],\n",
      "        [-1.4170,  1.7169, -0.2941],\n",
      "        [-1.6790,  1.5279, -0.1742],\n",
      "        [ 0.4215,  0.1363, -0.8381],\n",
      "        [ 0.5759, -0.0372, -1.1097],\n",
      "        [-2.1263,  0.6578,  0.7944],\n",
      "        [-2.3422,  1.6028,  0.2962],\n",
      "        [ 0.3367, -0.0103, -0.8541],\n",
      "        [-0.8324,  0.4251, -0.0777],\n",
      "        [-2.1144,  0.6001,  1.0192]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2026e+00,  7.8478e-01,  9.4017e-01],\n",
      "        [-1.9702e+00,  1.3964e+00,  2.3825e-01],\n",
      "        [ 1.3158e-01,  3.5358e-01, -9.5030e-01],\n",
      "        [-1.2767e-01,  4.6840e-01, -9.0016e-01],\n",
      "        [-2.2358e+00,  1.0165e+00,  7.1087e-01],\n",
      "        [ 3.4404e-01,  3.1044e-01, -1.0395e+00],\n",
      "        [-2.1681e+00,  1.6850e+00,  3.1116e-01],\n",
      "        [-1.8588e+00,  1.6093e+00,  2.8002e-02],\n",
      "        [-1.8152e+00,  1.4223e+00,  1.1178e-02],\n",
      "        [-1.8930e+00,  1.4321e+00,  2.2762e-03],\n",
      "        [-2.0251e+00,  1.2643e+00,  2.5583e-01],\n",
      "        [-1.9793e+00,  1.2001e+00,  6.0797e-01],\n",
      "        [-2.0379e+00,  1.4379e+00,  4.1150e-01],\n",
      "        [-1.8087e+00,  1.5697e+00,  8.6610e-02],\n",
      "        [-2.3313e+00,  1.6212e+00,  4.6631e-02],\n",
      "        [-1.8249e+00,  4.5793e-01,  9.8432e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.2026e+00,  7.8478e-01,  9.4017e-01],\n",
      "        [-1.9702e+00,  1.3964e+00,  2.3825e-01],\n",
      "        [ 1.3158e-01,  3.5358e-01, -9.5030e-01],\n",
      "        [-1.2767e-01,  4.6840e-01, -9.0016e-01],\n",
      "        [-2.2358e+00,  1.0165e+00,  7.1087e-01],\n",
      "        [ 3.4404e-01,  3.1044e-01, -1.0395e+00],\n",
      "        [-2.1681e+00,  1.6850e+00,  3.1116e-01],\n",
      "        [-1.8588e+00,  1.6093e+00,  2.8002e-02],\n",
      "        [-1.8152e+00,  1.4223e+00,  1.1178e-02],\n",
      "        [-1.8930e+00,  1.4321e+00,  2.2762e-03],\n",
      "        [-2.0251e+00,  1.2643e+00,  2.5583e-01],\n",
      "        [-1.9793e+00,  1.2001e+00,  6.0797e-01],\n",
      "        [-2.0379e+00,  1.4379e+00,  4.1150e-01],\n",
      "        [-1.8087e+00,  1.5697e+00,  8.6610e-02],\n",
      "        [-2.3313e+00,  1.6212e+00,  4.6631e-02],\n",
      "        [-1.8249e+00,  4.5793e-01,  9.8432e-01]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.4124,  1.2846,  0.6857],\n",
      "        [-1.8028,  1.3500, -0.0758],\n",
      "        [-2.1848,  1.0047,  0.6597],\n",
      "        [-1.6880,  1.4142,  0.2404],\n",
      "        [-2.1074,  1.3313,  0.4990],\n",
      "        [-1.9188,  1.5059,  0.4770],\n",
      "        [-2.0976,  1.6097,  0.4881],\n",
      "        [-1.6169,  1.6240,  0.1039],\n",
      "        [-1.8440,  1.2097,  0.3961],\n",
      "        [-2.2177,  0.7754,  0.8486],\n",
      "        [-2.0818,  1.1875,  0.6408],\n",
      "        [-1.6801,  1.5328, -0.0654],\n",
      "        [-1.2698,  1.4023, -0.4753],\n",
      "        [-1.7524,  1.3702,  0.0542],\n",
      "        [-1.7128,  1.3559, -0.0474],\n",
      "        [-1.4300,  1.2955, -0.0620]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.4124,  1.2846,  0.6857],\n",
      "        [-1.8028,  1.3500, -0.0758],\n",
      "        [-2.1848,  1.0047,  0.6597],\n",
      "        [-1.6880,  1.4142,  0.2404],\n",
      "        [-2.1074,  1.3313,  0.4990],\n",
      "        [-1.9188,  1.5059,  0.4770],\n",
      "        [-2.0976,  1.6097,  0.4881],\n",
      "        [-1.6169,  1.6240,  0.1039],\n",
      "        [-1.8440,  1.2097,  0.3961],\n",
      "        [-2.2177,  0.7754,  0.8486],\n",
      "        [-2.0818,  1.1875,  0.6408],\n",
      "        [-1.6801,  1.5328, -0.0654],\n",
      "        [-1.2698,  1.4023, -0.4753],\n",
      "        [-1.7524,  1.3702,  0.0542],\n",
      "        [-1.7128,  1.3559, -0.0474],\n",
      "        [-1.4300,  1.2955, -0.0620]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7993,  1.4972,  0.0309],\n",
      "        [-2.2965,  1.1838,  0.6829],\n",
      "        [-0.4948,  0.8397, -0.6195],\n",
      "        [-2.0422,  0.7085,  1.0508],\n",
      "        [-0.3262,  0.4632, -0.4354],\n",
      "        [-2.4930,  1.3647,  0.6164],\n",
      "        [ 0.4091, -0.0455, -0.8811],\n",
      "        [-1.9165,  1.5976, -0.2146],\n",
      "        [-1.9766,  1.2294,  0.4164],\n",
      "        [ 0.0040,  0.4809, -0.7295],\n",
      "        [-2.0419,  1.2230,  0.5695],\n",
      "        [-1.8514,  1.3950, -0.1196],\n",
      "        [ 0.5184,  0.0813, -0.9102],\n",
      "        [-1.9056,  0.7753,  0.9141],\n",
      "        [-1.8222,  0.7731,  0.9787],\n",
      "        [-1.6657,  1.5609,  0.0198]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7993,  1.4972,  0.0309],\n",
      "        [-2.2965,  1.1838,  0.6829],\n",
      "        [-0.4948,  0.8397, -0.6195],\n",
      "        [-2.0422,  0.7085,  1.0508],\n",
      "        [-0.3262,  0.4632, -0.4354],\n",
      "        [-2.4930,  1.3647,  0.6164],\n",
      "        [ 0.4091, -0.0455, -0.8811],\n",
      "        [-1.9165,  1.5976, -0.2146],\n",
      "        [-1.9766,  1.2294,  0.4164],\n",
      "        [ 0.0040,  0.4809, -0.7295],\n",
      "        [-2.0419,  1.2230,  0.5695],\n",
      "        [-1.8514,  1.3950, -0.1196],\n",
      "        [ 0.5184,  0.0813, -0.9102],\n",
      "        [-1.9056,  0.7753,  0.9141],\n",
      "        [-1.8222,  0.7731,  0.9787],\n",
      "        [-1.6657,  1.5609,  0.0198]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3968,  1.2937, -0.1311],\n",
      "        [-2.0710,  1.0570,  0.4677],\n",
      "        [-1.4146,  1.3578, -0.1908],\n",
      "        [-1.8834,  0.6231,  0.8630],\n",
      "        [-1.5718,  1.1395, -0.1479],\n",
      "        [-2.0315,  1.6150,  0.2095],\n",
      "        [-1.7276,  0.2971,  0.9305],\n",
      "        [-1.8157,  1.5717,  0.0592],\n",
      "        [-1.2067,  1.6200, -0.2811],\n",
      "        [-1.2935,  0.7521,  0.2244],\n",
      "        [-1.5258,  1.3332, -0.1748],\n",
      "        [-1.6795,  1.2923,  0.2303],\n",
      "        [-2.2193,  0.9275,  1.0426],\n",
      "        [-0.8913,  1.1886, -0.8016],\n",
      "        [-1.7305,  1.3322,  0.1728],\n",
      "        [-1.5796,  0.7858,  0.2914]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3968,  1.2937, -0.1311],\n",
      "        [-2.0710,  1.0570,  0.4677],\n",
      "        [-1.4146,  1.3578, -0.1908],\n",
      "        [-1.8834,  0.6231,  0.8630],\n",
      "        [-1.5718,  1.1395, -0.1479],\n",
      "        [-2.0315,  1.6150,  0.2095],\n",
      "        [-1.7276,  0.2971,  0.9305],\n",
      "        [-1.8157,  1.5717,  0.0592],\n",
      "        [-1.2067,  1.6200, -0.2811],\n",
      "        [-1.2935,  0.7521,  0.2244],\n",
      "        [-1.5258,  1.3332, -0.1748],\n",
      "        [-1.6795,  1.2923,  0.2303],\n",
      "        [-2.2193,  0.9275,  1.0426],\n",
      "        [-0.8913,  1.1886, -0.8016],\n",
      "        [-1.7305,  1.3322,  0.1728],\n",
      "        [-1.5796,  0.7858,  0.2914]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.2949, -0.0353, -0.9060],\n",
      "        [-1.4809,  1.2609,  0.0080],\n",
      "        [-2.1235,  1.5603,  0.3231],\n",
      "        [-1.9352,  1.5274,  0.0348],\n",
      "        [-1.8600,  1.5229,  0.1648],\n",
      "        [-1.9876,  1.3464,  0.2469],\n",
      "        [-1.8078,  0.9841,  0.5350],\n",
      "        [-1.6115,  1.2840, -0.0586],\n",
      "        [-1.8178,  1.3468,  0.3814],\n",
      "        [ 0.2792,  0.1360, -0.9413],\n",
      "        [-1.9685,  0.5677,  1.1617],\n",
      "        [-2.0464,  0.9119,  0.7198],\n",
      "        [ 0.2926,  0.1165, -0.9106],\n",
      "        [-1.5272,  1.2775, -0.1740],\n",
      "        [-1.7108,  1.2761,  0.1806],\n",
      "        [-1.9620,  1.4867,  0.0507]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.2949, -0.0353, -0.9060],\n",
      "        [-1.4809,  1.2609,  0.0080],\n",
      "        [-2.1235,  1.5603,  0.3231],\n",
      "        [-1.9352,  1.5274,  0.0348],\n",
      "        [-1.8600,  1.5229,  0.1648],\n",
      "        [-1.9876,  1.3464,  0.2469],\n",
      "        [-1.8078,  0.9841,  0.5350],\n",
      "        [-1.6115,  1.2840, -0.0586],\n",
      "        [-1.8178,  1.3468,  0.3814],\n",
      "        [ 0.2792,  0.1360, -0.9413],\n",
      "        [-1.9685,  0.5677,  1.1617],\n",
      "        [-2.0464,  0.9119,  0.7198],\n",
      "        [ 0.2926,  0.1165, -0.9106],\n",
      "        [-1.5272,  1.2775, -0.1740],\n",
      "        [-1.7108,  1.2761,  0.1806],\n",
      "        [-1.9620,  1.4867,  0.0507]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.1328,  0.1523, -0.6214],\n",
      "        [-1.7005,  1.3099,  0.2880],\n",
      "        [-1.8501,  0.5710,  0.9457],\n",
      "        [-2.0052,  0.5493,  1.0234],\n",
      "        [-1.8300,  0.7927,  0.8858],\n",
      "        [-1.3701,  0.7549,  0.3592],\n",
      "        [-2.0148,  1.2070,  0.2099],\n",
      "        [-1.2903,  1.2003, -0.0716],\n",
      "        [-2.0446,  0.5562,  0.8467],\n",
      "        [-1.7712,  1.9766, -0.0951],\n",
      "        [ 0.2980,  0.2074, -0.9178],\n",
      "        [-2.0644,  1.5834,  0.1297],\n",
      "        [-2.0355,  1.5966,  0.1695],\n",
      "        [-2.0816,  1.1746,  0.3903],\n",
      "        [-1.7721,  1.3085,  0.0588],\n",
      "        [ 0.3750,  0.0516, -0.8968]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.1328,  0.1523, -0.6214],\n",
      "        [-1.7005,  1.3099,  0.2880],\n",
      "        [-1.8501,  0.5710,  0.9457],\n",
      "        [-2.0052,  0.5493,  1.0234],\n",
      "        [-1.8300,  0.7927,  0.8858],\n",
      "        [-1.3701,  0.7549,  0.3592],\n",
      "        [-2.0148,  1.2070,  0.2099],\n",
      "        [-1.2903,  1.2003, -0.0716],\n",
      "        [-2.0446,  0.5562,  0.8467],\n",
      "        [-1.7712,  1.9766, -0.0951],\n",
      "        [ 0.2980,  0.2074, -0.9178],\n",
      "        [-2.0644,  1.5834,  0.1297],\n",
      "        [-2.0355,  1.5966,  0.1695],\n",
      "        [-2.0816,  1.1746,  0.3903],\n",
      "        [-1.7721,  1.3085,  0.0588],\n",
      "        [ 0.3750,  0.0516, -0.8968]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1491e+00,  1.6023e+00,  1.3924e-01],\n",
      "        [-1.9703e+00,  1.2094e+00,  6.4100e-01],\n",
      "        [-1.4648e+00,  1.4833e+00, -9.2048e-03],\n",
      "        [-1.5037e+00,  1.4628e+00, -1.0687e-01],\n",
      "        [-1.7461e+00,  1.6036e+00,  3.2691e-01],\n",
      "        [-1.4136e+00,  1.4119e+00, -3.1461e-01],\n",
      "        [-1.8982e+00,  4.0869e-01,  9.6476e-01],\n",
      "        [-1.4748e+00,  1.4360e+00,  9.4396e-04],\n",
      "        [-1.8026e+00,  6.3234e-01,  1.1372e+00],\n",
      "        [-2.0506e+00,  9.6225e-01,  5.4069e-01],\n",
      "        [-1.2849e+00,  1.2566e+00, -2.4742e-01],\n",
      "        [-1.5317e+00,  1.7782e+00, -4.2399e-01],\n",
      "        [-1.4349e+00,  1.1619e+00, -6.1875e-02],\n",
      "        [-1.8628e+00,  1.4725e+00,  1.2070e-01],\n",
      "        [-1.9454e+00,  3.2478e-01,  9.1072e-01],\n",
      "        [-2.0558e+00,  1.3191e+00,  3.5409e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.1491e+00,  1.6023e+00,  1.3924e-01],\n",
      "        [-1.9703e+00,  1.2094e+00,  6.4100e-01],\n",
      "        [-1.4648e+00,  1.4833e+00, -9.2048e-03],\n",
      "        [-1.5037e+00,  1.4628e+00, -1.0687e-01],\n",
      "        [-1.7461e+00,  1.6036e+00,  3.2691e-01],\n",
      "        [-1.4136e+00,  1.4119e+00, -3.1461e-01],\n",
      "        [-1.8982e+00,  4.0869e-01,  9.6476e-01],\n",
      "        [-1.4748e+00,  1.4360e+00,  9.4396e-04],\n",
      "        [-1.8026e+00,  6.3234e-01,  1.1372e+00],\n",
      "        [-2.0506e+00,  9.6225e-01,  5.4069e-01],\n",
      "        [-1.2849e+00,  1.2566e+00, -2.4742e-01],\n",
      "        [-1.5317e+00,  1.7782e+00, -4.2399e-01],\n",
      "        [-1.4349e+00,  1.1619e+00, -6.1875e-02],\n",
      "        [-1.8628e+00,  1.4725e+00,  1.2070e-01],\n",
      "        [-1.9454e+00,  3.2478e-01,  9.1072e-01],\n",
      "        [-2.0558e+00,  1.3191e+00,  3.5409e-01]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5407,  1.0414,  0.1383],\n",
      "        [-2.0983,  1.4852,  0.2083],\n",
      "        [-1.9726,  1.5567,  0.1756],\n",
      "        [-1.5318,  1.2376, -0.0421],\n",
      "        [-1.7535,  1.3428,  0.2127],\n",
      "        [-1.7863,  1.5544,  0.0601],\n",
      "        [-2.0149,  0.7828,  0.7990],\n",
      "        [-1.8073,  1.5522, -0.0114],\n",
      "        [-1.6612,  1.4085,  0.1592],\n",
      "        [-1.7907,  1.3830,  0.0553],\n",
      "        [-1.4371,  1.2280, -0.1564],\n",
      "        [-1.7240,  0.7384,  0.7239],\n",
      "        [-1.6621,  1.4913, -0.2311],\n",
      "        [-1.4830,  1.2453, -0.2940],\n",
      "        [ 0.4539, -0.1449, -0.7420],\n",
      "        [-1.4559,  1.1877,  0.1413]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5407,  1.0414,  0.1383],\n",
      "        [-2.0983,  1.4852,  0.2083],\n",
      "        [-1.9726,  1.5567,  0.1756],\n",
      "        [-1.5318,  1.2376, -0.0421],\n",
      "        [-1.7535,  1.3428,  0.2127],\n",
      "        [-1.7863,  1.5544,  0.0601],\n",
      "        [-2.0149,  0.7828,  0.7990],\n",
      "        [-1.8073,  1.5522, -0.0114],\n",
      "        [-1.6612,  1.4085,  0.1592],\n",
      "        [-1.7907,  1.3830,  0.0553],\n",
      "        [-1.4371,  1.2280, -0.1564],\n",
      "        [-1.7240,  0.7384,  0.7239],\n",
      "        [-1.6621,  1.4913, -0.2311],\n",
      "        [-1.4830,  1.2453, -0.2940],\n",
      "        [ 0.4539, -0.1449, -0.7420],\n",
      "        [-1.4559,  1.1877,  0.1413]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9768,  0.4685,  1.0646],\n",
      "        [-1.8344,  1.3127,  0.0957],\n",
      "        [-1.7173,  1.3740, -0.0447],\n",
      "        [-1.0946,  1.2646, -0.2473],\n",
      "        [ 0.2397, -0.0587, -0.8147],\n",
      "        [-1.7795,  0.8479,  0.7190],\n",
      "        [-1.9804,  0.6084,  1.2400],\n",
      "        [-1.7694,  1.3991, -0.0653],\n",
      "        [-1.7685,  0.4952,  0.8929],\n",
      "        [-1.8329,  0.4614,  1.1261],\n",
      "        [-1.3426,  1.2483, -0.0406],\n",
      "        [-1.8782,  1.4180,  0.0205],\n",
      "        [-1.7436,  1.4271, -0.0123],\n",
      "        [-1.9834,  0.9168,  0.7730],\n",
      "        [-2.0323,  0.5325,  1.0357],\n",
      "        [-1.6242,  1.7057, -0.0417]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9768,  0.4685,  1.0646],\n",
      "        [-1.8344,  1.3127,  0.0957],\n",
      "        [-1.7173,  1.3740, -0.0447],\n",
      "        [-1.0946,  1.2646, -0.2473],\n",
      "        [ 0.2397, -0.0587, -0.8147],\n",
      "        [-1.7795,  0.8479,  0.7190],\n",
      "        [-1.9804,  0.6084,  1.2400],\n",
      "        [-1.7694,  1.3991, -0.0653],\n",
      "        [-1.7685,  0.4952,  0.8929],\n",
      "        [-1.8329,  0.4614,  1.1261],\n",
      "        [-1.3426,  1.2483, -0.0406],\n",
      "        [-1.8782,  1.4180,  0.0205],\n",
      "        [-1.7436,  1.4271, -0.0123],\n",
      "        [-1.9834,  0.9168,  0.7730],\n",
      "        [-2.0323,  0.5325,  1.0357],\n",
      "        [-1.6242,  1.7057, -0.0417]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1737,  0.5648,  1.1256],\n",
      "        [ 0.1421,  0.4352, -0.7538],\n",
      "        [-0.3496,  0.8832, -0.9682],\n",
      "        [-1.7526,  0.8965,  0.6240],\n",
      "        [-1.5874,  1.0301,  0.0455],\n",
      "        [-1.6969,  0.6895,  0.8503],\n",
      "        [-1.0139,  0.9557,  0.0159],\n",
      "        [-1.4640,  1.6553, -0.2845],\n",
      "        [ 0.3993,  0.0773, -0.7615],\n",
      "        [ 0.4883, -0.0489, -0.8049],\n",
      "        [-1.9863,  1.1868,  0.4008],\n",
      "        [-1.5445,  1.4678, -0.0084],\n",
      "        [-1.7052,  0.5622,  0.9239],\n",
      "        [-2.3387,  0.8512,  1.0229],\n",
      "        [-1.8207,  1.0305,  0.3225],\n",
      "        [-1.6242,  1.1162, -0.0694]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.1737,  0.5648,  1.1256],\n",
      "        [ 0.1421,  0.4352, -0.7538],\n",
      "        [-0.3496,  0.8832, -0.9682],\n",
      "        [-1.7526,  0.8965,  0.6240],\n",
      "        [-1.5874,  1.0301,  0.0455],\n",
      "        [-1.6969,  0.6895,  0.8503],\n",
      "        [-1.0139,  0.9557,  0.0159],\n",
      "        [-1.4640,  1.6553, -0.2845],\n",
      "        [ 0.3993,  0.0773, -0.7615],\n",
      "        [ 0.4883, -0.0489, -0.8049],\n",
      "        [-1.9863,  1.1868,  0.4008],\n",
      "        [-1.5445,  1.4678, -0.0084],\n",
      "        [-1.7052,  0.5622,  0.9239],\n",
      "        [-2.3387,  0.8512,  1.0229],\n",
      "        [-1.8207,  1.0305,  0.3225],\n",
      "        [-1.6242,  1.1162, -0.0694]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.0788,  1.3498, -0.4431],\n",
      "        [-1.7284,  1.6353, -0.3045],\n",
      "        [-1.5816,  1.5156, -0.1686],\n",
      "        [-1.6171,  1.1364,  0.3574],\n",
      "        [-1.5271,  1.4904,  0.0419],\n",
      "        [-1.8009,  0.3849,  0.9977],\n",
      "        [-1.5553,  1.4328, -0.1645],\n",
      "        [ 0.6359, -0.0747, -0.8079],\n",
      "        [-1.3873,  1.2456, -0.2708],\n",
      "        [-1.5880,  1.2441, -0.1748],\n",
      "        [-1.5231,  0.3273,  1.1142],\n",
      "        [-1.3785,  1.1645, -0.3824],\n",
      "        [-1.8323,  0.5910,  0.7492],\n",
      "        [-1.5661,  1.4215, -0.0129],\n",
      "        [-1.5611,  0.3172,  0.8050],\n",
      "        [-1.8986,  0.7828,  0.7348]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.0788,  1.3498, -0.4431],\n",
      "        [-1.7284,  1.6353, -0.3045],\n",
      "        [-1.5816,  1.5156, -0.1686],\n",
      "        [-1.6171,  1.1364,  0.3574],\n",
      "        [-1.5271,  1.4904,  0.0419],\n",
      "        [-1.8009,  0.3849,  0.9977],\n",
      "        [-1.5553,  1.4328, -0.1645],\n",
      "        [ 0.6359, -0.0747, -0.8079],\n",
      "        [-1.3873,  1.2456, -0.2708],\n",
      "        [-1.5880,  1.2441, -0.1748],\n",
      "        [-1.5231,  0.3273,  1.1142],\n",
      "        [-1.3785,  1.1645, -0.3824],\n",
      "        [-1.8323,  0.5910,  0.7492],\n",
      "        [-1.5661,  1.4215, -0.0129],\n",
      "        [-1.5611,  0.3172,  0.8050],\n",
      "        [-1.8986,  0.7828,  0.7348]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5079e+00,  1.3078e+00, -2.3452e-01],\n",
      "        [-1.8150e+00,  9.5841e-01,  6.3561e-01],\n",
      "        [-1.7785e+00,  1.5858e+00, -4.6734e-01],\n",
      "        [-1.8000e-03,  4.4577e-01, -1.0783e+00],\n",
      "        [-2.0593e+00,  1.0961e+00,  3.7491e-01],\n",
      "        [-1.7226e+00,  1.4564e+00, -3.3064e-02],\n",
      "        [-1.9063e+00,  3.9351e-01,  1.0155e+00],\n",
      "        [-1.6079e+00,  1.3672e+00, -1.0490e-01],\n",
      "        [-1.1492e+00,  5.7279e-01,  4.8708e-01],\n",
      "        [-1.4987e+00,  1.4578e+00, -2.3348e-01],\n",
      "        [ 3.5714e-01,  3.6234e-02, -7.6356e-01],\n",
      "        [-1.1463e+00,  1.3023e+00, -3.0967e-01],\n",
      "        [-1.7336e+00,  1.5910e+00, -9.6977e-02],\n",
      "        [-1.5392e+00,  1.2648e+00, -2.6235e-01],\n",
      "        [-1.5006e+00,  1.3090e+00, -8.5506e-02],\n",
      "        [-1.6735e+00,  1.5506e+00,  5.2781e-02]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5079e+00,  1.3078e+00, -2.3452e-01],\n",
      "        [-1.8150e+00,  9.5841e-01,  6.3561e-01],\n",
      "        [-1.7785e+00,  1.5858e+00, -4.6734e-01],\n",
      "        [-1.8000e-03,  4.4577e-01, -1.0783e+00],\n",
      "        [-2.0593e+00,  1.0961e+00,  3.7491e-01],\n",
      "        [-1.7226e+00,  1.4564e+00, -3.3064e-02],\n",
      "        [-1.9063e+00,  3.9351e-01,  1.0155e+00],\n",
      "        [-1.6079e+00,  1.3672e+00, -1.0490e-01],\n",
      "        [-1.1492e+00,  5.7279e-01,  4.8708e-01],\n",
      "        [-1.4987e+00,  1.4578e+00, -2.3348e-01],\n",
      "        [ 3.5714e-01,  3.6234e-02, -7.6356e-01],\n",
      "        [-1.1463e+00,  1.3023e+00, -3.0967e-01],\n",
      "        [-1.7336e+00,  1.5910e+00, -9.6977e-02],\n",
      "        [-1.5392e+00,  1.2648e+00, -2.6235e-01],\n",
      "        [-1.5006e+00,  1.3090e+00, -8.5506e-02],\n",
      "        [-1.6735e+00,  1.5506e+00,  5.2781e-02]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9921,  0.6428,  1.0531],\n",
      "        [-1.5763,  0.7289,  0.5339],\n",
      "        [-1.7620,  1.4955, -0.1881],\n",
      "        [-1.0096,  0.5677,  0.4178],\n",
      "        [-1.8416,  1.1750,  0.3888],\n",
      "        [-1.4494,  1.6961, -0.1015],\n",
      "        [ 0.3821,  0.1131, -0.9870],\n",
      "        [-1.7396,  0.9662,  0.7546],\n",
      "        [-1.9888,  0.7874,  1.0579],\n",
      "        [-2.0298,  0.6453,  1.0247],\n",
      "        [-0.1842,  0.3841, -0.5891],\n",
      "        [-0.2711,  0.4382, -0.6806],\n",
      "        [-1.7888,  0.9493,  0.3755],\n",
      "        [-2.0058,  1.3055,  0.4174],\n",
      "        [-1.9908,  1.7281, -0.2262],\n",
      "        [-0.2562,  0.8534, -0.9246]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9921,  0.6428,  1.0531],\n",
      "        [-1.5763,  0.7289,  0.5339],\n",
      "        [-1.7620,  1.4955, -0.1881],\n",
      "        [-1.0096,  0.5677,  0.4178],\n",
      "        [-1.8416,  1.1750,  0.3888],\n",
      "        [-1.4494,  1.6961, -0.1015],\n",
      "        [ 0.3821,  0.1131, -0.9870],\n",
      "        [-1.7396,  0.9662,  0.7546],\n",
      "        [-1.9888,  0.7874,  1.0579],\n",
      "        [-2.0298,  0.6453,  1.0247],\n",
      "        [-0.1842,  0.3841, -0.5891],\n",
      "        [-0.2711,  0.4382, -0.6806],\n",
      "        [-1.7888,  0.9493,  0.3755],\n",
      "        [-2.0058,  1.3055,  0.4174],\n",
      "        [-1.9908,  1.7281, -0.2262],\n",
      "        [-0.2562,  0.8534, -0.9246]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1137,  0.8680,  0.7887],\n",
      "        [-1.2522,  1.7719, -0.5970],\n",
      "        [-0.9590,  1.1587, -0.5103],\n",
      "        [ 0.4810,  0.0121, -0.9518],\n",
      "        [-2.0209,  0.8255,  0.9415],\n",
      "        [-2.2026,  0.8294,  0.7599],\n",
      "        [-1.4433,  1.4290, -0.2851],\n",
      "        [-1.5034,  1.5639, -0.3057],\n",
      "        [-1.7964,  0.5156,  0.7872],\n",
      "        [-1.9176,  1.1608,  0.3990],\n",
      "        [-0.9095,  0.4037,  0.0771],\n",
      "        [-1.3564,  1.6000, -0.5386],\n",
      "        [-1.2227,  1.4191, -0.4720],\n",
      "        [-2.2992,  0.8093,  0.9689],\n",
      "        [-1.5961,  1.5755, -0.0728],\n",
      "        [-1.5428,  1.7438, -0.4588]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.1137,  0.8680,  0.7887],\n",
      "        [-1.2522,  1.7719, -0.5970],\n",
      "        [-0.9590,  1.1587, -0.5103],\n",
      "        [ 0.4810,  0.0121, -0.9518],\n",
      "        [-2.0209,  0.8255,  0.9415],\n",
      "        [-2.2026,  0.8294,  0.7599],\n",
      "        [-1.4433,  1.4290, -0.2851],\n",
      "        [-1.5034,  1.5639, -0.3057],\n",
      "        [-1.7964,  0.5156,  0.7872],\n",
      "        [-1.9176,  1.1608,  0.3990],\n",
      "        [-0.9095,  0.4037,  0.0771],\n",
      "        [-1.3564,  1.6000, -0.5386],\n",
      "        [-1.2227,  1.4191, -0.4720],\n",
      "        [-2.2992,  0.8093,  0.9689],\n",
      "        [-1.5961,  1.5755, -0.0728],\n",
      "        [-1.5428,  1.7438, -0.4588]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3182,  1.4718, -0.4840],\n",
      "        [-1.6578,  0.4504,  1.0398],\n",
      "        [-0.3365,  0.9701, -0.9505],\n",
      "        [-1.4502,  1.4528, -0.4804],\n",
      "        [-1.7047,  1.7349, -0.1063],\n",
      "        [-1.8092,  1.5350, -0.0317],\n",
      "        [-1.6429,  1.5502, -0.2956],\n",
      "        [-1.6288,  1.6832, -0.3330],\n",
      "        [-1.5050,  1.4516, -0.4750],\n",
      "        [-1.8896,  1.6108,  0.1082],\n",
      "        [ 0.4013, -0.1751, -0.8057],\n",
      "        [ 0.5431, -0.1449, -0.8332],\n",
      "        [-1.4239,  1.8479, -0.6227],\n",
      "        [-1.9517,  1.3757,  0.4420],\n",
      "        [-2.2041,  1.2647,  0.6167],\n",
      "        [-1.5313,  1.7563, -0.4046]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3182,  1.4718, -0.4840],\n",
      "        [-1.6578,  0.4504,  1.0398],\n",
      "        [-0.3365,  0.9701, -0.9505],\n",
      "        [-1.4502,  1.4528, -0.4804],\n",
      "        [-1.7047,  1.7349, -0.1063],\n",
      "        [-1.8092,  1.5350, -0.0317],\n",
      "        [-1.6429,  1.5502, -0.2956],\n",
      "        [-1.6288,  1.6832, -0.3330],\n",
      "        [-1.5050,  1.4516, -0.4750],\n",
      "        [-1.8896,  1.6108,  0.1082],\n",
      "        [ 0.4013, -0.1751, -0.8057],\n",
      "        [ 0.5431, -0.1449, -0.8332],\n",
      "        [-1.4239,  1.8479, -0.6227],\n",
      "        [-1.9517,  1.3757,  0.4420],\n",
      "        [-2.2041,  1.2647,  0.6167],\n",
      "        [-1.5313,  1.7563, -0.4046]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1388,  0.5726,  0.8874],\n",
      "        [-2.0844,  1.2122,  0.6429],\n",
      "        [-1.7374,  1.8250, -0.3420],\n",
      "        [-1.7339,  1.4185, -0.2247],\n",
      "        [-1.3862,  1.3636, -0.1346],\n",
      "        [-2.0508,  0.9189,  0.9852],\n",
      "        [-1.6760,  1.8324, -0.3263],\n",
      "        [-1.4415,  0.9347,  0.2968],\n",
      "        [-1.3623,  1.7185, -0.3968],\n",
      "        [-1.9083,  0.4426,  0.9361],\n",
      "        [-1.3277,  1.4158, -0.5804],\n",
      "        [ 0.3070,  0.1045, -0.7338],\n",
      "        [-2.1357,  0.8213,  0.7372],\n",
      "        [-2.1458,  0.7162,  1.1041],\n",
      "        [-1.5214,  1.9138, -0.7235],\n",
      "        [-1.9563,  0.7940,  0.7403]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.1388,  0.5726,  0.8874],\n",
      "        [-2.0844,  1.2122,  0.6429],\n",
      "        [-1.7374,  1.8250, -0.3420],\n",
      "        [-1.7339,  1.4185, -0.2247],\n",
      "        [-1.3862,  1.3636, -0.1346],\n",
      "        [-2.0508,  0.9189,  0.9852],\n",
      "        [-1.6760,  1.8324, -0.3263],\n",
      "        [-1.4415,  0.9347,  0.2968],\n",
      "        [-1.3623,  1.7185, -0.3968],\n",
      "        [-1.9083,  0.4426,  0.9361],\n",
      "        [-1.3277,  1.4158, -0.5804],\n",
      "        [ 0.3070,  0.1045, -0.7338],\n",
      "        [-2.1357,  0.8213,  0.7372],\n",
      "        [-2.1458,  0.7162,  1.1041],\n",
      "        [-1.5214,  1.9138, -0.7235],\n",
      "        [-1.9563,  0.7940,  0.7403]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-8.6856e-01,  1.1573e+00, -5.6783e-01],\n",
      "        [-1.5464e+00,  2.0306e+00, -6.6507e-01],\n",
      "        [-1.9758e+00,  6.8754e-01,  8.9163e-01],\n",
      "        [-1.6067e+00,  1.7873e+00, -4.2124e-01],\n",
      "        [-1.5996e+00,  1.9108e+00, -4.2811e-01],\n",
      "        [-1.3531e+00,  1.3971e+00, -2.7992e-01],\n",
      "        [-1.4715e+00,  1.6595e+00, -3.8446e-01],\n",
      "        [-1.5467e+00,  1.8954e+00, -5.1558e-01],\n",
      "        [-1.5699e+00,  1.8837e+00, -5.0411e-01],\n",
      "        [-1.8503e+00,  4.2376e-01,  8.7642e-01],\n",
      "        [-1.7031e+00,  1.6881e+00, -4.4424e-01],\n",
      "        [-1.2198e+00,  1.5837e+00, -5.8833e-01],\n",
      "        [ 4.5165e-01, -2.6162e-01, -8.4401e-01],\n",
      "        [-1.8483e+00,  8.3531e-01,  9.1635e-01],\n",
      "        [-2.0430e+00,  1.8047e+00, -7.5335e-04],\n",
      "        [ 3.6482e-01, -1.6390e-02, -8.5745e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-8.6856e-01,  1.1573e+00, -5.6783e-01],\n",
      "        [-1.5464e+00,  2.0306e+00, -6.6507e-01],\n",
      "        [-1.9758e+00,  6.8754e-01,  8.9163e-01],\n",
      "        [-1.6067e+00,  1.7873e+00, -4.2124e-01],\n",
      "        [-1.5996e+00,  1.9108e+00, -4.2811e-01],\n",
      "        [-1.3531e+00,  1.3971e+00, -2.7992e-01],\n",
      "        [-1.4715e+00,  1.6595e+00, -3.8446e-01],\n",
      "        [-1.5467e+00,  1.8954e+00, -5.1558e-01],\n",
      "        [-1.5699e+00,  1.8837e+00, -5.0411e-01],\n",
      "        [-1.8503e+00,  4.2376e-01,  8.7642e-01],\n",
      "        [-1.7031e+00,  1.6881e+00, -4.4424e-01],\n",
      "        [-1.2198e+00,  1.5837e+00, -5.8833e-01],\n",
      "        [ 4.5165e-01, -2.6162e-01, -8.4401e-01],\n",
      "        [-1.8483e+00,  8.3531e-01,  9.1635e-01],\n",
      "        [-2.0430e+00,  1.8047e+00, -7.5335e-04],\n",
      "        [ 3.6482e-01, -1.6390e-02, -8.5745e-01]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6544,  1.8535, -0.4945],\n",
      "        [-1.1878,  1.6785, -0.6321],\n",
      "        [-1.1818,  1.6488, -0.7015],\n",
      "        [-1.4733,  1.6549, -0.5889],\n",
      "        [-2.0264,  0.6995,  1.2920],\n",
      "        [-1.4492,  1.6586, -0.5599],\n",
      "        [-2.0001,  1.9980, -0.1133],\n",
      "        [-1.8767,  1.0885,  0.4290],\n",
      "        [-2.3973,  0.8504,  0.8332],\n",
      "        [ 0.0591,  0.3409, -1.1022],\n",
      "        [-1.6742,  1.4985, -0.3419],\n",
      "        [ 0.4581,  0.0165, -0.8839],\n",
      "        [-1.6270,  1.8441, -0.3937],\n",
      "        [-1.7463,  2.1133, -0.3617],\n",
      "        [-1.6944,  1.9498, -0.5383],\n",
      "        [-1.9741,  0.5385,  1.1724]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6544,  1.8535, -0.4945],\n",
      "        [-1.1878,  1.6785, -0.6321],\n",
      "        [-1.1818,  1.6488, -0.7015],\n",
      "        [-1.4733,  1.6549, -0.5889],\n",
      "        [-2.0264,  0.6995,  1.2920],\n",
      "        [-1.4492,  1.6586, -0.5599],\n",
      "        [-2.0001,  1.9980, -0.1133],\n",
      "        [-1.8767,  1.0885,  0.4290],\n",
      "        [-2.3973,  0.8504,  0.8332],\n",
      "        [ 0.0591,  0.3409, -1.1022],\n",
      "        [-1.6742,  1.4985, -0.3419],\n",
      "        [ 0.4581,  0.0165, -0.8839],\n",
      "        [-1.6270,  1.8441, -0.3937],\n",
      "        [-1.7463,  2.1133, -0.3617],\n",
      "        [-1.6944,  1.9498, -0.5383],\n",
      "        [-1.9741,  0.5385,  1.1724]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5862,  1.8999, -0.6431],\n",
      "        [-1.5350,  1.8016, -0.6835],\n",
      "        [-1.7012,  2.0044, -0.5496],\n",
      "        [-1.6136,  0.6939,  0.7041],\n",
      "        [-1.5693,  1.9624, -0.6860],\n",
      "        [-0.9912,  1.4020, -0.5953],\n",
      "        [-2.0727,  0.8789,  0.8825],\n",
      "        [-0.1632,  0.8487, -0.9523],\n",
      "        [-1.9803,  1.1531,  0.5635],\n",
      "        [-1.9623,  1.5840,  0.2248],\n",
      "        [-1.5543,  1.6778, -0.4196],\n",
      "        [-1.2098,  1.9101, -0.5590],\n",
      "        [-1.6546,  2.0642, -0.5407],\n",
      "        [-1.5954,  1.8011, -0.4328],\n",
      "        [-2.3328,  1.2203,  0.8169],\n",
      "        [-1.6797,  1.7047, -0.4260]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5862,  1.8999, -0.6431],\n",
      "        [-1.5350,  1.8016, -0.6835],\n",
      "        [-1.7012,  2.0044, -0.5496],\n",
      "        [-1.6136,  0.6939,  0.7041],\n",
      "        [-1.5693,  1.9624, -0.6860],\n",
      "        [-0.9912,  1.4020, -0.5953],\n",
      "        [-2.0727,  0.8789,  0.8825],\n",
      "        [-0.1632,  0.8487, -0.9523],\n",
      "        [-1.9803,  1.1531,  0.5635],\n",
      "        [-1.9623,  1.5840,  0.2248],\n",
      "        [-1.5543,  1.6778, -0.4196],\n",
      "        [-1.2098,  1.9101, -0.5590],\n",
      "        [-1.6546,  2.0642, -0.5407],\n",
      "        [-1.5954,  1.8011, -0.4328],\n",
      "        [-2.3328,  1.2203,  0.8169],\n",
      "        [-1.6797,  1.7047, -0.4260]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7755,  2.0310, -0.6466],\n",
      "        [-2.0988,  0.6301,  0.9343],\n",
      "        [-2.0365,  0.7374,  1.0580],\n",
      "        [-2.2198,  1.2184,  0.7729],\n",
      "        [-1.3825,  2.0417, -0.6671],\n",
      "        [-1.5647,  1.9811, -0.6021],\n",
      "        [-1.3604,  1.9081, -0.7679],\n",
      "        [-1.1728,  1.7514, -0.9326],\n",
      "        [-1.8329,  0.5159,  1.0923],\n",
      "        [-1.2808,  2.0404, -0.7449],\n",
      "        [-1.7497,  1.9864, -0.6145],\n",
      "        [-1.9820,  1.2693,  0.3616],\n",
      "        [-1.4953,  1.8943, -0.7714],\n",
      "        [-2.2029,  1.2347,  0.6266],\n",
      "        [-1.8559,  1.9657, -0.0700],\n",
      "        [-1.8506,  1.9975, -0.4090]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7755,  2.0310, -0.6466],\n",
      "        [-2.0988,  0.6301,  0.9343],\n",
      "        [-2.0365,  0.7374,  1.0580],\n",
      "        [-2.2198,  1.2184,  0.7729],\n",
      "        [-1.3825,  2.0417, -0.6671],\n",
      "        [-1.5647,  1.9811, -0.6021],\n",
      "        [-1.3604,  1.9081, -0.7679],\n",
      "        [-1.1728,  1.7514, -0.9326],\n",
      "        [-1.8329,  0.5159,  1.0923],\n",
      "        [-1.2808,  2.0404, -0.7449],\n",
      "        [-1.7497,  1.9864, -0.6145],\n",
      "        [-1.9820,  1.2693,  0.3616],\n",
      "        [-1.4953,  1.8943, -0.7714],\n",
      "        [-2.2029,  1.2347,  0.6266],\n",
      "        [-1.8559,  1.9657, -0.0700],\n",
      "        [-1.8506,  1.9975, -0.4090]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1662,  0.9194,  0.8387],\n",
      "        [-1.7225,  1.8710, -0.5269],\n",
      "        [-1.6236,  1.6734, -0.6691],\n",
      "        [-1.5683,  2.1694, -0.4509],\n",
      "        [ 0.5450, -0.1945, -0.9762],\n",
      "        [-1.9859,  1.8286, -0.4169],\n",
      "        [-2.0226,  0.7053,  1.0684],\n",
      "        [-2.2198,  1.2584,  0.6168],\n",
      "        [-1.7630,  2.1677, -0.6252],\n",
      "        [-1.9490,  0.4648,  0.9805],\n",
      "        [-1.6742,  2.0480, -0.5868],\n",
      "        [-1.5876,  1.9920, -0.5716],\n",
      "        [-1.8987,  0.4519,  1.2004],\n",
      "        [-1.2649,  2.0241, -0.5878],\n",
      "        [-2.2745,  0.9281,  0.9107],\n",
      "        [-1.9323,  1.9410, -0.1991]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.1662,  0.9194,  0.8387],\n",
      "        [-1.7225,  1.8710, -0.5269],\n",
      "        [-1.6236,  1.6734, -0.6691],\n",
      "        [-1.5683,  2.1694, -0.4509],\n",
      "        [ 0.5450, -0.1945, -0.9762],\n",
      "        [-1.9859,  1.8286, -0.4169],\n",
      "        [-2.0226,  0.7053,  1.0684],\n",
      "        [-2.2198,  1.2584,  0.6168],\n",
      "        [-1.7630,  2.1677, -0.6252],\n",
      "        [-1.9490,  0.4648,  0.9805],\n",
      "        [-1.6742,  2.0480, -0.5868],\n",
      "        [-1.5876,  1.9920, -0.5716],\n",
      "        [-1.8987,  0.4519,  1.2004],\n",
      "        [-1.2649,  2.0241, -0.5878],\n",
      "        [-2.2745,  0.9281,  0.9107],\n",
      "        [-1.9323,  1.9410, -0.1991]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6660,  1.9245, -0.2870],\n",
      "        [ 0.3027,  0.1950, -0.8994],\n",
      "        [-1.5399,  2.1750, -0.8427],\n",
      "        [-2.0631,  0.5190,  1.2097],\n",
      "        [-1.4907,  2.1244, -0.8799],\n",
      "        [-1.7207,  1.6628, -0.4684],\n",
      "        [-1.6293,  2.1331, -0.6555],\n",
      "        [-2.1247,  2.0411, -0.3763],\n",
      "        [-1.7266,  0.3879,  1.2186],\n",
      "        [-1.7286,  1.8080, -0.2915],\n",
      "        [-2.0474,  0.9127,  0.5560],\n",
      "        [-1.7352,  2.1617, -0.8467],\n",
      "        [-1.5168,  1.9416, -0.6569],\n",
      "        [-1.8183,  1.9425, -0.7058],\n",
      "        [-2.0026,  1.5214,  0.3370],\n",
      "        [-1.8420,  2.0589, -0.7991]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6660,  1.9245, -0.2870],\n",
      "        [ 0.3027,  0.1950, -0.8994],\n",
      "        [-1.5399,  2.1750, -0.8427],\n",
      "        [-2.0631,  0.5190,  1.2097],\n",
      "        [-1.4907,  2.1244, -0.8799],\n",
      "        [-1.7207,  1.6628, -0.4684],\n",
      "        [-1.6293,  2.1331, -0.6555],\n",
      "        [-2.1247,  2.0411, -0.3763],\n",
      "        [-1.7266,  0.3879,  1.2186],\n",
      "        [-1.7286,  1.8080, -0.2915],\n",
      "        [-2.0474,  0.9127,  0.5560],\n",
      "        [-1.7352,  2.1617, -0.8467],\n",
      "        [-1.5168,  1.9416, -0.6569],\n",
      "        [-1.8183,  1.9425, -0.7058],\n",
      "        [-2.0026,  1.5214,  0.3370],\n",
      "        [-1.8420,  2.0589, -0.7991]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9153,  2.3404, -0.7273],\n",
      "        [-1.0373,  1.1848, -0.2490],\n",
      "        [-2.0324,  0.3404,  1.0937],\n",
      "        [-2.1150,  0.6945,  1.2505],\n",
      "        [-2.1214,  1.3041,  0.5106],\n",
      "        [ 0.4268,  0.1983, -0.8264],\n",
      "        [-1.5855,  2.0427, -0.7791],\n",
      "        [-2.2930,  1.0809,  0.6842],\n",
      "        [-1.6662,  2.2741, -0.4012],\n",
      "        [-2.1034,  1.5466,  0.4654],\n",
      "        [-1.5721,  2.1279, -0.5727],\n",
      "        [-1.6134,  2.0054, -0.5914],\n",
      "        [ 0.1168,  0.0760, -0.8486],\n",
      "        [-2.0309,  2.3420, -0.3549],\n",
      "        [-1.7609,  2.1599, -0.5959],\n",
      "        [ 0.6329,  0.0630, -1.0754]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9153,  2.3404, -0.7273],\n",
      "        [-1.0373,  1.1848, -0.2490],\n",
      "        [-2.0324,  0.3404,  1.0937],\n",
      "        [-2.1150,  0.6945,  1.2505],\n",
      "        [-2.1214,  1.3041,  0.5106],\n",
      "        [ 0.4268,  0.1983, -0.8264],\n",
      "        [-1.5855,  2.0427, -0.7791],\n",
      "        [-2.2930,  1.0809,  0.6842],\n",
      "        [-1.6662,  2.2741, -0.4012],\n",
      "        [-2.1034,  1.5466,  0.4654],\n",
      "        [-1.5721,  2.1279, -0.5727],\n",
      "        [-1.6134,  2.0054, -0.5914],\n",
      "        [ 0.1168,  0.0760, -0.8486],\n",
      "        [-2.0309,  2.3420, -0.3549],\n",
      "        [-1.7609,  2.1599, -0.5959],\n",
      "        [ 0.6329,  0.0630, -1.0754]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7369,  2.2006, -0.5638],\n",
      "        [-1.5825,  2.2225, -0.7997],\n",
      "        [-1.8406,  0.2685,  1.3754],\n",
      "        [-2.0716,  0.3122,  1.1927],\n",
      "        [-2.2060,  1.3326,  0.3272],\n",
      "        [-1.8205,  1.9720, -0.6133],\n",
      "        [-2.0689,  0.2799,  1.2989],\n",
      "        [-1.2963,  1.0412,  0.0626],\n",
      "        [-1.8471,  1.8001, -0.0923],\n",
      "        [-1.9830,  0.3317,  1.3978],\n",
      "        [-2.2451,  0.6248,  1.2195],\n",
      "        [-1.7428,  0.3233,  1.0899],\n",
      "        [-2.1035,  0.7839,  0.8624],\n",
      "        [-1.9738,  0.4983,  1.2070],\n",
      "        [-2.0980,  0.6733,  0.9699],\n",
      "        [-1.4409,  2.0261, -0.5690]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7369,  2.2006, -0.5638],\n",
      "        [-1.5825,  2.2225, -0.7997],\n",
      "        [-1.8406,  0.2685,  1.3754],\n",
      "        [-2.0716,  0.3122,  1.1927],\n",
      "        [-2.2060,  1.3326,  0.3272],\n",
      "        [-1.8205,  1.9720, -0.6133],\n",
      "        [-2.0689,  0.2799,  1.2989],\n",
      "        [-1.2963,  1.0412,  0.0626],\n",
      "        [-1.8471,  1.8001, -0.0923],\n",
      "        [-1.9830,  0.3317,  1.3978],\n",
      "        [-2.2451,  0.6248,  1.2195],\n",
      "        [-1.7428,  0.3233,  1.0899],\n",
      "        [-2.1035,  0.7839,  0.8624],\n",
      "        [-1.9738,  0.4983,  1.2070],\n",
      "        [-2.0980,  0.6733,  0.9699],\n",
      "        [-1.4409,  2.0261, -0.5690]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.1223,  0.5683, -1.0191],\n",
      "        [-1.6029,  1.6778, -0.2673],\n",
      "        [-2.0551,  1.0688,  0.3842],\n",
      "        [-1.6303,  1.7900, -0.1914],\n",
      "        [-1.9791,  2.0777, -0.5152],\n",
      "        [-2.3577,  1.3992,  0.4042],\n",
      "        [-1.8974,  2.1705, -0.5407],\n",
      "        [-1.9797,  1.8944, -0.2769],\n",
      "        [-1.1220,  1.4037, -0.6978],\n",
      "        [-1.8001,  0.2987,  1.3190],\n",
      "        [-1.6734,  0.1110,  1.2209],\n",
      "        [-2.1968,  1.7395, -0.1194],\n",
      "        [-1.6319,  2.1620, -0.3784],\n",
      "        [-1.9393,  1.6826, -0.1922],\n",
      "        [-1.8142,  0.1991,  1.0765],\n",
      "        [-1.7608,  1.8276, -0.3861]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.1223,  0.5683, -1.0191],\n",
      "        [-1.6029,  1.6778, -0.2673],\n",
      "        [-2.0551,  1.0688,  0.3842],\n",
      "        [-1.6303,  1.7900, -0.1914],\n",
      "        [-1.9791,  2.0777, -0.5152],\n",
      "        [-2.3577,  1.3992,  0.4042],\n",
      "        [-1.8974,  2.1705, -0.5407],\n",
      "        [-1.9797,  1.8944, -0.2769],\n",
      "        [-1.1220,  1.4037, -0.6978],\n",
      "        [-1.8001,  0.2987,  1.3190],\n",
      "        [-1.6734,  0.1110,  1.2209],\n",
      "        [-2.1968,  1.7395, -0.1194],\n",
      "        [-1.6319,  2.1620, -0.3784],\n",
      "        [-1.9393,  1.6826, -0.1922],\n",
      "        [-1.8142,  0.1991,  1.0765],\n",
      "        [-1.7608,  1.8276, -0.3861]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2525,  1.9500,  0.0824],\n",
      "        [-1.6989,  0.4080,  1.2108],\n",
      "        [ 0.5228, -0.2431, -0.9392],\n",
      "        [-1.8328,  2.0757, -0.5917],\n",
      "        [-2.2976,  1.7440,  0.0702],\n",
      "        [-2.1479,  1.0634,  0.8373],\n",
      "        [-2.0143,  0.3833,  1.1867],\n",
      "        [-1.9085,  2.2390, -0.4592],\n",
      "        [-2.1629,  0.9920,  0.9476],\n",
      "        [ 0.5349,  0.0084, -0.9636],\n",
      "        [-2.3796,  0.8823,  1.1376],\n",
      "        [-1.6900,  1.9783, -0.3745],\n",
      "        [-1.8757,  1.9406, -0.4491],\n",
      "        [-2.3405,  0.5084,  1.3274],\n",
      "        [-2.2817,  1.2406,  0.9789],\n",
      "        [-2.2834,  0.9956,  0.9098]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.2525,  1.9500,  0.0824],\n",
      "        [-1.6989,  0.4080,  1.2108],\n",
      "        [ 0.5228, -0.2431, -0.9392],\n",
      "        [-1.8328,  2.0757, -0.5917],\n",
      "        [-2.2976,  1.7440,  0.0702],\n",
      "        [-2.1479,  1.0634,  0.8373],\n",
      "        [-2.0143,  0.3833,  1.1867],\n",
      "        [-1.9085,  2.2390, -0.4592],\n",
      "        [-2.1629,  0.9920,  0.9476],\n",
      "        [ 0.5349,  0.0084, -0.9636],\n",
      "        [-2.3796,  0.8823,  1.1376],\n",
      "        [-1.6900,  1.9783, -0.3745],\n",
      "        [-1.8757,  1.9406, -0.4491],\n",
      "        [-2.3405,  0.5084,  1.3274],\n",
      "        [-2.2817,  1.2406,  0.9789],\n",
      "        [-2.2834,  0.9956,  0.9098]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5253,  0.5618,  0.7947],\n",
      "        [-2.2295,  0.5518,  1.4206],\n",
      "        [-2.1186,  0.2676,  1.4295],\n",
      "        [-1.3245,  1.6347, -0.7258],\n",
      "        [-2.2525,  1.7112,  0.1575],\n",
      "        [-1.6948,  2.2432, -0.6416],\n",
      "        [-0.7971,  1.1851, -0.9072],\n",
      "        [-2.3721,  0.8525,  1.0021],\n",
      "        [-1.9712,  2.2175, -0.6035],\n",
      "        [-1.7150,  2.0025, -0.7394],\n",
      "        [-2.3260,  0.6015,  1.1574],\n",
      "        [-1.7588,  2.2631, -0.5367],\n",
      "        [-2.0057,  2.3644, -0.4458],\n",
      "        [-1.9616,  1.8111,  0.1105],\n",
      "        [-1.9496,  0.1856,  1.2768],\n",
      "        [-1.9022,  1.9529, -0.0898]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5253,  0.5618,  0.7947],\n",
      "        [-2.2295,  0.5518,  1.4206],\n",
      "        [-2.1186,  0.2676,  1.4295],\n",
      "        [-1.3245,  1.6347, -0.7258],\n",
      "        [-2.2525,  1.7112,  0.1575],\n",
      "        [-1.6948,  2.2432, -0.6416],\n",
      "        [-0.7971,  1.1851, -0.9072],\n",
      "        [-2.3721,  0.8525,  1.0021],\n",
      "        [-1.9712,  2.2175, -0.6035],\n",
      "        [-1.7150,  2.0025, -0.7394],\n",
      "        [-2.3260,  0.6015,  1.1574],\n",
      "        [-1.7588,  2.2631, -0.5367],\n",
      "        [-2.0057,  2.3644, -0.4458],\n",
      "        [-1.9616,  1.8111,  0.1105],\n",
      "        [-1.9496,  0.1856,  1.2768],\n",
      "        [-1.9022,  1.9529, -0.0898]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8676,  1.9529, -0.1475],\n",
      "        [-1.6613,  0.1987,  1.0555],\n",
      "        [-1.8047,  1.6372,  0.1244],\n",
      "        [-1.9042,  0.2724,  1.3831],\n",
      "        [-2.0103,  1.9302, -0.1319],\n",
      "        [-1.6428,  1.4459, -0.0180],\n",
      "        [-1.7079,  0.0141,  1.2755],\n",
      "        [-2.0335,  0.3477,  1.3355],\n",
      "        [-1.9208,  2.1933, -0.5873],\n",
      "        [ 0.5205, -0.1913, -0.9759],\n",
      "        [-1.7763,  2.3422, -0.5123],\n",
      "        [-1.8692,  1.8066,  0.1020],\n",
      "        [-2.0480,  0.5096,  1.0585],\n",
      "        [-1.9275,  0.4160,  1.1797],\n",
      "        [-2.4385,  1.8729,  0.4027],\n",
      "        [-2.2728,  0.5007,  1.4193]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8676,  1.9529, -0.1475],\n",
      "        [-1.6613,  0.1987,  1.0555],\n",
      "        [-1.8047,  1.6372,  0.1244],\n",
      "        [-1.9042,  0.2724,  1.3831],\n",
      "        [-2.0103,  1.9302, -0.1319],\n",
      "        [-1.6428,  1.4459, -0.0180],\n",
      "        [-1.7079,  0.0141,  1.2755],\n",
      "        [-2.0335,  0.3477,  1.3355],\n",
      "        [-1.9208,  2.1933, -0.5873],\n",
      "        [ 0.5205, -0.1913, -0.9759],\n",
      "        [-1.7763,  2.3422, -0.5123],\n",
      "        [-1.8692,  1.8066,  0.1020],\n",
      "        [-2.0480,  0.5096,  1.0585],\n",
      "        [-1.9275,  0.4160,  1.1797],\n",
      "        [-2.4385,  1.8729,  0.4027],\n",
      "        [-2.2728,  0.5007,  1.4193]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8778,  2.2860, -0.4169],\n",
      "        [-2.0548,  2.2815, -0.4640],\n",
      "        [-2.1752,  0.8711,  0.9894],\n",
      "        [-2.1274,  0.3094,  1.3499],\n",
      "        [-2.2890,  0.6823,  1.1910],\n",
      "        [-1.5895,  1.6163, -0.1845],\n",
      "        [-1.7780,  2.3018, -0.7165],\n",
      "        [-2.0898,  0.4224,  1.2891],\n",
      "        [-2.0216,  0.2802,  1.2917],\n",
      "        [-2.2054,  2.5114, -0.2217],\n",
      "        [-1.8244,  2.1878, -0.3488],\n",
      "        [-2.0877,  0.4151,  1.1912],\n",
      "        [-1.7406,  2.1675, -0.6204],\n",
      "        [-1.9907,  0.3064,  1.2703],\n",
      "        [ 0.6071, -0.1726, -0.9964],\n",
      "        [-1.9411,  2.0415, -0.3128]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8778,  2.2860, -0.4169],\n",
      "        [-2.0548,  2.2815, -0.4640],\n",
      "        [-2.1752,  0.8711,  0.9894],\n",
      "        [-2.1274,  0.3094,  1.3499],\n",
      "        [-2.2890,  0.6823,  1.1910],\n",
      "        [-1.5895,  1.6163, -0.1845],\n",
      "        [-1.7780,  2.3018, -0.7165],\n",
      "        [-2.0898,  0.4224,  1.2891],\n",
      "        [-2.0216,  0.2802,  1.2917],\n",
      "        [-2.2054,  2.5114, -0.2217],\n",
      "        [-1.8244,  2.1878, -0.3488],\n",
      "        [-2.0877,  0.4151,  1.1912],\n",
      "        [-1.7406,  2.1675, -0.6204],\n",
      "        [-1.9907,  0.3064,  1.2703],\n",
      "        [ 0.6071, -0.1726, -0.9964],\n",
      "        [-1.9411,  2.0415, -0.3128]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0370,  1.9576, -0.3056],\n",
      "        [-1.8742,  0.3842,  1.2252],\n",
      "        [-1.4038,  0.3187,  0.7774],\n",
      "        [-2.1762,  0.9430,  0.8320],\n",
      "        [-2.2167,  2.2510, -0.1254],\n",
      "        [-2.1491,  1.1951,  0.8714],\n",
      "        [-2.1014,  0.3226,  1.3522],\n",
      "        [-2.0009,  2.2011, -0.5154],\n",
      "        [-1.8728,  1.8697, -0.2672],\n",
      "        [-2.0096,  0.1367,  1.3543],\n",
      "        [-1.8539,  0.1911,  1.2057],\n",
      "        [ 0.7104, -0.2528, -0.9451],\n",
      "        [-2.4961,  1.4386,  0.5706],\n",
      "        [ 0.5873,  0.0473, -1.0303],\n",
      "        [ 0.4056,  0.1446, -0.9520],\n",
      "        [-2.3111,  0.9894,  0.8609]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.0370,  1.9576, -0.3056],\n",
      "        [-1.8742,  0.3842,  1.2252],\n",
      "        [-1.4038,  0.3187,  0.7774],\n",
      "        [-2.1762,  0.9430,  0.8320],\n",
      "        [-2.2167,  2.2510, -0.1254],\n",
      "        [-2.1491,  1.1951,  0.8714],\n",
      "        [-2.1014,  0.3226,  1.3522],\n",
      "        [-2.0009,  2.2011, -0.5154],\n",
      "        [-1.8728,  1.8697, -0.2672],\n",
      "        [-2.0096,  0.1367,  1.3543],\n",
      "        [-1.8539,  0.1911,  1.2057],\n",
      "        [ 0.7104, -0.2528, -0.9451],\n",
      "        [-2.4961,  1.4386,  0.5706],\n",
      "        [ 0.5873,  0.0473, -1.0303],\n",
      "        [ 0.4056,  0.1446, -0.9520],\n",
      "        [-2.3111,  0.9894,  0.8609]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1247,  1.7233,  0.0082],\n",
      "        [-2.3489,  1.8177,  0.1136],\n",
      "        [-2.0526,  2.2546, -0.5546],\n",
      "        [-2.2089,  1.9934, -0.2681],\n",
      "        [-1.8615,  2.2031, -0.2762],\n",
      "        [-1.7446,  2.1666, -0.4608],\n",
      "        [-2.2977,  0.4530,  1.1303],\n",
      "        [-1.6877,  2.3248, -0.4361],\n",
      "        [ 0.5963, -0.2995, -1.0348],\n",
      "        [-1.5677,  1.9768, -0.2830],\n",
      "        [-1.3264,  0.2892,  0.6400],\n",
      "        [-2.1485,  2.3368, -0.5983],\n",
      "        [-2.0022,  0.4396,  1.4755],\n",
      "        [-1.6459,  1.8564, -0.3874],\n",
      "        [ 0.5530,  0.0443, -1.0194],\n",
      "        [-2.0031,  1.0935,  0.6980]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.1247,  1.7233,  0.0082],\n",
      "        [-2.3489,  1.8177,  0.1136],\n",
      "        [-2.0526,  2.2546, -0.5546],\n",
      "        [-2.2089,  1.9934, -0.2681],\n",
      "        [-1.8615,  2.2031, -0.2762],\n",
      "        [-1.7446,  2.1666, -0.4608],\n",
      "        [-2.2977,  0.4530,  1.1303],\n",
      "        [-1.6877,  2.3248, -0.4361],\n",
      "        [ 0.5963, -0.2995, -1.0348],\n",
      "        [-1.5677,  1.9768, -0.2830],\n",
      "        [-1.3264,  0.2892,  0.6400],\n",
      "        [-2.1485,  2.3368, -0.5983],\n",
      "        [-2.0022,  0.4396,  1.4755],\n",
      "        [-1.6459,  1.8564, -0.3874],\n",
      "        [ 0.5530,  0.0443, -1.0194],\n",
      "        [-2.0031,  1.0935,  0.6980]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3807,  1.7459, -0.5688],\n",
      "        [-1.9588,  1.3197,  0.2659],\n",
      "        [-2.1717,  2.3606, -0.4918],\n",
      "        [-1.4262,  1.1566,  0.0571],\n",
      "        [-2.3322,  0.8721,  1.1606],\n",
      "        [-2.2288,  2.1650, -0.1323],\n",
      "        [-2.1696,  1.0961,  0.6521],\n",
      "        [ 0.4018, -0.1310, -0.9386],\n",
      "        [-2.3438,  0.4825,  1.1914],\n",
      "        [-1.9487,  1.8441, -0.3330],\n",
      "        [ 0.3784, -0.1120, -0.7507],\n",
      "        [-2.0751,  2.1009, -0.3518],\n",
      "        [-2.3126,  1.7006,  0.2943],\n",
      "        [-2.2299,  0.7801,  1.2193],\n",
      "        [-2.3840,  1.5762,  0.4706],\n",
      "        [-1.7307,  2.2997, -0.7216]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3807,  1.7459, -0.5688],\n",
      "        [-1.9588,  1.3197,  0.2659],\n",
      "        [-2.1717,  2.3606, -0.4918],\n",
      "        [-1.4262,  1.1566,  0.0571],\n",
      "        [-2.3322,  0.8721,  1.1606],\n",
      "        [-2.2288,  2.1650, -0.1323],\n",
      "        [-2.1696,  1.0961,  0.6521],\n",
      "        [ 0.4018, -0.1310, -0.9386],\n",
      "        [-2.3438,  0.4825,  1.1914],\n",
      "        [-1.9487,  1.8441, -0.3330],\n",
      "        [ 0.3784, -0.1120, -0.7507],\n",
      "        [-2.0751,  2.1009, -0.3518],\n",
      "        [-2.3126,  1.7006,  0.2943],\n",
      "        [-2.2299,  0.7801,  1.2193],\n",
      "        [-2.3840,  1.5762,  0.4706],\n",
      "        [-1.7307,  2.2997, -0.7216]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2932,  0.4728,  1.2756],\n",
      "        [-1.9379,  2.2648, -0.7773],\n",
      "        [-1.6730,  2.3139, -0.7165],\n",
      "        [-1.9698,  2.0153, -0.2826],\n",
      "        [-2.3570,  1.3640,  0.5176],\n",
      "        [-1.7267,  1.9315, -0.2695],\n",
      "        [-2.0262,  0.7408,  1.1259],\n",
      "        [-2.0531,  1.8564, -0.0873],\n",
      "        [ 0.3132,  0.5197, -1.2896],\n",
      "        [-1.8807,  2.1038, -0.5023],\n",
      "        [ 0.2179, -0.0949, -0.8188],\n",
      "        [-2.1342,  2.2941, -0.4094],\n",
      "        [-0.8234,  1.4096, -0.7687],\n",
      "        [ 0.6757, -0.2132, -1.0098],\n",
      "        [-1.6749,  2.1626, -0.5886],\n",
      "        [-1.1521,  0.5855,  0.2175]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.2932,  0.4728,  1.2756],\n",
      "        [-1.9379,  2.2648, -0.7773],\n",
      "        [-1.6730,  2.3139, -0.7165],\n",
      "        [-1.9698,  2.0153, -0.2826],\n",
      "        [-2.3570,  1.3640,  0.5176],\n",
      "        [-1.7267,  1.9315, -0.2695],\n",
      "        [-2.0262,  0.7408,  1.1259],\n",
      "        [-2.0531,  1.8564, -0.0873],\n",
      "        [ 0.3132,  0.5197, -1.2896],\n",
      "        [-1.8807,  2.1038, -0.5023],\n",
      "        [ 0.2179, -0.0949, -0.8188],\n",
      "        [-2.1342,  2.2941, -0.4094],\n",
      "        [-0.8234,  1.4096, -0.7687],\n",
      "        [ 0.6757, -0.2132, -1.0098],\n",
      "        [-1.6749,  2.1626, -0.5886],\n",
      "        [-1.1521,  0.5855,  0.2175]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0337,  0.7201,  1.1708],\n",
      "        [-2.0802,  1.0186,  0.8903],\n",
      "        [-2.1007,  0.4318,  1.2325],\n",
      "        [ 0.4314,  0.2996, -1.0781],\n",
      "        [ 0.1483,  0.3314, -0.9179],\n",
      "        [ 0.5713,  0.0407, -1.1200],\n",
      "        [-2.0291,  2.4402, -0.6878],\n",
      "        [-1.9600,  2.0901, -0.5506],\n",
      "        [-2.0956,  0.6116,  1.0419],\n",
      "        [-1.5847,  1.7514, -0.2898],\n",
      "        [-1.7794,  2.0660, -0.6036],\n",
      "        [ 0.3921,  0.2698, -1.1496],\n",
      "        [-2.2842,  1.1252,  0.8403],\n",
      "        [-1.6681,  2.0367, -0.3749],\n",
      "        [-1.8352,  1.9309, -0.3806],\n",
      "        [-2.0917,  0.7532,  1.2962]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.0337,  0.7201,  1.1708],\n",
      "        [-2.0802,  1.0186,  0.8903],\n",
      "        [-2.1007,  0.4318,  1.2325],\n",
      "        [ 0.4314,  0.2996, -1.0781],\n",
      "        [ 0.1483,  0.3314, -0.9179],\n",
      "        [ 0.5713,  0.0407, -1.1200],\n",
      "        [-2.0291,  2.4402, -0.6878],\n",
      "        [-1.9600,  2.0901, -0.5506],\n",
      "        [-2.0956,  0.6116,  1.0419],\n",
      "        [-1.5847,  1.7514, -0.2898],\n",
      "        [-1.7794,  2.0660, -0.6036],\n",
      "        [ 0.3921,  0.2698, -1.1496],\n",
      "        [-2.2842,  1.1252,  0.8403],\n",
      "        [-1.6681,  2.0367, -0.3749],\n",
      "        [-1.8352,  1.9309, -0.3806],\n",
      "        [-2.0917,  0.7532,  1.2962]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9156,  1.9520, -0.3333],\n",
      "        [-2.1588,  0.5290,  1.2744],\n",
      "        [ 0.4699, -0.0405, -0.9844],\n",
      "        [-0.2081,  0.4921, -0.6961],\n",
      "        [-1.9810,  1.9637, -0.1603],\n",
      "        [-1.7487,  2.0842, -0.6899],\n",
      "        [-1.4195,  1.7164, -0.7770],\n",
      "        [-1.8582,  2.0959, -0.5565],\n",
      "        [-2.0391,  2.2353, -0.6855],\n",
      "        [-1.8471,  0.3376,  1.1192],\n",
      "        [-2.2494,  2.1388, -0.3662],\n",
      "        [-1.5777,  1.8001, -0.2130],\n",
      "        [-1.5277,  1.8290, -0.5189],\n",
      "        [-1.9824,  1.9019, -0.4019],\n",
      "        [ 0.6269,  0.0320, -0.9990],\n",
      "        [ 0.6158, -0.0530, -1.1728]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9156,  1.9520, -0.3333],\n",
      "        [-2.1588,  0.5290,  1.2744],\n",
      "        [ 0.4699, -0.0405, -0.9844],\n",
      "        [-0.2081,  0.4921, -0.6961],\n",
      "        [-1.9810,  1.9637, -0.1603],\n",
      "        [-1.7487,  2.0842, -0.6899],\n",
      "        [-1.4195,  1.7164, -0.7770],\n",
      "        [-1.8582,  2.0959, -0.5565],\n",
      "        [-2.0391,  2.2353, -0.6855],\n",
      "        [-1.8471,  0.3376,  1.1192],\n",
      "        [-2.2494,  2.1388, -0.3662],\n",
      "        [-1.5777,  1.8001, -0.2130],\n",
      "        [-1.5277,  1.8290, -0.5189],\n",
      "        [-1.9824,  1.9019, -0.4019],\n",
      "        [ 0.6269,  0.0320, -0.9990],\n",
      "        [ 0.6158, -0.0530, -1.1728]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.2758,  0.1873, -1.0931],\n",
      "        [-2.2274,  1.4172,  0.5350],\n",
      "        [-1.9576,  2.3064, -0.3033],\n",
      "        [-1.1681,  1.3442, -0.2895],\n",
      "        [-0.9023,  0.2634,  0.2010],\n",
      "        [-1.8993,  1.9725, -0.3066],\n",
      "        [-1.8364,  2.4515, -0.4875],\n",
      "        [-2.2272,  1.5067,  0.4055],\n",
      "        [-2.2454,  1.9462,  0.0153],\n",
      "        [-2.1117,  1.0282,  0.8962],\n",
      "        [-1.8027,  0.3709,  1.0282],\n",
      "        [-2.0286,  2.1685, -0.6134],\n",
      "        [ 0.2517,  0.1120, -0.6491],\n",
      "        [-1.9989,  1.0317,  0.5940],\n",
      "        [-1.6002,  0.9799,  0.4823],\n",
      "        [-1.8973,  0.3233,  1.0471]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.2758,  0.1873, -1.0931],\n",
      "        [-2.2274,  1.4172,  0.5350],\n",
      "        [-1.9576,  2.3064, -0.3033],\n",
      "        [-1.1681,  1.3442, -0.2895],\n",
      "        [-0.9023,  0.2634,  0.2010],\n",
      "        [-1.8993,  1.9725, -0.3066],\n",
      "        [-1.8364,  2.4515, -0.4875],\n",
      "        [-2.2272,  1.5067,  0.4055],\n",
      "        [-2.2454,  1.9462,  0.0153],\n",
      "        [-2.1117,  1.0282,  0.8962],\n",
      "        [-1.8027,  0.3709,  1.0282],\n",
      "        [-2.0286,  2.1685, -0.6134],\n",
      "        [ 0.2517,  0.1120, -0.6491],\n",
      "        [-1.9989,  1.0317,  0.5940],\n",
      "        [-1.6002,  0.9799,  0.4823],\n",
      "        [-1.8973,  0.3233,  1.0471]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.4107,  0.9573, -1.1225],\n",
      "        [-1.1334,  1.3471, -0.2969],\n",
      "        [-1.8782,  2.0754, -0.5374],\n",
      "        [-1.0999,  0.5239,  0.3744],\n",
      "        [-0.4735,  1.2303, -0.9421],\n",
      "        [-2.2140,  0.8608,  0.9840],\n",
      "        [-1.2274,  1.6844, -0.7232],\n",
      "        [-1.7698,  1.7778, -0.4047],\n",
      "        [-1.6949,  2.1172, -0.7067],\n",
      "        [-1.5887,  1.7460, -0.5146],\n",
      "        [-1.9194,  0.2554,  1.1654],\n",
      "        [-1.7477,  1.7814, -0.3133],\n",
      "        [-1.8817,  2.0714, -0.2072],\n",
      "        [-1.4606,  1.9289, -0.5333],\n",
      "        [-1.7999,  1.9390, -0.6958],\n",
      "        [-1.5641,  1.5621, -0.2824]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-0.4107,  0.9573, -1.1225],\n",
      "        [-1.1334,  1.3471, -0.2969],\n",
      "        [-1.8782,  2.0754, -0.5374],\n",
      "        [-1.0999,  0.5239,  0.3744],\n",
      "        [-0.4735,  1.2303, -0.9421],\n",
      "        [-2.2140,  0.8608,  0.9840],\n",
      "        [-1.2274,  1.6844, -0.7232],\n",
      "        [-1.7698,  1.7778, -0.4047],\n",
      "        [-1.6949,  2.1172, -0.7067],\n",
      "        [-1.5887,  1.7460, -0.5146],\n",
      "        [-1.9194,  0.2554,  1.1654],\n",
      "        [-1.7477,  1.7814, -0.3133],\n",
      "        [-1.8817,  2.0714, -0.2072],\n",
      "        [-1.4606,  1.9289, -0.5333],\n",
      "        [-1.7999,  1.9390, -0.6958],\n",
      "        [-1.5641,  1.5621, -0.2824]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.4449,  1.2686,  0.8654],\n",
      "        [-2.1086,  0.4957,  1.2709],\n",
      "        [-1.5289,  1.7675, -0.3240],\n",
      "        [-1.7826, -0.0945,  1.2702],\n",
      "        [-1.7972,  2.1157, -0.7791],\n",
      "        [-1.7709,  1.9054, -0.4767],\n",
      "        [-1.8738,  1.2694,  0.1496],\n",
      "        [-1.5585,  1.6767, -0.3210],\n",
      "        [-1.5536,  1.8334, -0.6134],\n",
      "        [ 0.2301,  0.1491, -1.1126],\n",
      "        [-2.1886,  0.6593,  1.3691],\n",
      "        [-1.9280,  1.9087, -0.1202],\n",
      "        [ 0.2596,  0.4734, -1.1369],\n",
      "        [-2.2897,  0.9404,  0.7341],\n",
      "        [-1.7902,  2.0677, -0.5372],\n",
      "        [-1.1492,  1.3622, -0.5506]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.4449,  1.2686,  0.8654],\n",
      "        [-2.1086,  0.4957,  1.2709],\n",
      "        [-1.5289,  1.7675, -0.3240],\n",
      "        [-1.7826, -0.0945,  1.2702],\n",
      "        [-1.7972,  2.1157, -0.7791],\n",
      "        [-1.7709,  1.9054, -0.4767],\n",
      "        [-1.8738,  1.2694,  0.1496],\n",
      "        [-1.5585,  1.6767, -0.3210],\n",
      "        [-1.5536,  1.8334, -0.6134],\n",
      "        [ 0.2301,  0.1491, -1.1126],\n",
      "        [-2.1886,  0.6593,  1.3691],\n",
      "        [-1.9280,  1.9087, -0.1202],\n",
      "        [ 0.2596,  0.4734, -1.1369],\n",
      "        [-2.2897,  0.9404,  0.7341],\n",
      "        [-1.7902,  2.0677, -0.5372],\n",
      "        [-1.1492,  1.3622, -0.5506]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.4799,  0.2892, -1.1492],\n",
      "        [-2.2237,  2.0589, -0.0459],\n",
      "        [-2.3820,  0.7107,  0.9790],\n",
      "        [-1.8342,  0.1991,  0.9474],\n",
      "        [-1.7373,  2.3869, -0.6624],\n",
      "        [ 0.2356,  0.2195, -1.3631],\n",
      "        [-2.0080,  2.1275, -0.3985],\n",
      "        [-1.7695,  1.7237, -0.3590],\n",
      "        [-2.2180,  1.7415,  0.2435],\n",
      "        [-1.8189,  1.7274, -0.0719],\n",
      "        [-2.2071,  0.6215,  1.0939],\n",
      "        [ 0.1871,  0.3779, -1.1758],\n",
      "        [-2.0775,  2.2289, -0.5950],\n",
      "        [ 0.4362,  0.3700, -1.1112],\n",
      "        [-2.0661,  2.1217, -0.3220],\n",
      "        [-1.7647,  2.0419, -0.6654]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.4799,  0.2892, -1.1492],\n",
      "        [-2.2237,  2.0589, -0.0459],\n",
      "        [-2.3820,  0.7107,  0.9790],\n",
      "        [-1.8342,  0.1991,  0.9474],\n",
      "        [-1.7373,  2.3869, -0.6624],\n",
      "        [ 0.2356,  0.2195, -1.3631],\n",
      "        [-2.0080,  2.1275, -0.3985],\n",
      "        [-1.7695,  1.7237, -0.3590],\n",
      "        [-2.2180,  1.7415,  0.2435],\n",
      "        [-1.8189,  1.7274, -0.0719],\n",
      "        [-2.2071,  0.6215,  1.0939],\n",
      "        [ 0.1871,  0.3779, -1.1758],\n",
      "        [-2.0775,  2.2289, -0.5950],\n",
      "        [ 0.4362,  0.3700, -1.1112],\n",
      "        [-2.0661,  2.1217, -0.3220],\n",
      "        [-1.7647,  2.0419, -0.6654]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.0185,  1.3213, -0.8420],\n",
      "        [-1.6594,  2.0219, -0.7760],\n",
      "        [-2.0092,  0.6553,  0.6891],\n",
      "        [-1.7074,  1.8999, -0.6147],\n",
      "        [-2.2854,  0.6830,  1.1462],\n",
      "        [-1.7906,  2.1817, -0.4442],\n",
      "        [-1.6203,  1.7743, -0.1964],\n",
      "        [ 0.4488,  0.1494, -1.1745],\n",
      "        [-0.9221,  0.6117, -0.2252],\n",
      "        [-2.1568,  2.1644, -0.0616],\n",
      "        [-0.3232,  0.9356, -0.9970],\n",
      "        [-1.8995,  0.5315,  1.0706],\n",
      "        [-1.7702,  1.8158, -0.1892],\n",
      "        [-1.8795,  1.8538, -0.3122],\n",
      "        [-0.5521,  0.6664, -0.5491],\n",
      "        [ 0.4360,  0.3480, -1.0701]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.0185,  1.3213, -0.8420],\n",
      "        [-1.6594,  2.0219, -0.7760],\n",
      "        [-2.0092,  0.6553,  0.6891],\n",
      "        [-1.7074,  1.8999, -0.6147],\n",
      "        [-2.2854,  0.6830,  1.1462],\n",
      "        [-1.7906,  2.1817, -0.4442],\n",
      "        [-1.6203,  1.7743, -0.1964],\n",
      "        [ 0.4488,  0.1494, -1.1745],\n",
      "        [-0.9221,  0.6117, -0.2252],\n",
      "        [-2.1568,  2.1644, -0.0616],\n",
      "        [-0.3232,  0.9356, -0.9970],\n",
      "        [-1.8995,  0.5315,  1.0706],\n",
      "        [-1.7702,  1.8158, -0.1892],\n",
      "        [-1.8795,  1.8538, -0.3122],\n",
      "        [-0.5521,  0.6664, -0.5491],\n",
      "        [ 0.4360,  0.3480, -1.0701]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8118,  1.9310, -0.3915],\n",
      "        [-1.6526,  2.1228, -0.6527],\n",
      "        [-1.7864,  1.9776, -0.3650],\n",
      "        [-1.8963,  2.1380, -0.3395],\n",
      "        [-1.9922,  0.4159,  1.1879],\n",
      "        [-2.1661,  0.5602,  0.9087],\n",
      "        [-1.9191,  1.8751, -0.2693],\n",
      "        [-1.2557,  1.7213, -0.8752],\n",
      "        [-1.7813,  2.0737, -0.5721],\n",
      "        [-2.4254,  1.4626,  0.4691],\n",
      "        [-1.9895,  2.1081, -0.3780],\n",
      "        [-1.8486,  2.1058, -0.6139],\n",
      "        [-2.2854,  1.0663,  1.0544],\n",
      "        [-1.8383,  0.5156,  1.1022],\n",
      "        [-2.0525,  1.5114,  0.2403],\n",
      "        [-1.9164,  1.8949, -0.5644]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8118,  1.9310, -0.3915],\n",
      "        [-1.6526,  2.1228, -0.6527],\n",
      "        [-1.7864,  1.9776, -0.3650],\n",
      "        [-1.8963,  2.1380, -0.3395],\n",
      "        [-1.9922,  0.4159,  1.1879],\n",
      "        [-2.1661,  0.5602,  0.9087],\n",
      "        [-1.9191,  1.8751, -0.2693],\n",
      "        [-1.2557,  1.7213, -0.8752],\n",
      "        [-1.7813,  2.0737, -0.5721],\n",
      "        [-2.4254,  1.4626,  0.4691],\n",
      "        [-1.9895,  2.1081, -0.3780],\n",
      "        [-1.8486,  2.1058, -0.6139],\n",
      "        [-2.2854,  1.0663,  1.0544],\n",
      "        [-1.8383,  0.5156,  1.1022],\n",
      "        [-2.0525,  1.5114,  0.2403],\n",
      "        [-1.9164,  1.8949, -0.5644]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0341,  1.7545, -0.0036],\n",
      "        [-1.8460,  2.0373, -0.2578],\n",
      "        [-2.1833,  2.0158,  0.0074],\n",
      "        [-1.8453,  2.0147, -0.3379],\n",
      "        [-1.9446,  1.8098, -0.4341],\n",
      "        [-0.2186,  0.4432, -0.8169],\n",
      "        [-2.1130,  0.6738,  1.0344],\n",
      "        [-1.9123,  1.9689, -0.3420],\n",
      "        [-2.1751,  1.7441,  0.1518],\n",
      "        [-2.0994,  0.6119,  1.2945],\n",
      "        [-2.2183,  0.6018,  1.2209],\n",
      "        [-1.9531,  1.9839, -0.3356],\n",
      "        [-1.8221,  2.0073, -0.2288],\n",
      "        [-1.8380,  1.9041, -0.7863],\n",
      "        [-0.1279,  0.7262, -1.1870],\n",
      "        [-1.7865,  1.4052,  0.2550]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.0341,  1.7545, -0.0036],\n",
      "        [-1.8460,  2.0373, -0.2578],\n",
      "        [-2.1833,  2.0158,  0.0074],\n",
      "        [-1.8453,  2.0147, -0.3379],\n",
      "        [-1.9446,  1.8098, -0.4341],\n",
      "        [-0.2186,  0.4432, -0.8169],\n",
      "        [-2.1130,  0.6738,  1.0344],\n",
      "        [-1.9123,  1.9689, -0.3420],\n",
      "        [-2.1751,  1.7441,  0.1518],\n",
      "        [-2.0994,  0.6119,  1.2945],\n",
      "        [-2.2183,  0.6018,  1.2209],\n",
      "        [-1.9531,  1.9839, -0.3356],\n",
      "        [-1.8221,  2.0073, -0.2288],\n",
      "        [-1.8380,  1.9041, -0.7863],\n",
      "        [-0.1279,  0.7262, -1.1870],\n",
      "        [-1.7865,  1.4052,  0.2550]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4773,  1.5984, -0.3667],\n",
      "        [-1.7148,  2.1453, -0.3721],\n",
      "        [-1.7103,  1.9287, -0.2929],\n",
      "        [-1.5016,  1.7924, -0.2424],\n",
      "        [-1.6929,  2.0682, -0.6684],\n",
      "        [-1.7770,  2.0668, -0.4957],\n",
      "        [-1.5483,  1.7772, -0.3482],\n",
      "        [-1.6409,  1.7548, -0.1950],\n",
      "        [-1.8863,  1.8961, -0.2186],\n",
      "        [-1.8484,  1.8261, -0.3246],\n",
      "        [-2.0500,  1.6497, -0.0153],\n",
      "        [-2.0643,  1.3688,  0.4328],\n",
      "        [-2.2727,  0.6671,  1.2011],\n",
      "        [ 0.2883,  0.3539, -1.1528],\n",
      "        [-1.9716,  1.9444, -0.2384],\n",
      "        [-2.0492,  0.5004,  0.9771]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4773,  1.5984, -0.3667],\n",
      "        [-1.7148,  2.1453, -0.3721],\n",
      "        [-1.7103,  1.9287, -0.2929],\n",
      "        [-1.5016,  1.7924, -0.2424],\n",
      "        [-1.6929,  2.0682, -0.6684],\n",
      "        [-1.7770,  2.0668, -0.4957],\n",
      "        [-1.5483,  1.7772, -0.3482],\n",
      "        [-1.6409,  1.7548, -0.1950],\n",
      "        [-1.8863,  1.8961, -0.2186],\n",
      "        [-1.8484,  1.8261, -0.3246],\n",
      "        [-2.0500,  1.6497, -0.0153],\n",
      "        [-2.0643,  1.3688,  0.4328],\n",
      "        [-2.2727,  0.6671,  1.2011],\n",
      "        [ 0.2883,  0.3539, -1.1528],\n",
      "        [-1.9716,  1.9444, -0.2384],\n",
      "        [-2.0492,  0.5004,  0.9771]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2516,  1.0247,  0.9752],\n",
      "        [ 0.3480,  0.1906, -1.1403],\n",
      "        [-1.1441,  1.3259, -0.3963],\n",
      "        [-2.2542,  0.7582,  1.2746],\n",
      "        [-1.9675,  0.4780,  1.1213],\n",
      "        [-2.1385,  0.4744,  1.0801],\n",
      "        [-0.6777,  0.9381, -0.6290],\n",
      "        [-1.5654,  1.5431, -0.2812],\n",
      "        [-1.5060,  1.7169, -0.0848],\n",
      "        [-1.8592,  1.9548, -0.2038],\n",
      "        [-1.7821,  1.9575, -0.2284],\n",
      "        [-2.0038,  1.8937, -0.2102],\n",
      "        [-0.0097,  0.4448, -0.9904],\n",
      "        [-1.7617,  1.7723, -0.2013],\n",
      "        [-1.8449,  1.9107, -0.1376],\n",
      "        [-2.0926,  1.8033,  0.0371]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.2516,  1.0247,  0.9752],\n",
      "        [ 0.3480,  0.1906, -1.1403],\n",
      "        [-1.1441,  1.3259, -0.3963],\n",
      "        [-2.2542,  0.7582,  1.2746],\n",
      "        [-1.9675,  0.4780,  1.1213],\n",
      "        [-2.1385,  0.4744,  1.0801],\n",
      "        [-0.6777,  0.9381, -0.6290],\n",
      "        [-1.5654,  1.5431, -0.2812],\n",
      "        [-1.5060,  1.7169, -0.0848],\n",
      "        [-1.8592,  1.9548, -0.2038],\n",
      "        [-1.7821,  1.9575, -0.2284],\n",
      "        [-2.0038,  1.8937, -0.2102],\n",
      "        [-0.0097,  0.4448, -0.9904],\n",
      "        [-1.7617,  1.7723, -0.2013],\n",
      "        [-1.8449,  1.9107, -0.1376],\n",
      "        [-2.0926,  1.8033,  0.0371]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8186,  1.6237, -0.0672],\n",
      "        [-1.9771,  0.4328,  0.9904],\n",
      "        [-2.1478,  1.7057,  0.0386],\n",
      "        [-2.0338,  1.8162,  0.0553],\n",
      "        [-2.1958,  1.3132,  0.5219],\n",
      "        [ 0.3291,  0.4065, -1.1321],\n",
      "        [-1.8126,  2.0663, -0.3616],\n",
      "        [-1.8822,  1.9341, -0.0830],\n",
      "        [-0.6533,  1.2255, -0.9161],\n",
      "        [-1.8321,  1.9578, -0.2253],\n",
      "        [-2.0201,  1.3016,  0.8272],\n",
      "        [-0.4860,  0.8289, -0.6967],\n",
      "        [-0.9119,  0.7482, -0.1111],\n",
      "        [-1.9062,  1.8315, -0.1195],\n",
      "        [ 0.4116,  0.3554, -1.2147],\n",
      "        [-2.0032,  1.8279, -0.1572]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8186,  1.6237, -0.0672],\n",
      "        [-1.9771,  0.4328,  0.9904],\n",
      "        [-2.1478,  1.7057,  0.0386],\n",
      "        [-2.0338,  1.8162,  0.0553],\n",
      "        [-2.1958,  1.3132,  0.5219],\n",
      "        [ 0.3291,  0.4065, -1.1321],\n",
      "        [-1.8126,  2.0663, -0.3616],\n",
      "        [-1.8822,  1.9341, -0.0830],\n",
      "        [-0.6533,  1.2255, -0.9161],\n",
      "        [-1.8321,  1.9578, -0.2253],\n",
      "        [-2.0201,  1.3016,  0.8272],\n",
      "        [-0.4860,  0.8289, -0.6967],\n",
      "        [-0.9119,  0.7482, -0.1111],\n",
      "        [-1.9062,  1.8315, -0.1195],\n",
      "        [ 0.4116,  0.3554, -1.2147],\n",
      "        [-2.0032,  1.8279, -0.1572]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3942,  1.4365, -0.2846],\n",
      "        [-2.3024,  0.6559,  0.9639],\n",
      "        [-1.9700,  1.2777,  0.1116],\n",
      "        [-2.1009,  0.3958,  1.0580],\n",
      "        [-1.7732,  1.5358,  0.1508],\n",
      "        [-2.0422,  1.7364,  0.2936],\n",
      "        [ 0.1374,  0.3797, -1.0744],\n",
      "        [-1.8636,  1.5694,  0.1285],\n",
      "        [-1.9690,  1.6755, -0.1196],\n",
      "        [-1.4010,  0.2783,  0.7342],\n",
      "        [-0.0689,  0.5132, -0.8392],\n",
      "        [-2.2057,  0.6440,  1.0791],\n",
      "        [-1.9954,  0.9441,  0.5211],\n",
      "        [-1.9411,  1.3829,  0.2149],\n",
      "        [ 0.0265,  0.3014, -0.9875],\n",
      "        [-1.5187,  1.5104, -0.5095]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3942,  1.4365, -0.2846],\n",
      "        [-2.3024,  0.6559,  0.9639],\n",
      "        [-1.9700,  1.2777,  0.1116],\n",
      "        [-2.1009,  0.3958,  1.0580],\n",
      "        [-1.7732,  1.5358,  0.1508],\n",
      "        [-2.0422,  1.7364,  0.2936],\n",
      "        [ 0.1374,  0.3797, -1.0744],\n",
      "        [-1.8636,  1.5694,  0.1285],\n",
      "        [-1.9690,  1.6755, -0.1196],\n",
      "        [-1.4010,  0.2783,  0.7342],\n",
      "        [-0.0689,  0.5132, -0.8392],\n",
      "        [-2.2057,  0.6440,  1.0791],\n",
      "        [-1.9954,  0.9441,  0.5211],\n",
      "        [-1.9411,  1.3829,  0.2149],\n",
      "        [ 0.0265,  0.3014, -0.9875],\n",
      "        [-1.5187,  1.5104, -0.5095]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1814,  1.1039,  0.5281],\n",
      "        [-2.2716,  0.6650,  1.0321],\n",
      "        [-2.0168,  0.6287,  1.2965],\n",
      "        [-1.7847,  1.6774, -0.1163],\n",
      "        [ 0.4775,  0.1156, -1.3164],\n",
      "        [-1.8640,  1.7390, -0.0232],\n",
      "        [ 0.5127,  0.2613, -1.2639],\n",
      "        [-2.4501,  0.8241,  0.9557],\n",
      "        [-1.6527,  1.7635,  0.0640],\n",
      "        [-1.3692,  1.4170, -0.3853],\n",
      "        [-2.0888,  0.4631,  1.1111],\n",
      "        [ 0.5636,  0.2481, -1.2057],\n",
      "        [-0.1139,  0.6179, -0.8561],\n",
      "        [ 0.3483,  0.2238, -0.9831],\n",
      "        [-1.8322,  1.7391, -0.0961],\n",
      "        [-1.8058,  0.4834,  0.9766]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.1814,  1.1039,  0.5281],\n",
      "        [-2.2716,  0.6650,  1.0321],\n",
      "        [-2.0168,  0.6287,  1.2965],\n",
      "        [-1.7847,  1.6774, -0.1163],\n",
      "        [ 0.4775,  0.1156, -1.3164],\n",
      "        [-1.8640,  1.7390, -0.0232],\n",
      "        [ 0.5127,  0.2613, -1.2639],\n",
      "        [-2.4501,  0.8241,  0.9557],\n",
      "        [-1.6527,  1.7635,  0.0640],\n",
      "        [-1.3692,  1.4170, -0.3853],\n",
      "        [-2.0888,  0.4631,  1.1111],\n",
      "        [ 0.5636,  0.2481, -1.2057],\n",
      "        [-0.1139,  0.6179, -0.8561],\n",
      "        [ 0.3483,  0.2238, -0.9831],\n",
      "        [-1.8322,  1.7391, -0.0961],\n",
      "        [-1.8058,  0.4834,  0.9766]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6759,  1.6716, -0.2213],\n",
      "        [-1.0731,  1.4011, -0.4666],\n",
      "        [-1.9086,  1.6802, -0.0567],\n",
      "        [-1.9591,  1.2062,  0.2760],\n",
      "        [ 0.0521,  0.3491, -0.9278],\n",
      "        [-1.7448,  1.5687, -0.1287],\n",
      "        [-1.3753,  1.4690, -0.5342],\n",
      "        [-1.5631,  1.4995, -0.1556],\n",
      "        [-1.8241,  1.1768,  0.4509],\n",
      "        [-1.6172,  1.5463, -0.2080],\n",
      "        [-1.6253,  1.6422, -0.2363],\n",
      "        [-0.2914,  0.3758, -0.4152],\n",
      "        [-2.0907,  1.5181,  0.4858],\n",
      "        [-2.1157,  0.6642,  1.0349],\n",
      "        [-1.3109,  1.4059, -0.2993],\n",
      "        [-1.4545,  1.2947, -0.1371]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6759,  1.6716, -0.2213],\n",
      "        [-1.0731,  1.4011, -0.4666],\n",
      "        [-1.9086,  1.6802, -0.0567],\n",
      "        [-1.9591,  1.2062,  0.2760],\n",
      "        [ 0.0521,  0.3491, -0.9278],\n",
      "        [-1.7448,  1.5687, -0.1287],\n",
      "        [-1.3753,  1.4690, -0.5342],\n",
      "        [-1.5631,  1.4995, -0.1556],\n",
      "        [-1.8241,  1.1768,  0.4509],\n",
      "        [-1.6172,  1.5463, -0.2080],\n",
      "        [-1.6253,  1.6422, -0.2363],\n",
      "        [-0.2914,  0.3758, -0.4152],\n",
      "        [-2.0907,  1.5181,  0.4858],\n",
      "        [-2.1157,  0.6642,  1.0349],\n",
      "        [-1.3109,  1.4059, -0.2993],\n",
      "        [-1.4545,  1.2947, -0.1371]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6140,  1.5033, -0.2607],\n",
      "        [ 0.1503,  0.4033, -1.0496],\n",
      "        [-1.5940,  1.2337,  0.0703],\n",
      "        [-2.0055,  0.4589,  1.2230],\n",
      "        [-1.3236,  1.4461, -0.2700],\n",
      "        [-1.9710,  0.8080,  0.9093],\n",
      "        [-1.4481,  1.6240, -0.3440],\n",
      "        [-1.5684,  1.4916, -0.3932],\n",
      "        [-2.1728,  1.1187,  0.8299],\n",
      "        [-1.7910,  1.5849, -0.2145],\n",
      "        [ 0.2528,  0.1881, -0.7717],\n",
      "        [-0.0252,  0.6912, -0.9828],\n",
      "        [-1.4525,  1.5486, -0.2833],\n",
      "        [-0.4542,  0.1219, -0.1150],\n",
      "        [-1.4667,  1.4827, -0.1354],\n",
      "        [-1.8101,  0.4678,  0.9431]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6140,  1.5033, -0.2607],\n",
      "        [ 0.1503,  0.4033, -1.0496],\n",
      "        [-1.5940,  1.2337,  0.0703],\n",
      "        [-2.0055,  0.4589,  1.2230],\n",
      "        [-1.3236,  1.4461, -0.2700],\n",
      "        [-1.9710,  0.8080,  0.9093],\n",
      "        [-1.4481,  1.6240, -0.3440],\n",
      "        [-1.5684,  1.4916, -0.3932],\n",
      "        [-2.1728,  1.1187,  0.8299],\n",
      "        [-1.7910,  1.5849, -0.2145],\n",
      "        [ 0.2528,  0.1881, -0.7717],\n",
      "        [-0.0252,  0.6912, -0.9828],\n",
      "        [-1.4525,  1.5486, -0.2833],\n",
      "        [-0.4542,  0.1219, -0.1150],\n",
      "        [-1.4667,  1.4827, -0.1354],\n",
      "        [-1.8101,  0.4678,  0.9431]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3753,  1.6768, -0.4969],\n",
      "        [ 0.3957,  0.1830, -1.0354],\n",
      "        [-1.9360,  0.7125,  1.0642],\n",
      "        [-1.5902,  1.6409, -0.2251],\n",
      "        [-2.0004,  0.3990,  1.1998],\n",
      "        [-1.7467,  0.2143,  1.1406],\n",
      "        [-1.6047,  1.5968,  0.0389],\n",
      "        [-1.2888,  0.7063,  0.1743],\n",
      "        [-1.8903,  0.5564,  0.8095],\n",
      "        [-2.0570,  0.7214,  0.8618],\n",
      "        [-1.9412,  0.3163,  1.2128],\n",
      "        [-1.9587,  0.3222,  1.0600],\n",
      "        [-1.6474,  1.8844, -0.0548],\n",
      "        [-1.6329,  1.8560, -0.4924],\n",
      "        [-1.7570,  1.0013,  0.4124],\n",
      "        [-1.9182,  0.5818,  1.1856]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3753,  1.6768, -0.4969],\n",
      "        [ 0.3957,  0.1830, -1.0354],\n",
      "        [-1.9360,  0.7125,  1.0642],\n",
      "        [-1.5902,  1.6409, -0.2251],\n",
      "        [-2.0004,  0.3990,  1.1998],\n",
      "        [-1.7467,  0.2143,  1.1406],\n",
      "        [-1.6047,  1.5968,  0.0389],\n",
      "        [-1.2888,  0.7063,  0.1743],\n",
      "        [-1.8903,  0.5564,  0.8095],\n",
      "        [-2.0570,  0.7214,  0.8618],\n",
      "        [-1.9412,  0.3163,  1.2128],\n",
      "        [-1.9587,  0.3222,  1.0600],\n",
      "        [-1.6474,  1.8844, -0.0548],\n",
      "        [-1.6329,  1.8560, -0.4924],\n",
      "        [-1.7570,  1.0013,  0.4124],\n",
      "        [-1.9182,  0.5818,  1.1856]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5973,  0.2230, -1.1858],\n",
      "        [-0.8074,  0.6609, -0.1021],\n",
      "        [-1.1486,  1.0715, -0.1448],\n",
      "        [-1.8977,  0.1990,  1.0693],\n",
      "        [-1.3293,  1.5357, -0.3347],\n",
      "        [-1.4613,  1.6599, -0.4178],\n",
      "        [ 0.6110,  0.2210, -1.2199],\n",
      "        [-1.6408,  1.4961, -0.0210],\n",
      "        [-2.2004,  0.5120,  1.1313],\n",
      "        [-1.1272,  0.6656,  0.1048],\n",
      "        [-1.4778,  1.5010, -0.1517],\n",
      "        [-0.9022,  1.2354, -0.5189],\n",
      "        [-1.7323,  1.2608,  0.0296],\n",
      "        [-2.1106,  0.4833,  1.3013],\n",
      "        [-1.1755,  1.5724, -0.5026],\n",
      "        [-1.8445,  0.3859,  1.0886]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.5973,  0.2230, -1.1858],\n",
      "        [-0.8074,  0.6609, -0.1021],\n",
      "        [-1.1486,  1.0715, -0.1448],\n",
      "        [-1.8977,  0.1990,  1.0693],\n",
      "        [-1.3293,  1.5357, -0.3347],\n",
      "        [-1.4613,  1.6599, -0.4178],\n",
      "        [ 0.6110,  0.2210, -1.2199],\n",
      "        [-1.6408,  1.4961, -0.0210],\n",
      "        [-2.2004,  0.5120,  1.1313],\n",
      "        [-1.1272,  0.6656,  0.1048],\n",
      "        [-1.4778,  1.5010, -0.1517],\n",
      "        [-0.9022,  1.2354, -0.5189],\n",
      "        [-1.7323,  1.2608,  0.0296],\n",
      "        [-2.1106,  0.4833,  1.3013],\n",
      "        [-1.1755,  1.5724, -0.5026],\n",
      "        [-1.8445,  0.3859,  1.0886]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.8006,  0.1838, -1.1799],\n",
      "        [-1.1851,  1.3206, -0.3892],\n",
      "        [-0.1068,  0.5842, -0.6880],\n",
      "        [-1.2313,  1.5963, -0.4567],\n",
      "        [-1.6982,  0.2484,  0.9321],\n",
      "        [-1.5416,  1.4136, -0.3174],\n",
      "        [-0.1535,  0.5851, -0.6179],\n",
      "        [-1.3486,  1.4698, -0.2745],\n",
      "        [ 0.5987,  0.1131, -1.1652],\n",
      "        [-1.9203,  1.5752,  0.0357],\n",
      "        [ 0.4674,  0.3024, -1.3094],\n",
      "        [ 0.5296,  0.2798, -1.1643],\n",
      "        [-2.2177,  0.4585,  1.2456],\n",
      "        [-1.2355,  1.5529, -0.6887],\n",
      "        [-1.6824,  1.6023, -0.1322],\n",
      "        [ 0.5538,  0.2873, -1.1733]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.8006,  0.1838, -1.1799],\n",
      "        [-1.1851,  1.3206, -0.3892],\n",
      "        [-0.1068,  0.5842, -0.6880],\n",
      "        [-1.2313,  1.5963, -0.4567],\n",
      "        [-1.6982,  0.2484,  0.9321],\n",
      "        [-1.5416,  1.4136, -0.3174],\n",
      "        [-0.1535,  0.5851, -0.6179],\n",
      "        [-1.3486,  1.4698, -0.2745],\n",
      "        [ 0.5987,  0.1131, -1.1652],\n",
      "        [-1.9203,  1.5752,  0.0357],\n",
      "        [ 0.4674,  0.3024, -1.3094],\n",
      "        [ 0.5296,  0.2798, -1.1643],\n",
      "        [-2.2177,  0.4585,  1.2456],\n",
      "        [-1.2355,  1.5529, -0.6887],\n",
      "        [-1.6824,  1.6023, -0.1322],\n",
      "        [ 0.5538,  0.2873, -1.1733]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.3697,  0.9920, -0.7754],\n",
      "        [-1.2106,  1.4391, -0.4400],\n",
      "        [-1.4155,  0.2457,  0.7984],\n",
      "        [-0.9193,  1.1170, -0.5218],\n",
      "        [-1.2319,  1.4657, -0.3222],\n",
      "        [-0.9815,  1.2991, -0.6557],\n",
      "        [-1.1828,  0.9487,  0.2290],\n",
      "        [-1.7366,  1.1216,  0.2688],\n",
      "        [ 0.4994,  0.2167, -1.0871],\n",
      "        [-1.7177,  0.4087,  0.9409],\n",
      "        [-1.1130,  1.4891, -0.8582],\n",
      "        [ 0.4919,  0.3423, -1.1642],\n",
      "        [-2.0515,  0.7341,  1.0213],\n",
      "        [-1.6007,  1.6348, -0.2447],\n",
      "        [-1.1571,  1.4991, -0.5738],\n",
      "        [-1.1562,  0.9049, -0.0372]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-0.3697,  0.9920, -0.7754],\n",
      "        [-1.2106,  1.4391, -0.4400],\n",
      "        [-1.4155,  0.2457,  0.7984],\n",
      "        [-0.9193,  1.1170, -0.5218],\n",
      "        [-1.2319,  1.4657, -0.3222],\n",
      "        [-0.9815,  1.2991, -0.6557],\n",
      "        [-1.1828,  0.9487,  0.2290],\n",
      "        [-1.7366,  1.1216,  0.2688],\n",
      "        [ 0.4994,  0.2167, -1.0871],\n",
      "        [-1.7177,  0.4087,  0.9409],\n",
      "        [-1.1130,  1.4891, -0.8582],\n",
      "        [ 0.4919,  0.3423, -1.1642],\n",
      "        [-2.0515,  0.7341,  1.0213],\n",
      "        [-1.6007,  1.6348, -0.2447],\n",
      "        [-1.1571,  1.4991, -0.5738],\n",
      "        [-1.1562,  0.9049, -0.0372]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.1913,  0.7271,  0.0420],\n",
      "        [-0.4413,  0.1819, -0.3850],\n",
      "        [-0.0075,  0.7480, -0.9310],\n",
      "        [-1.0926,  1.2736, -0.3589],\n",
      "        [-1.3461,  1.6901, -0.3696],\n",
      "        [-0.5823,  1.1109, -0.5999],\n",
      "        [-1.2162,  1.2883, -0.3075],\n",
      "        [-1.3809,  1.4710, -0.5487],\n",
      "        [-1.7000,  0.5077,  0.9162],\n",
      "        [-0.2357,  0.7510, -1.0525],\n",
      "        [-1.5574,  1.0203,  0.2140],\n",
      "        [-1.4350,  1.6889, -0.4240],\n",
      "        [ 0.0673,  0.4106, -0.6758],\n",
      "        [-1.1210,  1.5366, -0.4299],\n",
      "        [-1.1359,  1.2612, -0.3724],\n",
      "        [-1.5389,  1.6430, -0.1619]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.1913,  0.7271,  0.0420],\n",
      "        [-0.4413,  0.1819, -0.3850],\n",
      "        [-0.0075,  0.7480, -0.9310],\n",
      "        [-1.0926,  1.2736, -0.3589],\n",
      "        [-1.3461,  1.6901, -0.3696],\n",
      "        [-0.5823,  1.1109, -0.5999],\n",
      "        [-1.2162,  1.2883, -0.3075],\n",
      "        [-1.3809,  1.4710, -0.5487],\n",
      "        [-1.7000,  0.5077,  0.9162],\n",
      "        [-0.2357,  0.7510, -1.0525],\n",
      "        [-1.5574,  1.0203,  0.2140],\n",
      "        [-1.4350,  1.6889, -0.4240],\n",
      "        [ 0.0673,  0.4106, -0.6758],\n",
      "        [-1.1210,  1.5366, -0.4299],\n",
      "        [-1.1359,  1.2612, -0.3724],\n",
      "        [-1.5389,  1.6430, -0.1619]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7706,  1.5548,  0.0273],\n",
      "        [-1.1204,  1.8101, -0.7279],\n",
      "        [-1.8705,  0.7083,  0.7870],\n",
      "        [-1.5511,  1.5350, -0.3603],\n",
      "        [ 0.7227,  0.1734, -1.1677],\n",
      "        [-1.1657,  1.7444, -0.6626],\n",
      "        [-0.9880,  1.4909, -0.3294],\n",
      "        [-1.3949,  1.4992, -0.5978],\n",
      "        [-0.6275,  1.1607, -0.8052],\n",
      "        [-1.4345,  1.4840, -0.1883],\n",
      "        [-2.0596,  0.4227,  1.0981],\n",
      "        [-1.8638,  1.4927,  0.2669],\n",
      "        [-1.3438,  1.1725, -0.1904],\n",
      "        [ 0.7404,  0.0961, -1.2912],\n",
      "        [ 0.0532,  0.2158, -0.8871],\n",
      "        [-1.6465,  2.0016, -0.3326]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7706,  1.5548,  0.0273],\n",
      "        [-1.1204,  1.8101, -0.7279],\n",
      "        [-1.8705,  0.7083,  0.7870],\n",
      "        [-1.5511,  1.5350, -0.3603],\n",
      "        [ 0.7227,  0.1734, -1.1677],\n",
      "        [-1.1657,  1.7444, -0.6626],\n",
      "        [-0.9880,  1.4909, -0.3294],\n",
      "        [-1.3949,  1.4992, -0.5978],\n",
      "        [-0.6275,  1.1607, -0.8052],\n",
      "        [-1.4345,  1.4840, -0.1883],\n",
      "        [-2.0596,  0.4227,  1.0981],\n",
      "        [-1.8638,  1.4927,  0.2669],\n",
      "        [-1.3438,  1.1725, -0.1904],\n",
      "        [ 0.7404,  0.0961, -1.2912],\n",
      "        [ 0.0532,  0.2158, -0.8871],\n",
      "        [-1.6465,  2.0016, -0.3326]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.8484,  0.6708, -0.1337],\n",
      "        [-1.5146,  1.5082, -0.0853],\n",
      "        [-1.7440,  1.4008,  0.1099],\n",
      "        [-1.6357,  0.2873,  0.9916],\n",
      "        [-0.7330,  1.1726, -0.8706],\n",
      "        [-0.1389,  0.2524, -0.4708],\n",
      "        [ 0.4411,  0.3131, -0.9739],\n",
      "        [-0.6437,  0.7536, -0.5119],\n",
      "        [ 0.1782,  0.4933, -1.2898],\n",
      "        [-1.4993,  1.5275, -0.4923],\n",
      "        [-1.6522,  0.8363,  0.3254],\n",
      "        [-1.2304,  1.2960, -0.4524],\n",
      "        [-0.2675,  0.5801, -0.7008],\n",
      "        [-1.7011,  0.3275,  0.9615],\n",
      "        [-1.5170,  1.7728, -0.4745],\n",
      "        [-1.5750,  1.5930, -0.2669]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-0.8484,  0.6708, -0.1337],\n",
      "        [-1.5146,  1.5082, -0.0853],\n",
      "        [-1.7440,  1.4008,  0.1099],\n",
      "        [-1.6357,  0.2873,  0.9916],\n",
      "        [-0.7330,  1.1726, -0.8706],\n",
      "        [-0.1389,  0.2524, -0.4708],\n",
      "        [ 0.4411,  0.3131, -0.9739],\n",
      "        [-0.6437,  0.7536, -0.5119],\n",
      "        [ 0.1782,  0.4933, -1.2898],\n",
      "        [-1.4993,  1.5275, -0.4923],\n",
      "        [-1.6522,  0.8363,  0.3254],\n",
      "        [-1.2304,  1.2960, -0.4524],\n",
      "        [-0.2675,  0.5801, -0.7008],\n",
      "        [-1.7011,  0.3275,  0.9615],\n",
      "        [-1.5170,  1.7728, -0.4745],\n",
      "        [-1.5750,  1.5930, -0.2669]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7220,  0.7358,  0.7211],\n",
      "        [-1.8245,  0.2591,  1.0525],\n",
      "        [-1.2307,  1.4376, -0.6816],\n",
      "        [-1.6311,  0.8505,  0.4506],\n",
      "        [-2.1516,  0.4717,  1.0135],\n",
      "        [-1.3775,  1.8513, -0.6397],\n",
      "        [ 0.2993,  0.4065, -1.1149],\n",
      "        [-1.8796,  0.9210,  0.7396],\n",
      "        [-2.1009,  0.7707,  0.9550],\n",
      "        [ 0.3884,  0.2012, -1.1451],\n",
      "        [-1.7811,  1.1746,  0.3255],\n",
      "        [-1.3305,  1.7198, -0.5546],\n",
      "        [-1.0005,  1.2715, -0.6175],\n",
      "        [-0.4301,  1.1162, -1.0808],\n",
      "        [-0.9869,  1.4502, -0.6751],\n",
      "        [-1.2403,  1.4495, -0.5661]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7220,  0.7358,  0.7211],\n",
      "        [-1.8245,  0.2591,  1.0525],\n",
      "        [-1.2307,  1.4376, -0.6816],\n",
      "        [-1.6311,  0.8505,  0.4506],\n",
      "        [-2.1516,  0.4717,  1.0135],\n",
      "        [-1.3775,  1.8513, -0.6397],\n",
      "        [ 0.2993,  0.4065, -1.1149],\n",
      "        [-1.8796,  0.9210,  0.7396],\n",
      "        [-2.1009,  0.7707,  0.9550],\n",
      "        [ 0.3884,  0.2012, -1.1451],\n",
      "        [-1.7811,  1.1746,  0.3255],\n",
      "        [-1.3305,  1.7198, -0.5546],\n",
      "        [-1.0005,  1.2715, -0.6175],\n",
      "        [-0.4301,  1.1162, -1.0808],\n",
      "        [-0.9869,  1.4502, -0.6751],\n",
      "        [-1.2403,  1.4495, -0.5661]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2150,  1.7462, -0.5996],\n",
      "        [-1.3728,  1.9337, -0.3615],\n",
      "        [-1.4172,  0.4024,  0.7580],\n",
      "        [-1.2918,  1.7338, -0.6560],\n",
      "        [-1.1495,  1.5671, -0.5117],\n",
      "        [ 0.6474,  0.2765, -1.3047],\n",
      "        [-1.3607,  0.7682,  0.1445],\n",
      "        [-1.4177,  1.5407, -0.4057],\n",
      "        [ 0.5847,  0.0949, -1.2355],\n",
      "        [-1.0655,  0.1655,  0.4295],\n",
      "        [-0.8396,  1.0906, -0.3057],\n",
      "        [-1.7432,  1.5971, -0.0654],\n",
      "        [-0.4045,  1.0868, -0.8353],\n",
      "        [-1.5601,  1.6384, -0.3806],\n",
      "        [-0.0383,  0.8220, -0.9960],\n",
      "        [-1.3809,  1.9747, -0.4554]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.2150,  1.7462, -0.5996],\n",
      "        [-1.3728,  1.9337, -0.3615],\n",
      "        [-1.4172,  0.4024,  0.7580],\n",
      "        [-1.2918,  1.7338, -0.6560],\n",
      "        [-1.1495,  1.5671, -0.5117],\n",
      "        [ 0.6474,  0.2765, -1.3047],\n",
      "        [-1.3607,  0.7682,  0.1445],\n",
      "        [-1.4177,  1.5407, -0.4057],\n",
      "        [ 0.5847,  0.0949, -1.2355],\n",
      "        [-1.0655,  0.1655,  0.4295],\n",
      "        [-0.8396,  1.0906, -0.3057],\n",
      "        [-1.7432,  1.5971, -0.0654],\n",
      "        [-0.4045,  1.0868, -0.8353],\n",
      "        [-1.5601,  1.6384, -0.3806],\n",
      "        [-0.0383,  0.8220, -0.9960],\n",
      "        [-1.3809,  1.9747, -0.4554]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5575,  1.8216, -0.5019],\n",
      "        [-1.5537,  1.6238, -0.3129],\n",
      "        [-1.3453,  1.6854, -0.5172],\n",
      "        [-1.9373,  0.7114,  0.9558],\n",
      "        [ 0.8308,  0.1064, -1.1417],\n",
      "        [-1.4649,  1.7960, -0.5593],\n",
      "        [-1.4233,  1.7772, -0.4258],\n",
      "        [-1.2703,  1.7407, -0.5835],\n",
      "        [-1.7634,  1.9395, -0.4068],\n",
      "        [-1.4961,  1.9062, -0.2903],\n",
      "        [-1.9202,  1.1424,  0.1760],\n",
      "        [-1.0870,  1.1381, -0.4247],\n",
      "        [ 0.5013,  0.4652, -1.1734],\n",
      "        [-1.6980,  1.5936, -0.0030],\n",
      "        [-0.3107,  0.3449, -0.4086],\n",
      "        [-0.7531,  1.2893, -0.6184]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5575,  1.8216, -0.5019],\n",
      "        [-1.5537,  1.6238, -0.3129],\n",
      "        [-1.3453,  1.6854, -0.5172],\n",
      "        [-1.9373,  0.7114,  0.9558],\n",
      "        [ 0.8308,  0.1064, -1.1417],\n",
      "        [-1.4649,  1.7960, -0.5593],\n",
      "        [-1.4233,  1.7772, -0.4258],\n",
      "        [-1.2703,  1.7407, -0.5835],\n",
      "        [-1.7634,  1.9395, -0.4068],\n",
      "        [-1.4961,  1.9062, -0.2903],\n",
      "        [-1.9202,  1.1424,  0.1760],\n",
      "        [-1.0870,  1.1381, -0.4247],\n",
      "        [ 0.5013,  0.4652, -1.1734],\n",
      "        [-1.6980,  1.5936, -0.0030],\n",
      "        [-0.3107,  0.3449, -0.4086],\n",
      "        [-0.7531,  1.2893, -0.6184]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.2296,  0.3842, -1.0622],\n",
      "        [-1.5998,  1.6553, -0.4885],\n",
      "        [-1.0807,  1.1339, -0.3214],\n",
      "        [-2.0213,  0.3211,  1.0273],\n",
      "        [-1.6417,  1.8457, -0.3277],\n",
      "        [-1.7832,  1.7823, -0.3341],\n",
      "        [-1.7114,  1.1416,  0.5137],\n",
      "        [-1.2058,  1.6167, -0.5470],\n",
      "        [-1.7519,  1.2756,  0.4459],\n",
      "        [-1.4309,  1.8602, -0.5583],\n",
      "        [-1.5374,  1.7372, -0.4784],\n",
      "        [-1.8441,  0.1623,  1.1801],\n",
      "        [-0.1786,  0.2892, -0.4428],\n",
      "        [-2.0425,  0.9833,  0.6288],\n",
      "        [-1.4564,  1.6962, -0.4482],\n",
      "        [-1.7440,  2.1448, -0.5848]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.2296,  0.3842, -1.0622],\n",
      "        [-1.5998,  1.6553, -0.4885],\n",
      "        [-1.0807,  1.1339, -0.3214],\n",
      "        [-2.0213,  0.3211,  1.0273],\n",
      "        [-1.6417,  1.8457, -0.3277],\n",
      "        [-1.7832,  1.7823, -0.3341],\n",
      "        [-1.7114,  1.1416,  0.5137],\n",
      "        [-1.2058,  1.6167, -0.5470],\n",
      "        [-1.7519,  1.2756,  0.4459],\n",
      "        [-1.4309,  1.8602, -0.5583],\n",
      "        [-1.5374,  1.7372, -0.4784],\n",
      "        [-1.8441,  0.1623,  1.1801],\n",
      "        [-0.1786,  0.2892, -0.4428],\n",
      "        [-2.0425,  0.9833,  0.6288],\n",
      "        [-1.4564,  1.6962, -0.4482],\n",
      "        [-1.7440,  2.1448, -0.5848]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.3660,  0.2152, -0.0902],\n",
      "        [-1.9293,  1.1718,  0.3303],\n",
      "        [-1.7369,  1.8085, -0.3807],\n",
      "        [-1.6699,  1.8534, -0.3675],\n",
      "        [-1.6346,  1.8749, -0.2816],\n",
      "        [ 0.0414,  0.7619, -0.8653],\n",
      "        [ 0.2629,  0.5767, -1.1333],\n",
      "        [-0.3879,  0.2082, -0.1836],\n",
      "        [-1.3112,  1.5863, -0.3532],\n",
      "        [-1.5473,  1.7702, -0.3588],\n",
      "        [-1.0985,  0.3036,  0.4518],\n",
      "        [-1.4766,  1.6774, -0.4064],\n",
      "        [-1.5570,  1.6420, -0.4294],\n",
      "        [-1.7719,  1.1852,  0.2764],\n",
      "        [-1.9386,  1.9506, -0.1950],\n",
      "        [ 0.6963,  0.1875, -1.2469]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-0.3660,  0.2152, -0.0902],\n",
      "        [-1.9293,  1.1718,  0.3303],\n",
      "        [-1.7369,  1.8085, -0.3807],\n",
      "        [-1.6699,  1.8534, -0.3675],\n",
      "        [-1.6346,  1.8749, -0.2816],\n",
      "        [ 0.0414,  0.7619, -0.8653],\n",
      "        [ 0.2629,  0.5767, -1.1333],\n",
      "        [-0.3879,  0.2082, -0.1836],\n",
      "        [-1.3112,  1.5863, -0.3532],\n",
      "        [-1.5473,  1.7702, -0.3588],\n",
      "        [-1.0985,  0.3036,  0.4518],\n",
      "        [-1.4766,  1.6774, -0.4064],\n",
      "        [-1.5570,  1.6420, -0.4294],\n",
      "        [-1.7719,  1.1852,  0.2764],\n",
      "        [-1.9386,  1.9506, -0.1950],\n",
      "        [ 0.6963,  0.1875, -1.2469]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6680,  1.8943, -0.4425],\n",
      "        [-1.6076,  1.5040, -0.2145],\n",
      "        [-1.5170,  1.6459, -0.3154],\n",
      "        [-1.3811,  1.7844, -0.4989],\n",
      "        [-1.2859,  1.8791, -0.6064],\n",
      "        [-1.8538,  1.8863, -0.2506],\n",
      "        [-1.2787,  1.1921, -0.0719],\n",
      "        [ 0.3482,  0.2356, -0.9715],\n",
      "        [-1.8154,  0.5290,  1.1479],\n",
      "        [-2.0830,  0.2697,  1.1770],\n",
      "        [ 0.0257,  0.7619, -0.9509],\n",
      "        [-1.6492,  1.9018, -0.1053],\n",
      "        [-2.0920,  0.6405,  0.9879],\n",
      "        [-1.5188,  1.6063, -0.3840],\n",
      "        [-1.6852,  1.8250, -0.5523],\n",
      "        [-1.3999,  1.7053, -0.4829]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6680,  1.8943, -0.4425],\n",
      "        [-1.6076,  1.5040, -0.2145],\n",
      "        [-1.5170,  1.6459, -0.3154],\n",
      "        [-1.3811,  1.7844, -0.4989],\n",
      "        [-1.2859,  1.8791, -0.6064],\n",
      "        [-1.8538,  1.8863, -0.2506],\n",
      "        [-1.2787,  1.1921, -0.0719],\n",
      "        [ 0.3482,  0.2356, -0.9715],\n",
      "        [-1.8154,  0.5290,  1.1479],\n",
      "        [-2.0830,  0.2697,  1.1770],\n",
      "        [ 0.0257,  0.7619, -0.9509],\n",
      "        [-1.6492,  1.9018, -0.1053],\n",
      "        [-2.0920,  0.6405,  0.9879],\n",
      "        [-1.5188,  1.6063, -0.3840],\n",
      "        [-1.6852,  1.8250, -0.5523],\n",
      "        [-1.3999,  1.7053, -0.4829]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3178,  1.7021, -0.3209],\n",
      "        [-1.7084,  1.6022, -0.0505],\n",
      "        [-1.6900,  1.7193, -0.4076],\n",
      "        [-1.6111,  1.7707, -0.2561],\n",
      "        [-1.8703,  1.7311, -0.1936],\n",
      "        [ 0.5176,  0.3047, -1.1362],\n",
      "        [-1.6507,  1.8585, -0.4621],\n",
      "        [-1.4197,  1.6192, -0.6777],\n",
      "        [ 0.3691,  0.4136, -1.1752],\n",
      "        [-0.9271,  1.6728, -0.7101],\n",
      "        [-1.8957,  1.3729,  0.1883],\n",
      "        [-1.0012,  1.4496, -0.6520],\n",
      "        [-0.8108,  1.2970, -0.4018],\n",
      "        [-1.6078,  1.8273, -0.4876],\n",
      "        [-1.8773,  1.6140, -0.0773],\n",
      "        [-1.9958,  0.9896,  0.5378]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3178,  1.7021, -0.3209],\n",
      "        [-1.7084,  1.6022, -0.0505],\n",
      "        [-1.6900,  1.7193, -0.4076],\n",
      "        [-1.6111,  1.7707, -0.2561],\n",
      "        [-1.8703,  1.7311, -0.1936],\n",
      "        [ 0.5176,  0.3047, -1.1362],\n",
      "        [-1.6507,  1.8585, -0.4621],\n",
      "        [-1.4197,  1.6192, -0.6777],\n",
      "        [ 0.3691,  0.4136, -1.1752],\n",
      "        [-0.9271,  1.6728, -0.7101],\n",
      "        [-1.8957,  1.3729,  0.1883],\n",
      "        [-1.0012,  1.4496, -0.6520],\n",
      "        [-0.8108,  1.2970, -0.4018],\n",
      "        [-1.6078,  1.8273, -0.4876],\n",
      "        [-1.8773,  1.6140, -0.0773],\n",
      "        [-1.9958,  0.9896,  0.5378]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5234,  0.5419, -1.2099],\n",
      "        [-1.6177,  1.9447, -0.3205],\n",
      "        [-0.9918,  0.2494,  0.2910],\n",
      "        [-1.5204,  1.7287, -0.2758],\n",
      "        [-1.4441,  1.6588, -0.0457],\n",
      "        [-1.1474,  1.5402, -0.5231],\n",
      "        [-1.9453,  0.4978,  1.1515],\n",
      "        [-1.8884,  1.7680, -0.3039],\n",
      "        [-1.9785,  1.7036,  0.4697],\n",
      "        [-2.1451,  0.4319,  1.2681],\n",
      "        [-2.0069,  0.3729,  1.1088],\n",
      "        [-1.6763,  1.5877, -0.2881],\n",
      "        [-0.3762,  1.0447, -0.8469],\n",
      "        [ 0.4518,  0.3701, -1.1998],\n",
      "        [-2.4083,  1.2536,  0.3555],\n",
      "        [-1.5824,  0.3606,  1.0748]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.5234,  0.5419, -1.2099],\n",
      "        [-1.6177,  1.9447, -0.3205],\n",
      "        [-0.9918,  0.2494,  0.2910],\n",
      "        [-1.5204,  1.7287, -0.2758],\n",
      "        [-1.4441,  1.6588, -0.0457],\n",
      "        [-1.1474,  1.5402, -0.5231],\n",
      "        [-1.9453,  0.4978,  1.1515],\n",
      "        [-1.8884,  1.7680, -0.3039],\n",
      "        [-1.9785,  1.7036,  0.4697],\n",
      "        [-2.1451,  0.4319,  1.2681],\n",
      "        [-2.0069,  0.3729,  1.1088],\n",
      "        [-1.6763,  1.5877, -0.2881],\n",
      "        [-0.3762,  1.0447, -0.8469],\n",
      "        [ 0.4518,  0.3701, -1.1998],\n",
      "        [-2.4083,  1.2536,  0.3555],\n",
      "        [-1.5824,  0.3606,  1.0748]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5364,  1.7833, -0.3162],\n",
      "        [-1.5357,  1.7130, -0.3813],\n",
      "        [-1.8087,  1.8362, -0.1479],\n",
      "        [ 0.2578,  0.3840, -1.2029],\n",
      "        [-1.7731,  1.6891, -0.2608],\n",
      "        [-2.0343,  0.9308,  0.9065],\n",
      "        [-1.6460,  2.0082, -0.3024],\n",
      "        [-2.1672,  0.5042,  1.3399],\n",
      "        [-1.7187,  1.4884, -0.1290],\n",
      "        [-0.4438,  0.2978, -0.2193],\n",
      "        [-1.5703,  1.9288, -0.4716],\n",
      "        [-1.7384,  0.4309,  0.9795],\n",
      "        [-1.6622,  2.0966, -0.5079],\n",
      "        [-2.0734,  0.5270,  1.0462],\n",
      "        [-1.4884,  1.7898, -0.4800],\n",
      "        [-1.5671,  2.0410, -0.6064]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5364,  1.7833, -0.3162],\n",
      "        [-1.5357,  1.7130, -0.3813],\n",
      "        [-1.8087,  1.8362, -0.1479],\n",
      "        [ 0.2578,  0.3840, -1.2029],\n",
      "        [-1.7731,  1.6891, -0.2608],\n",
      "        [-2.0343,  0.9308,  0.9065],\n",
      "        [-1.6460,  2.0082, -0.3024],\n",
      "        [-2.1672,  0.5042,  1.3399],\n",
      "        [-1.7187,  1.4884, -0.1290],\n",
      "        [-0.4438,  0.2978, -0.2193],\n",
      "        [-1.5703,  1.9288, -0.4716],\n",
      "        [-1.7384,  0.4309,  0.9795],\n",
      "        [-1.6622,  2.0966, -0.5079],\n",
      "        [-2.0734,  0.5270,  1.0462],\n",
      "        [-1.4884,  1.7898, -0.4800],\n",
      "        [-1.5671,  2.0410, -0.6064]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.3870,  0.7302, -0.6633],\n",
      "        [-1.0473,  1.7291, -0.5552],\n",
      "        [-1.5161,  1.6221, -0.2656],\n",
      "        [-1.6716,  1.6950, -0.2783],\n",
      "        [-1.3567,  1.7236, -0.4035],\n",
      "        [-1.8428,  0.4565,  0.9462],\n",
      "        [-1.5781,  1.7617, -0.3984],\n",
      "        [-1.8955,  1.6885, -0.2908],\n",
      "        [-1.5063,  1.5907, -0.2137],\n",
      "        [ 0.3030,  0.6342, -0.9724],\n",
      "        [-1.7094,  1.9018, -0.3598],\n",
      "        [-1.6893,  1.6522, -0.0491],\n",
      "        [-1.6632,  1.7266, -0.4439],\n",
      "        [-1.7538,  1.6987, -0.2620],\n",
      "        [-2.1156,  0.4729,  0.8837],\n",
      "        [-1.4241,  1.9635, -0.5820]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-0.3870,  0.7302, -0.6633],\n",
      "        [-1.0473,  1.7291, -0.5552],\n",
      "        [-1.5161,  1.6221, -0.2656],\n",
      "        [-1.6716,  1.6950, -0.2783],\n",
      "        [-1.3567,  1.7236, -0.4035],\n",
      "        [-1.8428,  0.4565,  0.9462],\n",
      "        [-1.5781,  1.7617, -0.3984],\n",
      "        [-1.8955,  1.6885, -0.2908],\n",
      "        [-1.5063,  1.5907, -0.2137],\n",
      "        [ 0.3030,  0.6342, -0.9724],\n",
      "        [-1.7094,  1.9018, -0.3598],\n",
      "        [-1.6893,  1.6522, -0.0491],\n",
      "        [-1.6632,  1.7266, -0.4439],\n",
      "        [-1.7538,  1.6987, -0.2620],\n",
      "        [-2.1156,  0.4729,  0.8837],\n",
      "        [-1.4241,  1.9635, -0.5820]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.8682,  1.2301, -0.6830],\n",
      "        [-1.7328,  1.8076, -0.3258],\n",
      "        [-1.6954,  1.7991, -0.4088],\n",
      "        [-2.0723,  0.9818,  0.8392],\n",
      "        [-1.7571,  1.6441, -0.1834],\n",
      "        [-2.0621,  0.3723,  1.1957],\n",
      "        [-1.7601,  1.9191, -0.3923],\n",
      "        [-1.3508,  1.7472, -0.4569],\n",
      "        [-1.7694,  1.8965, -0.1290],\n",
      "        [-1.8406,  0.6586,  0.7912],\n",
      "        [-1.6160,  0.3435,  0.9541],\n",
      "        [-1.5791,  1.5556, -0.2814],\n",
      "        [-1.8795,  0.2958,  1.2399],\n",
      "        [-1.8980,  1.7882, -0.0753],\n",
      "        [-1.9138,  0.3857,  1.1330],\n",
      "        [-1.7374,  0.4367,  1.0293]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-0.8682,  1.2301, -0.6830],\n",
      "        [-1.7328,  1.8076, -0.3258],\n",
      "        [-1.6954,  1.7991, -0.4088],\n",
      "        [-2.0723,  0.9818,  0.8392],\n",
      "        [-1.7571,  1.6441, -0.1834],\n",
      "        [-2.0621,  0.3723,  1.1957],\n",
      "        [-1.7601,  1.9191, -0.3923],\n",
      "        [-1.3508,  1.7472, -0.4569],\n",
      "        [-1.7694,  1.8965, -0.1290],\n",
      "        [-1.8406,  0.6586,  0.7912],\n",
      "        [-1.6160,  0.3435,  0.9541],\n",
      "        [-1.5791,  1.5556, -0.2814],\n",
      "        [-1.8795,  0.2958,  1.2399],\n",
      "        [-1.8980,  1.7882, -0.0753],\n",
      "        [-1.9138,  0.3857,  1.1330],\n",
      "        [-1.7374,  0.4367,  1.0293]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4263,  1.3913, -0.1417],\n",
      "        [-0.7640,  0.0834,  0.0807],\n",
      "        [-1.6018,  1.7291, -0.4561],\n",
      "        [-1.5258,  1.8251, -0.3872],\n",
      "        [ 0.1680,  0.2522, -0.7748],\n",
      "        [-1.4780,  1.7410, -0.2770],\n",
      "        [-1.6416,  0.6936,  0.7465],\n",
      "        [-1.3851,  1.4639, -0.2896],\n",
      "        [-1.5832,  1.7730, -0.2794],\n",
      "        [-1.8677,  1.3803,  0.1536],\n",
      "        [-1.2487,  1.9524, -0.6876],\n",
      "        [-1.9615,  0.4573,  0.9468],\n",
      "        [-1.4492,  1.7715, -0.4111],\n",
      "        [-1.2733,  1.5765, -0.4797],\n",
      "        [-1.6122,  1.6866, -0.3304],\n",
      "        [-1.5974,  1.7783, -0.2518]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4263,  1.3913, -0.1417],\n",
      "        [-0.7640,  0.0834,  0.0807],\n",
      "        [-1.6018,  1.7291, -0.4561],\n",
      "        [-1.5258,  1.8251, -0.3872],\n",
      "        [ 0.1680,  0.2522, -0.7748],\n",
      "        [-1.4780,  1.7410, -0.2770],\n",
      "        [-1.6416,  0.6936,  0.7465],\n",
      "        [-1.3851,  1.4639, -0.2896],\n",
      "        [-1.5832,  1.7730, -0.2794],\n",
      "        [-1.8677,  1.3803,  0.1536],\n",
      "        [-1.2487,  1.9524, -0.6876],\n",
      "        [-1.9615,  0.4573,  0.9468],\n",
      "        [-1.4492,  1.7715, -0.4111],\n",
      "        [-1.2733,  1.5765, -0.4797],\n",
      "        [-1.6122,  1.6866, -0.3304],\n",
      "        [-1.5974,  1.7783, -0.2518]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4133,  1.6596, -0.3949],\n",
      "        [-1.7839,  0.2629,  0.8893],\n",
      "        [-1.4300,  1.3274, -0.0810],\n",
      "        [-1.0885,  1.6198, -0.6863],\n",
      "        [-1.6900,  1.7356, -0.1722],\n",
      "        [-1.5387,  1.4476, -0.1241],\n",
      "        [-1.4387,  1.6813, -0.5690],\n",
      "        [-1.7160,  1.8273, -0.2933],\n",
      "        [-1.4425,  1.9205, -0.2908],\n",
      "        [-1.4021,  1.5670, -0.5284],\n",
      "        [-1.6343,  1.6712, -0.1905],\n",
      "        [-2.1158,  0.5497,  0.9505],\n",
      "        [-1.5938,  1.7321, -0.3354],\n",
      "        [-0.1845,  0.8865, -1.0623],\n",
      "        [-1.6176,  0.8472,  0.3905],\n",
      "        [-1.3583,  0.5092,  0.8023]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4133,  1.6596, -0.3949],\n",
      "        [-1.7839,  0.2629,  0.8893],\n",
      "        [-1.4300,  1.3274, -0.0810],\n",
      "        [-1.0885,  1.6198, -0.6863],\n",
      "        [-1.6900,  1.7356, -0.1722],\n",
      "        [-1.5387,  1.4476, -0.1241],\n",
      "        [-1.4387,  1.6813, -0.5690],\n",
      "        [-1.7160,  1.8273, -0.2933],\n",
      "        [-1.4425,  1.9205, -0.2908],\n",
      "        [-1.4021,  1.5670, -0.5284],\n",
      "        [-1.6343,  1.6712, -0.1905],\n",
      "        [-2.1158,  0.5497,  0.9505],\n",
      "        [-1.5938,  1.7321, -0.3354],\n",
      "        [-0.1845,  0.8865, -1.0623],\n",
      "        [-1.6176,  0.8472,  0.3905],\n",
      "        [-1.3583,  0.5092,  0.8023]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7749,  0.6178,  0.9603],\n",
      "        [-1.4125,  1.6145, -0.3236],\n",
      "        [-1.5919,  1.5500, -0.2596],\n",
      "        [-1.6676,  1.7913, -0.2402],\n",
      "        [-1.5689,  2.0776, -0.1194],\n",
      "        [-1.7089,  1.4854, -0.0551],\n",
      "        [ 0.1599,  0.1824, -1.0766],\n",
      "        [-1.6490,  1.6475, -0.2629],\n",
      "        [ 0.4608,  0.2168, -1.1088],\n",
      "        [-1.6369,  1.6123, -0.0284],\n",
      "        [-1.6368,  1.5819, -0.1612],\n",
      "        [-1.8217,  1.8684, -0.3520],\n",
      "        [-1.7617,  1.5577, -0.2171],\n",
      "        [ 0.2156,  0.4056, -0.7950],\n",
      "        [-2.0747,  0.6308,  0.9408],\n",
      "        [-1.4831,  1.5908, -0.1754]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7749,  0.6178,  0.9603],\n",
      "        [-1.4125,  1.6145, -0.3236],\n",
      "        [-1.5919,  1.5500, -0.2596],\n",
      "        [-1.6676,  1.7913, -0.2402],\n",
      "        [-1.5689,  2.0776, -0.1194],\n",
      "        [-1.7089,  1.4854, -0.0551],\n",
      "        [ 0.1599,  0.1824, -1.0766],\n",
      "        [-1.6490,  1.6475, -0.2629],\n",
      "        [ 0.4608,  0.2168, -1.1088],\n",
      "        [-1.6369,  1.6123, -0.0284],\n",
      "        [-1.6368,  1.5819, -0.1612],\n",
      "        [-1.8217,  1.8684, -0.3520],\n",
      "        [-1.7617,  1.5577, -0.2171],\n",
      "        [ 0.2156,  0.4056, -0.7950],\n",
      "        [-2.0747,  0.6308,  0.9408],\n",
      "        [-1.4831,  1.5908, -0.1754]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6584,  1.6088, -0.3080],\n",
      "        [-1.3297,  0.5092,  0.4804],\n",
      "        [-1.7826,  0.4541,  1.0320],\n",
      "        [-1.4458,  0.8597,  0.3731],\n",
      "        [-2.0616,  0.7937,  1.0061],\n",
      "        [-1.5363,  1.4422, -0.2716],\n",
      "        [ 0.1895,  0.2996, -0.9130],\n",
      "        [-1.6231,  1.6624, -0.1033],\n",
      "        [ 0.3128,  0.3744, -1.1827],\n",
      "        [-2.1233,  0.5639,  1.2083],\n",
      "        [-2.1755,  0.6941,  1.2578],\n",
      "        [-1.8867,  0.9439,  0.5380],\n",
      "        [-1.7193,  1.7154, -0.0065],\n",
      "        [-2.1761,  0.6584,  1.1071],\n",
      "        [-1.5858,  1.1711,  0.1404],\n",
      "        [ 0.3667,  0.3173, -1.0987]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6584,  1.6088, -0.3080],\n",
      "        [-1.3297,  0.5092,  0.4804],\n",
      "        [-1.7826,  0.4541,  1.0320],\n",
      "        [-1.4458,  0.8597,  0.3731],\n",
      "        [-2.0616,  0.7937,  1.0061],\n",
      "        [-1.5363,  1.4422, -0.2716],\n",
      "        [ 0.1895,  0.2996, -0.9130],\n",
      "        [-1.6231,  1.6624, -0.1033],\n",
      "        [ 0.3128,  0.3744, -1.1827],\n",
      "        [-2.1233,  0.5639,  1.2083],\n",
      "        [-2.1755,  0.6941,  1.2578],\n",
      "        [-1.8867,  0.9439,  0.5380],\n",
      "        [-1.7193,  1.7154, -0.0065],\n",
      "        [-2.1761,  0.6584,  1.1071],\n",
      "        [-1.5858,  1.1711,  0.1404],\n",
      "        [ 0.3667,  0.3173, -1.0987]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5226,  1.6990, -0.3131],\n",
      "        [-1.7737,  1.2594,  0.0294],\n",
      "        [-1.8912,  0.8030,  0.9040],\n",
      "        [-1.9960,  0.5979,  1.0523],\n",
      "        [-1.5328,  1.6819, -0.2168],\n",
      "        [-1.3318,  1.5911, -0.1872],\n",
      "        [ 0.5139,  0.1784, -1.0318],\n",
      "        [ 0.6523,  0.2571, -1.3126],\n",
      "        [-1.9336,  0.8134,  0.7839],\n",
      "        [-1.6781,  1.4387, -0.1081],\n",
      "        [-1.3243,  1.4392, -0.1401],\n",
      "        [ 0.3812,  0.3659, -1.0786],\n",
      "        [-1.8845,  1.3166,  0.3422],\n",
      "        [-1.8796,  1.7777, -0.0873],\n",
      "        [-0.8028,  0.6444, -0.0352],\n",
      "        [-0.7620,  1.0302, -0.4303]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5226,  1.6990, -0.3131],\n",
      "        [-1.7737,  1.2594,  0.0294],\n",
      "        [-1.8912,  0.8030,  0.9040],\n",
      "        [-1.9960,  0.5979,  1.0523],\n",
      "        [-1.5328,  1.6819, -0.2168],\n",
      "        [-1.3318,  1.5911, -0.1872],\n",
      "        [ 0.5139,  0.1784, -1.0318],\n",
      "        [ 0.6523,  0.2571, -1.3126],\n",
      "        [-1.9336,  0.8134,  0.7839],\n",
      "        [-1.6781,  1.4387, -0.1081],\n",
      "        [-1.3243,  1.4392, -0.1401],\n",
      "        [ 0.3812,  0.3659, -1.0786],\n",
      "        [-1.8845,  1.3166,  0.3422],\n",
      "        [-1.8796,  1.7777, -0.0873],\n",
      "        [-0.8028,  0.6444, -0.0352],\n",
      "        [-0.7620,  1.0302, -0.4303]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6409,  1.0932,  0.2554],\n",
      "        [-2.0153,  1.1669,  0.3659],\n",
      "        [-1.6440,  1.3127,  0.2534],\n",
      "        [-1.4243,  1.5782, -0.2296],\n",
      "        [-1.8886,  1.0381,  0.4651],\n",
      "        [-1.1674,  1.3933, -0.3435],\n",
      "        [-0.9817,  1.2305, -0.3496],\n",
      "        [-2.1864,  1.0754,  0.8946],\n",
      "        [ 0.4759,  0.1817, -1.1806],\n",
      "        [-1.4702,  1.3763, -0.2450],\n",
      "        [-0.5322,  0.7050, -0.3702],\n",
      "        [-1.5595,  1.0329,  0.2866],\n",
      "        [-1.8563,  0.7529,  0.8484],\n",
      "        [-1.3768,  1.4191, -0.1556],\n",
      "        [-1.4915,  1.5852, -0.3943],\n",
      "        [-1.7741,  0.5573,  0.9495]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6409,  1.0932,  0.2554],\n",
      "        [-2.0153,  1.1669,  0.3659],\n",
      "        [-1.6440,  1.3127,  0.2534],\n",
      "        [-1.4243,  1.5782, -0.2296],\n",
      "        [-1.8886,  1.0381,  0.4651],\n",
      "        [-1.1674,  1.3933, -0.3435],\n",
      "        [-0.9817,  1.2305, -0.3496],\n",
      "        [-2.1864,  1.0754,  0.8946],\n",
      "        [ 0.4759,  0.1817, -1.1806],\n",
      "        [-1.4702,  1.3763, -0.2450],\n",
      "        [-0.5322,  0.7050, -0.3702],\n",
      "        [-1.5595,  1.0329,  0.2866],\n",
      "        [-1.8563,  0.7529,  0.8484],\n",
      "        [-1.3768,  1.4191, -0.1556],\n",
      "        [-1.4915,  1.5852, -0.3943],\n",
      "        [-1.7741,  0.5573,  0.9495]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5057,  1.6222, -0.1549],\n",
      "        [-1.5962,  1.6810, -0.2519],\n",
      "        [-1.5641,  1.7952, -0.1669],\n",
      "        [-1.4897,  1.3846, -0.3204],\n",
      "        [-1.9342,  0.5346,  0.9028],\n",
      "        [-1.4156,  1.6692, -0.3037],\n",
      "        [-1.2680,  1.2407, -0.0906],\n",
      "        [-0.3201,  0.8583, -0.8263],\n",
      "        [-1.4351,  1.4439, -0.1499],\n",
      "        [-1.7572,  1.5817, -0.0120],\n",
      "        [-1.9156,  1.5157,  0.2482],\n",
      "        [-1.4668,  1.5758, -0.1564],\n",
      "        [-1.3528,  0.2445,  0.7474],\n",
      "        [-1.6977,  0.3648,  0.8458],\n",
      "        [-1.7918,  0.6333,  0.8127],\n",
      "        [-1.4010,  1.6408, -0.0925]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5057,  1.6222, -0.1549],\n",
      "        [-1.5962,  1.6810, -0.2519],\n",
      "        [-1.5641,  1.7952, -0.1669],\n",
      "        [-1.4897,  1.3846, -0.3204],\n",
      "        [-1.9342,  0.5346,  0.9028],\n",
      "        [-1.4156,  1.6692, -0.3037],\n",
      "        [-1.2680,  1.2407, -0.0906],\n",
      "        [-0.3201,  0.8583, -0.8263],\n",
      "        [-1.4351,  1.4439, -0.1499],\n",
      "        [-1.7572,  1.5817, -0.0120],\n",
      "        [-1.9156,  1.5157,  0.2482],\n",
      "        [-1.4668,  1.5758, -0.1564],\n",
      "        [-1.3528,  0.2445,  0.7474],\n",
      "        [-1.6977,  0.3648,  0.8458],\n",
      "        [-1.7918,  0.6333,  0.8127],\n",
      "        [-1.4010,  1.6408, -0.0925]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6392,  0.4923,  0.6883],\n",
      "        [-1.2847,  1.3454, -0.3098],\n",
      "        [-1.3093,  1.7064, -0.1973],\n",
      "        [-1.6462,  1.2605, -0.3020],\n",
      "        [-1.4103,  1.3081, -0.2198],\n",
      "        [ 0.5344,  0.0832, -1.2216],\n",
      "        [-1.9061,  0.6107,  1.0281],\n",
      "        [-1.3160,  1.4229, -0.2406],\n",
      "        [-1.1587,  1.1506, -0.2376],\n",
      "        [-1.7846,  1.8712, -0.0434],\n",
      "        [-1.9332,  0.4153,  0.8904],\n",
      "        [-1.8246,  1.1633,  0.5156],\n",
      "        [-1.2716,  1.2253, -0.1367],\n",
      "        [-1.5934,  1.1279,  0.3845],\n",
      "        [-1.7594,  0.7434,  0.8337],\n",
      "        [-0.5274,  0.1708, -0.0901]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6392,  0.4923,  0.6883],\n",
      "        [-1.2847,  1.3454, -0.3098],\n",
      "        [-1.3093,  1.7064, -0.1973],\n",
      "        [-1.6462,  1.2605, -0.3020],\n",
      "        [-1.4103,  1.3081, -0.2198],\n",
      "        [ 0.5344,  0.0832, -1.2216],\n",
      "        [-1.9061,  0.6107,  1.0281],\n",
      "        [-1.3160,  1.4229, -0.2406],\n",
      "        [-1.1587,  1.1506, -0.2376],\n",
      "        [-1.7846,  1.8712, -0.0434],\n",
      "        [-1.9332,  0.4153,  0.8904],\n",
      "        [-1.8246,  1.1633,  0.5156],\n",
      "        [-1.2716,  1.2253, -0.1367],\n",
      "        [-1.5934,  1.1279,  0.3845],\n",
      "        [-1.7594,  0.7434,  0.8337],\n",
      "        [-0.5274,  0.1708, -0.0901]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4437,  1.3560, -0.2489],\n",
      "        [-1.8065,  0.6198,  0.5733],\n",
      "        [-1.5098,  1.3405, -0.0547],\n",
      "        [-0.2800,  0.1237, -0.2569],\n",
      "        [-1.8633,  0.5239,  0.8925],\n",
      "        [-1.4925,  1.5025, -0.2089],\n",
      "        [-1.0478,  1.3333, -0.2023],\n",
      "        [-1.8968,  0.5139,  0.8684],\n",
      "        [-1.8727,  0.5127,  0.7088],\n",
      "        [-1.2139,  1.3372, -0.1683],\n",
      "        [-1.8029,  0.8054,  0.7557],\n",
      "        [-1.5923,  1.6061, -0.2191],\n",
      "        [-1.3063,  1.6559, -0.3063],\n",
      "        [-1.1835,  1.4440, -0.4024],\n",
      "        [-1.7999,  0.5407,  0.9703],\n",
      "        [-1.3522,  1.0807, -0.0294]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4437,  1.3560, -0.2489],\n",
      "        [-1.8065,  0.6198,  0.5733],\n",
      "        [-1.5098,  1.3405, -0.0547],\n",
      "        [-0.2800,  0.1237, -0.2569],\n",
      "        [-1.8633,  0.5239,  0.8925],\n",
      "        [-1.4925,  1.5025, -0.2089],\n",
      "        [-1.0478,  1.3333, -0.2023],\n",
      "        [-1.8968,  0.5139,  0.8684],\n",
      "        [-1.8727,  0.5127,  0.7088],\n",
      "        [-1.2139,  1.3372, -0.1683],\n",
      "        [-1.8029,  0.8054,  0.7557],\n",
      "        [-1.5923,  1.6061, -0.2191],\n",
      "        [-1.3063,  1.6559, -0.3063],\n",
      "        [-1.1835,  1.4440, -0.4024],\n",
      "        [-1.7999,  0.5407,  0.9703],\n",
      "        [-1.3522,  1.0807, -0.0294]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3384,  1.4453, -0.2525],\n",
      "        [-1.3669,  1.5851, -0.2582],\n",
      "        [-1.7421,  0.8264,  0.6126],\n",
      "        [-1.0954,  1.4725, -0.5560],\n",
      "        [-1.5078,  1.5734, -0.2983],\n",
      "        [ 0.3398,  0.3861, -1.0986],\n",
      "        [-0.8062,  0.8740, -0.4773],\n",
      "        [-1.2971,  1.4899, -0.2609],\n",
      "        [-1.8674,  0.8729,  0.8869],\n",
      "        [-1.2240,  1.3726, -0.2147],\n",
      "        [-1.7369,  0.4644,  0.7078],\n",
      "        [-1.9703,  0.6510,  0.9024],\n",
      "        [-1.7371,  0.6390,  0.7418],\n",
      "        [-1.2622,  1.4670, -0.2209],\n",
      "        [-0.8750,  1.2593, -0.3883],\n",
      "        [-1.6387,  0.6264,  0.6031]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3384,  1.4453, -0.2525],\n",
      "        [-1.3669,  1.5851, -0.2582],\n",
      "        [-1.7421,  0.8264,  0.6126],\n",
      "        [-1.0954,  1.4725, -0.5560],\n",
      "        [-1.5078,  1.5734, -0.2983],\n",
      "        [ 0.3398,  0.3861, -1.0986],\n",
      "        [-0.8062,  0.8740, -0.4773],\n",
      "        [-1.2971,  1.4899, -0.2609],\n",
      "        [-1.8674,  0.8729,  0.8869],\n",
      "        [-1.2240,  1.3726, -0.2147],\n",
      "        [-1.7369,  0.4644,  0.7078],\n",
      "        [-1.9703,  0.6510,  0.9024],\n",
      "        [-1.7371,  0.6390,  0.7418],\n",
      "        [-1.2622,  1.4670, -0.2209],\n",
      "        [-0.8750,  1.2593, -0.3883],\n",
      "        [-1.6387,  0.6264,  0.6031]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7165,  0.4669,  0.8685],\n",
      "        [-1.2870,  1.5353, -0.3801],\n",
      "        [-1.2202,  1.5077, -0.2578],\n",
      "        [-0.7676,  1.3726, -0.4437],\n",
      "        [-1.4582,  0.3875,  0.7671],\n",
      "        [ 0.5775,  0.1207, -1.0362],\n",
      "        [-1.3550,  1.3933, -0.4495],\n",
      "        [-1.7378,  0.6090,  0.9236],\n",
      "        [-1.6153,  1.6303, -0.1672],\n",
      "        [-2.0641,  0.6592,  0.9689],\n",
      "        [-1.3117,  1.4334, -0.0810],\n",
      "        [-1.7375,  0.6079,  0.7219],\n",
      "        [-1.5524,  1.5711, -0.1761],\n",
      "        [-1.9808,  0.6645,  0.8695],\n",
      "        [-1.6618,  1.1715,  0.1338],\n",
      "        [-1.2592,  1.3824, -0.0662]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7165,  0.4669,  0.8685],\n",
      "        [-1.2870,  1.5353, -0.3801],\n",
      "        [-1.2202,  1.5077, -0.2578],\n",
      "        [-0.7676,  1.3726, -0.4437],\n",
      "        [-1.4582,  0.3875,  0.7671],\n",
      "        [ 0.5775,  0.1207, -1.0362],\n",
      "        [-1.3550,  1.3933, -0.4495],\n",
      "        [-1.7378,  0.6090,  0.9236],\n",
      "        [-1.6153,  1.6303, -0.1672],\n",
      "        [-2.0641,  0.6592,  0.9689],\n",
      "        [-1.3117,  1.4334, -0.0810],\n",
      "        [-1.7375,  0.6079,  0.7219],\n",
      "        [-1.5524,  1.5711, -0.1761],\n",
      "        [-1.9808,  0.6645,  0.8695],\n",
      "        [-1.6618,  1.1715,  0.1338],\n",
      "        [-1.2592,  1.3824, -0.0662]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3252,  1.1344,  0.1296],\n",
      "        [-1.0690,  1.4454, -0.3808],\n",
      "        [-1.2709,  1.4083, -0.3625],\n",
      "        [-1.4194,  1.4355, -0.0227],\n",
      "        [-1.1385,  0.2402,  0.5316],\n",
      "        [-1.3813,  1.6067, -0.2593],\n",
      "        [-1.4763,  1.3743, -0.0709],\n",
      "        [-1.8086,  0.5308,  0.8966],\n",
      "        [-1.3914,  1.3302, -0.0464],\n",
      "        [-1.3756,  0.5768,  0.6808],\n",
      "        [-1.8366,  0.6705,  0.9570],\n",
      "        [ 0.3381,  0.0789, -0.8669],\n",
      "        [-1.6833,  0.9733,  0.4992],\n",
      "        [-1.2784,  1.4184, -0.4255],\n",
      "        [-1.2867,  1.4889, -0.3008],\n",
      "        [-1.2164,  1.1570, -0.2877]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3252,  1.1344,  0.1296],\n",
      "        [-1.0690,  1.4454, -0.3808],\n",
      "        [-1.2709,  1.4083, -0.3625],\n",
      "        [-1.4194,  1.4355, -0.0227],\n",
      "        [-1.1385,  0.2402,  0.5316],\n",
      "        [-1.3813,  1.6067, -0.2593],\n",
      "        [-1.4763,  1.3743, -0.0709],\n",
      "        [-1.8086,  0.5308,  0.8966],\n",
      "        [-1.3914,  1.3302, -0.0464],\n",
      "        [-1.3756,  0.5768,  0.6808],\n",
      "        [-1.8366,  0.6705,  0.9570],\n",
      "        [ 0.3381,  0.0789, -0.8669],\n",
      "        [-1.6833,  0.9733,  0.4992],\n",
      "        [-1.2784,  1.4184, -0.4255],\n",
      "        [-1.2867,  1.4889, -0.3008],\n",
      "        [-1.2164,  1.1570, -0.2877]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6553,  0.5600,  0.9343],\n",
      "        [-1.2129,  1.3475, -0.3237],\n",
      "        [-1.2666,  1.4012, -0.2809],\n",
      "        [-1.6561,  0.4751,  0.8970],\n",
      "        [-1.6707,  0.6403,  0.6158],\n",
      "        [-1.2045,  1.3794,  0.0498],\n",
      "        [ 0.2163,  0.2187, -0.8174],\n",
      "        [-1.6787,  0.4643,  0.9444],\n",
      "        [ 0.3211,  0.1292, -0.7211],\n",
      "        [-1.1591,  1.2641, -0.3136],\n",
      "        [ 0.1868,  0.4068, -0.8974],\n",
      "        [-1.5392,  1.3336, -0.1661],\n",
      "        [-1.6522,  0.3747,  0.8333],\n",
      "        [-1.0099,  1.1073, -0.3873],\n",
      "        [-1.2987,  1.4057, -0.2878],\n",
      "        [-1.5299,  1.0563,  0.0686]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6553,  0.5600,  0.9343],\n",
      "        [-1.2129,  1.3475, -0.3237],\n",
      "        [-1.2666,  1.4012, -0.2809],\n",
      "        [-1.6561,  0.4751,  0.8970],\n",
      "        [-1.6707,  0.6403,  0.6158],\n",
      "        [-1.2045,  1.3794,  0.0498],\n",
      "        [ 0.2163,  0.2187, -0.8174],\n",
      "        [-1.6787,  0.4643,  0.9444],\n",
      "        [ 0.3211,  0.1292, -0.7211],\n",
      "        [-1.1591,  1.2641, -0.3136],\n",
      "        [ 0.1868,  0.4068, -0.8974],\n",
      "        [-1.5392,  1.3336, -0.1661],\n",
      "        [-1.6522,  0.3747,  0.8333],\n",
      "        [-1.0099,  1.1073, -0.3873],\n",
      "        [-1.2987,  1.4057, -0.2878],\n",
      "        [-1.5299,  1.0563,  0.0686]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4162,  0.8245,  0.3071],\n",
      "        [-1.4522,  1.4889, -0.3801],\n",
      "        [-1.2054,  1.1950, -0.2006],\n",
      "        [-1.4070,  1.3100, -0.3265],\n",
      "        [-1.3087,  1.5889, -0.6150],\n",
      "        [-1.6639,  0.4200,  0.8646],\n",
      "        [-1.1911,  1.5679, -0.4181],\n",
      "        [-1.5966,  0.5384,  0.6229],\n",
      "        [-1.2914,  1.3960, -0.2165],\n",
      "        [-1.6777,  1.5752,  0.0263],\n",
      "        [-1.0578,  1.1712, -0.4673],\n",
      "        [-1.0145,  1.4913, -0.4457],\n",
      "        [-1.6682,  0.3592,  0.9296],\n",
      "        [-1.7549,  0.5469,  0.6255],\n",
      "        [-0.6349,  0.9815, -0.6660],\n",
      "        [-1.1604,  1.3152, -0.3413]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4162,  0.8245,  0.3071],\n",
      "        [-1.4522,  1.4889, -0.3801],\n",
      "        [-1.2054,  1.1950, -0.2006],\n",
      "        [-1.4070,  1.3100, -0.3265],\n",
      "        [-1.3087,  1.5889, -0.6150],\n",
      "        [-1.6639,  0.4200,  0.8646],\n",
      "        [-1.1911,  1.5679, -0.4181],\n",
      "        [-1.5966,  0.5384,  0.6229],\n",
      "        [-1.2914,  1.3960, -0.2165],\n",
      "        [-1.6777,  1.5752,  0.0263],\n",
      "        [-1.0578,  1.1712, -0.4673],\n",
      "        [-1.0145,  1.4913, -0.4457],\n",
      "        [-1.6682,  0.3592,  0.9296],\n",
      "        [-1.7549,  0.5469,  0.6255],\n",
      "        [-0.6349,  0.9815, -0.6660],\n",
      "        [-1.1604,  1.3152, -0.3413]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7338,  1.0017,  0.2777],\n",
      "        [-1.2687,  1.4505, -0.3509],\n",
      "        [-1.2222,  1.3598, -0.1214],\n",
      "        [-1.9011,  0.7310,  0.8012],\n",
      "        [-1.9262,  0.4412,  1.0473],\n",
      "        [-1.1267,  1.3283, -0.3704],\n",
      "        [-1.5651,  0.3690,  0.8685],\n",
      "        [-1.4412,  0.9942,  0.3080],\n",
      "        [-1.7684,  1.1913,  0.4152],\n",
      "        [-1.3384,  1.5863, -0.4633],\n",
      "        [-1.2022,  1.5680, -0.4444],\n",
      "        [-1.1150,  1.6209, -0.3880],\n",
      "        [-1.4438,  1.5482, -0.3233],\n",
      "        [-0.9089,  0.4422,  0.2168],\n",
      "        [-1.1470,  1.6085, -0.4459],\n",
      "        [-0.7288,  0.3214, -0.0047]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7338,  1.0017,  0.2777],\n",
      "        [-1.2687,  1.4505, -0.3509],\n",
      "        [-1.2222,  1.3598, -0.1214],\n",
      "        [-1.9011,  0.7310,  0.8012],\n",
      "        [-1.9262,  0.4412,  1.0473],\n",
      "        [-1.1267,  1.3283, -0.3704],\n",
      "        [-1.5651,  0.3690,  0.8685],\n",
      "        [-1.4412,  0.9942,  0.3080],\n",
      "        [-1.7684,  1.1913,  0.4152],\n",
      "        [-1.3384,  1.5863, -0.4633],\n",
      "        [-1.2022,  1.5680, -0.4444],\n",
      "        [-1.1150,  1.6209, -0.3880],\n",
      "        [-1.4438,  1.5482, -0.3233],\n",
      "        [-0.9089,  0.4422,  0.2168],\n",
      "        [-1.1470,  1.6085, -0.4459],\n",
      "        [-0.7288,  0.3214, -0.0047]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2777,  1.5666, -0.5149],\n",
      "        [-1.6756,  0.4372,  0.8902],\n",
      "        [-0.1354,  0.0816, -0.1787],\n",
      "        [-2.0697,  0.8405,  0.9237],\n",
      "        [-1.3809,  1.7105, -0.5614],\n",
      "        [-1.3589,  1.6115, -0.2560],\n",
      "        [ 0.6774,  0.1162, -1.0700],\n",
      "        [-1.6213,  0.5704,  0.8143],\n",
      "        [-1.5441,  1.5724, -0.2635],\n",
      "        [-1.4391,  1.3884, -0.2778],\n",
      "        [-0.9926,  1.3918, -0.4085],\n",
      "        [-0.5224,  0.1735,  0.1598],\n",
      "        [-1.7275,  0.7343,  0.8724],\n",
      "        [-1.2689,  1.2698, -0.5527],\n",
      "        [-1.4468,  0.8530,  0.3440],\n",
      "        [-1.2855,  1.6418, -0.4661]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.2777,  1.5666, -0.5149],\n",
      "        [-1.6756,  0.4372,  0.8902],\n",
      "        [-0.1354,  0.0816, -0.1787],\n",
      "        [-2.0697,  0.8405,  0.9237],\n",
      "        [-1.3809,  1.7105, -0.5614],\n",
      "        [-1.3589,  1.6115, -0.2560],\n",
      "        [ 0.6774,  0.1162, -1.0700],\n",
      "        [-1.6213,  0.5704,  0.8143],\n",
      "        [-1.5441,  1.5724, -0.2635],\n",
      "        [-1.4391,  1.3884, -0.2778],\n",
      "        [-0.9926,  1.3918, -0.4085],\n",
      "        [-0.5224,  0.1735,  0.1598],\n",
      "        [-1.7275,  0.7343,  0.8724],\n",
      "        [-1.2689,  1.2698, -0.5527],\n",
      "        [-1.4468,  0.8530,  0.3440],\n",
      "        [-1.2855,  1.6418, -0.4661]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3010,  0.9237,  0.1583],\n",
      "        [-1.6058,  0.4519,  0.9583],\n",
      "        [-1.4956,  1.3421,  0.0587],\n",
      "        [ 0.5144,  0.1394, -1.1256],\n",
      "        [-1.6494,  0.4116,  1.0284],\n",
      "        [ 0.2656,  0.0427, -0.7772],\n",
      "        [ 0.5810,  0.1777, -1.0311],\n",
      "        [-0.6948,  1.5690, -0.5836],\n",
      "        [-1.3742,  1.1404, -0.2193],\n",
      "        [-1.4609,  1.6326, -0.3043],\n",
      "        [-1.5178,  1.8934, -0.2118],\n",
      "        [-1.1849,  1.5467, -0.5277],\n",
      "        [-1.1470,  1.5686, -0.3780],\n",
      "        [-1.8153,  0.5976,  0.8733],\n",
      "        [-1.0243,  0.1612,  0.5777],\n",
      "        [-1.7996,  0.4581,  1.0171]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3010,  0.9237,  0.1583],\n",
      "        [-1.6058,  0.4519,  0.9583],\n",
      "        [-1.4956,  1.3421,  0.0587],\n",
      "        [ 0.5144,  0.1394, -1.1256],\n",
      "        [-1.6494,  0.4116,  1.0284],\n",
      "        [ 0.2656,  0.0427, -0.7772],\n",
      "        [ 0.5810,  0.1777, -1.0311],\n",
      "        [-0.6948,  1.5690, -0.5836],\n",
      "        [-1.3742,  1.1404, -0.2193],\n",
      "        [-1.4609,  1.6326, -0.3043],\n",
      "        [-1.5178,  1.8934, -0.2118],\n",
      "        [-1.1849,  1.5467, -0.5277],\n",
      "        [-1.1470,  1.5686, -0.3780],\n",
      "        [-1.8153,  0.5976,  0.8733],\n",
      "        [-1.0243,  0.1612,  0.5777],\n",
      "        [-1.7996,  0.4581,  1.0171]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5865,  0.0173, -0.9571],\n",
      "        [-1.6557,  0.9550,  0.4989],\n",
      "        [-1.3769,  1.6764, -0.5493],\n",
      "        [-1.4437,  0.1680,  0.7862],\n",
      "        [-0.9985,  1.5833, -0.5735],\n",
      "        [-1.2326,  1.6610, -0.6965],\n",
      "        [-1.6006,  0.3991,  0.8745],\n",
      "        [-1.3611,  1.3848, -0.0407],\n",
      "        [-1.4884,  1.4120, -0.4105],\n",
      "        [ 0.6514,  0.0659, -1.0071],\n",
      "        [-1.7688,  0.4451,  0.8208],\n",
      "        [-0.5247,  0.2670, -0.0879],\n",
      "        [-0.0573,  0.2299, -0.5329],\n",
      "        [-1.2356,  1.5928, -0.4616],\n",
      "        [ 0.4621, -0.0424, -1.0814],\n",
      "        [-1.2508,  1.6145, -0.4643]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.5865,  0.0173, -0.9571],\n",
      "        [-1.6557,  0.9550,  0.4989],\n",
      "        [-1.3769,  1.6764, -0.5493],\n",
      "        [-1.4437,  0.1680,  0.7862],\n",
      "        [-0.9985,  1.5833, -0.5735],\n",
      "        [-1.2326,  1.6610, -0.6965],\n",
      "        [-1.6006,  0.3991,  0.8745],\n",
      "        [-1.3611,  1.3848, -0.0407],\n",
      "        [-1.4884,  1.4120, -0.4105],\n",
      "        [ 0.6514,  0.0659, -1.0071],\n",
      "        [-1.7688,  0.4451,  0.8208],\n",
      "        [-0.5247,  0.2670, -0.0879],\n",
      "        [-0.0573,  0.2299, -0.5329],\n",
      "        [-1.2356,  1.5928, -0.4616],\n",
      "        [ 0.4621, -0.0424, -1.0814],\n",
      "        [-1.2508,  1.6145, -0.4643]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2063,  1.5420, -0.5989],\n",
      "        [ 0.2043,  0.3591, -1.0806],\n",
      "        [-1.1856,  1.5653, -0.4957],\n",
      "        [-1.2126,  1.5946, -0.3564],\n",
      "        [-1.5954,  0.5039,  0.8925],\n",
      "        [-1.3961,  1.5694, -0.5244],\n",
      "        [ 0.4304,  0.3210, -0.9666],\n",
      "        [-1.2945,  1.4977, -0.5712],\n",
      "        [-1.9245,  0.7195,  0.9623],\n",
      "        [-1.2788,  1.6565, -0.6031],\n",
      "        [ 0.6287,  0.1748, -0.9595],\n",
      "        [-1.1988,  1.7105, -0.5364],\n",
      "        [-1.2543,  1.7071, -0.3481],\n",
      "        [-1.2150,  1.6379, -0.3651],\n",
      "        [-1.7811,  0.5559,  0.8047],\n",
      "        [ 0.5585,  0.1636, -1.0655]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.2063,  1.5420, -0.5989],\n",
      "        [ 0.2043,  0.3591, -1.0806],\n",
      "        [-1.1856,  1.5653, -0.4957],\n",
      "        [-1.2126,  1.5946, -0.3564],\n",
      "        [-1.5954,  0.5039,  0.8925],\n",
      "        [-1.3961,  1.5694, -0.5244],\n",
      "        [ 0.4304,  0.3210, -0.9666],\n",
      "        [-1.2945,  1.4977, -0.5712],\n",
      "        [-1.9245,  0.7195,  0.9623],\n",
      "        [-1.2788,  1.6565, -0.6031],\n",
      "        [ 0.6287,  0.1748, -0.9595],\n",
      "        [-1.1988,  1.7105, -0.5364],\n",
      "        [-1.2543,  1.7071, -0.3481],\n",
      "        [-1.2150,  1.6379, -0.3651],\n",
      "        [-1.7811,  0.5559,  0.8047],\n",
      "        [ 0.5585,  0.1636, -1.0655]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6682,  0.7060,  0.7074],\n",
      "        [-1.6583,  0.4277,  0.8658],\n",
      "        [-1.2912,  1.9062, -0.6273],\n",
      "        [ 0.1211, -0.0057, -0.5869],\n",
      "        [-1.2931,  1.6365, -0.6784],\n",
      "        [ 0.3018,  0.5056, -1.0874],\n",
      "        [-1.0451,  1.4526, -0.5594],\n",
      "        [-1.1258,  1.6976, -0.6921],\n",
      "        [-1.3876,  0.3697,  0.8752],\n",
      "        [-0.6324,  1.2599, -0.9372],\n",
      "        [-0.6289,  1.2685, -0.9734],\n",
      "        [-1.2832,  1.6339, -0.3284],\n",
      "        [-1.4236,  1.9067, -0.4098],\n",
      "        [-1.5055,  0.4412,  0.9168],\n",
      "        [-1.0687,  1.7557, -0.7018],\n",
      "        [-1.4991,  1.1816, -0.1834]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6682,  0.7060,  0.7074],\n",
      "        [-1.6583,  0.4277,  0.8658],\n",
      "        [-1.2912,  1.9062, -0.6273],\n",
      "        [ 0.1211, -0.0057, -0.5869],\n",
      "        [-1.2931,  1.6365, -0.6784],\n",
      "        [ 0.3018,  0.5056, -1.0874],\n",
      "        [-1.0451,  1.4526, -0.5594],\n",
      "        [-1.1258,  1.6976, -0.6921],\n",
      "        [-1.3876,  0.3697,  0.8752],\n",
      "        [-0.6324,  1.2599, -0.9372],\n",
      "        [-0.6289,  1.2685, -0.9734],\n",
      "        [-1.2832,  1.6339, -0.3284],\n",
      "        [-1.4236,  1.9067, -0.4098],\n",
      "        [-1.5055,  0.4412,  0.9168],\n",
      "        [-1.0687,  1.7557, -0.7018],\n",
      "        [-1.4991,  1.1816, -0.1834]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.1184,  1.4366, -0.5725],\n",
      "        [-1.6252,  0.8228,  0.4149],\n",
      "        [-0.9605,  1.3866, -0.8052],\n",
      "        [-1.0323,  1.5955, -0.7175],\n",
      "        [-1.3169,  1.7162, -0.6618],\n",
      "        [-1.3698,  1.5812, -0.5145],\n",
      "        [-1.0911,  1.6999, -0.6087],\n",
      "        [-1.6903,  1.0873,  0.2165],\n",
      "        [ 0.6557,  0.0639, -1.2224],\n",
      "        [-1.8630,  0.8018,  0.6773],\n",
      "        [-1.1502,  1.6838, -0.4790],\n",
      "        [-1.8053,  1.9412, -0.1781],\n",
      "        [ 0.6628, -0.0054, -1.0280],\n",
      "        [-1.2142,  1.7892, -0.5477],\n",
      "        [-1.2567,  1.8931, -0.7826],\n",
      "        [-1.4032,  0.4738,  0.5284]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.1184,  1.4366, -0.5725],\n",
      "        [-1.6252,  0.8228,  0.4149],\n",
      "        [-0.9605,  1.3866, -0.8052],\n",
      "        [-1.0323,  1.5955, -0.7175],\n",
      "        [-1.3169,  1.7162, -0.6618],\n",
      "        [-1.3698,  1.5812, -0.5145],\n",
      "        [-1.0911,  1.6999, -0.6087],\n",
      "        [-1.6903,  1.0873,  0.2165],\n",
      "        [ 0.6557,  0.0639, -1.2224],\n",
      "        [-1.8630,  0.8018,  0.6773],\n",
      "        [-1.1502,  1.6838, -0.4790],\n",
      "        [-1.8053,  1.9412, -0.1781],\n",
      "        [ 0.6628, -0.0054, -1.0280],\n",
      "        [-1.2142,  1.7892, -0.5477],\n",
      "        [-1.2567,  1.8931, -0.7826],\n",
      "        [-1.4032,  0.4738,  0.5284]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4829e+00,  1.3837e+00,  9.2623e-02],\n",
      "        [-1.1813e+00,  1.7342e+00, -3.6067e-01],\n",
      "        [-1.1541e+00,  1.7156e+00, -6.1222e-01],\n",
      "        [-5.5024e-05,  7.0478e-02, -3.4514e-01],\n",
      "        [-1.4998e+00,  5.3871e-01,  6.9909e-01],\n",
      "        [-1.1841e+00,  1.6214e+00, -7.3670e-01],\n",
      "        [-9.7702e-01,  1.5412e+00, -6.5792e-01],\n",
      "        [-1.8170e+00,  6.7715e-01,  6.6417e-01],\n",
      "        [-1.8467e+00,  9.0383e-01,  3.5099e-01],\n",
      "        [-1.1838e+00,  1.4736e+00, -4.5544e-01],\n",
      "        [-1.4058e+00,  1.7171e+00, -5.0132e-01],\n",
      "        [ 5.8421e-01,  5.8477e-02, -1.1578e+00],\n",
      "        [-1.2953e+00,  1.7878e+00, -6.7615e-01],\n",
      "        [-1.4467e+00,  3.7961e-01,  7.7286e-01],\n",
      "        [-1.1181e+00,  1.5535e+00, -6.7502e-01],\n",
      "        [-1.5508e+00,  2.6167e-01,  9.3949e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4829e+00,  1.3837e+00,  9.2623e-02],\n",
      "        [-1.1813e+00,  1.7342e+00, -3.6067e-01],\n",
      "        [-1.1541e+00,  1.7156e+00, -6.1222e-01],\n",
      "        [-5.5024e-05,  7.0478e-02, -3.4514e-01],\n",
      "        [-1.4998e+00,  5.3871e-01,  6.9909e-01],\n",
      "        [-1.1841e+00,  1.6214e+00, -7.3670e-01],\n",
      "        [-9.7702e-01,  1.5412e+00, -6.5792e-01],\n",
      "        [-1.8170e+00,  6.7715e-01,  6.6417e-01],\n",
      "        [-1.8467e+00,  9.0383e-01,  3.5099e-01],\n",
      "        [-1.1838e+00,  1.4736e+00, -4.5544e-01],\n",
      "        [-1.4058e+00,  1.7171e+00, -5.0132e-01],\n",
      "        [ 5.8421e-01,  5.8477e-02, -1.1578e+00],\n",
      "        [-1.2953e+00,  1.7878e+00, -6.7615e-01],\n",
      "        [-1.4467e+00,  3.7961e-01,  7.7286e-01],\n",
      "        [-1.1181e+00,  1.5535e+00, -6.7502e-01],\n",
      "        [-1.5508e+00,  2.6167e-01,  9.3949e-01]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.1829,  2.0652, -0.7652],\n",
      "        [-1.7004,  0.7567,  0.5977],\n",
      "        [-1.2492,  1.7770, -0.5560],\n",
      "        [-1.0210,  1.6470, -0.7751],\n",
      "        [-0.4064,  0.1964,  0.0066],\n",
      "        [-1.0398,  1.2992, -0.7337],\n",
      "        [ 0.5706,  0.2618, -1.0155],\n",
      "        [-1.1878,  1.6657, -0.5378],\n",
      "        [ 0.4243,  0.2689, -0.9712],\n",
      "        [-1.4050,  0.3534,  0.9169],\n",
      "        [-0.5823,  0.1251,  0.0118],\n",
      "        [-1.1862,  1.8853, -0.8158],\n",
      "        [-1.7349,  0.3718,  0.8943],\n",
      "        [-1.3791,  1.7757, -0.6337],\n",
      "        [-1.2653,  1.7221, -0.6424],\n",
      "        [-1.0777,  1.6373, -0.8314]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.1829,  2.0652, -0.7652],\n",
      "        [-1.7004,  0.7567,  0.5977],\n",
      "        [-1.2492,  1.7770, -0.5560],\n",
      "        [-1.0210,  1.6470, -0.7751],\n",
      "        [-0.4064,  0.1964,  0.0066],\n",
      "        [-1.0398,  1.2992, -0.7337],\n",
      "        [ 0.5706,  0.2618, -1.0155],\n",
      "        [-1.1878,  1.6657, -0.5378],\n",
      "        [ 0.4243,  0.2689, -0.9712],\n",
      "        [-1.4050,  0.3534,  0.9169],\n",
      "        [-0.5823,  0.1251,  0.0118],\n",
      "        [-1.1862,  1.8853, -0.8158],\n",
      "        [-1.7349,  0.3718,  0.8943],\n",
      "        [-1.3791,  1.7757, -0.6337],\n",
      "        [-1.2653,  1.7221, -0.6424],\n",
      "        [-1.0777,  1.6373, -0.8314]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3963,  1.6937, -0.4786],\n",
      "        [-1.2720,  1.6972, -0.8072],\n",
      "        [ 0.5889,  0.1620, -1.1160],\n",
      "        [ 0.7003,  0.0531, -1.0811],\n",
      "        [-1.3386,  1.9066, -0.4617],\n",
      "        [-0.7710,  1.3426, -0.7534],\n",
      "        [-0.9155,  0.1608,  0.6358],\n",
      "        [-1.0939,  1.4675, -0.4261],\n",
      "        [-1.5049,  1.8916, -0.7414],\n",
      "        [-0.1352,  0.6390, -0.8277],\n",
      "        [-1.0792,  1.5769, -0.6328],\n",
      "        [-0.9432,  1.7735, -0.8190],\n",
      "        [-1.0967,  1.8134, -0.7727],\n",
      "        [-1.6324,  0.9693,  0.4655],\n",
      "        [-1.0463,  1.4376, -0.7265],\n",
      "        [-1.1887,  1.6480, -0.6281]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3963,  1.6937, -0.4786],\n",
      "        [-1.2720,  1.6972, -0.8072],\n",
      "        [ 0.5889,  0.1620, -1.1160],\n",
      "        [ 0.7003,  0.0531, -1.0811],\n",
      "        [-1.3386,  1.9066, -0.4617],\n",
      "        [-0.7710,  1.3426, -0.7534],\n",
      "        [-0.9155,  0.1608,  0.6358],\n",
      "        [-1.0939,  1.4675, -0.4261],\n",
      "        [-1.5049,  1.8916, -0.7414],\n",
      "        [-0.1352,  0.6390, -0.8277],\n",
      "        [-1.0792,  1.5769, -0.6328],\n",
      "        [-0.9432,  1.7735, -0.8190],\n",
      "        [-1.0967,  1.8134, -0.7727],\n",
      "        [-1.6324,  0.9693,  0.4655],\n",
      "        [-1.0463,  1.4376, -0.7265],\n",
      "        [-1.1887,  1.6480, -0.6281]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.1040,  1.7815, -0.9178],\n",
      "        [-1.1370,  1.7505, -0.7701],\n",
      "        [-1.4488,  1.8623, -0.6352],\n",
      "        [-1.3521,  1.7729, -0.6374],\n",
      "        [-1.2255,  1.3650, -0.2342],\n",
      "        [-0.3538,  0.8954, -0.8368],\n",
      "        [-1.3406,  1.9200, -0.6610],\n",
      "        [-1.3014,  1.6122, -0.2861],\n",
      "        [-1.1559,  1.7659, -0.7762],\n",
      "        [-1.0683,  1.3086, -0.6208],\n",
      "        [-1.2982,  1.4995, -0.4151],\n",
      "        [-1.6683,  0.5448,  0.7751],\n",
      "        [-0.2771,  0.8158, -1.1241],\n",
      "        [-1.7701,  0.2957,  0.9552],\n",
      "        [-1.3372,  1.7932, -0.6258],\n",
      "        [-0.5225,  1.0750, -0.4636]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.1040,  1.7815, -0.9178],\n",
      "        [-1.1370,  1.7505, -0.7701],\n",
      "        [-1.4488,  1.8623, -0.6352],\n",
      "        [-1.3521,  1.7729, -0.6374],\n",
      "        [-1.2255,  1.3650, -0.2342],\n",
      "        [-0.3538,  0.8954, -0.8368],\n",
      "        [-1.3406,  1.9200, -0.6610],\n",
      "        [-1.3014,  1.6122, -0.2861],\n",
      "        [-1.1559,  1.7659, -0.7762],\n",
      "        [-1.0683,  1.3086, -0.6208],\n",
      "        [-1.2982,  1.4995, -0.4151],\n",
      "        [-1.6683,  0.5448,  0.7751],\n",
      "        [-0.2771,  0.8158, -1.1241],\n",
      "        [-1.7701,  0.2957,  0.9552],\n",
      "        [-1.3372,  1.7932, -0.6258],\n",
      "        [-0.5225,  1.0750, -0.4636]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4197,  1.6995, -0.7205],\n",
      "        [-1.5412,  0.2465,  0.9100],\n",
      "        [-1.4946,  1.8691, -0.6567],\n",
      "        [ 0.7461,  0.0139, -1.1915],\n",
      "        [-0.9846,  1.6620, -0.7297],\n",
      "        [-1.1372,  1.7576, -0.6601],\n",
      "        [-1.3863,  1.9451, -0.6520],\n",
      "        [-1.3680,  0.6978,  0.2598],\n",
      "        [-1.3870,  1.8603, -0.7231],\n",
      "        [-1.2802,  1.6238, -0.4697],\n",
      "        [-1.3185, -0.0108,  1.0924],\n",
      "        [-1.1466,  1.9015, -0.7414],\n",
      "        [-1.6601,  0.6567,  0.6507],\n",
      "        [-1.2854,  1.5554, -0.4853],\n",
      "        [-1.5139,  0.1993,  0.9920],\n",
      "        [-1.6356,  0.4161,  0.9525]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4197,  1.6995, -0.7205],\n",
      "        [-1.5412,  0.2465,  0.9100],\n",
      "        [-1.4946,  1.8691, -0.6567],\n",
      "        [ 0.7461,  0.0139, -1.1915],\n",
      "        [-0.9846,  1.6620, -0.7297],\n",
      "        [-1.1372,  1.7576, -0.6601],\n",
      "        [-1.3863,  1.9451, -0.6520],\n",
      "        [-1.3680,  0.6978,  0.2598],\n",
      "        [-1.3870,  1.8603, -0.7231],\n",
      "        [-1.2802,  1.6238, -0.4697],\n",
      "        [-1.3185, -0.0108,  1.0924],\n",
      "        [-1.1466,  1.9015, -0.7414],\n",
      "        [-1.6601,  0.6567,  0.6507],\n",
      "        [-1.2854,  1.5554, -0.4853],\n",
      "        [-1.5139,  0.1993,  0.9920],\n",
      "        [-1.6356,  0.4161,  0.9525]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.0821,  1.7648, -0.6472],\n",
      "        [-1.7319,  0.2912,  1.1081],\n",
      "        [-1.2371,  1.7870, -0.8052],\n",
      "        [-1.2444,  1.8543, -0.3605],\n",
      "        [-0.8246,  1.7386, -0.5907],\n",
      "        [-1.2375,  1.6149, -0.2249],\n",
      "        [-1.7816,  0.5708,  0.8969],\n",
      "        [ 0.2632,  0.0784, -0.7399],\n",
      "        [-1.6520,  0.2283,  1.1385],\n",
      "        [-1.2593,  2.0137, -0.7254],\n",
      "        [-1.7676,  1.3370,  0.2173],\n",
      "        [-1.3809,  1.9181, -0.4661],\n",
      "        [-1.2931,  1.6250, -0.1639],\n",
      "        [-1.2422,  1.3411, -0.3836],\n",
      "        [-1.5257,  1.8530, -0.6771],\n",
      "        [-1.7091,  0.2674,  0.9723]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.0821,  1.7648, -0.6472],\n",
      "        [-1.7319,  0.2912,  1.1081],\n",
      "        [-1.2371,  1.7870, -0.8052],\n",
      "        [-1.2444,  1.8543, -0.3605],\n",
      "        [-0.8246,  1.7386, -0.5907],\n",
      "        [-1.2375,  1.6149, -0.2249],\n",
      "        [-1.7816,  0.5708,  0.8969],\n",
      "        [ 0.2632,  0.0784, -0.7399],\n",
      "        [-1.6520,  0.2283,  1.1385],\n",
      "        [-1.2593,  2.0137, -0.7254],\n",
      "        [-1.7676,  1.3370,  0.2173],\n",
      "        [-1.3809,  1.9181, -0.4661],\n",
      "        [-1.2931,  1.6250, -0.1639],\n",
      "        [-1.2422,  1.3411, -0.3836],\n",
      "        [-1.5257,  1.8530, -0.6771],\n",
      "        [-1.7091,  0.2674,  0.9723]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5255,  0.1166, -0.8160],\n",
      "        [-1.6735,  1.3551, -0.0516],\n",
      "        [-1.3214,  1.7702, -0.4983],\n",
      "        [-1.0212,  1.4224, -0.6585],\n",
      "        [-1.5200,  1.3293, -0.0516],\n",
      "        [-2.0124,  0.4838,  1.1289],\n",
      "        [-1.3512,  1.8545, -0.7062],\n",
      "        [-0.8659,  1.6707, -0.5836],\n",
      "        [-1.6338,  1.0187,  0.3713],\n",
      "        [-0.9101,  1.5096, -0.2792],\n",
      "        [ 0.2031, -0.0506, -0.5014],\n",
      "        [-1.1694,  1.7197, -0.7184],\n",
      "        [-1.4578,  0.0255,  1.0361],\n",
      "        [-1.3143,  1.6313, -0.5368],\n",
      "        [ 0.7223,  0.1016, -0.9507],\n",
      "        [-1.4729,  1.7734, -0.4096]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.5255,  0.1166, -0.8160],\n",
      "        [-1.6735,  1.3551, -0.0516],\n",
      "        [-1.3214,  1.7702, -0.4983],\n",
      "        [-1.0212,  1.4224, -0.6585],\n",
      "        [-1.5200,  1.3293, -0.0516],\n",
      "        [-2.0124,  0.4838,  1.1289],\n",
      "        [-1.3512,  1.8545, -0.7062],\n",
      "        [-0.8659,  1.6707, -0.5836],\n",
      "        [-1.6338,  1.0187,  0.3713],\n",
      "        [-0.9101,  1.5096, -0.2792],\n",
      "        [ 0.2031, -0.0506, -0.5014],\n",
      "        [-1.1694,  1.7197, -0.7184],\n",
      "        [-1.4578,  0.0255,  1.0361],\n",
      "        [-1.3143,  1.6313, -0.5368],\n",
      "        [ 0.7223,  0.1016, -0.9507],\n",
      "        [-1.4729,  1.7734, -0.4096]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3635,  0.4710,  1.1305],\n",
      "        [ 0.4720, -0.0353, -1.0844],\n",
      "        [-2.0076,  1.1181,  0.4492],\n",
      "        [-1.5661,  1.8401, -0.4462],\n",
      "        [-1.2846,  1.6455, -0.5859],\n",
      "        [-1.3760,  0.1467,  1.0058],\n",
      "        [-1.7391,  0.1021,  1.0195],\n",
      "        [-1.8590,  0.0386,  1.1714],\n",
      "        [-0.6849,  1.1446, -0.7012],\n",
      "        [-1.5077,  0.0825,  0.8979],\n",
      "        [-1.1984,  1.7667, -0.6896],\n",
      "        [-1.0165,  1.5619, -0.5715],\n",
      "        [-1.4516,  1.9457, -0.5288],\n",
      "        [-1.6323,  0.1336,  1.0451],\n",
      "        [ 0.7700,  0.0092, -0.9275],\n",
      "        [-1.3483,  2.0346, -0.6052]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3635,  0.4710,  1.1305],\n",
      "        [ 0.4720, -0.0353, -1.0844],\n",
      "        [-2.0076,  1.1181,  0.4492],\n",
      "        [-1.5661,  1.8401, -0.4462],\n",
      "        [-1.2846,  1.6455, -0.5859],\n",
      "        [-1.3760,  0.1467,  1.0058],\n",
      "        [-1.7391,  0.1021,  1.0195],\n",
      "        [-1.8590,  0.0386,  1.1714],\n",
      "        [-0.6849,  1.1446, -0.7012],\n",
      "        [-1.5077,  0.0825,  0.8979],\n",
      "        [-1.1984,  1.7667, -0.6896],\n",
      "        [-1.0165,  1.5619, -0.5715],\n",
      "        [-1.4516,  1.9457, -0.5288],\n",
      "        [-1.6323,  0.1336,  1.0451],\n",
      "        [ 0.7700,  0.0092, -0.9275],\n",
      "        [-1.3483,  2.0346, -0.6052]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3018,  1.4446, -0.6256],\n",
      "        [-1.3014,  1.7990, -0.6022],\n",
      "        [-1.2999,  1.5785, -0.3557],\n",
      "        [-1.5589,  1.5859, -0.3437],\n",
      "        [-1.3633,  0.0557,  1.1184],\n",
      "        [-1.3029,  1.1748, -0.1112],\n",
      "        [-1.5471,  1.1451,  0.4636],\n",
      "        [ 0.5711, -0.1088, -0.9191],\n",
      "        [-0.6244,  1.3223, -0.8214],\n",
      "        [-1.4766,  0.1802,  1.0309],\n",
      "        [-1.2100,  1.4272, -0.3248],\n",
      "        [-1.1664,  1.7871, -0.7437],\n",
      "        [-1.9227,  0.7889,  0.6356],\n",
      "        [-1.0360,  1.6558, -0.5294],\n",
      "        [-1.0029,  1.5384, -0.7012],\n",
      "        [-1.3498,  1.8228, -0.8205]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3018,  1.4446, -0.6256],\n",
      "        [-1.3014,  1.7990, -0.6022],\n",
      "        [-1.2999,  1.5785, -0.3557],\n",
      "        [-1.5589,  1.5859, -0.3437],\n",
      "        [-1.3633,  0.0557,  1.1184],\n",
      "        [-1.3029,  1.1748, -0.1112],\n",
      "        [-1.5471,  1.1451,  0.4636],\n",
      "        [ 0.5711, -0.1088, -0.9191],\n",
      "        [-0.6244,  1.3223, -0.8214],\n",
      "        [-1.4766,  0.1802,  1.0309],\n",
      "        [-1.2100,  1.4272, -0.3248],\n",
      "        [-1.1664,  1.7871, -0.7437],\n",
      "        [-1.9227,  0.7889,  0.6356],\n",
      "        [-1.0360,  1.6558, -0.5294],\n",
      "        [-1.0029,  1.5384, -0.7012],\n",
      "        [-1.3498,  1.8228, -0.8205]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8578,  0.2468,  1.1745],\n",
      "        [-1.8234,  0.8009,  0.6265],\n",
      "        [-1.4914,  0.6081,  0.4201],\n",
      "        [-0.7676,  1.2485, -0.6864],\n",
      "        [-1.3854,  1.4835, -0.3738],\n",
      "        [-1.0113,  1.5816, -0.7154],\n",
      "        [-0.7645,  0.0758,  0.4424],\n",
      "        [-1.5604,  1.7035, -0.5668],\n",
      "        [-1.1859,  1.7785, -0.4097],\n",
      "        [-1.1144,  1.4853, -0.5058],\n",
      "        [-1.4658,  1.7079, -0.3914],\n",
      "        [-1.5811,  0.2768,  1.0361],\n",
      "        [-1.6894,  0.2627,  1.1414],\n",
      "        [-1.1972,  1.0926, -0.2768],\n",
      "        [-1.1899,  1.7670, -0.4386],\n",
      "        [-1.4482,  0.0717,  1.2160]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8578,  0.2468,  1.1745],\n",
      "        [-1.8234,  0.8009,  0.6265],\n",
      "        [-1.4914,  0.6081,  0.4201],\n",
      "        [-0.7676,  1.2485, -0.6864],\n",
      "        [-1.3854,  1.4835, -0.3738],\n",
      "        [-1.0113,  1.5816, -0.7154],\n",
      "        [-0.7645,  0.0758,  0.4424],\n",
      "        [-1.5604,  1.7035, -0.5668],\n",
      "        [-1.1859,  1.7785, -0.4097],\n",
      "        [-1.1144,  1.4853, -0.5058],\n",
      "        [-1.4658,  1.7079, -0.3914],\n",
      "        [-1.5811,  0.2768,  1.0361],\n",
      "        [-1.6894,  0.2627,  1.1414],\n",
      "        [-1.1972,  1.0926, -0.2768],\n",
      "        [-1.1899,  1.7670, -0.4386],\n",
      "        [-1.4482,  0.0717,  1.2160]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.1094,  1.6734, -0.8167],\n",
      "        [-1.1679,  1.5788, -0.5515],\n",
      "        [-1.7564,  0.2122,  1.2817],\n",
      "        [-1.5900,  1.6504, -0.1970],\n",
      "        [-1.6180,  0.0892,  1.2403],\n",
      "        [-1.8187,  0.1317,  1.0645],\n",
      "        [-1.2788,  1.9798, -0.5618],\n",
      "        [-1.5080,  1.7827, -0.1023],\n",
      "        [ 0.6154, -0.0306, -0.8671],\n",
      "        [-1.3332,  1.7121, -0.5655],\n",
      "        [-1.5034, -0.0323,  1.3414],\n",
      "        [-1.6612,  0.0387,  1.2107],\n",
      "        [-1.8563,  0.2290,  1.2955],\n",
      "        [-1.7917,  1.6266, -0.2292],\n",
      "        [-1.2449,  1.6472, -0.5700],\n",
      "        [-1.7357,  0.2550,  1.1002]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.1094,  1.6734, -0.8167],\n",
      "        [-1.1679,  1.5788, -0.5515],\n",
      "        [-1.7564,  0.2122,  1.2817],\n",
      "        [-1.5900,  1.6504, -0.1970],\n",
      "        [-1.6180,  0.0892,  1.2403],\n",
      "        [-1.8187,  0.1317,  1.0645],\n",
      "        [-1.2788,  1.9798, -0.5618],\n",
      "        [-1.5080,  1.7827, -0.1023],\n",
      "        [ 0.6154, -0.0306, -0.8671],\n",
      "        [-1.3332,  1.7121, -0.5655],\n",
      "        [-1.5034, -0.0323,  1.3414],\n",
      "        [-1.6612,  0.0387,  1.2107],\n",
      "        [-1.8563,  0.2290,  1.2955],\n",
      "        [-1.7917,  1.6266, -0.2292],\n",
      "        [-1.2449,  1.6472, -0.5700],\n",
      "        [-1.7357,  0.2550,  1.1002]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6212,  1.6614, -0.2808],\n",
      "        [-1.6859,  0.8689,  0.4109],\n",
      "        [-1.8145,  0.5396,  1.0842],\n",
      "        [-0.7309,  0.1523,  0.4819],\n",
      "        [-0.9630,  1.4290, -0.5998],\n",
      "        [-1.3093,  1.2586, -0.4148],\n",
      "        [-1.8071, -0.0708,  1.1587],\n",
      "        [ 0.4748, -0.2390, -0.4868],\n",
      "        [-1.0477,  1.8117, -0.5847],\n",
      "        [-1.8493,  0.1982,  1.1631],\n",
      "        [-1.6288,  0.5236,  0.8887],\n",
      "        [-1.4821,  1.5274, -0.1952],\n",
      "        [-1.6915,  0.9759,  0.3277],\n",
      "        [-1.8108,  0.4238,  1.2259],\n",
      "        [-1.9910,  0.4815,  1.2782],\n",
      "        [-1.5941,  0.2453,  1.3673]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6212,  1.6614, -0.2808],\n",
      "        [-1.6859,  0.8689,  0.4109],\n",
      "        [-1.8145,  0.5396,  1.0842],\n",
      "        [-0.7309,  0.1523,  0.4819],\n",
      "        [-0.9630,  1.4290, -0.5998],\n",
      "        [-1.3093,  1.2586, -0.4148],\n",
      "        [-1.8071, -0.0708,  1.1587],\n",
      "        [ 0.4748, -0.2390, -0.4868],\n",
      "        [-1.0477,  1.8117, -0.5847],\n",
      "        [-1.8493,  0.1982,  1.1631],\n",
      "        [-1.6288,  0.5236,  0.8887],\n",
      "        [-1.4821,  1.5274, -0.1952],\n",
      "        [-1.6915,  0.9759,  0.3277],\n",
      "        [-1.8108,  0.4238,  1.2259],\n",
      "        [-1.9910,  0.4815,  1.2782],\n",
      "        [-1.5941,  0.2453,  1.3673]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6917,  0.2718,  1.2528],\n",
      "        [ 0.4957, -0.1571, -0.7796],\n",
      "        [-1.8351,  0.1672,  1.1581],\n",
      "        [ 0.1544,  0.2687, -0.7888],\n",
      "        [-0.9586,  1.1735, -0.1711],\n",
      "        [-1.4105,  1.8016, -0.6443],\n",
      "        [-1.6738,  0.4821,  0.8851],\n",
      "        [-1.8207, -0.0513,  1.1771],\n",
      "        [-1.6213,  1.4818, -0.1658],\n",
      "        [-1.1578,  1.9115, -0.3772],\n",
      "        [-1.7110,  0.4389,  0.9634],\n",
      "        [-0.9527,  1.4069, -0.7129],\n",
      "        [ 0.5711,  0.1315, -1.0651],\n",
      "        [-1.7641, -0.0653,  1.3383],\n",
      "        [-1.6009,  0.2665,  1.0649],\n",
      "        [-1.6459,  0.3963,  0.9604]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6917,  0.2718,  1.2528],\n",
      "        [ 0.4957, -0.1571, -0.7796],\n",
      "        [-1.8351,  0.1672,  1.1581],\n",
      "        [ 0.1544,  0.2687, -0.7888],\n",
      "        [-0.9586,  1.1735, -0.1711],\n",
      "        [-1.4105,  1.8016, -0.6443],\n",
      "        [-1.6738,  0.4821,  0.8851],\n",
      "        [-1.8207, -0.0513,  1.1771],\n",
      "        [-1.6213,  1.4818, -0.1658],\n",
      "        [-1.1578,  1.9115, -0.3772],\n",
      "        [-1.7110,  0.4389,  0.9634],\n",
      "        [-0.9527,  1.4069, -0.7129],\n",
      "        [ 0.5711,  0.1315, -1.0651],\n",
      "        [-1.7641, -0.0653,  1.3383],\n",
      "        [-1.6009,  0.2665,  1.0649],\n",
      "        [-1.6459,  0.3963,  0.9604]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2588,  1.9372, -0.5755],\n",
      "        [-1.7183,  0.5639,  0.6778],\n",
      "        [-1.4689,  1.8356, -0.6351],\n",
      "        [-1.3782, -0.0145,  1.1723],\n",
      "        [-1.7201,  1.0479,  0.4056],\n",
      "        [-0.0163, -0.2495, -0.0903],\n",
      "        [-2.1382,  0.7178,  0.7863],\n",
      "        [-2.0694,  0.7179,  1.0213],\n",
      "        [-1.1396,  1.7056, -0.7907],\n",
      "        [-0.5461, -0.0588,  0.4007],\n",
      "        [-0.4869,  0.7744, -0.5224],\n",
      "        [-1.5221,  1.6947, -0.4759],\n",
      "        [-1.8784,  0.2912,  1.2625],\n",
      "        [-1.7287,  0.2491,  1.2600],\n",
      "        [-1.8173,  0.4504,  1.0564],\n",
      "        [-1.5737,  0.6786,  0.7319]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.2588,  1.9372, -0.5755],\n",
      "        [-1.7183,  0.5639,  0.6778],\n",
      "        [-1.4689,  1.8356, -0.6351],\n",
      "        [-1.3782, -0.0145,  1.1723],\n",
      "        [-1.7201,  1.0479,  0.4056],\n",
      "        [-0.0163, -0.2495, -0.0903],\n",
      "        [-2.1382,  0.7178,  0.7863],\n",
      "        [-2.0694,  0.7179,  1.0213],\n",
      "        [-1.1396,  1.7056, -0.7907],\n",
      "        [-0.5461, -0.0588,  0.4007],\n",
      "        [-0.4869,  0.7744, -0.5224],\n",
      "        [-1.5221,  1.6947, -0.4759],\n",
      "        [-1.8784,  0.2912,  1.2625],\n",
      "        [-1.7287,  0.2491,  1.2600],\n",
      "        [-1.8173,  0.4504,  1.0564],\n",
      "        [-1.5737,  0.6786,  0.7319]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.7783, -0.1906, -0.9851],\n",
      "        [ 0.6377, -0.1688, -0.8286],\n",
      "        [-0.8351,  1.2377, -0.8038],\n",
      "        [-0.3281,  0.8385, -0.8592],\n",
      "        [-1.5836, -0.0551,  1.0817],\n",
      "        [-1.1630,  1.9201, -0.5398],\n",
      "        [-1.1082,  1.4569, -0.5302],\n",
      "        [-1.5606,  1.7990, -0.5567],\n",
      "        [-1.6426,  1.8543, -0.2529],\n",
      "        [-0.8846,  1.4810, -0.5161],\n",
      "        [-2.0175,  1.3903,  0.5301],\n",
      "        [-1.3079,  1.4824, -0.6201],\n",
      "        [-1.7043, -0.0528,  1.2179],\n",
      "        [-1.8506,  0.4830,  1.0265],\n",
      "        [ 0.8443, -0.2345, -0.7961],\n",
      "        [-1.3142,  1.6167, -0.5519]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.7783, -0.1906, -0.9851],\n",
      "        [ 0.6377, -0.1688, -0.8286],\n",
      "        [-0.8351,  1.2377, -0.8038],\n",
      "        [-0.3281,  0.8385, -0.8592],\n",
      "        [-1.5836, -0.0551,  1.0817],\n",
      "        [-1.1630,  1.9201, -0.5398],\n",
      "        [-1.1082,  1.4569, -0.5302],\n",
      "        [-1.5606,  1.7990, -0.5567],\n",
      "        [-1.6426,  1.8543, -0.2529],\n",
      "        [-0.8846,  1.4810, -0.5161],\n",
      "        [-2.0175,  1.3903,  0.5301],\n",
      "        [-1.3079,  1.4824, -0.6201],\n",
      "        [-1.7043, -0.0528,  1.2179],\n",
      "        [-1.8506,  0.4830,  1.0265],\n",
      "        [ 0.8443, -0.2345, -0.7961],\n",
      "        [-1.3142,  1.6167, -0.5519]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2356,  1.2679, -0.3040],\n",
      "        [-1.4079,  1.6726, -0.5897],\n",
      "        [-1.2999,  1.4985, -0.3664],\n",
      "        [-1.2685,  1.6145, -0.2531],\n",
      "        [-1.6932, -0.1191,  1.1590],\n",
      "        [-1.3480,  1.7783, -0.4185],\n",
      "        [-1.7924,  1.3821,  0.0769],\n",
      "        [-1.6334,  1.7958, -0.0959],\n",
      "        [-1.7497,  0.1768,  1.3280],\n",
      "        [-1.9811,  0.4824,  1.2098],\n",
      "        [-1.6005,  1.9682, -0.4616],\n",
      "        [-1.2869,  1.6579, -0.4443],\n",
      "        [-0.7979,  1.3335, -0.8443],\n",
      "        [-1.4990,  1.5118, -0.2615],\n",
      "        [-2.1431,  0.2508,  1.4751],\n",
      "        [ 0.5581, -0.0890, -0.6692]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.2356,  1.2679, -0.3040],\n",
      "        [-1.4079,  1.6726, -0.5897],\n",
      "        [-1.2999,  1.4985, -0.3664],\n",
      "        [-1.2685,  1.6145, -0.2531],\n",
      "        [-1.6932, -0.1191,  1.1590],\n",
      "        [-1.3480,  1.7783, -0.4185],\n",
      "        [-1.7924,  1.3821,  0.0769],\n",
      "        [-1.6334,  1.7958, -0.0959],\n",
      "        [-1.7497,  0.1768,  1.3280],\n",
      "        [-1.9811,  0.4824,  1.2098],\n",
      "        [-1.6005,  1.9682, -0.4616],\n",
      "        [-1.2869,  1.6579, -0.4443],\n",
      "        [-0.7979,  1.3335, -0.8443],\n",
      "        [-1.4990,  1.5118, -0.2615],\n",
      "        [-2.1431,  0.2508,  1.4751],\n",
      "        [ 0.5581, -0.0890, -0.6692]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9332,  0.9724,  0.8265],\n",
      "        [-1.7380,  0.3141,  1.1101],\n",
      "        [-2.0389,  0.4166,  1.1886],\n",
      "        [ 0.4043, -0.0802, -0.5821],\n",
      "        [-1.6681,  1.8298, -0.3581],\n",
      "        [ 0.3910, -0.0148, -0.7565],\n",
      "        [-2.0732,  0.9514,  0.7468],\n",
      "        [-1.2075,  1.4354, -0.6021],\n",
      "        [-1.4402,  1.8724, -0.5189],\n",
      "        [-1.3283,  1.7744, -0.3173],\n",
      "        [-1.6841,  1.5225,  0.1007],\n",
      "        [-1.6957,  0.1828,  1.3629],\n",
      "        [-0.0313, -0.1326, -0.0596],\n",
      "        [-1.2768,  1.6627, -0.3875],\n",
      "        [-1.1855,  0.4901,  0.4361],\n",
      "        [-1.0896,  0.5261,  0.2966]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9332,  0.9724,  0.8265],\n",
      "        [-1.7380,  0.3141,  1.1101],\n",
      "        [-2.0389,  0.4166,  1.1886],\n",
      "        [ 0.4043, -0.0802, -0.5821],\n",
      "        [-1.6681,  1.8298, -0.3581],\n",
      "        [ 0.3910, -0.0148, -0.7565],\n",
      "        [-2.0732,  0.9514,  0.7468],\n",
      "        [-1.2075,  1.4354, -0.6021],\n",
      "        [-1.4402,  1.8724, -0.5189],\n",
      "        [-1.3283,  1.7744, -0.3173],\n",
      "        [-1.6841,  1.5225,  0.1007],\n",
      "        [-1.6957,  0.1828,  1.3629],\n",
      "        [-0.0313, -0.1326, -0.0596],\n",
      "        [-1.2768,  1.6627, -0.3875],\n",
      "        [-1.1855,  0.4901,  0.4361],\n",
      "        [-1.0896,  0.5261,  0.2966]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.3212,  0.4096,  1.0402],\n",
      "        [-1.6298,  0.0154,  1.1231],\n",
      "        [-1.1405,  1.6105, -0.4139],\n",
      "        [-1.6011,  2.1088, -0.2477],\n",
      "        [-1.3272,  1.6468, -0.8081],\n",
      "        [-1.4086,  1.6582, -0.4054],\n",
      "        [ 0.0420,  0.2749, -0.5436],\n",
      "        [ 0.6561, -0.1801, -0.7742],\n",
      "        [-1.3303,  1.7262, -0.4790],\n",
      "        [ 0.3348,  0.2067, -0.7074],\n",
      "        [-2.0870,  0.3089,  1.3991],\n",
      "        [-1.4085,  1.7786, -0.3494],\n",
      "        [-1.1970,  1.5407, -0.8100],\n",
      "        [ 0.0113,  0.3315, -0.6566],\n",
      "        [-0.7860,  1.6039, -0.8308],\n",
      "        [-1.2695,  1.7395, -0.5918]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.3212,  0.4096,  1.0402],\n",
      "        [-1.6298,  0.0154,  1.1231],\n",
      "        [-1.1405,  1.6105, -0.4139],\n",
      "        [-1.6011,  2.1088, -0.2477],\n",
      "        [-1.3272,  1.6468, -0.8081],\n",
      "        [-1.4086,  1.6582, -0.4054],\n",
      "        [ 0.0420,  0.2749, -0.5436],\n",
      "        [ 0.6561, -0.1801, -0.7742],\n",
      "        [-1.3303,  1.7262, -0.4790],\n",
      "        [ 0.3348,  0.2067, -0.7074],\n",
      "        [-2.0870,  0.3089,  1.3991],\n",
      "        [-1.4085,  1.7786, -0.3494],\n",
      "        [-1.1970,  1.5407, -0.8100],\n",
      "        [ 0.0113,  0.3315, -0.6566],\n",
      "        [-0.7860,  1.6039, -0.8308],\n",
      "        [-1.2695,  1.7395, -0.5918]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9599,  1.2297,  0.5135],\n",
      "        [-1.3094,  1.8398, -0.5243],\n",
      "        [-1.8277,  0.1859,  1.2791],\n",
      "        [-2.0634,  0.5140,  1.1969],\n",
      "        [-1.4175,  1.7700, -0.6032],\n",
      "        [ 0.2998, -0.1923, -0.5294],\n",
      "        [-1.4600,  1.8012, -0.3987],\n",
      "        [-1.1956,  1.7524, -0.6168],\n",
      "        [-1.3223,  1.6675, -0.4367],\n",
      "        [-1.8382,  0.6345,  0.8768],\n",
      "        [-1.4524,  2.0403, -0.5378],\n",
      "        [-1.4735,  1.7702, -0.5796],\n",
      "        [-1.9469,  1.4882,  0.1952],\n",
      "        [-1.2404,  1.6839, -0.4374],\n",
      "        [-0.5655,  1.2038, -0.6384],\n",
      "        [-1.4862,  1.7801, -0.3068]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9599,  1.2297,  0.5135],\n",
      "        [-1.3094,  1.8398, -0.5243],\n",
      "        [-1.8277,  0.1859,  1.2791],\n",
      "        [-2.0634,  0.5140,  1.1969],\n",
      "        [-1.4175,  1.7700, -0.6032],\n",
      "        [ 0.2998, -0.1923, -0.5294],\n",
      "        [-1.4600,  1.8012, -0.3987],\n",
      "        [-1.1956,  1.7524, -0.6168],\n",
      "        [-1.3223,  1.6675, -0.4367],\n",
      "        [-1.8382,  0.6345,  0.8768],\n",
      "        [-1.4524,  2.0403, -0.5378],\n",
      "        [-1.4735,  1.7702, -0.5796],\n",
      "        [-1.9469,  1.4882,  0.1952],\n",
      "        [-1.2404,  1.6839, -0.4374],\n",
      "        [-0.5655,  1.2038, -0.6384],\n",
      "        [-1.4862,  1.7801, -0.3068]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0900,  1.1634,  0.4443],\n",
      "        [ 0.2648, -0.0438, -0.6904],\n",
      "        [ 0.5842, -0.0363, -0.8356],\n",
      "        [-1.3366,  2.1410, -0.6584],\n",
      "        [-1.9008,  0.3999,  1.2661],\n",
      "        [-1.6814,  1.8590, -0.3172],\n",
      "        [-1.7539,  2.0141, -0.1392],\n",
      "        [-1.5506,  1.7691, -0.3913],\n",
      "        [-1.8514,  0.1696,  1.1499],\n",
      "        [-1.3246,  2.0107, -0.7740],\n",
      "        [-1.3521,  1.6101, -0.6620],\n",
      "        [-0.6066,  1.1688, -0.9010],\n",
      "        [-1.4530,  1.8531, -0.5220],\n",
      "        [ 0.3702,  0.3922, -0.9482],\n",
      "        [-1.2950,  1.6457, -0.6270],\n",
      "        [-1.6420,  2.0038, -0.4079]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.0900,  1.1634,  0.4443],\n",
      "        [ 0.2648, -0.0438, -0.6904],\n",
      "        [ 0.5842, -0.0363, -0.8356],\n",
      "        [-1.3366,  2.1410, -0.6584],\n",
      "        [-1.9008,  0.3999,  1.2661],\n",
      "        [-1.6814,  1.8590, -0.3172],\n",
      "        [-1.7539,  2.0141, -0.1392],\n",
      "        [-1.5506,  1.7691, -0.3913],\n",
      "        [-1.8514,  0.1696,  1.1499],\n",
      "        [-1.3246,  2.0107, -0.7740],\n",
      "        [-1.3521,  1.6101, -0.6620],\n",
      "        [-0.6066,  1.1688, -0.9010],\n",
      "        [-1.4530,  1.8531, -0.5220],\n",
      "        [ 0.3702,  0.3922, -0.9482],\n",
      "        [-1.2950,  1.6457, -0.6270],\n",
      "        [-1.6420,  2.0038, -0.4079]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1438,  0.3974,  1.2203],\n",
      "        [-1.9557,  0.6797,  0.8921],\n",
      "        [-1.6063,  1.7090, -0.4532],\n",
      "        [-1.0967,  1.5000, -0.4659],\n",
      "        [-1.8148,  0.0701,  1.1597],\n",
      "        [-1.7026,  1.6183, -0.2363],\n",
      "        [-1.6322,  1.9610, -0.5893],\n",
      "        [-2.0304,  0.6579,  0.8714],\n",
      "        [-1.6787,  2.0790, -0.2976],\n",
      "        [-1.2815,  1.8638, -0.5439],\n",
      "        [-1.8931,  0.5110,  1.0329],\n",
      "        [-1.5198,  1.9792, -0.6155],\n",
      "        [-1.8732,  1.8248, -0.2999],\n",
      "        [-1.9092,  1.7148, -0.3256],\n",
      "        [-1.6026,  2.0051, -0.5434],\n",
      "        [-1.3229,  1.8544, -0.4867]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.1438,  0.3974,  1.2203],\n",
      "        [-1.9557,  0.6797,  0.8921],\n",
      "        [-1.6063,  1.7090, -0.4532],\n",
      "        [-1.0967,  1.5000, -0.4659],\n",
      "        [-1.8148,  0.0701,  1.1597],\n",
      "        [-1.7026,  1.6183, -0.2363],\n",
      "        [-1.6322,  1.9610, -0.5893],\n",
      "        [-2.0304,  0.6579,  0.8714],\n",
      "        [-1.6787,  2.0790, -0.2976],\n",
      "        [-1.2815,  1.8638, -0.5439],\n",
      "        [-1.8931,  0.5110,  1.0329],\n",
      "        [-1.5198,  1.9792, -0.6155],\n",
      "        [-1.8732,  1.8248, -0.2999],\n",
      "        [-1.9092,  1.7148, -0.3256],\n",
      "        [-1.6026,  2.0051, -0.5434],\n",
      "        [-1.3229,  1.8544, -0.4867]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9677,  1.0890,  0.4164],\n",
      "        [-1.7157,  1.6872,  0.0028],\n",
      "        [-2.1156,  1.0456,  0.8007],\n",
      "        [-2.4226,  0.5915,  1.3972],\n",
      "        [-1.4835,  1.8244, -0.3640],\n",
      "        [-1.5185,  1.9588, -0.5272],\n",
      "        [-1.8555,  1.7001, -0.0028],\n",
      "        [-1.6217,  1.8537, -0.3512],\n",
      "        [-1.7274,  1.7479, -0.0592],\n",
      "        [-1.7050,  1.9091, -0.4366],\n",
      "        [-1.9659,  1.0229,  0.7634],\n",
      "        [-1.7865,  0.2741,  1.1821],\n",
      "        [-1.5947,  1.8875, -0.6645],\n",
      "        [-1.6333,  0.3717,  1.1178],\n",
      "        [-1.8879,  1.6557, -0.4223],\n",
      "        [ 0.4114, -0.0563, -0.7571]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9677,  1.0890,  0.4164],\n",
      "        [-1.7157,  1.6872,  0.0028],\n",
      "        [-2.1156,  1.0456,  0.8007],\n",
      "        [-2.4226,  0.5915,  1.3972],\n",
      "        [-1.4835,  1.8244, -0.3640],\n",
      "        [-1.5185,  1.9588, -0.5272],\n",
      "        [-1.8555,  1.7001, -0.0028],\n",
      "        [-1.6217,  1.8537, -0.3512],\n",
      "        [-1.7274,  1.7479, -0.0592],\n",
      "        [-1.7050,  1.9091, -0.4366],\n",
      "        [-1.9659,  1.0229,  0.7634],\n",
      "        [-1.7865,  0.2741,  1.1821],\n",
      "        [-1.5947,  1.8875, -0.6645],\n",
      "        [-1.6333,  0.3717,  1.1178],\n",
      "        [-1.8879,  1.6557, -0.4223],\n",
      "        [ 0.4114, -0.0563, -0.7571]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6908,  1.7773, -0.3534],\n",
      "        [-1.6351,  2.0891, -0.3636],\n",
      "        [-1.7102,  1.7350, -0.3458],\n",
      "        [-1.5360,  1.9997, -0.7154],\n",
      "        [-1.7110,  2.1971, -0.6079],\n",
      "        [-1.6377,  2.0493, -0.2008],\n",
      "        [-1.5347,  0.8928,  0.5230],\n",
      "        [-0.5538,  1.2011, -0.8268],\n",
      "        [-1.9729,  0.5362,  0.9216],\n",
      "        [-1.7300,  2.1823, -0.4716],\n",
      "        [-1.6235,  2.0031, -0.4073],\n",
      "        [-1.6188,  1.9749, -0.4792],\n",
      "        [-1.3440,  2.1416, -0.7366],\n",
      "        [-1.8814,  0.5300,  1.0462],\n",
      "        [-2.2143,  0.5555,  1.1495],\n",
      "        [-1.7217,  2.2298, -0.4074]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6908,  1.7773, -0.3534],\n",
      "        [-1.6351,  2.0891, -0.3636],\n",
      "        [-1.7102,  1.7350, -0.3458],\n",
      "        [-1.5360,  1.9997, -0.7154],\n",
      "        [-1.7110,  2.1971, -0.6079],\n",
      "        [-1.6377,  2.0493, -0.2008],\n",
      "        [-1.5347,  0.8928,  0.5230],\n",
      "        [-0.5538,  1.2011, -0.8268],\n",
      "        [-1.9729,  0.5362,  0.9216],\n",
      "        [-1.7300,  2.1823, -0.4716],\n",
      "        [-1.6235,  2.0031, -0.4073],\n",
      "        [-1.6188,  1.9749, -0.4792],\n",
      "        [-1.3440,  2.1416, -0.7366],\n",
      "        [-1.8814,  0.5300,  1.0462],\n",
      "        [-2.2143,  0.5555,  1.1495],\n",
      "        [-1.7217,  2.2298, -0.4074]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.4053,  0.3148, -1.0955],\n",
      "        [-1.5915,  1.9636, -0.3565],\n",
      "        [-2.1327,  0.6928,  1.0536],\n",
      "        [-1.5844,  2.0813, -0.5912],\n",
      "        [ 0.3818,  0.1061, -0.9206],\n",
      "        [-1.8180,  1.9127, -0.4315],\n",
      "        [-2.1171,  0.8056,  0.8728],\n",
      "        [-1.6127,  0.6470,  0.4877],\n",
      "        [-1.7156,  2.2044, -0.5525],\n",
      "        [-1.5132,  2.0672, -0.5551],\n",
      "        [-1.4362,  1.9077, -0.3334],\n",
      "        [-1.8126,  0.2863,  1.2882],\n",
      "        [-1.8234,  1.8538, -0.2953],\n",
      "        [-2.1432,  1.0941,  0.6135],\n",
      "        [-2.0549,  0.7609,  1.0317],\n",
      "        [-1.5557,  1.9032, -0.3445]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.4053,  0.3148, -1.0955],\n",
      "        [-1.5915,  1.9636, -0.3565],\n",
      "        [-2.1327,  0.6928,  1.0536],\n",
      "        [-1.5844,  2.0813, -0.5912],\n",
      "        [ 0.3818,  0.1061, -0.9206],\n",
      "        [-1.8180,  1.9127, -0.4315],\n",
      "        [-2.1171,  0.8056,  0.8728],\n",
      "        [-1.6127,  0.6470,  0.4877],\n",
      "        [-1.7156,  2.2044, -0.5525],\n",
      "        [-1.5132,  2.0672, -0.5551],\n",
      "        [-1.4362,  1.9077, -0.3334],\n",
      "        [-1.8126,  0.2863,  1.2882],\n",
      "        [-1.8234,  1.8538, -0.2953],\n",
      "        [-2.1432,  1.0941,  0.6135],\n",
      "        [-2.0549,  0.7609,  1.0317],\n",
      "        [-1.5557,  1.9032, -0.3445]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7917e+00,  2.3284e-01,  1.0344e+00],\n",
      "        [-1.7784e+00,  3.7567e-01,  1.2530e+00],\n",
      "        [ 6.7674e-01, -1.0496e-01, -9.6751e-01],\n",
      "        [-2.0590e+00,  1.8779e+00, -5.3598e-02],\n",
      "        [-1.6626e+00,  1.9756e+00, -4.0503e-01],\n",
      "        [-1.9525e+00,  2.2789e+00, -5.2064e-01],\n",
      "        [-1.8051e+00,  4.2873e-01,  1.0528e+00],\n",
      "        [-1.6370e+00,  2.2463e+00, -5.6880e-01],\n",
      "        [-1.7741e+00,  1.8010e+00, -7.3129e-04],\n",
      "        [-1.6181e+00,  1.9518e+00, -4.2724e-01],\n",
      "        [-2.4483e+00,  1.6618e+00,  3.4239e-01],\n",
      "        [-1.7575e+00,  1.9183e+00, -4.3116e-01],\n",
      "        [-2.0288e+00,  9.1199e-01,  7.9772e-01],\n",
      "        [-2.2631e+00,  1.1736e+00,  7.6387e-01],\n",
      "        [-1.8190e+00,  1.8768e+00, -5.7511e-01],\n",
      "        [-1.4353e+00,  2.0340e+00, -6.2388e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7917e+00,  2.3284e-01,  1.0344e+00],\n",
      "        [-1.7784e+00,  3.7567e-01,  1.2530e+00],\n",
      "        [ 6.7674e-01, -1.0496e-01, -9.6751e-01],\n",
      "        [-2.0590e+00,  1.8779e+00, -5.3598e-02],\n",
      "        [-1.6626e+00,  1.9756e+00, -4.0503e-01],\n",
      "        [-1.9525e+00,  2.2789e+00, -5.2064e-01],\n",
      "        [-1.8051e+00,  4.2873e-01,  1.0528e+00],\n",
      "        [-1.6370e+00,  2.2463e+00, -5.6880e-01],\n",
      "        [-1.7741e+00,  1.8010e+00, -7.3129e-04],\n",
      "        [-1.6181e+00,  1.9518e+00, -4.2724e-01],\n",
      "        [-2.4483e+00,  1.6618e+00,  3.4239e-01],\n",
      "        [-1.7575e+00,  1.9183e+00, -4.3116e-01],\n",
      "        [-2.0288e+00,  9.1199e-01,  7.9772e-01],\n",
      "        [-2.2631e+00,  1.1736e+00,  7.6387e-01],\n",
      "        [-1.8190e+00,  1.8768e+00, -5.7511e-01],\n",
      "        [-1.4353e+00,  2.0340e+00, -6.2388e-01]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7679,  2.1359, -0.3493],\n",
      "        [-1.8135,  2.2142, -0.4329],\n",
      "        [-1.6420,  2.0343, -0.2353],\n",
      "        [-1.7025,  1.8590, -0.4345],\n",
      "        [ 0.4854, -0.0661, -1.0141],\n",
      "        [-1.9911,  2.1332, -0.2885],\n",
      "        [-0.0036,  0.3544, -0.5381],\n",
      "        [-1.7941,  1.4189, -0.2811],\n",
      "        [-2.4170,  1.8154,  0.3219],\n",
      "        [-1.5626,  1.7821, -0.4360],\n",
      "        [-1.2793,  1.5425, -0.5997],\n",
      "        [-1.7527,  2.0271, -0.6312],\n",
      "        [-2.0134,  1.7975,  0.1207],\n",
      "        [-1.3732,  1.6321, -0.4413],\n",
      "        [-2.0889,  1.7723,  0.0794],\n",
      "        [-1.8953,  1.9825, -0.3443]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7679,  2.1359, -0.3493],\n",
      "        [-1.8135,  2.2142, -0.4329],\n",
      "        [-1.6420,  2.0343, -0.2353],\n",
      "        [-1.7025,  1.8590, -0.4345],\n",
      "        [ 0.4854, -0.0661, -1.0141],\n",
      "        [-1.9911,  2.1332, -0.2885],\n",
      "        [-0.0036,  0.3544, -0.5381],\n",
      "        [-1.7941,  1.4189, -0.2811],\n",
      "        [-2.4170,  1.8154,  0.3219],\n",
      "        [-1.5626,  1.7821, -0.4360],\n",
      "        [-1.2793,  1.5425, -0.5997],\n",
      "        [-1.7527,  2.0271, -0.6312],\n",
      "        [-2.0134,  1.7975,  0.1207],\n",
      "        [-1.3732,  1.6321, -0.4413],\n",
      "        [-2.0889,  1.7723,  0.0794],\n",
      "        [-1.8953,  1.9825, -0.3443]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5824,  0.2020, -0.9547],\n",
      "        [-1.6759,  2.1564, -0.1438],\n",
      "        [-2.0570,  0.8636,  0.9925],\n",
      "        [-1.9621,  0.5454,  1.1464],\n",
      "        [-2.4482,  2.0785,  0.0497],\n",
      "        [-1.6559,  2.1020, -0.4884],\n",
      "        [-1.6286,  2.1955, -0.4307],\n",
      "        [-2.0061,  1.8307, -0.4473],\n",
      "        [ 0.7036, -0.0214, -0.9513],\n",
      "        [ 0.6085, -0.0167, -1.0085],\n",
      "        [-1.5254,  1.8474, -0.2458],\n",
      "        [-1.7883,  2.0556, -0.3316],\n",
      "        [-1.8554,  1.8201,  0.1281],\n",
      "        [-1.9870,  1.9580, -0.0904],\n",
      "        [-1.9451,  2.0919, -0.2922],\n",
      "        [-1.9431,  1.9926, -0.1145]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.5824,  0.2020, -0.9547],\n",
      "        [-1.6759,  2.1564, -0.1438],\n",
      "        [-2.0570,  0.8636,  0.9925],\n",
      "        [-1.9621,  0.5454,  1.1464],\n",
      "        [-2.4482,  2.0785,  0.0497],\n",
      "        [-1.6559,  2.1020, -0.4884],\n",
      "        [-1.6286,  2.1955, -0.4307],\n",
      "        [-2.0061,  1.8307, -0.4473],\n",
      "        [ 0.7036, -0.0214, -0.9513],\n",
      "        [ 0.6085, -0.0167, -1.0085],\n",
      "        [-1.5254,  1.8474, -0.2458],\n",
      "        [-1.7883,  2.0556, -0.3316],\n",
      "        [-1.8554,  1.8201,  0.1281],\n",
      "        [-1.9870,  1.9580, -0.0904],\n",
      "        [-1.9451,  2.0919, -0.2922],\n",
      "        [-1.9431,  1.9926, -0.1145]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1020,  1.9496, -0.3218],\n",
      "        [-1.6033,  1.9349, -0.3926],\n",
      "        [-1.7152,  2.1485, -0.5893],\n",
      "        [-1.5543,  1.9917, -0.4640],\n",
      "        [-1.4698,  1.7138, -0.4454],\n",
      "        [-2.0475,  2.0410, -0.1787],\n",
      "        [-2.1791,  0.5950,  0.9211],\n",
      "        [-1.5006,  1.7337, -0.4556],\n",
      "        [-2.0778,  1.4929,  0.4591],\n",
      "        [-2.1144,  0.7224,  0.9434],\n",
      "        [-1.7933,  2.0094, -0.3490],\n",
      "        [-1.8311,  1.7549, -0.2168],\n",
      "        [-1.7860,  2.1134, -0.4194],\n",
      "        [-1.9692,  2.0919, -0.2115],\n",
      "        [-1.6874,  1.9233, -0.3188],\n",
      "        [-1.2386,  1.4028, -0.2955]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.1020,  1.9496, -0.3218],\n",
      "        [-1.6033,  1.9349, -0.3926],\n",
      "        [-1.7152,  2.1485, -0.5893],\n",
      "        [-1.5543,  1.9917, -0.4640],\n",
      "        [-1.4698,  1.7138, -0.4454],\n",
      "        [-2.0475,  2.0410, -0.1787],\n",
      "        [-2.1791,  0.5950,  0.9211],\n",
      "        [-1.5006,  1.7337, -0.4556],\n",
      "        [-2.0778,  1.4929,  0.4591],\n",
      "        [-2.1144,  0.7224,  0.9434],\n",
      "        [-1.7933,  2.0094, -0.3490],\n",
      "        [-1.8311,  1.7549, -0.2168],\n",
      "        [-1.7860,  2.1134, -0.4194],\n",
      "        [-1.9692,  2.0919, -0.2115],\n",
      "        [-1.6874,  1.9233, -0.3188],\n",
      "        [-1.2386,  1.4028, -0.2955]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9460,  1.7087, -0.5237],\n",
      "        [-1.9995,  1.0583,  0.5302],\n",
      "        [-1.8472,  2.0217, -0.3616],\n",
      "        [-2.3147,  1.0399,  1.0837],\n",
      "        [-1.7801,  1.7824, -0.0419],\n",
      "        [-1.8404,  0.4681,  1.0259],\n",
      "        [-1.9804,  2.2716, -0.3475],\n",
      "        [-1.5917,  1.7186, -0.3396],\n",
      "        [-1.5554,  1.9726, -0.5792],\n",
      "        [ 0.6586,  0.1921, -1.0866],\n",
      "        [-1.5892,  1.8809, -0.3995],\n",
      "        [-1.6574,  1.8735, -0.4443],\n",
      "        [-1.6362,  2.0157, -0.1405],\n",
      "        [-1.8787,  2.0117, -0.4219],\n",
      "        [ 0.8586, -0.0688, -1.0211],\n",
      "        [-2.0375,  0.5612,  0.6719]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9460,  1.7087, -0.5237],\n",
      "        [-1.9995,  1.0583,  0.5302],\n",
      "        [-1.8472,  2.0217, -0.3616],\n",
      "        [-2.3147,  1.0399,  1.0837],\n",
      "        [-1.7801,  1.7824, -0.0419],\n",
      "        [-1.8404,  0.4681,  1.0259],\n",
      "        [-1.9804,  2.2716, -0.3475],\n",
      "        [-1.5917,  1.7186, -0.3396],\n",
      "        [-1.5554,  1.9726, -0.5792],\n",
      "        [ 0.6586,  0.1921, -1.0866],\n",
      "        [-1.5892,  1.8809, -0.3995],\n",
      "        [-1.6574,  1.8735, -0.4443],\n",
      "        [-1.6362,  2.0157, -0.1405],\n",
      "        [-1.8787,  2.0117, -0.4219],\n",
      "        [ 0.8586, -0.0688, -1.0211],\n",
      "        [-2.0375,  0.5612,  0.6719]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1247e+00,  1.9272e+00,  1.4634e-01],\n",
      "        [-2.0161e+00,  2.0042e+00,  4.4966e-04],\n",
      "        [-2.1776e+00,  1.2359e+00,  5.0065e-01],\n",
      "        [-1.9849e+00,  1.4254e+00,  4.7441e-01],\n",
      "        [-2.3230e+00,  8.3024e-01,  1.1249e+00],\n",
      "        [-1.9446e+00,  5.8587e-01,  8.5805e-01],\n",
      "        [-1.7612e+00,  2.0485e+00, -3.5346e-01],\n",
      "        [-1.7949e+00,  2.0420e+00, -3.2816e-01],\n",
      "        [-2.0154e+00,  7.3728e-01,  7.7266e-01],\n",
      "        [-1.8484e+00,  2.0247e+00, -2.0875e-01],\n",
      "        [-6.9890e-01,  4.9615e-01, -1.9342e-02],\n",
      "        [ 3.9519e-01,  1.5071e-01, -7.7649e-01],\n",
      "        [-2.2969e+00,  1.9680e+00, -4.6888e-02],\n",
      "        [-2.1902e+00,  7.9755e-01,  8.7494e-01],\n",
      "        [-1.8657e+00,  1.9144e+00, -1.8724e-01],\n",
      "        [-1.7464e+00,  1.9700e+00, -2.8957e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.1247e+00,  1.9272e+00,  1.4634e-01],\n",
      "        [-2.0161e+00,  2.0042e+00,  4.4966e-04],\n",
      "        [-2.1776e+00,  1.2359e+00,  5.0065e-01],\n",
      "        [-1.9849e+00,  1.4254e+00,  4.7441e-01],\n",
      "        [-2.3230e+00,  8.3024e-01,  1.1249e+00],\n",
      "        [-1.9446e+00,  5.8587e-01,  8.5805e-01],\n",
      "        [-1.7612e+00,  2.0485e+00, -3.5346e-01],\n",
      "        [-1.7949e+00,  2.0420e+00, -3.2816e-01],\n",
      "        [-2.0154e+00,  7.3728e-01,  7.7266e-01],\n",
      "        [-1.8484e+00,  2.0247e+00, -2.0875e-01],\n",
      "        [-6.9890e-01,  4.9615e-01, -1.9342e-02],\n",
      "        [ 3.9519e-01,  1.5071e-01, -7.7649e-01],\n",
      "        [-2.2969e+00,  1.9680e+00, -4.6888e-02],\n",
      "        [-2.1902e+00,  7.9755e-01,  8.7494e-01],\n",
      "        [-1.8657e+00,  1.9144e+00, -1.8724e-01],\n",
      "        [-1.7464e+00,  1.9700e+00, -2.8957e-01]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9736,  1.8908, -0.1743],\n",
      "        [-2.1029,  2.1890, -0.2979],\n",
      "        [ 0.8311, -0.0605, -1.1241],\n",
      "        [-2.3003,  1.3613,  0.7382],\n",
      "        [-1.8130,  0.8381,  0.5511],\n",
      "        [-0.7022,  1.2809, -0.6841],\n",
      "        [-1.7146,  0.1062,  1.3618],\n",
      "        [-1.7536,  1.9360, -0.1955],\n",
      "        [-1.7430,  2.0000, -0.3408],\n",
      "        [-1.6749,  1.6973, -0.3013],\n",
      "        [-1.8399,  2.0022, -0.2094],\n",
      "        [-1.1854,  1.6903, -0.4891],\n",
      "        [-1.7322,  1.9194, -0.3406],\n",
      "        [-1.6586,  0.5810,  1.0126],\n",
      "        [-1.9064,  1.9872, -0.0801],\n",
      "        [-1.7511,  1.7010, -0.3547]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9736,  1.8908, -0.1743],\n",
      "        [-2.1029,  2.1890, -0.2979],\n",
      "        [ 0.8311, -0.0605, -1.1241],\n",
      "        [-2.3003,  1.3613,  0.7382],\n",
      "        [-1.8130,  0.8381,  0.5511],\n",
      "        [-0.7022,  1.2809, -0.6841],\n",
      "        [-1.7146,  0.1062,  1.3618],\n",
      "        [-1.7536,  1.9360, -0.1955],\n",
      "        [-1.7430,  2.0000, -0.3408],\n",
      "        [-1.6749,  1.6973, -0.3013],\n",
      "        [-1.8399,  2.0022, -0.2094],\n",
      "        [-1.1854,  1.6903, -0.4891],\n",
      "        [-1.7322,  1.9194, -0.3406],\n",
      "        [-1.6586,  0.5810,  1.0126],\n",
      "        [-1.9064,  1.9872, -0.0801],\n",
      "        [-1.7511,  1.7010, -0.3547]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8279,  1.9857, -0.2974],\n",
      "        [-2.0801,  1.9076, -0.1380],\n",
      "        [-1.0927,  1.6291, -0.5943],\n",
      "        [-1.8365,  1.9915, -0.1607],\n",
      "        [-1.8487,  1.9624, -0.2091],\n",
      "        [-1.8986,  0.2878,  1.1534],\n",
      "        [-1.7578,  2.0044, -0.1555],\n",
      "        [-1.6784,  0.9127,  0.6119],\n",
      "        [-0.6701,  0.4714,  0.0276],\n",
      "        [ 0.3275,  0.3538, -1.0149],\n",
      "        [ 0.4775, -0.0735, -0.9274],\n",
      "        [-1.8205,  0.4103,  1.1676],\n",
      "        [-1.7463,  1.9320, -0.3098],\n",
      "        [-2.1946,  0.8208,  0.9407],\n",
      "        [-1.9103,  2.0507, -0.1014],\n",
      "        [-1.6268,  1.8597, -0.2414]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8279,  1.9857, -0.2974],\n",
      "        [-2.0801,  1.9076, -0.1380],\n",
      "        [-1.0927,  1.6291, -0.5943],\n",
      "        [-1.8365,  1.9915, -0.1607],\n",
      "        [-1.8487,  1.9624, -0.2091],\n",
      "        [-1.8986,  0.2878,  1.1534],\n",
      "        [-1.7578,  2.0044, -0.1555],\n",
      "        [-1.6784,  0.9127,  0.6119],\n",
      "        [-0.6701,  0.4714,  0.0276],\n",
      "        [ 0.3275,  0.3538, -1.0149],\n",
      "        [ 0.4775, -0.0735, -0.9274],\n",
      "        [-1.8205,  0.4103,  1.1676],\n",
      "        [-1.7463,  1.9320, -0.3098],\n",
      "        [-2.1946,  0.8208,  0.9407],\n",
      "        [-1.9103,  2.0507, -0.1014],\n",
      "        [-1.6268,  1.8597, -0.2414]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0388e+00,  1.0728e+00,  7.9340e-01],\n",
      "        [-1.4539e+00,  1.0004e-02,  1.1918e+00],\n",
      "        [-1.9009e+00,  4.7413e-01,  1.1358e+00],\n",
      "        [-2.2065e+00,  2.1130e+00, -7.7575e-02],\n",
      "        [-1.7585e+00,  5.0874e-01,  9.7516e-01],\n",
      "        [-1.6437e+00, -1.1966e-05,  1.1165e+00],\n",
      "        [ 7.1616e-01, -1.2322e-01, -7.5012e-01],\n",
      "        [-1.7946e+00,  4.0875e-01,  1.1555e+00],\n",
      "        [-1.7019e+00,  1.9019e+00, -1.6133e-01],\n",
      "        [-2.1422e+00,  1.9547e+00,  1.1015e-01],\n",
      "        [-1.7902e+00,  1.9501e+00, -5.0211e-01],\n",
      "        [ 3.7349e-01,  1.4800e-01, -8.6248e-01],\n",
      "        [-2.0096e+00,  1.5265e+00,  3.2996e-01],\n",
      "        [-1.7811e+00,  4.8739e-01,  1.0496e+00],\n",
      "        [-2.0588e+00,  2.0116e+00, -3.5530e-01],\n",
      "        [-2.0061e+00,  2.1467e+00, -8.3223e-02]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.0388e+00,  1.0728e+00,  7.9340e-01],\n",
      "        [-1.4539e+00,  1.0004e-02,  1.1918e+00],\n",
      "        [-1.9009e+00,  4.7413e-01,  1.1358e+00],\n",
      "        [-2.2065e+00,  2.1130e+00, -7.7575e-02],\n",
      "        [-1.7585e+00,  5.0874e-01,  9.7516e-01],\n",
      "        [-1.6437e+00, -1.1966e-05,  1.1165e+00],\n",
      "        [ 7.1616e-01, -1.2322e-01, -7.5012e-01],\n",
      "        [-1.7946e+00,  4.0875e-01,  1.1555e+00],\n",
      "        [-1.7019e+00,  1.9019e+00, -1.6133e-01],\n",
      "        [-2.1422e+00,  1.9547e+00,  1.1015e-01],\n",
      "        [-1.7902e+00,  1.9501e+00, -5.0211e-01],\n",
      "        [ 3.7349e-01,  1.4800e-01, -8.6248e-01],\n",
      "        [-2.0096e+00,  1.5265e+00,  3.2996e-01],\n",
      "        [-1.7811e+00,  4.8739e-01,  1.0496e+00],\n",
      "        [-2.0588e+00,  2.0116e+00, -3.5530e-01],\n",
      "        [-2.0061e+00,  2.1467e+00, -8.3223e-02]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5806,  0.0221, -0.9597],\n",
      "        [ 0.4003,  0.0712, -0.9199],\n",
      "        [-2.0314,  0.2000,  1.1166],\n",
      "        [-2.2018,  0.6254,  1.1223],\n",
      "        [-1.6982,  0.2416,  1.0703],\n",
      "        [-1.9643,  2.1376, -0.3440],\n",
      "        [-1.5122,  1.7228, -0.4589],\n",
      "        [-1.9314,  1.9469,  0.0346],\n",
      "        [ 0.1911,  0.3618, -0.8753],\n",
      "        [-1.7308,  1.9075, -0.3242],\n",
      "        [-1.8062,  1.7791, -0.0131],\n",
      "        [-1.7874,  1.7601, -0.2427],\n",
      "        [-2.3728,  1.4065,  0.6269],\n",
      "        [-1.8851,  1.7462, -0.0983],\n",
      "        [-2.1310,  0.2729,  1.2602],\n",
      "        [-1.6905,  1.8812, -0.1379]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.5806,  0.0221, -0.9597],\n",
      "        [ 0.4003,  0.0712, -0.9199],\n",
      "        [-2.0314,  0.2000,  1.1166],\n",
      "        [-2.2018,  0.6254,  1.1223],\n",
      "        [-1.6982,  0.2416,  1.0703],\n",
      "        [-1.9643,  2.1376, -0.3440],\n",
      "        [-1.5122,  1.7228, -0.4589],\n",
      "        [-1.9314,  1.9469,  0.0346],\n",
      "        [ 0.1911,  0.3618, -0.8753],\n",
      "        [-1.7308,  1.9075, -0.3242],\n",
      "        [-1.8062,  1.7791, -0.0131],\n",
      "        [-1.7874,  1.7601, -0.2427],\n",
      "        [-2.3728,  1.4065,  0.6269],\n",
      "        [-1.8851,  1.7462, -0.0983],\n",
      "        [-2.1310,  0.2729,  1.2602],\n",
      "        [-1.6905,  1.8812, -0.1379]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1033,  2.1409,  0.0359],\n",
      "        [-0.7506,  0.9531, -0.4982],\n",
      "        [-1.9322,  1.8228, -0.0079],\n",
      "        [-2.3090,  0.7984,  1.4036],\n",
      "        [ 0.6599, -0.1417, -0.7787],\n",
      "        [-1.3674,  1.4400, -0.3603],\n",
      "        [-1.8710,  0.4578,  1.3015],\n",
      "        [-2.0478,  1.9460,  0.0642],\n",
      "        [-1.8070,  1.8811, -0.1702],\n",
      "        [-0.7849,  0.5451, -0.0476],\n",
      "        [-2.0877,  2.0487,  0.1280],\n",
      "        [ 0.5784,  0.1368, -0.6619],\n",
      "        [-2.0919,  1.8102,  0.1177],\n",
      "        [-1.8314,  1.7714, -0.1927],\n",
      "        [ 0.5368,  0.0398, -1.0978],\n",
      "        [-1.4090,  1.8171, -0.0725]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.1033,  2.1409,  0.0359],\n",
      "        [-0.7506,  0.9531, -0.4982],\n",
      "        [-1.9322,  1.8228, -0.0079],\n",
      "        [-2.3090,  0.7984,  1.4036],\n",
      "        [ 0.6599, -0.1417, -0.7787],\n",
      "        [-1.3674,  1.4400, -0.3603],\n",
      "        [-1.8710,  0.4578,  1.3015],\n",
      "        [-2.0478,  1.9460,  0.0642],\n",
      "        [-1.8070,  1.8811, -0.1702],\n",
      "        [-0.7849,  0.5451, -0.0476],\n",
      "        [-2.0877,  2.0487,  0.1280],\n",
      "        [ 0.5784,  0.1368, -0.6619],\n",
      "        [-2.0919,  1.8102,  0.1177],\n",
      "        [-1.8314,  1.7714, -0.1927],\n",
      "        [ 0.5368,  0.0398, -1.0978],\n",
      "        [-1.4090,  1.8171, -0.0725]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6939,  0.1158,  1.1838],\n",
      "        [-1.8216,  1.9027, -0.2193],\n",
      "        [-1.6249, -0.0549,  1.2068],\n",
      "        [-1.9235,  1.9204, -0.0116],\n",
      "        [-2.0690,  1.5191,  0.1612],\n",
      "        [-2.1277,  1.8087,  0.3343],\n",
      "        [-1.8385,  0.5172,  0.7381],\n",
      "        [-2.0105,  0.1977,  1.2735],\n",
      "        [ 0.5281, -0.0678, -0.9905],\n",
      "        [-1.6922,  1.8607, -0.3567],\n",
      "        [-1.5217, -0.1141,  1.3411],\n",
      "        [-2.0466,  1.9453,  0.0757],\n",
      "        [-1.8716,  1.8692,  0.0061],\n",
      "        [ 0.2473,  0.3033, -0.8771],\n",
      "        [-1.6401,  1.7091, -0.1087],\n",
      "        [ 0.5816,  0.0304, -0.7649]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6939,  0.1158,  1.1838],\n",
      "        [-1.8216,  1.9027, -0.2193],\n",
      "        [-1.6249, -0.0549,  1.2068],\n",
      "        [-1.9235,  1.9204, -0.0116],\n",
      "        [-2.0690,  1.5191,  0.1612],\n",
      "        [-2.1277,  1.8087,  0.3343],\n",
      "        [-1.8385,  0.5172,  0.7381],\n",
      "        [-2.0105,  0.1977,  1.2735],\n",
      "        [ 0.5281, -0.0678, -0.9905],\n",
      "        [-1.6922,  1.8607, -0.3567],\n",
      "        [-1.5217, -0.1141,  1.3411],\n",
      "        [-2.0466,  1.9453,  0.0757],\n",
      "        [-1.8716,  1.8692,  0.0061],\n",
      "        [ 0.2473,  0.3033, -0.8771],\n",
      "        [-1.6401,  1.7091, -0.1087],\n",
      "        [ 0.5816,  0.0304, -0.7649]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1409,  1.5472,  0.2009],\n",
      "        [ 0.2975,  0.0987, -0.7971],\n",
      "        [-2.0046,  0.4248,  1.2094],\n",
      "        [-1.1714,  1.3737, -0.4926],\n",
      "        [-1.4673,  1.7673, -0.2091],\n",
      "        [-1.8740,  1.8335, -0.0509],\n",
      "        [-2.0571,  1.9667,  0.1943],\n",
      "        [-1.9716,  0.4308,  1.2065],\n",
      "        [-1.7679,  1.6528, -0.0704],\n",
      "        [-0.6361,  1.0113, -0.5591],\n",
      "        [ 0.5161, -0.0299, -1.0043],\n",
      "        [-1.6463,  0.6808,  0.7744],\n",
      "        [-1.9951,  1.6743,  0.0552],\n",
      "        [ 0.6161, -0.1273, -0.8353],\n",
      "        [-1.8555,  1.8967, -0.2088],\n",
      "        [-1.8254,  1.9096, -0.0500]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.1409,  1.5472,  0.2009],\n",
      "        [ 0.2975,  0.0987, -0.7971],\n",
      "        [-2.0046,  0.4248,  1.2094],\n",
      "        [-1.1714,  1.3737, -0.4926],\n",
      "        [-1.4673,  1.7673, -0.2091],\n",
      "        [-1.8740,  1.8335, -0.0509],\n",
      "        [-2.0571,  1.9667,  0.1943],\n",
      "        [-1.9716,  0.4308,  1.2065],\n",
      "        [-1.7679,  1.6528, -0.0704],\n",
      "        [-0.6361,  1.0113, -0.5591],\n",
      "        [ 0.5161, -0.0299, -1.0043],\n",
      "        [-1.6463,  0.6808,  0.7744],\n",
      "        [-1.9951,  1.6743,  0.0552],\n",
      "        [ 0.6161, -0.1273, -0.8353],\n",
      "        [-1.8555,  1.8967, -0.2088],\n",
      "        [-1.8254,  1.9096, -0.0500]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9986,  1.9892, -0.0401],\n",
      "        [-2.0546,  1.8604,  0.0294],\n",
      "        [-2.1170,  1.9269, -0.1032],\n",
      "        [-0.0488,  0.5116, -0.8600],\n",
      "        [-1.8008,  0.6259,  0.9415],\n",
      "        [-1.7673,  1.8669, -0.2276],\n",
      "        [-1.8233,  2.0263,  0.1019],\n",
      "        [-2.0224,  2.0370,  0.0346],\n",
      "        [-2.1376,  2.1673, -0.2032],\n",
      "        [ 0.3915, -0.0174, -0.7377],\n",
      "        [-1.9740,  2.1278, -0.0608],\n",
      "        [-1.8764,  1.6321, -0.1261],\n",
      "        [-1.5108,  1.2970,  0.0290],\n",
      "        [-2.0603,  2.0318,  0.0441],\n",
      "        [-1.8769,  1.8121, -0.0669],\n",
      "        [-2.0328,  0.5732,  1.1487]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9986,  1.9892, -0.0401],\n",
      "        [-2.0546,  1.8604,  0.0294],\n",
      "        [-2.1170,  1.9269, -0.1032],\n",
      "        [-0.0488,  0.5116, -0.8600],\n",
      "        [-1.8008,  0.6259,  0.9415],\n",
      "        [-1.7673,  1.8669, -0.2276],\n",
      "        [-1.8233,  2.0263,  0.1019],\n",
      "        [-2.0224,  2.0370,  0.0346],\n",
      "        [-2.1376,  2.1673, -0.2032],\n",
      "        [ 0.3915, -0.0174, -0.7377],\n",
      "        [-1.9740,  2.1278, -0.0608],\n",
      "        [-1.8764,  1.6321, -0.1261],\n",
      "        [-1.5108,  1.2970,  0.0290],\n",
      "        [-2.0603,  2.0318,  0.0441],\n",
      "        [-1.8769,  1.8121, -0.0669],\n",
      "        [-2.0328,  0.5732,  1.1487]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2429,  1.9614,  0.1404],\n",
      "        [-1.7766,  1.7295,  0.0293],\n",
      "        [-2.2854,  1.5669,  0.4702],\n",
      "        [-1.5702, -0.1204,  1.3506],\n",
      "        [-2.2436,  1.5027,  0.4552],\n",
      "        [-1.9607,  1.7375,  0.1340],\n",
      "        [-2.2638,  1.5732,  0.2601],\n",
      "        [-2.0281,  0.2873,  1.3472],\n",
      "        [-2.1977,  0.8094,  1.2240],\n",
      "        [-2.3911,  1.1915,  0.7232],\n",
      "        [-2.0322,  1.7049,  0.0798],\n",
      "        [ 0.3782,  0.0433, -0.7843],\n",
      "        [-2.2657,  2.0306, -0.0386],\n",
      "        [-0.1154,  0.0572, -0.3321],\n",
      "        [ 0.2114,  0.0765, -0.8176],\n",
      "        [-2.3311,  1.9211,  0.1678]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.2429,  1.9614,  0.1404],\n",
      "        [-1.7766,  1.7295,  0.0293],\n",
      "        [-2.2854,  1.5669,  0.4702],\n",
      "        [-1.5702, -0.1204,  1.3506],\n",
      "        [-2.2436,  1.5027,  0.4552],\n",
      "        [-1.9607,  1.7375,  0.1340],\n",
      "        [-2.2638,  1.5732,  0.2601],\n",
      "        [-2.0281,  0.2873,  1.3472],\n",
      "        [-2.1977,  0.8094,  1.2240],\n",
      "        [-2.3911,  1.1915,  0.7232],\n",
      "        [-2.0322,  1.7049,  0.0798],\n",
      "        [ 0.3782,  0.0433, -0.7843],\n",
      "        [-2.2657,  2.0306, -0.0386],\n",
      "        [-0.1154,  0.0572, -0.3321],\n",
      "        [ 0.2114,  0.0765, -0.8176],\n",
      "        [-2.3311,  1.9211,  0.1678]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9879,  0.3601,  1.2459],\n",
      "        [-2.0899,  1.5898,  0.2870],\n",
      "        [-1.7409,  0.3856,  1.2300],\n",
      "        [-0.4615,  0.3539, -0.5364],\n",
      "        [-1.0700,  0.5692,  0.3435],\n",
      "        [-1.5005,  0.7350,  0.5259],\n",
      "        [-2.2444,  1.6210,  0.0534],\n",
      "        [-1.6915,  0.5293,  0.9911],\n",
      "        [-2.0955,  1.7662, -0.1679],\n",
      "        [-2.1602,  1.9549,  0.0625],\n",
      "        [-2.3003,  0.6487,  1.3337],\n",
      "        [ 0.3956,  0.0258, -0.6257],\n",
      "        [-2.1501,  1.5451,  0.2912],\n",
      "        [ 0.5523, -0.1414, -0.6962],\n",
      "        [-1.2506,  1.2559, -0.3018],\n",
      "        [ 0.3406,  0.0046, -0.8321]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9879,  0.3601,  1.2459],\n",
      "        [-2.0899,  1.5898,  0.2870],\n",
      "        [-1.7409,  0.3856,  1.2300],\n",
      "        [-0.4615,  0.3539, -0.5364],\n",
      "        [-1.0700,  0.5692,  0.3435],\n",
      "        [-1.5005,  0.7350,  0.5259],\n",
      "        [-2.2444,  1.6210,  0.0534],\n",
      "        [-1.6915,  0.5293,  0.9911],\n",
      "        [-2.0955,  1.7662, -0.1679],\n",
      "        [-2.1602,  1.9549,  0.0625],\n",
      "        [-2.3003,  0.6487,  1.3337],\n",
      "        [ 0.3956,  0.0258, -0.6257],\n",
      "        [-2.1501,  1.5451,  0.2912],\n",
      "        [ 0.5523, -0.1414, -0.6962],\n",
      "        [-1.2506,  1.2559, -0.3018],\n",
      "        [ 0.3406,  0.0046, -0.8321]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9524,  0.4004,  1.1391],\n",
      "        [-2.1815,  0.8654,  1.1246],\n",
      "        [-2.0985,  1.8226,  0.3026],\n",
      "        [-1.9281,  1.5126, -0.1114],\n",
      "        [-1.9253,  1.4716,  0.0805],\n",
      "        [-2.3453,  1.8988,  0.0808],\n",
      "        [ 0.4987, -0.0051, -0.6302],\n",
      "        [-2.2792,  1.5851,  0.1037],\n",
      "        [-1.8387,  1.9276, -0.2637],\n",
      "        [-2.1941,  1.7888,  0.0851],\n",
      "        [-2.1824,  1.9362,  0.1904],\n",
      "        [-2.1550,  1.8435, -0.0096],\n",
      "        [-1.5949, -0.1857,  1.3051],\n",
      "        [-2.2723,  1.7165,  0.2818],\n",
      "        [-1.7280, -0.0708,  1.3021],\n",
      "        [-2.0832,  1.6110, -0.1172]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9524,  0.4004,  1.1391],\n",
      "        [-2.1815,  0.8654,  1.1246],\n",
      "        [-2.0985,  1.8226,  0.3026],\n",
      "        [-1.9281,  1.5126, -0.1114],\n",
      "        [-1.9253,  1.4716,  0.0805],\n",
      "        [-2.3453,  1.8988,  0.0808],\n",
      "        [ 0.4987, -0.0051, -0.6302],\n",
      "        [-2.2792,  1.5851,  0.1037],\n",
      "        [-1.8387,  1.9276, -0.2637],\n",
      "        [-2.1941,  1.7888,  0.0851],\n",
      "        [-2.1824,  1.9362,  0.1904],\n",
      "        [-2.1550,  1.8435, -0.0096],\n",
      "        [-1.5949, -0.1857,  1.3051],\n",
      "        [-2.2723,  1.7165,  0.2818],\n",
      "        [-1.7280, -0.0708,  1.3021],\n",
      "        [-2.0832,  1.6110, -0.1172]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9827,  1.7538, -0.0169],\n",
      "        [ 0.5003, -0.1890, -0.6232],\n",
      "        [-2.4823,  1.1385,  0.9052],\n",
      "        [-2.2339,  1.9621,  0.0877],\n",
      "        [-1.9878, -0.0385,  1.3451],\n",
      "        [-1.8909,  1.6778,  0.2908],\n",
      "        [-1.7586,  1.4903,  0.1697],\n",
      "        [-2.2393,  1.9862,  0.2403],\n",
      "        [-1.8787,  1.7773,  0.1327],\n",
      "        [-2.1942,  1.8776,  0.1235],\n",
      "        [-1.7314,  1.6989, -0.0405],\n",
      "        [ 0.3638, -0.2842, -0.6592],\n",
      "        [ 0.2932,  0.0637, -0.6743],\n",
      "        [-1.6009,  0.3315,  0.9690],\n",
      "        [-1.5229,  0.1758,  0.9395],\n",
      "        [-0.5025, -0.0148,  0.3643]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9827,  1.7538, -0.0169],\n",
      "        [ 0.5003, -0.1890, -0.6232],\n",
      "        [-2.4823,  1.1385,  0.9052],\n",
      "        [-2.2339,  1.9621,  0.0877],\n",
      "        [-1.9878, -0.0385,  1.3451],\n",
      "        [-1.8909,  1.6778,  0.2908],\n",
      "        [-1.7586,  1.4903,  0.1697],\n",
      "        [-2.2393,  1.9862,  0.2403],\n",
      "        [-1.8787,  1.7773,  0.1327],\n",
      "        [-2.1942,  1.8776,  0.1235],\n",
      "        [-1.7314,  1.6989, -0.0405],\n",
      "        [ 0.3638, -0.2842, -0.6592],\n",
      "        [ 0.2932,  0.0637, -0.6743],\n",
      "        [-1.6009,  0.3315,  0.9690],\n",
      "        [-1.5229,  0.1758,  0.9395],\n",
      "        [-0.5025, -0.0148,  0.3643]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2578,  1.7243,  0.0671],\n",
      "        [-2.1748,  1.2107,  0.5614],\n",
      "        [-2.1959,  1.4926,  0.5417],\n",
      "        [-1.8145,  1.2943,  0.1614],\n",
      "        [-1.9308,  1.8557,  0.0608],\n",
      "        [-1.7417,  0.3074,  1.2116],\n",
      "        [-1.0098,  0.3557,  0.3407],\n",
      "        [-2.2339,  0.3379,  1.4817],\n",
      "        [-2.2410,  1.7564,  0.0820],\n",
      "        [-1.7643,  1.5932, -0.3065],\n",
      "        [-1.8952,  1.4384, -0.0115],\n",
      "        [ 0.3581, -0.1806, -0.8143],\n",
      "        [-2.1424,  1.7808,  0.2295],\n",
      "        [-1.8574,  0.2481,  1.3264],\n",
      "        [-1.9296,  1.9931, -0.0256],\n",
      "        [-1.8751,  0.0097,  1.4562]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.2578,  1.7243,  0.0671],\n",
      "        [-2.1748,  1.2107,  0.5614],\n",
      "        [-2.1959,  1.4926,  0.5417],\n",
      "        [-1.8145,  1.2943,  0.1614],\n",
      "        [-1.9308,  1.8557,  0.0608],\n",
      "        [-1.7417,  0.3074,  1.2116],\n",
      "        [-1.0098,  0.3557,  0.3407],\n",
      "        [-2.2339,  0.3379,  1.4817],\n",
      "        [-2.2410,  1.7564,  0.0820],\n",
      "        [-1.7643,  1.5932, -0.3065],\n",
      "        [-1.8952,  1.4384, -0.0115],\n",
      "        [ 0.3581, -0.1806, -0.8143],\n",
      "        [-2.1424,  1.7808,  0.2295],\n",
      "        [-1.8574,  0.2481,  1.3264],\n",
      "        [-1.9296,  1.9931, -0.0256],\n",
      "        [-1.8751,  0.0097,  1.4562]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 1.8550e-01, -6.6454e-02, -4.0802e-01],\n",
      "        [-2.3452e+00,  1.8774e+00,  2.7355e-01],\n",
      "        [-2.2182e+00,  6.7701e-01,  1.3160e+00],\n",
      "        [-2.0088e+00,  3.4774e-01,  1.2738e+00],\n",
      "        [-2.2997e+00,  1.9197e+00,  4.0437e-01],\n",
      "        [-1.9742e+00,  4.8095e-01,  1.4711e+00],\n",
      "        [-2.2824e+00,  6.9714e-01,  8.8607e-01],\n",
      "        [-1.7714e+00,  1.2956e-03,  1.4237e+00],\n",
      "        [-2.2842e+00,  1.5973e+00,  2.6539e-01],\n",
      "        [ 4.7060e-01, -6.1313e-02, -6.1803e-01],\n",
      "        [-1.8425e+00,  1.7588e+00,  1.7532e-01],\n",
      "        [-1.9967e+00,  1.6791e+00,  8.1486e-02],\n",
      "        [-2.2253e+00,  8.7285e-01,  1.2634e+00],\n",
      "        [-2.3670e+00,  1.1510e+00,  6.0493e-01],\n",
      "        [-2.2300e+00,  1.6938e+00,  2.0844e-01],\n",
      "        [ 2.0146e-01,  1.1447e-01, -7.7836e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 1.8550e-01, -6.6454e-02, -4.0802e-01],\n",
      "        [-2.3452e+00,  1.8774e+00,  2.7355e-01],\n",
      "        [-2.2182e+00,  6.7701e-01,  1.3160e+00],\n",
      "        [-2.0088e+00,  3.4774e-01,  1.2738e+00],\n",
      "        [-2.2997e+00,  1.9197e+00,  4.0437e-01],\n",
      "        [-1.9742e+00,  4.8095e-01,  1.4711e+00],\n",
      "        [-2.2824e+00,  6.9714e-01,  8.8607e-01],\n",
      "        [-1.7714e+00,  1.2956e-03,  1.4237e+00],\n",
      "        [-2.2842e+00,  1.5973e+00,  2.6539e-01],\n",
      "        [ 4.7060e-01, -6.1313e-02, -6.1803e-01],\n",
      "        [-1.8425e+00,  1.7588e+00,  1.7532e-01],\n",
      "        [-1.9967e+00,  1.6791e+00,  8.1486e-02],\n",
      "        [-2.2253e+00,  8.7285e-01,  1.2634e+00],\n",
      "        [-2.3670e+00,  1.1510e+00,  6.0493e-01],\n",
      "        [-2.2300e+00,  1.6938e+00,  2.0844e-01],\n",
      "        [ 2.0146e-01,  1.1447e-01, -7.7836e-01]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1683e+00,  1.7596e-01,  1.3482e+00],\n",
      "        [-3.0844e-01, -7.4550e-03,  3.3931e-02],\n",
      "        [-1.9840e+00,  8.0633e-01,  8.8481e-01],\n",
      "        [-1.9342e+00,  1.7138e+00,  1.3777e-01],\n",
      "        [-2.2205e+00,  1.5264e+00,  5.9592e-01],\n",
      "        [-1.8981e+00,  1.2304e-02,  1.4844e+00],\n",
      "        [-1.9341e+00,  1.4548e+00,  2.9653e-01],\n",
      "        [-1.9298e+00,  1.2402e-01,  1.1993e+00],\n",
      "        [-1.6865e+00,  1.6469e+00, -6.9512e-02],\n",
      "        [-1.8857e+00,  1.7035e+00, -3.4553e-04],\n",
      "        [-2.2346e+00,  1.9992e+00, -2.9898e-02],\n",
      "        [ 4.4297e-01, -9.5890e-02, -5.5328e-01],\n",
      "        [-2.0639e+00,  4.5922e-01,  1.2944e+00],\n",
      "        [-1.8733e+00,  7.8179e-03,  1.5865e+00],\n",
      "        [-2.1405e+00,  1.1458e+00,  1.0892e+00],\n",
      "        [-1.9925e+00,  8.2877e-01,  8.0980e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.1683e+00,  1.7596e-01,  1.3482e+00],\n",
      "        [-3.0844e-01, -7.4550e-03,  3.3931e-02],\n",
      "        [-1.9840e+00,  8.0633e-01,  8.8481e-01],\n",
      "        [-1.9342e+00,  1.7138e+00,  1.3777e-01],\n",
      "        [-2.2205e+00,  1.5264e+00,  5.9592e-01],\n",
      "        [-1.8981e+00,  1.2304e-02,  1.4844e+00],\n",
      "        [-1.9341e+00,  1.4548e+00,  2.9653e-01],\n",
      "        [-1.9298e+00,  1.2402e-01,  1.1993e+00],\n",
      "        [-1.6865e+00,  1.6469e+00, -6.9512e-02],\n",
      "        [-1.8857e+00,  1.7035e+00, -3.4553e-04],\n",
      "        [-2.2346e+00,  1.9992e+00, -2.9898e-02],\n",
      "        [ 4.4297e-01, -9.5890e-02, -5.5328e-01],\n",
      "        [-2.0639e+00,  4.5922e-01,  1.2944e+00],\n",
      "        [-1.8733e+00,  7.8179e-03,  1.5865e+00],\n",
      "        [-2.1405e+00,  1.1458e+00,  1.0892e+00],\n",
      "        [-1.9925e+00,  8.2877e-01,  8.0980e-01]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.4071, -0.0584,  0.1550],\n",
      "        [-0.3623,  0.7068, -0.8859],\n",
      "        [-2.3095,  0.4446,  1.3430],\n",
      "        [-0.0716,  0.2316, -0.4129],\n",
      "        [-2.2325,  1.7076,  0.3211],\n",
      "        [-2.0347,  1.7504, -0.1966],\n",
      "        [-2.0991,  1.7922,  0.0904],\n",
      "        [-1.8346,  0.3604,  1.2811],\n",
      "        [-1.1536,  1.2716, -0.3680],\n",
      "        [-2.3599,  1.8179,  0.0844],\n",
      "        [-2.0132,  0.3440,  1.3561],\n",
      "        [-1.5066,  1.5607, -0.1114],\n",
      "        [ 0.4046, -0.1341, -0.7614],\n",
      "        [-1.4870,  0.8783,  0.4010],\n",
      "        [-1.7100,  0.0316,  1.3478],\n",
      "        [-1.8823,  1.7258,  0.0600]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-0.4071, -0.0584,  0.1550],\n",
      "        [-0.3623,  0.7068, -0.8859],\n",
      "        [-2.3095,  0.4446,  1.3430],\n",
      "        [-0.0716,  0.2316, -0.4129],\n",
      "        [-2.2325,  1.7076,  0.3211],\n",
      "        [-2.0347,  1.7504, -0.1966],\n",
      "        [-2.0991,  1.7922,  0.0904],\n",
      "        [-1.8346,  0.3604,  1.2811],\n",
      "        [-1.1536,  1.2716, -0.3680],\n",
      "        [-2.3599,  1.8179,  0.0844],\n",
      "        [-2.0132,  0.3440,  1.3561],\n",
      "        [-1.5066,  1.5607, -0.1114],\n",
      "        [ 0.4046, -0.1341, -0.7614],\n",
      "        [-1.4870,  0.8783,  0.4010],\n",
      "        [-1.7100,  0.0316,  1.3478],\n",
      "        [-1.8823,  1.7258,  0.0600]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1940,  0.9678,  0.8905],\n",
      "        [-2.3988,  1.1978,  0.8125],\n",
      "        [-1.5627,  0.1567,  1.0047],\n",
      "        [-1.8386,  1.7623,  0.3003],\n",
      "        [-2.0199,  0.0114,  1.2929],\n",
      "        [ 0.3544, -0.1047, -0.5480],\n",
      "        [-1.9406,  1.8089, -0.0545],\n",
      "        [-1.8423,  0.0801,  1.3246],\n",
      "        [ 0.3617, -0.1898, -0.5609],\n",
      "        [-2.5776,  1.4888,  0.8690],\n",
      "        [-0.9759,  1.2395, -0.4509],\n",
      "        [-1.8985,  0.2619,  1.1281],\n",
      "        [-1.9680,  1.7949,  0.1556],\n",
      "        [-1.9239,  0.2211,  1.3188],\n",
      "        [-1.9134,  0.2684,  1.2422],\n",
      "        [-2.1184,  0.7554,  0.9817]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.1940,  0.9678,  0.8905],\n",
      "        [-2.3988,  1.1978,  0.8125],\n",
      "        [-1.5627,  0.1567,  1.0047],\n",
      "        [-1.8386,  1.7623,  0.3003],\n",
      "        [-2.0199,  0.0114,  1.2929],\n",
      "        [ 0.3544, -0.1047, -0.5480],\n",
      "        [-1.9406,  1.8089, -0.0545],\n",
      "        [-1.8423,  0.0801,  1.3246],\n",
      "        [ 0.3617, -0.1898, -0.5609],\n",
      "        [-2.5776,  1.4888,  0.8690],\n",
      "        [-0.9759,  1.2395, -0.4509],\n",
      "        [-1.8985,  0.2619,  1.1281],\n",
      "        [-1.9680,  1.7949,  0.1556],\n",
      "        [-1.9239,  0.2211,  1.3188],\n",
      "        [-1.9134,  0.2684,  1.2422],\n",
      "        [-2.1184,  0.7554,  0.9817]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.3614,  1.1380,  1.0301],\n",
      "        [ 0.4110, -0.1803, -0.3939],\n",
      "        [-2.2228,  1.5175,  0.5413],\n",
      "        [-1.3929,  1.7136, -0.3633],\n",
      "        [-2.1800,  0.9457,  0.9585],\n",
      "        [-2.0276,  0.5464,  1.1645],\n",
      "        [-2.0455,  1.8832,  0.0643],\n",
      "        [-0.5774,  0.8598, -0.8602],\n",
      "        [-2.1465,  1.9067,  0.0156],\n",
      "        [-2.2301,  1.0629,  1.2173],\n",
      "        [ 0.2639,  0.0082, -0.5808],\n",
      "        [-1.5646,  0.1184,  1.1207],\n",
      "        [-2.0399,  0.5422,  1.3090],\n",
      "        [-1.9191,  1.9304, -0.0533],\n",
      "        [-1.9114,  1.8515, -0.0068],\n",
      "        [-1.7856,  1.5590, -0.0460]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.3614,  1.1380,  1.0301],\n",
      "        [ 0.4110, -0.1803, -0.3939],\n",
      "        [-2.2228,  1.5175,  0.5413],\n",
      "        [-1.3929,  1.7136, -0.3633],\n",
      "        [-2.1800,  0.9457,  0.9585],\n",
      "        [-2.0276,  0.5464,  1.1645],\n",
      "        [-2.0455,  1.8832,  0.0643],\n",
      "        [-0.5774,  0.8598, -0.8602],\n",
      "        [-2.1465,  1.9067,  0.0156],\n",
      "        [-2.2301,  1.0629,  1.2173],\n",
      "        [ 0.2639,  0.0082, -0.5808],\n",
      "        [-1.5646,  0.1184,  1.1207],\n",
      "        [-2.0399,  0.5422,  1.3090],\n",
      "        [-1.9191,  1.9304, -0.0533],\n",
      "        [-1.9114,  1.8515, -0.0068],\n",
      "        [-1.7856,  1.5590, -0.0460]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1384,  1.7499,  0.1229],\n",
      "        [-0.3868,  0.0195,  0.0995],\n",
      "        [-1.5003,  0.0654,  1.2575],\n",
      "        [-2.1200,  1.6607,  0.2727],\n",
      "        [-2.1375,  1.8108,  0.0888],\n",
      "        [-1.2767,  0.3778,  0.8539],\n",
      "        [-1.9883,  1.4429, -0.0473],\n",
      "        [-1.9132,  0.3411,  1.3088],\n",
      "        [ 0.3115,  0.0916, -0.7521],\n",
      "        [ 0.3214,  0.0421, -0.7095],\n",
      "        [-1.7365,  0.1405,  1.3313],\n",
      "        [-1.8219,  2.0185,  0.0314],\n",
      "        [-1.7574,  1.7531, -0.0812],\n",
      "        [-1.8857,  0.4573,  1.1570],\n",
      "        [-2.0843,  1.4320,  0.4892],\n",
      "        [-2.2087,  1.8138, -0.0059]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.1384,  1.7499,  0.1229],\n",
      "        [-0.3868,  0.0195,  0.0995],\n",
      "        [-1.5003,  0.0654,  1.2575],\n",
      "        [-2.1200,  1.6607,  0.2727],\n",
      "        [-2.1375,  1.8108,  0.0888],\n",
      "        [-1.2767,  0.3778,  0.8539],\n",
      "        [-1.9883,  1.4429, -0.0473],\n",
      "        [-1.9132,  0.3411,  1.3088],\n",
      "        [ 0.3115,  0.0916, -0.7521],\n",
      "        [ 0.3214,  0.0421, -0.7095],\n",
      "        [-1.7365,  0.1405,  1.3313],\n",
      "        [-1.8219,  2.0185,  0.0314],\n",
      "        [-1.7574,  1.7531, -0.0812],\n",
      "        [-1.8857,  0.4573,  1.1570],\n",
      "        [-2.0843,  1.4320,  0.4892],\n",
      "        [-2.2087,  1.8138, -0.0059]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0240,  0.5834,  1.1283],\n",
      "        [-1.7183,  0.1488,  1.2269],\n",
      "        [-2.0897,  1.7379,  0.1642],\n",
      "        [-2.2035,  0.7779,  1.0803],\n",
      "        [-2.0807,  1.6935, -0.0776],\n",
      "        [-1.6213,  0.2046,  1.3093],\n",
      "        [ 0.1707,  0.0140, -0.5242],\n",
      "        [-1.8224,  1.4902,  0.2507],\n",
      "        [-1.6947,  1.9286,  0.1757],\n",
      "        [-2.4373,  2.1449, -0.0732],\n",
      "        [-1.9168,  1.6835,  0.1190],\n",
      "        [-0.2636,  0.6146, -0.6983],\n",
      "        [-1.8572,  1.9584,  0.0559],\n",
      "        [-1.8726,  1.9005, -0.0672],\n",
      "        [-2.1811,  0.2137,  1.2652],\n",
      "        [-0.7078,  0.5874, -0.1122]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.0240,  0.5834,  1.1283],\n",
      "        [-1.7183,  0.1488,  1.2269],\n",
      "        [-2.0897,  1.7379,  0.1642],\n",
      "        [-2.2035,  0.7779,  1.0803],\n",
      "        [-2.0807,  1.6935, -0.0776],\n",
      "        [-1.6213,  0.2046,  1.3093],\n",
      "        [ 0.1707,  0.0140, -0.5242],\n",
      "        [-1.8224,  1.4902,  0.2507],\n",
      "        [-1.6947,  1.9286,  0.1757],\n",
      "        [-2.4373,  2.1449, -0.0732],\n",
      "        [-1.9168,  1.6835,  0.1190],\n",
      "        [-0.2636,  0.6146, -0.6983],\n",
      "        [-1.8572,  1.9584,  0.0559],\n",
      "        [-1.8726,  1.9005, -0.0672],\n",
      "        [-2.1811,  0.2137,  1.2652],\n",
      "        [-0.7078,  0.5874, -0.1122]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6439,  0.3138,  1.2551],\n",
      "        [-1.6702,  1.5267, -0.3727],\n",
      "        [-2.0169,  0.7118,  0.8616],\n",
      "        [-1.7934,  1.8505, -0.1025],\n",
      "        [-2.2947,  1.1398,  0.7626],\n",
      "        [-2.2112,  2.1920, -0.1253],\n",
      "        [ 0.2009, -0.0256, -0.5132],\n",
      "        [-2.1766,  1.6477,  0.2479],\n",
      "        [-2.4674,  1.4888,  0.6668],\n",
      "        [-1.9279,  2.0197, -0.1968],\n",
      "        [-2.1702,  2.1130, -0.1999],\n",
      "        [ 0.3988, -0.2165, -0.5653],\n",
      "        [-1.6635,  1.8969, -0.2454],\n",
      "        [-1.7774,  1.6064, -0.2258],\n",
      "        [-2.2335,  1.6717,  0.0502],\n",
      "        [-2.0220,  1.7896, -0.0185]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6439,  0.3138,  1.2551],\n",
      "        [-1.6702,  1.5267, -0.3727],\n",
      "        [-2.0169,  0.7118,  0.8616],\n",
      "        [-1.7934,  1.8505, -0.1025],\n",
      "        [-2.2947,  1.1398,  0.7626],\n",
      "        [-2.2112,  2.1920, -0.1253],\n",
      "        [ 0.2009, -0.0256, -0.5132],\n",
      "        [-2.1766,  1.6477,  0.2479],\n",
      "        [-2.4674,  1.4888,  0.6668],\n",
      "        [-1.9279,  2.0197, -0.1968],\n",
      "        [-2.1702,  2.1130, -0.1999],\n",
      "        [ 0.3988, -0.2165, -0.5653],\n",
      "        [-1.6635,  1.8969, -0.2454],\n",
      "        [-1.7774,  1.6064, -0.2258],\n",
      "        [-2.2335,  1.6717,  0.0502],\n",
      "        [-2.0220,  1.7896, -0.0185]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7549,  0.7328,  0.4039],\n",
      "        [ 0.2895, -0.0801, -0.5515],\n",
      "        [-1.9835,  2.0172, -0.0486],\n",
      "        [-1.7308,  1.7772, -0.2612],\n",
      "        [-1.8490,  1.8546, -0.1503],\n",
      "        [-1.9326,  1.9569, -0.1776],\n",
      "        [-1.5144,  1.6662, -0.4058],\n",
      "        [-1.9684,  1.9657, -0.0482],\n",
      "        [ 0.3548, -0.1471, -0.7216],\n",
      "        [ 0.2574,  0.0077, -0.6658],\n",
      "        [-1.8839,  2.0874, -0.3498],\n",
      "        [-1.8929,  2.1075, -0.1763],\n",
      "        [-2.4657,  1.3390,  0.9454],\n",
      "        [-1.7176,  1.7948, -0.2376],\n",
      "        [-1.8821,  1.6426, -0.0597],\n",
      "        [-1.8487,  0.5825,  1.1267]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7549,  0.7328,  0.4039],\n",
      "        [ 0.2895, -0.0801, -0.5515],\n",
      "        [-1.9835,  2.0172, -0.0486],\n",
      "        [-1.7308,  1.7772, -0.2612],\n",
      "        [-1.8490,  1.8546, -0.1503],\n",
      "        [-1.9326,  1.9569, -0.1776],\n",
      "        [-1.5144,  1.6662, -0.4058],\n",
      "        [-1.9684,  1.9657, -0.0482],\n",
      "        [ 0.3548, -0.1471, -0.7216],\n",
      "        [ 0.2574,  0.0077, -0.6658],\n",
      "        [-1.8839,  2.0874, -0.3498],\n",
      "        [-1.8929,  2.1075, -0.1763],\n",
      "        [-2.4657,  1.3390,  0.9454],\n",
      "        [-1.7176,  1.7948, -0.2376],\n",
      "        [-1.8821,  1.6426, -0.0597],\n",
      "        [-1.8487,  0.5825,  1.1267]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.2826,  0.1501, -0.8328],\n",
      "        [ 0.2755,  0.0087, -0.6638],\n",
      "        [-2.0299,  1.8631, -0.1432],\n",
      "        [-2.0139,  1.9577, -0.2332],\n",
      "        [-1.9429,  1.8388, -0.1134],\n",
      "        [-2.0182,  1.7790, -0.2344],\n",
      "        [-1.9457,  1.9980, -0.0561],\n",
      "        [-1.8038,  1.7324, -0.3496],\n",
      "        [-1.9849,  1.9060, -0.1028],\n",
      "        [ 0.0825,  0.1639, -0.5873],\n",
      "        [ 0.2449,  0.0213, -0.7051],\n",
      "        [-1.3982,  1.3944, -0.5707],\n",
      "        [-2.3346,  1.3084,  0.7468],\n",
      "        [-1.9931,  1.5528,  0.0134],\n",
      "        [-1.7922,  1.8609, -0.1935],\n",
      "        [-1.8100,  0.5899,  0.8082]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.2826,  0.1501, -0.8328],\n",
      "        [ 0.2755,  0.0087, -0.6638],\n",
      "        [-2.0299,  1.8631, -0.1432],\n",
      "        [-2.0139,  1.9577, -0.2332],\n",
      "        [-1.9429,  1.8388, -0.1134],\n",
      "        [-2.0182,  1.7790, -0.2344],\n",
      "        [-1.9457,  1.9980, -0.0561],\n",
      "        [-1.8038,  1.7324, -0.3496],\n",
      "        [-1.9849,  1.9060, -0.1028],\n",
      "        [ 0.0825,  0.1639, -0.5873],\n",
      "        [ 0.2449,  0.0213, -0.7051],\n",
      "        [-1.3982,  1.3944, -0.5707],\n",
      "        [-2.3346,  1.3084,  0.7468],\n",
      "        [-1.9931,  1.5528,  0.0134],\n",
      "        [-1.7922,  1.8609, -0.1935],\n",
      "        [-1.8100,  0.5899,  0.8082]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7501,  0.6862,  0.7280],\n",
      "        [-1.9211,  1.9553, -0.2012],\n",
      "        [-2.0001,  1.9428, -0.2515],\n",
      "        [-1.8213,  1.9829, -0.2607],\n",
      "        [-2.2371,  1.4698,  0.4496],\n",
      "        [-1.6691,  0.5143,  0.9057],\n",
      "        [-2.3334,  1.1120,  0.8973],\n",
      "        [-1.5597,  0.5505,  0.7185],\n",
      "        [-1.9727,  1.6849,  0.2625],\n",
      "        [-2.3728,  0.9357,  0.9793],\n",
      "        [-2.1159,  0.4489,  1.1196],\n",
      "        [-1.7320,  0.4637,  1.1406],\n",
      "        [-2.0510,  1.9693, -0.2150],\n",
      "        [-2.4250,  0.8491,  1.0057],\n",
      "        [-2.0708,  1.8928, -0.2013],\n",
      "        [-1.8983,  1.9538, -0.1508]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7501,  0.6862,  0.7280],\n",
      "        [-1.9211,  1.9553, -0.2012],\n",
      "        [-2.0001,  1.9428, -0.2515],\n",
      "        [-1.8213,  1.9829, -0.2607],\n",
      "        [-2.2371,  1.4698,  0.4496],\n",
      "        [-1.6691,  0.5143,  0.9057],\n",
      "        [-2.3334,  1.1120,  0.8973],\n",
      "        [-1.5597,  0.5505,  0.7185],\n",
      "        [-1.9727,  1.6849,  0.2625],\n",
      "        [-2.3728,  0.9357,  0.9793],\n",
      "        [-2.1159,  0.4489,  1.1196],\n",
      "        [-1.7320,  0.4637,  1.1406],\n",
      "        [-2.0510,  1.9693, -0.2150],\n",
      "        [-2.4250,  0.8491,  1.0057],\n",
      "        [-2.0708,  1.8928, -0.2013],\n",
      "        [-1.8983,  1.9538, -0.1508]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3327, -0.2144, -0.4604],\n",
      "        [-1.6136,  0.5918,  0.7576],\n",
      "        [-1.8637,  1.9608, -0.2252],\n",
      "        [-2.0785,  1.1700,  0.7060],\n",
      "        [ 0.4138, -0.1601, -0.7234],\n",
      "        [-2.0009,  0.6500,  1.0588],\n",
      "        [-2.1772,  1.2035,  0.8171],\n",
      "        [-1.9312,  2.0248, -0.1438],\n",
      "        [-2.1799,  1.0886,  1.0407],\n",
      "        [ 0.3216, -0.0735, -0.6430],\n",
      "        [-1.7455,  1.8386, -0.4077],\n",
      "        [-1.9492,  1.9423,  0.0341],\n",
      "        [-1.9112,  0.5874,  1.1702],\n",
      "        [-1.9190,  2.0275,  0.0036],\n",
      "        [-1.9467,  2.0114, -0.1583],\n",
      "        [-1.9342,  1.9379, -0.2027]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.3327, -0.2144, -0.4604],\n",
      "        [-1.6136,  0.5918,  0.7576],\n",
      "        [-1.8637,  1.9608, -0.2252],\n",
      "        [-2.0785,  1.1700,  0.7060],\n",
      "        [ 0.4138, -0.1601, -0.7234],\n",
      "        [-2.0009,  0.6500,  1.0588],\n",
      "        [-2.1772,  1.2035,  0.8171],\n",
      "        [-1.9312,  2.0248, -0.1438],\n",
      "        [-2.1799,  1.0886,  1.0407],\n",
      "        [ 0.3216, -0.0735, -0.6430],\n",
      "        [-1.7455,  1.8386, -0.4077],\n",
      "        [-1.9492,  1.9423,  0.0341],\n",
      "        [-1.9112,  0.5874,  1.1702],\n",
      "        [-1.9190,  2.0275,  0.0036],\n",
      "        [-1.9467,  2.0114, -0.1583],\n",
      "        [-1.9342,  1.9379, -0.2027]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3383, -0.1208, -0.5647],\n",
      "        [-1.9975,  0.5015,  1.2948],\n",
      "        [-1.9234,  1.9467, -0.0901],\n",
      "        [-1.5901,  1.7964, -0.7084],\n",
      "        [ 0.1963,  0.0539, -0.6886],\n",
      "        [ 0.3228,  0.0457, -0.7744],\n",
      "        [-2.0107,  0.7829,  1.1400],\n",
      "        [-2.2657,  0.8365,  0.8401],\n",
      "        [ 0.2290, -0.0478, -0.2443],\n",
      "        [-1.9262,  2.0177, -0.1345],\n",
      "        [-1.8076,  1.8180, -0.2609],\n",
      "        [-1.7220,  1.5027, -0.1744],\n",
      "        [-1.9109,  0.7208,  0.8693],\n",
      "        [-2.1894,  1.7405,  0.2135],\n",
      "        [-1.9404,  0.3486,  1.2165],\n",
      "        [ 0.3332, -0.0453, -0.6760]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.3383, -0.1208, -0.5647],\n",
      "        [-1.9975,  0.5015,  1.2948],\n",
      "        [-1.9234,  1.9467, -0.0901],\n",
      "        [-1.5901,  1.7964, -0.7084],\n",
      "        [ 0.1963,  0.0539, -0.6886],\n",
      "        [ 0.3228,  0.0457, -0.7744],\n",
      "        [-2.0107,  0.7829,  1.1400],\n",
      "        [-2.2657,  0.8365,  0.8401],\n",
      "        [ 0.2290, -0.0478, -0.2443],\n",
      "        [-1.9262,  2.0177, -0.1345],\n",
      "        [-1.8076,  1.8180, -0.2609],\n",
      "        [-1.7220,  1.5027, -0.1744],\n",
      "        [-1.9109,  0.7208,  0.8693],\n",
      "        [-2.1894,  1.7405,  0.2135],\n",
      "        [-1.9404,  0.3486,  1.2165],\n",
      "        [ 0.3332, -0.0453, -0.6760]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8422,  1.9656, -0.2923],\n",
      "        [-1.6314,  1.5139, -0.1757],\n",
      "        [-1.6300,  1.6077, -0.2910],\n",
      "        [ 0.3505, -0.1036, -0.5700],\n",
      "        [-1.9183,  2.0015, -0.4421],\n",
      "        [-1.8843,  2.0582, -0.4484],\n",
      "        [-1.8423,  1.5766, -0.0801],\n",
      "        [-1.9324,  1.8974, -0.1955],\n",
      "        [-1.7327,  1.7411, -0.1117],\n",
      "        [ 0.5660, -0.1318, -0.6085],\n",
      "        [-2.2457,  0.9831,  0.9038],\n",
      "        [-1.6041,  1.2048,  0.0526],\n",
      "        [-0.7426,  1.1820, -0.8448],\n",
      "        [-1.6953,  2.1308, -0.3348],\n",
      "        [-1.8428,  1.7744,  0.0801],\n",
      "        [-1.5882,  1.3855, -0.3809]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8422,  1.9656, -0.2923],\n",
      "        [-1.6314,  1.5139, -0.1757],\n",
      "        [-1.6300,  1.6077, -0.2910],\n",
      "        [ 0.3505, -0.1036, -0.5700],\n",
      "        [-1.9183,  2.0015, -0.4421],\n",
      "        [-1.8843,  2.0582, -0.4484],\n",
      "        [-1.8423,  1.5766, -0.0801],\n",
      "        [-1.9324,  1.8974, -0.1955],\n",
      "        [-1.7327,  1.7411, -0.1117],\n",
      "        [ 0.5660, -0.1318, -0.6085],\n",
      "        [-2.2457,  0.9831,  0.9038],\n",
      "        [-1.6041,  1.2048,  0.0526],\n",
      "        [-0.7426,  1.1820, -0.8448],\n",
      "        [-1.6953,  2.1308, -0.3348],\n",
      "        [-1.8428,  1.7744,  0.0801],\n",
      "        [-1.5882,  1.3855, -0.3809]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.6046, -0.2681, -0.4939],\n",
      "        [-1.9589,  2.0794, -0.1831],\n",
      "        [ 0.3738, -0.2106, -0.5040],\n",
      "        [-2.0299,  1.8561,  0.1633],\n",
      "        [-1.6060,  1.6782, -0.2209],\n",
      "        [-1.6331,  1.8780, -0.3861],\n",
      "        [-1.7302,  1.7020, -0.1430],\n",
      "        [-1.6720,  1.8437, -0.0957],\n",
      "        [-1.4949,  1.5722, -0.6568],\n",
      "        [-1.6800,  1.7706, -0.0705],\n",
      "        [-1.6151,  1.6932, -0.2948],\n",
      "        [ 0.1358, -0.0175, -0.1826],\n",
      "        [-2.0306,  0.7060,  1.1578],\n",
      "        [-2.0749,  1.2374,  0.7686],\n",
      "        [-1.8604,  2.1233, -0.2668],\n",
      "        [-1.9662,  2.0022, -0.0500]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.6046, -0.2681, -0.4939],\n",
      "        [-1.9589,  2.0794, -0.1831],\n",
      "        [ 0.3738, -0.2106, -0.5040],\n",
      "        [-2.0299,  1.8561,  0.1633],\n",
      "        [-1.6060,  1.6782, -0.2209],\n",
      "        [-1.6331,  1.8780, -0.3861],\n",
      "        [-1.7302,  1.7020, -0.1430],\n",
      "        [-1.6720,  1.8437, -0.0957],\n",
      "        [-1.4949,  1.5722, -0.6568],\n",
      "        [-1.6800,  1.7706, -0.0705],\n",
      "        [-1.6151,  1.6932, -0.2948],\n",
      "        [ 0.1358, -0.0175, -0.1826],\n",
      "        [-2.0306,  0.7060,  1.1578],\n",
      "        [-2.0749,  1.2374,  0.7686],\n",
      "        [-1.8604,  2.1233, -0.2668],\n",
      "        [-1.9662,  2.0022, -0.0500]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0053,  1.9630, -0.2635],\n",
      "        [-1.7212,  1.7683, -0.1600],\n",
      "        [-1.5804,  1.6754, -0.1747],\n",
      "        [-1.8246,  2.0506, -0.2326],\n",
      "        [ 0.5549, -0.3442, -0.5728],\n",
      "        [-1.6222,  1.9061, -0.2284],\n",
      "        [-2.0059,  1.3456,  0.3953],\n",
      "        [-1.7116,  1.9486, -0.2836],\n",
      "        [ 0.5424, -0.2562, -0.7357],\n",
      "        [-2.1031,  0.9706,  0.7918],\n",
      "        [-1.5315,  1.7214, -0.3573],\n",
      "        [-1.9696,  0.7237,  0.9097],\n",
      "        [-1.6891,  1.8513, -0.1964],\n",
      "        [-2.0974,  0.6349,  1.0521],\n",
      "        [-1.7463,  1.8837, -0.1926],\n",
      "        [-1.9457,  1.0880,  0.7165]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.0053,  1.9630, -0.2635],\n",
      "        [-1.7212,  1.7683, -0.1600],\n",
      "        [-1.5804,  1.6754, -0.1747],\n",
      "        [-1.8246,  2.0506, -0.2326],\n",
      "        [ 0.5549, -0.3442, -0.5728],\n",
      "        [-1.6222,  1.9061, -0.2284],\n",
      "        [-2.0059,  1.3456,  0.3953],\n",
      "        [-1.7116,  1.9486, -0.2836],\n",
      "        [ 0.5424, -0.2562, -0.7357],\n",
      "        [-2.1031,  0.9706,  0.7918],\n",
      "        [-1.5315,  1.7214, -0.3573],\n",
      "        [-1.9696,  0.7237,  0.9097],\n",
      "        [-1.6891,  1.8513, -0.1964],\n",
      "        [-2.0974,  0.6349,  1.0521],\n",
      "        [-1.7463,  1.8837, -0.1926],\n",
      "        [-1.9457,  1.0880,  0.7165]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5921,  1.7952, -0.5719],\n",
      "        [ 0.6835, -0.2639, -0.6374],\n",
      "        [-2.0107,  1.6313, -0.2454],\n",
      "        [-2.1491,  1.2990,  0.8515],\n",
      "        [-1.9252,  1.8151, -0.0739],\n",
      "        [-1.5096,  1.9336, -0.3520],\n",
      "        [-1.9984,  1.3529,  0.1765],\n",
      "        [-1.9370,  1.8767, -0.1601],\n",
      "        [-1.6521,  1.7733, -0.3570],\n",
      "        [ 0.4416, -0.1979, -0.7911],\n",
      "        [-2.0955,  0.6307,  1.1763],\n",
      "        [-1.8926,  0.3659,  1.2650],\n",
      "        [-1.8250,  0.6338,  1.0186],\n",
      "        [-1.8260,  0.4561,  1.1119],\n",
      "        [-1.8770,  0.3462,  1.2695],\n",
      "        [-1.8650,  0.3518,  1.2318]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5921,  1.7952, -0.5719],\n",
      "        [ 0.6835, -0.2639, -0.6374],\n",
      "        [-2.0107,  1.6313, -0.2454],\n",
      "        [-2.1491,  1.2990,  0.8515],\n",
      "        [-1.9252,  1.8151, -0.0739],\n",
      "        [-1.5096,  1.9336, -0.3520],\n",
      "        [-1.9984,  1.3529,  0.1765],\n",
      "        [-1.9370,  1.8767, -0.1601],\n",
      "        [-1.6521,  1.7733, -0.3570],\n",
      "        [ 0.4416, -0.1979, -0.7911],\n",
      "        [-2.0955,  0.6307,  1.1763],\n",
      "        [-1.8926,  0.3659,  1.2650],\n",
      "        [-1.8250,  0.6338,  1.0186],\n",
      "        [-1.8260,  0.4561,  1.1119],\n",
      "        [-1.8770,  0.3462,  1.2695],\n",
      "        [-1.8650,  0.3518,  1.2318]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.6283, -0.1826, -0.7049],\n",
      "        [-1.7748,  1.6839, -0.2307],\n",
      "        [-1.9996,  1.7513, -0.1953],\n",
      "        [-1.5842,  0.1383,  1.1937],\n",
      "        [-0.8807,  1.2449, -0.5957],\n",
      "        [-1.5774,  1.8059, -0.1855],\n",
      "        [ 0.3287, -0.2067, -0.4829],\n",
      "        [-1.5462,  1.9049, -0.3444],\n",
      "        [-2.0603,  0.5104,  1.2070],\n",
      "        [-1.0619,  1.1828, -0.1818],\n",
      "        [-1.4085,  1.6259, -0.3607],\n",
      "        [-1.6584,  1.8479, -0.2547],\n",
      "        [-2.1705,  0.6494,  1.1099],\n",
      "        [-1.8988,  0.6122,  0.9639],\n",
      "        [-2.0991,  1.4746,  0.3426],\n",
      "        [-2.1831,  0.4791,  1.2352]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.6283, -0.1826, -0.7049],\n",
      "        [-1.7748,  1.6839, -0.2307],\n",
      "        [-1.9996,  1.7513, -0.1953],\n",
      "        [-1.5842,  0.1383,  1.1937],\n",
      "        [-0.8807,  1.2449, -0.5957],\n",
      "        [-1.5774,  1.8059, -0.1855],\n",
      "        [ 0.3287, -0.2067, -0.4829],\n",
      "        [-1.5462,  1.9049, -0.3444],\n",
      "        [-2.0603,  0.5104,  1.2070],\n",
      "        [-1.0619,  1.1828, -0.1818],\n",
      "        [-1.4085,  1.6259, -0.3607],\n",
      "        [-1.6584,  1.8479, -0.2547],\n",
      "        [-2.1705,  0.6494,  1.1099],\n",
      "        [-1.8988,  0.6122,  0.9639],\n",
      "        [-2.0991,  1.4746,  0.3426],\n",
      "        [-2.1831,  0.4791,  1.2352]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3901,  1.4092, -0.0511],\n",
      "        [-1.4465,  1.6953, -0.3598],\n",
      "        [-1.8695,  1.7841, -0.0262],\n",
      "        [-1.2305,  1.6056, -0.4609],\n",
      "        [-1.6284,  1.7681, -0.3665],\n",
      "        [-1.5633,  1.8026, -0.3127],\n",
      "        [-1.9050,  0.3854,  1.2984],\n",
      "        [-1.5886,  0.3281,  1.0247],\n",
      "        [ 0.5947, -0.2671, -0.5796],\n",
      "        [-1.5602,  1.5600, -0.1697],\n",
      "        [-1.8264,  1.4786,  0.3882],\n",
      "        [-1.5068,  1.7747, -0.3650],\n",
      "        [ 0.6347, -0.1367, -0.8848],\n",
      "        [-1.5514,  1.9702, -0.4218],\n",
      "        [-1.5795,  1.6672, -0.1137],\n",
      "        [-1.3950,  1.5794, -0.2023]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3901,  1.4092, -0.0511],\n",
      "        [-1.4465,  1.6953, -0.3598],\n",
      "        [-1.8695,  1.7841, -0.0262],\n",
      "        [-1.2305,  1.6056, -0.4609],\n",
      "        [-1.6284,  1.7681, -0.3665],\n",
      "        [-1.5633,  1.8026, -0.3127],\n",
      "        [-1.9050,  0.3854,  1.2984],\n",
      "        [-1.5886,  0.3281,  1.0247],\n",
      "        [ 0.5947, -0.2671, -0.5796],\n",
      "        [-1.5602,  1.5600, -0.1697],\n",
      "        [-1.8264,  1.4786,  0.3882],\n",
      "        [-1.5068,  1.7747, -0.3650],\n",
      "        [ 0.6347, -0.1367, -0.8848],\n",
      "        [-1.5514,  1.9702, -0.4218],\n",
      "        [-1.5795,  1.6672, -0.1137],\n",
      "        [-1.3950,  1.5794, -0.2023]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8408,  1.8151, -0.0258],\n",
      "        [-1.6678,  1.7961, -0.1367],\n",
      "        [-1.2831,  1.5526, -0.3167],\n",
      "        [-1.1016,  1.3384, -0.5793],\n",
      "        [ 0.4350, -0.0432, -0.7986],\n",
      "        [-1.7095,  1.5932,  0.1046],\n",
      "        [-1.4976,  1.5779, -0.4566],\n",
      "        [ 0.5996, -0.3481, -0.7182],\n",
      "        [-1.5852,  1.3729, -0.3650],\n",
      "        [-1.5143,  1.7373, -0.2262],\n",
      "        [-1.5872,  1.8143, -0.3000],\n",
      "        [-2.0723,  0.4465,  1.2569],\n",
      "        [-1.3636,  1.5796, -0.0614],\n",
      "        [-1.5025,  1.9414, -0.3255],\n",
      "        [-2.0911,  0.8937,  0.8682],\n",
      "        [-1.9078,  1.0182,  0.6844]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8408,  1.8151, -0.0258],\n",
      "        [-1.6678,  1.7961, -0.1367],\n",
      "        [-1.2831,  1.5526, -0.3167],\n",
      "        [-1.1016,  1.3384, -0.5793],\n",
      "        [ 0.4350, -0.0432, -0.7986],\n",
      "        [-1.7095,  1.5932,  0.1046],\n",
      "        [-1.4976,  1.5779, -0.4566],\n",
      "        [ 0.5996, -0.3481, -0.7182],\n",
      "        [-1.5852,  1.3729, -0.3650],\n",
      "        [-1.5143,  1.7373, -0.2262],\n",
      "        [-1.5872,  1.8143, -0.3000],\n",
      "        [-2.0723,  0.4465,  1.2569],\n",
      "        [-1.3636,  1.5796, -0.0614],\n",
      "        [-1.5025,  1.9414, -0.3255],\n",
      "        [-2.0911,  0.8937,  0.8682],\n",
      "        [-1.9078,  1.0182,  0.6844]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4944,  1.6047, -0.2635],\n",
      "        [-0.1791,  0.0941, -0.3416],\n",
      "        [-1.7691,  1.8495,  0.0372],\n",
      "        [-1.8817,  0.4052,  1.2445],\n",
      "        [-1.7408,  0.2653,  1.2230],\n",
      "        [-1.5548,  1.7629, -0.2701],\n",
      "        [-1.8317,  1.2728,  0.6713],\n",
      "        [ 0.1102, -0.3506, -0.2833],\n",
      "        [-1.7046,  1.9484, -0.2571],\n",
      "        [ 0.5964, -0.2380, -0.8013],\n",
      "        [-1.1743,  0.4940,  0.3489],\n",
      "        [-1.3196,  1.6114, -0.4265],\n",
      "        [-1.8662,  0.1184,  1.1918],\n",
      "        [-1.2087,  1.5047, -0.1798],\n",
      "        [-1.6372,  1.5383,  0.0233],\n",
      "        [-1.2254,  0.4552,  0.5615]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4944,  1.6047, -0.2635],\n",
      "        [-0.1791,  0.0941, -0.3416],\n",
      "        [-1.7691,  1.8495,  0.0372],\n",
      "        [-1.8817,  0.4052,  1.2445],\n",
      "        [-1.7408,  0.2653,  1.2230],\n",
      "        [-1.5548,  1.7629, -0.2701],\n",
      "        [-1.8317,  1.2728,  0.6713],\n",
      "        [ 0.1102, -0.3506, -0.2833],\n",
      "        [-1.7046,  1.9484, -0.2571],\n",
      "        [ 0.5964, -0.2380, -0.8013],\n",
      "        [-1.1743,  0.4940,  0.3489],\n",
      "        [-1.3196,  1.6114, -0.4265],\n",
      "        [-1.8662,  0.1184,  1.1918],\n",
      "        [-1.2087,  1.5047, -0.1798],\n",
      "        [-1.6372,  1.5383,  0.0233],\n",
      "        [-1.2254,  0.4552,  0.5615]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4955,  1.8767, -0.1760],\n",
      "        [-2.0662,  0.7212,  1.0551],\n",
      "        [-1.5056,  1.6040, -0.3254],\n",
      "        [-1.7858,  1.5633, -0.0123],\n",
      "        [ 0.5383, -0.3213, -0.7987],\n",
      "        [ 0.1820,  0.0437, -0.4260],\n",
      "        [-2.1241,  0.4418,  1.2268],\n",
      "        [-1.5846,  1.7956, -0.2847],\n",
      "        [-1.9541,  1.7477,  0.1119],\n",
      "        [-1.7652,  1.8529, -0.0703],\n",
      "        [-1.4398,  1.8733, -0.3436],\n",
      "        [-1.7914,  0.5977,  0.9998],\n",
      "        [-1.8585,  1.4072,  0.1210],\n",
      "        [-1.7044,  1.3285,  0.2770],\n",
      "        [-1.6164,  1.6647, -0.1685],\n",
      "        [-1.5548,  1.6137, -0.3061]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4955,  1.8767, -0.1760],\n",
      "        [-2.0662,  0.7212,  1.0551],\n",
      "        [-1.5056,  1.6040, -0.3254],\n",
      "        [-1.7858,  1.5633, -0.0123],\n",
      "        [ 0.5383, -0.3213, -0.7987],\n",
      "        [ 0.1820,  0.0437, -0.4260],\n",
      "        [-2.1241,  0.4418,  1.2268],\n",
      "        [-1.5846,  1.7956, -0.2847],\n",
      "        [-1.9541,  1.7477,  0.1119],\n",
      "        [-1.7652,  1.8529, -0.0703],\n",
      "        [-1.4398,  1.8733, -0.3436],\n",
      "        [-1.7914,  0.5977,  0.9998],\n",
      "        [-1.8585,  1.4072,  0.1210],\n",
      "        [-1.7044,  1.3285,  0.2770],\n",
      "        [-1.6164,  1.6647, -0.1685],\n",
      "        [-1.5548,  1.6137, -0.3061]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.6249, -0.0960, -0.9561],\n",
      "        [-1.4178,  1.6193, -0.0991],\n",
      "        [-1.6120,  0.9865,  0.4863],\n",
      "        [-1.6598,  1.7143, -0.3284],\n",
      "        [-1.7139,  0.3122,  1.3102],\n",
      "        [-1.7127,  1.8806, -0.0326],\n",
      "        [-0.6319, -0.0446,  0.4211],\n",
      "        [-1.8377,  1.3366,  0.4354],\n",
      "        [-1.4743,  1.7585, -0.3054],\n",
      "        [-1.5889,  1.7035, -0.2585],\n",
      "        [-1.4983,  1.3768, -0.1482],\n",
      "        [-1.6999,  1.4039,  0.1549],\n",
      "        [-1.6316,  1.7401, -0.1224],\n",
      "        [-1.5243,  1.7167, -0.3365],\n",
      "        [-1.6001,  1.7012, -0.1157],\n",
      "        [-1.5345,  1.4558, -0.0861]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.6249, -0.0960, -0.9561],\n",
      "        [-1.4178,  1.6193, -0.0991],\n",
      "        [-1.6120,  0.9865,  0.4863],\n",
      "        [-1.6598,  1.7143, -0.3284],\n",
      "        [-1.7139,  0.3122,  1.3102],\n",
      "        [-1.7127,  1.8806, -0.0326],\n",
      "        [-0.6319, -0.0446,  0.4211],\n",
      "        [-1.8377,  1.3366,  0.4354],\n",
      "        [-1.4743,  1.7585, -0.3054],\n",
      "        [-1.5889,  1.7035, -0.2585],\n",
      "        [-1.4983,  1.3768, -0.1482],\n",
      "        [-1.6999,  1.4039,  0.1549],\n",
      "        [-1.6316,  1.7401, -0.1224],\n",
      "        [-1.5243,  1.7167, -0.3365],\n",
      "        [-1.6001,  1.7012, -0.1157],\n",
      "        [-1.5345,  1.4558, -0.0861]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6343,  1.7427, -0.1658],\n",
      "        [-1.8266,  0.1946,  1.0970],\n",
      "        [-1.5207,  1.4862, -0.0067],\n",
      "        [ 0.0506,  0.2612, -0.8414],\n",
      "        [ 0.2638,  0.1914, -0.7276],\n",
      "        [-1.4637,  1.5000,  0.0496],\n",
      "        [-1.8880,  1.9234, -0.1622],\n",
      "        [-1.5329,  1.5569, -0.2602],\n",
      "        [-1.5939,  1.4886, -0.2003],\n",
      "        [-1.6847,  0.9071,  0.3746],\n",
      "        [-1.8103,  1.4769,  0.2853],\n",
      "        [-1.8994,  0.5477,  0.8349],\n",
      "        [-1.8936,  0.4547,  1.2716],\n",
      "        [-1.8210,  0.5271,  1.2407],\n",
      "        [-1.4860,  1.2120,  0.1349],\n",
      "        [-2.0524,  1.4360,  0.0783]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6343,  1.7427, -0.1658],\n",
      "        [-1.8266,  0.1946,  1.0970],\n",
      "        [-1.5207,  1.4862, -0.0067],\n",
      "        [ 0.0506,  0.2612, -0.8414],\n",
      "        [ 0.2638,  0.1914, -0.7276],\n",
      "        [-1.4637,  1.5000,  0.0496],\n",
      "        [-1.8880,  1.9234, -0.1622],\n",
      "        [-1.5329,  1.5569, -0.2602],\n",
      "        [-1.5939,  1.4886, -0.2003],\n",
      "        [-1.6847,  0.9071,  0.3746],\n",
      "        [-1.8103,  1.4769,  0.2853],\n",
      "        [-1.8994,  0.5477,  0.8349],\n",
      "        [-1.8936,  0.4547,  1.2716],\n",
      "        [-1.8210,  0.5271,  1.2407],\n",
      "        [-1.4860,  1.2120,  0.1349],\n",
      "        [-2.0524,  1.4360,  0.0783]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5381,  1.1984,  0.1751],\n",
      "        [-1.6014,  0.0479,  1.3752],\n",
      "        [-1.3216,  1.2579,  0.0205],\n",
      "        [-1.9269,  1.3544,  0.0929],\n",
      "        [-1.6707,  0.2839,  1.2107],\n",
      "        [-1.3197,  1.4474, -0.2152],\n",
      "        [-1.6671,  0.3669,  1.0056],\n",
      "        [ 0.2484,  0.0305, -0.7121],\n",
      "        [-1.4277,  1.6603, -0.3740],\n",
      "        [-1.3927,  1.4570, -0.0121],\n",
      "        [ 0.4968, -0.3757, -0.8160],\n",
      "        [-1.8559,  0.3816,  1.1995],\n",
      "        [ 0.4757, -0.1562, -0.9912],\n",
      "        [-1.5832,  0.0856,  1.3049],\n",
      "        [-1.1344,  1.2400, -0.0020],\n",
      "        [-1.5687,  1.5167,  0.0761]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5381,  1.1984,  0.1751],\n",
      "        [-1.6014,  0.0479,  1.3752],\n",
      "        [-1.3216,  1.2579,  0.0205],\n",
      "        [-1.9269,  1.3544,  0.0929],\n",
      "        [-1.6707,  0.2839,  1.2107],\n",
      "        [-1.3197,  1.4474, -0.2152],\n",
      "        [-1.6671,  0.3669,  1.0056],\n",
      "        [ 0.2484,  0.0305, -0.7121],\n",
      "        [-1.4277,  1.6603, -0.3740],\n",
      "        [-1.3927,  1.4570, -0.0121],\n",
      "        [ 0.4968, -0.3757, -0.8160],\n",
      "        [-1.8559,  0.3816,  1.1995],\n",
      "        [ 0.4757, -0.1562, -0.9912],\n",
      "        [-1.5832,  0.0856,  1.3049],\n",
      "        [-1.1344,  1.2400, -0.0020],\n",
      "        [-1.5687,  1.5167,  0.0761]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.8274, -0.2227, -0.9373],\n",
      "        [-1.8724,  1.3342,  0.1965],\n",
      "        [-1.3718,  1.1932, -0.1131],\n",
      "        [-1.3249,  1.1640, -0.0462],\n",
      "        [ 0.2409, -0.1041, -0.5989],\n",
      "        [-1.4274,  1.4218,  0.1351],\n",
      "        [ 0.5334, -0.3986, -0.6808],\n",
      "        [-1.3578,  1.3875, -0.0197],\n",
      "        [ 0.0264,  0.2692, -0.7970],\n",
      "        [-1.8650,  0.3672,  1.1732],\n",
      "        [-1.5088,  1.3052,  0.1008],\n",
      "        [-1.7631,  1.2673,  0.2880],\n",
      "        [-1.3413,  1.5022, -0.1829],\n",
      "        [-1.3787,  1.2702,  0.0825],\n",
      "        [-1.2799,  1.3542, -0.0038],\n",
      "        [ 0.4929,  0.2157, -0.8174]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.8274, -0.2227, -0.9373],\n",
      "        [-1.8724,  1.3342,  0.1965],\n",
      "        [-1.3718,  1.1932, -0.1131],\n",
      "        [-1.3249,  1.1640, -0.0462],\n",
      "        [ 0.2409, -0.1041, -0.5989],\n",
      "        [-1.4274,  1.4218,  0.1351],\n",
      "        [ 0.5334, -0.3986, -0.6808],\n",
      "        [-1.3578,  1.3875, -0.0197],\n",
      "        [ 0.0264,  0.2692, -0.7970],\n",
      "        [-1.8650,  0.3672,  1.1732],\n",
      "        [-1.5088,  1.3052,  0.1008],\n",
      "        [-1.7631,  1.2673,  0.2880],\n",
      "        [-1.3413,  1.5022, -0.1829],\n",
      "        [-1.3787,  1.2702,  0.0825],\n",
      "        [-1.2799,  1.3542, -0.0038],\n",
      "        [ 0.4929,  0.2157, -0.8174]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6754,  0.3446,  1.1233],\n",
      "        [-1.3263,  1.5419, -0.0268],\n",
      "        [-1.7029,  1.7913, -0.1859],\n",
      "        [-1.7108,  0.1192,  1.4258],\n",
      "        [-1.5442,  1.3685,  0.1262],\n",
      "        [-1.0713,  1.3391, -0.1216],\n",
      "        [-1.0985, -0.0144,  0.9212],\n",
      "        [-1.9366,  0.8564,  0.8132],\n",
      "        [-1.8413,  0.4964,  0.9844],\n",
      "        [-1.7162,  0.3388,  0.9613],\n",
      "        [-1.3313,  1.4235, -0.0172],\n",
      "        [-1.5741,  0.6552,  0.8263],\n",
      "        [-1.6451, -0.0928,  1.2361],\n",
      "        [-1.7812,  0.8226,  0.7294],\n",
      "        [-1.4350,  1.4176,  0.0321],\n",
      "        [-0.1105, -0.1614, -0.0429]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6754,  0.3446,  1.1233],\n",
      "        [-1.3263,  1.5419, -0.0268],\n",
      "        [-1.7029,  1.7913, -0.1859],\n",
      "        [-1.7108,  0.1192,  1.4258],\n",
      "        [-1.5442,  1.3685,  0.1262],\n",
      "        [-1.0713,  1.3391, -0.1216],\n",
      "        [-1.0985, -0.0144,  0.9212],\n",
      "        [-1.9366,  0.8564,  0.8132],\n",
      "        [-1.8413,  0.4964,  0.9844],\n",
      "        [-1.7162,  0.3388,  0.9613],\n",
      "        [-1.3313,  1.4235, -0.0172],\n",
      "        [-1.5741,  0.6552,  0.8263],\n",
      "        [-1.6451, -0.0928,  1.2361],\n",
      "        [-1.7812,  0.8226,  0.7294],\n",
      "        [-1.4350,  1.4176,  0.0321],\n",
      "        [-0.1105, -0.1614, -0.0429]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7332,  0.8843,  0.7106],\n",
      "        [-1.4708,  1.0852,  0.3193],\n",
      "        [-1.2075,  1.0982,  0.0969],\n",
      "        [-1.2352,  1.2779,  0.0344],\n",
      "        [-1.4556,  1.2725, -0.0605],\n",
      "        [-1.8672,  1.3499,  0.1319],\n",
      "        [-1.5653,  0.9536,  0.3420],\n",
      "        [-1.2785,  1.4626, -0.2228],\n",
      "        [-1.5167,  1.4099,  0.1879],\n",
      "        [-1.4044,  0.8809,  0.2933],\n",
      "        [ 0.4196, -0.1829, -0.7809],\n",
      "        [ 0.5996, -0.1231, -0.9879],\n",
      "        [-1.3790,  1.2909,  0.0477],\n",
      "        [-1.8351,  0.2391,  1.3917],\n",
      "        [ 0.2470, -0.0403, -0.5752],\n",
      "        [-1.4278,  1.4324, -0.0329]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7332,  0.8843,  0.7106],\n",
      "        [-1.4708,  1.0852,  0.3193],\n",
      "        [-1.2075,  1.0982,  0.0969],\n",
      "        [-1.2352,  1.2779,  0.0344],\n",
      "        [-1.4556,  1.2725, -0.0605],\n",
      "        [-1.8672,  1.3499,  0.1319],\n",
      "        [-1.5653,  0.9536,  0.3420],\n",
      "        [-1.2785,  1.4626, -0.2228],\n",
      "        [-1.5167,  1.4099,  0.1879],\n",
      "        [-1.4044,  0.8809,  0.2933],\n",
      "        [ 0.4196, -0.1829, -0.7809],\n",
      "        [ 0.5996, -0.1231, -0.9879],\n",
      "        [-1.3790,  1.2909,  0.0477],\n",
      "        [-1.8351,  0.2391,  1.3917],\n",
      "        [ 0.2470, -0.0403, -0.5752],\n",
      "        [-1.4278,  1.4324, -0.0329]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2752,  1.0903,  0.0509],\n",
      "        [-1.6599,  1.1704,  0.2927],\n",
      "        [ 0.4657, -0.0506, -0.8211],\n",
      "        [ 0.5251,  0.1161, -1.0495],\n",
      "        [ 0.3828,  0.2213, -0.9904],\n",
      "        [-1.3853,  0.9427,  0.0319],\n",
      "        [-1.6549,  0.2312,  1.2424],\n",
      "        [-1.4994,  1.2256,  0.1363],\n",
      "        [-1.9204,  0.4337,  1.1571],\n",
      "        [-0.4081, -0.0900,  0.2968],\n",
      "        [ 0.5020, -0.1757, -0.9514],\n",
      "        [-1.6905,  0.9876,  0.3250],\n",
      "        [-1.0487,  1.1481, -0.1633],\n",
      "        [-1.0798,  1.0682,  0.0562],\n",
      "        [ 0.1001, -0.0075, -0.3302],\n",
      "        [-2.0270,  0.3219,  1.2850]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.2752,  1.0903,  0.0509],\n",
      "        [-1.6599,  1.1704,  0.2927],\n",
      "        [ 0.4657, -0.0506, -0.8211],\n",
      "        [ 0.5251,  0.1161, -1.0495],\n",
      "        [ 0.3828,  0.2213, -0.9904],\n",
      "        [-1.3853,  0.9427,  0.0319],\n",
      "        [-1.6549,  0.2312,  1.2424],\n",
      "        [-1.4994,  1.2256,  0.1363],\n",
      "        [-1.9204,  0.4337,  1.1571],\n",
      "        [-0.4081, -0.0900,  0.2968],\n",
      "        [ 0.5020, -0.1757, -0.9514],\n",
      "        [-1.6905,  0.9876,  0.3250],\n",
      "        [-1.0487,  1.1481, -0.1633],\n",
      "        [-1.0798,  1.0682,  0.0562],\n",
      "        [ 0.1001, -0.0075, -0.3302],\n",
      "        [-2.0270,  0.3219,  1.2850]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7267,  0.3379,  1.2051],\n",
      "        [-1.8049,  0.0194,  1.3827],\n",
      "        [ 0.2640, -0.0697, -0.5832],\n",
      "        [-1.3035,  1.5315, -0.1654],\n",
      "        [-1.6362,  1.2840, -0.0619],\n",
      "        [-1.7185,  0.2944,  1.4264],\n",
      "        [ 0.6259, -0.1948, -1.0903],\n",
      "        [-1.5189,  1.2686,  0.3431],\n",
      "        [-1.7054,  0.7130,  0.6288],\n",
      "        [-1.5938,  1.1734,  0.3499],\n",
      "        [ 0.3000, -0.1148, -0.7639],\n",
      "        [-1.5278,  0.3174,  0.9431],\n",
      "        [-1.8525,  0.3928,  1.1487],\n",
      "        [-1.4511,  1.4075, -0.1058],\n",
      "        [ 0.5879, -0.1329, -0.7995],\n",
      "        [-1.3239,  1.2044,  0.0504]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7267,  0.3379,  1.2051],\n",
      "        [-1.8049,  0.0194,  1.3827],\n",
      "        [ 0.2640, -0.0697, -0.5832],\n",
      "        [-1.3035,  1.5315, -0.1654],\n",
      "        [-1.6362,  1.2840, -0.0619],\n",
      "        [-1.7185,  0.2944,  1.4264],\n",
      "        [ 0.6259, -0.1948, -1.0903],\n",
      "        [-1.5189,  1.2686,  0.3431],\n",
      "        [-1.7054,  0.7130,  0.6288],\n",
      "        [-1.5938,  1.1734,  0.3499],\n",
      "        [ 0.3000, -0.1148, -0.7639],\n",
      "        [-1.5278,  0.3174,  0.9431],\n",
      "        [-1.8525,  0.3928,  1.1487],\n",
      "        [-1.4511,  1.4075, -0.1058],\n",
      "        [ 0.5879, -0.1329, -0.7995],\n",
      "        [-1.3239,  1.2044,  0.0504]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.0850,  1.4694, -0.5759],\n",
      "        [ 0.5341,  0.1782, -1.0246],\n",
      "        [-1.2459,  1.1444,  0.1973],\n",
      "        [-1.6194,  1.3439,  0.1856],\n",
      "        [ 0.4620, -0.0547, -0.8420],\n",
      "        [-1.3684,  1.2329,  0.0113],\n",
      "        [ 0.7515, -0.1860, -0.8134],\n",
      "        [ 0.5199,  0.0239, -0.8222],\n",
      "        [-1.1310,  1.2267, -0.6271],\n",
      "        [ 0.6012, -0.1328, -0.8262],\n",
      "        [-1.6435,  0.2610,  1.0828],\n",
      "        [ 0.4804,  0.0066, -0.9372],\n",
      "        [-1.4760,  1.3027,  0.1029],\n",
      "        [-1.5418,  1.2872, -0.1748],\n",
      "        [-1.3641,  1.0946,  0.0249],\n",
      "        [-1.5674,  0.1471,  1.1321]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.0850,  1.4694, -0.5759],\n",
      "        [ 0.5341,  0.1782, -1.0246],\n",
      "        [-1.2459,  1.1444,  0.1973],\n",
      "        [-1.6194,  1.3439,  0.1856],\n",
      "        [ 0.4620, -0.0547, -0.8420],\n",
      "        [-1.3684,  1.2329,  0.0113],\n",
      "        [ 0.7515, -0.1860, -0.8134],\n",
      "        [ 0.5199,  0.0239, -0.8222],\n",
      "        [-1.1310,  1.2267, -0.6271],\n",
      "        [ 0.6012, -0.1328, -0.8262],\n",
      "        [-1.6435,  0.2610,  1.0828],\n",
      "        [ 0.4804,  0.0066, -0.9372],\n",
      "        [-1.4760,  1.3027,  0.1029],\n",
      "        [-1.5418,  1.2872, -0.1748],\n",
      "        [-1.3641,  1.0946,  0.0249],\n",
      "        [-1.5674,  0.1471,  1.1321]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0140e-01,  3.3414e-01, -5.8073e-01],\n",
      "        [-1.7743e+00,  8.9174e-01,  7.0927e-01],\n",
      "        [-1.9361e+00,  1.5926e+00,  2.3969e-01],\n",
      "        [-1.5693e+00,  8.2812e-01,  6.9358e-01],\n",
      "        [-1.7199e+00,  2.0871e-01,  1.2610e+00],\n",
      "        [-1.0606e+00,  1.1059e+00, -1.8688e-04],\n",
      "        [ 2.7108e-01,  1.3764e-01, -9.0377e-01],\n",
      "        [-1.5115e+00,  1.4853e+00, -2.6728e-01],\n",
      "        [ 6.1963e-01, -2.1288e-02, -7.7768e-01],\n",
      "        [-1.3752e+00,  1.2639e+00, -8.2067e-02],\n",
      "        [-1.2392e+00,  1.2576e+00, -3.0805e-02],\n",
      "        [-1.3735e+00,  3.4863e-01,  9.9526e-01],\n",
      "        [-1.3876e+00,  1.2225e+00,  6.5730e-02],\n",
      "        [ 4.4718e-01, -7.5083e-02, -7.6457e-01],\n",
      "        [-1.1392e+00,  1.3173e+00, -4.1746e-02],\n",
      "        [ 2.2671e-01,  3.2475e-01, -8.6569e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.0140e-01,  3.3414e-01, -5.8073e-01],\n",
      "        [-1.7743e+00,  8.9174e-01,  7.0927e-01],\n",
      "        [-1.9361e+00,  1.5926e+00,  2.3969e-01],\n",
      "        [-1.5693e+00,  8.2812e-01,  6.9358e-01],\n",
      "        [-1.7199e+00,  2.0871e-01,  1.2610e+00],\n",
      "        [-1.0606e+00,  1.1059e+00, -1.8688e-04],\n",
      "        [ 2.7108e-01,  1.3764e-01, -9.0377e-01],\n",
      "        [-1.5115e+00,  1.4853e+00, -2.6728e-01],\n",
      "        [ 6.1963e-01, -2.1288e-02, -7.7768e-01],\n",
      "        [-1.3752e+00,  1.2639e+00, -8.2067e-02],\n",
      "        [-1.2392e+00,  1.2576e+00, -3.0805e-02],\n",
      "        [-1.3735e+00,  3.4863e-01,  9.9526e-01],\n",
      "        [-1.3876e+00,  1.2225e+00,  6.5730e-02],\n",
      "        [ 4.4718e-01, -7.5083e-02, -7.6457e-01],\n",
      "        [-1.1392e+00,  1.3173e+00, -4.1746e-02],\n",
      "        [ 2.2671e-01,  3.2475e-01, -8.6569e-01]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5406,  1.2338,  0.0671],\n",
      "        [-0.1343,  0.6280, -0.8277],\n",
      "        [ 0.2694, -0.1693, -0.5446],\n",
      "        [ 0.3956,  0.1016, -1.1015],\n",
      "        [-1.3505,  1.3351, -0.2408],\n",
      "        [-1.4774,  1.6251, -0.3501],\n",
      "        [-1.8450,  1.5492,  0.1108],\n",
      "        [ 0.0885, -0.1756, -0.3064],\n",
      "        [-1.6911,  1.2702,  0.2620],\n",
      "        [-1.6948,  1.5659, -0.1097],\n",
      "        [-1.4768,  1.4446,  0.0147],\n",
      "        [-1.4738,  1.0374,  0.0312],\n",
      "        [-1.5762,  1.6716,  0.0091],\n",
      "        [-1.7671,  1.1602,  0.4864],\n",
      "        [-1.3718,  1.2644,  0.1145],\n",
      "        [-1.6930,  0.4946,  1.1039]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5406,  1.2338,  0.0671],\n",
      "        [-0.1343,  0.6280, -0.8277],\n",
      "        [ 0.2694, -0.1693, -0.5446],\n",
      "        [ 0.3956,  0.1016, -1.1015],\n",
      "        [-1.3505,  1.3351, -0.2408],\n",
      "        [-1.4774,  1.6251, -0.3501],\n",
      "        [-1.8450,  1.5492,  0.1108],\n",
      "        [ 0.0885, -0.1756, -0.3064],\n",
      "        [-1.6911,  1.2702,  0.2620],\n",
      "        [-1.6948,  1.5659, -0.1097],\n",
      "        [-1.4768,  1.4446,  0.0147],\n",
      "        [-1.4738,  1.0374,  0.0312],\n",
      "        [-1.5762,  1.6716,  0.0091],\n",
      "        [-1.7671,  1.1602,  0.4864],\n",
      "        [-1.3718,  1.2644,  0.1145],\n",
      "        [-1.6930,  0.4946,  1.1039]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6405,  0.2032,  1.1575],\n",
      "        [-1.1115,  0.0056,  0.6102],\n",
      "        [ 0.3101, -0.0478, -0.7596],\n",
      "        [-1.6197,  1.1288, -0.0293],\n",
      "        [ 0.5268, -0.1358, -0.7584],\n",
      "        [-1.8106,  0.7106,  0.8023],\n",
      "        [-1.3334,  1.2698,  0.0785],\n",
      "        [-2.0541,  0.8664,  0.7210],\n",
      "        [-1.4129,  1.1886,  0.0426],\n",
      "        [-1.5637,  1.0169,  0.4110],\n",
      "        [-1.1496,  1.0881,  0.0635],\n",
      "        [-1.2558,  1.1909,  0.0800],\n",
      "        [-1.4638,  0.2158,  1.0488],\n",
      "        [-1.8492,  1.0481,  0.5014],\n",
      "        [-1.5725,  0.6013,  1.0538],\n",
      "        [-1.5425,  1.3956,  0.0592]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6405,  0.2032,  1.1575],\n",
      "        [-1.1115,  0.0056,  0.6102],\n",
      "        [ 0.3101, -0.0478, -0.7596],\n",
      "        [-1.6197,  1.1288, -0.0293],\n",
      "        [ 0.5268, -0.1358, -0.7584],\n",
      "        [-1.8106,  0.7106,  0.8023],\n",
      "        [-1.3334,  1.2698,  0.0785],\n",
      "        [-2.0541,  0.8664,  0.7210],\n",
      "        [-1.4129,  1.1886,  0.0426],\n",
      "        [-1.5637,  1.0169,  0.4110],\n",
      "        [-1.1496,  1.0881,  0.0635],\n",
      "        [-1.2558,  1.1909,  0.0800],\n",
      "        [-1.4638,  0.2158,  1.0488],\n",
      "        [-1.8492,  1.0481,  0.5014],\n",
      "        [-1.5725,  0.6013,  1.0538],\n",
      "        [-1.5425,  1.3956,  0.0592]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8240e+00,  4.3491e-01,  1.0697e+00],\n",
      "        [-1.7556e+00,  1.5119e+00,  1.4308e-03],\n",
      "        [-1.3197e+00,  1.9949e-01,  1.0614e+00],\n",
      "        [-1.6010e+00,  1.5597e+00, -6.8188e-02],\n",
      "        [ 3.5718e-01,  5.8909e-02, -9.4358e-01],\n",
      "        [ 4.7137e-01, -2.0690e-01, -8.1010e-01],\n",
      "        [-1.4879e+00,  1.3301e+00, -6.0698e-02],\n",
      "        [-1.4480e+00,  1.1040e+00, -2.4616e-02],\n",
      "        [-1.7804e+00,  6.7324e-01,  8.3161e-01],\n",
      "        [-1.7226e+00,  1.4934e+00,  1.3780e-01],\n",
      "        [-1.7983e+00,  1.3202e+00,  3.4764e-01],\n",
      "        [-1.4655e+00,  1.3894e-01,  1.2911e+00],\n",
      "        [-1.7275e+00,  1.3876e+00,  3.1341e-02],\n",
      "        [-1.6108e+00,  1.4974e+00, -7.4069e-02],\n",
      "        [-1.9197e+00,  1.0883e+00,  5.6735e-01],\n",
      "        [-1.6017e+00,  1.4602e-02,  1.4194e+00]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8240e+00,  4.3491e-01,  1.0697e+00],\n",
      "        [-1.7556e+00,  1.5119e+00,  1.4308e-03],\n",
      "        [-1.3197e+00,  1.9949e-01,  1.0614e+00],\n",
      "        [-1.6010e+00,  1.5597e+00, -6.8188e-02],\n",
      "        [ 3.5718e-01,  5.8909e-02, -9.4358e-01],\n",
      "        [ 4.7137e-01, -2.0690e-01, -8.1010e-01],\n",
      "        [-1.4879e+00,  1.3301e+00, -6.0698e-02],\n",
      "        [-1.4480e+00,  1.1040e+00, -2.4616e-02],\n",
      "        [-1.7804e+00,  6.7324e-01,  8.3161e-01],\n",
      "        [-1.7226e+00,  1.4934e+00,  1.3780e-01],\n",
      "        [-1.7983e+00,  1.3202e+00,  3.4764e-01],\n",
      "        [-1.4655e+00,  1.3894e-01,  1.2911e+00],\n",
      "        [-1.7275e+00,  1.3876e+00,  3.1341e-02],\n",
      "        [-1.6108e+00,  1.4974e+00, -7.4069e-02],\n",
      "        [-1.9197e+00,  1.0883e+00,  5.6735e-01],\n",
      "        [-1.6017e+00,  1.4602e-02,  1.4194e+00]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4347,  1.4259,  0.0052],\n",
      "        [-1.8950,  0.2950,  1.2582],\n",
      "        [-1.3129,  1.3578,  0.0041],\n",
      "        [-1.3011,  0.0434,  1.0184],\n",
      "        [-1.5029,  0.0243,  0.8957],\n",
      "        [-1.7484,  0.3695,  1.1634],\n",
      "        [-1.5519,  0.3373,  1.1858],\n",
      "        [-1.7856,  1.2405,  0.2642],\n",
      "        [-1.5629,  1.7158, -0.3755],\n",
      "        [-1.5940,  1.1144,  0.0865],\n",
      "        [-1.9289,  0.5261,  0.8173],\n",
      "        [ 0.5608,  0.0835, -1.1005],\n",
      "        [-1.5541,  1.0857, -0.0511],\n",
      "        [-1.5242,  1.3534, -0.0279],\n",
      "        [-1.4412,  1.2469,  0.1561],\n",
      "        [ 0.4977,  0.0152, -1.0171]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4347,  1.4259,  0.0052],\n",
      "        [-1.8950,  0.2950,  1.2582],\n",
      "        [-1.3129,  1.3578,  0.0041],\n",
      "        [-1.3011,  0.0434,  1.0184],\n",
      "        [-1.5029,  0.0243,  0.8957],\n",
      "        [-1.7484,  0.3695,  1.1634],\n",
      "        [-1.5519,  0.3373,  1.1858],\n",
      "        [-1.7856,  1.2405,  0.2642],\n",
      "        [-1.5629,  1.7158, -0.3755],\n",
      "        [-1.5940,  1.1144,  0.0865],\n",
      "        [-1.9289,  0.5261,  0.8173],\n",
      "        [ 0.5608,  0.0835, -1.1005],\n",
      "        [-1.5541,  1.0857, -0.0511],\n",
      "        [-1.5242,  1.3534, -0.0279],\n",
      "        [-1.4412,  1.2469,  0.1561],\n",
      "        [ 0.4977,  0.0152, -1.0171]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3774e+00,  1.3491e+00,  5.3384e-04],\n",
      "        [-7.9775e-01,  1.2066e+00, -4.0941e-01],\n",
      "        [-1.5110e+00,  1.1635e+00,  1.1793e-01],\n",
      "        [-1.6036e+00,  1.2292e+00,  3.6819e-01],\n",
      "        [-1.7060e+00,  1.6146e+00,  2.1022e-02],\n",
      "        [-1.5986e+00,  1.2245e+00, -5.9986e-02],\n",
      "        [-1.4346e+00,  1.0791e-01,  8.9763e-01],\n",
      "        [-1.5863e+00,  1.0855e+00,  2.2807e-01],\n",
      "        [-1.8507e+00,  6.4217e-01,  9.7364e-01],\n",
      "        [-1.8919e+00,  1.2499e+00,  3.4063e-01],\n",
      "        [-1.4142e+00,  1.1473e+00, -1.0589e-01],\n",
      "        [-2.2144e-01,  9.5724e-02, -2.5509e-01],\n",
      "        [-1.6531e+00,  5.0845e-01,  4.9132e-01],\n",
      "        [-1.9504e+00,  4.7484e-01,  1.2084e+00],\n",
      "        [ 7.4565e-02,  2.4506e-01, -6.9154e-01],\n",
      "        [-1.8512e+00,  1.6798e+00,  7.7640e-02]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3774e+00,  1.3491e+00,  5.3384e-04],\n",
      "        [-7.9775e-01,  1.2066e+00, -4.0941e-01],\n",
      "        [-1.5110e+00,  1.1635e+00,  1.1793e-01],\n",
      "        [-1.6036e+00,  1.2292e+00,  3.6819e-01],\n",
      "        [-1.7060e+00,  1.6146e+00,  2.1022e-02],\n",
      "        [-1.5986e+00,  1.2245e+00, -5.9986e-02],\n",
      "        [-1.4346e+00,  1.0791e-01,  8.9763e-01],\n",
      "        [-1.5863e+00,  1.0855e+00,  2.2807e-01],\n",
      "        [-1.8507e+00,  6.4217e-01,  9.7364e-01],\n",
      "        [-1.8919e+00,  1.2499e+00,  3.4063e-01],\n",
      "        [-1.4142e+00,  1.1473e+00, -1.0589e-01],\n",
      "        [-2.2144e-01,  9.5724e-02, -2.5509e-01],\n",
      "        [-1.6531e+00,  5.0845e-01,  4.9132e-01],\n",
      "        [-1.9504e+00,  4.7484e-01,  1.2084e+00],\n",
      "        [ 7.4565e-02,  2.4506e-01, -6.9154e-01],\n",
      "        [-1.8512e+00,  1.6798e+00,  7.7640e-02]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5988,  1.5680,  0.0646],\n",
      "        [-1.5752,  1.5649, -0.0633],\n",
      "        [ 0.4022,  0.0264, -1.0241],\n",
      "        [ 0.5311,  0.0292, -1.0300],\n",
      "        [-1.5631,  1.4599,  0.0874],\n",
      "        [-1.7773,  0.0711,  1.0051],\n",
      "        [-1.6797,  0.1546,  1.3194],\n",
      "        [-1.5606,  0.2702,  0.9794],\n",
      "        [-1.5409,  1.2513,  0.1188],\n",
      "        [-1.3540,  0.1240,  1.3123],\n",
      "        [ 0.5269,  0.0353, -0.8276],\n",
      "        [-1.2576,  1.1312,  0.1500],\n",
      "        [ 0.4046,  0.2338, -1.0288],\n",
      "        [-1.5261,  0.8091,  0.4610],\n",
      "        [-1.5306,  1.6742, -0.1396],\n",
      "        [-1.3197,  0.0766,  1.0444]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5988,  1.5680,  0.0646],\n",
      "        [-1.5752,  1.5649, -0.0633],\n",
      "        [ 0.4022,  0.0264, -1.0241],\n",
      "        [ 0.5311,  0.0292, -1.0300],\n",
      "        [-1.5631,  1.4599,  0.0874],\n",
      "        [-1.7773,  0.0711,  1.0051],\n",
      "        [-1.6797,  0.1546,  1.3194],\n",
      "        [-1.5606,  0.2702,  0.9794],\n",
      "        [-1.5409,  1.2513,  0.1188],\n",
      "        [-1.3540,  0.1240,  1.3123],\n",
      "        [ 0.5269,  0.0353, -0.8276],\n",
      "        [-1.2576,  1.1312,  0.1500],\n",
      "        [ 0.4046,  0.2338, -1.0288],\n",
      "        [-1.5261,  0.8091,  0.4610],\n",
      "        [-1.5306,  1.6742, -0.1396],\n",
      "        [-1.3197,  0.0766,  1.0444]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4043,  1.2494, -0.2870],\n",
      "        [-1.2591,  1.5246, -0.4960],\n",
      "        [-1.3841,  1.4757, -0.0234],\n",
      "        [ 0.1490,  0.5846, -1.0174],\n",
      "        [-1.3116,  1.5400, -0.3328],\n",
      "        [-1.5310,  1.3721, -0.1189],\n",
      "        [-1.7578,  0.4535,  1.0204],\n",
      "        [-1.4642,  1.5436, -0.2853],\n",
      "        [-1.6594,  1.5158,  0.1014],\n",
      "        [-2.0253,  0.4977,  1.1990],\n",
      "        [-1.5608,  1.3536,  0.2479],\n",
      "        [ 0.3350,  0.1108, -0.9865],\n",
      "        [-1.8074,  1.9347, -0.1663],\n",
      "        [-1.4224,  1.3062, -0.1261],\n",
      "        [-1.7988,  1.3463, -0.1657],\n",
      "        [-1.7957,  1.5599,  0.3014]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4043,  1.2494, -0.2870],\n",
      "        [-1.2591,  1.5246, -0.4960],\n",
      "        [-1.3841,  1.4757, -0.0234],\n",
      "        [ 0.1490,  0.5846, -1.0174],\n",
      "        [-1.3116,  1.5400, -0.3328],\n",
      "        [-1.5310,  1.3721, -0.1189],\n",
      "        [-1.7578,  0.4535,  1.0204],\n",
      "        [-1.4642,  1.5436, -0.2853],\n",
      "        [-1.6594,  1.5158,  0.1014],\n",
      "        [-2.0253,  0.4977,  1.1990],\n",
      "        [-1.5608,  1.3536,  0.2479],\n",
      "        [ 0.3350,  0.1108, -0.9865],\n",
      "        [-1.8074,  1.9347, -0.1663],\n",
      "        [-1.4224,  1.3062, -0.1261],\n",
      "        [-1.7988,  1.3463, -0.1657],\n",
      "        [-1.7957,  1.5599,  0.3014]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 4.8773e-01,  1.6422e-01, -1.0833e+00],\n",
      "        [-1.4927e+00,  1.6104e+00, -2.3649e-01],\n",
      "        [-1.8015e+00,  6.0284e-01,  1.1438e+00],\n",
      "        [-1.6781e+00,  1.8801e-01,  1.1323e+00],\n",
      "        [ 6.7304e-02,  6.4004e-01, -1.1722e+00],\n",
      "        [-1.6747e+00,  1.5605e+00, -4.5511e-02],\n",
      "        [-2.0814e+00,  1.0671e+00,  5.2518e-01],\n",
      "        [ 5.7903e-01,  2.0316e-01, -1.1209e+00],\n",
      "        [ 1.0761e-01,  1.5193e-03, -4.6654e-01],\n",
      "        [-1.5774e+00,  4.2154e-01,  1.0876e+00],\n",
      "        [-1.9767e+00,  1.3892e+00,  1.6594e-01],\n",
      "        [-1.5845e+00,  1.5327e+00, -2.1776e-01],\n",
      "        [ 5.1207e-01,  1.9021e-02, -9.9005e-01],\n",
      "        [-1.9290e+00,  1.6697e+00,  1.0314e-01],\n",
      "        [-1.7425e+00,  1.5502e+00, -5.6260e-02],\n",
      "        [-1.8699e+00,  1.7202e+00, -1.5457e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 4.8773e-01,  1.6422e-01, -1.0833e+00],\n",
      "        [-1.4927e+00,  1.6104e+00, -2.3649e-01],\n",
      "        [-1.8015e+00,  6.0284e-01,  1.1438e+00],\n",
      "        [-1.6781e+00,  1.8801e-01,  1.1323e+00],\n",
      "        [ 6.7304e-02,  6.4004e-01, -1.1722e+00],\n",
      "        [-1.6747e+00,  1.5605e+00, -4.5511e-02],\n",
      "        [-2.0814e+00,  1.0671e+00,  5.2518e-01],\n",
      "        [ 5.7903e-01,  2.0316e-01, -1.1209e+00],\n",
      "        [ 1.0761e-01,  1.5193e-03, -4.6654e-01],\n",
      "        [-1.5774e+00,  4.2154e-01,  1.0876e+00],\n",
      "        [-1.9767e+00,  1.3892e+00,  1.6594e-01],\n",
      "        [-1.5845e+00,  1.5327e+00, -2.1776e-01],\n",
      "        [ 5.1207e-01,  1.9021e-02, -9.9005e-01],\n",
      "        [-1.9290e+00,  1.6697e+00,  1.0314e-01],\n",
      "        [-1.7425e+00,  1.5502e+00, -5.6260e-02],\n",
      "        [-1.8699e+00,  1.7202e+00, -1.5457e-01]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8233,  1.5853, -0.2400],\n",
      "        [-0.0897, -0.0030, -0.2684],\n",
      "        [-1.5785,  1.3103, -0.0986],\n",
      "        [-1.6523,  1.7152, -0.0551],\n",
      "        [ 0.4626,  0.2669, -1.1566],\n",
      "        [-1.7576,  0.7302,  0.7963],\n",
      "        [-1.5091,  1.7236, -0.0630],\n",
      "        [-1.5714,  1.5116,  0.0774],\n",
      "        [-0.8037,  1.4487, -0.7336],\n",
      "        [-1.8365,  1.7864, -0.0411],\n",
      "        [ 0.1088,  0.3826, -0.9204],\n",
      "        [-1.2552,  1.3660, -0.2644],\n",
      "        [ 0.5141,  0.1226, -1.0923],\n",
      "        [-0.9004,  1.1758, -0.6801],\n",
      "        [-1.4886,  1.5484,  0.0172],\n",
      "        [-1.6799,  1.3891,  0.1097]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8233,  1.5853, -0.2400],\n",
      "        [-0.0897, -0.0030, -0.2684],\n",
      "        [-1.5785,  1.3103, -0.0986],\n",
      "        [-1.6523,  1.7152, -0.0551],\n",
      "        [ 0.4626,  0.2669, -1.1566],\n",
      "        [-1.7576,  0.7302,  0.7963],\n",
      "        [-1.5091,  1.7236, -0.0630],\n",
      "        [-1.5714,  1.5116,  0.0774],\n",
      "        [-0.8037,  1.4487, -0.7336],\n",
      "        [-1.8365,  1.7864, -0.0411],\n",
      "        [ 0.1088,  0.3826, -0.9204],\n",
      "        [-1.2552,  1.3660, -0.2644],\n",
      "        [ 0.5141,  0.1226, -1.0923],\n",
      "        [-0.9004,  1.1758, -0.6801],\n",
      "        [-1.4886,  1.5484,  0.0172],\n",
      "        [-1.6799,  1.3891,  0.1097]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7150e+00,  1.9257e-01,  1.3709e+00],\n",
      "        [-1.5180e+00,  1.4361e+00,  4.7035e-03],\n",
      "        [-1.6922e+00,  1.5969e+00,  9.5192e-02],\n",
      "        [ 5.2747e-01,  2.9831e-01, -1.0035e+00],\n",
      "        [-6.4880e-01,  1.3299e+00, -7.6181e-01],\n",
      "        [-1.6524e+00,  4.4935e-01,  1.1226e+00],\n",
      "        [-1.6466e+00,  1.0508e+00,  1.5383e-01],\n",
      "        [-1.0143e+00,  6.0812e-01,  3.4682e-01],\n",
      "        [ 4.3454e-01, -1.4135e-03, -6.3426e-01],\n",
      "        [-1.7497e+00,  2.7209e-01,  1.1285e+00],\n",
      "        [-1.5315e+00,  6.1458e-01,  6.3165e-01],\n",
      "        [-1.4578e+00,  1.4970e+00, -1.6539e-01],\n",
      "        [-1.5117e+00,  1.5538e+00, -2.8478e-01],\n",
      "        [-1.9282e+00,  1.6423e+00,  4.6726e-02],\n",
      "        [-1.6750e+00,  1.6799e+00, -1.5301e-01],\n",
      "        [-1.4817e+00,  1.1786e+00,  4.0410e-02]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7150e+00,  1.9257e-01,  1.3709e+00],\n",
      "        [-1.5180e+00,  1.4361e+00,  4.7035e-03],\n",
      "        [-1.6922e+00,  1.5969e+00,  9.5192e-02],\n",
      "        [ 5.2747e-01,  2.9831e-01, -1.0035e+00],\n",
      "        [-6.4880e-01,  1.3299e+00, -7.6181e-01],\n",
      "        [-1.6524e+00,  4.4935e-01,  1.1226e+00],\n",
      "        [-1.6466e+00,  1.0508e+00,  1.5383e-01],\n",
      "        [-1.0143e+00,  6.0812e-01,  3.4682e-01],\n",
      "        [ 4.3454e-01, -1.4135e-03, -6.3426e-01],\n",
      "        [-1.7497e+00,  2.7209e-01,  1.1285e+00],\n",
      "        [-1.5315e+00,  6.1458e-01,  6.3165e-01],\n",
      "        [-1.4578e+00,  1.4970e+00, -1.6539e-01],\n",
      "        [-1.5117e+00,  1.5538e+00, -2.8478e-01],\n",
      "        [-1.9282e+00,  1.6423e+00,  4.6726e-02],\n",
      "        [-1.6750e+00,  1.6799e+00, -1.5301e-01],\n",
      "        [-1.4817e+00,  1.1786e+00,  4.0410e-02]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7328,  1.5762, -0.1616],\n",
      "        [-1.9475,  0.5378,  1.0089],\n",
      "        [ 0.3842,  0.2028, -1.1508],\n",
      "        [-0.1035,  0.6140, -0.9635],\n",
      "        [-1.6605,  0.4435,  1.2957],\n",
      "        [-1.8641,  0.2681,  1.0046],\n",
      "        [-1.5915,  1.5485, -0.1697],\n",
      "        [-1.7948,  1.5642, -0.1639],\n",
      "        [-1.6278,  1.6994, -0.1636],\n",
      "        [-1.5591,  0.7203,  0.6920],\n",
      "        [-1.0753,  0.2821,  0.6671],\n",
      "        [ 0.3960,  0.1171, -1.0726],\n",
      "        [-1.9128,  1.3134,  0.1784],\n",
      "        [-1.4533,  1.4374,  0.0281],\n",
      "        [-1.9593,  1.8695, -0.2747],\n",
      "        [-1.7809,  0.8938,  0.7059]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7328,  1.5762, -0.1616],\n",
      "        [-1.9475,  0.5378,  1.0089],\n",
      "        [ 0.3842,  0.2028, -1.1508],\n",
      "        [-0.1035,  0.6140, -0.9635],\n",
      "        [-1.6605,  0.4435,  1.2957],\n",
      "        [-1.8641,  0.2681,  1.0046],\n",
      "        [-1.5915,  1.5485, -0.1697],\n",
      "        [-1.7948,  1.5642, -0.1639],\n",
      "        [-1.6278,  1.6994, -0.1636],\n",
      "        [-1.5591,  0.7203,  0.6920],\n",
      "        [-1.0753,  0.2821,  0.6671],\n",
      "        [ 0.3960,  0.1171, -1.0726],\n",
      "        [-1.9128,  1.3134,  0.1784],\n",
      "        [-1.4533,  1.4374,  0.0281],\n",
      "        [-1.9593,  1.8695, -0.2747],\n",
      "        [-1.7809,  0.8938,  0.7059]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6874,  1.3671, -0.0529],\n",
      "        [-1.5714,  1.0241,  0.4602],\n",
      "        [-1.5468,  1.3847,  0.0306],\n",
      "        [ 0.1093,  0.6923, -1.1097],\n",
      "        [-1.7733,  1.6817, -0.0114],\n",
      "        [-1.7240,  1.5835, -0.2228],\n",
      "        [-1.7645,  1.8581, -0.1797],\n",
      "        [-1.4764,  1.4517, -0.2929],\n",
      "        [-1.6984,  0.3202,  1.2562],\n",
      "        [-1.7267,  1.7542, -0.1494],\n",
      "        [-1.3487,  1.4492, -0.0354],\n",
      "        [-1.4051,  1.5084, -0.1476],\n",
      "        [-1.6308,  1.7747, -0.1390],\n",
      "        [-1.4989,  1.5906, -0.2531],\n",
      "        [-2.0568,  0.1206,  1.2602],\n",
      "        [-1.8216,  0.0473,  1.3872]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6874,  1.3671, -0.0529],\n",
      "        [-1.5714,  1.0241,  0.4602],\n",
      "        [-1.5468,  1.3847,  0.0306],\n",
      "        [ 0.1093,  0.6923, -1.1097],\n",
      "        [-1.7733,  1.6817, -0.0114],\n",
      "        [-1.7240,  1.5835, -0.2228],\n",
      "        [-1.7645,  1.8581, -0.1797],\n",
      "        [-1.4764,  1.4517, -0.2929],\n",
      "        [-1.6984,  0.3202,  1.2562],\n",
      "        [-1.7267,  1.7542, -0.1494],\n",
      "        [-1.3487,  1.4492, -0.0354],\n",
      "        [-1.4051,  1.5084, -0.1476],\n",
      "        [-1.6308,  1.7747, -0.1390],\n",
      "        [-1.4989,  1.5906, -0.2531],\n",
      "        [-2.0568,  0.1206,  1.2602],\n",
      "        [-1.8216,  0.0473,  1.3872]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7311,  0.5898,  0.8662],\n",
      "        [ 0.5266,  0.1550, -1.3046],\n",
      "        [-1.6297,  1.7281, -0.2657],\n",
      "        [-1.5576,  0.2250,  1.2206],\n",
      "        [-1.6545,  1.7696, -0.3713],\n",
      "        [-1.0636,  1.2458, -0.4840],\n",
      "        [-1.6795,  1.5764,  0.0163],\n",
      "        [-1.8507,  1.7627, -0.2870],\n",
      "        [-1.5530,  1.5347, -0.1071],\n",
      "        [-1.9723,  1.1971,  0.3440],\n",
      "        [-1.7291,  1.6095,  0.0443],\n",
      "        [-1.8327,  1.4457,  0.4624],\n",
      "        [ 0.5797,  0.4467, -1.1790],\n",
      "        [-1.9476,  0.8112,  0.7260],\n",
      "        [-1.8158,  0.2409,  1.2241],\n",
      "        [-1.8973,  1.6976,  0.0584]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7311,  0.5898,  0.8662],\n",
      "        [ 0.5266,  0.1550, -1.3046],\n",
      "        [-1.6297,  1.7281, -0.2657],\n",
      "        [-1.5576,  0.2250,  1.2206],\n",
      "        [-1.6545,  1.7696, -0.3713],\n",
      "        [-1.0636,  1.2458, -0.4840],\n",
      "        [-1.6795,  1.5764,  0.0163],\n",
      "        [-1.8507,  1.7627, -0.2870],\n",
      "        [-1.5530,  1.5347, -0.1071],\n",
      "        [-1.9723,  1.1971,  0.3440],\n",
      "        [-1.7291,  1.6095,  0.0443],\n",
      "        [-1.8327,  1.4457,  0.4624],\n",
      "        [ 0.5797,  0.4467, -1.1790],\n",
      "        [-1.9476,  0.8112,  0.7260],\n",
      "        [-1.8158,  0.2409,  1.2241],\n",
      "        [-1.8973,  1.6976,  0.0584]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7076,  1.5558,  0.0649],\n",
      "        [-1.6371,  1.0105,  0.5634],\n",
      "        [ 0.6281,  0.0285, -1.2754],\n",
      "        [-1.5233,  1.8539, -0.2733],\n",
      "        [-1.8474,  0.3642,  1.3116],\n",
      "        [-1.7396,  2.0084, -0.1413],\n",
      "        [ 0.2835,  0.0049, -1.0683],\n",
      "        [-1.4295,  1.8070, -0.1921],\n",
      "        [-1.8686,  0.3440,  1.0822],\n",
      "        [-1.7977,  0.7824,  0.7732],\n",
      "        [-1.6424,  1.8321, -0.4987],\n",
      "        [-1.5879,  1.7947, -0.4378],\n",
      "        [-1.7618,  1.8081, -0.2463],\n",
      "        [-1.7607,  0.3214,  1.2043],\n",
      "        [-1.7629,  1.7408, -0.2581],\n",
      "        [ 0.2279,  0.1734, -1.0501]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7076,  1.5558,  0.0649],\n",
      "        [-1.6371,  1.0105,  0.5634],\n",
      "        [ 0.6281,  0.0285, -1.2754],\n",
      "        [-1.5233,  1.8539, -0.2733],\n",
      "        [-1.8474,  0.3642,  1.3116],\n",
      "        [-1.7396,  2.0084, -0.1413],\n",
      "        [ 0.2835,  0.0049, -1.0683],\n",
      "        [-1.4295,  1.8070, -0.1921],\n",
      "        [-1.8686,  0.3440,  1.0822],\n",
      "        [-1.7977,  0.7824,  0.7732],\n",
      "        [-1.6424,  1.8321, -0.4987],\n",
      "        [-1.5879,  1.7947, -0.4378],\n",
      "        [-1.7618,  1.8081, -0.2463],\n",
      "        [-1.7607,  0.3214,  1.2043],\n",
      "        [-1.7629,  1.7408, -0.2581],\n",
      "        [ 0.2279,  0.1734, -1.0501]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8267,  2.0654, -0.2306],\n",
      "        [-1.8935,  1.2777,  0.6264],\n",
      "        [-1.8639,  0.3729,  1.3272],\n",
      "        [-1.7690,  1.7687, -0.3630],\n",
      "        [-1.5734,  1.8831, -0.3874],\n",
      "        [-1.7589,  1.5292, -0.0147],\n",
      "        [-1.6698,  1.2952,  0.1582],\n",
      "        [-1.6026,  1.1946,  0.3688],\n",
      "        [-1.5800,  1.8070, -0.4066],\n",
      "        [-1.5058,  1.5341, -0.2084],\n",
      "        [ 0.5299,  0.2433, -1.2581],\n",
      "        [ 0.4143,  0.3010, -1.2606],\n",
      "        [-1.8524,  1.9505, -0.2893],\n",
      "        [-1.5025,  1.7677, -0.2287],\n",
      "        [-1.6609,  1.9490, -0.2101],\n",
      "        [-1.5321,  1.7406, -0.2647]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8267,  2.0654, -0.2306],\n",
      "        [-1.8935,  1.2777,  0.6264],\n",
      "        [-1.8639,  0.3729,  1.3272],\n",
      "        [-1.7690,  1.7687, -0.3630],\n",
      "        [-1.5734,  1.8831, -0.3874],\n",
      "        [-1.7589,  1.5292, -0.0147],\n",
      "        [-1.6698,  1.2952,  0.1582],\n",
      "        [-1.6026,  1.1946,  0.3688],\n",
      "        [-1.5800,  1.8070, -0.4066],\n",
      "        [-1.5058,  1.5341, -0.2084],\n",
      "        [ 0.5299,  0.2433, -1.2581],\n",
      "        [ 0.4143,  0.3010, -1.2606],\n",
      "        [-1.8524,  1.9505, -0.2893],\n",
      "        [-1.5025,  1.7677, -0.2287],\n",
      "        [-1.6609,  1.9490, -0.2101],\n",
      "        [-1.5321,  1.7406, -0.2647]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5760,  1.9634, -0.4918],\n",
      "        [-1.7606,  0.1933,  1.3688],\n",
      "        [ 0.4631,  0.2449, -1.0974],\n",
      "        [-1.6604,  1.7649, -0.2444],\n",
      "        [-1.3827,  1.6952, -0.4434],\n",
      "        [-1.8244,  1.7652, -0.1679],\n",
      "        [-1.5448,  1.6591, -0.2488],\n",
      "        [-1.7154,  0.1331,  1.2778],\n",
      "        [-1.6618,  1.8567, -0.3953],\n",
      "        [-1.7075,  0.4956,  1.0923],\n",
      "        [-1.7538,  1.7859, -0.0837],\n",
      "        [-1.6498,  1.8411, -0.1859],\n",
      "        [ 0.4508,  0.2071, -1.0559],\n",
      "        [-1.8047,  0.4381,  1.0016],\n",
      "        [-1.6646,  1.8217, -0.6678],\n",
      "        [-1.8605,  0.2523,  1.4498]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5760,  1.9634, -0.4918],\n",
      "        [-1.7606,  0.1933,  1.3688],\n",
      "        [ 0.4631,  0.2449, -1.0974],\n",
      "        [-1.6604,  1.7649, -0.2444],\n",
      "        [-1.3827,  1.6952, -0.4434],\n",
      "        [-1.8244,  1.7652, -0.1679],\n",
      "        [-1.5448,  1.6591, -0.2488],\n",
      "        [-1.7154,  0.1331,  1.2778],\n",
      "        [-1.6618,  1.8567, -0.3953],\n",
      "        [-1.7075,  0.4956,  1.0923],\n",
      "        [-1.7538,  1.7859, -0.0837],\n",
      "        [-1.6498,  1.8411, -0.1859],\n",
      "        [ 0.4508,  0.2071, -1.0559],\n",
      "        [-1.8047,  0.4381,  1.0016],\n",
      "        [-1.6646,  1.8217, -0.6678],\n",
      "        [-1.8605,  0.2523,  1.4498]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-9.4157e-01,  1.3919e+00, -8.2194e-01],\n",
      "        [-1.6483e+00,  2.1630e-01,  1.4804e+00],\n",
      "        [ 3.6638e-01,  2.1032e-01, -1.2299e+00],\n",
      "        [ 2.9982e-01,  3.1770e-01, -1.1921e+00],\n",
      "        [-1.7567e+00,  1.1956e+00,  5.7104e-01],\n",
      "        [-1.5920e+00,  1.6880e+00,  1.9019e-04],\n",
      "        [-1.9195e+00,  1.1301e+00,  6.0801e-01],\n",
      "        [-5.2892e-01,  3.0229e-01, -1.1621e-01],\n",
      "        [-1.0180e+00,  1.4688e+00, -6.5472e-01],\n",
      "        [-1.6874e+00,  4.2598e-02,  1.3475e+00],\n",
      "        [-1.1342e-01,  1.1230e-01, -5.7489e-01],\n",
      "        [-1.6313e+00,  2.0450e-01,  1.2058e+00],\n",
      "        [ 3.4800e-01,  3.5607e-01, -1.2233e+00],\n",
      "        [-1.9076e+00,  1.1515e+00,  6.0455e-01],\n",
      "        [-1.6822e+00,  2.0365e+00, -3.2051e-01],\n",
      "        [ 3.5212e-01,  2.8074e-01, -1.2400e+00]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-9.4157e-01,  1.3919e+00, -8.2194e-01],\n",
      "        [-1.6483e+00,  2.1630e-01,  1.4804e+00],\n",
      "        [ 3.6638e-01,  2.1032e-01, -1.2299e+00],\n",
      "        [ 2.9982e-01,  3.1770e-01, -1.1921e+00],\n",
      "        [-1.7567e+00,  1.1956e+00,  5.7104e-01],\n",
      "        [-1.5920e+00,  1.6880e+00,  1.9019e-04],\n",
      "        [-1.9195e+00,  1.1301e+00,  6.0801e-01],\n",
      "        [-5.2892e-01,  3.0229e-01, -1.1621e-01],\n",
      "        [-1.0180e+00,  1.4688e+00, -6.5472e-01],\n",
      "        [-1.6874e+00,  4.2598e-02,  1.3475e+00],\n",
      "        [-1.1342e-01,  1.1230e-01, -5.7489e-01],\n",
      "        [-1.6313e+00,  2.0450e-01,  1.2058e+00],\n",
      "        [ 3.4800e-01,  3.5607e-01, -1.2233e+00],\n",
      "        [-1.9076e+00,  1.1515e+00,  6.0455e-01],\n",
      "        [-1.6822e+00,  2.0365e+00, -3.2051e-01],\n",
      "        [ 3.5212e-01,  2.8074e-01, -1.2400e+00]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7344,  1.7751,  0.1480],\n",
      "        [-1.9432,  0.3059,  1.1133],\n",
      "        [-2.0526,  1.1942,  0.4277],\n",
      "        [ 0.5701,  0.4018, -1.2777],\n",
      "        [-1.6665,  0.7124,  0.7488],\n",
      "        [ 0.4891,  0.3204, -1.2989],\n",
      "        [-1.6684,  0.2439,  1.2760],\n",
      "        [-1.9982,  0.5700,  1.0685],\n",
      "        [-1.5895,  1.6957, -0.2906],\n",
      "        [-1.5937,  1.9984, -0.4099],\n",
      "        [-1.8677,  2.1438, -0.4215],\n",
      "        [ 0.1258,  0.4307, -1.0312],\n",
      "        [-1.6125,  1.8556, -0.4511],\n",
      "        [-1.5394,  1.9095, -0.3933],\n",
      "        [-1.8037,  2.1181, -0.2575],\n",
      "        [ 0.2713,  0.6176, -1.1831]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7344,  1.7751,  0.1480],\n",
      "        [-1.9432,  0.3059,  1.1133],\n",
      "        [-2.0526,  1.1942,  0.4277],\n",
      "        [ 0.5701,  0.4018, -1.2777],\n",
      "        [-1.6665,  0.7124,  0.7488],\n",
      "        [ 0.4891,  0.3204, -1.2989],\n",
      "        [-1.6684,  0.2439,  1.2760],\n",
      "        [-1.9982,  0.5700,  1.0685],\n",
      "        [-1.5895,  1.6957, -0.2906],\n",
      "        [-1.5937,  1.9984, -0.4099],\n",
      "        [-1.8677,  2.1438, -0.4215],\n",
      "        [ 0.1258,  0.4307, -1.0312],\n",
      "        [-1.6125,  1.8556, -0.4511],\n",
      "        [-1.5394,  1.9095, -0.3933],\n",
      "        [-1.8037,  2.1181, -0.2575],\n",
      "        [ 0.2713,  0.6176, -1.1831]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4884,  1.7074, -0.1277],\n",
      "        [ 0.3758,  0.2596, -1.3442],\n",
      "        [-1.7574,  0.5762,  1.0470],\n",
      "        [ 0.4303,  0.3631, -1.2397],\n",
      "        [-0.5585,  0.1059,  0.0064],\n",
      "        [-1.9498,  0.3662,  1.2487],\n",
      "        [-1.8099,  1.7121, -0.0621],\n",
      "        [-1.8930,  0.2391,  1.1967],\n",
      "        [-1.5762,  0.9048,  0.6212],\n",
      "        [-1.5037,  0.2562,  1.4114],\n",
      "        [-1.5182,  0.3954,  0.9144],\n",
      "        [-1.4667,  1.7550, -0.3375],\n",
      "        [ 0.2841,  0.7290, -1.2488],\n",
      "        [-1.8384,  0.8699,  0.8383],\n",
      "        [-1.7140,  1.0359,  0.6878],\n",
      "        [-1.7332,  2.0534, -0.6849]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4884,  1.7074, -0.1277],\n",
      "        [ 0.3758,  0.2596, -1.3442],\n",
      "        [-1.7574,  0.5762,  1.0470],\n",
      "        [ 0.4303,  0.3631, -1.2397],\n",
      "        [-0.5585,  0.1059,  0.0064],\n",
      "        [-1.9498,  0.3662,  1.2487],\n",
      "        [-1.8099,  1.7121, -0.0621],\n",
      "        [-1.8930,  0.2391,  1.1967],\n",
      "        [-1.5762,  0.9048,  0.6212],\n",
      "        [-1.5037,  0.2562,  1.4114],\n",
      "        [-1.5182,  0.3954,  0.9144],\n",
      "        [-1.4667,  1.7550, -0.3375],\n",
      "        [ 0.2841,  0.7290, -1.2488],\n",
      "        [-1.8384,  0.8699,  0.8383],\n",
      "        [-1.7140,  1.0359,  0.6878],\n",
      "        [-1.7332,  2.0534, -0.6849]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8291,  1.5084, -0.1764],\n",
      "        [-1.7540,  1.8619, -0.4229],\n",
      "        [ 0.3745,  0.4795, -1.0420],\n",
      "        [-1.7794, -0.0788,  1.2069],\n",
      "        [-0.0294,  0.4591, -0.9194],\n",
      "        [-1.7717,  0.9341,  0.2690],\n",
      "        [-1.6508,  0.3429,  1.0282],\n",
      "        [-1.4407,  1.9834, -0.4440],\n",
      "        [-1.8413,  0.1124,  1.2972],\n",
      "        [-1.6353,  2.0659, -0.5176],\n",
      "        [-0.7281,  1.1605, -0.4750],\n",
      "        [-1.7183,  2.0978, -0.5473],\n",
      "        [-1.4878,  1.5330, -0.1593],\n",
      "        [-1.6564,  2.0000, -0.3361],\n",
      "        [-1.5350,  0.2063,  1.3498],\n",
      "        [-1.7023,  1.9929, -0.3875]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8291,  1.5084, -0.1764],\n",
      "        [-1.7540,  1.8619, -0.4229],\n",
      "        [ 0.3745,  0.4795, -1.0420],\n",
      "        [-1.7794, -0.0788,  1.2069],\n",
      "        [-0.0294,  0.4591, -0.9194],\n",
      "        [-1.7717,  0.9341,  0.2690],\n",
      "        [-1.6508,  0.3429,  1.0282],\n",
      "        [-1.4407,  1.9834, -0.4440],\n",
      "        [-1.8413,  0.1124,  1.2972],\n",
      "        [-1.6353,  2.0659, -0.5176],\n",
      "        [-0.7281,  1.1605, -0.4750],\n",
      "        [-1.7183,  2.0978, -0.5473],\n",
      "        [-1.4878,  1.5330, -0.1593],\n",
      "        [-1.6564,  2.0000, -0.3361],\n",
      "        [-1.5350,  0.2063,  1.3498],\n",
      "        [-1.7023,  1.9929, -0.3875]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3268,  0.4995, -1.1391],\n",
      "        [-1.8351,  0.0069,  1.2039],\n",
      "        [-1.9394,  1.4339,  0.3483],\n",
      "        [ 0.4293,  0.3908, -1.2064],\n",
      "        [-1.1238,  0.1451,  0.5848],\n",
      "        [-1.9124,  1.0508,  0.5804],\n",
      "        [-1.5362,  1.4065,  0.0348],\n",
      "        [-1.7427,  2.0852, -0.2102],\n",
      "        [-1.6514,  2.0050, -0.4907],\n",
      "        [-1.9576,  1.0869,  0.4012],\n",
      "        [-1.5804,  0.1312,  1.2399],\n",
      "        [-1.8895,  1.3702,  0.1606],\n",
      "        [ 0.3761,  0.4053, -1.3211],\n",
      "        [-1.4869,  1.6654, -0.3208],\n",
      "        [ 0.3916,  0.3057, -1.1212],\n",
      "        [-1.4866,  1.7664, -0.4643]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.3268,  0.4995, -1.1391],\n",
      "        [-1.8351,  0.0069,  1.2039],\n",
      "        [-1.9394,  1.4339,  0.3483],\n",
      "        [ 0.4293,  0.3908, -1.2064],\n",
      "        [-1.1238,  0.1451,  0.5848],\n",
      "        [-1.9124,  1.0508,  0.5804],\n",
      "        [-1.5362,  1.4065,  0.0348],\n",
      "        [-1.7427,  2.0852, -0.2102],\n",
      "        [-1.6514,  2.0050, -0.4907],\n",
      "        [-1.9576,  1.0869,  0.4012],\n",
      "        [-1.5804,  0.1312,  1.2399],\n",
      "        [-1.8895,  1.3702,  0.1606],\n",
      "        [ 0.3761,  0.4053, -1.3211],\n",
      "        [-1.4869,  1.6654, -0.3208],\n",
      "        [ 0.3916,  0.3057, -1.1212],\n",
      "        [-1.4866,  1.7664, -0.4643]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.4618,  0.2711, -1.2033],\n",
      "        [ 0.0656,  0.7318, -1.2364],\n",
      "        [-1.8276,  0.3257,  1.5009],\n",
      "        [-1.4061,  1.6870, -0.5433],\n",
      "        [-1.7186,  0.0960,  1.3970],\n",
      "        [-1.6558,  1.7715, -0.0954],\n",
      "        [-1.5053,  0.2717,  1.0541],\n",
      "        [-1.7960,  1.6246, -0.0025],\n",
      "        [-1.7196,  0.3246,  1.0859],\n",
      "        [-1.7400,  1.9606, -0.6798],\n",
      "        [-1.6387,  0.9039,  0.3892],\n",
      "        [-1.7625,  2.1095, -0.4555],\n",
      "        [-1.7633,  0.4569,  0.8263],\n",
      "        [-1.4292,  1.7330, -0.2070],\n",
      "        [-1.7531,  0.5397,  1.1362],\n",
      "        [-1.4066,  1.8334, -0.7235]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.4618,  0.2711, -1.2033],\n",
      "        [ 0.0656,  0.7318, -1.2364],\n",
      "        [-1.8276,  0.3257,  1.5009],\n",
      "        [-1.4061,  1.6870, -0.5433],\n",
      "        [-1.7186,  0.0960,  1.3970],\n",
      "        [-1.6558,  1.7715, -0.0954],\n",
      "        [-1.5053,  0.2717,  1.0541],\n",
      "        [-1.7960,  1.6246, -0.0025],\n",
      "        [-1.7196,  0.3246,  1.0859],\n",
      "        [-1.7400,  1.9606, -0.6798],\n",
      "        [-1.6387,  0.9039,  0.3892],\n",
      "        [-1.7625,  2.1095, -0.4555],\n",
      "        [-1.7633,  0.4569,  0.8263],\n",
      "        [-1.4292,  1.7330, -0.2070],\n",
      "        [-1.7531,  0.5397,  1.1362],\n",
      "        [-1.4066,  1.8334, -0.7235]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3332,  0.3996, -1.2178],\n",
      "        [-1.3170,  1.6801, -0.5940],\n",
      "        [-1.6009,  1.8679, -0.5332],\n",
      "        [-1.6233,  0.8114,  0.8550],\n",
      "        [-1.7701,  2.1166, -0.5588],\n",
      "        [-1.7558,  1.7748, -0.0676],\n",
      "        [-1.7828,  0.0427,  1.5107],\n",
      "        [-1.5031,  1.6432, -0.4736],\n",
      "        [-1.8377,  0.1331,  1.2141],\n",
      "        [-1.7836,  1.6418, -0.1155],\n",
      "        [-1.6888,  1.9668, -0.5007],\n",
      "        [-1.6967, -0.0426,  1.3690],\n",
      "        [-1.5707,  0.3616,  0.8760],\n",
      "        [ 0.5618,  0.3189, -1.3209],\n",
      "        [-1.7482,  0.3832,  1.1861],\n",
      "        [-1.7737,  1.7628, -0.2543]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.3332,  0.3996, -1.2178],\n",
      "        [-1.3170,  1.6801, -0.5940],\n",
      "        [-1.6009,  1.8679, -0.5332],\n",
      "        [-1.6233,  0.8114,  0.8550],\n",
      "        [-1.7701,  2.1166, -0.5588],\n",
      "        [-1.7558,  1.7748, -0.0676],\n",
      "        [-1.7828,  0.0427,  1.5107],\n",
      "        [-1.5031,  1.6432, -0.4736],\n",
      "        [-1.8377,  0.1331,  1.2141],\n",
      "        [-1.7836,  1.6418, -0.1155],\n",
      "        [-1.6888,  1.9668, -0.5007],\n",
      "        [-1.6967, -0.0426,  1.3690],\n",
      "        [-1.5707,  0.3616,  0.8760],\n",
      "        [ 0.5618,  0.3189, -1.3209],\n",
      "        [-1.7482,  0.3832,  1.1861],\n",
      "        [-1.7737,  1.7628, -0.2543]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5296,  0.2119, -1.1879],\n",
      "        [-1.5975,  2.0142, -0.5254],\n",
      "        [-1.6831,  0.6012,  0.9468],\n",
      "        [-1.5535,  1.9735, -0.3223],\n",
      "        [-1.5850,  1.9472, -0.3468],\n",
      "        [-1.7444,  2.0428, -0.4787],\n",
      "        [-1.6131,  1.8681, -0.5985],\n",
      "        [-1.4223,  1.7962, -0.5601],\n",
      "        [-1.6250,  1.1963,  0.3523],\n",
      "        [-1.2185,  0.2143,  0.8481],\n",
      "        [-1.7560,  1.7918, -0.5102],\n",
      "        [-1.3069,  1.5724, -0.4184],\n",
      "        [ 0.4152,  0.3225, -1.1918],\n",
      "        [-1.5949,  2.0721, -0.4511],\n",
      "        [-1.5583,  2.0117, -0.4593],\n",
      "        [-1.2694,  0.5390,  0.5780]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.5296,  0.2119, -1.1879],\n",
      "        [-1.5975,  2.0142, -0.5254],\n",
      "        [-1.6831,  0.6012,  0.9468],\n",
      "        [-1.5535,  1.9735, -0.3223],\n",
      "        [-1.5850,  1.9472, -0.3468],\n",
      "        [-1.7444,  2.0428, -0.4787],\n",
      "        [-1.6131,  1.8681, -0.5985],\n",
      "        [-1.4223,  1.7962, -0.5601],\n",
      "        [-1.6250,  1.1963,  0.3523],\n",
      "        [-1.2185,  0.2143,  0.8481],\n",
      "        [-1.7560,  1.7918, -0.5102],\n",
      "        [-1.3069,  1.5724, -0.4184],\n",
      "        [ 0.4152,  0.3225, -1.1918],\n",
      "        [-1.5949,  2.0721, -0.4511],\n",
      "        [-1.5583,  2.0117, -0.4593],\n",
      "        [-1.2694,  0.5390,  0.5780]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0455,  1.7517, -0.1057],\n",
      "        [-1.3567,  0.3624,  0.6882],\n",
      "        [-1.7377,  1.5535, -0.0970],\n",
      "        [-1.5010,  1.7754, -0.5566],\n",
      "        [-1.5834,  0.0954,  1.0683],\n",
      "        [-1.2902,  1.6895, -0.7779],\n",
      "        [-1.6051,  0.2689,  1.2094],\n",
      "        [-1.4664,  1.7624, -0.4038],\n",
      "        [ 0.4325,  0.1185, -1.0598],\n",
      "        [-1.4583, -0.1061,  1.6323],\n",
      "        [-1.5830,  1.4911,  0.1335],\n",
      "        [-1.5047,  0.2328,  1.2433],\n",
      "        [-1.4471,  1.5972, -0.4202],\n",
      "        [-1.5451,  0.6308,  0.9527],\n",
      "        [ 0.3257,  0.3478, -1.0497],\n",
      "        [ 0.4359,  0.0788, -1.2347]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.0455,  1.7517, -0.1057],\n",
      "        [-1.3567,  0.3624,  0.6882],\n",
      "        [-1.7377,  1.5535, -0.0970],\n",
      "        [-1.5010,  1.7754, -0.5566],\n",
      "        [-1.5834,  0.0954,  1.0683],\n",
      "        [-1.2902,  1.6895, -0.7779],\n",
      "        [-1.6051,  0.2689,  1.2094],\n",
      "        [-1.4664,  1.7624, -0.4038],\n",
      "        [ 0.4325,  0.1185, -1.0598],\n",
      "        [-1.4583, -0.1061,  1.6323],\n",
      "        [-1.5830,  1.4911,  0.1335],\n",
      "        [-1.5047,  0.2328,  1.2433],\n",
      "        [-1.4471,  1.5972, -0.4202],\n",
      "        [-1.5451,  0.6308,  0.9527],\n",
      "        [ 0.3257,  0.3478, -1.0497],\n",
      "        [ 0.4359,  0.0788, -1.2347]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6172,  0.1944,  1.2180],\n",
      "        [ 0.4446,  0.1177, -1.1033],\n",
      "        [-1.8686,  1.7087, -0.0927],\n",
      "        [-1.4338,  1.4766, -0.3710],\n",
      "        [-0.2094, -0.0071, -0.1716],\n",
      "        [-1.9076,  1.1429,  0.4563],\n",
      "        [ 0.4066,  0.2254, -1.0137],\n",
      "        [-1.3551,  1.8189, -0.8570],\n",
      "        [-1.5505,  0.6173,  0.8632],\n",
      "        [-1.5619,  0.5465,  0.8732],\n",
      "        [-1.4881, -0.0376,  1.4196],\n",
      "        [-0.1925,  0.6817, -1.1089],\n",
      "        [-1.4331,  1.5646, -0.5353],\n",
      "        [-1.4192,  0.2314,  1.1404],\n",
      "        [ 0.3664,  0.3409, -1.0644],\n",
      "        [ 0.4407,  0.2537, -1.2345]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6172,  0.1944,  1.2180],\n",
      "        [ 0.4446,  0.1177, -1.1033],\n",
      "        [-1.8686,  1.7087, -0.0927],\n",
      "        [-1.4338,  1.4766, -0.3710],\n",
      "        [-0.2094, -0.0071, -0.1716],\n",
      "        [-1.9076,  1.1429,  0.4563],\n",
      "        [ 0.4066,  0.2254, -1.0137],\n",
      "        [-1.3551,  1.8189, -0.8570],\n",
      "        [-1.5505,  0.6173,  0.8632],\n",
      "        [-1.5619,  0.5465,  0.8732],\n",
      "        [-1.4881, -0.0376,  1.4196],\n",
      "        [-0.1925,  0.6817, -1.1089],\n",
      "        [-1.4331,  1.5646, -0.5353],\n",
      "        [-1.4192,  0.2314,  1.1404],\n",
      "        [ 0.3664,  0.3409, -1.0644],\n",
      "        [ 0.4407,  0.2537, -1.2345]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5480e+00,  8.0399e-02,  1.2795e+00],\n",
      "        [-1.3190e+00,  1.7067e+00, -6.6505e-01],\n",
      "        [-1.5539e+00, -1.3599e-05,  1.3107e+00],\n",
      "        [-1.5152e+00,  1.8256e+00, -4.0869e-01],\n",
      "        [-1.5138e+00,  1.7773e+00, -9.8601e-02],\n",
      "        [-1.1009e+00,  9.0198e-01,  3.6408e-01],\n",
      "        [-1.4788e+00,  1.3133e-01,  1.0347e+00],\n",
      "        [-1.5636e+00,  1.8608e+00, -3.1653e-01],\n",
      "        [-1.5647e+00,  1.9193e+00, -4.9791e-01],\n",
      "        [-1.6009e+00,  4.4207e-01,  1.0252e+00],\n",
      "        [-1.5083e+00,  2.7256e-02,  1.4077e+00],\n",
      "        [-1.5195e+00,  3.6334e-02,  1.3258e+00],\n",
      "        [-1.3169e+00,  1.9627e+00, -5.6433e-01],\n",
      "        [-1.3254e+00,  6.7057e-01,  5.2465e-01],\n",
      "        [-1.7249e+00,  4.0823e-01,  1.1774e+00],\n",
      "        [ 3.0789e-01,  3.3249e-01, -9.0281e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5480e+00,  8.0399e-02,  1.2795e+00],\n",
      "        [-1.3190e+00,  1.7067e+00, -6.6505e-01],\n",
      "        [-1.5539e+00, -1.3599e-05,  1.3107e+00],\n",
      "        [-1.5152e+00,  1.8256e+00, -4.0869e-01],\n",
      "        [-1.5138e+00,  1.7773e+00, -9.8601e-02],\n",
      "        [-1.1009e+00,  9.0198e-01,  3.6408e-01],\n",
      "        [-1.4788e+00,  1.3133e-01,  1.0347e+00],\n",
      "        [-1.5636e+00,  1.8608e+00, -3.1653e-01],\n",
      "        [-1.5647e+00,  1.9193e+00, -4.9791e-01],\n",
      "        [-1.6009e+00,  4.4207e-01,  1.0252e+00],\n",
      "        [-1.5083e+00,  2.7256e-02,  1.4077e+00],\n",
      "        [-1.5195e+00,  3.6334e-02,  1.3258e+00],\n",
      "        [-1.3169e+00,  1.9627e+00, -5.6433e-01],\n",
      "        [-1.3254e+00,  6.7057e-01,  5.2465e-01],\n",
      "        [-1.7249e+00,  4.0823e-01,  1.1774e+00],\n",
      "        [ 3.0789e-01,  3.3249e-01, -9.0281e-01]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6022, -0.0079,  1.2913],\n",
      "        [-1.6367,  0.5067,  1.2925],\n",
      "        [-1.7108,  0.0741,  1.5814],\n",
      "        [-1.2131,  1.7320, -0.4419],\n",
      "        [-1.5802,  1.5819,  0.1510],\n",
      "        [-1.2447,  0.9315, -0.0026],\n",
      "        [-1.5440, -0.0329,  1.1443],\n",
      "        [ 0.4988,  0.1312, -1.0523],\n",
      "        [-1.5362,  1.8466, -0.5458],\n",
      "        [ 0.2623,  0.1479, -1.0326],\n",
      "        [-1.5438,  1.9437, -0.5595],\n",
      "        [-1.9753,  0.2002,  1.3399],\n",
      "        [-1.5707, -0.0166,  1.3200],\n",
      "        [-1.5164,  0.4713,  0.7562],\n",
      "        [-1.4777,  1.3952, -0.5793],\n",
      "        [-1.5926,  0.0746,  1.4086]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6022, -0.0079,  1.2913],\n",
      "        [-1.6367,  0.5067,  1.2925],\n",
      "        [-1.7108,  0.0741,  1.5814],\n",
      "        [-1.2131,  1.7320, -0.4419],\n",
      "        [-1.5802,  1.5819,  0.1510],\n",
      "        [-1.2447,  0.9315, -0.0026],\n",
      "        [-1.5440, -0.0329,  1.1443],\n",
      "        [ 0.4988,  0.1312, -1.0523],\n",
      "        [-1.5362,  1.8466, -0.5458],\n",
      "        [ 0.2623,  0.1479, -1.0326],\n",
      "        [-1.5438,  1.9437, -0.5595],\n",
      "        [-1.9753,  0.2002,  1.3399],\n",
      "        [-1.5707, -0.0166,  1.3200],\n",
      "        [-1.5164,  0.4713,  0.7562],\n",
      "        [-1.4777,  1.3952, -0.5793],\n",
      "        [-1.5926,  0.0746,  1.4086]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4864,  1.5780, -0.2805],\n",
      "        [-1.4768,  1.7481, -0.1462],\n",
      "        [ 0.5578,  0.2706, -1.0826],\n",
      "        [-1.2333,  1.2709,  0.1100],\n",
      "        [-0.9817,  0.4337,  0.4984],\n",
      "        [-1.4584,  1.4617,  0.1032],\n",
      "        [-1.6388, -0.0541,  1.1293],\n",
      "        [-1.6030,  1.1728,  0.4252],\n",
      "        [-1.6858,  0.7465,  0.4658],\n",
      "        [-1.3282,  1.4717, -0.1853],\n",
      "        [ 0.2255,  0.1354, -0.9134],\n",
      "        [-1.4001,  1.6662, -0.5434],\n",
      "        [-1.5070,  0.2024,  1.3587],\n",
      "        [-1.4015,  1.6788, -0.2746],\n",
      "        [-1.5008,  1.5120, -0.4240],\n",
      "        [ 0.3393,  0.1116, -0.7732]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4864,  1.5780, -0.2805],\n",
      "        [-1.4768,  1.7481, -0.1462],\n",
      "        [ 0.5578,  0.2706, -1.0826],\n",
      "        [-1.2333,  1.2709,  0.1100],\n",
      "        [-0.9817,  0.4337,  0.4984],\n",
      "        [-1.4584,  1.4617,  0.1032],\n",
      "        [-1.6388, -0.0541,  1.1293],\n",
      "        [-1.6030,  1.1728,  0.4252],\n",
      "        [-1.6858,  0.7465,  0.4658],\n",
      "        [-1.3282,  1.4717, -0.1853],\n",
      "        [ 0.2255,  0.1354, -0.9134],\n",
      "        [-1.4001,  1.6662, -0.5434],\n",
      "        [-1.5070,  0.2024,  1.3587],\n",
      "        [-1.4015,  1.6788, -0.2746],\n",
      "        [-1.5008,  1.5120, -0.4240],\n",
      "        [ 0.3393,  0.1116, -0.7732]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3203,  0.1427,  1.3337],\n",
      "        [-1.7396,  0.3815,  1.1404],\n",
      "        [ 0.5136,  0.2786, -1.2197],\n",
      "        [-1.6912,  0.2618,  1.0688],\n",
      "        [-1.0565,  1.3968, -0.1228],\n",
      "        [-1.5587,  1.9296, -0.4756],\n",
      "        [-1.5210,  1.3617,  0.1213],\n",
      "        [-1.5286,  0.9792,  0.2246],\n",
      "        [-1.6613,  0.8485,  0.6723],\n",
      "        [-1.0946,  1.4610, -0.1646],\n",
      "        [-0.8187,  1.4076, -1.1329],\n",
      "        [-1.4674,  1.7325, -0.7461],\n",
      "        [-1.1103,  1.3574, -0.5478],\n",
      "        [ 0.5368,  0.1302, -1.2082],\n",
      "        [-1.4583,  1.0972,  0.2062],\n",
      "        [-1.4884,  0.2517,  1.1783]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3203,  0.1427,  1.3337],\n",
      "        [-1.7396,  0.3815,  1.1404],\n",
      "        [ 0.5136,  0.2786, -1.2197],\n",
      "        [-1.6912,  0.2618,  1.0688],\n",
      "        [-1.0565,  1.3968, -0.1228],\n",
      "        [-1.5587,  1.9296, -0.4756],\n",
      "        [-1.5210,  1.3617,  0.1213],\n",
      "        [-1.5286,  0.9792,  0.2246],\n",
      "        [-1.6613,  0.8485,  0.6723],\n",
      "        [-1.0946,  1.4610, -0.1646],\n",
      "        [-0.8187,  1.4076, -1.1329],\n",
      "        [-1.4674,  1.7325, -0.7461],\n",
      "        [-1.1103,  1.3574, -0.5478],\n",
      "        [ 0.5368,  0.1302, -1.2082],\n",
      "        [-1.4583,  1.0972,  0.2062],\n",
      "        [-1.4884,  0.2517,  1.1783]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5833,  1.4680, -0.2106],\n",
      "        [-1.4256,  1.7487, -0.3193],\n",
      "        [-1.2177,  1.6745, -0.4403],\n",
      "        [-1.5692,  1.6454, -0.2117],\n",
      "        [-1.0790,  1.6855, -0.4410],\n",
      "        [-1.4926,  1.1514,  0.2438],\n",
      "        [-1.3616,  1.6332, -0.3906],\n",
      "        [-1.1601,  1.2425, -0.1504],\n",
      "        [-1.5607,  1.3860, -0.1479],\n",
      "        [-1.2913,  1.9167, -0.6567],\n",
      "        [-0.6328,  0.7750, -0.4580],\n",
      "        [-1.1937,  1.5183, -0.4768],\n",
      "        [ 0.4622,  0.0805, -1.0238],\n",
      "        [-1.1215,  1.5936, -0.6052],\n",
      "        [-1.4579,  1.1679,  0.0485],\n",
      "        [-0.8252,  0.2151,  0.3894]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5833,  1.4680, -0.2106],\n",
      "        [-1.4256,  1.7487, -0.3193],\n",
      "        [-1.2177,  1.6745, -0.4403],\n",
      "        [-1.5692,  1.6454, -0.2117],\n",
      "        [-1.0790,  1.6855, -0.4410],\n",
      "        [-1.4926,  1.1514,  0.2438],\n",
      "        [-1.3616,  1.6332, -0.3906],\n",
      "        [-1.1601,  1.2425, -0.1504],\n",
      "        [-1.5607,  1.3860, -0.1479],\n",
      "        [-1.2913,  1.9167, -0.6567],\n",
      "        [-0.6328,  0.7750, -0.4580],\n",
      "        [-1.1937,  1.5183, -0.4768],\n",
      "        [ 0.4622,  0.0805, -1.0238],\n",
      "        [-1.1215,  1.5936, -0.6052],\n",
      "        [-1.4579,  1.1679,  0.0485],\n",
      "        [-0.8252,  0.2151,  0.3894]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5827,  0.1849,  1.1541],\n",
      "        [-1.6367,  1.2797,  0.0827],\n",
      "        [-1.7756,  0.9557,  0.6747],\n",
      "        [-1.5162,  0.5767,  0.9104],\n",
      "        [-1.3976,  1.9745, -0.4387],\n",
      "        [ 0.3150,  0.1986, -1.0103],\n",
      "        [-1.6373,  0.2782,  1.1819],\n",
      "        [-1.6005,  1.0687,  0.5281],\n",
      "        [-1.2609,  0.4586,  0.8847],\n",
      "        [-1.4543,  1.7025, -0.3051],\n",
      "        [-1.1837,  1.6218, -0.2445],\n",
      "        [-1.2730,  1.6702, -0.4491],\n",
      "        [-1.5974,  0.5388,  0.9425],\n",
      "        [ 0.3395,  0.1522, -0.8918],\n",
      "        [ 0.3780,  0.2085, -1.1187],\n",
      "        [-1.6624,  1.7238, -0.5187]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5827,  0.1849,  1.1541],\n",
      "        [-1.6367,  1.2797,  0.0827],\n",
      "        [-1.7756,  0.9557,  0.6747],\n",
      "        [-1.5162,  0.5767,  0.9104],\n",
      "        [-1.3976,  1.9745, -0.4387],\n",
      "        [ 0.3150,  0.1986, -1.0103],\n",
      "        [-1.6373,  0.2782,  1.1819],\n",
      "        [-1.6005,  1.0687,  0.5281],\n",
      "        [-1.2609,  0.4586,  0.8847],\n",
      "        [-1.4543,  1.7025, -0.3051],\n",
      "        [-1.1837,  1.6218, -0.2445],\n",
      "        [-1.2730,  1.6702, -0.4491],\n",
      "        [-1.5974,  0.5388,  0.9425],\n",
      "        [ 0.3395,  0.1522, -0.8918],\n",
      "        [ 0.3780,  0.2085, -1.1187],\n",
      "        [-1.6624,  1.7238, -0.5187]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5443,  0.7098,  0.7279],\n",
      "        [-1.5644,  1.6453, -0.3897],\n",
      "        [-1.1719,  1.9052, -0.9764],\n",
      "        [-1.4623,  1.7206, -0.3246],\n",
      "        [-1.5340,  0.7417,  0.7935],\n",
      "        [-1.3447,  1.9009, -0.6701],\n",
      "        [ 0.3399,  0.1703, -1.0889],\n",
      "        [-0.7518,  0.2519,  0.3901],\n",
      "        [-1.7728,  0.5606,  0.9677],\n",
      "        [ 0.0341,  0.2259, -0.8335],\n",
      "        [-1.5179,  1.9629, -0.3948],\n",
      "        [-1.6597, -0.0455,  1.4703],\n",
      "        [ 0.4389,  0.1132, -1.0524],\n",
      "        [-1.7490,  0.4655,  1.2511],\n",
      "        [-1.0089,  1.2969, -0.1093],\n",
      "        [-1.6822,  1.0537,  0.3305]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5443,  0.7098,  0.7279],\n",
      "        [-1.5644,  1.6453, -0.3897],\n",
      "        [-1.1719,  1.9052, -0.9764],\n",
      "        [-1.4623,  1.7206, -0.3246],\n",
      "        [-1.5340,  0.7417,  0.7935],\n",
      "        [-1.3447,  1.9009, -0.6701],\n",
      "        [ 0.3399,  0.1703, -1.0889],\n",
      "        [-0.7518,  0.2519,  0.3901],\n",
      "        [-1.7728,  0.5606,  0.9677],\n",
      "        [ 0.0341,  0.2259, -0.8335],\n",
      "        [-1.5179,  1.9629, -0.3948],\n",
      "        [-1.6597, -0.0455,  1.4703],\n",
      "        [ 0.4389,  0.1132, -1.0524],\n",
      "        [-1.7490,  0.4655,  1.2511],\n",
      "        [-1.0089,  1.2969, -0.1093],\n",
      "        [-1.6822,  1.0537,  0.3305]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5890,  1.9627, -0.2472],\n",
      "        [-1.2382,  1.4711, -0.6534],\n",
      "        [-1.3771,  1.5748, -0.5175],\n",
      "        [-1.4408,  1.0709,  0.2810],\n",
      "        [-1.5839,  0.2799,  1.0577],\n",
      "        [ 0.4732,  0.0232, -0.8018],\n",
      "        [-1.4254,  1.3427,  0.4882],\n",
      "        [-1.4108,  1.4401, -0.4915],\n",
      "        [ 0.3421,  0.0511, -0.8899],\n",
      "        [-1.4470,  0.2870,  1.0769],\n",
      "        [-1.5868,  1.3840, -0.1240],\n",
      "        [-1.6362,  1.4431, -0.0484],\n",
      "        [-1.0194,  1.5556, -0.8286],\n",
      "        [-1.6612,  1.3340,  0.2443],\n",
      "        [-1.6065,  1.8767, -0.3361],\n",
      "        [-1.3890,  1.8883, -0.3494]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5890,  1.9627, -0.2472],\n",
      "        [-1.2382,  1.4711, -0.6534],\n",
      "        [-1.3771,  1.5748, -0.5175],\n",
      "        [-1.4408,  1.0709,  0.2810],\n",
      "        [-1.5839,  0.2799,  1.0577],\n",
      "        [ 0.4732,  0.0232, -0.8018],\n",
      "        [-1.4254,  1.3427,  0.4882],\n",
      "        [-1.4108,  1.4401, -0.4915],\n",
      "        [ 0.3421,  0.0511, -0.8899],\n",
      "        [-1.4470,  0.2870,  1.0769],\n",
      "        [-1.5868,  1.3840, -0.1240],\n",
      "        [-1.6362,  1.4431, -0.0484],\n",
      "        [-1.0194,  1.5556, -0.8286],\n",
      "        [-1.6612,  1.3340,  0.2443],\n",
      "        [-1.6065,  1.8767, -0.3361],\n",
      "        [-1.3890,  1.8883, -0.3494]], grad_fn=<AddmmBackward0>)\n",
      "Epoch 1/3, Loss: 0.6177\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4485,  2.0752, -0.7274],\n",
      "        [-0.5155,  0.4191, -0.3043],\n",
      "        [-1.7204,  0.2690,  1.0380],\n",
      "        [-1.5407,  1.8707, -0.5008],\n",
      "        [-1.3855,  1.9309, -0.7021],\n",
      "        [-1.7423,  1.1646,  0.6149],\n",
      "        [ 0.5511,  0.0591, -1.0089],\n",
      "        [-1.7006,  1.9496, -0.3070],\n",
      "        [-1.5253,  1.7423, -0.2981],\n",
      "        [-1.5178,  1.6330, -0.2278],\n",
      "        [-1.5899,  1.3149,  0.2426],\n",
      "        [-1.4200,  0.5173,  1.1284],\n",
      "        [-1.5881,  1.8861, -0.4367],\n",
      "        [-1.4559,  0.4416,  0.8990],\n",
      "        [-0.4859,  0.1893,  0.0196],\n",
      "        [-1.7676,  1.8937, -0.2291]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4485,  2.0752, -0.7274],\n",
      "        [-0.5155,  0.4191, -0.3043],\n",
      "        [-1.7204,  0.2690,  1.0380],\n",
      "        [-1.5407,  1.8707, -0.5008],\n",
      "        [-1.3855,  1.9309, -0.7021],\n",
      "        [-1.7423,  1.1646,  0.6149],\n",
      "        [ 0.5511,  0.0591, -1.0089],\n",
      "        [-1.7006,  1.9496, -0.3070],\n",
      "        [-1.5253,  1.7423, -0.2981],\n",
      "        [-1.5178,  1.6330, -0.2278],\n",
      "        [-1.5899,  1.3149,  0.2426],\n",
      "        [-1.4200,  0.5173,  1.1284],\n",
      "        [-1.5881,  1.8861, -0.4367],\n",
      "        [-1.4559,  0.4416,  0.8990],\n",
      "        [-0.4859,  0.1893,  0.0196],\n",
      "        [-1.7676,  1.8937, -0.2291]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3878,  1.9606, -0.5221],\n",
      "        [-1.5723,  2.0585, -0.5577],\n",
      "        [-1.5952,  2.1116, -0.9646],\n",
      "        [-1.6014,  0.3774,  1.0650],\n",
      "        [-1.6391,  1.9252, -0.6249],\n",
      "        [-1.5581,  1.2263, -0.0059],\n",
      "        [-1.7241,  1.7379, -0.2880],\n",
      "        [-1.3670,  0.1675,  0.7775],\n",
      "        [-1.4339,  1.2548, -0.0682],\n",
      "        [ 0.4632, -0.0036, -0.9866],\n",
      "        [-1.5142,  1.5252, -0.2293],\n",
      "        [-1.5025,  2.0399, -0.4948],\n",
      "        [-1.6709,  1.7396, -0.0709],\n",
      "        [-1.2930,  0.4555,  0.5473],\n",
      "        [-1.4573,  0.4275,  0.8730],\n",
      "        [-1.3231,  0.2192,  0.9791]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3878,  1.9606, -0.5221],\n",
      "        [-1.5723,  2.0585, -0.5577],\n",
      "        [-1.5952,  2.1116, -0.9646],\n",
      "        [-1.6014,  0.3774,  1.0650],\n",
      "        [-1.6391,  1.9252, -0.6249],\n",
      "        [-1.5581,  1.2263, -0.0059],\n",
      "        [-1.7241,  1.7379, -0.2880],\n",
      "        [-1.3670,  0.1675,  0.7775],\n",
      "        [-1.4339,  1.2548, -0.0682],\n",
      "        [ 0.4632, -0.0036, -0.9866],\n",
      "        [-1.5142,  1.5252, -0.2293],\n",
      "        [-1.5025,  2.0399, -0.4948],\n",
      "        [-1.6709,  1.7396, -0.0709],\n",
      "        [-1.2930,  0.4555,  0.5473],\n",
      "        [-1.4573,  0.4275,  0.8730],\n",
      "        [-1.3231,  0.2192,  0.9791]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.1115,  1.5779, -0.6552],\n",
      "        [-1.5399,  1.8953, -0.3126],\n",
      "        [-1.5924,  1.8661, -0.0861],\n",
      "        [-1.5598,  1.8385, -0.4715],\n",
      "        [-1.7561,  0.8326,  0.7716],\n",
      "        [-1.7700,  0.4009,  1.1007],\n",
      "        [-1.7324,  0.5962,  0.8682],\n",
      "        [-1.6923,  0.4239,  1.1498],\n",
      "        [-1.6057,  1.9345, -0.7065],\n",
      "        [-1.4868,  0.8626,  0.3693],\n",
      "        [-1.2918,  1.7831, -0.5148],\n",
      "        [-1.7047,  1.7670, -0.1164],\n",
      "        [-1.4672,  0.3545,  1.0483],\n",
      "        [-1.2849,  1.4194, -0.3947],\n",
      "        [-1.5660,  0.3418,  0.9423],\n",
      "        [-1.6155,  0.6555,  1.1066]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.1115,  1.5779, -0.6552],\n",
      "        [-1.5399,  1.8953, -0.3126],\n",
      "        [-1.5924,  1.8661, -0.0861],\n",
      "        [-1.5598,  1.8385, -0.4715],\n",
      "        [-1.7561,  0.8326,  0.7716],\n",
      "        [-1.7700,  0.4009,  1.1007],\n",
      "        [-1.7324,  0.5962,  0.8682],\n",
      "        [-1.6923,  0.4239,  1.1498],\n",
      "        [-1.6057,  1.9345, -0.7065],\n",
      "        [-1.4868,  0.8626,  0.3693],\n",
      "        [-1.2918,  1.7831, -0.5148],\n",
      "        [-1.7047,  1.7670, -0.1164],\n",
      "        [-1.4672,  0.3545,  1.0483],\n",
      "        [-1.2849,  1.4194, -0.3947],\n",
      "        [-1.5660,  0.3418,  0.9423],\n",
      "        [-1.6155,  0.6555,  1.1066]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5593,  0.2843,  1.1484],\n",
      "        [-1.3850,  1.8727, -0.5840],\n",
      "        [-1.5304,  1.4264, -0.2573],\n",
      "        [-1.6775,  0.5830,  0.9966],\n",
      "        [-1.3580,  0.2842,  0.8110],\n",
      "        [ 0.3878,  0.0156, -1.0252],\n",
      "        [-1.5380,  1.8718, -0.2135],\n",
      "        [ 0.3107,  0.1543, -0.9282],\n",
      "        [-1.6730,  0.0942,  1.2986],\n",
      "        [-1.5033,  1.7717, -0.3517],\n",
      "        [-1.4022,  1.9869, -0.4783],\n",
      "        [-1.4801,  0.5605,  0.5590],\n",
      "        [-1.6711,  2.2582, -0.5488],\n",
      "        [-1.4757,  1.9766, -0.4140],\n",
      "        [-1.1789,  1.5351, -0.4388],\n",
      "        [-1.6154,  1.1828,  0.5317]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5593,  0.2843,  1.1484],\n",
      "        [-1.3850,  1.8727, -0.5840],\n",
      "        [-1.5304,  1.4264, -0.2573],\n",
      "        [-1.6775,  0.5830,  0.9966],\n",
      "        [-1.3580,  0.2842,  0.8110],\n",
      "        [ 0.3878,  0.0156, -1.0252],\n",
      "        [-1.5380,  1.8718, -0.2135],\n",
      "        [ 0.3107,  0.1543, -0.9282],\n",
      "        [-1.6730,  0.0942,  1.2986],\n",
      "        [-1.5033,  1.7717, -0.3517],\n",
      "        [-1.4022,  1.9869, -0.4783],\n",
      "        [-1.4801,  0.5605,  0.5590],\n",
      "        [-1.6711,  2.2582, -0.5488],\n",
      "        [-1.4757,  1.9766, -0.4140],\n",
      "        [-1.1789,  1.5351, -0.4388],\n",
      "        [-1.6154,  1.1828,  0.5317]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5205,  1.4853, -0.1467],\n",
      "        [-1.4950,  1.9429, -0.2826],\n",
      "        [-1.5981,  1.8700, -0.3216],\n",
      "        [-1.6286,  0.3489,  1.0298],\n",
      "        [-1.6904,  1.5971,  0.0142],\n",
      "        [-0.4270,  1.0714, -0.9768],\n",
      "        [ 0.5653, -0.1231, -0.8548],\n",
      "        [-1.4456,  1.6981, -0.4948],\n",
      "        [-1.7819,  1.2726,  0.2995],\n",
      "        [-1.7524,  2.1469, -0.4656],\n",
      "        [-1.6668,  1.9996, -0.3360],\n",
      "        [-1.4175,  0.5586,  0.8767],\n",
      "        [-1.2851,  1.7211, -0.4697],\n",
      "        [-0.9640,  0.4246,  0.3558],\n",
      "        [ 0.3155,  0.0995, -0.9192],\n",
      "        [-1.7245,  0.9527,  0.5298]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5205,  1.4853, -0.1467],\n",
      "        [-1.4950,  1.9429, -0.2826],\n",
      "        [-1.5981,  1.8700, -0.3216],\n",
      "        [-1.6286,  0.3489,  1.0298],\n",
      "        [-1.6904,  1.5971,  0.0142],\n",
      "        [-0.4270,  1.0714, -0.9768],\n",
      "        [ 0.5653, -0.1231, -0.8548],\n",
      "        [-1.4456,  1.6981, -0.4948],\n",
      "        [-1.7819,  1.2726,  0.2995],\n",
      "        [-1.7524,  2.1469, -0.4656],\n",
      "        [-1.6668,  1.9996, -0.3360],\n",
      "        [-1.4175,  0.5586,  0.8767],\n",
      "        [-1.2851,  1.7211, -0.4697],\n",
      "        [-0.9640,  0.4246,  0.3558],\n",
      "        [ 0.3155,  0.0995, -0.9192],\n",
      "        [-1.7245,  0.9527,  0.5298]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7350,  2.0024, -0.5823],\n",
      "        [-1.7047,  1.7994, -0.0239],\n",
      "        [-0.0208,  0.1432, -0.5033],\n",
      "        [ 0.4618, -0.0585, -0.9501],\n",
      "        [-0.9873,  0.3592,  0.3709],\n",
      "        [-1.8940,  0.4563,  1.0645],\n",
      "        [-1.4819,  1.8777, -0.3691],\n",
      "        [ 0.3855,  0.2402, -0.9408],\n",
      "        [-1.5760,  0.3585,  0.8729],\n",
      "        [-1.4066,  1.1415,  0.6052],\n",
      "        [-1.2735,  1.8023, -0.3911],\n",
      "        [-1.5922,  0.4994,  1.1693],\n",
      "        [ 0.2224,  0.3009, -1.0535],\n",
      "        [ 0.3887,  0.0180, -0.8738],\n",
      "        [-1.5390,  1.9939, -0.4690],\n",
      "        [-1.7676,  0.7212,  0.7845]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7350,  2.0024, -0.5823],\n",
      "        [-1.7047,  1.7994, -0.0239],\n",
      "        [-0.0208,  0.1432, -0.5033],\n",
      "        [ 0.4618, -0.0585, -0.9501],\n",
      "        [-0.9873,  0.3592,  0.3709],\n",
      "        [-1.8940,  0.4563,  1.0645],\n",
      "        [-1.4819,  1.8777, -0.3691],\n",
      "        [ 0.3855,  0.2402, -0.9408],\n",
      "        [-1.5760,  0.3585,  0.8729],\n",
      "        [-1.4066,  1.1415,  0.6052],\n",
      "        [-1.2735,  1.8023, -0.3911],\n",
      "        [-1.5922,  0.4994,  1.1693],\n",
      "        [ 0.2224,  0.3009, -1.0535],\n",
      "        [ 0.3887,  0.0180, -0.8738],\n",
      "        [-1.5390,  1.9939, -0.4690],\n",
      "        [-1.7676,  0.7212,  0.7845]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5800,  2.0931, -0.5048],\n",
      "        [-1.2564,  1.8702, -0.4041],\n",
      "        [-1.4384,  2.3145, -0.6760],\n",
      "        [-1.7901,  1.8990, -0.3479],\n",
      "        [-1.4885,  0.6866,  0.6823],\n",
      "        [-1.5971,  2.0120, -0.4495],\n",
      "        [-1.3430,  1.7421, -0.6463],\n",
      "        [-1.4037,  1.9837, -0.5669],\n",
      "        [-1.5933,  2.1382, -0.5400],\n",
      "        [-0.9778,  1.6387, -0.6988],\n",
      "        [-1.5027,  0.6699,  0.6166],\n",
      "        [-0.0752,  0.7625, -1.1183],\n",
      "        [-1.3007,  1.9486, -0.4322],\n",
      "        [-1.8119,  2.0350, -0.3080],\n",
      "        [-1.6130,  1.7910, -0.3154],\n",
      "        [ 0.5530, -0.1601, -0.9376]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5800,  2.0931, -0.5048],\n",
      "        [-1.2564,  1.8702, -0.4041],\n",
      "        [-1.4384,  2.3145, -0.6760],\n",
      "        [-1.7901,  1.8990, -0.3479],\n",
      "        [-1.4885,  0.6866,  0.6823],\n",
      "        [-1.5971,  2.0120, -0.4495],\n",
      "        [-1.3430,  1.7421, -0.6463],\n",
      "        [-1.4037,  1.9837, -0.5669],\n",
      "        [-1.5933,  2.1382, -0.5400],\n",
      "        [-0.9778,  1.6387, -0.6988],\n",
      "        [-1.5027,  0.6699,  0.6166],\n",
      "        [-0.0752,  0.7625, -1.1183],\n",
      "        [-1.3007,  1.9486, -0.4322],\n",
      "        [-1.8119,  2.0350, -0.3080],\n",
      "        [-1.6130,  1.7910, -0.3154],\n",
      "        [ 0.5530, -0.1601, -0.9376]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7048,  2.2333, -0.5352],\n",
      "        [-1.4017,  1.9627, -0.7903],\n",
      "        [-1.4257,  1.9160, -0.6687],\n",
      "        [-1.4338,  0.4215,  0.9311],\n",
      "        [-1.5569,  0.1093,  1.0928],\n",
      "        [-1.2824,  1.7868, -0.4973],\n",
      "        [-1.5267,  1.8422, -0.4887],\n",
      "        [-0.1602,  0.2169, -0.5604],\n",
      "        [ 0.0395,  0.6294, -1.0896],\n",
      "        [-1.5696,  0.5947,  0.9431],\n",
      "        [-1.5567,  0.5920,  0.7663],\n",
      "        [-1.5645,  2.3186, -0.4542],\n",
      "        [-1.5526,  0.4766,  0.9584],\n",
      "        [-1.5556,  1.0503,  0.4195],\n",
      "        [-1.5668,  0.2828,  0.9736],\n",
      "        [-1.3691,  0.0823,  1.1518]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7048,  2.2333, -0.5352],\n",
      "        [-1.4017,  1.9627, -0.7903],\n",
      "        [-1.4257,  1.9160, -0.6687],\n",
      "        [-1.4338,  0.4215,  0.9311],\n",
      "        [-1.5569,  0.1093,  1.0928],\n",
      "        [-1.2824,  1.7868, -0.4973],\n",
      "        [-1.5267,  1.8422, -0.4887],\n",
      "        [-0.1602,  0.2169, -0.5604],\n",
      "        [ 0.0395,  0.6294, -1.0896],\n",
      "        [-1.5696,  0.5947,  0.9431],\n",
      "        [-1.5567,  0.5920,  0.7663],\n",
      "        [-1.5645,  2.3186, -0.4542],\n",
      "        [-1.5526,  0.4766,  0.9584],\n",
      "        [-1.5556,  1.0503,  0.4195],\n",
      "        [-1.5668,  0.2828,  0.9736],\n",
      "        [-1.3691,  0.0823,  1.1518]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9076,  1.9435, -0.4114],\n",
      "        [-1.6627,  2.0398, -0.7955],\n",
      "        [-1.6634,  2.2645, -0.5654],\n",
      "        [-1.3159,  1.9568, -0.8007],\n",
      "        [ 0.0582,  0.6734, -1.0096],\n",
      "        [-1.7695,  1.9925, -0.7227],\n",
      "        [-1.3448,  2.0557, -0.2952],\n",
      "        [-0.2475,  0.9873, -1.0265],\n",
      "        [-1.7257,  0.6283,  0.9593],\n",
      "        [-1.5160,  2.0958, -0.6030],\n",
      "        [-1.6974,  2.0141, -0.5430],\n",
      "        [-1.5297,  1.8561, -0.5897],\n",
      "        [-1.6270,  1.9051, -0.4281],\n",
      "        [ 0.3101,  0.2424, -0.8375],\n",
      "        [-1.6247,  2.1146, -0.6298],\n",
      "        [-1.5481,  0.1260,  1.1617]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9076,  1.9435, -0.4114],\n",
      "        [-1.6627,  2.0398, -0.7955],\n",
      "        [-1.6634,  2.2645, -0.5654],\n",
      "        [-1.3159,  1.9568, -0.8007],\n",
      "        [ 0.0582,  0.6734, -1.0096],\n",
      "        [-1.7695,  1.9925, -0.7227],\n",
      "        [-1.3448,  2.0557, -0.2952],\n",
      "        [-0.2475,  0.9873, -1.0265],\n",
      "        [-1.7257,  0.6283,  0.9593],\n",
      "        [-1.5160,  2.0958, -0.6030],\n",
      "        [-1.6974,  2.0141, -0.5430],\n",
      "        [-1.5297,  1.8561, -0.5897],\n",
      "        [-1.6270,  1.9051, -0.4281],\n",
      "        [ 0.3101,  0.2424, -0.8375],\n",
      "        [-1.6247,  2.1146, -0.6298],\n",
      "        [-1.5481,  0.1260,  1.1617]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7307,  0.1253,  1.2508],\n",
      "        [-1.5947,  2.0215, -0.4498],\n",
      "        [-1.5863,  0.3703,  1.2194],\n",
      "        [-1.5590,  0.1473,  1.3219],\n",
      "        [-1.6012,  1.9353, -0.4563],\n",
      "        [ 0.3796,  0.1348, -0.9543],\n",
      "        [-1.5414,  0.1378,  0.8923],\n",
      "        [-1.7453,  1.9687, -0.6100],\n",
      "        [ 0.4415, -0.0477, -0.9116],\n",
      "        [-1.3327,  0.1059,  0.9296],\n",
      "        [-1.8142,  2.1961, -0.4565],\n",
      "        [-1.5767,  1.3757,  0.1179],\n",
      "        [-1.4900,  1.9936, -0.5401],\n",
      "        [-1.7545,  0.8928,  0.5924],\n",
      "        [-1.4762,  0.2997,  1.1875],\n",
      "        [-1.4209,  2.1333, -0.5005]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7307,  0.1253,  1.2508],\n",
      "        [-1.5947,  2.0215, -0.4498],\n",
      "        [-1.5863,  0.3703,  1.2194],\n",
      "        [-1.5590,  0.1473,  1.3219],\n",
      "        [-1.6012,  1.9353, -0.4563],\n",
      "        [ 0.3796,  0.1348, -0.9543],\n",
      "        [-1.5414,  0.1378,  0.8923],\n",
      "        [-1.7453,  1.9687, -0.6100],\n",
      "        [ 0.4415, -0.0477, -0.9116],\n",
      "        [-1.3327,  0.1059,  0.9296],\n",
      "        [-1.8142,  2.1961, -0.4565],\n",
      "        [-1.5767,  1.3757,  0.1179],\n",
      "        [-1.4900,  1.9936, -0.5401],\n",
      "        [-1.7545,  0.8928,  0.5924],\n",
      "        [-1.4762,  0.2997,  1.1875],\n",
      "        [-1.4209,  2.1333, -0.5005]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8332,  0.3511,  1.3822],\n",
      "        [-1.5541,  1.9061, -0.4221],\n",
      "        [-1.3373,  1.9666, -0.3987],\n",
      "        [-1.4998,  1.5656, -0.0593],\n",
      "        [-1.4586,  1.9508, -0.6267],\n",
      "        [-1.7434,  2.1379, -0.4103],\n",
      "        [ 0.5958, -0.0270, -0.8198],\n",
      "        [-1.6705,  1.8582, -0.6169],\n",
      "        [-1.6485,  1.3709,  0.3577],\n",
      "        [-1.5215,  2.0571, -0.7566],\n",
      "        [-1.0019,  0.1792,  0.8505],\n",
      "        [-1.7554,  1.9956, -0.2727],\n",
      "        [-1.9246,  1.9496, -0.1240],\n",
      "        [-1.0823,  1.6493, -0.9716],\n",
      "        [-1.6693,  0.3869,  1.0596],\n",
      "        [-1.4787,  2.1394, -0.6998]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8332,  0.3511,  1.3822],\n",
      "        [-1.5541,  1.9061, -0.4221],\n",
      "        [-1.3373,  1.9666, -0.3987],\n",
      "        [-1.4998,  1.5656, -0.0593],\n",
      "        [-1.4586,  1.9508, -0.6267],\n",
      "        [-1.7434,  2.1379, -0.4103],\n",
      "        [ 0.5958, -0.0270, -0.8198],\n",
      "        [-1.6705,  1.8582, -0.6169],\n",
      "        [-1.6485,  1.3709,  0.3577],\n",
      "        [-1.5215,  2.0571, -0.7566],\n",
      "        [-1.0019,  0.1792,  0.8505],\n",
      "        [-1.7554,  1.9956, -0.2727],\n",
      "        [-1.9246,  1.9496, -0.1240],\n",
      "        [-1.0823,  1.6493, -0.9716],\n",
      "        [-1.6693,  0.3869,  1.0596],\n",
      "        [-1.4787,  2.1394, -0.6998]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6614,  2.0562, -0.5259],\n",
      "        [ 0.3956, -0.0237, -0.8556],\n",
      "        [ 0.5006, -0.0052, -0.9478],\n",
      "        [-1.4442,  2.0449, -0.7562],\n",
      "        [-1.7427,  1.9222, -0.5191],\n",
      "        [-1.6649,  0.2110,  1.2069],\n",
      "        [-1.6223,  2.1472, -0.3781],\n",
      "        [-1.6895,  0.4824,  1.3191],\n",
      "        [-1.8603,  2.0387, -0.1372],\n",
      "        [-1.8556,  2.1060, -0.3136],\n",
      "        [-1.6384,  1.9662, -0.5038],\n",
      "        [-1.7325,  1.8890, -0.5069],\n",
      "        [-1.3270,  1.7068, -0.6694],\n",
      "        [-1.6570,  0.7528,  0.7536],\n",
      "        [-0.5801,  0.4565, -0.0532],\n",
      "        [-1.7355,  2.0345, -0.5429]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6614,  2.0562, -0.5259],\n",
      "        [ 0.3956, -0.0237, -0.8556],\n",
      "        [ 0.5006, -0.0052, -0.9478],\n",
      "        [-1.4442,  2.0449, -0.7562],\n",
      "        [-1.7427,  1.9222, -0.5191],\n",
      "        [-1.6649,  0.2110,  1.2069],\n",
      "        [-1.6223,  2.1472, -0.3781],\n",
      "        [-1.6895,  0.4824,  1.3191],\n",
      "        [-1.8603,  2.0387, -0.1372],\n",
      "        [-1.8556,  2.1060, -0.3136],\n",
      "        [-1.6384,  1.9662, -0.5038],\n",
      "        [-1.7325,  1.8890, -0.5069],\n",
      "        [-1.3270,  1.7068, -0.6694],\n",
      "        [-1.6570,  0.7528,  0.7536],\n",
      "        [-0.5801,  0.4565, -0.0532],\n",
      "        [-1.7355,  2.0345, -0.5429]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7705,  1.1449,  0.6890],\n",
      "        [-1.4835,  1.9739, -0.2355],\n",
      "        [-1.8668,  0.0754,  1.3514],\n",
      "        [-1.2743,  1.5267, -0.2662],\n",
      "        [-1.5754,  1.8011, -0.4968],\n",
      "        [-1.6361,  2.3602, -0.6656],\n",
      "        [-1.6379,  1.2929,  0.0470],\n",
      "        [-1.6786,  2.2319, -0.6267],\n",
      "        [-1.6823,  0.1384,  1.3622],\n",
      "        [-1.9048,  1.8657, -0.4649],\n",
      "        [-1.5941,  0.5088,  0.9850],\n",
      "        [-1.6444,  2.1990, -0.5127],\n",
      "        [-1.7394,  1.7428, -0.1104],\n",
      "        [-1.6055,  1.9518, -0.3847],\n",
      "        [-0.5914,  0.1151,  0.2187],\n",
      "        [-1.8129,  2.1793, -0.4090]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7705,  1.1449,  0.6890],\n",
      "        [-1.4835,  1.9739, -0.2355],\n",
      "        [-1.8668,  0.0754,  1.3514],\n",
      "        [-1.2743,  1.5267, -0.2662],\n",
      "        [-1.5754,  1.8011, -0.4968],\n",
      "        [-1.6361,  2.3602, -0.6656],\n",
      "        [-1.6379,  1.2929,  0.0470],\n",
      "        [-1.6786,  2.2319, -0.6267],\n",
      "        [-1.6823,  0.1384,  1.3622],\n",
      "        [-1.9048,  1.8657, -0.4649],\n",
      "        [-1.5941,  0.5088,  0.9850],\n",
      "        [-1.6444,  2.1990, -0.5127],\n",
      "        [-1.7394,  1.7428, -0.1104],\n",
      "        [-1.6055,  1.9518, -0.3847],\n",
      "        [-0.5914,  0.1151,  0.2187],\n",
      "        [-1.8129,  2.1793, -0.4090]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4778,  2.0819, -0.4722],\n",
      "        [-1.5266,  1.9775, -0.5446],\n",
      "        [-1.9716,  0.8743,  0.8611],\n",
      "        [-1.5595,  2.0351, -0.5766],\n",
      "        [-1.6878,  2.2156, -0.5854],\n",
      "        [-1.3773,  2.0433, -0.6264],\n",
      "        [-1.8681,  0.1422,  1.3255],\n",
      "        [ 0.5254, -0.0613, -0.8748],\n",
      "        [-1.7749,  2.0980, -0.5540],\n",
      "        [-1.6012,  0.1824,  1.2792],\n",
      "        [ 0.2622,  0.1147, -0.7708],\n",
      "        [-1.8573,  0.4497,  1.1385],\n",
      "        [-1.6212,  2.1378, -0.8758],\n",
      "        [-1.7843, -0.0031,  1.5358],\n",
      "        [-1.8321,  2.0488, -0.2711],\n",
      "        [ 0.3704,  0.0409, -0.8673]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4778,  2.0819, -0.4722],\n",
      "        [-1.5266,  1.9775, -0.5446],\n",
      "        [-1.9716,  0.8743,  0.8611],\n",
      "        [-1.5595,  2.0351, -0.5766],\n",
      "        [-1.6878,  2.2156, -0.5854],\n",
      "        [-1.3773,  2.0433, -0.6264],\n",
      "        [-1.8681,  0.1422,  1.3255],\n",
      "        [ 0.5254, -0.0613, -0.8748],\n",
      "        [-1.7749,  2.0980, -0.5540],\n",
      "        [-1.6012,  0.1824,  1.2792],\n",
      "        [ 0.2622,  0.1147, -0.7708],\n",
      "        [-1.8573,  0.4497,  1.1385],\n",
      "        [-1.6212,  2.1378, -0.8758],\n",
      "        [-1.7843, -0.0031,  1.5358],\n",
      "        [-1.8321,  2.0488, -0.2711],\n",
      "        [ 0.3704,  0.0409, -0.8673]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6231,  1.9852, -0.6181],\n",
      "        [-1.7993,  2.0818, -0.1544],\n",
      "        [-0.9035,  1.5219, -0.8779],\n",
      "        [-1.5718,  2.0574, -0.5419],\n",
      "        [-1.8853,  0.4694,  1.1745],\n",
      "        [-1.7238,  0.0634,  1.1843],\n",
      "        [-1.5875,  0.2973,  0.9024],\n",
      "        [-1.1523,  0.0870,  0.9664],\n",
      "        [-0.7490,  1.0780, -0.6804],\n",
      "        [-0.9207,  1.2856, -0.7141],\n",
      "        [-1.5991,  2.2241, -0.6105],\n",
      "        [-1.7433,  0.3347,  1.1302],\n",
      "        [-1.4086,  1.7253, -0.2969],\n",
      "        [-1.6867,  2.2905, -0.4666],\n",
      "        [-1.4992,  2.0364, -0.5715],\n",
      "        [-1.8562,  0.1279,  1.3397]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6231,  1.9852, -0.6181],\n",
      "        [-1.7993,  2.0818, -0.1544],\n",
      "        [-0.9035,  1.5219, -0.8779],\n",
      "        [-1.5718,  2.0574, -0.5419],\n",
      "        [-1.8853,  0.4694,  1.1745],\n",
      "        [-1.7238,  0.0634,  1.1843],\n",
      "        [-1.5875,  0.2973,  0.9024],\n",
      "        [-1.1523,  0.0870,  0.9664],\n",
      "        [-0.7490,  1.0780, -0.6804],\n",
      "        [-0.9207,  1.2856, -0.7141],\n",
      "        [-1.5991,  2.2241, -0.6105],\n",
      "        [-1.7433,  0.3347,  1.1302],\n",
      "        [-1.4086,  1.7253, -0.2969],\n",
      "        [-1.6867,  2.2905, -0.4666],\n",
      "        [-1.4992,  2.0364, -0.5715],\n",
      "        [-1.8562,  0.1279,  1.3397]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8165,  1.9379, -0.2983],\n",
      "        [-1.6862,  1.8563, -0.2461],\n",
      "        [-1.5634,  1.5595, -0.2269],\n",
      "        [-1.6806,  2.2781, -0.5167],\n",
      "        [-1.7580,  1.9326, -0.5052],\n",
      "        [ 0.2483,  0.0371, -0.9076],\n",
      "        [-1.8797,  2.2354, -0.2769],\n",
      "        [-1.6317,  1.7459, -0.2226],\n",
      "        [ 0.0654,  0.4249, -0.9411],\n",
      "        [-1.8538,  2.1374, -0.2678],\n",
      "        [-1.7397,  1.3553,  0.2856],\n",
      "        [ 0.3711, -0.1829, -0.7678],\n",
      "        [-1.7877,  1.5737,  0.2891],\n",
      "        [-1.3224,  1.3039, -0.1489],\n",
      "        [ 0.3084,  0.0259, -0.7640],\n",
      "        [-1.3741,  0.0237,  1.2784]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8165,  1.9379, -0.2983],\n",
      "        [-1.6862,  1.8563, -0.2461],\n",
      "        [-1.5634,  1.5595, -0.2269],\n",
      "        [-1.6806,  2.2781, -0.5167],\n",
      "        [-1.7580,  1.9326, -0.5052],\n",
      "        [ 0.2483,  0.0371, -0.9076],\n",
      "        [-1.8797,  2.2354, -0.2769],\n",
      "        [-1.6317,  1.7459, -0.2226],\n",
      "        [ 0.0654,  0.4249, -0.9411],\n",
      "        [-1.8538,  2.1374, -0.2678],\n",
      "        [-1.7397,  1.3553,  0.2856],\n",
      "        [ 0.3711, -0.1829, -0.7678],\n",
      "        [-1.7877,  1.5737,  0.2891],\n",
      "        [-1.3224,  1.3039, -0.1489],\n",
      "        [ 0.3084,  0.0259, -0.7640],\n",
      "        [-1.3741,  0.0237,  1.2784]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5531,  0.0280,  1.5801],\n",
      "        [ 0.3313,  0.0811, -0.8746],\n",
      "        [-1.8371,  1.9144, -0.5603],\n",
      "        [-1.0661,  1.3080, -0.6739],\n",
      "        [ 0.4588,  0.0310, -0.8608],\n",
      "        [ 0.3308, -0.1145, -0.7887],\n",
      "        [-1.6034,  1.8673, -0.4659],\n",
      "        [ 0.4352,  0.0089, -0.8894],\n",
      "        [-1.6911,  0.3739,  0.9754],\n",
      "        [-1.7405,  2.1642, -0.3712],\n",
      "        [-1.7163,  1.3134,  0.0237],\n",
      "        [-1.8297,  1.8668, -0.0499],\n",
      "        [-1.7949,  2.1510, -0.4506],\n",
      "        [-1.5289,  0.4267,  1.1432],\n",
      "        [-1.6205,  0.1166,  1.4220],\n",
      "        [-1.6280,  0.0895,  1.3533]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5531,  0.0280,  1.5801],\n",
      "        [ 0.3313,  0.0811, -0.8746],\n",
      "        [-1.8371,  1.9144, -0.5603],\n",
      "        [-1.0661,  1.3080, -0.6739],\n",
      "        [ 0.4588,  0.0310, -0.8608],\n",
      "        [ 0.3308, -0.1145, -0.7887],\n",
      "        [-1.6034,  1.8673, -0.4659],\n",
      "        [ 0.4352,  0.0089, -0.8894],\n",
      "        [-1.6911,  0.3739,  0.9754],\n",
      "        [-1.7405,  2.1642, -0.3712],\n",
      "        [-1.7163,  1.3134,  0.0237],\n",
      "        [-1.8297,  1.8668, -0.0499],\n",
      "        [-1.7949,  2.1510, -0.4506],\n",
      "        [-1.5289,  0.4267,  1.1432],\n",
      "        [-1.6205,  0.1166,  1.4220],\n",
      "        [-1.6280,  0.0895,  1.3533]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8038,  0.0813,  1.3856],\n",
      "        [-1.9471,  1.3156,  0.0795],\n",
      "        [-1.6725,  1.9204, -0.3756],\n",
      "        [-1.5898,  1.1930,  0.2293],\n",
      "        [-1.5674,  1.8475, -0.4882],\n",
      "        [-1.6163,  1.8869, -0.6319],\n",
      "        [-1.7730, -0.0627,  1.6469],\n",
      "        [-1.6866,  1.6996, -0.1548],\n",
      "        [-0.3131,  0.7519, -0.8307],\n",
      "        [-2.0407,  1.8807, -0.2765],\n",
      "        [-1.4494,  1.4902, -0.1957],\n",
      "        [-1.9152,  1.0644,  0.6990],\n",
      "        [-1.6360,  2.0106, -0.6467],\n",
      "        [-1.5315,  1.8011, -0.5887],\n",
      "        [-1.6414,  2.0343, -0.3175],\n",
      "        [-1.5573,  1.9806, -0.3286]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8038,  0.0813,  1.3856],\n",
      "        [-1.9471,  1.3156,  0.0795],\n",
      "        [-1.6725,  1.9204, -0.3756],\n",
      "        [-1.5898,  1.1930,  0.2293],\n",
      "        [-1.5674,  1.8475, -0.4882],\n",
      "        [-1.6163,  1.8869, -0.6319],\n",
      "        [-1.7730, -0.0627,  1.6469],\n",
      "        [-1.6866,  1.6996, -0.1548],\n",
      "        [-0.3131,  0.7519, -0.8307],\n",
      "        [-2.0407,  1.8807, -0.2765],\n",
      "        [-1.4494,  1.4902, -0.1957],\n",
      "        [-1.9152,  1.0644,  0.6990],\n",
      "        [-1.6360,  2.0106, -0.6467],\n",
      "        [-1.5315,  1.8011, -0.5887],\n",
      "        [-1.6414,  2.0343, -0.3175],\n",
      "        [-1.5573,  1.9806, -0.3286]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7215,  0.1154,  1.2276],\n",
      "        [-1.8117,  0.1755,  1.4723],\n",
      "        [-1.8328,  2.1312, -0.5187],\n",
      "        [-1.7385,  0.0921,  1.2811],\n",
      "        [ 0.3868, -0.0609, -0.7752],\n",
      "        [-1.5911,  1.8627, -0.5657],\n",
      "        [-1.7673,  0.5423,  1.0181],\n",
      "        [-1.7558,  0.1873,  1.2828],\n",
      "        [-0.6991,  0.2095,  0.0485],\n",
      "        [-1.9910,  1.6843,  0.1490],\n",
      "        [-0.1483,  0.4771, -1.0562],\n",
      "        [-2.0958,  0.5673,  1.1248],\n",
      "        [-1.7485, -0.0165,  1.5759],\n",
      "        [-1.9374,  0.1526,  1.4211],\n",
      "        [-1.7753,  1.8162, -0.4234],\n",
      "        [ 0.3999,  0.0610, -0.9096]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7215,  0.1154,  1.2276],\n",
      "        [-1.8117,  0.1755,  1.4723],\n",
      "        [-1.8328,  2.1312, -0.5187],\n",
      "        [-1.7385,  0.0921,  1.2811],\n",
      "        [ 0.3868, -0.0609, -0.7752],\n",
      "        [-1.5911,  1.8627, -0.5657],\n",
      "        [-1.7673,  0.5423,  1.0181],\n",
      "        [-1.7558,  0.1873,  1.2828],\n",
      "        [-0.6991,  0.2095,  0.0485],\n",
      "        [-1.9910,  1.6843,  0.1490],\n",
      "        [-0.1483,  0.4771, -1.0562],\n",
      "        [-2.0958,  0.5673,  1.1248],\n",
      "        [-1.7485, -0.0165,  1.5759],\n",
      "        [-1.9374,  0.1526,  1.4211],\n",
      "        [-1.7753,  1.8162, -0.4234],\n",
      "        [ 0.3999,  0.0610, -0.9096]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6785,  1.8300, -0.3898],\n",
      "        [-1.6730,  0.9391,  0.2842],\n",
      "        [-1.7387,  1.9310, -0.1856],\n",
      "        [-1.4798,  0.1689,  1.1534],\n",
      "        [-1.4892,  0.2604,  1.0486],\n",
      "        [-1.7267,  0.1707,  1.1931],\n",
      "        [-1.5666,  0.3413,  0.8821],\n",
      "        [-0.1647,  0.4552, -0.4586],\n",
      "        [-1.7994,  2.0155, -0.3464],\n",
      "        [-1.7427,  0.1785,  1.4520],\n",
      "        [-1.5818,  0.4846,  1.0847],\n",
      "        [-1.5879,  1.8821, -0.6391],\n",
      "        [-1.7782,  1.7537, -0.3864],\n",
      "        [-1.4428,  1.7457, -0.3065],\n",
      "        [-1.7338,  0.7130,  0.9999],\n",
      "        [-1.7036,  0.1703,  1.4775]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6785,  1.8300, -0.3898],\n",
      "        [-1.6730,  0.9391,  0.2842],\n",
      "        [-1.7387,  1.9310, -0.1856],\n",
      "        [-1.4798,  0.1689,  1.1534],\n",
      "        [-1.4892,  0.2604,  1.0486],\n",
      "        [-1.7267,  0.1707,  1.1931],\n",
      "        [-1.5666,  0.3413,  0.8821],\n",
      "        [-0.1647,  0.4552, -0.4586],\n",
      "        [-1.7994,  2.0155, -0.3464],\n",
      "        [-1.7427,  0.1785,  1.4520],\n",
      "        [-1.5818,  0.4846,  1.0847],\n",
      "        [-1.5879,  1.8821, -0.6391],\n",
      "        [-1.7782,  1.7537, -0.3864],\n",
      "        [-1.4428,  1.7457, -0.3065],\n",
      "        [-1.7338,  0.7130,  0.9999],\n",
      "        [-1.7036,  0.1703,  1.4775]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5135, -0.0867, -0.7853],\n",
      "        [-1.5212,  0.1740,  1.2492],\n",
      "        [ 0.4265,  0.0533, -0.9036],\n",
      "        [-1.7702,  1.0527,  0.7025],\n",
      "        [ 0.2807,  0.0292, -0.8393],\n",
      "        [-1.1542,  1.6368, -0.6917],\n",
      "        [ 0.0932,  0.1093, -0.8177],\n",
      "        [-1.8436,  0.1083,  1.3519],\n",
      "        [-1.5286,  1.7779, -0.5410],\n",
      "        [ 0.0959,  0.3445, -0.8596],\n",
      "        [-1.4119,  0.1555,  0.9834],\n",
      "        [-1.5482,  1.9907, -0.5045],\n",
      "        [-1.6901,  2.0649, -0.2534],\n",
      "        [-1.7320,  0.4279,  1.3182],\n",
      "        [-1.2351,  1.3801, -0.3586],\n",
      "        [-1.8307,  2.0323,  0.0110]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.5135, -0.0867, -0.7853],\n",
      "        [-1.5212,  0.1740,  1.2492],\n",
      "        [ 0.4265,  0.0533, -0.9036],\n",
      "        [-1.7702,  1.0527,  0.7025],\n",
      "        [ 0.2807,  0.0292, -0.8393],\n",
      "        [-1.1542,  1.6368, -0.6917],\n",
      "        [ 0.0932,  0.1093, -0.8177],\n",
      "        [-1.8436,  0.1083,  1.3519],\n",
      "        [-1.5286,  1.7779, -0.5410],\n",
      "        [ 0.0959,  0.3445, -0.8596],\n",
      "        [-1.4119,  0.1555,  0.9834],\n",
      "        [-1.5482,  1.9907, -0.5045],\n",
      "        [-1.6901,  2.0649, -0.2534],\n",
      "        [-1.7320,  0.4279,  1.3182],\n",
      "        [-1.2351,  1.3801, -0.3586],\n",
      "        [-1.8307,  2.0323,  0.0110]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7528,  2.3253, -0.3889],\n",
      "        [-1.5948,  2.0545, -0.3673],\n",
      "        [-1.5822,  1.5039, -0.2184],\n",
      "        [-1.7257,  1.8429, -0.3761],\n",
      "        [-1.8827,  1.0843,  0.3897],\n",
      "        [-1.7372,  2.0746, -0.3372],\n",
      "        [-1.4254,  1.6297, -0.2598],\n",
      "        [-1.9322,  0.2775,  1.3032],\n",
      "        [-1.6476,  0.5322,  1.0265],\n",
      "        [-1.2642,  1.6668, -0.2271],\n",
      "        [-1.7491,  2.1344, -0.3920],\n",
      "        [ 0.3172,  0.0484, -0.9910],\n",
      "        [-1.5407,  1.7757, -0.4294],\n",
      "        [-1.5503,  1.8033, -0.3218],\n",
      "        [-1.6855,  0.2679,  0.8705],\n",
      "        [-1.6151,  1.8466, -0.1601]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7528,  2.3253, -0.3889],\n",
      "        [-1.5948,  2.0545, -0.3673],\n",
      "        [-1.5822,  1.5039, -0.2184],\n",
      "        [-1.7257,  1.8429, -0.3761],\n",
      "        [-1.8827,  1.0843,  0.3897],\n",
      "        [-1.7372,  2.0746, -0.3372],\n",
      "        [-1.4254,  1.6297, -0.2598],\n",
      "        [-1.9322,  0.2775,  1.3032],\n",
      "        [-1.6476,  0.5322,  1.0265],\n",
      "        [-1.2642,  1.6668, -0.2271],\n",
      "        [-1.7491,  2.1344, -0.3920],\n",
      "        [ 0.3172,  0.0484, -0.9910],\n",
      "        [-1.5407,  1.7757, -0.4294],\n",
      "        [-1.5503,  1.8033, -0.3218],\n",
      "        [-1.6855,  0.2679,  0.8705],\n",
      "        [-1.6151,  1.8466, -0.1601]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3560,  0.4169,  0.7598],\n",
      "        [-1.8547,  1.5746,  0.0070],\n",
      "        [ 0.3053, -0.0191, -0.8235],\n",
      "        [-1.8260,  1.5312,  0.1719],\n",
      "        [ 0.3599,  0.1906, -1.0369],\n",
      "        [-1.7749,  1.3755,  0.2660],\n",
      "        [-1.4491,  1.6800, -0.2775],\n",
      "        [-1.8090,  0.5893,  0.8840],\n",
      "        [-1.8489,  0.2449,  1.3796],\n",
      "        [-1.8225,  1.7227, -0.1518],\n",
      "        [-1.8761,  0.7131,  0.7318],\n",
      "        [-1.8668,  0.2839,  1.3686],\n",
      "        [-1.7413,  0.5722,  0.9698],\n",
      "        [-1.6447,  1.6591, -0.2289],\n",
      "        [-1.9147,  0.5275,  1.0227],\n",
      "        [-1.8770,  0.3154,  1.1180]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3560,  0.4169,  0.7598],\n",
      "        [-1.8547,  1.5746,  0.0070],\n",
      "        [ 0.3053, -0.0191, -0.8235],\n",
      "        [-1.8260,  1.5312,  0.1719],\n",
      "        [ 0.3599,  0.1906, -1.0369],\n",
      "        [-1.7749,  1.3755,  0.2660],\n",
      "        [-1.4491,  1.6800, -0.2775],\n",
      "        [-1.8090,  0.5893,  0.8840],\n",
      "        [-1.8489,  0.2449,  1.3796],\n",
      "        [-1.8225,  1.7227, -0.1518],\n",
      "        [-1.8761,  0.7131,  0.7318],\n",
      "        [-1.8668,  0.2839,  1.3686],\n",
      "        [-1.7413,  0.5722,  0.9698],\n",
      "        [-1.6447,  1.6591, -0.2289],\n",
      "        [-1.9147,  0.5275,  1.0227],\n",
      "        [-1.8770,  0.3154,  1.1180]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6216,  2.0025, -0.4473],\n",
      "        [-1.5779,  1.4179,  0.4098],\n",
      "        [-1.5404,  1.5688, -0.1254],\n",
      "        [-1.7568,  1.8291, -0.1805],\n",
      "        [-1.6424,  1.3468,  0.1876],\n",
      "        [-1.5338,  1.4296, -0.2464],\n",
      "        [-0.0750,  0.1328, -0.4534],\n",
      "        [-1.4319,  0.6557,  0.3923],\n",
      "        [-1.5635,  1.7846, -0.2881],\n",
      "        [-1.4860,  1.4732, -0.6114],\n",
      "        [-1.5903,  1.8333, -0.4387],\n",
      "        [-1.7279,  1.6331, -0.2545],\n",
      "        [-1.5347,  1.4264, -0.4136],\n",
      "        [-1.7285,  2.0700, -0.4807],\n",
      "        [-1.7399,  1.2571,  0.4065],\n",
      "        [-1.8158,  1.7144, -0.0337]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6216,  2.0025, -0.4473],\n",
      "        [-1.5779,  1.4179,  0.4098],\n",
      "        [-1.5404,  1.5688, -0.1254],\n",
      "        [-1.7568,  1.8291, -0.1805],\n",
      "        [-1.6424,  1.3468,  0.1876],\n",
      "        [-1.5338,  1.4296, -0.2464],\n",
      "        [-0.0750,  0.1328, -0.4534],\n",
      "        [-1.4319,  0.6557,  0.3923],\n",
      "        [-1.5635,  1.7846, -0.2881],\n",
      "        [-1.4860,  1.4732, -0.6114],\n",
      "        [-1.5903,  1.8333, -0.4387],\n",
      "        [-1.7279,  1.6331, -0.2545],\n",
      "        [-1.5347,  1.4264, -0.4136],\n",
      "        [-1.7285,  2.0700, -0.4807],\n",
      "        [-1.7399,  1.2571,  0.4065],\n",
      "        [-1.8158,  1.7144, -0.0337]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0398,  0.3001,  1.2541],\n",
      "        [-1.7143,  1.3656,  0.1760],\n",
      "        [-1.6329,  0.3483,  1.2202],\n",
      "        [-1.6108,  1.6276, -0.1950],\n",
      "        [-0.0337,  0.2247, -0.6293],\n",
      "        [-1.7803,  0.5360,  1.0290],\n",
      "        [-1.7775,  0.1686,  1.2746],\n",
      "        [ 0.3204,  0.0145, -0.8777],\n",
      "        [-1.7806,  0.2844,  1.3206],\n",
      "        [-1.5339,  0.2799,  0.9405],\n",
      "        [-1.7330,  0.8943,  0.7269],\n",
      "        [-1.6384,  1.9887, -0.5086],\n",
      "        [-1.5453,  1.5151,  0.1041],\n",
      "        [ 0.5060, -0.0036, -0.9114],\n",
      "        [-1.5847,  0.7607,  0.5514],\n",
      "        [-1.4916,  0.7366,  0.6498]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.0398,  0.3001,  1.2541],\n",
      "        [-1.7143,  1.3656,  0.1760],\n",
      "        [-1.6329,  0.3483,  1.2202],\n",
      "        [-1.6108,  1.6276, -0.1950],\n",
      "        [-0.0337,  0.2247, -0.6293],\n",
      "        [-1.7803,  0.5360,  1.0290],\n",
      "        [-1.7775,  0.1686,  1.2746],\n",
      "        [ 0.3204,  0.0145, -0.8777],\n",
      "        [-1.7806,  0.2844,  1.3206],\n",
      "        [-1.5339,  0.2799,  0.9405],\n",
      "        [-1.7330,  0.8943,  0.7269],\n",
      "        [-1.6384,  1.9887, -0.5086],\n",
      "        [-1.5453,  1.5151,  0.1041],\n",
      "        [ 0.5060, -0.0036, -0.9114],\n",
      "        [-1.5847,  0.7607,  0.5514],\n",
      "        [-1.4916,  0.7366,  0.6498]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3484,  1.6612, -0.2012],\n",
      "        [-1.3590,  1.3463, -0.3381],\n",
      "        [-1.6944,  1.9550, -0.3265],\n",
      "        [-1.1085,  1.4230, -0.2188],\n",
      "        [-1.5410,  0.4343,  1.1843],\n",
      "        [-1.2968,  1.5355, -0.2323],\n",
      "        [-1.6142,  0.5668,  0.9189],\n",
      "        [-1.3631,  1.4867, -0.4254],\n",
      "        [-1.4464,  1.6049, -0.3215],\n",
      "        [-1.6842,  1.2435,  0.4330],\n",
      "        [-1.0063,  0.2430,  0.5760],\n",
      "        [-1.2824,  1.1354,  0.1934],\n",
      "        [-1.5405,  0.3998,  1.2256],\n",
      "        [-1.7894,  0.9230,  0.8541],\n",
      "        [-1.5993,  1.6245, -0.3999],\n",
      "        [-1.5698,  1.7296, -0.4847]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3484,  1.6612, -0.2012],\n",
      "        [-1.3590,  1.3463, -0.3381],\n",
      "        [-1.6944,  1.9550, -0.3265],\n",
      "        [-1.1085,  1.4230, -0.2188],\n",
      "        [-1.5410,  0.4343,  1.1843],\n",
      "        [-1.2968,  1.5355, -0.2323],\n",
      "        [-1.6142,  0.5668,  0.9189],\n",
      "        [-1.3631,  1.4867, -0.4254],\n",
      "        [-1.4464,  1.6049, -0.3215],\n",
      "        [-1.6842,  1.2435,  0.4330],\n",
      "        [-1.0063,  0.2430,  0.5760],\n",
      "        [-1.2824,  1.1354,  0.1934],\n",
      "        [-1.5405,  0.3998,  1.2256],\n",
      "        [-1.7894,  0.9230,  0.8541],\n",
      "        [-1.5993,  1.6245, -0.3999],\n",
      "        [-1.5698,  1.7296, -0.4847]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5404,  1.2911,  0.2657],\n",
      "        [-1.6634,  1.3832, -0.0151],\n",
      "        [-1.6807,  0.3331,  1.4464],\n",
      "        [-1.4366,  1.4557, -0.0678],\n",
      "        [-1.6640,  1.7412, -0.1513],\n",
      "        [-1.7146,  0.4627,  1.1327],\n",
      "        [ 0.4328,  0.0463, -0.8151],\n",
      "        [-1.6821,  0.4517,  1.2687],\n",
      "        [-1.5330,  1.6420, -0.3794],\n",
      "        [-1.3730,  1.6970, -0.2895],\n",
      "        [-1.7421,  1.3456,  0.2881],\n",
      "        [ 0.3828, -0.0854, -0.8514],\n",
      "        [-1.5238,  0.3972,  1.0052],\n",
      "        [-1.7835,  0.0450,  1.5090],\n",
      "        [-1.6658,  1.7366, -0.0931],\n",
      "        [ 0.5685, -0.0904, -0.9773]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5404,  1.2911,  0.2657],\n",
      "        [-1.6634,  1.3832, -0.0151],\n",
      "        [-1.6807,  0.3331,  1.4464],\n",
      "        [-1.4366,  1.4557, -0.0678],\n",
      "        [-1.6640,  1.7412, -0.1513],\n",
      "        [-1.7146,  0.4627,  1.1327],\n",
      "        [ 0.4328,  0.0463, -0.8151],\n",
      "        [-1.6821,  0.4517,  1.2687],\n",
      "        [-1.5330,  1.6420, -0.3794],\n",
      "        [-1.3730,  1.6970, -0.2895],\n",
      "        [-1.7421,  1.3456,  0.2881],\n",
      "        [ 0.3828, -0.0854, -0.8514],\n",
      "        [-1.5238,  0.3972,  1.0052],\n",
      "        [-1.7835,  0.0450,  1.5090],\n",
      "        [-1.6658,  1.7366, -0.0931],\n",
      "        [ 0.5685, -0.0904, -0.9773]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5678,  0.9803,  0.5526],\n",
      "        [-1.5543,  0.3601,  1.0068],\n",
      "        [-1.8271,  0.3953,  1.3172],\n",
      "        [-1.6590,  0.3317,  1.2503],\n",
      "        [-1.7297,  0.3315,  1.0901],\n",
      "        [-0.2103,  0.2499, -0.4258],\n",
      "        [-1.2643,  1.1617,  0.0726],\n",
      "        [-1.2886,  0.1929,  0.9455],\n",
      "        [-1.1165,  1.2657, -0.1632],\n",
      "        [ 0.2384, -0.0324, -0.7331],\n",
      "        [-1.3037,  1.7127, -0.4807],\n",
      "        [-1.6162,  0.3092,  1.2642],\n",
      "        [ 0.4682,  0.0293, -0.9325],\n",
      "        [-1.6073,  1.7675, -0.3053],\n",
      "        [-1.1146,  1.0936, -0.1436],\n",
      "        [-1.6584,  1.8174, -0.3683]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5678,  0.9803,  0.5526],\n",
      "        [-1.5543,  0.3601,  1.0068],\n",
      "        [-1.8271,  0.3953,  1.3172],\n",
      "        [-1.6590,  0.3317,  1.2503],\n",
      "        [-1.7297,  0.3315,  1.0901],\n",
      "        [-0.2103,  0.2499, -0.4258],\n",
      "        [-1.2643,  1.1617,  0.0726],\n",
      "        [-1.2886,  0.1929,  0.9455],\n",
      "        [-1.1165,  1.2657, -0.1632],\n",
      "        [ 0.2384, -0.0324, -0.7331],\n",
      "        [-1.3037,  1.7127, -0.4807],\n",
      "        [-1.6162,  0.3092,  1.2642],\n",
      "        [ 0.4682,  0.0293, -0.9325],\n",
      "        [-1.6073,  1.7675, -0.3053],\n",
      "        [-1.1146,  1.0936, -0.1436],\n",
      "        [-1.6584,  1.8174, -0.3683]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7946,  0.2559,  1.3670],\n",
      "        [-1.8000,  0.5514,  1.1080],\n",
      "        [-1.6273,  1.5158, -0.0291],\n",
      "        [-0.8791,  1.3153, -0.4964],\n",
      "        [-1.6585,  1.3187,  0.3293],\n",
      "        [ 0.3095, -0.0254, -0.7457],\n",
      "        [-1.0819,  1.2903, -0.6478],\n",
      "        [-1.2781,  1.3809, -0.2024],\n",
      "        [-1.4177,  1.2832,  0.0943],\n",
      "        [-1.5405,  1.8144, -0.0929],\n",
      "        [-1.1247,  1.7136, -0.4958],\n",
      "        [ 0.2389, -0.0543, -0.8812],\n",
      "        [-1.4221,  1.5635, -0.3735],\n",
      "        [-1.4993,  1.2963,  0.0827],\n",
      "        [-1.5022,  1.6658, -0.3343],\n",
      "        [-1.2859,  1.6789, -0.3882]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7946,  0.2559,  1.3670],\n",
      "        [-1.8000,  0.5514,  1.1080],\n",
      "        [-1.6273,  1.5158, -0.0291],\n",
      "        [-0.8791,  1.3153, -0.4964],\n",
      "        [-1.6585,  1.3187,  0.3293],\n",
      "        [ 0.3095, -0.0254, -0.7457],\n",
      "        [-1.0819,  1.2903, -0.6478],\n",
      "        [-1.2781,  1.3809, -0.2024],\n",
      "        [-1.4177,  1.2832,  0.0943],\n",
      "        [-1.5405,  1.8144, -0.0929],\n",
      "        [-1.1247,  1.7136, -0.4958],\n",
      "        [ 0.2389, -0.0543, -0.8812],\n",
      "        [-1.4221,  1.5635, -0.3735],\n",
      "        [-1.4993,  1.2963,  0.0827],\n",
      "        [-1.5022,  1.6658, -0.3343],\n",
      "        [-1.2859,  1.6789, -0.3882]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2841,  1.6231, -0.3944],\n",
      "        [-1.4476,  0.7786,  0.5027],\n",
      "        [ 0.3933,  0.0125, -0.9762],\n",
      "        [-1.1080,  1.1599, -0.0070],\n",
      "        [-1.3838,  1.4142, -0.2665],\n",
      "        [-1.7545,  1.1259,  0.6280],\n",
      "        [-1.8741,  0.2736,  1.0869],\n",
      "        [-1.8300,  0.2413,  1.2261],\n",
      "        [-1.1837,  1.2744, -0.0191],\n",
      "        [-1.7308,  0.5675,  0.8626],\n",
      "        [-1.3494,  1.5638, -0.3730],\n",
      "        [-1.6285,  1.9489, -0.3425],\n",
      "        [-1.4272,  1.5679, -0.3009],\n",
      "        [-1.6063,  1.0609,  0.2468],\n",
      "        [ 0.2895, -0.0106, -0.6078],\n",
      "        [-1.4406,  1.6562, -0.2632]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.2841,  1.6231, -0.3944],\n",
      "        [-1.4476,  0.7786,  0.5027],\n",
      "        [ 0.3933,  0.0125, -0.9762],\n",
      "        [-1.1080,  1.1599, -0.0070],\n",
      "        [-1.3838,  1.4142, -0.2665],\n",
      "        [-1.7545,  1.1259,  0.6280],\n",
      "        [-1.8741,  0.2736,  1.0869],\n",
      "        [-1.8300,  0.2413,  1.2261],\n",
      "        [-1.1837,  1.2744, -0.0191],\n",
      "        [-1.7308,  0.5675,  0.8626],\n",
      "        [-1.3494,  1.5638, -0.3730],\n",
      "        [-1.6285,  1.9489, -0.3425],\n",
      "        [-1.4272,  1.5679, -0.3009],\n",
      "        [-1.6063,  1.0609,  0.2468],\n",
      "        [ 0.2895, -0.0106, -0.6078],\n",
      "        [-1.4406,  1.6562, -0.2632]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7280,  1.3306,  0.0735],\n",
      "        [-1.4840,  1.5231, -0.6480],\n",
      "        [-1.5036,  1.7581, -0.2875],\n",
      "        [-1.1057,  0.3946,  0.7229],\n",
      "        [-1.3890,  1.3445, -0.0940],\n",
      "        [-1.4073,  1.4188, -0.1757],\n",
      "        [-1.3845,  1.5869, -0.3884],\n",
      "        [-1.5288,  1.3789,  0.1498],\n",
      "        [-1.7167,  0.6404,  1.2116],\n",
      "        [-1.3184,  1.4989, -0.3598],\n",
      "        [-1.7373,  0.9894,  0.6373],\n",
      "        [-1.6881,  0.4272,  1.3612],\n",
      "        [-1.2860,  0.3855,  1.0457],\n",
      "        [ 0.6227, -0.2985, -0.8861],\n",
      "        [ 0.4428, -0.1150, -0.8444],\n",
      "        [-1.7453,  1.8486, -0.2399]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7280,  1.3306,  0.0735],\n",
      "        [-1.4840,  1.5231, -0.6480],\n",
      "        [-1.5036,  1.7581, -0.2875],\n",
      "        [-1.1057,  0.3946,  0.7229],\n",
      "        [-1.3890,  1.3445, -0.0940],\n",
      "        [-1.4073,  1.4188, -0.1757],\n",
      "        [-1.3845,  1.5869, -0.3884],\n",
      "        [-1.5288,  1.3789,  0.1498],\n",
      "        [-1.7167,  0.6404,  1.2116],\n",
      "        [-1.3184,  1.4989, -0.3598],\n",
      "        [-1.7373,  0.9894,  0.6373],\n",
      "        [-1.6881,  0.4272,  1.3612],\n",
      "        [-1.2860,  0.3855,  1.0457],\n",
      "        [ 0.6227, -0.2985, -0.8861],\n",
      "        [ 0.4428, -0.1150, -0.8444],\n",
      "        [-1.7453,  1.8486, -0.2399]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3175,  0.0813, -0.9399],\n",
      "        [-1.4005,  1.5641, -0.3190],\n",
      "        [-1.5563,  0.3798,  1.0969],\n",
      "        [-1.6942,  0.7149,  0.6844],\n",
      "        [-1.5259,  0.2764,  1.1063],\n",
      "        [-1.0445,  0.3596,  0.2736],\n",
      "        [-1.2899,  1.6025, -0.2483],\n",
      "        [-1.5251,  0.3118,  1.0749],\n",
      "        [ 0.3540,  0.0032, -0.7585],\n",
      "        [ 0.6093,  0.1106, -0.8815],\n",
      "        [-1.7026,  1.0586,  0.4393],\n",
      "        [ 0.3769, -0.1272, -0.7465],\n",
      "        [-1.3920,  1.8465, -0.4877],\n",
      "        [-1.5640,  1.4783, -0.1551],\n",
      "        [-1.2717,  1.3820, -0.3332],\n",
      "        [-0.4176,  0.1928, -0.0421]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.3175,  0.0813, -0.9399],\n",
      "        [-1.4005,  1.5641, -0.3190],\n",
      "        [-1.5563,  0.3798,  1.0969],\n",
      "        [-1.6942,  0.7149,  0.6844],\n",
      "        [-1.5259,  0.2764,  1.1063],\n",
      "        [-1.0445,  0.3596,  0.2736],\n",
      "        [-1.2899,  1.6025, -0.2483],\n",
      "        [-1.5251,  0.3118,  1.0749],\n",
      "        [ 0.3540,  0.0032, -0.7585],\n",
      "        [ 0.6093,  0.1106, -0.8815],\n",
      "        [-1.7026,  1.0586,  0.4393],\n",
      "        [ 0.3769, -0.1272, -0.7465],\n",
      "        [-1.3920,  1.8465, -0.4877],\n",
      "        [-1.5640,  1.4783, -0.1551],\n",
      "        [-1.2717,  1.3820, -0.3332],\n",
      "        [-0.4176,  0.1928, -0.0421]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8202,  0.4728,  1.1181],\n",
      "        [-1.2459,  1.1139, -0.0738],\n",
      "        [-1.4667,  1.6009, -0.1728],\n",
      "        [-1.4920,  1.3921, -0.3580],\n",
      "        [-1.4094,  1.2686,  0.1735],\n",
      "        [-1.3314,  1.5682, -0.3023],\n",
      "        [-1.5989,  0.2820,  1.1612],\n",
      "        [-1.4261,  1.1915, -0.0104],\n",
      "        [-1.6198,  1.9932, -0.2268],\n",
      "        [-1.4038,  1.8064, -0.4323],\n",
      "        [-1.3506,  1.7825, -0.5272],\n",
      "        [-1.5472,  1.5917, -0.3323],\n",
      "        [-1.3518,  1.3700, -0.2502],\n",
      "        [-1.3879,  1.6518, -0.3355],\n",
      "        [-1.4443,  1.0853,  0.2282],\n",
      "        [-1.7727,  0.2124,  1.4873]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8202,  0.4728,  1.1181],\n",
      "        [-1.2459,  1.1139, -0.0738],\n",
      "        [-1.4667,  1.6009, -0.1728],\n",
      "        [-1.4920,  1.3921, -0.3580],\n",
      "        [-1.4094,  1.2686,  0.1735],\n",
      "        [-1.3314,  1.5682, -0.3023],\n",
      "        [-1.5989,  0.2820,  1.1612],\n",
      "        [-1.4261,  1.1915, -0.0104],\n",
      "        [-1.6198,  1.9932, -0.2268],\n",
      "        [-1.4038,  1.8064, -0.4323],\n",
      "        [-1.3506,  1.7825, -0.5272],\n",
      "        [-1.5472,  1.5917, -0.3323],\n",
      "        [-1.3518,  1.3700, -0.2502],\n",
      "        [-1.3879,  1.6518, -0.3355],\n",
      "        [-1.4443,  1.0853,  0.2282],\n",
      "        [-1.7727,  0.2124,  1.4873]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3983,  1.0189,  0.5649],\n",
      "        [-1.5488,  0.2975,  1.1005],\n",
      "        [-1.3811,  0.5272,  0.9292],\n",
      "        [ 0.6493, -0.0979, -0.8506],\n",
      "        [-1.5309,  0.6216,  0.8855],\n",
      "        [-1.5358,  1.4149,  0.0256],\n",
      "        [-1.5656,  0.5185,  0.9502],\n",
      "        [-0.5625,  0.2130,  0.1710],\n",
      "        [-1.5614,  1.7345, -0.4025],\n",
      "        [-1.4673,  1.5750, -0.4954],\n",
      "        [-1.2687,  0.8806,  0.4185],\n",
      "        [-1.4608,  0.4204,  1.0550],\n",
      "        [-1.5174,  0.3836,  1.0466],\n",
      "        [-1.6453,  1.9511, -0.3074],\n",
      "        [-1.5970,  0.8497,  0.6311],\n",
      "        [-1.7026,  0.3650,  1.3363]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3983,  1.0189,  0.5649],\n",
      "        [-1.5488,  0.2975,  1.1005],\n",
      "        [-1.3811,  0.5272,  0.9292],\n",
      "        [ 0.6493, -0.0979, -0.8506],\n",
      "        [-1.5309,  0.6216,  0.8855],\n",
      "        [-1.5358,  1.4149,  0.0256],\n",
      "        [-1.5656,  0.5185,  0.9502],\n",
      "        [-0.5625,  0.2130,  0.1710],\n",
      "        [-1.5614,  1.7345, -0.4025],\n",
      "        [-1.4673,  1.5750, -0.4954],\n",
      "        [-1.2687,  0.8806,  0.4185],\n",
      "        [-1.4608,  0.4204,  1.0550],\n",
      "        [-1.5174,  0.3836,  1.0466],\n",
      "        [-1.6453,  1.9511, -0.3074],\n",
      "        [-1.5970,  0.8497,  0.6311],\n",
      "        [-1.7026,  0.3650,  1.3363]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6071,  0.4458,  1.0080],\n",
      "        [-0.4947,  0.6841, -0.4864],\n",
      "        [-1.5823,  1.6948, -0.4218],\n",
      "        [-1.6179,  1.5935, -0.3209],\n",
      "        [ 0.4937,  0.0508, -0.8344],\n",
      "        [-1.4487,  0.2400,  1.1575],\n",
      "        [-1.7052,  1.3948,  0.2095],\n",
      "        [-1.7859,  0.3010,  1.0974],\n",
      "        [-1.0075,  1.3997, -0.5041],\n",
      "        [ 0.6170, -0.2117, -0.8853],\n",
      "        [-1.4317,  1.7449, -0.2120],\n",
      "        [-1.3339,  1.1836, -0.0653],\n",
      "        [ 0.5204, -0.0659, -0.8965],\n",
      "        [-1.4557,  1.4319, -0.3571],\n",
      "        [-1.4764,  0.1406,  1.0785],\n",
      "        [-1.5914,  1.7637, -0.3233]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6071,  0.4458,  1.0080],\n",
      "        [-0.4947,  0.6841, -0.4864],\n",
      "        [-1.5823,  1.6948, -0.4218],\n",
      "        [-1.6179,  1.5935, -0.3209],\n",
      "        [ 0.4937,  0.0508, -0.8344],\n",
      "        [-1.4487,  0.2400,  1.1575],\n",
      "        [-1.7052,  1.3948,  0.2095],\n",
      "        [-1.7859,  0.3010,  1.0974],\n",
      "        [-1.0075,  1.3997, -0.5041],\n",
      "        [ 0.6170, -0.2117, -0.8853],\n",
      "        [-1.4317,  1.7449, -0.2120],\n",
      "        [-1.3339,  1.1836, -0.0653],\n",
      "        [ 0.5204, -0.0659, -0.8965],\n",
      "        [-1.4557,  1.4319, -0.3571],\n",
      "        [-1.4764,  0.1406,  1.0785],\n",
      "        [-1.5914,  1.7637, -0.3233]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2964,  1.5653, -0.3592],\n",
      "        [-1.3136,  1.0574,  0.0980],\n",
      "        [-1.6748,  0.6936,  0.8819],\n",
      "        [-1.1910,  1.0867,  0.0132],\n",
      "        [-1.0298,  0.9062, -0.0055],\n",
      "        [-0.1892,  0.6103, -0.8066],\n",
      "        [ 0.3668,  0.1614, -0.9849],\n",
      "        [-1.4874,  0.6129,  0.9216],\n",
      "        [-1.3543,  1.7981, -0.5375],\n",
      "        [-1.6141,  0.2118,  1.2387],\n",
      "        [-1.5299,  1.9864, -0.4899],\n",
      "        [-1.7140,  1.5678, -0.5352],\n",
      "        [ 0.7135, -0.1390, -1.0658],\n",
      "        [-1.4167,  1.5507, -0.0479],\n",
      "        [ 0.5204, -0.0874, -0.8780],\n",
      "        [-1.7617,  0.3928,  1.1969]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.2964,  1.5653, -0.3592],\n",
      "        [-1.3136,  1.0574,  0.0980],\n",
      "        [-1.6748,  0.6936,  0.8819],\n",
      "        [-1.1910,  1.0867,  0.0132],\n",
      "        [-1.0298,  0.9062, -0.0055],\n",
      "        [-0.1892,  0.6103, -0.8066],\n",
      "        [ 0.3668,  0.1614, -0.9849],\n",
      "        [-1.4874,  0.6129,  0.9216],\n",
      "        [-1.3543,  1.7981, -0.5375],\n",
      "        [-1.6141,  0.2118,  1.2387],\n",
      "        [-1.5299,  1.9864, -0.4899],\n",
      "        [-1.7140,  1.5678, -0.5352],\n",
      "        [ 0.7135, -0.1390, -1.0658],\n",
      "        [-1.4167,  1.5507, -0.0479],\n",
      "        [ 0.5204, -0.0874, -0.8780],\n",
      "        [-1.7617,  0.3928,  1.1969]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.8039, -0.1927, -1.1503],\n",
      "        [-1.3283,  1.5542, -0.4308],\n",
      "        [-1.4636,  1.4113, -0.2277],\n",
      "        [-1.5966,  0.4308,  1.0654],\n",
      "        [-1.3946,  1.7923, -0.4717],\n",
      "        [-1.4066,  1.5693, -0.3897],\n",
      "        [ 0.7169, -0.1620, -1.0351],\n",
      "        [-1.1319,  1.1760, -0.0766],\n",
      "        [ 0.6054, -0.0059, -0.9910],\n",
      "        [-1.4937,  1.8291, -0.5118],\n",
      "        [-1.5715,  0.4827,  1.0459],\n",
      "        [ 0.5288,  0.0169, -0.9970],\n",
      "        [-1.6705,  1.9662, -0.4866],\n",
      "        [-1.4035,  0.3904,  0.7845],\n",
      "        [-1.6326,  0.9219,  0.6324],\n",
      "        [ 0.6421, -0.1753, -0.8134]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.8039, -0.1927, -1.1503],\n",
      "        [-1.3283,  1.5542, -0.4308],\n",
      "        [-1.4636,  1.4113, -0.2277],\n",
      "        [-1.5966,  0.4308,  1.0654],\n",
      "        [-1.3946,  1.7923, -0.4717],\n",
      "        [-1.4066,  1.5693, -0.3897],\n",
      "        [ 0.7169, -0.1620, -1.0351],\n",
      "        [-1.1319,  1.1760, -0.0766],\n",
      "        [ 0.6054, -0.0059, -0.9910],\n",
      "        [-1.4937,  1.8291, -0.5118],\n",
      "        [-1.5715,  0.4827,  1.0459],\n",
      "        [ 0.5288,  0.0169, -0.9970],\n",
      "        [-1.6705,  1.9662, -0.4866],\n",
      "        [-1.4035,  0.3904,  0.7845],\n",
      "        [-1.6326,  0.9219,  0.6324],\n",
      "        [ 0.6421, -0.1753, -0.8134]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5671,  1.7084, -0.2822],\n",
      "        [ 0.9017, -0.1788, -0.9165],\n",
      "        [-1.7840,  0.4150,  1.0576],\n",
      "        [-1.5502,  0.4188,  1.0320],\n",
      "        [-1.6879,  1.8159, -0.2441],\n",
      "        [ 0.6381, -0.2332, -1.0288],\n",
      "        [ 0.8501, -0.1490, -1.0606],\n",
      "        [ 0.6435, -0.2112, -1.0661],\n",
      "        [-1.4142,  0.4224,  0.8363],\n",
      "        [-1.4633,  1.2162,  0.0941],\n",
      "        [-1.7123,  1.7660, -0.2512],\n",
      "        [-1.6987,  2.0610, -0.2913],\n",
      "        [-1.3855,  1.0749,  0.4411],\n",
      "        [ 0.4989,  0.0596, -0.9922],\n",
      "        [-1.6012,  0.8841,  0.6769],\n",
      "        [-1.4843,  0.7463,  0.7674]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5671,  1.7084, -0.2822],\n",
      "        [ 0.9017, -0.1788, -0.9165],\n",
      "        [-1.7840,  0.4150,  1.0576],\n",
      "        [-1.5502,  0.4188,  1.0320],\n",
      "        [-1.6879,  1.8159, -0.2441],\n",
      "        [ 0.6381, -0.2332, -1.0288],\n",
      "        [ 0.8501, -0.1490, -1.0606],\n",
      "        [ 0.6435, -0.2112, -1.0661],\n",
      "        [-1.4142,  0.4224,  0.8363],\n",
      "        [-1.4633,  1.2162,  0.0941],\n",
      "        [-1.7123,  1.7660, -0.2512],\n",
      "        [-1.6987,  2.0610, -0.2913],\n",
      "        [-1.3855,  1.0749,  0.4411],\n",
      "        [ 0.4989,  0.0596, -0.9922],\n",
      "        [-1.6012,  0.8841,  0.6769],\n",
      "        [-1.4843,  0.7463,  0.7674]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5080,  0.2918, -0.7832],\n",
      "        [-1.3903,  1.7599, -0.5258],\n",
      "        [-1.5318,  1.7638, -0.3773],\n",
      "        [-1.5321,  1.7127, -0.3207],\n",
      "        [-1.5182,  1.9905, -0.3620],\n",
      "        [ 0.4372,  0.2232, -1.0773],\n",
      "        [ 0.6893, -0.1010, -1.1229],\n",
      "        [-1.5508,  1.9823, -0.4224],\n",
      "        [-1.0506,  0.5281,  0.2776],\n",
      "        [-1.6418,  1.9268, -0.5137],\n",
      "        [-1.4095,  1.7877, -0.5039],\n",
      "        [-1.6336,  2.0154, -0.3405],\n",
      "        [-1.5563,  1.6903, -0.3312],\n",
      "        [-1.4107,  1.1404,  0.2635],\n",
      "        [-0.4391,  0.2839, -0.1601],\n",
      "        [ 0.2289,  0.2694, -0.9287]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.5080,  0.2918, -0.7832],\n",
      "        [-1.3903,  1.7599, -0.5258],\n",
      "        [-1.5318,  1.7638, -0.3773],\n",
      "        [-1.5321,  1.7127, -0.3207],\n",
      "        [-1.5182,  1.9905, -0.3620],\n",
      "        [ 0.4372,  0.2232, -1.0773],\n",
      "        [ 0.6893, -0.1010, -1.1229],\n",
      "        [-1.5508,  1.9823, -0.4224],\n",
      "        [-1.0506,  0.5281,  0.2776],\n",
      "        [-1.6418,  1.9268, -0.5137],\n",
      "        [-1.4095,  1.7877, -0.5039],\n",
      "        [-1.6336,  2.0154, -0.3405],\n",
      "        [-1.5563,  1.6903, -0.3312],\n",
      "        [-1.4107,  1.1404,  0.2635],\n",
      "        [-0.4391,  0.2839, -0.1601],\n",
      "        [ 0.2289,  0.2694, -0.9287]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8065,  0.5786,  1.1738],\n",
      "        [-1.3001,  1.6346, -0.2137],\n",
      "        [-1.4557,  0.5608,  0.6759],\n",
      "        [-1.3195,  1.3404, -0.0755],\n",
      "        [-1.0579,  1.3292, -0.5816],\n",
      "        [-1.4588,  1.3240,  0.0321],\n",
      "        [-1.5858,  1.9250, -0.3375],\n",
      "        [-1.6872,  0.6004,  0.9818],\n",
      "        [-0.7267,  0.4974,  0.0423],\n",
      "        [-1.5422,  1.1886,  0.0468],\n",
      "        [-1.6517,  1.5687,  0.0571],\n",
      "        [-1.7582,  0.4159,  1.1362],\n",
      "        [-1.6803,  1.9294, -0.4656],\n",
      "        [-1.4329,  1.4502, -0.2569],\n",
      "        [-1.6579,  1.7229, -0.4289],\n",
      "        [-1.5118,  1.7111, -0.3575]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8065,  0.5786,  1.1738],\n",
      "        [-1.3001,  1.6346, -0.2137],\n",
      "        [-1.4557,  0.5608,  0.6759],\n",
      "        [-1.3195,  1.3404, -0.0755],\n",
      "        [-1.0579,  1.3292, -0.5816],\n",
      "        [-1.4588,  1.3240,  0.0321],\n",
      "        [-1.5858,  1.9250, -0.3375],\n",
      "        [-1.6872,  0.6004,  0.9818],\n",
      "        [-0.7267,  0.4974,  0.0423],\n",
      "        [-1.5422,  1.1886,  0.0468],\n",
      "        [-1.6517,  1.5687,  0.0571],\n",
      "        [-1.7582,  0.4159,  1.1362],\n",
      "        [-1.6803,  1.9294, -0.4656],\n",
      "        [-1.4329,  1.4502, -0.2569],\n",
      "        [-1.6579,  1.7229, -0.4289],\n",
      "        [-1.5118,  1.7111, -0.3575]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6089,  1.5335,  0.0763],\n",
      "        [ 0.5815, -0.0103, -0.9066],\n",
      "        [-1.3670,  1.6096, -0.3144],\n",
      "        [-1.6741,  0.5820,  1.0193],\n",
      "        [-1.4888,  1.7409, -0.3798],\n",
      "        [-1.8732,  1.3966,  0.0983],\n",
      "        [-1.0064,  0.5473, -0.0739],\n",
      "        [-1.5261,  1.6944, -0.3232],\n",
      "        [ 0.6169, -0.2436, -1.1093],\n",
      "        [ 0.3665, -0.1115, -0.8817],\n",
      "        [-1.4731,  1.9459, -0.4118],\n",
      "        [-1.7520,  1.7987, -0.1127],\n",
      "        [-1.5439,  1.3793,  0.0751],\n",
      "        [-1.5255,  1.7280, -0.3763],\n",
      "        [-1.6804,  1.9130, -0.1272],\n",
      "        [-1.4011,  1.7201, -0.6861]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6089,  1.5335,  0.0763],\n",
      "        [ 0.5815, -0.0103, -0.9066],\n",
      "        [-1.3670,  1.6096, -0.3144],\n",
      "        [-1.6741,  0.5820,  1.0193],\n",
      "        [-1.4888,  1.7409, -0.3798],\n",
      "        [-1.8732,  1.3966,  0.0983],\n",
      "        [-1.0064,  0.5473, -0.0739],\n",
      "        [-1.5261,  1.6944, -0.3232],\n",
      "        [ 0.6169, -0.2436, -1.1093],\n",
      "        [ 0.3665, -0.1115, -0.8817],\n",
      "        [-1.4731,  1.9459, -0.4118],\n",
      "        [-1.7520,  1.7987, -0.1127],\n",
      "        [-1.5439,  1.3793,  0.0751],\n",
      "        [-1.5255,  1.7280, -0.3763],\n",
      "        [-1.6804,  1.9130, -0.1272],\n",
      "        [-1.4011,  1.7201, -0.6861]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6876,  0.7235,  0.8723],\n",
      "        [-1.7339,  1.4474,  0.1040],\n",
      "        [-1.6630,  1.7818, -0.2214],\n",
      "        [-1.3896,  1.5481, -0.1955],\n",
      "        [-1.7964,  2.0319, -0.6756],\n",
      "        [-1.5754,  1.4030,  0.3039],\n",
      "        [ 0.5670,  0.0912, -0.9198],\n",
      "        [-1.5918,  1.9792, -0.4765],\n",
      "        [-1.6475,  1.6918,  0.0048],\n",
      "        [ 0.7656, -0.1237, -1.1646],\n",
      "        [-1.6956,  1.4389, -0.0309],\n",
      "        [-1.5333,  1.7980, -0.4542],\n",
      "        [-1.7964,  0.3429,  1.0754],\n",
      "        [-1.4613,  2.0164, -0.3351],\n",
      "        [-1.7341,  1.9386, -0.2760],\n",
      "        [-1.8373,  1.9801, -0.4247]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6876,  0.7235,  0.8723],\n",
      "        [-1.7339,  1.4474,  0.1040],\n",
      "        [-1.6630,  1.7818, -0.2214],\n",
      "        [-1.3896,  1.5481, -0.1955],\n",
      "        [-1.7964,  2.0319, -0.6756],\n",
      "        [-1.5754,  1.4030,  0.3039],\n",
      "        [ 0.5670,  0.0912, -0.9198],\n",
      "        [-1.5918,  1.9792, -0.4765],\n",
      "        [-1.6475,  1.6918,  0.0048],\n",
      "        [ 0.7656, -0.1237, -1.1646],\n",
      "        [-1.6956,  1.4389, -0.0309],\n",
      "        [-1.5333,  1.7980, -0.4542],\n",
      "        [-1.7964,  0.3429,  1.0754],\n",
      "        [-1.4613,  2.0164, -0.3351],\n",
      "        [-1.7341,  1.9386, -0.2760],\n",
      "        [-1.8373,  1.9801, -0.4247]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6500,  1.8810, -0.2811],\n",
      "        [-1.7712,  2.0845, -0.3382],\n",
      "        [-1.1787,  1.4976, -0.5893],\n",
      "        [-1.8242,  2.0132, -0.1290],\n",
      "        [ 0.5607,  0.0926, -1.1884],\n",
      "        [-1.8991,  0.5180,  1.3642],\n",
      "        [-1.8924,  1.9114, -0.3484],\n",
      "        [-1.7780,  2.1515, -0.4486],\n",
      "        [-1.6223,  1.8569, -0.0375],\n",
      "        [-1.7112,  0.4525,  1.0046],\n",
      "        [ 0.7630, -0.1574, -1.1166],\n",
      "        [-0.7294,  0.8234, -0.7114],\n",
      "        [-1.6484,  1.5502,  0.2080],\n",
      "        [-1.7164,  1.8377, -0.3464],\n",
      "        [-1.8207,  0.2941,  0.9730],\n",
      "        [ 0.3020,  0.2974, -1.0670]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6500,  1.8810, -0.2811],\n",
      "        [-1.7712,  2.0845, -0.3382],\n",
      "        [-1.1787,  1.4976, -0.5893],\n",
      "        [-1.8242,  2.0132, -0.1290],\n",
      "        [ 0.5607,  0.0926, -1.1884],\n",
      "        [-1.8991,  0.5180,  1.3642],\n",
      "        [-1.8924,  1.9114, -0.3484],\n",
      "        [-1.7780,  2.1515, -0.4486],\n",
      "        [-1.6223,  1.8569, -0.0375],\n",
      "        [-1.7112,  0.4525,  1.0046],\n",
      "        [ 0.7630, -0.1574, -1.1166],\n",
      "        [-0.7294,  0.8234, -0.7114],\n",
      "        [-1.6484,  1.5502,  0.2080],\n",
      "        [-1.7164,  1.8377, -0.3464],\n",
      "        [-1.8207,  0.2941,  0.9730],\n",
      "        [ 0.3020,  0.2974, -1.0670]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8207,  2.1766, -0.3122],\n",
      "        [ 0.3410,  0.3166, -1.2471],\n",
      "        [-1.6127,  1.8059, -0.5151],\n",
      "        [-1.8391,  2.0600, -0.4975],\n",
      "        [-1.9724,  1.0774,  0.6136],\n",
      "        [-1.8534,  0.5692,  1.1380],\n",
      "        [ 0.6064,  0.0177, -1.2158],\n",
      "        [-1.9445,  1.7625, -0.1130],\n",
      "        [-1.8157,  2.0740, -0.3229],\n",
      "        [-1.8132,  2.0032, -0.0675],\n",
      "        [-1.9307,  1.1214,  0.6198],\n",
      "        [-2.0204,  2.1297, -0.5654],\n",
      "        [-1.8345,  0.9209,  0.7634],\n",
      "        [-1.8086,  1.3150,  0.1809],\n",
      "        [-1.7163,  2.2443, -0.5848],\n",
      "        [-1.9531,  1.4376,  0.4195]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8207,  2.1766, -0.3122],\n",
      "        [ 0.3410,  0.3166, -1.2471],\n",
      "        [-1.6127,  1.8059, -0.5151],\n",
      "        [-1.8391,  2.0600, -0.4975],\n",
      "        [-1.9724,  1.0774,  0.6136],\n",
      "        [-1.8534,  0.5692,  1.1380],\n",
      "        [ 0.6064,  0.0177, -1.2158],\n",
      "        [-1.9445,  1.7625, -0.1130],\n",
      "        [-1.8157,  2.0740, -0.3229],\n",
      "        [-1.8132,  2.0032, -0.0675],\n",
      "        [-1.9307,  1.1214,  0.6198],\n",
      "        [-2.0204,  2.1297, -0.5654],\n",
      "        [-1.8345,  0.9209,  0.7634],\n",
      "        [-1.8086,  1.3150,  0.1809],\n",
      "        [-1.7163,  2.2443, -0.5848],\n",
      "        [-1.9531,  1.4376,  0.4195]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9668,  0.6298,  1.2886],\n",
      "        [-1.8843,  2.2780, -0.4539],\n",
      "        [-1.5761,  1.7709,  0.0079],\n",
      "        [-1.7318,  1.0106,  0.4099],\n",
      "        [-1.6627,  0.5497,  0.9678],\n",
      "        [-1.7832,  0.7301,  0.9641],\n",
      "        [-1.7954,  0.8018,  0.7312],\n",
      "        [-2.1447,  1.5855,  0.2379],\n",
      "        [-1.6714,  0.5623,  1.0130],\n",
      "        [-1.6370,  0.6991,  1.0335],\n",
      "        [-1.9241,  2.3286, -0.2539],\n",
      "        [-1.6630,  0.8402,  1.2545],\n",
      "        [-1.7444,  0.8629,  0.7208],\n",
      "        [-1.6912,  1.3977,  0.2204],\n",
      "        [-1.7201,  2.0459, -0.4019],\n",
      "        [-1.7545,  0.5466,  1.1286]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9668,  0.6298,  1.2886],\n",
      "        [-1.8843,  2.2780, -0.4539],\n",
      "        [-1.5761,  1.7709,  0.0079],\n",
      "        [-1.7318,  1.0106,  0.4099],\n",
      "        [-1.6627,  0.5497,  0.9678],\n",
      "        [-1.7832,  0.7301,  0.9641],\n",
      "        [-1.7954,  0.8018,  0.7312],\n",
      "        [-2.1447,  1.5855,  0.2379],\n",
      "        [-1.6714,  0.5623,  1.0130],\n",
      "        [-1.6370,  0.6991,  1.0335],\n",
      "        [-1.9241,  2.3286, -0.2539],\n",
      "        [-1.6630,  0.8402,  1.2545],\n",
      "        [-1.7444,  0.8629,  0.7208],\n",
      "        [-1.6912,  1.3977,  0.2204],\n",
      "        [-1.7201,  2.0459, -0.4019],\n",
      "        [-1.7545,  0.5466,  1.1286]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9491,  1.9294,  0.1814],\n",
      "        [-1.7947,  0.3566,  1.2900],\n",
      "        [-1.9408,  2.3319, -0.4492],\n",
      "        [-1.7597,  1.7471, -0.2486],\n",
      "        [ 0.6276, -0.0165, -1.1206],\n",
      "        [-1.9773,  1.1452,  0.7318],\n",
      "        [-2.1344,  2.4958, -0.3244],\n",
      "        [-1.9630,  1.0593,  0.7103],\n",
      "        [-1.9211,  0.5447,  1.0300],\n",
      "        [-1.7597,  2.4080, -0.4631],\n",
      "        [-1.9407,  1.7691, -0.3092],\n",
      "        [-2.1477,  2.1110, -0.1361],\n",
      "        [-1.8159,  0.7567,  0.8596],\n",
      "        [-2.0827,  2.3447, -0.2960],\n",
      "        [-1.6425,  1.9595, -0.6143],\n",
      "        [-1.7737,  2.2532, -0.4818]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9491,  1.9294,  0.1814],\n",
      "        [-1.7947,  0.3566,  1.2900],\n",
      "        [-1.9408,  2.3319, -0.4492],\n",
      "        [-1.7597,  1.7471, -0.2486],\n",
      "        [ 0.6276, -0.0165, -1.1206],\n",
      "        [-1.9773,  1.1452,  0.7318],\n",
      "        [-2.1344,  2.4958, -0.3244],\n",
      "        [-1.9630,  1.0593,  0.7103],\n",
      "        [-1.9211,  0.5447,  1.0300],\n",
      "        [-1.7597,  2.4080, -0.4631],\n",
      "        [-1.9407,  1.7691, -0.3092],\n",
      "        [-2.1477,  2.1110, -0.1361],\n",
      "        [-1.8159,  0.7567,  0.8596],\n",
      "        [-2.0827,  2.3447, -0.2960],\n",
      "        [-1.6425,  1.9595, -0.6143],\n",
      "        [-1.7737,  2.2532, -0.4818]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8641,  0.9141,  0.9778],\n",
      "        [ 0.5147, -0.1086, -1.1776],\n",
      "        [-1.8528,  1.9191,  0.0211],\n",
      "        [-1.8233,  1.4728,  0.1179],\n",
      "        [-1.9090,  1.9558, -0.4669],\n",
      "        [-1.7383,  1.8430, -0.5229],\n",
      "        [-1.6478,  1.1091,  0.4232],\n",
      "        [-1.9195,  0.5703,  1.0206],\n",
      "        [-1.7770,  2.0252, -0.1762],\n",
      "        [-1.7379,  0.6128,  1.0086],\n",
      "        [-1.7610,  1.7332,  0.0596],\n",
      "        [-1.7573,  1.0668,  0.6957],\n",
      "        [-1.7391,  0.5350,  1.2104],\n",
      "        [-1.7291,  0.5806,  1.0721],\n",
      "        [ 0.5501, -0.0112, -1.1210],\n",
      "        [-2.1065,  1.1185,  0.5113]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8641,  0.9141,  0.9778],\n",
      "        [ 0.5147, -0.1086, -1.1776],\n",
      "        [-1.8528,  1.9191,  0.0211],\n",
      "        [-1.8233,  1.4728,  0.1179],\n",
      "        [-1.9090,  1.9558, -0.4669],\n",
      "        [-1.7383,  1.8430, -0.5229],\n",
      "        [-1.6478,  1.1091,  0.4232],\n",
      "        [-1.9195,  0.5703,  1.0206],\n",
      "        [-1.7770,  2.0252, -0.1762],\n",
      "        [-1.7379,  0.6128,  1.0086],\n",
      "        [-1.7610,  1.7332,  0.0596],\n",
      "        [-1.7573,  1.0668,  0.6957],\n",
      "        [-1.7391,  0.5350,  1.2104],\n",
      "        [-1.7291,  0.5806,  1.0721],\n",
      "        [ 0.5501, -0.0112, -1.1210],\n",
      "        [-2.1065,  1.1185,  0.5113]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9735,  0.6236,  1.0674],\n",
      "        [-1.9541,  1.9232, -0.4994],\n",
      "        [-1.9374,  0.9563,  0.7539],\n",
      "        [-1.7051,  2.0096, -0.3315],\n",
      "        [-1.8848,  0.7851,  1.1022],\n",
      "        [ 0.7814, -0.2405, -1.1767],\n",
      "        [-1.8904,  1.7222, -0.0358],\n",
      "        [-1.9245,  0.6369,  0.9842],\n",
      "        [ 0.7246,  0.0282, -1.3488],\n",
      "        [-1.9557,  1.0236,  0.9678],\n",
      "        [-1.9228,  0.5350,  1.1890],\n",
      "        [ 0.6348,  0.0335, -1.2176],\n",
      "        [ 0.9124, -0.1193, -1.0237],\n",
      "        [-1.9363,  0.4751,  1.2850],\n",
      "        [-1.7275,  2.0069, -0.4085],\n",
      "        [-1.4588,  1.6994, -0.3921]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9735,  0.6236,  1.0674],\n",
      "        [-1.9541,  1.9232, -0.4994],\n",
      "        [-1.9374,  0.9563,  0.7539],\n",
      "        [-1.7051,  2.0096, -0.3315],\n",
      "        [-1.8848,  0.7851,  1.1022],\n",
      "        [ 0.7814, -0.2405, -1.1767],\n",
      "        [-1.8904,  1.7222, -0.0358],\n",
      "        [-1.9245,  0.6369,  0.9842],\n",
      "        [ 0.7246,  0.0282, -1.3488],\n",
      "        [-1.9557,  1.0236,  0.9678],\n",
      "        [-1.9228,  0.5350,  1.1890],\n",
      "        [ 0.6348,  0.0335, -1.2176],\n",
      "        [ 0.9124, -0.1193, -1.0237],\n",
      "        [-1.9363,  0.4751,  1.2850],\n",
      "        [-1.7275,  2.0069, -0.4085],\n",
      "        [-1.4588,  1.6994, -0.3921]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2292,  1.6123,  0.6995],\n",
      "        [-2.3656,  1.0969,  0.8342],\n",
      "        [-0.7607,  1.1739, -0.8377],\n",
      "        [-1.5628,  1.2535,  0.0679],\n",
      "        [-0.5718,  1.2267, -1.0460],\n",
      "        [-1.9926,  2.1183, -0.2132],\n",
      "        [-1.9328,  1.4695,  0.3834],\n",
      "        [-2.0004,  1.1305,  0.6354],\n",
      "        [ 0.2898,  0.1989, -1.0716],\n",
      "        [-1.9934,  1.6592,  0.3426],\n",
      "        [-1.9734,  1.9200, -0.0235],\n",
      "        [-1.7115,  0.3966,  1.1890],\n",
      "        [ 0.1728,  0.2345, -1.1292],\n",
      "        [-1.9989,  0.4961,  1.3857],\n",
      "        [-1.7242,  1.8647, -0.0138],\n",
      "        [-2.0545,  1.8180, -0.1053]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.2292,  1.6123,  0.6995],\n",
      "        [-2.3656,  1.0969,  0.8342],\n",
      "        [-0.7607,  1.1739, -0.8377],\n",
      "        [-1.5628,  1.2535,  0.0679],\n",
      "        [-0.5718,  1.2267, -1.0460],\n",
      "        [-1.9926,  2.1183, -0.2132],\n",
      "        [-1.9328,  1.4695,  0.3834],\n",
      "        [-2.0004,  1.1305,  0.6354],\n",
      "        [ 0.2898,  0.1989, -1.0716],\n",
      "        [-1.9934,  1.6592,  0.3426],\n",
      "        [-1.9734,  1.9200, -0.0235],\n",
      "        [-1.7115,  0.3966,  1.1890],\n",
      "        [ 0.1728,  0.2345, -1.1292],\n",
      "        [-1.9989,  0.4961,  1.3857],\n",
      "        [-1.7242,  1.8647, -0.0138],\n",
      "        [-2.0545,  1.8180, -0.1053]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1170,  2.1902, -0.4607],\n",
      "        [-2.0577,  1.4811,  0.1394],\n",
      "        [-1.8924,  2.0659, -0.3826],\n",
      "        [-2.0476,  2.0799, -0.0854],\n",
      "        [-1.9935,  2.0835, -0.2457],\n",
      "        [-2.0727,  2.0042,  0.1120],\n",
      "        [-2.0580,  0.7653,  1.2203],\n",
      "        [-2.2585,  2.0322, -0.0536],\n",
      "        [-1.7531,  1.8357, -0.0561],\n",
      "        [ 0.3319,  0.3723, -1.2516],\n",
      "        [-2.1214,  2.1723, -0.3182],\n",
      "        [-2.0319,  1.8940, -0.2828],\n",
      "        [-2.2809,  0.4702,  1.4819],\n",
      "        [-1.8600,  2.0046, -0.1793],\n",
      "        [-1.7956,  2.3206, -0.2998],\n",
      "        [-1.9236,  1.9590, -0.2244]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.1170,  2.1902, -0.4607],\n",
      "        [-2.0577,  1.4811,  0.1394],\n",
      "        [-1.8924,  2.0659, -0.3826],\n",
      "        [-2.0476,  2.0799, -0.0854],\n",
      "        [-1.9935,  2.0835, -0.2457],\n",
      "        [-2.0727,  2.0042,  0.1120],\n",
      "        [-2.0580,  0.7653,  1.2203],\n",
      "        [-2.2585,  2.0322, -0.0536],\n",
      "        [-1.7531,  1.8357, -0.0561],\n",
      "        [ 0.3319,  0.3723, -1.2516],\n",
      "        [-2.1214,  2.1723, -0.3182],\n",
      "        [-2.0319,  1.8940, -0.2828],\n",
      "        [-2.2809,  0.4702,  1.4819],\n",
      "        [-1.8600,  2.0046, -0.1793],\n",
      "        [-1.7956,  2.3206, -0.2998],\n",
      "        [-1.9236,  1.9590, -0.2244]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.4775,  0.1040, -1.2240],\n",
      "        [-1.9517,  0.6065,  1.3460],\n",
      "        [-2.1107,  2.0184, -0.1848],\n",
      "        [-1.8237,  1.8923, -0.0025],\n",
      "        [-1.9402,  2.0196, -0.1095],\n",
      "        [-1.8982,  1.8560, -0.0334],\n",
      "        [-1.9596,  1.9899, -0.0247],\n",
      "        [-2.1070,  2.1608, -0.5008],\n",
      "        [-1.9532,  0.4775,  1.3200],\n",
      "        [-1.8672,  2.0747, -0.1959],\n",
      "        [-2.2002,  1.6776,  0.4746],\n",
      "        [-1.8834,  0.8257,  0.7013],\n",
      "        [-2.0334,  0.8546,  1.1672],\n",
      "        [-1.9172,  1.0001,  0.7898],\n",
      "        [ 0.7132,  0.0562, -1.2556],\n",
      "        [-2.0107,  1.8836, -0.2480]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.4775,  0.1040, -1.2240],\n",
      "        [-1.9517,  0.6065,  1.3460],\n",
      "        [-2.1107,  2.0184, -0.1848],\n",
      "        [-1.8237,  1.8923, -0.0025],\n",
      "        [-1.9402,  2.0196, -0.1095],\n",
      "        [-1.8982,  1.8560, -0.0334],\n",
      "        [-1.9596,  1.9899, -0.0247],\n",
      "        [-2.1070,  2.1608, -0.5008],\n",
      "        [-1.9532,  0.4775,  1.3200],\n",
      "        [-1.8672,  2.0747, -0.1959],\n",
      "        [-2.2002,  1.6776,  0.4746],\n",
      "        [-1.8834,  0.8257,  0.7013],\n",
      "        [-2.0334,  0.8546,  1.1672],\n",
      "        [-1.9172,  1.0001,  0.7898],\n",
      "        [ 0.7132,  0.0562, -1.2556],\n",
      "        [-2.0107,  1.8836, -0.2480]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0699,  1.6010,  0.0027],\n",
      "        [-2.0452,  0.5150,  1.2269],\n",
      "        [-1.7279,  0.5040,  0.9272],\n",
      "        [-2.0503,  2.3329, -0.1930],\n",
      "        [-1.8678,  1.8877, -0.1048],\n",
      "        [-1.8468,  1.7860,  0.2894],\n",
      "        [-2.1027,  1.8676, -0.1990],\n",
      "        [-1.9707,  0.6386,  1.3421],\n",
      "        [-1.8293,  1.5787,  0.2258],\n",
      "        [-1.8046,  0.7213,  1.0999],\n",
      "        [-1.9970,  1.8764, -0.2013],\n",
      "        [-1.9795,  1.9785, -0.1175],\n",
      "        [-2.1784,  1.8793, -0.0616],\n",
      "        [-2.1630,  1.1568,  0.5844],\n",
      "        [-2.0654,  1.6018,  0.4898],\n",
      "        [-2.2817,  0.9603,  0.9650]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.0699,  1.6010,  0.0027],\n",
      "        [-2.0452,  0.5150,  1.2269],\n",
      "        [-1.7279,  0.5040,  0.9272],\n",
      "        [-2.0503,  2.3329, -0.1930],\n",
      "        [-1.8678,  1.8877, -0.1048],\n",
      "        [-1.8468,  1.7860,  0.2894],\n",
      "        [-2.1027,  1.8676, -0.1990],\n",
      "        [-1.9707,  0.6386,  1.3421],\n",
      "        [-1.8293,  1.5787,  0.2258],\n",
      "        [-1.8046,  0.7213,  1.0999],\n",
      "        [-1.9970,  1.8764, -0.2013],\n",
      "        [-1.9795,  1.9785, -0.1175],\n",
      "        [-2.1784,  1.8793, -0.0616],\n",
      "        [-2.1630,  1.1568,  0.5844],\n",
      "        [-2.0654,  1.6018,  0.4898],\n",
      "        [-2.2817,  0.9603,  0.9650]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.0542,  0.5864, -1.1789],\n",
      "        [-2.0303,  1.9518,  0.1649],\n",
      "        [-1.9631,  0.8432,  0.8595],\n",
      "        [-2.0901,  2.0665, -0.3278],\n",
      "        [-1.9257,  2.2320, -0.2800],\n",
      "        [-2.3267,  2.3315,  0.0660],\n",
      "        [-2.1915,  2.2310, -0.0227],\n",
      "        [-1.8409,  0.7775,  1.3181],\n",
      "        [ 0.7533, -0.2509, -1.1474],\n",
      "        [-1.9777,  1.6873,  0.0610],\n",
      "        [ 0.5789,  0.0743, -1.0745],\n",
      "        [-2.2949,  1.8458,  0.4408],\n",
      "        [-2.0013,  1.8812, -0.0947],\n",
      "        [-2.1249,  0.5657,  1.2163],\n",
      "        [-1.9912,  1.5608,  0.0917],\n",
      "        [-2.1829,  0.4015,  0.9998]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-0.0542,  0.5864, -1.1789],\n",
      "        [-2.0303,  1.9518,  0.1649],\n",
      "        [-1.9631,  0.8432,  0.8595],\n",
      "        [-2.0901,  2.0665, -0.3278],\n",
      "        [-1.9257,  2.2320, -0.2800],\n",
      "        [-2.3267,  2.3315,  0.0660],\n",
      "        [-2.1915,  2.2310, -0.0227],\n",
      "        [-1.8409,  0.7775,  1.3181],\n",
      "        [ 0.7533, -0.2509, -1.1474],\n",
      "        [-1.9777,  1.6873,  0.0610],\n",
      "        [ 0.5789,  0.0743, -1.0745],\n",
      "        [-2.2949,  1.8458,  0.4408],\n",
      "        [-2.0013,  1.8812, -0.0947],\n",
      "        [-2.1249,  0.5657,  1.2163],\n",
      "        [-1.9912,  1.5608,  0.0917],\n",
      "        [-2.1829,  0.4015,  0.9998]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1234,  1.9841, -0.0132],\n",
      "        [-2.1560,  0.6066,  1.2508],\n",
      "        [ 0.5989,  0.2888, -1.1512],\n",
      "        [ 0.0647,  0.2929, -0.9637],\n",
      "        [-2.1680,  2.1275, -0.1429],\n",
      "        [-2.2184,  1.3719,  0.5643],\n",
      "        [-1.9026,  0.6169,  1.1091],\n",
      "        [-2.0942,  1.3316,  0.5197],\n",
      "        [-1.9421,  2.0990, -0.3341],\n",
      "        [-2.0466,  1.2152,  0.7401],\n",
      "        [-2.1308,  2.0961, -0.3190],\n",
      "        [-2.2153,  2.2341, -0.1613],\n",
      "        [-2.0693,  1.3062,  0.0132],\n",
      "        [-2.0719,  2.1492, -0.3356],\n",
      "        [-2.2321,  0.8349,  1.0973],\n",
      "        [-1.9965,  2.2063, -0.0985]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.1234,  1.9841, -0.0132],\n",
      "        [-2.1560,  0.6066,  1.2508],\n",
      "        [ 0.5989,  0.2888, -1.1512],\n",
      "        [ 0.0647,  0.2929, -0.9637],\n",
      "        [-2.1680,  2.1275, -0.1429],\n",
      "        [-2.2184,  1.3719,  0.5643],\n",
      "        [-1.9026,  0.6169,  1.1091],\n",
      "        [-2.0942,  1.3316,  0.5197],\n",
      "        [-1.9421,  2.0990, -0.3341],\n",
      "        [-2.0466,  1.2152,  0.7401],\n",
      "        [-2.1308,  2.0961, -0.3190],\n",
      "        [-2.2153,  2.2341, -0.1613],\n",
      "        [-2.0693,  1.3062,  0.0132],\n",
      "        [-2.0719,  2.1492, -0.3356],\n",
      "        [-2.2321,  0.8349,  1.0973],\n",
      "        [-1.9965,  2.2063, -0.0985]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0966,  2.2229, -0.3478],\n",
      "        [ 0.5151,  0.1312, -1.1714],\n",
      "        [-1.8466,  2.0661, -0.4124],\n",
      "        [-2.1629,  1.4212,  0.6910],\n",
      "        [-1.9098,  2.1128, -0.1877],\n",
      "        [-1.4013,  1.9152, -0.7539],\n",
      "        [-2.0215,  1.8646,  0.3940],\n",
      "        [-1.9599,  2.1715,  0.0321],\n",
      "        [-1.8614,  1.8106,  0.2005],\n",
      "        [-2.0278,  1.0041,  0.5946],\n",
      "        [ 0.6655, -0.0124, -0.9777],\n",
      "        [-2.0850,  1.9112,  0.0707],\n",
      "        [-2.0327,  1.8603, -0.0175],\n",
      "        [-2.1276,  2.2307, -0.3067],\n",
      "        [-1.8221,  0.7383,  1.0536],\n",
      "        [ 0.3979,  0.0599, -0.9285]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.0966,  2.2229, -0.3478],\n",
      "        [ 0.5151,  0.1312, -1.1714],\n",
      "        [-1.8466,  2.0661, -0.4124],\n",
      "        [-2.1629,  1.4212,  0.6910],\n",
      "        [-1.9098,  2.1128, -0.1877],\n",
      "        [-1.4013,  1.9152, -0.7539],\n",
      "        [-2.0215,  1.8646,  0.3940],\n",
      "        [-1.9599,  2.1715,  0.0321],\n",
      "        [-1.8614,  1.8106,  0.2005],\n",
      "        [-2.0278,  1.0041,  0.5946],\n",
      "        [ 0.6655, -0.0124, -0.9777],\n",
      "        [-2.0850,  1.9112,  0.0707],\n",
      "        [-2.0327,  1.8603, -0.0175],\n",
      "        [-2.1276,  2.2307, -0.3067],\n",
      "        [-1.8221,  0.7383,  1.0536],\n",
      "        [ 0.3979,  0.0599, -0.9285]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1278,  2.2138, -0.1600],\n",
      "        [-2.2351,  2.1976, -0.2771],\n",
      "        [ 0.4400, -0.1867, -1.1980],\n",
      "        [-2.2606,  1.8608,  0.2750],\n",
      "        [-2.4362,  2.0534,  0.1828],\n",
      "        [-1.9982,  2.0802, -0.3131],\n",
      "        [-1.9566,  1.9898, -0.0548],\n",
      "        [-2.3283,  2.2405, -0.0522],\n",
      "        [ 0.6022, -0.1210, -1.1503],\n",
      "        [-2.2009,  2.2058,  0.1559],\n",
      "        [-2.1701,  0.6887,  1.2832],\n",
      "        [-2.4474,  2.1316, -0.2336],\n",
      "        [-2.2578,  0.7108,  1.1962],\n",
      "        [-2.2526,  1.9698, -0.1274],\n",
      "        [-2.0763,  2.0975, -0.3042],\n",
      "        [ 0.9512, -0.1556, -1.2645]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.1278,  2.2138, -0.1600],\n",
      "        [-2.2351,  2.1976, -0.2771],\n",
      "        [ 0.4400, -0.1867, -1.1980],\n",
      "        [-2.2606,  1.8608,  0.2750],\n",
      "        [-2.4362,  2.0534,  0.1828],\n",
      "        [-1.9982,  2.0802, -0.3131],\n",
      "        [-1.9566,  1.9898, -0.0548],\n",
      "        [-2.3283,  2.2405, -0.0522],\n",
      "        [ 0.6022, -0.1210, -1.1503],\n",
      "        [-2.2009,  2.2058,  0.1559],\n",
      "        [-2.1701,  0.6887,  1.2832],\n",
      "        [-2.4474,  2.1316, -0.2336],\n",
      "        [-2.2578,  0.7108,  1.1962],\n",
      "        [-2.2526,  1.9698, -0.1274],\n",
      "        [-2.0763,  2.0975, -0.3042],\n",
      "        [ 0.9512, -0.1556, -1.2645]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0461,  1.8873, -0.0364],\n",
      "        [ 0.5654, -0.0161, -1.1706],\n",
      "        [-2.4040,  2.1617,  0.0133],\n",
      "        [-2.2205,  1.4452,  0.3742],\n",
      "        [-1.9424,  2.1596, -0.3335],\n",
      "        [ 0.3149,  0.1999, -1.0837],\n",
      "        [-2.2971,  2.0980, -0.1576],\n",
      "        [-2.0962,  2.2517, -0.1459],\n",
      "        [-1.9324,  2.1573, -0.4309],\n",
      "        [-2.1800,  1.8267, -0.0452],\n",
      "        [-2.1021,  2.2626, -0.2007],\n",
      "        [-2.1163,  0.6493,  1.1058],\n",
      "        [-1.9682,  2.1943, -0.5442],\n",
      "        [-2.0089,  1.4936,  0.2800],\n",
      "        [-1.8543,  1.9950, -0.0846],\n",
      "        [-2.0088,  0.5582,  1.0771]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.0461,  1.8873, -0.0364],\n",
      "        [ 0.5654, -0.0161, -1.1706],\n",
      "        [-2.4040,  2.1617,  0.0133],\n",
      "        [-2.2205,  1.4452,  0.3742],\n",
      "        [-1.9424,  2.1596, -0.3335],\n",
      "        [ 0.3149,  0.1999, -1.0837],\n",
      "        [-2.2971,  2.0980, -0.1576],\n",
      "        [-2.0962,  2.2517, -0.1459],\n",
      "        [-1.9324,  2.1573, -0.4309],\n",
      "        [-2.1800,  1.8267, -0.0452],\n",
      "        [-2.1021,  2.2626, -0.2007],\n",
      "        [-2.1163,  0.6493,  1.1058],\n",
      "        [-1.9682,  2.1943, -0.5442],\n",
      "        [-2.0089,  1.4936,  0.2800],\n",
      "        [-1.8543,  1.9950, -0.0846],\n",
      "        [-2.0088,  0.5582,  1.0771]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2311,  2.2924, -0.0979],\n",
      "        [-2.1339,  1.1902,  0.8105],\n",
      "        [-2.1072,  1.8472, -0.0532],\n",
      "        [-2.1660,  1.7961,  0.3066],\n",
      "        [-1.8965,  2.1118, -0.0910],\n",
      "        [-1.9602,  1.7418,  0.1977],\n",
      "        [-2.1132,  1.0653,  0.7909],\n",
      "        [ 0.5655,  0.2005, -1.0329],\n",
      "        [-1.9815,  2.0200,  0.1004],\n",
      "        [-2.3077,  1.2203,  0.7309],\n",
      "        [-2.2247,  2.1043, -0.2468],\n",
      "        [-2.4094,  1.7049,  0.2608],\n",
      "        [-2.1585,  2.0884, -0.0328],\n",
      "        [-2.2957,  1.2068,  0.8818],\n",
      "        [-2.4039,  2.5237, -0.0969],\n",
      "        [-2.1418,  2.2364, -0.2148]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.2311,  2.2924, -0.0979],\n",
      "        [-2.1339,  1.1902,  0.8105],\n",
      "        [-2.1072,  1.8472, -0.0532],\n",
      "        [-2.1660,  1.7961,  0.3066],\n",
      "        [-1.8965,  2.1118, -0.0910],\n",
      "        [-1.9602,  1.7418,  0.1977],\n",
      "        [-2.1132,  1.0653,  0.7909],\n",
      "        [ 0.5655,  0.2005, -1.0329],\n",
      "        [-1.9815,  2.0200,  0.1004],\n",
      "        [-2.3077,  1.2203,  0.7309],\n",
      "        [-2.2247,  2.1043, -0.2468],\n",
      "        [-2.4094,  1.7049,  0.2608],\n",
      "        [-2.1585,  2.0884, -0.0328],\n",
      "        [-2.2957,  1.2068,  0.8818],\n",
      "        [-2.4039,  2.5237, -0.0969],\n",
      "        [-2.1418,  2.2364, -0.2148]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0514,  0.6662,  1.1864],\n",
      "        [-2.1052,  0.8191,  1.1464],\n",
      "        [-2.1782,  1.4664,  0.5983],\n",
      "        [-1.8814,  1.4883,  0.2837],\n",
      "        [-1.9664,  1.9789, -0.0793],\n",
      "        [-2.2037,  2.2837, -0.0764],\n",
      "        [-2.0827,  0.9767,  1.1097],\n",
      "        [-2.0337,  0.8569,  1.1035],\n",
      "        [-1.9473,  0.9536,  0.9050],\n",
      "        [-2.1211,  1.1948,  0.6980],\n",
      "        [-2.2588,  1.8803,  0.5365],\n",
      "        [-1.9671,  2.0398, -0.6185],\n",
      "        [-2.1604,  2.2070, -0.3986],\n",
      "        [-2.0854,  2.1482, -0.2190],\n",
      "        [-2.1742,  0.8104,  1.0711],\n",
      "        [-2.2619,  2.3461, -0.3685]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.0514,  0.6662,  1.1864],\n",
      "        [-2.1052,  0.8191,  1.1464],\n",
      "        [-2.1782,  1.4664,  0.5983],\n",
      "        [-1.8814,  1.4883,  0.2837],\n",
      "        [-1.9664,  1.9789, -0.0793],\n",
      "        [-2.2037,  2.2837, -0.0764],\n",
      "        [-2.0827,  0.9767,  1.1097],\n",
      "        [-2.0337,  0.8569,  1.1035],\n",
      "        [-1.9473,  0.9536,  0.9050],\n",
      "        [-2.1211,  1.1948,  0.6980],\n",
      "        [-2.2588,  1.8803,  0.5365],\n",
      "        [-1.9671,  2.0398, -0.6185],\n",
      "        [-2.1604,  2.2070, -0.3986],\n",
      "        [-2.0854,  2.1482, -0.2190],\n",
      "        [-2.1742,  0.8104,  1.0711],\n",
      "        [-2.2619,  2.3461, -0.3685]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9139,  2.3562, -0.3512],\n",
      "        [-1.9667,  1.8563,  0.0505],\n",
      "        [-1.9987,  2.1860, -0.2676],\n",
      "        [-0.6239,  0.4432, -0.2084],\n",
      "        [-2.2130,  1.2175,  0.8662],\n",
      "        [-2.0642,  1.9791, -0.0683],\n",
      "        [ 0.1922,  0.3218, -1.3173],\n",
      "        [-2.1448,  1.4505,  0.5662],\n",
      "        [-2.0784,  2.1678, -0.3641],\n",
      "        [-2.2039,  1.1320,  0.9414],\n",
      "        [-1.8273,  1.8800, -0.6838],\n",
      "        [-2.1827,  0.7395,  1.2455],\n",
      "        [-1.8658,  2.0844, -0.4931],\n",
      "        [-1.7452,  1.1743,  0.2445],\n",
      "        [-2.0302,  0.9575,  0.8273],\n",
      "        [-2.0712,  1.9055,  0.1502]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9139,  2.3562, -0.3512],\n",
      "        [-1.9667,  1.8563,  0.0505],\n",
      "        [-1.9987,  2.1860, -0.2676],\n",
      "        [-0.6239,  0.4432, -0.2084],\n",
      "        [-2.2130,  1.2175,  0.8662],\n",
      "        [-2.0642,  1.9791, -0.0683],\n",
      "        [ 0.1922,  0.3218, -1.3173],\n",
      "        [-2.1448,  1.4505,  0.5662],\n",
      "        [-2.0784,  2.1678, -0.3641],\n",
      "        [-2.2039,  1.1320,  0.9414],\n",
      "        [-1.8273,  1.8800, -0.6838],\n",
      "        [-2.1827,  0.7395,  1.2455],\n",
      "        [-1.8658,  2.0844, -0.4931],\n",
      "        [-1.7452,  1.1743,  0.2445],\n",
      "        [-2.0302,  0.9575,  0.8273],\n",
      "        [-2.0712,  1.9055,  0.1502]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8872,  2.0606, -0.3291],\n",
      "        [-1.8652,  1.8234, -0.1162],\n",
      "        [-1.9690,  2.1481, -0.5070],\n",
      "        [-2.0818,  1.3793,  0.6021],\n",
      "        [-2.3498,  1.5257,  0.3367],\n",
      "        [-1.8268,  1.6793,  0.0298],\n",
      "        [-2.0159,  1.7237,  0.2037],\n",
      "        [-1.9626,  1.4966,  0.3514],\n",
      "        [-2.0640,  1.0937,  0.9625],\n",
      "        [-1.8647,  2.1453, -0.5299],\n",
      "        [-2.1262,  2.2139, -0.1734],\n",
      "        [-1.9311,  2.0216, -0.4322],\n",
      "        [-2.0273,  2.1460, -0.2385],\n",
      "        [-2.0349,  2.3183, -0.3803],\n",
      "        [-2.2478,  2.1753, -0.3013],\n",
      "        [-1.6922,  2.2639, -0.4232]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8872,  2.0606, -0.3291],\n",
      "        [-1.8652,  1.8234, -0.1162],\n",
      "        [-1.9690,  2.1481, -0.5070],\n",
      "        [-2.0818,  1.3793,  0.6021],\n",
      "        [-2.3498,  1.5257,  0.3367],\n",
      "        [-1.8268,  1.6793,  0.0298],\n",
      "        [-2.0159,  1.7237,  0.2037],\n",
      "        [-1.9626,  1.4966,  0.3514],\n",
      "        [-2.0640,  1.0937,  0.9625],\n",
      "        [-1.8647,  2.1453, -0.5299],\n",
      "        [-2.1262,  2.2139, -0.1734],\n",
      "        [-1.9311,  2.0216, -0.4322],\n",
      "        [-2.0273,  2.1460, -0.2385],\n",
      "        [-2.0349,  2.3183, -0.3803],\n",
      "        [-2.2478,  2.1753, -0.3013],\n",
      "        [-1.6922,  2.2639, -0.4232]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9388,  2.0164, -0.3205],\n",
      "        [-2.2213,  0.8662,  1.1237],\n",
      "        [-2.0232,  2.1687, -0.1584],\n",
      "        [-2.1688,  1.0352,  0.6610],\n",
      "        [-1.5711,  2.1260, -0.6315],\n",
      "        [-2.2254,  0.8573,  1.2324],\n",
      "        [-1.9958,  2.0835, -0.1847],\n",
      "        [-1.9909,  2.1869, -0.4229],\n",
      "        [-2.2793,  0.9579,  0.7563],\n",
      "        [ 0.3219,  0.4891, -1.0127],\n",
      "        [-1.7119,  1.4762, -0.1566],\n",
      "        [-2.2053,  1.5150,  0.5140],\n",
      "        [ 0.3231,  0.1925, -1.1793],\n",
      "        [-2.3670,  1.0121,  0.9579],\n",
      "        [-1.8595,  2.2625, -0.2969],\n",
      "        [-1.7776,  1.8497, -0.2427]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9388,  2.0164, -0.3205],\n",
      "        [-2.2213,  0.8662,  1.1237],\n",
      "        [-2.0232,  2.1687, -0.1584],\n",
      "        [-2.1688,  1.0352,  0.6610],\n",
      "        [-1.5711,  2.1260, -0.6315],\n",
      "        [-2.2254,  0.8573,  1.2324],\n",
      "        [-1.9958,  2.0835, -0.1847],\n",
      "        [-1.9909,  2.1869, -0.4229],\n",
      "        [-2.2793,  0.9579,  0.7563],\n",
      "        [ 0.3219,  0.4891, -1.0127],\n",
      "        [-1.7119,  1.4762, -0.1566],\n",
      "        [-2.2053,  1.5150,  0.5140],\n",
      "        [ 0.3231,  0.1925, -1.1793],\n",
      "        [-2.3670,  1.0121,  0.9579],\n",
      "        [-1.8595,  2.2625, -0.2969],\n",
      "        [-1.7776,  1.8497, -0.2427]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.8686,  1.0871, -1.0531],\n",
      "        [-2.1283,  0.8494,  1.1733],\n",
      "        [ 0.2223,  0.3207, -1.1602],\n",
      "        [-1.9464,  1.0830,  0.9907],\n",
      "        [ 0.5824,  0.1679, -1.0490],\n",
      "        [-2.2349,  1.5490,  0.5563],\n",
      "        [-1.9089,  1.7658,  0.0983],\n",
      "        [-1.7387,  2.1923, -0.4414],\n",
      "        [ 0.4879,  0.0481, -1.2778],\n",
      "        [-2.2017,  1.9462, -0.2898],\n",
      "        [-2.0897,  0.7600,  1.4555],\n",
      "        [-1.9588,  1.9699, -0.4351],\n",
      "        [-2.0103,  2.0239,  0.0034],\n",
      "        [-2.2882,  1.9479,  0.3035],\n",
      "        [-1.9978,  1.9574,  0.0646],\n",
      "        [-2.1032,  1.3513,  0.6440]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-0.8686,  1.0871, -1.0531],\n",
      "        [-2.1283,  0.8494,  1.1733],\n",
      "        [ 0.2223,  0.3207, -1.1602],\n",
      "        [-1.9464,  1.0830,  0.9907],\n",
      "        [ 0.5824,  0.1679, -1.0490],\n",
      "        [-2.2349,  1.5490,  0.5563],\n",
      "        [-1.9089,  1.7658,  0.0983],\n",
      "        [-1.7387,  2.1923, -0.4414],\n",
      "        [ 0.4879,  0.0481, -1.2778],\n",
      "        [-2.2017,  1.9462, -0.2898],\n",
      "        [-2.0897,  0.7600,  1.4555],\n",
      "        [-1.9588,  1.9699, -0.4351],\n",
      "        [-2.0103,  2.0239,  0.0034],\n",
      "        [-2.2882,  1.9479,  0.3035],\n",
      "        [-1.9978,  1.9574,  0.0646],\n",
      "        [-2.1032,  1.3513,  0.6440]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7189,  2.0344, -0.3572],\n",
      "        [-2.2466,  0.7972,  1.2925],\n",
      "        [-2.2966,  0.6322,  1.3553],\n",
      "        [-1.7663,  1.9830, -0.0770],\n",
      "        [-1.9963,  2.2055, -0.4502],\n",
      "        [ 0.4413,  0.1240, -1.1291],\n",
      "        [-2.0067,  0.8859,  0.9538],\n",
      "        [-1.7986,  2.0446, -0.4022],\n",
      "        [ 0.2777,  0.2000, -1.0955],\n",
      "        [-2.0470,  1.8594,  0.1087],\n",
      "        [-1.9738,  2.0176, -0.4938],\n",
      "        [-2.3844,  2.0454,  0.0254],\n",
      "        [-2.0686,  1.6555,  0.0998],\n",
      "        [ 0.4743,  0.1123, -1.2973],\n",
      "        [-1.9361,  0.7926,  0.9768],\n",
      "        [-2.0946,  0.7633,  1.3169]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7189,  2.0344, -0.3572],\n",
      "        [-2.2466,  0.7972,  1.2925],\n",
      "        [-2.2966,  0.6322,  1.3553],\n",
      "        [-1.7663,  1.9830, -0.0770],\n",
      "        [-1.9963,  2.2055, -0.4502],\n",
      "        [ 0.4413,  0.1240, -1.1291],\n",
      "        [-2.0067,  0.8859,  0.9538],\n",
      "        [-1.7986,  2.0446, -0.4022],\n",
      "        [ 0.2777,  0.2000, -1.0955],\n",
      "        [-2.0470,  1.8594,  0.1087],\n",
      "        [-1.9738,  2.0176, -0.4938],\n",
      "        [-2.3844,  2.0454,  0.0254],\n",
      "        [-2.0686,  1.6555,  0.0998],\n",
      "        [ 0.4743,  0.1123, -1.2973],\n",
      "        [-1.9361,  0.7926,  0.9768],\n",
      "        [-2.0946,  0.7633,  1.3169]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7154,  1.9449, -0.3431],\n",
      "        [-1.8105,  2.0477, -0.2544],\n",
      "        [-1.8874,  2.3700, -0.5358],\n",
      "        [-2.2082,  0.6538,  0.9779],\n",
      "        [-2.4088,  1.9239,  0.1366],\n",
      "        [-2.3036,  0.8239,  1.2682],\n",
      "        [-2.0500,  2.0913, -0.1734],\n",
      "        [-2.0138,  1.8660, -0.2755],\n",
      "        [-2.1912,  0.8106,  1.1464],\n",
      "        [-1.6172,  1.4804, -0.2241],\n",
      "        [-1.8160,  2.0625, -0.4677],\n",
      "        [-2.0589,  0.8034,  1.1179],\n",
      "        [-2.1970,  0.7355,  0.9959],\n",
      "        [-2.0698,  1.7817, -0.3276],\n",
      "        [-1.9610,  2.0590, -0.2073],\n",
      "        [-1.8235,  2.1269, -0.4578]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7154,  1.9449, -0.3431],\n",
      "        [-1.8105,  2.0477, -0.2544],\n",
      "        [-1.8874,  2.3700, -0.5358],\n",
      "        [-2.2082,  0.6538,  0.9779],\n",
      "        [-2.4088,  1.9239,  0.1366],\n",
      "        [-2.3036,  0.8239,  1.2682],\n",
      "        [-2.0500,  2.0913, -0.1734],\n",
      "        [-2.0138,  1.8660, -0.2755],\n",
      "        [-2.1912,  0.8106,  1.1464],\n",
      "        [-1.6172,  1.4804, -0.2241],\n",
      "        [-1.8160,  2.0625, -0.4677],\n",
      "        [-2.0589,  0.8034,  1.1179],\n",
      "        [-2.1970,  0.7355,  0.9959],\n",
      "        [-2.0698,  1.7817, -0.3276],\n",
      "        [-1.9610,  2.0590, -0.2073],\n",
      "        [-1.8235,  2.1269, -0.4578]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1970,  0.5930,  1.0666],\n",
      "        [-1.9896,  1.9537, -0.0040],\n",
      "        [-2.0595,  1.8562, -0.0367],\n",
      "        [-1.9353,  1.9823,  0.0869],\n",
      "        [-2.1829,  1.8686,  0.3783],\n",
      "        [-1.9221,  1.8241,  0.0532],\n",
      "        [-1.9347,  1.8213,  0.0580],\n",
      "        [-1.6863,  1.8631, -0.1141],\n",
      "        [-2.0152,  1.7506, -0.2285],\n",
      "        [-1.6510,  1.9609, -0.0419],\n",
      "        [-2.1363,  1.4063,  0.6277],\n",
      "        [-2.0481,  2.1436, -0.1913],\n",
      "        [-1.6951,  2.0708, -0.3254],\n",
      "        [-2.0578,  2.0421, -0.1338],\n",
      "        [-1.6647,  2.0276, -0.3033],\n",
      "        [-1.8332,  1.9415, -0.1836]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.1970,  0.5930,  1.0666],\n",
      "        [-1.9896,  1.9537, -0.0040],\n",
      "        [-2.0595,  1.8562, -0.0367],\n",
      "        [-1.9353,  1.9823,  0.0869],\n",
      "        [-2.1829,  1.8686,  0.3783],\n",
      "        [-1.9221,  1.8241,  0.0532],\n",
      "        [-1.9347,  1.8213,  0.0580],\n",
      "        [-1.6863,  1.8631, -0.1141],\n",
      "        [-2.0152,  1.7506, -0.2285],\n",
      "        [-1.6510,  1.9609, -0.0419],\n",
      "        [-2.1363,  1.4063,  0.6277],\n",
      "        [-2.0481,  2.1436, -0.1913],\n",
      "        [-1.6951,  2.0708, -0.3254],\n",
      "        [-2.0578,  2.0421, -0.1338],\n",
      "        [-1.6647,  2.0276, -0.3033],\n",
      "        [-1.8332,  1.9415, -0.1836]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2087,  0.7629,  1.0986],\n",
      "        [-1.6403,  2.0309, -0.1931],\n",
      "        [-1.8835,  1.9050, -0.1246],\n",
      "        [ 0.5479, -0.0344, -1.1814],\n",
      "        [-2.1120,  0.4799,  1.2377],\n",
      "        [-1.9582,  1.5319,  0.1563],\n",
      "        [-1.9804,  1.7348, -0.1086],\n",
      "        [-2.2280,  0.7240,  0.9942],\n",
      "        [-2.0100,  0.5300,  1.1412],\n",
      "        [-2.1200,  2.0063,  0.2847],\n",
      "        [-2.0005,  2.1343, -0.0097],\n",
      "        [-2.0915,  1.3479,  0.4842],\n",
      "        [-2.2187,  0.7657,  1.3719],\n",
      "        [-1.8058,  1.6183,  0.4307],\n",
      "        [-2.0920,  0.5567,  1.3353],\n",
      "        [-1.9170,  1.5540,  0.1022]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.2087,  0.7629,  1.0986],\n",
      "        [-1.6403,  2.0309, -0.1931],\n",
      "        [-1.8835,  1.9050, -0.1246],\n",
      "        [ 0.5479, -0.0344, -1.1814],\n",
      "        [-2.1120,  0.4799,  1.2377],\n",
      "        [-1.9582,  1.5319,  0.1563],\n",
      "        [-1.9804,  1.7348, -0.1086],\n",
      "        [-2.2280,  0.7240,  0.9942],\n",
      "        [-2.0100,  0.5300,  1.1412],\n",
      "        [-2.1200,  2.0063,  0.2847],\n",
      "        [-2.0005,  2.1343, -0.0097],\n",
      "        [-2.0915,  1.3479,  0.4842],\n",
      "        [-2.2187,  0.7657,  1.3719],\n",
      "        [-1.8058,  1.6183,  0.4307],\n",
      "        [-2.0920,  0.5567,  1.3353],\n",
      "        [-1.9170,  1.5540,  0.1022]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0278,  1.8908, -0.2736],\n",
      "        [-1.3840,  1.9021, -0.2669],\n",
      "        [-2.0637,  1.7744,  0.0559],\n",
      "        [-2.2556,  0.6597,  1.3678],\n",
      "        [-1.9330,  2.0550, -0.1579],\n",
      "        [-1.6871,  1.8936, -0.1408],\n",
      "        [-1.7916,  1.3348,  0.1654],\n",
      "        [ 0.0492, -0.0736, -0.8351],\n",
      "        [-1.8045,  2.0300,  0.0110],\n",
      "        [-2.0068,  0.6566,  1.1385],\n",
      "        [-1.8764,  1.8574, -0.3144],\n",
      "        [-1.5660,  1.7840, -0.1910],\n",
      "        [-1.7235,  1.6467, -0.0088],\n",
      "        [-2.3584,  0.5117,  1.2204],\n",
      "        [-1.8502,  1.7716, -0.2059],\n",
      "        [-1.8308,  1.8270,  0.0588]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.0278,  1.8908, -0.2736],\n",
      "        [-1.3840,  1.9021, -0.2669],\n",
      "        [-2.0637,  1.7744,  0.0559],\n",
      "        [-2.2556,  0.6597,  1.3678],\n",
      "        [-1.9330,  2.0550, -0.1579],\n",
      "        [-1.6871,  1.8936, -0.1408],\n",
      "        [-1.7916,  1.3348,  0.1654],\n",
      "        [ 0.0492, -0.0736, -0.8351],\n",
      "        [-1.8045,  2.0300,  0.0110],\n",
      "        [-2.0068,  0.6566,  1.1385],\n",
      "        [-1.8764,  1.8574, -0.3144],\n",
      "        [-1.5660,  1.7840, -0.1910],\n",
      "        [-1.7235,  1.6467, -0.0088],\n",
      "        [-2.3584,  0.5117,  1.2204],\n",
      "        [-1.8502,  1.7716, -0.2059],\n",
      "        [-1.8308,  1.8270,  0.0588]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3042,  0.0834, -1.0186],\n",
      "        [ 0.5261,  0.2989, -1.0544],\n",
      "        [ 0.0732,  0.1672, -0.8858],\n",
      "        [-2.2367,  1.4680,  0.7288],\n",
      "        [-2.0157,  1.0832,  0.8136],\n",
      "        [-2.0268,  0.5264,  1.3172],\n",
      "        [-2.0650,  0.6487,  1.3167],\n",
      "        [-2.2156,  0.4208,  1.4343],\n",
      "        [-1.9827,  1.3227,  0.5005],\n",
      "        [-1.6410,  1.5831, -0.1982],\n",
      "        [ 0.0243,  0.5582, -1.2556],\n",
      "        [-2.2211,  0.5077,  1.4161],\n",
      "        [-2.1026,  1.3324,  0.5239],\n",
      "        [-1.9045,  1.6342,  0.1501],\n",
      "        [-2.1811,  0.7340,  1.1671],\n",
      "        [-1.8886,  1.8908, -0.0637]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.3042,  0.0834, -1.0186],\n",
      "        [ 0.5261,  0.2989, -1.0544],\n",
      "        [ 0.0732,  0.1672, -0.8858],\n",
      "        [-2.2367,  1.4680,  0.7288],\n",
      "        [-2.0157,  1.0832,  0.8136],\n",
      "        [-2.0268,  0.5264,  1.3172],\n",
      "        [-2.0650,  0.6487,  1.3167],\n",
      "        [-2.2156,  0.4208,  1.4343],\n",
      "        [-1.9827,  1.3227,  0.5005],\n",
      "        [-1.6410,  1.5831, -0.1982],\n",
      "        [ 0.0243,  0.5582, -1.2556],\n",
      "        [-2.2211,  0.5077,  1.4161],\n",
      "        [-2.1026,  1.3324,  0.5239],\n",
      "        [-1.9045,  1.6342,  0.1501],\n",
      "        [-2.1811,  0.7340,  1.1671],\n",
      "        [-1.8886,  1.8908, -0.0637]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2261,  0.8265,  1.0314],\n",
      "        [-1.8933,  1.7015,  0.0422],\n",
      "        [-1.8279,  1.7596,  0.1928],\n",
      "        [ 0.2714,  0.1915, -1.2193],\n",
      "        [-1.9945,  0.3763,  1.2884],\n",
      "        [ 0.3528,  0.1377, -1.1414],\n",
      "        [-2.0828,  0.7120,  1.0043],\n",
      "        [-1.9875,  1.6742, -0.0034],\n",
      "        [-2.4305,  0.4432,  1.1049],\n",
      "        [-2.0035,  2.0194, -0.2675],\n",
      "        [-2.1909,  1.3040,  0.8690],\n",
      "        [-2.0237,  1.6685,  0.4271],\n",
      "        [-0.7284,  0.8303, -0.6147],\n",
      "        [-1.8342,  1.9407, -0.1105],\n",
      "        [-0.9474,  0.6769,  0.0580],\n",
      "        [-1.4441,  1.4388, -0.4503]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.2261,  0.8265,  1.0314],\n",
      "        [-1.8933,  1.7015,  0.0422],\n",
      "        [-1.8279,  1.7596,  0.1928],\n",
      "        [ 0.2714,  0.1915, -1.2193],\n",
      "        [-1.9945,  0.3763,  1.2884],\n",
      "        [ 0.3528,  0.1377, -1.1414],\n",
      "        [-2.0828,  0.7120,  1.0043],\n",
      "        [-1.9875,  1.6742, -0.0034],\n",
      "        [-2.4305,  0.4432,  1.1049],\n",
      "        [-2.0035,  2.0194, -0.2675],\n",
      "        [-2.1909,  1.3040,  0.8690],\n",
      "        [-2.0237,  1.6685,  0.4271],\n",
      "        [-0.7284,  0.8303, -0.6147],\n",
      "        [-1.8342,  1.9407, -0.1105],\n",
      "        [-0.9474,  0.6769,  0.0580],\n",
      "        [-1.4441,  1.4388, -0.4503]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1482,  1.6674,  0.2930],\n",
      "        [-1.7846,  1.7235, -0.1688],\n",
      "        [-2.1723,  0.5135,  1.1611],\n",
      "        [-2.0015,  1.1555,  0.7705],\n",
      "        [-2.1270,  0.6100,  1.3642],\n",
      "        [-1.8389,  1.1873,  0.4985],\n",
      "        [-1.3353,  1.9103, -0.7445],\n",
      "        [-2.2503,  0.9338,  0.8591],\n",
      "        [-1.7451,  1.8111, -0.3168],\n",
      "        [-1.9300,  0.4947,  1.0909],\n",
      "        [ 0.4307,  0.1548, -1.0834],\n",
      "        [-1.7191,  1.9828, -0.5884],\n",
      "        [-1.9049,  1.8715,  0.0687],\n",
      "        [-2.2866,  0.6291,  1.2506],\n",
      "        [-1.3070,  1.7469, -0.3807],\n",
      "        [-2.1939,  0.7004,  1.1158]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.1482,  1.6674,  0.2930],\n",
      "        [-1.7846,  1.7235, -0.1688],\n",
      "        [-2.1723,  0.5135,  1.1611],\n",
      "        [-2.0015,  1.1555,  0.7705],\n",
      "        [-2.1270,  0.6100,  1.3642],\n",
      "        [-1.8389,  1.1873,  0.4985],\n",
      "        [-1.3353,  1.9103, -0.7445],\n",
      "        [-2.2503,  0.9338,  0.8591],\n",
      "        [-1.7451,  1.8111, -0.3168],\n",
      "        [-1.9300,  0.4947,  1.0909],\n",
      "        [ 0.4307,  0.1548, -1.0834],\n",
      "        [-1.7191,  1.9828, -0.5884],\n",
      "        [-1.9049,  1.8715,  0.0687],\n",
      "        [-2.2866,  0.6291,  1.2506],\n",
      "        [-1.3070,  1.7469, -0.3807],\n",
      "        [-2.1939,  0.7004,  1.1158]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7744e+00,  1.7364e+00, -6.3627e-04],\n",
      "        [-1.9365e+00,  1.7298e+00,  5.1011e-02],\n",
      "        [-2.3246e+00,  6.3141e-01,  1.1653e+00],\n",
      "        [-1.7655e+00,  1.8608e+00, -1.8253e-01],\n",
      "        [-1.7896e+00,  1.4309e+00,  4.0192e-01],\n",
      "        [-2.2204e+00,  8.0701e-01,  1.3499e+00],\n",
      "        [-1.9006e+00,  1.2636e+00,  6.4173e-01],\n",
      "        [-2.2342e+00,  4.2685e-01,  1.4329e+00],\n",
      "        [-2.0919e+00,  1.2427e+00,  5.8822e-01],\n",
      "        [-1.9874e+00,  6.0888e-01,  1.2794e+00],\n",
      "        [-1.7835e+00,  1.6690e+00, -2.7327e-01],\n",
      "        [-1.4783e+00,  1.6507e+00, -5.4078e-01],\n",
      "        [-1.5066e+00,  1.7956e+00, -3.4990e-01],\n",
      "        [-1.9172e+00,  1.4412e+00,  5.6498e-02],\n",
      "        [ 4.2814e-01,  6.6264e-02, -1.0610e+00],\n",
      "        [-2.0578e+00,  9.6868e-01,  8.9048e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7744e+00,  1.7364e+00, -6.3627e-04],\n",
      "        [-1.9365e+00,  1.7298e+00,  5.1011e-02],\n",
      "        [-2.3246e+00,  6.3141e-01,  1.1653e+00],\n",
      "        [-1.7655e+00,  1.8608e+00, -1.8253e-01],\n",
      "        [-1.7896e+00,  1.4309e+00,  4.0192e-01],\n",
      "        [-2.2204e+00,  8.0701e-01,  1.3499e+00],\n",
      "        [-1.9006e+00,  1.2636e+00,  6.4173e-01],\n",
      "        [-2.2342e+00,  4.2685e-01,  1.4329e+00],\n",
      "        [-2.0919e+00,  1.2427e+00,  5.8822e-01],\n",
      "        [-1.9874e+00,  6.0888e-01,  1.2794e+00],\n",
      "        [-1.7835e+00,  1.6690e+00, -2.7327e-01],\n",
      "        [-1.4783e+00,  1.6507e+00, -5.4078e-01],\n",
      "        [-1.5066e+00,  1.7956e+00, -3.4990e-01],\n",
      "        [-1.9172e+00,  1.4412e+00,  5.6498e-02],\n",
      "        [ 4.2814e-01,  6.6264e-02, -1.0610e+00],\n",
      "        [-2.0578e+00,  9.6868e-01,  8.9048e-01]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.4371,  0.1817, -1.2157],\n",
      "        [-1.9783,  0.5664,  1.3216],\n",
      "        [-1.5641,  1.9293, -0.4354],\n",
      "        [-1.7390,  1.5558,  0.2335],\n",
      "        [-1.6193,  1.7487, -0.2610],\n",
      "        [-1.6541,  1.7739, -0.0443],\n",
      "        [-1.6481,  1.6558, -0.1084],\n",
      "        [-1.7813,  1.8264, -0.3801],\n",
      "        [ 0.6431,  0.1650, -1.2940],\n",
      "        [-2.3928,  0.6681,  1.3511],\n",
      "        [-2.0799,  0.7426,  1.0916],\n",
      "        [-1.8469,  1.5887,  0.2574],\n",
      "        [-1.9951,  1.7347,  0.1130],\n",
      "        [-2.1654,  0.3064,  1.3908],\n",
      "        [-1.7673,  1.8243, -0.3023],\n",
      "        [-1.5140,  1.7581, -0.2221]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.4371,  0.1817, -1.2157],\n",
      "        [-1.9783,  0.5664,  1.3216],\n",
      "        [-1.5641,  1.9293, -0.4354],\n",
      "        [-1.7390,  1.5558,  0.2335],\n",
      "        [-1.6193,  1.7487, -0.2610],\n",
      "        [-1.6541,  1.7739, -0.0443],\n",
      "        [-1.6481,  1.6558, -0.1084],\n",
      "        [-1.7813,  1.8264, -0.3801],\n",
      "        [ 0.6431,  0.1650, -1.2940],\n",
      "        [-2.3928,  0.6681,  1.3511],\n",
      "        [-2.0799,  0.7426,  1.0916],\n",
      "        [-1.8469,  1.5887,  0.2574],\n",
      "        [-1.9951,  1.7347,  0.1130],\n",
      "        [-2.1654,  0.3064,  1.3908],\n",
      "        [-1.7673,  1.8243, -0.3023],\n",
      "        [-1.5140,  1.7581, -0.2221]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7700,  2.1070, -0.4344],\n",
      "        [-2.0502,  0.8251,  1.2017],\n",
      "        [-1.9414,  1.1882,  0.6461],\n",
      "        [-2.0006,  0.6326,  1.1504],\n",
      "        [-1.5521,  1.7761, -0.3503],\n",
      "        [-1.6646,  1.8528, -0.4455],\n",
      "        [ 0.4389,  0.1613, -1.1754],\n",
      "        [-2.0899,  0.8782,  0.9366],\n",
      "        [-2.0900,  0.4649,  1.2380],\n",
      "        [-2.0120,  1.6263,  0.2856],\n",
      "        [ 0.5829,  0.1119, -1.3963],\n",
      "        [-1.8621,  1.8334, -0.3072],\n",
      "        [-2.0085,  1.4782,  0.1588],\n",
      "        [-1.8724,  1.7935, -0.0454],\n",
      "        [-1.6974,  1.6192, -0.0245],\n",
      "        [-1.5445,  1.8455, -0.4327]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7700,  2.1070, -0.4344],\n",
      "        [-2.0502,  0.8251,  1.2017],\n",
      "        [-1.9414,  1.1882,  0.6461],\n",
      "        [-2.0006,  0.6326,  1.1504],\n",
      "        [-1.5521,  1.7761, -0.3503],\n",
      "        [-1.6646,  1.8528, -0.4455],\n",
      "        [ 0.4389,  0.1613, -1.1754],\n",
      "        [-2.0899,  0.8782,  0.9366],\n",
      "        [-2.0900,  0.4649,  1.2380],\n",
      "        [-2.0120,  1.6263,  0.2856],\n",
      "        [ 0.5829,  0.1119, -1.3963],\n",
      "        [-1.8621,  1.8334, -0.3072],\n",
      "        [-2.0085,  1.4782,  0.1588],\n",
      "        [-1.8724,  1.7935, -0.0454],\n",
      "        [-1.6974,  1.6192, -0.0245],\n",
      "        [-1.5445,  1.8455, -0.4327]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0680,  0.3846,  1.2530],\n",
      "        [ 0.6308,  0.0650, -1.2821],\n",
      "        [-1.7752,  1.5327,  0.0805],\n",
      "        [-1.9280,  0.5050,  1.3407],\n",
      "        [-2.0894,  0.4448,  1.2733],\n",
      "        [ 0.6226,  0.2591, -1.3792],\n",
      "        [-1.4537,  1.7601, -0.2921],\n",
      "        [-2.0502,  0.5032,  1.3378],\n",
      "        [ 0.7016, -0.0450, -1.2358],\n",
      "        [-2.1957,  0.4968,  1.4407],\n",
      "        [-1.5155,  1.8496, -0.2407],\n",
      "        [ 0.3676, -0.0127, -1.1029],\n",
      "        [-1.4867,  1.6405, -0.4090],\n",
      "        [-1.5140,  1.5658, -0.0469],\n",
      "        [-1.8889,  1.5298,  0.2135],\n",
      "        [-2.0844,  0.5865,  1.2108]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.0680,  0.3846,  1.2530],\n",
      "        [ 0.6308,  0.0650, -1.2821],\n",
      "        [-1.7752,  1.5327,  0.0805],\n",
      "        [-1.9280,  0.5050,  1.3407],\n",
      "        [-2.0894,  0.4448,  1.2733],\n",
      "        [ 0.6226,  0.2591, -1.3792],\n",
      "        [-1.4537,  1.7601, -0.2921],\n",
      "        [-2.0502,  0.5032,  1.3378],\n",
      "        [ 0.7016, -0.0450, -1.2358],\n",
      "        [-2.1957,  0.4968,  1.4407],\n",
      "        [-1.5155,  1.8496, -0.2407],\n",
      "        [ 0.3676, -0.0127, -1.1029],\n",
      "        [-1.4867,  1.6405, -0.4090],\n",
      "        [-1.5140,  1.5658, -0.0469],\n",
      "        [-1.8889,  1.5298,  0.2135],\n",
      "        [-2.0844,  0.5865,  1.2108]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4275,  1.8857, -0.5434],\n",
      "        [-1.5677,  1.8403, -0.3143],\n",
      "        [-1.6145,  1.4749, -0.0973],\n",
      "        [ 0.3514,  0.3503, -1.2969],\n",
      "        [-1.5124,  1.5743, -0.2030],\n",
      "        [-2.2980,  0.6132,  1.1091],\n",
      "        [-1.9034,  1.7228,  0.0600],\n",
      "        [-1.4194,  1.5877, -0.2764],\n",
      "        [-2.0004,  0.8539,  0.8033],\n",
      "        [-1.9444,  1.1276,  0.7114],\n",
      "        [-2.2329,  1.1517,  1.0604],\n",
      "        [-2.0356,  0.6334,  1.1168],\n",
      "        [-2.2653,  0.4814,  1.2836],\n",
      "        [-1.8935,  2.0770, -0.1364],\n",
      "        [-1.4758,  1.4741,  0.1013],\n",
      "        [-2.1497,  0.3690,  1.3492]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4275,  1.8857, -0.5434],\n",
      "        [-1.5677,  1.8403, -0.3143],\n",
      "        [-1.6145,  1.4749, -0.0973],\n",
      "        [ 0.3514,  0.3503, -1.2969],\n",
      "        [-1.5124,  1.5743, -0.2030],\n",
      "        [-2.2980,  0.6132,  1.1091],\n",
      "        [-1.9034,  1.7228,  0.0600],\n",
      "        [-1.4194,  1.5877, -0.2764],\n",
      "        [-2.0004,  0.8539,  0.8033],\n",
      "        [-1.9444,  1.1276,  0.7114],\n",
      "        [-2.2329,  1.1517,  1.0604],\n",
      "        [-2.0356,  0.6334,  1.1168],\n",
      "        [-2.2653,  0.4814,  1.2836],\n",
      "        [-1.8935,  2.0770, -0.1364],\n",
      "        [-1.4758,  1.4741,  0.1013],\n",
      "        [-2.1497,  0.3690,  1.3492]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6036,  1.7754, -0.3838],\n",
      "        [-1.6627,  1.4591,  0.3960],\n",
      "        [-2.1452,  0.7919,  1.1798],\n",
      "        [-1.5158,  1.5349, -0.3259],\n",
      "        [-1.5010,  1.6189, -0.3564],\n",
      "        [-1.7613,  0.7688,  0.7064],\n",
      "        [-1.6792,  1.8220, -0.2262],\n",
      "        [-1.4458,  1.6376, -0.3246],\n",
      "        [-1.8705,  0.4658,  1.2202],\n",
      "        [-1.4303,  1.5731, -0.0331],\n",
      "        [-1.5753,  1.4748, -0.1590],\n",
      "        [-2.1266,  0.5016,  1.1647],\n",
      "        [ 0.8696, -0.0408, -1.2907],\n",
      "        [-2.1133,  0.5985,  1.3193],\n",
      "        [-1.1906,  1.9480, -0.4931],\n",
      "        [-1.3779,  1.6936, -0.4467]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6036,  1.7754, -0.3838],\n",
      "        [-1.6627,  1.4591,  0.3960],\n",
      "        [-2.1452,  0.7919,  1.1798],\n",
      "        [-1.5158,  1.5349, -0.3259],\n",
      "        [-1.5010,  1.6189, -0.3564],\n",
      "        [-1.7613,  0.7688,  0.7064],\n",
      "        [-1.6792,  1.8220, -0.2262],\n",
      "        [-1.4458,  1.6376, -0.3246],\n",
      "        [-1.8705,  0.4658,  1.2202],\n",
      "        [-1.4303,  1.5731, -0.0331],\n",
      "        [-1.5753,  1.4748, -0.1590],\n",
      "        [-2.1266,  0.5016,  1.1647],\n",
      "        [ 0.8696, -0.0408, -1.2907],\n",
      "        [-2.1133,  0.5985,  1.3193],\n",
      "        [-1.1906,  1.9480, -0.4931],\n",
      "        [-1.3779,  1.6936, -0.4467]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6430,  1.8200, -0.4528],\n",
      "        [-2.1152,  0.7125,  1.2232],\n",
      "        [-1.8913,  1.2449,  0.4786],\n",
      "        [-2.0824,  0.6900,  1.2677],\n",
      "        [-1.8490,  1.2789,  0.6043],\n",
      "        [-1.2817,  1.5467, -0.6196],\n",
      "        [-1.4578,  1.8085, -0.3809],\n",
      "        [-1.3479,  1.5987, -0.3484],\n",
      "        [ 0.8639, -0.0292, -1.1289],\n",
      "        [-1.6943,  1.0639,  0.2872],\n",
      "        [-1.3530,  1.6270, -0.3142],\n",
      "        [-2.1100,  0.5202,  1.3543],\n",
      "        [-1.4582,  1.7935, -0.5642],\n",
      "        [-2.1298,  0.4163,  1.4155],\n",
      "        [-1.6560,  1.5863, -0.2836],\n",
      "        [-1.3569,  1.4009, -0.0364]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6430,  1.8200, -0.4528],\n",
      "        [-2.1152,  0.7125,  1.2232],\n",
      "        [-1.8913,  1.2449,  0.4786],\n",
      "        [-2.0824,  0.6900,  1.2677],\n",
      "        [-1.8490,  1.2789,  0.6043],\n",
      "        [-1.2817,  1.5467, -0.6196],\n",
      "        [-1.4578,  1.8085, -0.3809],\n",
      "        [-1.3479,  1.5987, -0.3484],\n",
      "        [ 0.8639, -0.0292, -1.1289],\n",
      "        [-1.6943,  1.0639,  0.2872],\n",
      "        [-1.3530,  1.6270, -0.3142],\n",
      "        [-2.1100,  0.5202,  1.3543],\n",
      "        [-1.4582,  1.7935, -0.5642],\n",
      "        [-2.1298,  0.4163,  1.4155],\n",
      "        [-1.6560,  1.5863, -0.2836],\n",
      "        [-1.3569,  1.4009, -0.0364]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7091,  1.2747,  0.2455],\n",
      "        [-2.0644,  1.1379,  0.5544],\n",
      "        [-1.8658,  0.5972,  0.9914],\n",
      "        [-1.4446,  1.6457, -0.3790],\n",
      "        [-1.2427,  1.8800, -0.5873],\n",
      "        [-1.3875,  1.8957, -0.3655],\n",
      "        [ 0.6997,  0.0087, -1.4136],\n",
      "        [-1.4048,  1.9460, -0.6549],\n",
      "        [ 0.6836,  0.0296, -1.1335],\n",
      "        [-1.3977,  1.5744, -0.4604],\n",
      "        [-1.3797,  1.8501, -0.6644],\n",
      "        [-2.1322,  0.5232,  1.2318],\n",
      "        [-1.6985,  1.8314, -0.3480],\n",
      "        [-1.4587,  1.6165, -0.6113],\n",
      "        [-1.4979,  2.1582, -0.5309],\n",
      "        [-1.3282,  1.8292, -0.7027]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7091,  1.2747,  0.2455],\n",
      "        [-2.0644,  1.1379,  0.5544],\n",
      "        [-1.8658,  0.5972,  0.9914],\n",
      "        [-1.4446,  1.6457, -0.3790],\n",
      "        [-1.2427,  1.8800, -0.5873],\n",
      "        [-1.3875,  1.8957, -0.3655],\n",
      "        [ 0.6997,  0.0087, -1.4136],\n",
      "        [-1.4048,  1.9460, -0.6549],\n",
      "        [ 0.6836,  0.0296, -1.1335],\n",
      "        [-1.3977,  1.5744, -0.4604],\n",
      "        [-1.3797,  1.8501, -0.6644],\n",
      "        [-2.1322,  0.5232,  1.2318],\n",
      "        [-1.6985,  1.8314, -0.3480],\n",
      "        [-1.4587,  1.6165, -0.6113],\n",
      "        [-1.4979,  2.1582, -0.5309],\n",
      "        [-1.3282,  1.8292, -0.7027]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4307,  1.7797, -0.3557],\n",
      "        [-1.5763,  1.5317, -0.2567],\n",
      "        [-1.7503,  1.6742,  0.0958],\n",
      "        [-1.4134,  1.7317, -0.3477],\n",
      "        [-1.0490,  1.8366, -0.7156],\n",
      "        [-2.1515,  0.8311,  0.8790],\n",
      "        [-1.4899,  1.9087, -0.6580],\n",
      "        [-1.9180,  0.3413,  1.1226],\n",
      "        [-1.4417,  1.7664, -0.4665],\n",
      "        [-1.6933,  1.4883, -0.0877],\n",
      "        [-1.9794,  1.0201,  0.6594],\n",
      "        [ 0.6716,  0.0218, -1.2978],\n",
      "        [-1.7065,  1.8456, -0.1414],\n",
      "        [-1.4476,  1.8623, -0.7150],\n",
      "        [-2.0862,  1.0048,  0.9254],\n",
      "        [-2.0286,  0.7037,  1.1953]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4307,  1.7797, -0.3557],\n",
      "        [-1.5763,  1.5317, -0.2567],\n",
      "        [-1.7503,  1.6742,  0.0958],\n",
      "        [-1.4134,  1.7317, -0.3477],\n",
      "        [-1.0490,  1.8366, -0.7156],\n",
      "        [-2.1515,  0.8311,  0.8790],\n",
      "        [-1.4899,  1.9087, -0.6580],\n",
      "        [-1.9180,  0.3413,  1.1226],\n",
      "        [-1.4417,  1.7664, -0.4665],\n",
      "        [-1.6933,  1.4883, -0.0877],\n",
      "        [-1.9794,  1.0201,  0.6594],\n",
      "        [ 0.6716,  0.0218, -1.2978],\n",
      "        [-1.7065,  1.8456, -0.1414],\n",
      "        [-1.4476,  1.8623, -0.7150],\n",
      "        [-2.0862,  1.0048,  0.9254],\n",
      "        [-2.0286,  0.7037,  1.1953]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9182,  0.6705,  1.2135],\n",
      "        [-1.4147,  1.9409, -0.6385],\n",
      "        [-1.3212,  1.7437, -0.6972],\n",
      "        [-1.8652,  0.6957,  1.1057],\n",
      "        [ 0.8869,  0.0180, -1.0531],\n",
      "        [-1.8557,  0.4067,  1.1731],\n",
      "        [-1.1706,  1.7244, -0.6950],\n",
      "        [-1.5109,  1.9220, -0.5945],\n",
      "        [-2.0722,  0.4845,  1.2829],\n",
      "        [-1.2609,  1.7952, -0.4736],\n",
      "        [-1.1271,  1.7924, -0.5193],\n",
      "        [-2.0926,  0.4744,  0.8705],\n",
      "        [-2.1410,  0.3834,  1.2187],\n",
      "        [-1.7444,  1.0950,  0.4633],\n",
      "        [-2.1424,  0.4369,  1.2400],\n",
      "        [ 0.6134,  0.1705, -1.2637]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9182,  0.6705,  1.2135],\n",
      "        [-1.4147,  1.9409, -0.6385],\n",
      "        [-1.3212,  1.7437, -0.6972],\n",
      "        [-1.8652,  0.6957,  1.1057],\n",
      "        [ 0.8869,  0.0180, -1.0531],\n",
      "        [-1.8557,  0.4067,  1.1731],\n",
      "        [-1.1706,  1.7244, -0.6950],\n",
      "        [-1.5109,  1.9220, -0.5945],\n",
      "        [-2.0722,  0.4845,  1.2829],\n",
      "        [-1.2609,  1.7952, -0.4736],\n",
      "        [-1.1271,  1.7924, -0.5193],\n",
      "        [-2.0926,  0.4744,  0.8705],\n",
      "        [-2.1410,  0.3834,  1.2187],\n",
      "        [-1.7444,  1.0950,  0.4633],\n",
      "        [-2.1424,  0.4369,  1.2400],\n",
      "        [ 0.6134,  0.1705, -1.2637]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2230,  1.7260, -0.5721],\n",
      "        [ 0.4844,  0.0548, -1.2928],\n",
      "        [-1.9146,  0.4881,  1.1401],\n",
      "        [-1.1236,  1.8237, -0.6936],\n",
      "        [-1.2575,  1.8025, -0.7942],\n",
      "        [-1.7539,  0.9195,  0.7819],\n",
      "        [-1.3229,  1.7824, -0.6866],\n",
      "        [-1.2576,  1.6920, -0.7410],\n",
      "        [-1.1460,  1.6915, -0.4082],\n",
      "        [-1.2487,  1.8380, -0.6483],\n",
      "        [-1.4020,  1.9758, -0.6805],\n",
      "        [-1.4553,  1.6299, -0.5433],\n",
      "        [ 0.8784, -0.0973, -1.5148],\n",
      "        [-2.1698,  0.9719,  1.0023],\n",
      "        [-1.5623,  2.0327, -0.5930],\n",
      "        [-1.4193,  1.6842, -0.6759]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.2230,  1.7260, -0.5721],\n",
      "        [ 0.4844,  0.0548, -1.2928],\n",
      "        [-1.9146,  0.4881,  1.1401],\n",
      "        [-1.1236,  1.8237, -0.6936],\n",
      "        [-1.2575,  1.8025, -0.7942],\n",
      "        [-1.7539,  0.9195,  0.7819],\n",
      "        [-1.3229,  1.7824, -0.6866],\n",
      "        [-1.2576,  1.6920, -0.7410],\n",
      "        [-1.1460,  1.6915, -0.4082],\n",
      "        [-1.2487,  1.8380, -0.6483],\n",
      "        [-1.4020,  1.9758, -0.6805],\n",
      "        [-1.4553,  1.6299, -0.5433],\n",
      "        [ 0.8784, -0.0973, -1.5148],\n",
      "        [-2.1698,  0.9719,  1.0023],\n",
      "        [-1.5623,  2.0327, -0.5930],\n",
      "        [-1.4193,  1.6842, -0.6759]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5464,  1.9728, -0.5843],\n",
      "        [ 0.2994,  0.5409, -1.3286],\n",
      "        [-1.2858,  1.9562, -0.6760],\n",
      "        [-1.3944,  1.8175, -0.5205],\n",
      "        [-1.2658,  1.9602, -0.5192],\n",
      "        [-0.9726,  1.5920, -0.6153],\n",
      "        [-1.3663,  2.0263, -0.5498],\n",
      "        [-1.1800,  2.0644, -0.8729],\n",
      "        [-1.3224,  1.8881, -0.5845],\n",
      "        [-1.1211,  1.6591, -0.6654],\n",
      "        [-1.8040,  0.8419,  1.0696],\n",
      "        [-1.3856,  1.8127, -0.5920],\n",
      "        [-1.3789,  1.7856, -0.8844],\n",
      "        [-2.0842,  0.5684,  1.3097],\n",
      "        [-1.8666,  0.4077,  1.4099],\n",
      "        [-1.1933,  1.6860, -0.6123]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5464,  1.9728, -0.5843],\n",
      "        [ 0.2994,  0.5409, -1.3286],\n",
      "        [-1.2858,  1.9562, -0.6760],\n",
      "        [-1.3944,  1.8175, -0.5205],\n",
      "        [-1.2658,  1.9602, -0.5192],\n",
      "        [-0.9726,  1.5920, -0.6153],\n",
      "        [-1.3663,  2.0263, -0.5498],\n",
      "        [-1.1800,  2.0644, -0.8729],\n",
      "        [-1.3224,  1.8881, -0.5845],\n",
      "        [-1.1211,  1.6591, -0.6654],\n",
      "        [-1.8040,  0.8419,  1.0696],\n",
      "        [-1.3856,  1.8127, -0.5920],\n",
      "        [-1.3789,  1.7856, -0.8844],\n",
      "        [-2.0842,  0.5684,  1.3097],\n",
      "        [-1.8666,  0.4077,  1.4099],\n",
      "        [-1.1933,  1.6860, -0.6123]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0654,  0.7857,  0.9667],\n",
      "        [-2.0715,  0.6821,  1.1525],\n",
      "        [-1.1638,  1.8495, -0.7548],\n",
      "        [-1.9374,  0.3100,  1.1615],\n",
      "        [-1.9757,  0.5018,  1.1756],\n",
      "        [ 0.5410,  0.5442, -1.4320],\n",
      "        [-1.1750,  1.7128, -0.7033],\n",
      "        [-1.9599,  1.4369, -0.0343],\n",
      "        [-1.6082,  1.2177,  0.2608],\n",
      "        [-2.1619,  0.3883,  1.4059],\n",
      "        [-1.2408,  1.8533, -0.6565],\n",
      "        [-2.0921,  0.4307,  1.3296],\n",
      "        [-1.2488,  1.7007, -0.5931],\n",
      "        [-1.8630,  0.7860,  0.9583],\n",
      "        [-1.2012,  1.6320, -0.7519],\n",
      "        [-0.3129,  0.4164, -0.4739]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.0654,  0.7857,  0.9667],\n",
      "        [-2.0715,  0.6821,  1.1525],\n",
      "        [-1.1638,  1.8495, -0.7548],\n",
      "        [-1.9374,  0.3100,  1.1615],\n",
      "        [-1.9757,  0.5018,  1.1756],\n",
      "        [ 0.5410,  0.5442, -1.4320],\n",
      "        [-1.1750,  1.7128, -0.7033],\n",
      "        [-1.9599,  1.4369, -0.0343],\n",
      "        [-1.6082,  1.2177,  0.2608],\n",
      "        [-2.1619,  0.3883,  1.4059],\n",
      "        [-1.2408,  1.8533, -0.6565],\n",
      "        [-2.0921,  0.4307,  1.3296],\n",
      "        [-1.2488,  1.7007, -0.5931],\n",
      "        [-1.8630,  0.7860,  0.9583],\n",
      "        [-1.2012,  1.6320, -0.7519],\n",
      "        [-0.3129,  0.4164, -0.4739]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5568,  0.4292, -1.3453],\n",
      "        [-1.8409,  1.0242,  0.7166],\n",
      "        [-1.1672,  1.8231, -0.7262],\n",
      "        [-1.3786,  1.6938, -0.6403],\n",
      "        [-1.6864,  0.9725,  0.4815],\n",
      "        [-1.7907,  0.6383,  1.2391],\n",
      "        [-1.1072,  1.7749, -0.9505],\n",
      "        [ 0.6613,  0.0315, -1.3803],\n",
      "        [-1.3122,  1.7186, -0.3937],\n",
      "        [-0.1576,  1.2097, -1.3143],\n",
      "        [-2.0510,  0.5821,  1.0222],\n",
      "        [-1.4201,  1.8472, -0.7247],\n",
      "        [-1.2571,  1.8037, -0.5596],\n",
      "        [-1.2376,  1.9978, -0.7919],\n",
      "        [-1.5114,  1.8378, -0.6587],\n",
      "        [-0.9912,  1.5882, -0.9602]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.5568,  0.4292, -1.3453],\n",
      "        [-1.8409,  1.0242,  0.7166],\n",
      "        [-1.1672,  1.8231, -0.7262],\n",
      "        [-1.3786,  1.6938, -0.6403],\n",
      "        [-1.6864,  0.9725,  0.4815],\n",
      "        [-1.7907,  0.6383,  1.2391],\n",
      "        [-1.1072,  1.7749, -0.9505],\n",
      "        [ 0.6613,  0.0315, -1.3803],\n",
      "        [-1.3122,  1.7186, -0.3937],\n",
      "        [-0.1576,  1.2097, -1.3143],\n",
      "        [-2.0510,  0.5821,  1.0222],\n",
      "        [-1.4201,  1.8472, -0.7247],\n",
      "        [-1.2571,  1.8037, -0.5596],\n",
      "        [-1.2376,  1.9978, -0.7919],\n",
      "        [-1.5114,  1.8378, -0.6587],\n",
      "        [-0.9912,  1.5882, -0.9602]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3022e+00,  1.9159e+00, -7.8685e-01],\n",
      "        [ 7.0236e-01, -6.1270e-04, -1.3235e+00],\n",
      "        [-1.0925e+00,  1.6672e+00, -6.3969e-01],\n",
      "        [-1.3856e+00,  1.8600e+00, -5.8580e-01],\n",
      "        [-1.1209e+00,  1.9830e+00, -7.8471e-01],\n",
      "        [-1.1855e+00,  1.8249e+00, -7.4370e-01],\n",
      "        [-1.5269e+00,  1.7148e+00, -4.1585e-01],\n",
      "        [-1.3917e+00,  1.7128e+00, -5.0233e-01],\n",
      "        [-1.4011e+00,  2.0413e+00, -6.4042e-01],\n",
      "        [-1.9527e+00,  9.6954e-01,  8.2678e-01],\n",
      "        [-1.3062e+00,  2.2253e+00, -9.1745e-01],\n",
      "        [-1.1559e+00,  1.9323e+00, -9.1174e-01],\n",
      "        [-1.3734e+00,  1.8555e+00, -7.8837e-01],\n",
      "        [-1.1349e+00,  1.7496e+00, -6.5388e-01],\n",
      "        [ 6.0231e-01,  2.6591e-01, -1.2346e+00],\n",
      "        [ 7.0978e-01,  2.5408e-01, -1.2132e+00]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3022e+00,  1.9159e+00, -7.8685e-01],\n",
      "        [ 7.0236e-01, -6.1270e-04, -1.3235e+00],\n",
      "        [-1.0925e+00,  1.6672e+00, -6.3969e-01],\n",
      "        [-1.3856e+00,  1.8600e+00, -5.8580e-01],\n",
      "        [-1.1209e+00,  1.9830e+00, -7.8471e-01],\n",
      "        [-1.1855e+00,  1.8249e+00, -7.4370e-01],\n",
      "        [-1.5269e+00,  1.7148e+00, -4.1585e-01],\n",
      "        [-1.3917e+00,  1.7128e+00, -5.0233e-01],\n",
      "        [-1.4011e+00,  2.0413e+00, -6.4042e-01],\n",
      "        [-1.9527e+00,  9.6954e-01,  8.2678e-01],\n",
      "        [-1.3062e+00,  2.2253e+00, -9.1745e-01],\n",
      "        [-1.1559e+00,  1.9323e+00, -9.1174e-01],\n",
      "        [-1.3734e+00,  1.8555e+00, -7.8837e-01],\n",
      "        [-1.1349e+00,  1.7496e+00, -6.5388e-01],\n",
      "        [ 6.0231e-01,  2.6591e-01, -1.2346e+00],\n",
      "        [ 7.0978e-01,  2.5408e-01, -1.2132e+00]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.0045,  1.7508, -0.7985],\n",
      "        [-1.7530,  1.3519,  0.3213],\n",
      "        [-1.9702,  0.4337,  0.9729],\n",
      "        [ 0.7948,  0.0865, -1.3782],\n",
      "        [ 0.9227, -0.0269, -1.4967],\n",
      "        [-1.4366,  2.0554, -1.1314],\n",
      "        [-1.9684,  0.8793,  0.8256],\n",
      "        [-1.5901,  0.6566,  0.7490],\n",
      "        [-2.1799,  0.6012,  1.1130],\n",
      "        [-1.6804,  1.0236,  0.6753],\n",
      "        [ 0.5366,  0.2473, -1.2606],\n",
      "        [-1.1310,  1.9484, -0.9212],\n",
      "        [-0.8821,  1.8953, -0.7711],\n",
      "        [-1.2510,  1.7944, -0.4676],\n",
      "        [-1.0121,  1.8656, -0.9432],\n",
      "        [-1.2250,  1.5960, -0.8978]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.0045,  1.7508, -0.7985],\n",
      "        [-1.7530,  1.3519,  0.3213],\n",
      "        [-1.9702,  0.4337,  0.9729],\n",
      "        [ 0.7948,  0.0865, -1.3782],\n",
      "        [ 0.9227, -0.0269, -1.4967],\n",
      "        [-1.4366,  2.0554, -1.1314],\n",
      "        [-1.9684,  0.8793,  0.8256],\n",
      "        [-1.5901,  0.6566,  0.7490],\n",
      "        [-2.1799,  0.6012,  1.1130],\n",
      "        [-1.6804,  1.0236,  0.6753],\n",
      "        [ 0.5366,  0.2473, -1.2606],\n",
      "        [-1.1310,  1.9484, -0.9212],\n",
      "        [-0.8821,  1.8953, -0.7711],\n",
      "        [-1.2510,  1.7944, -0.4676],\n",
      "        [-1.0121,  1.8656, -0.9432],\n",
      "        [-1.2250,  1.5960, -0.8978]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.0879,  1.6673, -0.8520],\n",
      "        [-1.8490,  0.5803,  1.1191],\n",
      "        [-1.2699,  1.7404, -0.8651],\n",
      "        [-0.9991,  1.7683, -0.9722],\n",
      "        [-1.5849,  2.0401, -0.6617],\n",
      "        [-1.7385,  0.6299,  1.0002],\n",
      "        [-1.2610,  1.8504, -0.8388],\n",
      "        [-1.0468,  1.9685, -0.9539],\n",
      "        [-1.3102,  1.7936, -1.0276],\n",
      "        [-1.3861,  1.7502, -0.8206],\n",
      "        [-1.1645,  1.9035, -0.9399],\n",
      "        [-1.8903,  0.6225,  0.9835],\n",
      "        [-1.0608,  1.7873, -1.2894],\n",
      "        [-1.2349,  1.6266, -0.8761],\n",
      "        [-0.8548,  1.8699, -0.8309],\n",
      "        [ 0.7458,  0.1585, -1.2875]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.0879,  1.6673, -0.8520],\n",
      "        [-1.8490,  0.5803,  1.1191],\n",
      "        [-1.2699,  1.7404, -0.8651],\n",
      "        [-0.9991,  1.7683, -0.9722],\n",
      "        [-1.5849,  2.0401, -0.6617],\n",
      "        [-1.7385,  0.6299,  1.0002],\n",
      "        [-1.2610,  1.8504, -0.8388],\n",
      "        [-1.0468,  1.9685, -0.9539],\n",
      "        [-1.3102,  1.7936, -1.0276],\n",
      "        [-1.3861,  1.7502, -0.8206],\n",
      "        [-1.1645,  1.9035, -0.9399],\n",
      "        [-1.8903,  0.6225,  0.9835],\n",
      "        [-1.0608,  1.7873, -1.2894],\n",
      "        [-1.2349,  1.6266, -0.8761],\n",
      "        [-0.8548,  1.8699, -0.8309],\n",
      "        [ 0.7458,  0.1585, -1.2875]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5460,  1.5132, -0.2246],\n",
      "        [-1.1616,  1.9937, -0.9842],\n",
      "        [-1.1928,  2.0404, -0.9426],\n",
      "        [-1.0432,  1.7096, -0.9011],\n",
      "        [-1.0689,  1.8844, -1.0115],\n",
      "        [-1.0370,  1.8997, -0.7174],\n",
      "        [-1.9597,  0.3398,  1.3562],\n",
      "        [-1.3898,  1.8579, -0.7156],\n",
      "        [-1.1565,  2.0296, -1.1172],\n",
      "        [-1.7355,  1.1915,  0.6051],\n",
      "        [ 0.8996,  0.0133, -1.4088],\n",
      "        [-1.7188,  0.2684,  1.1036],\n",
      "        [-1.2149,  2.2147, -0.8110],\n",
      "        [-1.1661,  1.9460, -1.0870],\n",
      "        [-1.1402,  1.7817, -0.8169],\n",
      "        [-1.6898,  0.8359,  0.5573]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5460,  1.5132, -0.2246],\n",
      "        [-1.1616,  1.9937, -0.9842],\n",
      "        [-1.1928,  2.0404, -0.9426],\n",
      "        [-1.0432,  1.7096, -0.9011],\n",
      "        [-1.0689,  1.8844, -1.0115],\n",
      "        [-1.0370,  1.8997, -0.7174],\n",
      "        [-1.9597,  0.3398,  1.3562],\n",
      "        [-1.3898,  1.8579, -0.7156],\n",
      "        [-1.1565,  2.0296, -1.1172],\n",
      "        [-1.7355,  1.1915,  0.6051],\n",
      "        [ 0.8996,  0.0133, -1.4088],\n",
      "        [-1.7188,  0.2684,  1.1036],\n",
      "        [-1.2149,  2.2147, -0.8110],\n",
      "        [-1.1661,  1.9460, -1.0870],\n",
      "        [-1.1402,  1.7817, -0.8169],\n",
      "        [-1.6898,  0.8359,  0.5573]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.1539,  1.8567, -0.9108],\n",
      "        [-1.0757,  1.7874, -0.9408],\n",
      "        [ 0.6980,  0.1571, -1.5232],\n",
      "        [-0.9135,  1.7426, -0.8436],\n",
      "        [-1.2011,  1.9592, -0.8463],\n",
      "        [-1.1043,  1.9942, -0.8999],\n",
      "        [ 0.7722,  0.2031, -1.4467],\n",
      "        [-1.3314,  1.7983, -1.2084],\n",
      "        [-1.0578,  1.8830, -0.8569],\n",
      "        [ 0.7598,  0.1153, -1.5907],\n",
      "        [-1.1494,  2.0112, -0.7062],\n",
      "        [-1.2194,  1.9500, -0.9169],\n",
      "        [-1.0593,  1.7605, -0.9848],\n",
      "        [-0.9623,  1.7225, -0.7948],\n",
      "        [-1.1187,  1.7423, -0.6794],\n",
      "        [-0.7864,  0.3707, -0.1227]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.1539,  1.8567, -0.9108],\n",
      "        [-1.0757,  1.7874, -0.9408],\n",
      "        [ 0.6980,  0.1571, -1.5232],\n",
      "        [-0.9135,  1.7426, -0.8436],\n",
      "        [-1.2011,  1.9592, -0.8463],\n",
      "        [-1.1043,  1.9942, -0.8999],\n",
      "        [ 0.7722,  0.2031, -1.4467],\n",
      "        [-1.3314,  1.7983, -1.2084],\n",
      "        [-1.0578,  1.8830, -0.8569],\n",
      "        [ 0.7598,  0.1153, -1.5907],\n",
      "        [-1.1494,  2.0112, -0.7062],\n",
      "        [-1.2194,  1.9500, -0.9169],\n",
      "        [-1.0593,  1.7605, -0.9848],\n",
      "        [-0.9623,  1.7225, -0.7948],\n",
      "        [-1.1187,  1.7423, -0.6794],\n",
      "        [-0.7864,  0.3707, -0.1227]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2572,  2.0995, -0.9043],\n",
      "        [-1.5693,  1.1207,  0.2180],\n",
      "        [-1.7638,  0.6563,  1.2064],\n",
      "        [-1.1339,  1.8548, -0.8653],\n",
      "        [-1.8923,  0.3318,  1.0385],\n",
      "        [-1.1638,  2.0942, -0.8223],\n",
      "        [-0.9418,  1.9050, -1.1166],\n",
      "        [-1.3714,  1.6882, -0.3002],\n",
      "        [-1.1794,  1.9711, -0.9391],\n",
      "        [-1.1239,  1.7946, -0.9890],\n",
      "        [-0.9185,  1.6848, -0.7656],\n",
      "        [-1.1132,  1.8664, -1.1011],\n",
      "        [-1.0569,  1.9514, -0.8969],\n",
      "        [ 0.7641,  0.1688, -1.5592],\n",
      "        [-1.7221,  0.4351,  1.1763],\n",
      "        [-1.8044,  0.4678,  0.7190]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.2572,  2.0995, -0.9043],\n",
      "        [-1.5693,  1.1207,  0.2180],\n",
      "        [-1.7638,  0.6563,  1.2064],\n",
      "        [-1.1339,  1.8548, -0.8653],\n",
      "        [-1.8923,  0.3318,  1.0385],\n",
      "        [-1.1638,  2.0942, -0.8223],\n",
      "        [-0.9418,  1.9050, -1.1166],\n",
      "        [-1.3714,  1.6882, -0.3002],\n",
      "        [-1.1794,  1.9711, -0.9391],\n",
      "        [-1.1239,  1.7946, -0.9890],\n",
      "        [-0.9185,  1.6848, -0.7656],\n",
      "        [-1.1132,  1.8664, -1.1011],\n",
      "        [-1.0569,  1.9514, -0.8969],\n",
      "        [ 0.7641,  0.1688, -1.5592],\n",
      "        [-1.7221,  0.4351,  1.1763],\n",
      "        [-1.8044,  0.4678,  0.7190]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3968,  1.1170,  0.1600],\n",
      "        [-1.1105,  1.8828, -0.9412],\n",
      "        [ 0.7416,  0.1530, -1.4807],\n",
      "        [-1.2506,  1.6742, -0.7394],\n",
      "        [-1.1582,  1.6643, -0.8424],\n",
      "        [-1.4683,  2.0730, -1.0563],\n",
      "        [-1.2266,  1.8609, -0.8621],\n",
      "        [-1.1568,  1.6935, -0.7392],\n",
      "        [-1.0782,  1.7536, -0.9230],\n",
      "        [-1.0543,  2.0300, -1.2610],\n",
      "        [-1.2875,  2.0253, -1.0269],\n",
      "        [-1.2144,  1.5157, -0.6906],\n",
      "        [-1.3458,  1.8697, -0.5831],\n",
      "        [ 0.9517,  0.1654, -1.5232],\n",
      "        [ 0.6612,  0.2588, -1.4772],\n",
      "        [-1.5680,  2.0453, -0.5553]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3968,  1.1170,  0.1600],\n",
      "        [-1.1105,  1.8828, -0.9412],\n",
      "        [ 0.7416,  0.1530, -1.4807],\n",
      "        [-1.2506,  1.6742, -0.7394],\n",
      "        [-1.1582,  1.6643, -0.8424],\n",
      "        [-1.4683,  2.0730, -1.0563],\n",
      "        [-1.2266,  1.8609, -0.8621],\n",
      "        [-1.1568,  1.6935, -0.7392],\n",
      "        [-1.0782,  1.7536, -0.9230],\n",
      "        [-1.0543,  2.0300, -1.2610],\n",
      "        [-1.2875,  2.0253, -1.0269],\n",
      "        [-1.2144,  1.5157, -0.6906],\n",
      "        [-1.3458,  1.8697, -0.5831],\n",
      "        [ 0.9517,  0.1654, -1.5232],\n",
      "        [ 0.6612,  0.2588, -1.4772],\n",
      "        [-1.5680,  2.0453, -0.5553]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9363,  0.7292,  0.9451],\n",
      "        [-0.9691,  1.8176, -0.9657],\n",
      "        [-0.1176,  1.1636, -1.3991],\n",
      "        [ 0.4409,  0.5328, -1.4785],\n",
      "        [-0.8600,  1.6185, -1.1559],\n",
      "        [-1.2246,  1.8541, -0.9727],\n",
      "        [ 1.0418,  0.0141, -1.4413],\n",
      "        [ 0.9509, -0.0255, -1.5660],\n",
      "        [-1.1041,  1.8692, -0.9663],\n",
      "        [-1.0476,  1.9305, -1.0825],\n",
      "        [-1.2880,  1.8826, -0.6314],\n",
      "        [-1.2366,  2.0376, -0.9280],\n",
      "        [-1.4903,  1.1711,  0.3159],\n",
      "        [-1.2137,  2.0383, -1.0807],\n",
      "        [-1.5031,  0.9657,  0.4169],\n",
      "        [-0.9496,  1.6362, -0.6836]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9363,  0.7292,  0.9451],\n",
      "        [-0.9691,  1.8176, -0.9657],\n",
      "        [-0.1176,  1.1636, -1.3991],\n",
      "        [ 0.4409,  0.5328, -1.4785],\n",
      "        [-0.8600,  1.6185, -1.1559],\n",
      "        [-1.2246,  1.8541, -0.9727],\n",
      "        [ 1.0418,  0.0141, -1.4413],\n",
      "        [ 0.9509, -0.0255, -1.5660],\n",
      "        [-1.1041,  1.8692, -0.9663],\n",
      "        [-1.0476,  1.9305, -1.0825],\n",
      "        [-1.2880,  1.8826, -0.6314],\n",
      "        [-1.2366,  2.0376, -0.9280],\n",
      "        [-1.4903,  1.1711,  0.3159],\n",
      "        [-1.2137,  2.0383, -1.0807],\n",
      "        [-1.5031,  0.9657,  0.4169],\n",
      "        [-0.9496,  1.6362, -0.6836]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2209,  1.7011, -0.8016],\n",
      "        [-0.2799,  0.6785, -1.1007],\n",
      "        [-1.1602,  1.8352, -0.9001],\n",
      "        [-1.9805,  0.3911,  1.3652],\n",
      "        [-1.0625,  1.8297, -0.7860],\n",
      "        [-1.1465,  1.9567, -0.8079],\n",
      "        [-1.3293,  1.8865, -0.7376],\n",
      "        [-1.6228,  0.4929,  1.1897],\n",
      "        [-2.0465,  0.4673,  1.3679],\n",
      "        [-1.3154,  1.7574, -0.3704],\n",
      "        [-0.9323,  1.6516, -0.7405],\n",
      "        [-1.6412,  0.5156,  0.9000],\n",
      "        [-1.1796,  1.8227, -0.8473],\n",
      "        [ 0.8915,  0.0726, -1.4268],\n",
      "        [-1.4766,  0.6681,  0.9950],\n",
      "        [-1.0744,  1.8677, -0.6860]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.2209,  1.7011, -0.8016],\n",
      "        [-0.2799,  0.6785, -1.1007],\n",
      "        [-1.1602,  1.8352, -0.9001],\n",
      "        [-1.9805,  0.3911,  1.3652],\n",
      "        [-1.0625,  1.8297, -0.7860],\n",
      "        [-1.1465,  1.9567, -0.8079],\n",
      "        [-1.3293,  1.8865, -0.7376],\n",
      "        [-1.6228,  0.4929,  1.1897],\n",
      "        [-2.0465,  0.4673,  1.3679],\n",
      "        [-1.3154,  1.7574, -0.3704],\n",
      "        [-0.9323,  1.6516, -0.7405],\n",
      "        [-1.6412,  0.5156,  0.9000],\n",
      "        [-1.1796,  1.8227, -0.8473],\n",
      "        [ 0.8915,  0.0726, -1.4268],\n",
      "        [-1.4766,  0.6681,  0.9950],\n",
      "        [-1.0744,  1.8677, -0.6860]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2481e+00,  1.6101e+00, -6.4918e-01],\n",
      "        [ 9.0738e-01,  4.2274e-02, -1.6025e+00],\n",
      "        [-1.2278e+00,  1.8212e+00, -9.5408e-01],\n",
      "        [-1.2248e+00,  1.6238e+00, -7.1598e-01],\n",
      "        [-1.2919e+00,  1.8981e+00, -1.0462e+00],\n",
      "        [-1.2756e+00,  1.8487e+00, -7.5254e-01],\n",
      "        [-1.7241e+00,  5.8346e-01,  9.6085e-01],\n",
      "        [-1.2902e+00,  1.8767e+00, -9.1800e-01],\n",
      "        [-1.2703e+00,  1.7327e+00, -7.0105e-01],\n",
      "        [ 7.2231e-01, -9.1702e-04, -1.4584e+00],\n",
      "        [-1.8788e+00,  5.6083e-01,  1.1984e+00],\n",
      "        [-1.8518e+00,  3.5096e-01,  9.6794e-01],\n",
      "        [-1.7351e+00,  4.3894e-01,  1.2448e+00],\n",
      "        [-1.4215e+00,  2.0234e+00, -8.3062e-01],\n",
      "        [-1.1393e+00,  1.9277e+00, -7.3338e-01],\n",
      "        [-1.1849e+00,  1.7090e+00, -6.6905e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.2481e+00,  1.6101e+00, -6.4918e-01],\n",
      "        [ 9.0738e-01,  4.2274e-02, -1.6025e+00],\n",
      "        [-1.2278e+00,  1.8212e+00, -9.5408e-01],\n",
      "        [-1.2248e+00,  1.6238e+00, -7.1598e-01],\n",
      "        [-1.2919e+00,  1.8981e+00, -1.0462e+00],\n",
      "        [-1.2756e+00,  1.8487e+00, -7.5254e-01],\n",
      "        [-1.7241e+00,  5.8346e-01,  9.6085e-01],\n",
      "        [-1.2902e+00,  1.8767e+00, -9.1800e-01],\n",
      "        [-1.2703e+00,  1.7327e+00, -7.0105e-01],\n",
      "        [ 7.2231e-01, -9.1702e-04, -1.4584e+00],\n",
      "        [-1.8788e+00,  5.6083e-01,  1.1984e+00],\n",
      "        [-1.8518e+00,  3.5096e-01,  9.6794e-01],\n",
      "        [-1.7351e+00,  4.3894e-01,  1.2448e+00],\n",
      "        [-1.4215e+00,  2.0234e+00, -8.3062e-01],\n",
      "        [-1.1393e+00,  1.9277e+00, -7.3338e-01],\n",
      "        [-1.1849e+00,  1.7090e+00, -6.6905e-01]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2338,  1.7177, -0.4985],\n",
      "        [-1.1805,  1.7912, -0.6841],\n",
      "        [ 0.9378,  0.1752, -1.6889],\n",
      "        [-1.5436,  0.5266,  0.5592],\n",
      "        [-1.2166,  1.9537, -0.7880],\n",
      "        [-1.3335,  1.4409, -0.4241],\n",
      "        [-1.7363,  0.5391,  0.7738],\n",
      "        [-1.0982,  1.9428, -0.7983],\n",
      "        [-1.8147,  0.4436,  1.0849],\n",
      "        [-1.5541,  0.2378,  1.2293],\n",
      "        [-1.1311,  1.7413, -0.8503],\n",
      "        [ 0.7526, -0.0091, -1.4832],\n",
      "        [-1.0009,  1.7955, -0.9088],\n",
      "        [-1.9593,  0.2709,  1.1546],\n",
      "        [ 0.1098,  0.8952, -1.4808],\n",
      "        [ 0.8535,  0.0531, -1.6597]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.2338,  1.7177, -0.4985],\n",
      "        [-1.1805,  1.7912, -0.6841],\n",
      "        [ 0.9378,  0.1752, -1.6889],\n",
      "        [-1.5436,  0.5266,  0.5592],\n",
      "        [-1.2166,  1.9537, -0.7880],\n",
      "        [-1.3335,  1.4409, -0.4241],\n",
      "        [-1.7363,  0.5391,  0.7738],\n",
      "        [-1.0982,  1.9428, -0.7983],\n",
      "        [-1.8147,  0.4436,  1.0849],\n",
      "        [-1.5541,  0.2378,  1.2293],\n",
      "        [-1.1311,  1.7413, -0.8503],\n",
      "        [ 0.7526, -0.0091, -1.4832],\n",
      "        [-1.0009,  1.7955, -0.9088],\n",
      "        [-1.9593,  0.2709,  1.1546],\n",
      "        [ 0.1098,  0.8952, -1.4808],\n",
      "        [ 0.8535,  0.0531, -1.6597]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.9450,  0.1052, -1.3090],\n",
      "        [-1.2086,  1.3895, -0.2545],\n",
      "        [-1.0190,  1.6859, -0.5554],\n",
      "        [ 0.7835,  0.0860, -1.4539],\n",
      "        [ 0.9375,  0.0878, -1.5258],\n",
      "        [-1.7934,  0.3142,  1.2431],\n",
      "        [-1.1605,  1.8327, -0.9538],\n",
      "        [-1.0869,  1.5878, -0.6539],\n",
      "        [-1.7040,  0.4626,  1.0026],\n",
      "        [-1.3446,  1.7849, -0.6961],\n",
      "        [-1.2607,  1.5759, -0.6249],\n",
      "        [-1.1654,  1.9066, -0.7969],\n",
      "        [-1.7107,  0.1848,  1.3696],\n",
      "        [-1.5572,  0.4600,  1.0537],\n",
      "        [-1.2287,  1.8028, -0.8689],\n",
      "        [-1.7073,  0.1150,  1.2444]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.9450,  0.1052, -1.3090],\n",
      "        [-1.2086,  1.3895, -0.2545],\n",
      "        [-1.0190,  1.6859, -0.5554],\n",
      "        [ 0.7835,  0.0860, -1.4539],\n",
      "        [ 0.9375,  0.0878, -1.5258],\n",
      "        [-1.7934,  0.3142,  1.2431],\n",
      "        [-1.1605,  1.8327, -0.9538],\n",
      "        [-1.0869,  1.5878, -0.6539],\n",
      "        [-1.7040,  0.4626,  1.0026],\n",
      "        [-1.3446,  1.7849, -0.6961],\n",
      "        [-1.2607,  1.5759, -0.6249],\n",
      "        [-1.1654,  1.9066, -0.7969],\n",
      "        [-1.7107,  0.1848,  1.3696],\n",
      "        [-1.5572,  0.4600,  1.0537],\n",
      "        [-1.2287,  1.8028, -0.8689],\n",
      "        [-1.7073,  0.1150,  1.2444]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7845,  0.4552,  1.2346],\n",
      "        [ 0.8440,  0.1666, -1.4210],\n",
      "        [-1.1233,  1.4841, -0.4240],\n",
      "        [-0.9956,  1.6255, -0.7161],\n",
      "        [-1.1959,  1.7438, -0.7610],\n",
      "        [ 0.8869,  0.0531, -1.4117],\n",
      "        [ 0.7825,  0.0673, -1.5320],\n",
      "        [-1.3825,  1.1081,  0.1086],\n",
      "        [ 0.1039,  0.5704, -1.3997],\n",
      "        [-1.7065,  0.2163,  1.3812],\n",
      "        [-1.2708,  1.6437, -0.5231],\n",
      "        [-1.2938,  1.2109, -0.2221],\n",
      "        [-1.2406,  1.7289, -0.7072],\n",
      "        [-1.1225,  1.5731, -0.7730],\n",
      "        [ 0.8619, -0.0785, -1.5279],\n",
      "        [-1.8423,  0.4825,  1.0006]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7845,  0.4552,  1.2346],\n",
      "        [ 0.8440,  0.1666, -1.4210],\n",
      "        [-1.1233,  1.4841, -0.4240],\n",
      "        [-0.9956,  1.6255, -0.7161],\n",
      "        [-1.1959,  1.7438, -0.7610],\n",
      "        [ 0.8869,  0.0531, -1.4117],\n",
      "        [ 0.7825,  0.0673, -1.5320],\n",
      "        [-1.3825,  1.1081,  0.1086],\n",
      "        [ 0.1039,  0.5704, -1.3997],\n",
      "        [-1.7065,  0.2163,  1.3812],\n",
      "        [-1.2708,  1.6437, -0.5231],\n",
      "        [-1.2938,  1.2109, -0.2221],\n",
      "        [-1.2406,  1.7289, -0.7072],\n",
      "        [-1.1225,  1.5731, -0.7730],\n",
      "        [ 0.8619, -0.0785, -1.5279],\n",
      "        [-1.8423,  0.4825,  1.0006]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5473,  0.7803,  0.6165],\n",
      "        [-1.4082,  0.6253,  0.5837],\n",
      "        [-1.7222,  0.4513,  0.7043],\n",
      "        [-1.7344,  0.6622,  0.9333],\n",
      "        [-1.2916,  1.6426, -0.5133],\n",
      "        [-1.6109,  0.3032,  1.0685],\n",
      "        [-1.0674,  1.5396, -0.3808],\n",
      "        [-1.1699,  1.3881, -0.4750],\n",
      "        [-1.4407,  1.4239, -0.0321],\n",
      "        [-1.6251,  0.3611,  0.8804],\n",
      "        [ 1.0697, -0.0382, -1.6058],\n",
      "        [-1.6235,  0.8798,  0.6938],\n",
      "        [-1.3666,  1.2061, -0.0809],\n",
      "        [-1.6660,  0.3404,  0.9834],\n",
      "        [ 0.8424,  0.0662, -1.4357],\n",
      "        [ 0.9498, -0.0369, -1.4848]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5473,  0.7803,  0.6165],\n",
      "        [-1.4082,  0.6253,  0.5837],\n",
      "        [-1.7222,  0.4513,  0.7043],\n",
      "        [-1.7344,  0.6622,  0.9333],\n",
      "        [-1.2916,  1.6426, -0.5133],\n",
      "        [-1.6109,  0.3032,  1.0685],\n",
      "        [-1.0674,  1.5396, -0.3808],\n",
      "        [-1.1699,  1.3881, -0.4750],\n",
      "        [-1.4407,  1.4239, -0.0321],\n",
      "        [-1.6251,  0.3611,  0.8804],\n",
      "        [ 1.0697, -0.0382, -1.6058],\n",
      "        [-1.6235,  0.8798,  0.6938],\n",
      "        [-1.3666,  1.2061, -0.0809],\n",
      "        [-1.6660,  0.3404,  0.9834],\n",
      "        [ 0.8424,  0.0662, -1.4357],\n",
      "        [ 0.9498, -0.0369, -1.4848]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7395,  0.0594,  1.2972],\n",
      "        [-1.2829,  1.5133, -0.7517],\n",
      "        [-1.5283,  0.2230,  1.0148],\n",
      "        [ 0.6335,  0.1647, -1.5151],\n",
      "        [-1.0690,  1.4453, -0.7077],\n",
      "        [-1.9143,  0.1568,  1.2654],\n",
      "        [-1.6928,  0.9902,  0.4754],\n",
      "        [ 0.7896, -0.1167, -1.3857],\n",
      "        [-1.4923,  1.4078, -0.0893],\n",
      "        [-0.8384,  1.3448, -0.3420],\n",
      "        [-1.6880,  0.1416,  1.3195],\n",
      "        [-1.3519,  1.3868, -0.1737],\n",
      "        [ 0.8461,  0.0455, -1.4572],\n",
      "        [ 0.8685, -0.0135, -1.5054],\n",
      "        [-1.9520,  0.1426,  1.3394],\n",
      "        [-1.7225,  0.2304,  1.2305]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7395,  0.0594,  1.2972],\n",
      "        [-1.2829,  1.5133, -0.7517],\n",
      "        [-1.5283,  0.2230,  1.0148],\n",
      "        [ 0.6335,  0.1647, -1.5151],\n",
      "        [-1.0690,  1.4453, -0.7077],\n",
      "        [-1.9143,  0.1568,  1.2654],\n",
      "        [-1.6928,  0.9902,  0.4754],\n",
      "        [ 0.7896, -0.1167, -1.3857],\n",
      "        [-1.4923,  1.4078, -0.0893],\n",
      "        [-0.8384,  1.3448, -0.3420],\n",
      "        [-1.6880,  0.1416,  1.3195],\n",
      "        [-1.3519,  1.3868, -0.1737],\n",
      "        [ 0.8461,  0.0455, -1.4572],\n",
      "        [ 0.8685, -0.0135, -1.5054],\n",
      "        [-1.9520,  0.1426,  1.3394],\n",
      "        [-1.7225,  0.2304,  1.2305]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4194,  1.4233, -0.4683],\n",
      "        [-1.2843,  1.5269, -0.5704],\n",
      "        [-1.2215,  1.5642, -0.6836],\n",
      "        [-1.0153,  1.2649, -0.7450],\n",
      "        [-1.0909,  1.3958, -0.4184],\n",
      "        [ 0.8235,  0.2344, -1.3819],\n",
      "        [-0.8785,  1.2923, -0.7392],\n",
      "        [-1.2760,  1.4570, -0.4326],\n",
      "        [ 0.9348,  0.1582, -1.4956],\n",
      "        [-1.2649,  1.3128, -0.3762],\n",
      "        [-1.3653,  0.9772,  0.1114],\n",
      "        [-1.1063,  1.3956, -0.3967],\n",
      "        [ 0.2966,  0.4154, -1.1788],\n",
      "        [-1.2358,  1.6846, -0.5981],\n",
      "        [-1.1069,  1.5519, -0.5028],\n",
      "        [-1.2776,  1.6619, -0.4673]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4194,  1.4233, -0.4683],\n",
      "        [-1.2843,  1.5269, -0.5704],\n",
      "        [-1.2215,  1.5642, -0.6836],\n",
      "        [-1.0153,  1.2649, -0.7450],\n",
      "        [-1.0909,  1.3958, -0.4184],\n",
      "        [ 0.8235,  0.2344, -1.3819],\n",
      "        [-0.8785,  1.2923, -0.7392],\n",
      "        [-1.2760,  1.4570, -0.4326],\n",
      "        [ 0.9348,  0.1582, -1.4956],\n",
      "        [-1.2649,  1.3128, -0.3762],\n",
      "        [-1.3653,  0.9772,  0.1114],\n",
      "        [-1.1063,  1.3956, -0.3967],\n",
      "        [ 0.2966,  0.4154, -1.1788],\n",
      "        [-1.2358,  1.6846, -0.5981],\n",
      "        [-1.1069,  1.5519, -0.5028],\n",
      "        [-1.2776,  1.6619, -0.4673]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.7311, -0.0650, -1.3182],\n",
      "        [-1.5111,  1.6931, -0.5944],\n",
      "        [-1.1448,  1.4995, -0.2483],\n",
      "        [-1.6911,  0.3942,  1.1317],\n",
      "        [-1.5439,  1.6742, -0.3924],\n",
      "        [-1.2498,  1.3907, -0.5784],\n",
      "        [-1.0719,  1.3836, -0.6486],\n",
      "        [-1.0495,  1.5175, -0.5909],\n",
      "        [-1.5975,  0.9455,  0.3678],\n",
      "        [-1.5062,  0.2657,  1.2227],\n",
      "        [-1.3058,  1.5403, -0.5557],\n",
      "        [-1.6271,  0.6143,  0.4407],\n",
      "        [-1.5424,  0.3577,  1.1948],\n",
      "        [ 0.8443, -0.0388, -1.3555],\n",
      "        [-1.8571,  0.5172,  1.1264],\n",
      "        [-1.2189,  1.3568, -0.6057]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.7311, -0.0650, -1.3182],\n",
      "        [-1.5111,  1.6931, -0.5944],\n",
      "        [-1.1448,  1.4995, -0.2483],\n",
      "        [-1.6911,  0.3942,  1.1317],\n",
      "        [-1.5439,  1.6742, -0.3924],\n",
      "        [-1.2498,  1.3907, -0.5784],\n",
      "        [-1.0719,  1.3836, -0.6486],\n",
      "        [-1.0495,  1.5175, -0.5909],\n",
      "        [-1.5975,  0.9455,  0.3678],\n",
      "        [-1.5062,  0.2657,  1.2227],\n",
      "        [-1.3058,  1.5403, -0.5557],\n",
      "        [-1.6271,  0.6143,  0.4407],\n",
      "        [-1.5424,  0.3577,  1.1948],\n",
      "        [ 0.8443, -0.0388, -1.3555],\n",
      "        [-1.8571,  0.5172,  1.1264],\n",
      "        [-1.2189,  1.3568, -0.6057]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2319,  1.3747, -0.4830],\n",
      "        [-1.4232,  1.6019, -0.5232],\n",
      "        [ 0.8824,  0.1264, -1.2420],\n",
      "        [-1.0115,  1.5204, -0.6015],\n",
      "        [ 0.8742, -0.0176, -1.2907],\n",
      "        [-0.3580,  0.0865, -0.4361],\n",
      "        [-1.3002,  1.5524, -0.5966],\n",
      "        [-1.2322,  1.4855, -0.4186],\n",
      "        [-1.2239,  1.1088,  0.2638],\n",
      "        [-1.1872,  1.4020, -0.4268],\n",
      "        [-1.2022,  1.6373, -0.7079],\n",
      "        [-1.1509,  1.4039, -0.4190],\n",
      "        [-1.2008,  1.5685, -0.5751],\n",
      "        [-1.0146,  1.4621, -0.5386],\n",
      "        [-1.8223,  0.9962,  0.7762],\n",
      "        [-1.1531,  1.4324, -0.2690]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.2319,  1.3747, -0.4830],\n",
      "        [-1.4232,  1.6019, -0.5232],\n",
      "        [ 0.8824,  0.1264, -1.2420],\n",
      "        [-1.0115,  1.5204, -0.6015],\n",
      "        [ 0.8742, -0.0176, -1.2907],\n",
      "        [-0.3580,  0.0865, -0.4361],\n",
      "        [-1.3002,  1.5524, -0.5966],\n",
      "        [-1.2322,  1.4855, -0.4186],\n",
      "        [-1.2239,  1.1088,  0.2638],\n",
      "        [-1.1872,  1.4020, -0.4268],\n",
      "        [-1.2022,  1.6373, -0.7079],\n",
      "        [-1.1509,  1.4039, -0.4190],\n",
      "        [-1.2008,  1.5685, -0.5751],\n",
      "        [-1.0146,  1.4621, -0.5386],\n",
      "        [-1.8223,  0.9962,  0.7762],\n",
      "        [-1.1531,  1.4324, -0.2690]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6500,  0.2648,  1.1344],\n",
      "        [-1.8280,  0.3065,  1.3491],\n",
      "        [-1.5803,  0.4109,  0.8618],\n",
      "        [-1.3347,  1.6757, -0.4845],\n",
      "        [-1.8669,  0.3047,  1.2771],\n",
      "        [-1.8367,  0.7435,  0.6953],\n",
      "        [ 0.7155, -0.2095, -1.2811],\n",
      "        [-1.5144,  0.4050,  0.6611],\n",
      "        [ 0.5909,  0.0516, -1.2843],\n",
      "        [-1.2118,  1.6497, -0.5463],\n",
      "        [-1.2012,  1.5865, -0.3231],\n",
      "        [-1.2974,  1.5765, -0.5196],\n",
      "        [-1.7316,  0.5576,  1.0830],\n",
      "        [ 0.3425,  0.1548, -1.2967],\n",
      "        [-1.9221,  0.3196,  1.3028],\n",
      "        [-1.3030,  1.3680, -0.4324]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6500,  0.2648,  1.1344],\n",
      "        [-1.8280,  0.3065,  1.3491],\n",
      "        [-1.5803,  0.4109,  0.8618],\n",
      "        [-1.3347,  1.6757, -0.4845],\n",
      "        [-1.8669,  0.3047,  1.2771],\n",
      "        [-1.8367,  0.7435,  0.6953],\n",
      "        [ 0.7155, -0.2095, -1.2811],\n",
      "        [-1.5144,  0.4050,  0.6611],\n",
      "        [ 0.5909,  0.0516, -1.2843],\n",
      "        [-1.2118,  1.6497, -0.5463],\n",
      "        [-1.2012,  1.5865, -0.3231],\n",
      "        [-1.2974,  1.5765, -0.5196],\n",
      "        [-1.7316,  0.5576,  1.0830],\n",
      "        [ 0.3425,  0.1548, -1.2967],\n",
      "        [-1.9221,  0.3196,  1.3028],\n",
      "        [-1.3030,  1.3680, -0.4324]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7127,  0.6542,  0.8089],\n",
      "        [-1.9784,  0.3024,  1.1467],\n",
      "        [-1.4240,  1.7167, -0.4325],\n",
      "        [-1.8239,  0.3555,  1.4811],\n",
      "        [-1.4296,  1.4566, -0.3509],\n",
      "        [ 0.7373,  0.0763, -1.1247],\n",
      "        [-1.7304,  1.0373,  0.3476],\n",
      "        [-1.5278,  1.6722, -0.4388],\n",
      "        [-2.1506,  0.2411,  1.1690],\n",
      "        [-1.4712,  1.5008, -0.4876],\n",
      "        [-1.4334,  1.2518, -0.0951],\n",
      "        [-1.8495,  0.4049,  1.0965],\n",
      "        [ 0.7611,  0.1529, -1.3797],\n",
      "        [-2.0108,  0.2234,  1.2850],\n",
      "        [-1.7896,  0.5349,  0.7742],\n",
      "        [-1.9435,  0.3320,  1.3788]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7127,  0.6542,  0.8089],\n",
      "        [-1.9784,  0.3024,  1.1467],\n",
      "        [-1.4240,  1.7167, -0.4325],\n",
      "        [-1.8239,  0.3555,  1.4811],\n",
      "        [-1.4296,  1.4566, -0.3509],\n",
      "        [ 0.7373,  0.0763, -1.1247],\n",
      "        [-1.7304,  1.0373,  0.3476],\n",
      "        [-1.5278,  1.6722, -0.4388],\n",
      "        [-2.1506,  0.2411,  1.1690],\n",
      "        [-1.4712,  1.5008, -0.4876],\n",
      "        [-1.4334,  1.2518, -0.0951],\n",
      "        [-1.8495,  0.4049,  1.0965],\n",
      "        [ 0.7611,  0.1529, -1.3797],\n",
      "        [-2.0108,  0.2234,  1.2850],\n",
      "        [-1.7896,  0.5349,  0.7742],\n",
      "        [-1.9435,  0.3320,  1.3788]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8646,  0.2702,  1.1433],\n",
      "        [-1.7733,  0.9756,  0.2533],\n",
      "        [-1.1991,  1.6099, -0.4840],\n",
      "        [-1.3933,  1.3644, -0.2193],\n",
      "        [-0.7151,  1.1705, -0.9671],\n",
      "        [-1.1931,  1.3953, -0.5147],\n",
      "        [ 0.4185,  0.3924, -1.0878],\n",
      "        [-1.1967,  1.7546, -0.4502],\n",
      "        [-1.5091,  1.2852, -0.2201],\n",
      "        [-1.4127,  1.4071, -0.3239],\n",
      "        [-1.9795,  0.3961,  1.1312],\n",
      "        [-1.1576,  1.3166, -0.2295],\n",
      "        [-1.3776,  1.5198, -0.4447],\n",
      "        [-1.0778,  1.1876, -0.1084],\n",
      "        [ 0.8626, -0.1333, -1.2625],\n",
      "        [-1.2398,  1.5753, -0.4338]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8646,  0.2702,  1.1433],\n",
      "        [-1.7733,  0.9756,  0.2533],\n",
      "        [-1.1991,  1.6099, -0.4840],\n",
      "        [-1.3933,  1.3644, -0.2193],\n",
      "        [-0.7151,  1.1705, -0.9671],\n",
      "        [-1.1931,  1.3953, -0.5147],\n",
      "        [ 0.4185,  0.3924, -1.0878],\n",
      "        [-1.1967,  1.7546, -0.4502],\n",
      "        [-1.5091,  1.2852, -0.2201],\n",
      "        [-1.4127,  1.4071, -0.3239],\n",
      "        [-1.9795,  0.3961,  1.1312],\n",
      "        [-1.1576,  1.3166, -0.2295],\n",
      "        [-1.3776,  1.5198, -0.4447],\n",
      "        [-1.0778,  1.1876, -0.1084],\n",
      "        [ 0.8626, -0.1333, -1.2625],\n",
      "        [-1.2398,  1.5753, -0.4338]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3478,  1.6947, -0.3865],\n",
      "        [-1.9357,  0.4183,  1.2156],\n",
      "        [-1.2414,  1.5292, -0.5826],\n",
      "        [-1.9644,  0.4724,  1.1213],\n",
      "        [ 0.7355, -0.0554, -1.1373],\n",
      "        [-1.3071,  1.6060, -0.2901],\n",
      "        [-1.4915,  1.5927, -0.2930],\n",
      "        [-1.4906,  1.4856, -0.5445],\n",
      "        [-1.6913,  0.4430,  1.1161],\n",
      "        [-1.1363,  1.5962, -0.2959],\n",
      "        [ 0.8704, -0.0848, -1.2662],\n",
      "        [-1.3308,  1.6376, -0.3967],\n",
      "        [-1.3795,  1.4462, -0.3199],\n",
      "        [ 0.7124,  0.1545, -1.0887],\n",
      "        [ 0.8813, -0.0183, -1.1687],\n",
      "        [ 0.8702, -0.0266, -1.1140]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3478,  1.6947, -0.3865],\n",
      "        [-1.9357,  0.4183,  1.2156],\n",
      "        [-1.2414,  1.5292, -0.5826],\n",
      "        [-1.9644,  0.4724,  1.1213],\n",
      "        [ 0.7355, -0.0554, -1.1373],\n",
      "        [-1.3071,  1.6060, -0.2901],\n",
      "        [-1.4915,  1.5927, -0.2930],\n",
      "        [-1.4906,  1.4856, -0.5445],\n",
      "        [-1.6913,  0.4430,  1.1161],\n",
      "        [-1.1363,  1.5962, -0.2959],\n",
      "        [ 0.8704, -0.0848, -1.2662],\n",
      "        [-1.3308,  1.6376, -0.3967],\n",
      "        [-1.3795,  1.4462, -0.3199],\n",
      "        [ 0.7124,  0.1545, -1.0887],\n",
      "        [ 0.8813, -0.0183, -1.1687],\n",
      "        [ 0.8702, -0.0266, -1.1140]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6604,  1.0155,  0.5482],\n",
      "        [-1.2378,  1.6229, -0.3434],\n",
      "        [-1.7073,  0.4479,  1.0907],\n",
      "        [-1.7688,  0.6071,  1.0239],\n",
      "        [-1.3926,  1.3165, -0.4828],\n",
      "        [-1.7956,  0.5813,  0.9887],\n",
      "        [-1.1401,  1.5316, -0.6384],\n",
      "        [-1.7839,  0.7698,  0.9600],\n",
      "        [-1.3770,  1.7243, -0.7434],\n",
      "        [-1.2547,  1.7151, -0.5165],\n",
      "        [-1.4982,  1.6194, -0.4914],\n",
      "        [-1.3244,  1.6066, -0.5537],\n",
      "        [-1.7099,  0.6024,  0.7702],\n",
      "        [-1.9391,  0.4967,  1.3140],\n",
      "        [ 0.6076,  0.0162, -1.2623],\n",
      "        [-1.2562,  1.5436, -0.3713]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6604,  1.0155,  0.5482],\n",
      "        [-1.2378,  1.6229, -0.3434],\n",
      "        [-1.7073,  0.4479,  1.0907],\n",
      "        [-1.7688,  0.6071,  1.0239],\n",
      "        [-1.3926,  1.3165, -0.4828],\n",
      "        [-1.7956,  0.5813,  0.9887],\n",
      "        [-1.1401,  1.5316, -0.6384],\n",
      "        [-1.7839,  0.7698,  0.9600],\n",
      "        [-1.3770,  1.7243, -0.7434],\n",
      "        [-1.2547,  1.7151, -0.5165],\n",
      "        [-1.4982,  1.6194, -0.4914],\n",
      "        [-1.3244,  1.6066, -0.5537],\n",
      "        [-1.7099,  0.6024,  0.7702],\n",
      "        [-1.9391,  0.4967,  1.3140],\n",
      "        [ 0.6076,  0.0162, -1.2623],\n",
      "        [-1.2562,  1.5436, -0.3713]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.8332,  0.0454, -1.1640],\n",
      "        [-1.5699,  1.5436, -0.2541],\n",
      "        [-1.7987,  1.1147,  0.6372],\n",
      "        [-2.0563,  0.4580,  1.1145],\n",
      "        [-1.5753,  1.8549, -0.6522],\n",
      "        [-2.0364,  0.4692,  1.3504],\n",
      "        [-1.4394,  1.8417, -0.5128],\n",
      "        [-1.7371,  0.6059,  1.0673],\n",
      "        [-1.3650,  1.7555, -0.3829],\n",
      "        [-1.3187,  1.6373, -0.4381],\n",
      "        [-1.5279,  1.7628, -0.3859],\n",
      "        [-1.3328,  1.7343, -0.4530],\n",
      "        [-1.3860,  1.5962, -0.1153],\n",
      "        [-1.4257,  1.5689, -0.4959],\n",
      "        [-1.6327,  1.3521, -0.1773],\n",
      "        [ 0.7857,  0.0276, -1.1685]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.8332,  0.0454, -1.1640],\n",
      "        [-1.5699,  1.5436, -0.2541],\n",
      "        [-1.7987,  1.1147,  0.6372],\n",
      "        [-2.0563,  0.4580,  1.1145],\n",
      "        [-1.5753,  1.8549, -0.6522],\n",
      "        [-2.0364,  0.4692,  1.3504],\n",
      "        [-1.4394,  1.8417, -0.5128],\n",
      "        [-1.7371,  0.6059,  1.0673],\n",
      "        [-1.3650,  1.7555, -0.3829],\n",
      "        [-1.3187,  1.6373, -0.4381],\n",
      "        [-1.5279,  1.7628, -0.3859],\n",
      "        [-1.3328,  1.7343, -0.4530],\n",
      "        [-1.3860,  1.5962, -0.1153],\n",
      "        [-1.4257,  1.5689, -0.4959],\n",
      "        [-1.6327,  1.3521, -0.1773],\n",
      "        [ 0.7857,  0.0276, -1.1685]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.3130,  0.5464, -0.7475],\n",
      "        [-1.2938,  1.7043, -0.3873],\n",
      "        [-1.5365,  1.5644, -0.0504],\n",
      "        [-2.0903,  0.5578,  1.2598],\n",
      "        [-2.1467,  0.8975,  1.1075],\n",
      "        [ 0.6997,  0.0311, -1.2849],\n",
      "        [-1.6216,  0.2548,  0.9040],\n",
      "        [-1.5677,  1.4653, -0.0430],\n",
      "        [-1.8674,  0.9818,  0.6507],\n",
      "        [-1.7389,  1.8073, -0.4413],\n",
      "        [-1.8331,  0.8003,  0.9739],\n",
      "        [-1.5813,  1.8667, -0.5390],\n",
      "        [-1.8847,  0.5511,  1.0722],\n",
      "        [-1.5226,  1.6107, -0.0027],\n",
      "        [-1.5127,  1.8899, -0.3856],\n",
      "        [-0.4887,  0.2154, -0.2878]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-0.3130,  0.5464, -0.7475],\n",
      "        [-1.2938,  1.7043, -0.3873],\n",
      "        [-1.5365,  1.5644, -0.0504],\n",
      "        [-2.0903,  0.5578,  1.2598],\n",
      "        [-2.1467,  0.8975,  1.1075],\n",
      "        [ 0.6997,  0.0311, -1.2849],\n",
      "        [-1.6216,  0.2548,  0.9040],\n",
      "        [-1.5677,  1.4653, -0.0430],\n",
      "        [-1.8674,  0.9818,  0.6507],\n",
      "        [-1.7389,  1.8073, -0.4413],\n",
      "        [-1.8331,  0.8003,  0.9739],\n",
      "        [-1.5813,  1.8667, -0.5390],\n",
      "        [-1.8847,  0.5511,  1.0722],\n",
      "        [-1.5226,  1.6107, -0.0027],\n",
      "        [-1.5127,  1.8899, -0.3856],\n",
      "        [-0.4887,  0.2154, -0.2878]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9783,  0.8449,  0.9736],\n",
      "        [-1.7054,  0.6322,  1.2184],\n",
      "        [-1.3637,  1.6659, -0.3531],\n",
      "        [-1.6383,  1.7700, -0.2650],\n",
      "        [-0.9550,  1.5749, -0.9238],\n",
      "        [-0.9746,  1.5981, -0.7315],\n",
      "        [-1.4975,  1.5045, -0.4240],\n",
      "        [-1.8196,  0.6680,  0.9109],\n",
      "        [-2.0048,  0.3002,  0.8922],\n",
      "        [-1.2780,  1.7291, -0.2388],\n",
      "        [-1.5051,  1.7916, -0.4947],\n",
      "        [-1.9982,  0.4547,  0.9998],\n",
      "        [-1.4016,  1.6161, -0.6049],\n",
      "        [-1.5443,  1.7188, -0.3842],\n",
      "        [-1.5866,  1.6066, -0.2372],\n",
      "        [-1.5463,  1.8993, -0.3644]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9783,  0.8449,  0.9736],\n",
      "        [-1.7054,  0.6322,  1.2184],\n",
      "        [-1.3637,  1.6659, -0.3531],\n",
      "        [-1.6383,  1.7700, -0.2650],\n",
      "        [-0.9550,  1.5749, -0.9238],\n",
      "        [-0.9746,  1.5981, -0.7315],\n",
      "        [-1.4975,  1.5045, -0.4240],\n",
      "        [-1.8196,  0.6680,  0.9109],\n",
      "        [-2.0048,  0.3002,  0.8922],\n",
      "        [-1.2780,  1.7291, -0.2388],\n",
      "        [-1.5051,  1.7916, -0.4947],\n",
      "        [-1.9982,  0.4547,  0.9998],\n",
      "        [-1.4016,  1.6161, -0.6049],\n",
      "        [-1.5443,  1.7188, -0.3842],\n",
      "        [-1.5866,  1.6066, -0.2372],\n",
      "        [-1.5463,  1.8993, -0.3644]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3136,  1.5902, -0.5112],\n",
      "        [ 0.7096, -0.1270, -1.2147],\n",
      "        [-1.0270,  1.1001, -0.2966],\n",
      "        [-1.9627,  0.4918,  1.2720],\n",
      "        [ 0.8780, -0.1102, -1.2956],\n",
      "        [-1.2584,  1.7526, -0.3917],\n",
      "        [-2.1053,  0.5603,  1.1325],\n",
      "        [-1.9079,  0.7782,  0.7833],\n",
      "        [-1.8409,  1.3804,  0.0776],\n",
      "        [ 0.4777, -0.0935, -1.2431],\n",
      "        [-1.5096,  1.8867, -0.4133],\n",
      "        [-1.9709,  0.5486,  1.2458],\n",
      "        [-1.5286,  1.6605, -0.0954],\n",
      "        [-1.8676,  0.5191,  0.9045],\n",
      "        [-1.5490,  1.9116, -0.6679],\n",
      "        [ 0.6980, -0.0974, -1.1223]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3136,  1.5902, -0.5112],\n",
      "        [ 0.7096, -0.1270, -1.2147],\n",
      "        [-1.0270,  1.1001, -0.2966],\n",
      "        [-1.9627,  0.4918,  1.2720],\n",
      "        [ 0.8780, -0.1102, -1.2956],\n",
      "        [-1.2584,  1.7526, -0.3917],\n",
      "        [-2.1053,  0.5603,  1.1325],\n",
      "        [-1.9079,  0.7782,  0.7833],\n",
      "        [-1.8409,  1.3804,  0.0776],\n",
      "        [ 0.4777, -0.0935, -1.2431],\n",
      "        [-1.5096,  1.8867, -0.4133],\n",
      "        [-1.9709,  0.5486,  1.2458],\n",
      "        [-1.5286,  1.6605, -0.0954],\n",
      "        [-1.8676,  0.5191,  0.9045],\n",
      "        [-1.5490,  1.9116, -0.6679],\n",
      "        [ 0.6980, -0.0974, -1.1223]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7610,  1.7175, -0.0374],\n",
      "        [-1.5387,  1.7460, -0.4824],\n",
      "        [ 0.4251, -0.0502, -1.1125],\n",
      "        [-1.2672,  1.5132, -0.5068],\n",
      "        [-1.4891,  1.6385, -0.4849],\n",
      "        [-1.4609,  1.6613, -0.3905],\n",
      "        [ 0.5579, -0.0233, -1.0235],\n",
      "        [-1.9201,  1.2441,  0.2777],\n",
      "        [-1.6950,  1.7653, -0.2647],\n",
      "        [-1.6592,  1.8762, -0.2554],\n",
      "        [-2.0511,  0.5309,  1.0319],\n",
      "        [-2.0605,  0.6900,  1.1617],\n",
      "        [-1.9827,  0.5754,  1.2170],\n",
      "        [-1.5506,  1.9015, -0.5592],\n",
      "        [-1.9444,  0.4830,  1.1188],\n",
      "        [-0.4614,  0.0955,  0.0528]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7610,  1.7175, -0.0374],\n",
      "        [-1.5387,  1.7460, -0.4824],\n",
      "        [ 0.4251, -0.0502, -1.1125],\n",
      "        [-1.2672,  1.5132, -0.5068],\n",
      "        [-1.4891,  1.6385, -0.4849],\n",
      "        [-1.4609,  1.6613, -0.3905],\n",
      "        [ 0.5579, -0.0233, -1.0235],\n",
      "        [-1.9201,  1.2441,  0.2777],\n",
      "        [-1.6950,  1.7653, -0.2647],\n",
      "        [-1.6592,  1.8762, -0.2554],\n",
      "        [-2.0511,  0.5309,  1.0319],\n",
      "        [-2.0605,  0.6900,  1.1617],\n",
      "        [-1.9827,  0.5754,  1.2170],\n",
      "        [-1.5506,  1.9015, -0.5592],\n",
      "        [-1.9444,  0.4830,  1.1188],\n",
      "        [-0.4614,  0.0955,  0.0528]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3870,  1.8747, -0.5252],\n",
      "        [-0.6808,  0.5764, -0.3189],\n",
      "        [-1.5552,  1.6978, -0.5673],\n",
      "        [-1.8719,  0.6016,  1.2056],\n",
      "        [ 0.3636,  0.1326, -1.1680],\n",
      "        [ 0.4047,  0.0034, -1.0980],\n",
      "        [ 0.6545, -0.1523, -1.1883],\n",
      "        [-1.5553,  1.4817, -0.1674],\n",
      "        [-1.8692,  1.7253,  0.1265],\n",
      "        [-2.0642,  1.0620,  0.6283],\n",
      "        [-1.5214,  1.7471, -0.3785],\n",
      "        [-1.9054,  0.4298,  1.1921],\n",
      "        [ 0.6562,  0.0435, -1.0392],\n",
      "        [-1.8737,  1.7900, -0.3048],\n",
      "        [ 0.6531, -0.0565, -1.0490],\n",
      "        [-1.3043,  1.8035, -0.6089]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3870,  1.8747, -0.5252],\n",
      "        [-0.6808,  0.5764, -0.3189],\n",
      "        [-1.5552,  1.6978, -0.5673],\n",
      "        [-1.8719,  0.6016,  1.2056],\n",
      "        [ 0.3636,  0.1326, -1.1680],\n",
      "        [ 0.4047,  0.0034, -1.0980],\n",
      "        [ 0.6545, -0.1523, -1.1883],\n",
      "        [-1.5553,  1.4817, -0.1674],\n",
      "        [-1.8692,  1.7253,  0.1265],\n",
      "        [-2.0642,  1.0620,  0.6283],\n",
      "        [-1.5214,  1.7471, -0.3785],\n",
      "        [-1.9054,  0.4298,  1.1921],\n",
      "        [ 0.6562,  0.0435, -1.0392],\n",
      "        [-1.8737,  1.7900, -0.3048],\n",
      "        [ 0.6531, -0.0565, -1.0490],\n",
      "        [-1.3043,  1.8035, -0.6089]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.6877,  0.0825, -1.0842],\n",
      "        [ 0.3188,  0.0414, -0.9937],\n",
      "        [-1.9203,  0.5059,  1.1309],\n",
      "        [-1.8470,  1.6172, -0.1391],\n",
      "        [-1.7868,  0.5889,  1.0344],\n",
      "        [-1.6309,  1.7605, -0.4309],\n",
      "        [-1.7507,  0.6170,  1.0000],\n",
      "        [-1.7595,  0.7326,  1.1672],\n",
      "        [-1.7489,  1.6784, -0.0684],\n",
      "        [-1.6789,  1.8460, -0.5965],\n",
      "        [-1.6598,  1.5342, -0.1678],\n",
      "        [-1.8706,  0.6895,  1.0202],\n",
      "        [ 0.4774,  0.0574, -1.0752],\n",
      "        [-1.9362,  1.5017,  0.0409],\n",
      "        [-1.8719,  1.9139, -0.3835],\n",
      "        [-1.7111,  1.8147, -0.2902]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.6877,  0.0825, -1.0842],\n",
      "        [ 0.3188,  0.0414, -0.9937],\n",
      "        [-1.9203,  0.5059,  1.1309],\n",
      "        [-1.8470,  1.6172, -0.1391],\n",
      "        [-1.7868,  0.5889,  1.0344],\n",
      "        [-1.6309,  1.7605, -0.4309],\n",
      "        [-1.7507,  0.6170,  1.0000],\n",
      "        [-1.7595,  0.7326,  1.1672],\n",
      "        [-1.7489,  1.6784, -0.0684],\n",
      "        [-1.6789,  1.8460, -0.5965],\n",
      "        [-1.6598,  1.5342, -0.1678],\n",
      "        [-1.8706,  0.6895,  1.0202],\n",
      "        [ 0.4774,  0.0574, -1.0752],\n",
      "        [-1.9362,  1.5017,  0.0409],\n",
      "        [-1.8719,  1.9139, -0.3835],\n",
      "        [-1.7111,  1.8147, -0.2902]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7926,  1.2538,  0.1324],\n",
      "        [-1.4643,  1.5333, -0.3716],\n",
      "        [-1.2582,  1.7926, -0.7374],\n",
      "        [-1.7174,  1.8820, -0.3118],\n",
      "        [-1.3848,  1.7812, -0.1496],\n",
      "        [-1.3915,  1.7756, -0.3984],\n",
      "        [-2.0721,  0.3824,  1.0687],\n",
      "        [-1.8623,  0.5505,  1.3003],\n",
      "        [-1.3988,  1.8949, -0.6814],\n",
      "        [ 0.5483, -0.1260, -0.9051],\n",
      "        [-1.5344,  1.7347, -0.4198],\n",
      "        [-1.8799,  0.6302,  0.7981],\n",
      "        [-1.2248,  1.7088, -0.3904],\n",
      "        [ 0.6741, -0.1529, -1.0382],\n",
      "        [-1.6245,  1.7248, -0.1776],\n",
      "        [ 0.5092,  0.3719, -1.1278]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7926,  1.2538,  0.1324],\n",
      "        [-1.4643,  1.5333, -0.3716],\n",
      "        [-1.2582,  1.7926, -0.7374],\n",
      "        [-1.7174,  1.8820, -0.3118],\n",
      "        [-1.3848,  1.7812, -0.1496],\n",
      "        [-1.3915,  1.7756, -0.3984],\n",
      "        [-2.0721,  0.3824,  1.0687],\n",
      "        [-1.8623,  0.5505,  1.3003],\n",
      "        [-1.3988,  1.8949, -0.6814],\n",
      "        [ 0.5483, -0.1260, -0.9051],\n",
      "        [-1.5344,  1.7347, -0.4198],\n",
      "        [-1.8799,  0.6302,  0.7981],\n",
      "        [-1.2248,  1.7088, -0.3904],\n",
      "        [ 0.6741, -0.1529, -1.0382],\n",
      "        [-1.6245,  1.7248, -0.1776],\n",
      "        [ 0.5092,  0.3719, -1.1278]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7493,  1.8066, -0.3060],\n",
      "        [-1.8466,  1.6551, -0.1940],\n",
      "        [-1.6501,  2.0675, -0.2103],\n",
      "        [-1.8050,  0.4219,  1.0088],\n",
      "        [-1.6517,  1.6133, -0.0089],\n",
      "        [-1.4355,  1.6309, -0.4093],\n",
      "        [-1.6227,  1.9014, -0.4526],\n",
      "        [-2.0161,  0.5188,  1.0512],\n",
      "        [-0.1399,  0.0906, -0.7190],\n",
      "        [-1.2718,  1.7319, -0.3560],\n",
      "        [ 0.5033,  0.0126, -1.0248],\n",
      "        [-1.6985,  1.9408, -0.6873],\n",
      "        [ 0.4278,  0.0590, -0.9776],\n",
      "        [-1.7257,  1.8730, -0.6668],\n",
      "        [-1.5839,  1.8679, -0.2501],\n",
      "        [-1.4954,  1.8168, -0.4137]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7493,  1.8066, -0.3060],\n",
      "        [-1.8466,  1.6551, -0.1940],\n",
      "        [-1.6501,  2.0675, -0.2103],\n",
      "        [-1.8050,  0.4219,  1.0088],\n",
      "        [-1.6517,  1.6133, -0.0089],\n",
      "        [-1.4355,  1.6309, -0.4093],\n",
      "        [-1.6227,  1.9014, -0.4526],\n",
      "        [-2.0161,  0.5188,  1.0512],\n",
      "        [-0.1399,  0.0906, -0.7190],\n",
      "        [-1.2718,  1.7319, -0.3560],\n",
      "        [ 0.5033,  0.0126, -1.0248],\n",
      "        [-1.6985,  1.9408, -0.6873],\n",
      "        [ 0.4278,  0.0590, -0.9776],\n",
      "        [-1.7257,  1.8730, -0.6668],\n",
      "        [-1.5839,  1.8679, -0.2501],\n",
      "        [-1.4954,  1.8168, -0.4137]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7259,  1.7368, -0.2479],\n",
      "        [-1.6895,  1.6306, -0.3804],\n",
      "        [ 0.4343, -0.0604, -1.0008],\n",
      "        [-1.3779,  1.8124, -0.3625],\n",
      "        [ 0.6756,  0.0095, -0.9997],\n",
      "        [-1.8957,  0.2728,  1.1351],\n",
      "        [-1.3018,  1.6902, -0.5133],\n",
      "        [-1.8607,  0.5557,  1.0020],\n",
      "        [ 0.4196,  0.1003, -1.2012],\n",
      "        [-2.0616,  0.6477,  1.2719],\n",
      "        [-1.8006,  1.8503, -0.4527],\n",
      "        [-1.4441,  1.7524, -0.4437],\n",
      "        [ 0.5141,  0.0537, -0.9983],\n",
      "        [-1.9433,  0.5941,  0.9625],\n",
      "        [-1.3910,  1.8121, -0.4031],\n",
      "        [-1.4052,  1.7558, -0.4799]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7259,  1.7368, -0.2479],\n",
      "        [-1.6895,  1.6306, -0.3804],\n",
      "        [ 0.4343, -0.0604, -1.0008],\n",
      "        [-1.3779,  1.8124, -0.3625],\n",
      "        [ 0.6756,  0.0095, -0.9997],\n",
      "        [-1.8957,  0.2728,  1.1351],\n",
      "        [-1.3018,  1.6902, -0.5133],\n",
      "        [-1.8607,  0.5557,  1.0020],\n",
      "        [ 0.4196,  0.1003, -1.2012],\n",
      "        [-2.0616,  0.6477,  1.2719],\n",
      "        [-1.8006,  1.8503, -0.4527],\n",
      "        [-1.4441,  1.7524, -0.4437],\n",
      "        [ 0.5141,  0.0537, -0.9983],\n",
      "        [-1.9433,  0.5941,  0.9625],\n",
      "        [-1.3910,  1.8121, -0.4031],\n",
      "        [-1.4052,  1.7558, -0.4799]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5915,  1.6810, -0.4745],\n",
      "        [-1.1975,  1.5447, -0.3282],\n",
      "        [-1.4628,  1.5660, -0.4459],\n",
      "        [-2.0123,  0.7495,  0.9439],\n",
      "        [-1.6156,  1.7273, -0.5315],\n",
      "        [-0.0138,  0.6013, -1.0542],\n",
      "        [ 0.5276,  0.0164, -0.8731],\n",
      "        [ 0.5389, -0.2086, -1.1330],\n",
      "        [ 0.4266, -0.0875, -1.0895],\n",
      "        [-1.6777,  1.5985, -0.2665],\n",
      "        [-1.7716,  1.9595, -0.3429],\n",
      "        [-0.6334,  0.3456, -0.1269],\n",
      "        [-2.0059,  1.1196,  0.8211],\n",
      "        [-1.4174,  1.8089, -0.1430],\n",
      "        [ 0.5941, -0.0174, -1.0389],\n",
      "        [-1.7215,  2.0467, -0.5487]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5915,  1.6810, -0.4745],\n",
      "        [-1.1975,  1.5447, -0.3282],\n",
      "        [-1.4628,  1.5660, -0.4459],\n",
      "        [-2.0123,  0.7495,  0.9439],\n",
      "        [-1.6156,  1.7273, -0.5315],\n",
      "        [-0.0138,  0.6013, -1.0542],\n",
      "        [ 0.5276,  0.0164, -0.8731],\n",
      "        [ 0.5389, -0.2086, -1.1330],\n",
      "        [ 0.4266, -0.0875, -1.0895],\n",
      "        [-1.6777,  1.5985, -0.2665],\n",
      "        [-1.7716,  1.9595, -0.3429],\n",
      "        [-0.6334,  0.3456, -0.1269],\n",
      "        [-2.0059,  1.1196,  0.8211],\n",
      "        [-1.4174,  1.8089, -0.1430],\n",
      "        [ 0.5941, -0.0174, -1.0389],\n",
      "        [-1.7215,  2.0467, -0.5487]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8738,  0.9999,  0.7472],\n",
      "        [-1.7668,  0.3663,  1.0391],\n",
      "        [-1.5064,  1.9793, -0.7428],\n",
      "        [-1.6527,  1.7843, -0.3672],\n",
      "        [-1.5615,  1.4983, -0.2631],\n",
      "        [-1.9133,  0.9148,  0.7166],\n",
      "        [-1.8024,  0.6218,  0.9474],\n",
      "        [-1.9101,  0.8138,  1.0283],\n",
      "        [-1.5873,  1.6972, -0.3673],\n",
      "        [ 0.4719,  0.1115, -0.9263],\n",
      "        [-1.6149,  1.5395,  0.2697],\n",
      "        [-1.5896,  1.7750, -0.2543],\n",
      "        [-1.6042,  2.1437, -0.5672],\n",
      "        [-2.1619,  0.7106,  1.0542],\n",
      "        [-1.7202,  1.0387,  0.5896],\n",
      "        [ 0.3119, -0.0426, -1.1309]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8738,  0.9999,  0.7472],\n",
      "        [-1.7668,  0.3663,  1.0391],\n",
      "        [-1.5064,  1.9793, -0.7428],\n",
      "        [-1.6527,  1.7843, -0.3672],\n",
      "        [-1.5615,  1.4983, -0.2631],\n",
      "        [-1.9133,  0.9148,  0.7166],\n",
      "        [-1.8024,  0.6218,  0.9474],\n",
      "        [-1.9101,  0.8138,  1.0283],\n",
      "        [-1.5873,  1.6972, -0.3673],\n",
      "        [ 0.4719,  0.1115, -0.9263],\n",
      "        [-1.6149,  1.5395,  0.2697],\n",
      "        [-1.5896,  1.7750, -0.2543],\n",
      "        [-1.6042,  2.1437, -0.5672],\n",
      "        [-2.1619,  0.7106,  1.0542],\n",
      "        [-1.7202,  1.0387,  0.5896],\n",
      "        [ 0.3119, -0.0426, -1.1309]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7022,  1.8766, -0.3303],\n",
      "        [-1.6848,  1.7804,  0.0296],\n",
      "        [-1.3732,  1.7541, -0.6703],\n",
      "        [-1.6590,  1.3935, -0.0576],\n",
      "        [-1.4124,  1.5945, -0.5280],\n",
      "        [-1.7464,  0.7454,  0.8787],\n",
      "        [ 0.2333,  0.0666, -0.9316],\n",
      "        [-1.6996,  0.6265,  0.9180],\n",
      "        [-1.6029,  1.7154, -0.1192],\n",
      "        [-2.0075,  0.8397,  0.8324],\n",
      "        [ 0.4199,  0.0363, -0.9235],\n",
      "        [-1.7616,  1.5063,  0.0929],\n",
      "        [-1.6413,  0.5028,  0.9327],\n",
      "        [-1.8800,  0.5749,  1.0072],\n",
      "        [ 0.2321, -0.1021, -0.8881],\n",
      "        [-1.8112,  0.6606,  0.9214]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7022,  1.8766, -0.3303],\n",
      "        [-1.6848,  1.7804,  0.0296],\n",
      "        [-1.3732,  1.7541, -0.6703],\n",
      "        [-1.6590,  1.3935, -0.0576],\n",
      "        [-1.4124,  1.5945, -0.5280],\n",
      "        [-1.7464,  0.7454,  0.8787],\n",
      "        [ 0.2333,  0.0666, -0.9316],\n",
      "        [-1.6996,  0.6265,  0.9180],\n",
      "        [-1.6029,  1.7154, -0.1192],\n",
      "        [-2.0075,  0.8397,  0.8324],\n",
      "        [ 0.4199,  0.0363, -0.9235],\n",
      "        [-1.7616,  1.5063,  0.0929],\n",
      "        [-1.6413,  0.5028,  0.9327],\n",
      "        [-1.8800,  0.5749,  1.0072],\n",
      "        [ 0.2321, -0.1021, -0.8881],\n",
      "        [-1.8112,  0.6606,  0.9214]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6509,  1.7240, -0.4084],\n",
      "        [-1.6662,  1.8180,  0.0030],\n",
      "        [-1.8449,  1.2857, -0.0028],\n",
      "        [-1.5329,  1.4043,  0.0221],\n",
      "        [-1.4670,  1.5271, -0.3293],\n",
      "        [-1.6408,  1.2345, -0.0190],\n",
      "        [-1.8369,  0.5460,  1.0128],\n",
      "        [-1.6930,  1.6429, -0.3711],\n",
      "        [-1.7184,  1.7716, -0.0739],\n",
      "        [-1.8335,  0.5122,  1.0599],\n",
      "        [-1.7393,  0.5746,  0.8765],\n",
      "        [-1.5766,  1.7982, -0.0382],\n",
      "        [-1.9390,  0.5352,  0.8296],\n",
      "        [-1.7382,  0.4407,  0.9546],\n",
      "        [-1.6217,  1.5794, -0.0860],\n",
      "        [-1.5763,  1.7593, -0.1771]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6509,  1.7240, -0.4084],\n",
      "        [-1.6662,  1.8180,  0.0030],\n",
      "        [-1.8449,  1.2857, -0.0028],\n",
      "        [-1.5329,  1.4043,  0.0221],\n",
      "        [-1.4670,  1.5271, -0.3293],\n",
      "        [-1.6408,  1.2345, -0.0190],\n",
      "        [-1.8369,  0.5460,  1.0128],\n",
      "        [-1.6930,  1.6429, -0.3711],\n",
      "        [-1.7184,  1.7716, -0.0739],\n",
      "        [-1.8335,  0.5122,  1.0599],\n",
      "        [-1.7393,  0.5746,  0.8765],\n",
      "        [-1.5766,  1.7982, -0.0382],\n",
      "        [-1.9390,  0.5352,  0.8296],\n",
      "        [-1.7382,  0.4407,  0.9546],\n",
      "        [-1.6217,  1.5794, -0.0860],\n",
      "        [-1.5763,  1.7593, -0.1771]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3802,  1.2849, -0.0542],\n",
      "        [ 0.3511,  0.0776, -0.9710],\n",
      "        [-1.6171,  1.8058, -0.0964],\n",
      "        [-1.6557,  0.3513,  1.0410],\n",
      "        [-1.6253,  1.6181, -0.0555],\n",
      "        [-1.6384,  1.6075, -0.1877],\n",
      "        [ 0.5009,  0.1121, -0.8591],\n",
      "        [-1.4952,  1.7549, -0.1316],\n",
      "        [ 0.4035,  0.0761, -0.8058],\n",
      "        [-2.0544,  1.1643,  0.7762],\n",
      "        [-1.5359,  1.4548, -0.1110],\n",
      "        [-1.6754,  0.5099,  0.8383],\n",
      "        [ 0.4792, -0.0197, -1.0175],\n",
      "        [-1.7186,  0.5084,  1.0729],\n",
      "        [-1.6672,  0.4393,  0.8619],\n",
      "        [-0.1713,  0.0681, -0.6034]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3802,  1.2849, -0.0542],\n",
      "        [ 0.3511,  0.0776, -0.9710],\n",
      "        [-1.6171,  1.8058, -0.0964],\n",
      "        [-1.6557,  0.3513,  1.0410],\n",
      "        [-1.6253,  1.6181, -0.0555],\n",
      "        [-1.6384,  1.6075, -0.1877],\n",
      "        [ 0.5009,  0.1121, -0.8591],\n",
      "        [-1.4952,  1.7549, -0.1316],\n",
      "        [ 0.4035,  0.0761, -0.8058],\n",
      "        [-2.0544,  1.1643,  0.7762],\n",
      "        [-1.5359,  1.4548, -0.1110],\n",
      "        [-1.6754,  0.5099,  0.8383],\n",
      "        [ 0.4792, -0.0197, -1.0175],\n",
      "        [-1.7186,  0.5084,  1.0729],\n",
      "        [-1.6672,  0.4393,  0.8619],\n",
      "        [-0.1713,  0.0681, -0.6034]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2086,  0.9485,  0.8228],\n",
      "        [-1.6310,  1.8045, -0.3475],\n",
      "        [-1.6272,  1.9088, -0.0549],\n",
      "        [-1.7628,  0.5359,  1.0229],\n",
      "        [-1.6580,  1.6644, -0.3388],\n",
      "        [-1.5936,  1.7318, -0.5406],\n",
      "        [-1.7973,  0.7020,  1.2605],\n",
      "        [-1.7312,  1.6755, -0.1264],\n",
      "        [-1.4174,  1.8860, -0.1012],\n",
      "        [-1.7911,  1.5370, -0.2294],\n",
      "        [-1.4961,  1.5409, -0.3471],\n",
      "        [-1.5226,  1.1931,  0.2591],\n",
      "        [-1.8824,  1.2255,  0.4844],\n",
      "        [-1.6116,  2.1356, -0.5208],\n",
      "        [-1.5408,  1.5306, -0.2389],\n",
      "        [-1.8781,  1.4343,  0.1380]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.2086,  0.9485,  0.8228],\n",
      "        [-1.6310,  1.8045, -0.3475],\n",
      "        [-1.6272,  1.9088, -0.0549],\n",
      "        [-1.7628,  0.5359,  1.0229],\n",
      "        [-1.6580,  1.6644, -0.3388],\n",
      "        [-1.5936,  1.7318, -0.5406],\n",
      "        [-1.7973,  0.7020,  1.2605],\n",
      "        [-1.7312,  1.6755, -0.1264],\n",
      "        [-1.4174,  1.8860, -0.1012],\n",
      "        [-1.7911,  1.5370, -0.2294],\n",
      "        [-1.4961,  1.5409, -0.3471],\n",
      "        [-1.5226,  1.1931,  0.2591],\n",
      "        [-1.8824,  1.2255,  0.4844],\n",
      "        [-1.6116,  2.1356, -0.5208],\n",
      "        [-1.5408,  1.5306, -0.2389],\n",
      "        [-1.8781,  1.4343,  0.1380]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7121,  1.4517, -0.0955],\n",
      "        [-1.5181,  1.7374, -0.3168],\n",
      "        [-1.7725,  0.6270,  1.0591],\n",
      "        [-1.6666,  1.8874, -0.4567],\n",
      "        [-1.7137,  1.9366, -0.3336],\n",
      "        [-0.7007,  1.0823, -0.8382],\n",
      "        [-1.7512,  1.7924, -0.5256],\n",
      "        [ 0.2514, -0.0343, -0.9109],\n",
      "        [-1.5483,  1.6970, -0.2156],\n",
      "        [ 0.2626, -0.0306, -0.9062],\n",
      "        [-1.4696,  1.7020, -0.1306],\n",
      "        [-1.7043,  1.7023, -0.3423],\n",
      "        [-2.0564,  0.6373,  1.1336],\n",
      "        [-1.5670,  1.7854, -0.3273],\n",
      "        [-1.7100,  1.6082, -0.1675],\n",
      "        [-1.5897,  1.9176, -0.2263]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7121,  1.4517, -0.0955],\n",
      "        [-1.5181,  1.7374, -0.3168],\n",
      "        [-1.7725,  0.6270,  1.0591],\n",
      "        [-1.6666,  1.8874, -0.4567],\n",
      "        [-1.7137,  1.9366, -0.3336],\n",
      "        [-0.7007,  1.0823, -0.8382],\n",
      "        [-1.7512,  1.7924, -0.5256],\n",
      "        [ 0.2514, -0.0343, -0.9109],\n",
      "        [-1.5483,  1.6970, -0.2156],\n",
      "        [ 0.2626, -0.0306, -0.9062],\n",
      "        [-1.4696,  1.7020, -0.1306],\n",
      "        [-1.7043,  1.7023, -0.3423],\n",
      "        [-2.0564,  0.6373,  1.1336],\n",
      "        [-1.5670,  1.7854, -0.3273],\n",
      "        [-1.7100,  1.6082, -0.1675],\n",
      "        [-1.5897,  1.9176, -0.2263]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3801,  0.2338, -0.9375],\n",
      "        [-1.6211,  1.9860, -0.4975],\n",
      "        [-1.7957,  0.4672,  0.9757],\n",
      "        [-1.9741,  0.9226,  0.7266],\n",
      "        [-1.6841,  0.4602,  0.8981],\n",
      "        [-1.5944,  1.8431, -0.2109],\n",
      "        [ 0.3315,  0.1338, -0.8914],\n",
      "        [-1.7478,  0.6228,  0.8693],\n",
      "        [ 0.3064, -0.1256, -0.9325],\n",
      "        [-1.3969,  1.7262, -0.6361],\n",
      "        [-1.7543,  1.3060,  0.1969],\n",
      "        [-1.8196,  0.8097,  0.9570],\n",
      "        [-1.5026,  1.6751, -0.0532],\n",
      "        [-1.6889,  1.0472,  0.7146],\n",
      "        [-2.0123,  0.5538,  0.8540],\n",
      "        [-1.5723,  1.8600, -0.3206]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.3801,  0.2338, -0.9375],\n",
      "        [-1.6211,  1.9860, -0.4975],\n",
      "        [-1.7957,  0.4672,  0.9757],\n",
      "        [-1.9741,  0.9226,  0.7266],\n",
      "        [-1.6841,  0.4602,  0.8981],\n",
      "        [-1.5944,  1.8431, -0.2109],\n",
      "        [ 0.3315,  0.1338, -0.8914],\n",
      "        [-1.7478,  0.6228,  0.8693],\n",
      "        [ 0.3064, -0.1256, -0.9325],\n",
      "        [-1.3969,  1.7262, -0.6361],\n",
      "        [-1.7543,  1.3060,  0.1969],\n",
      "        [-1.8196,  0.8097,  0.9570],\n",
      "        [-1.5026,  1.6751, -0.0532],\n",
      "        [-1.6889,  1.0472,  0.7146],\n",
      "        [-2.0123,  0.5538,  0.8540],\n",
      "        [-1.5723,  1.8600, -0.3206]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.5633,  0.0499,  0.0585],\n",
      "        [-1.7509,  1.7157, -0.2564],\n",
      "        [-1.6317,  1.8051, -0.5502],\n",
      "        [-1.9252,  1.9191, -0.4182],\n",
      "        [-1.6463,  1.8332, -0.0860],\n",
      "        [-1.7795,  1.0855,  0.6090],\n",
      "        [-1.7038,  0.8228,  0.6337],\n",
      "        [-1.5327,  1.4852, -0.1349],\n",
      "        [-1.6047,  1.8957, -0.4550],\n",
      "        [-1.7642,  0.5718,  0.8998],\n",
      "        [-2.0118,  0.7838,  0.9195],\n",
      "        [ 0.3696, -0.0115, -0.8378],\n",
      "        [-1.6408,  1.7329, -0.2990],\n",
      "        [-1.7751,  0.8846,  0.8574],\n",
      "        [-1.6503,  0.5879,  0.8486],\n",
      "        [-1.7746,  1.9312, -0.3806]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-0.5633,  0.0499,  0.0585],\n",
      "        [-1.7509,  1.7157, -0.2564],\n",
      "        [-1.6317,  1.8051, -0.5502],\n",
      "        [-1.9252,  1.9191, -0.4182],\n",
      "        [-1.6463,  1.8332, -0.0860],\n",
      "        [-1.7795,  1.0855,  0.6090],\n",
      "        [-1.7038,  0.8228,  0.6337],\n",
      "        [-1.5327,  1.4852, -0.1349],\n",
      "        [-1.6047,  1.8957, -0.4550],\n",
      "        [-1.7642,  0.5718,  0.8998],\n",
      "        [-2.0118,  0.7838,  0.9195],\n",
      "        [ 0.3696, -0.0115, -0.8378],\n",
      "        [-1.6408,  1.7329, -0.2990],\n",
      "        [-1.7751,  0.8846,  0.8574],\n",
      "        [-1.6503,  0.5879,  0.8486],\n",
      "        [-1.7746,  1.9312, -0.3806]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8517,  0.5981,  1.0467],\n",
      "        [-1.5945,  1.9346, -0.2156],\n",
      "        [-1.4919,  1.7977, -0.4101],\n",
      "        [-1.5277,  1.9043, -0.7973],\n",
      "        [ 0.0987,  0.1077, -1.0276],\n",
      "        [-1.7561,  1.7392,  0.0134],\n",
      "        [ 0.2128,  0.3110, -0.9650],\n",
      "        [-1.6700,  1.9100, -0.5321],\n",
      "        [-1.8558,  2.0826, -0.1712],\n",
      "        [-1.7170,  0.5772,  1.0371],\n",
      "        [-1.6391,  1.8957, -0.5136],\n",
      "        [-1.5922,  1.5265, -0.2298],\n",
      "        [-1.9091,  0.6726,  0.8843],\n",
      "        [-1.6938,  1.9434, -0.4080],\n",
      "        [-1.5649,  0.3384,  1.0274],\n",
      "        [-2.0017,  1.6207,  0.1490]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8517,  0.5981,  1.0467],\n",
      "        [-1.5945,  1.9346, -0.2156],\n",
      "        [-1.4919,  1.7977, -0.4101],\n",
      "        [-1.5277,  1.9043, -0.7973],\n",
      "        [ 0.0987,  0.1077, -1.0276],\n",
      "        [-1.7561,  1.7392,  0.0134],\n",
      "        [ 0.2128,  0.3110, -0.9650],\n",
      "        [-1.6700,  1.9100, -0.5321],\n",
      "        [-1.8558,  2.0826, -0.1712],\n",
      "        [-1.7170,  0.5772,  1.0371],\n",
      "        [-1.6391,  1.8957, -0.5136],\n",
      "        [-1.5922,  1.5265, -0.2298],\n",
      "        [-1.9091,  0.6726,  0.8843],\n",
      "        [-1.6938,  1.9434, -0.4080],\n",
      "        [-1.5649,  0.3384,  1.0274],\n",
      "        [-2.0017,  1.6207,  0.1490]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3493, -0.1457, -0.8999],\n",
      "        [-1.5813,  1.7386, -0.2679],\n",
      "        [-1.9161,  0.6639,  1.1261],\n",
      "        [-1.7899,  1.7630, -0.1966],\n",
      "        [-2.0045,  1.1728,  0.6611],\n",
      "        [-1.8848,  0.8672,  0.6822],\n",
      "        [-1.8870,  1.2379,  0.3015],\n",
      "        [-1.7384,  1.9443, -0.3798],\n",
      "        [-1.6802,  0.3418,  1.0362],\n",
      "        [-1.6925,  2.0153, -0.4035],\n",
      "        [-1.7644,  1.8636, -0.4417],\n",
      "        [-1.7842,  0.7821,  0.8121],\n",
      "        [ 0.2843, -0.1404, -0.8527],\n",
      "        [-1.4883,  1.7667, -0.3606],\n",
      "        [ 0.3434, -0.0639, -0.8469],\n",
      "        [-1.5391,  2.0920, -0.3897]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.3493, -0.1457, -0.8999],\n",
      "        [-1.5813,  1.7386, -0.2679],\n",
      "        [-1.9161,  0.6639,  1.1261],\n",
      "        [-1.7899,  1.7630, -0.1966],\n",
      "        [-2.0045,  1.1728,  0.6611],\n",
      "        [-1.8848,  0.8672,  0.6822],\n",
      "        [-1.8870,  1.2379,  0.3015],\n",
      "        [-1.7384,  1.9443, -0.3798],\n",
      "        [-1.6802,  0.3418,  1.0362],\n",
      "        [-1.6925,  2.0153, -0.4035],\n",
      "        [-1.7644,  1.8636, -0.4417],\n",
      "        [-1.7842,  0.7821,  0.8121],\n",
      "        [ 0.2843, -0.1404, -0.8527],\n",
      "        [-1.4883,  1.7667, -0.3606],\n",
      "        [ 0.3434, -0.0639, -0.8469],\n",
      "        [-1.5391,  2.0920, -0.3897]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6053,  1.9436, -0.5422],\n",
      "        [-1.8089,  1.8275, -0.5344],\n",
      "        [ 0.4776, -0.2012, -0.9687],\n",
      "        [-1.6384,  1.8452, -0.4524],\n",
      "        [ 0.3514,  0.0295, -0.9570],\n",
      "        [-1.7714,  1.6923, -0.1573],\n",
      "        [-1.8362,  1.5493,  0.1061],\n",
      "        [-1.7656,  1.3173,  0.0874],\n",
      "        [-1.7632,  1.6686, -0.4125],\n",
      "        [-1.7684,  1.2561,  0.3205],\n",
      "        [-1.5590,  1.8245, -0.3079],\n",
      "        [ 0.2408,  0.0152, -0.8492],\n",
      "        [-1.8124,  0.5650,  1.0243],\n",
      "        [-1.5567,  1.9612, -0.3240],\n",
      "        [-1.7590,  0.7368,  0.5774],\n",
      "        [-1.6754,  2.0079, -0.3971]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6053,  1.9436, -0.5422],\n",
      "        [-1.8089,  1.8275, -0.5344],\n",
      "        [ 0.4776, -0.2012, -0.9687],\n",
      "        [-1.6384,  1.8452, -0.4524],\n",
      "        [ 0.3514,  0.0295, -0.9570],\n",
      "        [-1.7714,  1.6923, -0.1573],\n",
      "        [-1.8362,  1.5493,  0.1061],\n",
      "        [-1.7656,  1.3173,  0.0874],\n",
      "        [-1.7632,  1.6686, -0.4125],\n",
      "        [-1.7684,  1.2561,  0.3205],\n",
      "        [-1.5590,  1.8245, -0.3079],\n",
      "        [ 0.2408,  0.0152, -0.8492],\n",
      "        [-1.8124,  0.5650,  1.0243],\n",
      "        [-1.5567,  1.9612, -0.3240],\n",
      "        [-1.7590,  0.7368,  0.5774],\n",
      "        [-1.6754,  2.0079, -0.3971]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7322,  0.5833,  0.8712],\n",
      "        [-1.5441,  1.7207, -0.1714],\n",
      "        [-1.4173,  1.9071, -0.6055],\n",
      "        [-1.7539,  0.7153,  0.8468],\n",
      "        [-0.3406,  0.7273, -0.9769],\n",
      "        [-1.8413,  0.4675,  1.0166],\n",
      "        [-1.7750,  0.7875,  0.9322],\n",
      "        [-1.7127,  0.9301,  0.8975],\n",
      "        [-1.6560,  1.9659, -0.5360],\n",
      "        [-1.7196,  1.9586, -0.3239],\n",
      "        [-1.7311,  0.4297,  0.9182],\n",
      "        [-1.0358,  0.7666,  0.4168],\n",
      "        [-1.5250,  1.8217, -0.4477],\n",
      "        [-1.8247,  1.8839, -0.7165],\n",
      "        [-1.6689,  1.8355, -0.2694],\n",
      "        [ 0.4420, -0.0880, -0.9167]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7322,  0.5833,  0.8712],\n",
      "        [-1.5441,  1.7207, -0.1714],\n",
      "        [-1.4173,  1.9071, -0.6055],\n",
      "        [-1.7539,  0.7153,  0.8468],\n",
      "        [-0.3406,  0.7273, -0.9769],\n",
      "        [-1.8413,  0.4675,  1.0166],\n",
      "        [-1.7750,  0.7875,  0.9322],\n",
      "        [-1.7127,  0.9301,  0.8975],\n",
      "        [-1.6560,  1.9659, -0.5360],\n",
      "        [-1.7196,  1.9586, -0.3239],\n",
      "        [-1.7311,  0.4297,  0.9182],\n",
      "        [-1.0358,  0.7666,  0.4168],\n",
      "        [-1.5250,  1.8217, -0.4477],\n",
      "        [-1.8247,  1.8839, -0.7165],\n",
      "        [-1.6689,  1.8355, -0.2694],\n",
      "        [ 0.4420, -0.0880, -0.9167]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7437,  2.0448, -0.5546],\n",
      "        [-1.6738,  1.9089, -0.4855],\n",
      "        [-1.4335,  1.7948, -0.6577],\n",
      "        [-1.7304,  1.9475, -0.3578],\n",
      "        [-1.7789,  2.0496, -0.5071],\n",
      "        [-1.2005,  0.6983,  0.4250],\n",
      "        [-1.7411,  2.0197, -0.4741],\n",
      "        [-0.4037,  0.2771, -0.3014],\n",
      "        [-1.6126,  0.2149,  1.0812],\n",
      "        [ 0.5812, -0.1288, -0.8380],\n",
      "        [-1.6224,  1.9599, -0.3730],\n",
      "        [-1.8983,  0.7563,  0.7534],\n",
      "        [-1.7568,  1.7041, -0.4759],\n",
      "        [ 0.0692,  0.1435, -0.9741],\n",
      "        [ 0.1324,  0.2429, -1.0195],\n",
      "        [-1.7623,  0.7693,  0.7694]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7437,  2.0448, -0.5546],\n",
      "        [-1.6738,  1.9089, -0.4855],\n",
      "        [-1.4335,  1.7948, -0.6577],\n",
      "        [-1.7304,  1.9475, -0.3578],\n",
      "        [-1.7789,  2.0496, -0.5071],\n",
      "        [-1.2005,  0.6983,  0.4250],\n",
      "        [-1.7411,  2.0197, -0.4741],\n",
      "        [-0.4037,  0.2771, -0.3014],\n",
      "        [-1.6126,  0.2149,  1.0812],\n",
      "        [ 0.5812, -0.1288, -0.8380],\n",
      "        [-1.6224,  1.9599, -0.3730],\n",
      "        [-1.8983,  0.7563,  0.7534],\n",
      "        [-1.7568,  1.7041, -0.4759],\n",
      "        [ 0.0692,  0.1435, -0.9741],\n",
      "        [ 0.1324,  0.2429, -1.0195],\n",
      "        [-1.7623,  0.7693,  0.7694]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6019,  2.0041, -0.8306],\n",
      "        [-1.6421,  2.0453, -0.4202],\n",
      "        [ 0.4389, -0.1379, -0.8017],\n",
      "        [-1.5533,  1.8997, -0.5175],\n",
      "        [-1.8128,  0.5446,  1.1388],\n",
      "        [-1.6396,  1.7638, -0.5588],\n",
      "        [-1.5916,  2.0492, -0.7416],\n",
      "        [ 0.4771, -0.2299, -0.8506],\n",
      "        [-1.9977,  0.5615,  0.9539],\n",
      "        [-1.6164,  2.0879, -0.4113],\n",
      "        [ 0.3795, -0.1234, -0.6830],\n",
      "        [-1.5766,  0.6052,  0.8614],\n",
      "        [-1.5846,  1.9017, -0.1139],\n",
      "        [-1.7014,  1.7508, -0.2860],\n",
      "        [-1.4770,  1.4877, -0.5657],\n",
      "        [-1.5585,  1.9586, -0.6742]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6019,  2.0041, -0.8306],\n",
      "        [-1.6421,  2.0453, -0.4202],\n",
      "        [ 0.4389, -0.1379, -0.8017],\n",
      "        [-1.5533,  1.8997, -0.5175],\n",
      "        [-1.8128,  0.5446,  1.1388],\n",
      "        [-1.6396,  1.7638, -0.5588],\n",
      "        [-1.5916,  2.0492, -0.7416],\n",
      "        [ 0.4771, -0.2299, -0.8506],\n",
      "        [-1.9977,  0.5615,  0.9539],\n",
      "        [-1.6164,  2.0879, -0.4113],\n",
      "        [ 0.3795, -0.1234, -0.6830],\n",
      "        [-1.5766,  0.6052,  0.8614],\n",
      "        [-1.5846,  1.9017, -0.1139],\n",
      "        [-1.7014,  1.7508, -0.2860],\n",
      "        [-1.4770,  1.4877, -0.5657],\n",
      "        [-1.5585,  1.9586, -0.6742]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7065,  1.8254, -0.3477],\n",
      "        [ 0.2224,  0.1974, -0.9744],\n",
      "        [-1.6090,  0.7140,  1.1357],\n",
      "        [-1.5833,  2.1213, -0.5496],\n",
      "        [-1.8342,  0.5057,  1.0899],\n",
      "        [-1.5672,  1.6880, -0.5944],\n",
      "        [-1.7604,  0.4576,  0.8434],\n",
      "        [-1.8244,  1.9796, -0.8075],\n",
      "        [-1.5622,  1.9199, -0.2403],\n",
      "        [-1.7333,  1.9685, -0.6525],\n",
      "        [-1.8403,  2.1271, -0.4833],\n",
      "        [-1.6670,  0.8526,  0.8462],\n",
      "        [-1.6258,  2.2357, -0.5507],\n",
      "        [-1.2688,  1.9601, -0.7827],\n",
      "        [-1.5731,  2.1601, -0.4835],\n",
      "        [-1.5495,  0.6542,  0.6791]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7065,  1.8254, -0.3477],\n",
      "        [ 0.2224,  0.1974, -0.9744],\n",
      "        [-1.6090,  0.7140,  1.1357],\n",
      "        [-1.5833,  2.1213, -0.5496],\n",
      "        [-1.8342,  0.5057,  1.0899],\n",
      "        [-1.5672,  1.6880, -0.5944],\n",
      "        [-1.7604,  0.4576,  0.8434],\n",
      "        [-1.8244,  1.9796, -0.8075],\n",
      "        [-1.5622,  1.9199, -0.2403],\n",
      "        [-1.7333,  1.9685, -0.6525],\n",
      "        [-1.8403,  2.1271, -0.4833],\n",
      "        [-1.6670,  0.8526,  0.8462],\n",
      "        [-1.6258,  2.2357, -0.5507],\n",
      "        [-1.2688,  1.9601, -0.7827],\n",
      "        [-1.5731,  2.1601, -0.4835],\n",
      "        [-1.5495,  0.6542,  0.6791]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7118,  2.2183, -0.6238],\n",
      "        [-1.6831,  1.8727, -0.6320],\n",
      "        [-1.3401,  1.9675, -0.4143],\n",
      "        [ 0.1783,  0.2057, -1.1051],\n",
      "        [-2.0132,  2.0027, -0.1249],\n",
      "        [ 0.5054, -0.2267, -0.9375],\n",
      "        [-1.5523,  1.3576, -0.0148],\n",
      "        [-1.8589,  0.4266,  1.1245],\n",
      "        [-1.8025,  1.4686,  0.0481],\n",
      "        [-1.7106,  2.0143, -0.4253],\n",
      "        [-1.5467,  2.0352, -0.3726],\n",
      "        [-1.0385,  0.1158,  0.5062],\n",
      "        [-1.5078,  1.8373, -0.5735],\n",
      "        [ 0.0368,  0.2646, -1.1202],\n",
      "        [-1.4570,  1.8124, -0.2613],\n",
      "        [-1.7669,  1.6671,  0.0975]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7118,  2.2183, -0.6238],\n",
      "        [-1.6831,  1.8727, -0.6320],\n",
      "        [-1.3401,  1.9675, -0.4143],\n",
      "        [ 0.1783,  0.2057, -1.1051],\n",
      "        [-2.0132,  2.0027, -0.1249],\n",
      "        [ 0.5054, -0.2267, -0.9375],\n",
      "        [-1.5523,  1.3576, -0.0148],\n",
      "        [-1.8589,  0.4266,  1.1245],\n",
      "        [-1.8025,  1.4686,  0.0481],\n",
      "        [-1.7106,  2.0143, -0.4253],\n",
      "        [-1.5467,  2.0352, -0.3726],\n",
      "        [-1.0385,  0.1158,  0.5062],\n",
      "        [-1.5078,  1.8373, -0.5735],\n",
      "        [ 0.0368,  0.2646, -1.1202],\n",
      "        [-1.4570,  1.8124, -0.2613],\n",
      "        [-1.7669,  1.6671,  0.0975]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6655,  2.0827, -0.3907],\n",
      "        [-1.9213,  2.0319, -0.4715],\n",
      "        [-1.7127,  2.0406, -0.3392],\n",
      "        [-1.6673,  0.7010,  0.7634],\n",
      "        [-1.5330,  1.9561, -0.5189],\n",
      "        [ 0.2909, -0.1607, -0.6177],\n",
      "        [ 0.4890, -0.3274, -0.6618],\n",
      "        [-1.5621,  1.9332, -0.6246],\n",
      "        [-1.4838,  1.8994, -0.5419],\n",
      "        [-1.8331,  0.5519,  0.9931],\n",
      "        [-1.6209,  2.0409, -0.6764],\n",
      "        [-1.6443,  1.9465, -0.3636],\n",
      "        [-1.8636,  2.0527, -0.2969],\n",
      "        [-1.4469,  1.8125, -0.2063],\n",
      "        [-1.7338,  2.1229, -0.5602],\n",
      "        [-1.6909,  1.6198, -0.2978]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6655,  2.0827, -0.3907],\n",
      "        [-1.9213,  2.0319, -0.4715],\n",
      "        [-1.7127,  2.0406, -0.3392],\n",
      "        [-1.6673,  0.7010,  0.7634],\n",
      "        [-1.5330,  1.9561, -0.5189],\n",
      "        [ 0.2909, -0.1607, -0.6177],\n",
      "        [ 0.4890, -0.3274, -0.6618],\n",
      "        [-1.5621,  1.9332, -0.6246],\n",
      "        [-1.4838,  1.8994, -0.5419],\n",
      "        [-1.8331,  0.5519,  0.9931],\n",
      "        [-1.6209,  2.0409, -0.6764],\n",
      "        [-1.6443,  1.9465, -0.3636],\n",
      "        [-1.8636,  2.0527, -0.2969],\n",
      "        [-1.4469,  1.8125, -0.2063],\n",
      "        [-1.7338,  2.1229, -0.5602],\n",
      "        [-1.6909,  1.6198, -0.2978]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8094,  1.8633, -0.6160],\n",
      "        [-1.7225,  0.3433,  1.0621],\n",
      "        [-1.7957,  1.9848, -0.4167],\n",
      "        [-1.9262,  0.7486,  0.8310],\n",
      "        [ 0.4763, -0.2744, -0.7507],\n",
      "        [-1.9679,  0.4663,  1.1724],\n",
      "        [-1.5480,  0.5361,  1.0039],\n",
      "        [-1.7245,  2.1123, -0.5769],\n",
      "        [-1.8360,  1.9398, -0.3278],\n",
      "        [-1.8872,  0.6248,  1.0219],\n",
      "        [-1.6805,  0.3840,  1.1367],\n",
      "        [-1.7665,  1.9022, -0.2766],\n",
      "        [-1.2665,  1.7644, -0.4730],\n",
      "        [-1.6298,  2.0635, -0.4711],\n",
      "        [-1.6417,  0.4009,  0.9251],\n",
      "        [-1.6630,  2.0078, -0.4439]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8094,  1.8633, -0.6160],\n",
      "        [-1.7225,  0.3433,  1.0621],\n",
      "        [-1.7957,  1.9848, -0.4167],\n",
      "        [-1.9262,  0.7486,  0.8310],\n",
      "        [ 0.4763, -0.2744, -0.7507],\n",
      "        [-1.9679,  0.4663,  1.1724],\n",
      "        [-1.5480,  0.5361,  1.0039],\n",
      "        [-1.7245,  2.1123, -0.5769],\n",
      "        [-1.8360,  1.9398, -0.3278],\n",
      "        [-1.8872,  0.6248,  1.0219],\n",
      "        [-1.6805,  0.3840,  1.1367],\n",
      "        [-1.7665,  1.9022, -0.2766],\n",
      "        [-1.2665,  1.7644, -0.4730],\n",
      "        [-1.6298,  2.0635, -0.4711],\n",
      "        [-1.6417,  0.4009,  0.9251],\n",
      "        [-1.6630,  2.0078, -0.4439]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7707,  1.7335, -0.2259],\n",
      "        [-1.5566,  1.7763, -0.5101],\n",
      "        [-1.9082,  2.0146, -0.1573],\n",
      "        [-1.8710,  1.7731,  0.1729],\n",
      "        [-1.7237,  2.1202, -0.3626],\n",
      "        [-1.5457,  0.3285,  1.0272],\n",
      "        [-1.7147,  1.9887, -0.5448],\n",
      "        [-1.8297,  1.4826,  0.3143],\n",
      "        [-1.3802,  0.0455,  0.6718],\n",
      "        [-1.8738,  1.7058, -0.0769],\n",
      "        [-1.8756,  1.4405, -0.0903],\n",
      "        [-1.7592,  1.3426,  0.3612],\n",
      "        [-1.5435,  1.8204, -0.4647],\n",
      "        [-1.7759,  0.5901,  0.9739],\n",
      "        [ 0.5486, -0.2652, -0.7763],\n",
      "        [-1.6763,  2.0776, -0.2302]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7707,  1.7335, -0.2259],\n",
      "        [-1.5566,  1.7763, -0.5101],\n",
      "        [-1.9082,  2.0146, -0.1573],\n",
      "        [-1.8710,  1.7731,  0.1729],\n",
      "        [-1.7237,  2.1202, -0.3626],\n",
      "        [-1.5457,  0.3285,  1.0272],\n",
      "        [-1.7147,  1.9887, -0.5448],\n",
      "        [-1.8297,  1.4826,  0.3143],\n",
      "        [-1.3802,  0.0455,  0.6718],\n",
      "        [-1.8738,  1.7058, -0.0769],\n",
      "        [-1.8756,  1.4405, -0.0903],\n",
      "        [-1.7592,  1.3426,  0.3612],\n",
      "        [-1.5435,  1.8204, -0.4647],\n",
      "        [-1.7759,  0.5901,  0.9739],\n",
      "        [ 0.5486, -0.2652, -0.7763],\n",
      "        [-1.6763,  2.0776, -0.2302]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3289,  1.6413, -0.7728],\n",
      "        [ 0.4096, -0.1663, -0.8247],\n",
      "        [-2.0974,  2.0976, -0.3369],\n",
      "        [-1.7512,  0.8841,  0.9885],\n",
      "        [ 0.5345, -0.1702, -0.8664],\n",
      "        [-1.6641,  0.2440,  0.9708],\n",
      "        [-1.9175,  0.4807,  1.3735],\n",
      "        [-1.7679,  2.0421, -0.4198],\n",
      "        [-1.8150,  0.7540,  0.9288],\n",
      "        [-1.8085,  1.5231,  0.0976],\n",
      "        [-1.6194,  1.9576, -0.5871],\n",
      "        [-0.8456,  0.0736,  0.2901],\n",
      "        [-1.6709,  2.0734, -0.2772],\n",
      "        [ 0.4604, -0.2250, -0.6429],\n",
      "        [-1.6285,  0.3698,  1.0869],\n",
      "        [-1.7858,  0.3491,  1.2211]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3289,  1.6413, -0.7728],\n",
      "        [ 0.4096, -0.1663, -0.8247],\n",
      "        [-2.0974,  2.0976, -0.3369],\n",
      "        [-1.7512,  0.8841,  0.9885],\n",
      "        [ 0.5345, -0.1702, -0.8664],\n",
      "        [-1.6641,  0.2440,  0.9708],\n",
      "        [-1.9175,  0.4807,  1.3735],\n",
      "        [-1.7679,  2.0421, -0.4198],\n",
      "        [-1.8150,  0.7540,  0.9288],\n",
      "        [-1.8085,  1.5231,  0.0976],\n",
      "        [-1.6194,  1.9576, -0.5871],\n",
      "        [-0.8456,  0.0736,  0.2901],\n",
      "        [-1.6709,  2.0734, -0.2772],\n",
      "        [ 0.4604, -0.2250, -0.6429],\n",
      "        [-1.6285,  0.3698,  1.0869],\n",
      "        [-1.7858,  0.3491,  1.2211]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6308,  1.7296, -0.3942],\n",
      "        [-1.9579,  1.7922,  0.0146],\n",
      "        [-1.4591,  0.1624,  1.1802],\n",
      "        [ 0.4970, -0.1785, -0.9226],\n",
      "        [-1.7179,  1.9122, -0.4836],\n",
      "        [-1.7995,  2.1261, -0.2306],\n",
      "        [-1.8418,  1.9652, -0.3473],\n",
      "        [-1.4297,  0.1334,  1.1818],\n",
      "        [-1.8699,  0.5926,  0.8324],\n",
      "        [-1.9244,  0.9474,  0.5301],\n",
      "        [-1.7440,  0.9746,  1.0141],\n",
      "        [-2.0022,  2.0746,  0.0764],\n",
      "        [-1.5102,  1.9464, -0.4964],\n",
      "        [-1.8486,  2.1571, -0.2800],\n",
      "        [-1.8504,  0.5147,  1.0303],\n",
      "        [-1.7886,  1.5782, -0.3427]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6308,  1.7296, -0.3942],\n",
      "        [-1.9579,  1.7922,  0.0146],\n",
      "        [-1.4591,  0.1624,  1.1802],\n",
      "        [ 0.4970, -0.1785, -0.9226],\n",
      "        [-1.7179,  1.9122, -0.4836],\n",
      "        [-1.7995,  2.1261, -0.2306],\n",
      "        [-1.8418,  1.9652, -0.3473],\n",
      "        [-1.4297,  0.1334,  1.1818],\n",
      "        [-1.8699,  0.5926,  0.8324],\n",
      "        [-1.9244,  0.9474,  0.5301],\n",
      "        [-1.7440,  0.9746,  1.0141],\n",
      "        [-2.0022,  2.0746,  0.0764],\n",
      "        [-1.5102,  1.9464, -0.4964],\n",
      "        [-1.8486,  2.1571, -0.2800],\n",
      "        [-1.8504,  0.5147,  1.0303],\n",
      "        [-1.7886,  1.5782, -0.3427]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.3920,  0.7532, -0.6900],\n",
      "        [-1.8025,  1.9164, -0.4972],\n",
      "        [-1.8844,  2.1888, -0.2351],\n",
      "        [-1.6875,  0.7625,  0.6862],\n",
      "        [-1.7248,  1.9270, -0.4190],\n",
      "        [ 0.0719,  0.2219, -0.7717],\n",
      "        [-1.7970,  0.2967,  1.2698],\n",
      "        [-2.0413,  0.5414,  1.2319],\n",
      "        [-1.5996,  1.9234, -0.4221],\n",
      "        [ 0.6151, -0.2913, -0.7568],\n",
      "        [-1.7363,  1.9348, -0.0990],\n",
      "        [-1.6429,  0.3479,  1.2216],\n",
      "        [-1.9164,  1.8624, -0.4039],\n",
      "        [-1.7619,  0.3300,  1.1911],\n",
      "        [-1.6175,  0.8652,  0.3778],\n",
      "        [-1.6818,  0.2448,  1.2245]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-0.3920,  0.7532, -0.6900],\n",
      "        [-1.8025,  1.9164, -0.4972],\n",
      "        [-1.8844,  2.1888, -0.2351],\n",
      "        [-1.6875,  0.7625,  0.6862],\n",
      "        [-1.7248,  1.9270, -0.4190],\n",
      "        [ 0.0719,  0.2219, -0.7717],\n",
      "        [-1.7970,  0.2967,  1.2698],\n",
      "        [-2.0413,  0.5414,  1.2319],\n",
      "        [-1.5996,  1.9234, -0.4221],\n",
      "        [ 0.6151, -0.2913, -0.7568],\n",
      "        [-1.7363,  1.9348, -0.0990],\n",
      "        [-1.6429,  0.3479,  1.2216],\n",
      "        [-1.9164,  1.8624, -0.4039],\n",
      "        [-1.7619,  0.3300,  1.1911],\n",
      "        [-1.6175,  0.8652,  0.3778],\n",
      "        [-1.6818,  0.2448,  1.2245]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6843,  0.1769,  1.3577],\n",
      "        [-1.6072,  0.1309,  1.3600],\n",
      "        [-1.7617,  2.0308, -0.3095],\n",
      "        [-1.5440,  0.2296,  1.2404],\n",
      "        [-1.7038,  1.9413, -0.5335],\n",
      "        [-1.7616,  0.8513,  0.8934],\n",
      "        [-1.8252,  0.5180,  1.0525],\n",
      "        [-1.9035,  2.0929, -0.4117],\n",
      "        [-1.9184,  1.9947, -0.4135],\n",
      "        [-1.7971,  2.0681, -0.2863],\n",
      "        [-1.3335,  0.9165,  0.2362],\n",
      "        [-1.6263,  1.5903, -0.4650],\n",
      "        [-1.5783,  1.6040, -0.4449],\n",
      "        [-1.8806,  1.9936, -0.4118],\n",
      "        [-2.0156,  0.4158,  1.1894],\n",
      "        [-1.9758,  1.8286, -0.1532]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6843,  0.1769,  1.3577],\n",
      "        [-1.6072,  0.1309,  1.3600],\n",
      "        [-1.7617,  2.0308, -0.3095],\n",
      "        [-1.5440,  0.2296,  1.2404],\n",
      "        [-1.7038,  1.9413, -0.5335],\n",
      "        [-1.7616,  0.8513,  0.8934],\n",
      "        [-1.8252,  0.5180,  1.0525],\n",
      "        [-1.9035,  2.0929, -0.4117],\n",
      "        [-1.9184,  1.9947, -0.4135],\n",
      "        [-1.7971,  2.0681, -0.2863],\n",
      "        [-1.3335,  0.9165,  0.2362],\n",
      "        [-1.6263,  1.5903, -0.4650],\n",
      "        [-1.5783,  1.6040, -0.4449],\n",
      "        [-1.8806,  1.9936, -0.4118],\n",
      "        [-2.0156,  0.4158,  1.1894],\n",
      "        [-1.9758,  1.8286, -0.1532]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4401,  1.7471, -0.4319],\n",
      "        [-1.8308,  1.9789, -0.4953],\n",
      "        [ 0.4783, -0.2634, -0.7905],\n",
      "        [-1.8522,  1.4586, -0.0225],\n",
      "        [-1.7396,  1.6992, -0.3369],\n",
      "        [-1.9616,  1.9712, -0.1244],\n",
      "        [-1.7606,  1.9050,  0.0033],\n",
      "        [-1.7555,  0.3587,  1.1986],\n",
      "        [-1.9027,  1.7576, -0.1189],\n",
      "        [-1.9804,  0.7706,  1.0117],\n",
      "        [-1.7503,  0.1044,  1.1608],\n",
      "        [ 0.2854, -0.1032, -0.7467],\n",
      "        [-1.1399,  1.4867, -0.8154],\n",
      "        [-1.9156,  0.7014,  0.9613],\n",
      "        [-1.3528,  0.2496,  0.7380],\n",
      "        [ 0.3150, -0.1402, -0.7129]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4401,  1.7471, -0.4319],\n",
      "        [-1.8308,  1.9789, -0.4953],\n",
      "        [ 0.4783, -0.2634, -0.7905],\n",
      "        [-1.8522,  1.4586, -0.0225],\n",
      "        [-1.7396,  1.6992, -0.3369],\n",
      "        [-1.9616,  1.9712, -0.1244],\n",
      "        [-1.7606,  1.9050,  0.0033],\n",
      "        [-1.7555,  0.3587,  1.1986],\n",
      "        [-1.9027,  1.7576, -0.1189],\n",
      "        [-1.9804,  0.7706,  1.0117],\n",
      "        [-1.7503,  0.1044,  1.1608],\n",
      "        [ 0.2854, -0.1032, -0.7467],\n",
      "        [-1.1399,  1.4867, -0.8154],\n",
      "        [-1.9156,  0.7014,  0.9613],\n",
      "        [-1.3528,  0.2496,  0.7380],\n",
      "        [ 0.3150, -0.1402, -0.7129]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7807e+00,  1.7876e+00, -4.2513e-01],\n",
      "        [-1.7246e+00,  1.7366e+00, -4.2808e-01],\n",
      "        [-2.0551e+00,  1.9004e+00, -8.0623e-02],\n",
      "        [-1.8931e+00,  1.7496e+00, -1.1227e-01],\n",
      "        [ 5.6146e-01, -4.1001e-01, -7.4135e-01],\n",
      "        [-2.1209e+00,  1.1192e+00,  7.5940e-01],\n",
      "        [-1.6049e+00,  1.3540e+00, -9.3923e-04],\n",
      "        [-1.8110e+00,  2.0291e+00, -3.3600e-01],\n",
      "        [-1.8309e+00,  2.9771e-01,  1.1976e+00],\n",
      "        [-1.6937e+00,  1.9827e+00, -4.9205e-01],\n",
      "        [-1.7052e+00,  1.6801e+00, -3.6186e-01],\n",
      "        [-1.7495e+00,  1.9099e+00, -2.9835e-01],\n",
      "        [-1.8756e+00,  2.0135e+00, -1.6908e-01],\n",
      "        [-1.9282e+00,  2.0731e+00, -4.7202e-01],\n",
      "        [-2.0190e+00,  1.0086e+00,  7.5922e-01],\n",
      "        [-1.7815e+00,  2.9947e-01,  1.3453e+00]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7807e+00,  1.7876e+00, -4.2513e-01],\n",
      "        [-1.7246e+00,  1.7366e+00, -4.2808e-01],\n",
      "        [-2.0551e+00,  1.9004e+00, -8.0623e-02],\n",
      "        [-1.8931e+00,  1.7496e+00, -1.1227e-01],\n",
      "        [ 5.6146e-01, -4.1001e-01, -7.4135e-01],\n",
      "        [-2.1209e+00,  1.1192e+00,  7.5940e-01],\n",
      "        [-1.6049e+00,  1.3540e+00, -9.3923e-04],\n",
      "        [-1.8110e+00,  2.0291e+00, -3.3600e-01],\n",
      "        [-1.8309e+00,  2.9771e-01,  1.1976e+00],\n",
      "        [-1.6937e+00,  1.9827e+00, -4.9205e-01],\n",
      "        [-1.7052e+00,  1.6801e+00, -3.6186e-01],\n",
      "        [-1.7495e+00,  1.9099e+00, -2.9835e-01],\n",
      "        [-1.8756e+00,  2.0135e+00, -1.6908e-01],\n",
      "        [-1.9282e+00,  2.0731e+00, -4.7202e-01],\n",
      "        [-2.0190e+00,  1.0086e+00,  7.5922e-01],\n",
      "        [-1.7815e+00,  2.9947e-01,  1.3453e+00]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9591,  1.9848, -0.4950],\n",
      "        [-1.8128,  0.3613,  1.1985],\n",
      "        [-1.6925, -0.0460,  1.1841],\n",
      "        [-2.0027,  1.9906, -0.2109],\n",
      "        [-2.0759,  1.8091,  0.1674],\n",
      "        [-1.9404,  1.9098, -0.5035],\n",
      "        [-1.6906,  1.6400, -0.5598],\n",
      "        [-0.4487, -0.1111,  0.3103],\n",
      "        [-1.8152,  2.0337, -0.4377],\n",
      "        [-1.6800,  0.3643,  1.4768],\n",
      "        [-1.8685,  0.4880,  1.1960],\n",
      "        [-1.7564,  1.9096, -0.5442],\n",
      "        [ 0.1167, -0.3576, -0.2345],\n",
      "        [-1.8418,  2.0271, -0.0193],\n",
      "        [ 0.4915, -0.1280, -0.8629],\n",
      "        [-1.7678,  0.6611,  0.9612]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9591,  1.9848, -0.4950],\n",
      "        [-1.8128,  0.3613,  1.1985],\n",
      "        [-1.6925, -0.0460,  1.1841],\n",
      "        [-2.0027,  1.9906, -0.2109],\n",
      "        [-2.0759,  1.8091,  0.1674],\n",
      "        [-1.9404,  1.9098, -0.5035],\n",
      "        [-1.6906,  1.6400, -0.5598],\n",
      "        [-0.4487, -0.1111,  0.3103],\n",
      "        [-1.8152,  2.0337, -0.4377],\n",
      "        [-1.6800,  0.3643,  1.4768],\n",
      "        [-1.8685,  0.4880,  1.1960],\n",
      "        [-1.7564,  1.9096, -0.5442],\n",
      "        [ 0.1167, -0.3576, -0.2345],\n",
      "        [-1.8418,  2.0271, -0.0193],\n",
      "        [ 0.4915, -0.1280, -0.8629],\n",
      "        [-1.7678,  0.6611,  0.9612]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8886,  1.8432, -0.4014],\n",
      "        [-1.6874,  0.2042,  1.0564],\n",
      "        [-1.7265,  0.1982,  1.3502],\n",
      "        [-2.0174,  0.9551,  0.7042],\n",
      "        [-1.8036,  1.7396, -0.1978],\n",
      "        [-1.7975,  0.1959,  1.1254],\n",
      "        [-1.6980,  0.0931,  1.3476],\n",
      "        [-1.8170,  1.9174, -0.1391],\n",
      "        [ 0.5860, -0.2478, -0.7467],\n",
      "        [-1.8614,  0.3235,  1.3141],\n",
      "        [-1.7047,  0.3196,  1.1920],\n",
      "        [-2.0189,  1.3377,  0.5843],\n",
      "        [-2.0697,  1.3644,  0.4477],\n",
      "        [-1.7230,  1.6711, -0.0886],\n",
      "        [-1.6518,  1.5920, -0.2389],\n",
      "        [-1.7698,  2.0265, -0.3664]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8886,  1.8432, -0.4014],\n",
      "        [-1.6874,  0.2042,  1.0564],\n",
      "        [-1.7265,  0.1982,  1.3502],\n",
      "        [-2.0174,  0.9551,  0.7042],\n",
      "        [-1.8036,  1.7396, -0.1978],\n",
      "        [-1.7975,  0.1959,  1.1254],\n",
      "        [-1.6980,  0.0931,  1.3476],\n",
      "        [-1.8170,  1.9174, -0.1391],\n",
      "        [ 0.5860, -0.2478, -0.7467],\n",
      "        [-1.8614,  0.3235,  1.3141],\n",
      "        [-1.7047,  0.3196,  1.1920],\n",
      "        [-2.0189,  1.3377,  0.5843],\n",
      "        [-2.0697,  1.3644,  0.4477],\n",
      "        [-1.7230,  1.6711, -0.0886],\n",
      "        [-1.6518,  1.5920, -0.2389],\n",
      "        [-1.7698,  2.0265, -0.3664]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8703,  2.0375, -0.3745],\n",
      "        [ 0.4498, -0.3314, -0.5276],\n",
      "        [-1.8296,  2.0449, -0.2855],\n",
      "        [ 0.4702, -0.2653, -0.6470],\n",
      "        [ 0.4545, -0.2352, -0.5545],\n",
      "        [-1.7816,  0.2990,  1.2059],\n",
      "        [-1.8029,  1.3795,  0.5076],\n",
      "        [-1.7112,  2.1280, -0.1571],\n",
      "        [-1.6846,  0.2005,  1.2975],\n",
      "        [-1.7614,  0.3176,  1.2898],\n",
      "        [-1.8518,  0.0038,  1.3602],\n",
      "        [-1.9010,  0.5104,  1.2126],\n",
      "        [-1.8700,  1.8871, -0.3431],\n",
      "        [ 0.5457, -0.3524, -0.6591],\n",
      "        [-1.7149,  1.8313, -0.3377],\n",
      "        [-1.9166,  2.0826, -0.4553]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8703,  2.0375, -0.3745],\n",
      "        [ 0.4498, -0.3314, -0.5276],\n",
      "        [-1.8296,  2.0449, -0.2855],\n",
      "        [ 0.4702, -0.2653, -0.6470],\n",
      "        [ 0.4545, -0.2352, -0.5545],\n",
      "        [-1.7816,  0.2990,  1.2059],\n",
      "        [-1.8029,  1.3795,  0.5076],\n",
      "        [-1.7112,  2.1280, -0.1571],\n",
      "        [-1.6846,  0.2005,  1.2975],\n",
      "        [-1.7614,  0.3176,  1.2898],\n",
      "        [-1.8518,  0.0038,  1.3602],\n",
      "        [-1.9010,  0.5104,  1.2126],\n",
      "        [-1.8700,  1.8871, -0.3431],\n",
      "        [ 0.5457, -0.3524, -0.6591],\n",
      "        [-1.7149,  1.8313, -0.3377],\n",
      "        [-1.9166,  2.0826, -0.4553]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5395, -0.3721, -0.4823],\n",
      "        [-1.8125,  1.8929, -0.3455],\n",
      "        [-1.7749,  0.1634,  1.1482],\n",
      "        [-1.9298,  0.4172,  1.4179],\n",
      "        [-1.5416,  0.0719,  1.2284],\n",
      "        [-1.8498,  2.1528, -0.2375],\n",
      "        [-1.7350,  1.8910, -0.3426],\n",
      "        [-1.6599,  0.1748,  1.3470],\n",
      "        [-1.6160,  0.0694,  1.3876],\n",
      "        [-1.9034,  0.9514,  0.8598],\n",
      "        [-2.0746,  1.3503,  0.2479],\n",
      "        [-1.9786,  1.9734, -0.3770],\n",
      "        [-1.8187,  2.0177,  0.0131],\n",
      "        [-2.1479,  1.4218,  0.3714],\n",
      "        [ 0.6155, -0.0675, -1.0099],\n",
      "        [-1.7672,  0.6291,  1.0321]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.5395, -0.3721, -0.4823],\n",
      "        [-1.8125,  1.8929, -0.3455],\n",
      "        [-1.7749,  0.1634,  1.1482],\n",
      "        [-1.9298,  0.4172,  1.4179],\n",
      "        [-1.5416,  0.0719,  1.2284],\n",
      "        [-1.8498,  2.1528, -0.2375],\n",
      "        [-1.7350,  1.8910, -0.3426],\n",
      "        [-1.6599,  0.1748,  1.3470],\n",
      "        [-1.6160,  0.0694,  1.3876],\n",
      "        [-1.9034,  0.9514,  0.8598],\n",
      "        [-2.0746,  1.3503,  0.2479],\n",
      "        [-1.9786,  1.9734, -0.3770],\n",
      "        [-1.8187,  2.0177,  0.0131],\n",
      "        [-2.1479,  1.4218,  0.3714],\n",
      "        [ 0.6155, -0.0675, -1.0099],\n",
      "        [-1.7672,  0.6291,  1.0321]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6417,  0.0209,  1.0898],\n",
      "        [-1.9437,  1.6656, -0.2564],\n",
      "        [-1.8523,  1.7375, -0.0519],\n",
      "        [-1.7421,  0.1594,  1.3260],\n",
      "        [-1.9392,  0.2180,  1.4721],\n",
      "        [-1.8019,  2.1797, -0.3790],\n",
      "        [-1.7822,  0.3324,  1.3926],\n",
      "        [-1.8517,  0.3612,  1.2866],\n",
      "        [-1.8370, -0.0113,  1.3769],\n",
      "        [-1.6706,  1.2658,  0.2034],\n",
      "        [-1.6699,  0.1073,  1.3629],\n",
      "        [-1.4715,  1.7640, -0.2369],\n",
      "        [-1.7433,  1.4366,  0.3219],\n",
      "        [-2.0055,  1.5747,  0.4604],\n",
      "        [-1.8676,  1.9647, -0.1825],\n",
      "        [ 0.5906, -0.3750, -0.6570]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6417,  0.0209,  1.0898],\n",
      "        [-1.9437,  1.6656, -0.2564],\n",
      "        [-1.8523,  1.7375, -0.0519],\n",
      "        [-1.7421,  0.1594,  1.3260],\n",
      "        [-1.9392,  0.2180,  1.4721],\n",
      "        [-1.8019,  2.1797, -0.3790],\n",
      "        [-1.7822,  0.3324,  1.3926],\n",
      "        [-1.8517,  0.3612,  1.2866],\n",
      "        [-1.8370, -0.0113,  1.3769],\n",
      "        [-1.6706,  1.2658,  0.2034],\n",
      "        [-1.6699,  0.1073,  1.3629],\n",
      "        [-1.4715,  1.7640, -0.2369],\n",
      "        [-1.7433,  1.4366,  0.3219],\n",
      "        [-2.0055,  1.5747,  0.4604],\n",
      "        [-1.8676,  1.9647, -0.1825],\n",
      "        [ 0.5906, -0.3750, -0.6570]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8931,  2.0495, -0.2419],\n",
      "        [-1.9637,  1.9117, -0.0381],\n",
      "        [-1.9247,  2.0737, -0.1458],\n",
      "        [-1.5088,  0.1296,  1.2519],\n",
      "        [ 0.5192, -0.2805, -0.7036],\n",
      "        [-1.6604,  1.8089, -0.5408],\n",
      "        [-1.6813,  0.2542,  1.2028],\n",
      "        [-1.7607,  1.7305, -0.2105],\n",
      "        [-1.9380,  2.0496, -0.1304],\n",
      "        [ 0.1920,  0.0380, -0.7151],\n",
      "        [ 0.5217, -0.3065, -0.6612],\n",
      "        [-2.0030,  1.7364,  0.3692],\n",
      "        [-1.6273,  0.3169,  1.2388],\n",
      "        [-1.9336,  1.9714, -0.3434],\n",
      "        [-1.6065,  0.1750,  1.2159],\n",
      "        [-2.1647,  1.4079,  0.5221]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8931,  2.0495, -0.2419],\n",
      "        [-1.9637,  1.9117, -0.0381],\n",
      "        [-1.9247,  2.0737, -0.1458],\n",
      "        [-1.5088,  0.1296,  1.2519],\n",
      "        [ 0.5192, -0.2805, -0.7036],\n",
      "        [-1.6604,  1.8089, -0.5408],\n",
      "        [-1.6813,  0.2542,  1.2028],\n",
      "        [-1.7607,  1.7305, -0.2105],\n",
      "        [-1.9380,  2.0496, -0.1304],\n",
      "        [ 0.1920,  0.0380, -0.7151],\n",
      "        [ 0.5217, -0.3065, -0.6612],\n",
      "        [-2.0030,  1.7364,  0.3692],\n",
      "        [-1.6273,  0.3169,  1.2388],\n",
      "        [-1.9336,  1.9714, -0.3434],\n",
      "        [-1.6065,  0.1750,  1.2159],\n",
      "        [-2.1647,  1.4079,  0.5221]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1525e-01,  4.4840e-01, -7.3604e-01],\n",
      "        [-1.1952e+00, -1.4731e-03,  7.8673e-01],\n",
      "        [-1.7758e+00,  8.7489e-02,  1.4558e+00],\n",
      "        [-1.7848e+00,  1.6653e+00,  1.3726e-01],\n",
      "        [-2.0209e+00,  6.5676e-01,  1.0358e+00],\n",
      "        [-1.9971e+00,  1.0282e+00,  6.8901e-01],\n",
      "        [-2.1296e+00,  1.8007e+00,  1.6147e-01],\n",
      "        [-1.8087e+00,  3.2696e-01,  1.2659e+00],\n",
      "        [-1.8852e+00,  1.9149e-01,  1.3444e+00],\n",
      "        [-1.9916e+00,  2.1724e+00, -3.9776e-02],\n",
      "        [-1.8943e+00,  1.8954e+00, -1.7236e-01],\n",
      "        [-2.0126e+00,  1.9431e+00, -3.9563e-02],\n",
      "        [-2.0094e+00,  1.5383e+00,  1.2323e-01],\n",
      "        [-1.5184e+00,  1.6918e-01,  1.2311e+00],\n",
      "        [-1.9519e+00,  4.5030e-01,  1.1876e+00],\n",
      "        [-1.9226e+00,  1.6026e+00, -1.1362e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.1525e-01,  4.4840e-01, -7.3604e-01],\n",
      "        [-1.1952e+00, -1.4731e-03,  7.8673e-01],\n",
      "        [-1.7758e+00,  8.7489e-02,  1.4558e+00],\n",
      "        [-1.7848e+00,  1.6653e+00,  1.3726e-01],\n",
      "        [-2.0209e+00,  6.5676e-01,  1.0358e+00],\n",
      "        [-1.9971e+00,  1.0282e+00,  6.8901e-01],\n",
      "        [-2.1296e+00,  1.8007e+00,  1.6147e-01],\n",
      "        [-1.8087e+00,  3.2696e-01,  1.2659e+00],\n",
      "        [-1.8852e+00,  1.9149e-01,  1.3444e+00],\n",
      "        [-1.9916e+00,  2.1724e+00, -3.9776e-02],\n",
      "        [-1.8943e+00,  1.8954e+00, -1.7236e-01],\n",
      "        [-2.0126e+00,  1.9431e+00, -3.9563e-02],\n",
      "        [-2.0094e+00,  1.5383e+00,  1.2323e-01],\n",
      "        [-1.5184e+00,  1.6918e-01,  1.2311e+00],\n",
      "        [-1.9519e+00,  4.5030e-01,  1.1876e+00],\n",
      "        [-1.9226e+00,  1.6026e+00, -1.1362e-01]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5797,  1.5619, -0.1841],\n",
      "        [ 0.4033, -0.3110, -0.6366],\n",
      "        [-2.0159,  0.7345,  1.0301],\n",
      "        [-1.6959,  0.2869,  1.2141],\n",
      "        [-2.0938,  2.0062, -0.1665],\n",
      "        [-1.7929,  0.2637,  1.3208],\n",
      "        [-1.8544,  1.9201, -0.2765],\n",
      "        [-1.8827,  0.2916,  1.2978],\n",
      "        [-1.6822,  0.1366,  1.1805],\n",
      "        [-1.7741,  0.1703,  1.1474],\n",
      "        [-1.9546,  1.9004, -0.2761],\n",
      "        [ 0.4406, -0.2960, -0.6011],\n",
      "        [-2.0298,  1.8378,  0.3122],\n",
      "        [-1.9376,  1.8065, -0.0492],\n",
      "        [-1.9413,  2.1012, -0.2113],\n",
      "        [-1.7281,  2.0292, -0.2028]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5797,  1.5619, -0.1841],\n",
      "        [ 0.4033, -0.3110, -0.6366],\n",
      "        [-2.0159,  0.7345,  1.0301],\n",
      "        [-1.6959,  0.2869,  1.2141],\n",
      "        [-2.0938,  2.0062, -0.1665],\n",
      "        [-1.7929,  0.2637,  1.3208],\n",
      "        [-1.8544,  1.9201, -0.2765],\n",
      "        [-1.8827,  0.2916,  1.2978],\n",
      "        [-1.6822,  0.1366,  1.1805],\n",
      "        [-1.7741,  0.1703,  1.1474],\n",
      "        [-1.9546,  1.9004, -0.2761],\n",
      "        [ 0.4406, -0.2960, -0.6011],\n",
      "        [-2.0298,  1.8378,  0.3122],\n",
      "        [-1.9376,  1.8065, -0.0492],\n",
      "        [-1.9413,  2.1012, -0.2113],\n",
      "        [-1.7281,  2.0292, -0.2028]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9040,  0.3191,  1.2624],\n",
      "        [-1.8317,  1.7365, -0.2838],\n",
      "        [-1.9062,  1.6405, -0.0745],\n",
      "        [-1.9965,  2.0625, -0.3428],\n",
      "        [-1.7629,  0.0165,  1.2940],\n",
      "        [-1.6235,  1.5081,  0.0501],\n",
      "        [-2.0516,  1.4360,  0.4331],\n",
      "        [-2.0246,  1.8520,  0.0543],\n",
      "        [-1.7723,  0.0607,  1.1290],\n",
      "        [-2.0805,  0.6259,  1.0571],\n",
      "        [-2.2728,  1.9049, -0.0030],\n",
      "        [-1.9261,  0.8980,  0.7692],\n",
      "        [-1.9357,  2.0784, -0.3157],\n",
      "        [-1.8302,  0.3942,  1.2044],\n",
      "        [-1.9622,  0.3462,  1.2181],\n",
      "        [-2.2025,  1.4694,  0.3780]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9040,  0.3191,  1.2624],\n",
      "        [-1.8317,  1.7365, -0.2838],\n",
      "        [-1.9062,  1.6405, -0.0745],\n",
      "        [-1.9965,  2.0625, -0.3428],\n",
      "        [-1.7629,  0.0165,  1.2940],\n",
      "        [-1.6235,  1.5081,  0.0501],\n",
      "        [-2.0516,  1.4360,  0.4331],\n",
      "        [-2.0246,  1.8520,  0.0543],\n",
      "        [-1.7723,  0.0607,  1.1290],\n",
      "        [-2.0805,  0.6259,  1.0571],\n",
      "        [-2.2728,  1.9049, -0.0030],\n",
      "        [-1.9261,  0.8980,  0.7692],\n",
      "        [-1.9357,  2.0784, -0.3157],\n",
      "        [-1.8302,  0.3942,  1.2044],\n",
      "        [-1.9622,  0.3462,  1.2181],\n",
      "        [-2.2025,  1.4694,  0.3780]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1508,  2.1157, -0.0844],\n",
      "        [-2.0445,  1.7399,  0.1653],\n",
      "        [-2.0639,  2.1908,  0.0153],\n",
      "        [ 0.6842, -0.4120, -0.7304],\n",
      "        [-2.1147,  1.7749, -0.2860],\n",
      "        [ 0.5524, -0.3747, -0.6106],\n",
      "        [-2.0058,  0.5799,  0.9978],\n",
      "        [-1.6463,  0.3354,  1.1800],\n",
      "        [-1.5613,  1.7739, -0.1684],\n",
      "        [-1.6162,  0.2460,  1.1453],\n",
      "        [-1.9810,  2.0154, -0.1399],\n",
      "        [-1.7103,  0.3298,  1.4100],\n",
      "        [-1.7642,  0.2989,  1.4783],\n",
      "        [-2.0868,  2.0116,  0.1137],\n",
      "        [-1.6753,  0.1799,  1.2345],\n",
      "        [-1.8975,  0.7500,  0.9080]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.1508,  2.1157, -0.0844],\n",
      "        [-2.0445,  1.7399,  0.1653],\n",
      "        [-2.0639,  2.1908,  0.0153],\n",
      "        [ 0.6842, -0.4120, -0.7304],\n",
      "        [-2.1147,  1.7749, -0.2860],\n",
      "        [ 0.5524, -0.3747, -0.6106],\n",
      "        [-2.0058,  0.5799,  0.9978],\n",
      "        [-1.6463,  0.3354,  1.1800],\n",
      "        [-1.5613,  1.7739, -0.1684],\n",
      "        [-1.6162,  0.2460,  1.1453],\n",
      "        [-1.9810,  2.0154, -0.1399],\n",
      "        [-1.7103,  0.3298,  1.4100],\n",
      "        [-1.7642,  0.2989,  1.4783],\n",
      "        [-2.0868,  2.0116,  0.1137],\n",
      "        [-1.6753,  0.1799,  1.2345],\n",
      "        [-1.8975,  0.7500,  0.9080]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0530,  1.3896,  0.4569],\n",
      "        [ 0.4655, -0.1691, -0.8925],\n",
      "        [-2.2295,  1.7352,  0.4504],\n",
      "        [-0.2436, -0.2033,  0.1926],\n",
      "        [-2.0389,  1.9485,  0.0586],\n",
      "        [-2.2112,  2.0202, -0.1152],\n",
      "        [-1.7956,  2.0562, -0.2731],\n",
      "        [-2.0115,  1.7215,  0.3722],\n",
      "        [-2.1531,  1.9398,  0.2716],\n",
      "        [-1.8908,  1.8438, -0.2331],\n",
      "        [-1.8036,  1.7498,  0.1791],\n",
      "        [-1.4995,  1.1897,  0.2119],\n",
      "        [-1.9935,  1.9426,  0.0598],\n",
      "        [-1.9112,  1.5886,  0.2603],\n",
      "        [ 0.5265, -0.3638, -0.5571],\n",
      "        [-1.9292,  1.9759, -0.1274]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.0530,  1.3896,  0.4569],\n",
      "        [ 0.4655, -0.1691, -0.8925],\n",
      "        [-2.2295,  1.7352,  0.4504],\n",
      "        [-0.2436, -0.2033,  0.1926],\n",
      "        [-2.0389,  1.9485,  0.0586],\n",
      "        [-2.2112,  2.0202, -0.1152],\n",
      "        [-1.7956,  2.0562, -0.2731],\n",
      "        [-2.0115,  1.7215,  0.3722],\n",
      "        [-2.1531,  1.9398,  0.2716],\n",
      "        [-1.8908,  1.8438, -0.2331],\n",
      "        [-1.8036,  1.7498,  0.1791],\n",
      "        [-1.4995,  1.1897,  0.2119],\n",
      "        [-1.9935,  1.9426,  0.0598],\n",
      "        [-1.9112,  1.5886,  0.2603],\n",
      "        [ 0.5265, -0.3638, -0.5571],\n",
      "        [-1.9292,  1.9759, -0.1274]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0190,  1.8902,  0.0921],\n",
      "        [-1.4648,  0.4068,  1.1492],\n",
      "        [-1.6236,  0.0995,  0.9791],\n",
      "        [-1.7912,  0.3169,  1.3152],\n",
      "        [-2.2625,  1.4440,  0.5272],\n",
      "        [-2.0620,  1.7150, -0.1161],\n",
      "        [-1.9353,  0.4469,  1.0454],\n",
      "        [-1.6377,  1.5938, -0.7938],\n",
      "        [-1.9824,  1.8237, -0.0951],\n",
      "        [-1.6412,  0.3116,  1.2957],\n",
      "        [-1.8038,  1.9834, -0.2496],\n",
      "        [-1.8081,  0.7006,  1.1352],\n",
      "        [-1.8593,  0.3553,  1.2386],\n",
      "        [-1.8453,  2.1005, -0.2585],\n",
      "        [-2.3704,  2.0814, -0.0670],\n",
      "        [-1.8468,  1.9887, -0.1745]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.0190,  1.8902,  0.0921],\n",
      "        [-1.4648,  0.4068,  1.1492],\n",
      "        [-1.6236,  0.0995,  0.9791],\n",
      "        [-1.7912,  0.3169,  1.3152],\n",
      "        [-2.2625,  1.4440,  0.5272],\n",
      "        [-2.0620,  1.7150, -0.1161],\n",
      "        [-1.9353,  0.4469,  1.0454],\n",
      "        [-1.6377,  1.5938, -0.7938],\n",
      "        [-1.9824,  1.8237, -0.0951],\n",
      "        [-1.6412,  0.3116,  1.2957],\n",
      "        [-1.8038,  1.9834, -0.2496],\n",
      "        [-1.8081,  0.7006,  1.1352],\n",
      "        [-1.8593,  0.3553,  1.2386],\n",
      "        [-1.8453,  2.1005, -0.2585],\n",
      "        [-2.3704,  2.0814, -0.0670],\n",
      "        [-1.8468,  1.9887, -0.1745]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8982,  1.8575, -0.1670],\n",
      "        [-1.9041,  2.1491, -0.1489],\n",
      "        [-2.0045,  2.2060, -0.2544],\n",
      "        [-2.1197,  1.5508,  0.1969],\n",
      "        [ 0.3906, -0.3121, -0.4689],\n",
      "        [ 0.2879, -0.1317, -0.5682],\n",
      "        [-2.0377,  0.6480,  1.0348],\n",
      "        [-2.0649,  2.1799, -0.2084],\n",
      "        [-2.0142,  0.7870,  0.9118],\n",
      "        [-2.1416,  1.6956,  0.0731],\n",
      "        [-2.0702,  1.4710,  0.3179],\n",
      "        [-2.1149,  1.3431,  0.7531],\n",
      "        [ 0.4613, -0.0889, -0.6067],\n",
      "        [-2.0112,  1.9811,  0.0096],\n",
      "        [-2.1597,  2.0078, -0.0897],\n",
      "        [-1.8137,  2.0989, -0.3450]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8982,  1.8575, -0.1670],\n",
      "        [-1.9041,  2.1491, -0.1489],\n",
      "        [-2.0045,  2.2060, -0.2544],\n",
      "        [-2.1197,  1.5508,  0.1969],\n",
      "        [ 0.3906, -0.3121, -0.4689],\n",
      "        [ 0.2879, -0.1317, -0.5682],\n",
      "        [-2.0377,  0.6480,  1.0348],\n",
      "        [-2.0649,  2.1799, -0.2084],\n",
      "        [-2.0142,  0.7870,  0.9118],\n",
      "        [-2.1416,  1.6956,  0.0731],\n",
      "        [-2.0702,  1.4710,  0.3179],\n",
      "        [-2.1149,  1.3431,  0.7531],\n",
      "        [ 0.4613, -0.0889, -0.6067],\n",
      "        [-2.0112,  1.9811,  0.0096],\n",
      "        [-2.1597,  2.0078, -0.0897],\n",
      "        [-1.8137,  2.0989, -0.3450]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7441,  1.9693, -0.4576],\n",
      "        [ 0.6212, -0.3752, -0.6486],\n",
      "        [-1.8506,  2.1404, -0.2364],\n",
      "        [ 0.4420, -0.1604, -0.6945],\n",
      "        [-1.8267,  2.0880, -0.4502],\n",
      "        [-2.0077,  0.7526,  1.0061],\n",
      "        [-1.9348,  0.4480,  1.2014],\n",
      "        [-1.9930,  1.9113,  0.1144],\n",
      "        [-1.8969,  2.2834, -0.3945],\n",
      "        [-1.6737,  0.6108,  1.1524],\n",
      "        [-2.0411,  1.8948, -0.0995],\n",
      "        [-2.1341,  1.8382,  0.0025],\n",
      "        [-2.1564,  1.7983,  0.1806],\n",
      "        [-2.0366,  2.2174, -0.3440],\n",
      "        [-2.1234,  1.0999,  0.9496],\n",
      "        [-2.1260,  2.0978, -0.2445]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7441,  1.9693, -0.4576],\n",
      "        [ 0.6212, -0.3752, -0.6486],\n",
      "        [-1.8506,  2.1404, -0.2364],\n",
      "        [ 0.4420, -0.1604, -0.6945],\n",
      "        [-1.8267,  2.0880, -0.4502],\n",
      "        [-2.0077,  0.7526,  1.0061],\n",
      "        [-1.9348,  0.4480,  1.2014],\n",
      "        [-1.9930,  1.9113,  0.1144],\n",
      "        [-1.8969,  2.2834, -0.3945],\n",
      "        [-1.6737,  0.6108,  1.1524],\n",
      "        [-2.0411,  1.8948, -0.0995],\n",
      "        [-2.1341,  1.8382,  0.0025],\n",
      "        [-2.1564,  1.7983,  0.1806],\n",
      "        [-2.0366,  2.2174, -0.3440],\n",
      "        [-2.1234,  1.0999,  0.9496],\n",
      "        [-2.1260,  2.0978, -0.2445]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9551,  2.0948, -0.7409],\n",
      "        [-1.2043,  1.1230, -0.2497],\n",
      "        [-1.9584,  2.0826, -0.1850],\n",
      "        [ 0.2401, -0.3239, -0.4739],\n",
      "        [-1.7957,  1.9391, -0.3577],\n",
      "        [-1.7922,  0.8093,  0.8744],\n",
      "        [-1.9673,  0.5434,  1.2153],\n",
      "        [-1.9692,  1.8176,  0.0136],\n",
      "        [-2.0775,  2.3198, -0.4444],\n",
      "        [-1.6306,  0.3392,  0.9780],\n",
      "        [-2.1600,  1.8533,  0.2841],\n",
      "        [-2.2056,  1.1423,  0.7785],\n",
      "        [-2.0882,  2.0214, -0.3014],\n",
      "        [-2.1024,  1.1839,  0.4812],\n",
      "        [-1.7640,  0.7770,  0.9612],\n",
      "        [-1.8933,  2.0121, -0.5023]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9551,  2.0948, -0.7409],\n",
      "        [-1.2043,  1.1230, -0.2497],\n",
      "        [-1.9584,  2.0826, -0.1850],\n",
      "        [ 0.2401, -0.3239, -0.4739],\n",
      "        [-1.7957,  1.9391, -0.3577],\n",
      "        [-1.7922,  0.8093,  0.8744],\n",
      "        [-1.9673,  0.5434,  1.2153],\n",
      "        [-1.9692,  1.8176,  0.0136],\n",
      "        [-2.0775,  2.3198, -0.4444],\n",
      "        [-1.6306,  0.3392,  0.9780],\n",
      "        [-2.1600,  1.8533,  0.2841],\n",
      "        [-2.2056,  1.1423,  0.7785],\n",
      "        [-2.0882,  2.0214, -0.3014],\n",
      "        [-2.1024,  1.1839,  0.4812],\n",
      "        [-1.7640,  0.7770,  0.9612],\n",
      "        [-1.8933,  2.0121, -0.5023]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7056,  0.5542,  1.1721],\n",
      "        [ 0.2749, -0.1447, -0.7523],\n",
      "        [-1.7161,  0.5878,  0.8619],\n",
      "        [-1.8809,  2.1240, -0.2583],\n",
      "        [-1.7149,  0.6827,  0.8691],\n",
      "        [-1.9544,  2.2063, -0.2236],\n",
      "        [-1.5261,  0.3856,  0.9738],\n",
      "        [-1.6837,  0.5277,  1.0083],\n",
      "        [ 0.3398,  0.0100, -0.6318],\n",
      "        [-2.0358,  2.1599, -0.2504],\n",
      "        [-1.9881,  2.2171, -0.4003],\n",
      "        [ 0.3760, -0.4207, -0.4899],\n",
      "        [-2.0476,  2.1581, -0.1192],\n",
      "        [-1.6446,  0.2416,  1.1619],\n",
      "        [-1.9397,  2.1188, -0.4396],\n",
      "        [-2.0232,  2.0339, -0.2389]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7056,  0.5542,  1.1721],\n",
      "        [ 0.2749, -0.1447, -0.7523],\n",
      "        [-1.7161,  0.5878,  0.8619],\n",
      "        [-1.8809,  2.1240, -0.2583],\n",
      "        [-1.7149,  0.6827,  0.8691],\n",
      "        [-1.9544,  2.2063, -0.2236],\n",
      "        [-1.5261,  0.3856,  0.9738],\n",
      "        [-1.6837,  0.5277,  1.0083],\n",
      "        [ 0.3398,  0.0100, -0.6318],\n",
      "        [-2.0358,  2.1599, -0.2504],\n",
      "        [-1.9881,  2.2171, -0.4003],\n",
      "        [ 0.3760, -0.4207, -0.4899],\n",
      "        [-2.0476,  2.1581, -0.1192],\n",
      "        [-1.6446,  0.2416,  1.1619],\n",
      "        [-1.9397,  2.1188, -0.4396],\n",
      "        [-2.0232,  2.0339, -0.2389]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6216,  0.4080,  1.1239],\n",
      "        [-2.1500,  2.1079, -0.2706],\n",
      "        [-1.9219,  2.0905, -0.2795],\n",
      "        [-1.5441,  0.3479,  1.0921],\n",
      "        [-0.4379, -0.0036,  0.0757],\n",
      "        [-2.0334,  1.1711,  0.8045],\n",
      "        [-2.0601,  1.7063,  0.2438],\n",
      "        [ 0.4211, -0.3911, -0.5609],\n",
      "        [-1.9514,  0.7898,  1.1208],\n",
      "        [-2.1000,  2.3234, -0.4967],\n",
      "        [-2.1422,  2.3984, -0.2929],\n",
      "        [-2.0895,  2.0877, -0.2077],\n",
      "        [-2.1315,  2.0161,  0.0554],\n",
      "        [-0.7393,  0.0446,  0.2152],\n",
      "        [-2.1645,  2.2157, -0.2793],\n",
      "        [-2.1107,  1.4639,  0.7034]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6216,  0.4080,  1.1239],\n",
      "        [-2.1500,  2.1079, -0.2706],\n",
      "        [-1.9219,  2.0905, -0.2795],\n",
      "        [-1.5441,  0.3479,  1.0921],\n",
      "        [-0.4379, -0.0036,  0.0757],\n",
      "        [-2.0334,  1.1711,  0.8045],\n",
      "        [-2.0601,  1.7063,  0.2438],\n",
      "        [ 0.4211, -0.3911, -0.5609],\n",
      "        [-1.9514,  0.7898,  1.1208],\n",
      "        [-2.1000,  2.3234, -0.4967],\n",
      "        [-2.1422,  2.3984, -0.2929],\n",
      "        [-2.0895,  2.0877, -0.2077],\n",
      "        [-2.1315,  2.0161,  0.0554],\n",
      "        [-0.7393,  0.0446,  0.2152],\n",
      "        [-2.1645,  2.2157, -0.2793],\n",
      "        [-2.1107,  1.4639,  0.7034]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7307,  2.0880, -0.3760],\n",
      "        [ 0.3925, -0.3332, -0.3962],\n",
      "        [-1.6472,  0.4631,  0.9789],\n",
      "        [-1.6214,  0.5359,  1.0217],\n",
      "        [-1.9769,  1.8589,  0.0375],\n",
      "        [-1.7447,  2.0196, -0.3445],\n",
      "        [-1.8305,  0.4980,  1.1344],\n",
      "        [-2.4135,  1.6477,  0.3643],\n",
      "        [-2.0313,  2.1573, -0.2593],\n",
      "        [-2.0098,  2.2692, -0.3217],\n",
      "        [-2.0519,  2.2994, -0.2340],\n",
      "        [-0.5400,  0.0763,  0.1698],\n",
      "        [-1.7807,  1.9231, -0.2168],\n",
      "        [-2.0897,  0.9368,  0.4655],\n",
      "        [-2.0544,  2.2323, -0.3661],\n",
      "        [-2.0736,  2.1863,  0.0382]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7307,  2.0880, -0.3760],\n",
      "        [ 0.3925, -0.3332, -0.3962],\n",
      "        [-1.6472,  0.4631,  0.9789],\n",
      "        [-1.6214,  0.5359,  1.0217],\n",
      "        [-1.9769,  1.8589,  0.0375],\n",
      "        [-1.7447,  2.0196, -0.3445],\n",
      "        [-1.8305,  0.4980,  1.1344],\n",
      "        [-2.4135,  1.6477,  0.3643],\n",
      "        [-2.0313,  2.1573, -0.2593],\n",
      "        [-2.0098,  2.2692, -0.3217],\n",
      "        [-2.0519,  2.2994, -0.2340],\n",
      "        [-0.5400,  0.0763,  0.1698],\n",
      "        [-1.7807,  1.9231, -0.2168],\n",
      "        [-2.0897,  0.9368,  0.4655],\n",
      "        [-2.0544,  2.2323, -0.3661],\n",
      "        [-2.0736,  2.1863,  0.0382]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0293,  1.1253,  0.8817],\n",
      "        [-1.9259,  1.7974,  0.0818],\n",
      "        [-1.9832,  0.8944,  0.9076],\n",
      "        [-1.9466,  0.5699,  1.0736],\n",
      "        [-2.0926,  1.9708, -0.4159],\n",
      "        [-2.1057,  2.3305, -0.5604],\n",
      "        [-0.9996,  0.7789, -0.2754],\n",
      "        [-1.8326,  2.1770, -0.3537],\n",
      "        [-1.9304,  2.1795, -0.3767],\n",
      "        [ 0.1441,  0.2902, -0.8446],\n",
      "        [-2.1375,  2.0549, -0.0567],\n",
      "        [-2.0133,  1.4925,  0.6535],\n",
      "        [-2.0494,  0.7895,  0.8340],\n",
      "        [ 0.4068, -0.2716, -0.6346],\n",
      "        [-1.9494,  2.1848, -0.2142],\n",
      "        [-2.1015,  2.2722, -0.3073]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.0293,  1.1253,  0.8817],\n",
      "        [-1.9259,  1.7974,  0.0818],\n",
      "        [-1.9832,  0.8944,  0.9076],\n",
      "        [-1.9466,  0.5699,  1.0736],\n",
      "        [-2.0926,  1.9708, -0.4159],\n",
      "        [-2.1057,  2.3305, -0.5604],\n",
      "        [-0.9996,  0.7789, -0.2754],\n",
      "        [-1.8326,  2.1770, -0.3537],\n",
      "        [-1.9304,  2.1795, -0.3767],\n",
      "        [ 0.1441,  0.2902, -0.8446],\n",
      "        [-2.1375,  2.0549, -0.0567],\n",
      "        [-2.0133,  1.4925,  0.6535],\n",
      "        [-2.0494,  0.7895,  0.8340],\n",
      "        [ 0.4068, -0.2716, -0.6346],\n",
      "        [-1.9494,  2.1848, -0.2142],\n",
      "        [-2.1015,  2.2722, -0.3073]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9280,  1.7247, -0.1962],\n",
      "        [ 0.3515, -0.1977, -0.4271],\n",
      "        [-2.2401,  2.0365,  0.0210],\n",
      "        [-1.5931,  0.3681,  1.1825],\n",
      "        [-1.9375,  1.4880,  0.1919],\n",
      "        [ 0.3523, -0.0276, -0.3998],\n",
      "        [-1.9340,  1.8704, -0.2562],\n",
      "        [-2.1674,  1.9839, -0.3429],\n",
      "        [-1.5916,  0.3897,  0.9962],\n",
      "        [-1.8240,  0.6802,  0.9629],\n",
      "        [-2.0828,  1.8866, -0.4015],\n",
      "        [-1.8163,  1.9776, -0.3466],\n",
      "        [-1.8664,  0.4674,  1.0749],\n",
      "        [-1.9734,  1.9053, -0.1702],\n",
      "        [-1.6717,  0.5178,  0.7523],\n",
      "        [-2.0656,  0.8500,  0.8370]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9280,  1.7247, -0.1962],\n",
      "        [ 0.3515, -0.1977, -0.4271],\n",
      "        [-2.2401,  2.0365,  0.0210],\n",
      "        [-1.5931,  0.3681,  1.1825],\n",
      "        [-1.9375,  1.4880,  0.1919],\n",
      "        [ 0.3523, -0.0276, -0.3998],\n",
      "        [-1.9340,  1.8704, -0.2562],\n",
      "        [-2.1674,  1.9839, -0.3429],\n",
      "        [-1.5916,  0.3897,  0.9962],\n",
      "        [-1.8240,  0.6802,  0.9629],\n",
      "        [-2.0828,  1.8866, -0.4015],\n",
      "        [-1.8163,  1.9776, -0.3466],\n",
      "        [-1.8664,  0.4674,  1.0749],\n",
      "        [-1.9734,  1.9053, -0.1702],\n",
      "        [-1.6717,  0.5178,  0.7523],\n",
      "        [-2.0656,  0.8500,  0.8370]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8979e+00,  7.0519e-01,  1.1801e+00],\n",
      "        [-1.5951e+00,  4.1678e-01,  9.8371e-01],\n",
      "        [-1.9854e+00,  1.6247e+00,  1.1751e-04],\n",
      "        [-1.7697e+00,  3.2248e-01,  1.0056e+00],\n",
      "        [-1.6489e+00,  3.4829e-01,  9.1054e-01],\n",
      "        [-1.9816e+00,  2.1756e+00, -1.0065e-01],\n",
      "        [-1.9767e+00,  1.7930e+00, -6.9692e-02],\n",
      "        [-2.1866e+00,  1.4722e+00,  4.8242e-01],\n",
      "        [-1.6298e+00,  4.4718e-01,  9.3425e-01],\n",
      "        [-1.9583e+00,  2.4018e+00, -3.7784e-01],\n",
      "        [-1.0993e+00,  1.3882e+00, -8.2803e-01],\n",
      "        [-1.7071e+00,  8.0199e-01,  6.1283e-01],\n",
      "        [-1.7957e+00,  1.9407e+00, -4.9200e-01],\n",
      "        [-1.9385e+00,  2.0732e+00, -2.4162e-01],\n",
      "        [-1.5425e+00,  5.4942e-01,  8.4694e-01],\n",
      "        [-1.8352e+00,  1.9658e+00, -1.5862e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8979e+00,  7.0519e-01,  1.1801e+00],\n",
      "        [-1.5951e+00,  4.1678e-01,  9.8371e-01],\n",
      "        [-1.9854e+00,  1.6247e+00,  1.1751e-04],\n",
      "        [-1.7697e+00,  3.2248e-01,  1.0056e+00],\n",
      "        [-1.6489e+00,  3.4829e-01,  9.1054e-01],\n",
      "        [-1.9816e+00,  2.1756e+00, -1.0065e-01],\n",
      "        [-1.9767e+00,  1.7930e+00, -6.9692e-02],\n",
      "        [-2.1866e+00,  1.4722e+00,  4.8242e-01],\n",
      "        [-1.6298e+00,  4.4718e-01,  9.3425e-01],\n",
      "        [-1.9583e+00,  2.4018e+00, -3.7784e-01],\n",
      "        [-1.0993e+00,  1.3882e+00, -8.2803e-01],\n",
      "        [-1.7071e+00,  8.0199e-01,  6.1283e-01],\n",
      "        [-1.7957e+00,  1.9407e+00, -4.9200e-01],\n",
      "        [-1.9385e+00,  2.0732e+00, -2.4162e-01],\n",
      "        [-1.5425e+00,  5.4942e-01,  8.4694e-01],\n",
      "        [-1.8352e+00,  1.9658e+00, -1.5862e-01]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7203,  1.6547,  0.0772],\n",
      "        [-1.9963,  1.9926, -0.1208],\n",
      "        [-1.6106,  0.4219,  0.8785],\n",
      "        [-1.8870,  1.9904, -0.1449],\n",
      "        [ 0.4855, -0.2227, -0.5661],\n",
      "        [-1.5840,  0.4163,  1.0463],\n",
      "        [-1.9545,  1.9473, -0.2612],\n",
      "        [-2.0888,  2.1887, -0.4122],\n",
      "        [-1.5048,  1.7337, -0.4655],\n",
      "        [-2.0608,  1.8705, -0.1998],\n",
      "        [-2.0135,  2.0033, -0.2776],\n",
      "        [-1.6948,  1.8687, -0.2225],\n",
      "        [-1.7790,  1.8635, -0.3702],\n",
      "        [ 0.2273,  0.0565, -0.6486],\n",
      "        [-1.6292,  1.7346, -0.4019],\n",
      "        [-2.0886,  2.1368, -0.1333]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7203,  1.6547,  0.0772],\n",
      "        [-1.9963,  1.9926, -0.1208],\n",
      "        [-1.6106,  0.4219,  0.8785],\n",
      "        [-1.8870,  1.9904, -0.1449],\n",
      "        [ 0.4855, -0.2227, -0.5661],\n",
      "        [-1.5840,  0.4163,  1.0463],\n",
      "        [-1.9545,  1.9473, -0.2612],\n",
      "        [-2.0888,  2.1887, -0.4122],\n",
      "        [-1.5048,  1.7337, -0.4655],\n",
      "        [-2.0608,  1.8705, -0.1998],\n",
      "        [-2.0135,  2.0033, -0.2776],\n",
      "        [-1.6948,  1.8687, -0.2225],\n",
      "        [-1.7790,  1.8635, -0.3702],\n",
      "        [ 0.2273,  0.0565, -0.6486],\n",
      "        [-1.6292,  1.7346, -0.4019],\n",
      "        [-2.0886,  2.1368, -0.1333]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6950,  1.7902, -0.4915],\n",
      "        [-2.0714,  1.9333, -0.3824],\n",
      "        [-1.7611,  1.8555, -0.2025],\n",
      "        [-1.7201,  0.5477,  1.0353],\n",
      "        [-2.0211,  2.0530, -0.2857],\n",
      "        [-0.6003, -0.1698,  0.5554],\n",
      "        [-1.5315,  1.1946,  0.6461],\n",
      "        [-1.8430,  0.6228,  0.9161],\n",
      "        [-1.8523,  1.9239, -0.4998],\n",
      "        [-1.7433,  0.5994,  1.0570],\n",
      "        [-1.7232,  0.8939,  0.6069],\n",
      "        [-1.6826,  0.3872,  1.0917],\n",
      "        [-1.9115,  2.0010, -0.4837],\n",
      "        [-1.9768,  0.7747,  0.8966],\n",
      "        [-1.5880,  0.6290,  0.9349],\n",
      "        [-1.8098,  1.6826, -0.0082]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6950,  1.7902, -0.4915],\n",
      "        [-2.0714,  1.9333, -0.3824],\n",
      "        [-1.7611,  1.8555, -0.2025],\n",
      "        [-1.7201,  0.5477,  1.0353],\n",
      "        [-2.0211,  2.0530, -0.2857],\n",
      "        [-0.6003, -0.1698,  0.5554],\n",
      "        [-1.5315,  1.1946,  0.6461],\n",
      "        [-1.8430,  0.6228,  0.9161],\n",
      "        [-1.8523,  1.9239, -0.4998],\n",
      "        [-1.7433,  0.5994,  1.0570],\n",
      "        [-1.7232,  0.8939,  0.6069],\n",
      "        [-1.6826,  0.3872,  1.0917],\n",
      "        [-1.9115,  2.0010, -0.4837],\n",
      "        [-1.9768,  0.7747,  0.8966],\n",
      "        [-1.5880,  0.6290,  0.9349],\n",
      "        [-1.8098,  1.6826, -0.0082]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1069,  1.8984, -0.0531],\n",
      "        [-1.6321,  0.8869,  0.5563],\n",
      "        [-1.8670,  0.9525,  0.6462],\n",
      "        [-1.6342,  0.5913,  1.0895],\n",
      "        [-1.7233,  1.8863, -0.2787],\n",
      "        [ 0.3565,  0.0664, -0.6597],\n",
      "        [-1.4624,  0.4535,  0.9757],\n",
      "        [-1.5441,  0.1857,  0.8076],\n",
      "        [-1.7902,  1.8078, -0.1875],\n",
      "        [-1.4875,  0.4366,  1.0735],\n",
      "        [-1.8612,  1.9501, -0.4329],\n",
      "        [-1.7023,  0.3103,  1.0717],\n",
      "        [-0.4134,  0.7170, -0.8061],\n",
      "        [-1.7585,  0.7949,  0.6551],\n",
      "        [-1.3901,  0.2314,  0.7600],\n",
      "        [-1.6845,  1.9080, -0.2295]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.1069,  1.8984, -0.0531],\n",
      "        [-1.6321,  0.8869,  0.5563],\n",
      "        [-1.8670,  0.9525,  0.6462],\n",
      "        [-1.6342,  0.5913,  1.0895],\n",
      "        [-1.7233,  1.8863, -0.2787],\n",
      "        [ 0.3565,  0.0664, -0.6597],\n",
      "        [-1.4624,  0.4535,  0.9757],\n",
      "        [-1.5441,  0.1857,  0.8076],\n",
      "        [-1.7902,  1.8078, -0.1875],\n",
      "        [-1.4875,  0.4366,  1.0735],\n",
      "        [-1.8612,  1.9501, -0.4329],\n",
      "        [-1.7023,  0.3103,  1.0717],\n",
      "        [-0.4134,  0.7170, -0.8061],\n",
      "        [-1.7585,  0.7949,  0.6551],\n",
      "        [-1.3901,  0.2314,  0.7600],\n",
      "        [-1.6845,  1.9080, -0.2295]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8556,  0.4453,  1.0464],\n",
      "        [-1.9379,  1.4019,  0.2683],\n",
      "        [-0.6171,  0.2913, -0.2343],\n",
      "        [-1.8722,  2.1962, -0.1492],\n",
      "        [-1.9814,  1.9535, -0.1092],\n",
      "        [-1.6447,  0.4356,  0.8447],\n",
      "        [-1.8059,  2.0275, -0.2996],\n",
      "        [ 0.2657, -0.3026, -0.3986],\n",
      "        [-1.5425,  0.5631,  0.9800],\n",
      "        [ 0.3042, -0.2980, -0.5396],\n",
      "        [-1.4275,  0.3969,  0.7261],\n",
      "        [-1.9389,  1.4901,  0.1423],\n",
      "        [-1.9907,  1.5478,  0.4418],\n",
      "        [ 0.2857, -0.1582, -0.7167],\n",
      "        [-1.8656,  1.9090, -0.3747],\n",
      "        [-1.8698,  1.8488, -0.2092]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8556,  0.4453,  1.0464],\n",
      "        [-1.9379,  1.4019,  0.2683],\n",
      "        [-0.6171,  0.2913, -0.2343],\n",
      "        [-1.8722,  2.1962, -0.1492],\n",
      "        [-1.9814,  1.9535, -0.1092],\n",
      "        [-1.6447,  0.4356,  0.8447],\n",
      "        [-1.8059,  2.0275, -0.2996],\n",
      "        [ 0.2657, -0.3026, -0.3986],\n",
      "        [-1.5425,  0.5631,  0.9800],\n",
      "        [ 0.3042, -0.2980, -0.5396],\n",
      "        [-1.4275,  0.3969,  0.7261],\n",
      "        [-1.9389,  1.4901,  0.1423],\n",
      "        [-1.9907,  1.5478,  0.4418],\n",
      "        [ 0.2857, -0.1582, -0.7167],\n",
      "        [-1.8656,  1.9090, -0.3747],\n",
      "        [-1.8698,  1.8488, -0.2092]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9177,  1.6329,  0.0486],\n",
      "        [-1.6253,  1.8923, -0.1788],\n",
      "        [-1.8763,  1.9184, -0.3069],\n",
      "        [-1.7523,  0.5890,  1.0086],\n",
      "        [ 0.4090, -0.2858, -0.4933],\n",
      "        [-1.5451,  0.2479,  0.9341],\n",
      "        [-1.6950,  0.8093,  0.5982],\n",
      "        [-1.7385,  1.6457, -0.3238],\n",
      "        [-1.5685,  0.2823,  0.8485],\n",
      "        [-1.7104,  1.6968, -0.3130],\n",
      "        [-1.5998,  1.8629, -0.2458],\n",
      "        [-1.6123,  0.4069,  0.8256],\n",
      "        [-1.6192,  1.8948, -0.3680],\n",
      "        [-1.9683,  1.7061,  0.1536],\n",
      "        [-1.5161,  0.4123,  1.0043],\n",
      "        [-2.0219,  2.1080, -0.2087]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9177,  1.6329,  0.0486],\n",
      "        [-1.6253,  1.8923, -0.1788],\n",
      "        [-1.8763,  1.9184, -0.3069],\n",
      "        [-1.7523,  0.5890,  1.0086],\n",
      "        [ 0.4090, -0.2858, -0.4933],\n",
      "        [-1.5451,  0.2479,  0.9341],\n",
      "        [-1.6950,  0.8093,  0.5982],\n",
      "        [-1.7385,  1.6457, -0.3238],\n",
      "        [-1.5685,  0.2823,  0.8485],\n",
      "        [-1.7104,  1.6968, -0.3130],\n",
      "        [-1.5998,  1.8629, -0.2458],\n",
      "        [-1.6123,  0.4069,  0.8256],\n",
      "        [-1.6192,  1.8948, -0.3680],\n",
      "        [-1.9683,  1.7061,  0.1536],\n",
      "        [-1.5161,  0.4123,  1.0043],\n",
      "        [-2.0219,  2.1080, -0.2087]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5305,  0.3602,  0.9203],\n",
      "        [-1.5843,  0.6238,  0.8661],\n",
      "        [-1.7916,  1.8936, -0.2844],\n",
      "        [-1.8852,  1.8820, -0.1425],\n",
      "        [-1.7219,  1.0479,  0.4552],\n",
      "        [-1.7601,  1.8933, -0.1689],\n",
      "        [-1.9711,  1.3720,  0.3383],\n",
      "        [-1.8099,  1.9046, -0.3051],\n",
      "        [-1.7800,  1.8037,  0.1282],\n",
      "        [-1.8905,  1.7399, -0.2010],\n",
      "        [-1.5868,  0.3131,  0.9888],\n",
      "        [-1.7563,  1.8196, -0.3938],\n",
      "        [-0.0752,  0.2788, -0.6751],\n",
      "        [-1.7638,  0.4484,  1.0698],\n",
      "        [-1.9571,  1.7221, -0.0701],\n",
      "        [ 0.4725, -0.3241, -0.6027]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5305,  0.3602,  0.9203],\n",
      "        [-1.5843,  0.6238,  0.8661],\n",
      "        [-1.7916,  1.8936, -0.2844],\n",
      "        [-1.8852,  1.8820, -0.1425],\n",
      "        [-1.7219,  1.0479,  0.4552],\n",
      "        [-1.7601,  1.8933, -0.1689],\n",
      "        [-1.9711,  1.3720,  0.3383],\n",
      "        [-1.8099,  1.9046, -0.3051],\n",
      "        [-1.7800,  1.8037,  0.1282],\n",
      "        [-1.8905,  1.7399, -0.2010],\n",
      "        [-1.5868,  0.3131,  0.9888],\n",
      "        [-1.7563,  1.8196, -0.3938],\n",
      "        [-0.0752,  0.2788, -0.6751],\n",
      "        [-1.7638,  0.4484,  1.0698],\n",
      "        [-1.9571,  1.7221, -0.0701],\n",
      "        [ 0.4725, -0.3241, -0.6027]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7146,  0.5669,  0.8921],\n",
      "        [-1.6759,  1.8033, -0.1811],\n",
      "        [-1.6993,  0.8914,  0.7003],\n",
      "        [-1.4241,  0.4443,  1.1050],\n",
      "        [ 0.1523,  0.0771, -0.6875],\n",
      "        [-1.7039,  0.4674,  0.9456],\n",
      "        [-1.6655,  1.8078,  0.0571],\n",
      "        [-1.6749,  1.8432, -0.0218],\n",
      "        [-1.2712,  1.5361, -0.6020],\n",
      "        [-1.7523,  0.4655,  0.6506],\n",
      "        [-1.7449,  1.9379, -0.5365],\n",
      "        [-1.7149,  0.9410,  0.7139],\n",
      "        [-2.0074,  1.7855, -0.1615],\n",
      "        [-1.2209,  0.1343,  1.0590],\n",
      "        [-1.8603,  1.6360, -0.1039],\n",
      "        [-2.0778,  1.6908,  0.0135]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7146,  0.5669,  0.8921],\n",
      "        [-1.6759,  1.8033, -0.1811],\n",
      "        [-1.6993,  0.8914,  0.7003],\n",
      "        [-1.4241,  0.4443,  1.1050],\n",
      "        [ 0.1523,  0.0771, -0.6875],\n",
      "        [-1.7039,  0.4674,  0.9456],\n",
      "        [-1.6655,  1.8078,  0.0571],\n",
      "        [-1.6749,  1.8432, -0.0218],\n",
      "        [-1.2712,  1.5361, -0.6020],\n",
      "        [-1.7523,  0.4655,  0.6506],\n",
      "        [-1.7449,  1.9379, -0.5365],\n",
      "        [-1.7149,  0.9410,  0.7139],\n",
      "        [-2.0074,  1.7855, -0.1615],\n",
      "        [-1.2209,  0.1343,  1.0590],\n",
      "        [-1.8603,  1.6360, -0.1039],\n",
      "        [-2.0778,  1.6908,  0.0135]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7883,  1.9507, -0.1453],\n",
      "        [-1.5661,  0.2366,  1.0108],\n",
      "        [-1.6623,  1.4040,  0.2851],\n",
      "        [-1.7531,  1.8065, -0.1699],\n",
      "        [-1.7353,  0.7217,  0.8540],\n",
      "        [-1.4980,  0.2498,  1.1284],\n",
      "        [-1.4304,  0.2168,  1.0398],\n",
      "        [-1.7959,  1.5534, -0.1154],\n",
      "        [-0.4270,  0.2891, -0.2713],\n",
      "        [-1.5765,  0.9987,  0.2496],\n",
      "        [-2.0578,  0.9293,  0.8836],\n",
      "        [-1.7083,  1.5179, -0.1594],\n",
      "        [-1.6774,  0.7989,  0.6841],\n",
      "        [-1.7256,  1.4939, -0.2231],\n",
      "        [ 0.3882, -0.2854, -0.5156],\n",
      "        [-1.4859,  1.7050, -0.2460]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7883,  1.9507, -0.1453],\n",
      "        [-1.5661,  0.2366,  1.0108],\n",
      "        [-1.6623,  1.4040,  0.2851],\n",
      "        [-1.7531,  1.8065, -0.1699],\n",
      "        [-1.7353,  0.7217,  0.8540],\n",
      "        [-1.4980,  0.2498,  1.1284],\n",
      "        [-1.4304,  0.2168,  1.0398],\n",
      "        [-1.7959,  1.5534, -0.1154],\n",
      "        [-0.4270,  0.2891, -0.2713],\n",
      "        [-1.5765,  0.9987,  0.2496],\n",
      "        [-2.0578,  0.9293,  0.8836],\n",
      "        [-1.7083,  1.5179, -0.1594],\n",
      "        [-1.6774,  0.7989,  0.6841],\n",
      "        [-1.7256,  1.4939, -0.2231],\n",
      "        [ 0.3882, -0.2854, -0.5156],\n",
      "        [-1.4859,  1.7050, -0.2460]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5122,  0.4061,  0.9924],\n",
      "        [ 0.3285, -0.1500, -0.4319],\n",
      "        [-1.5488,  0.0301,  0.7999],\n",
      "        [-1.9377,  1.7279, -0.1499],\n",
      "        [-1.5981,  1.9370, -0.2123],\n",
      "        [-1.5785,  1.5026, -0.2472],\n",
      "        [-1.2899,  0.2413,  0.8271],\n",
      "        [-1.8283,  1.6210, -0.0966],\n",
      "        [ 0.4227, -0.2600, -0.5006],\n",
      "        [ 0.3118, -0.2649, -0.3832],\n",
      "        [-1.5880,  1.6987, -0.1838],\n",
      "        [-1.8540,  1.7086, -0.0374],\n",
      "        [-1.6751,  1.0912,  0.3555],\n",
      "        [-1.8694,  2.0058, -0.5167],\n",
      "        [-1.8480,  1.8329, -0.2310],\n",
      "        [-1.7954,  1.4219,  0.3230]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5122,  0.4061,  0.9924],\n",
      "        [ 0.3285, -0.1500, -0.4319],\n",
      "        [-1.5488,  0.0301,  0.7999],\n",
      "        [-1.9377,  1.7279, -0.1499],\n",
      "        [-1.5981,  1.9370, -0.2123],\n",
      "        [-1.5785,  1.5026, -0.2472],\n",
      "        [-1.2899,  0.2413,  0.8271],\n",
      "        [-1.8283,  1.6210, -0.0966],\n",
      "        [ 0.4227, -0.2600, -0.5006],\n",
      "        [ 0.3118, -0.2649, -0.3832],\n",
      "        [-1.5880,  1.6987, -0.1838],\n",
      "        [-1.8540,  1.7086, -0.0374],\n",
      "        [-1.6751,  1.0912,  0.3555],\n",
      "        [-1.8694,  2.0058, -0.5167],\n",
      "        [-1.8480,  1.8329, -0.2310],\n",
      "        [-1.7954,  1.4219,  0.3230]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3406,  0.3552,  0.8883],\n",
      "        [-1.8439,  1.8643,  0.1725],\n",
      "        [-1.6762,  2.0335, -0.3329],\n",
      "        [-1.6481,  1.3355,  0.1047],\n",
      "        [-1.8099,  1.7386,  0.3518],\n",
      "        [-1.8987,  1.7393, -0.0394],\n",
      "        [-1.2578,  0.2810,  0.8320],\n",
      "        [-1.8127,  0.3523,  0.9573],\n",
      "        [-1.2058,  0.2094,  0.8611],\n",
      "        [-1.8199,  1.9482, -0.1484],\n",
      "        [-2.0910,  2.0032, -0.2544],\n",
      "        [ 0.3925, -0.2153, -0.4004],\n",
      "        [-1.8586,  1.9913, -0.2836],\n",
      "        [-1.8401,  1.6895, -0.2414],\n",
      "        [-1.8640,  1.6211, -0.2205],\n",
      "        [-2.0210,  1.0850,  0.5589]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3406,  0.3552,  0.8883],\n",
      "        [-1.8439,  1.8643,  0.1725],\n",
      "        [-1.6762,  2.0335, -0.3329],\n",
      "        [-1.6481,  1.3355,  0.1047],\n",
      "        [-1.8099,  1.7386,  0.3518],\n",
      "        [-1.8987,  1.7393, -0.0394],\n",
      "        [-1.2578,  0.2810,  0.8320],\n",
      "        [-1.8127,  0.3523,  0.9573],\n",
      "        [-1.2058,  0.2094,  0.8611],\n",
      "        [-1.8199,  1.9482, -0.1484],\n",
      "        [-2.0910,  2.0032, -0.2544],\n",
      "        [ 0.3925, -0.2153, -0.4004],\n",
      "        [-1.8586,  1.9913, -0.2836],\n",
      "        [-1.8401,  1.6895, -0.2414],\n",
      "        [-1.8640,  1.6211, -0.2205],\n",
      "        [-2.0210,  1.0850,  0.5589]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8602,  1.6958, -0.0824],\n",
      "        [-0.1176, -0.1872, -0.0540],\n",
      "        [-1.9265,  0.9071,  0.6519],\n",
      "        [-1.7593,  1.2191,  0.4981],\n",
      "        [ 0.2645,  0.0052, -0.4882],\n",
      "        [-1.2899,  0.9552, -0.0577],\n",
      "        [-1.0748, -0.0333,  0.9111],\n",
      "        [-1.2554,  0.3346,  0.8487],\n",
      "        [-1.7243,  0.9659,  0.4878],\n",
      "        [-1.9831,  1.2057,  0.5060],\n",
      "        [-1.3317,  0.1754,  0.9574],\n",
      "        [ 0.2015, -0.2953, -0.4152],\n",
      "        [-1.8246,  1.9027, -0.1317],\n",
      "        [-1.7939,  1.7237, -0.1448],\n",
      "        [-1.9110,  1.8197, -0.0361],\n",
      "        [-1.9373,  1.5119,  0.1924]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8602,  1.6958, -0.0824],\n",
      "        [-0.1176, -0.1872, -0.0540],\n",
      "        [-1.9265,  0.9071,  0.6519],\n",
      "        [-1.7593,  1.2191,  0.4981],\n",
      "        [ 0.2645,  0.0052, -0.4882],\n",
      "        [-1.2899,  0.9552, -0.0577],\n",
      "        [-1.0748, -0.0333,  0.9111],\n",
      "        [-1.2554,  0.3346,  0.8487],\n",
      "        [-1.7243,  0.9659,  0.4878],\n",
      "        [-1.9831,  1.2057,  0.5060],\n",
      "        [-1.3317,  0.1754,  0.9574],\n",
      "        [ 0.2015, -0.2953, -0.4152],\n",
      "        [-1.8246,  1.9027, -0.1317],\n",
      "        [-1.7939,  1.7237, -0.1448],\n",
      "        [-1.9110,  1.8197, -0.0361],\n",
      "        [-1.9373,  1.5119,  0.1924]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5704,  0.3371,  0.9759],\n",
      "        [-1.1658,  1.0345, -0.3749],\n",
      "        [-1.6962,  1.7708, -0.2534],\n",
      "        [ 0.2535, -0.0678, -0.5904],\n",
      "        [-1.8942,  1.6128, -0.2138],\n",
      "        [-1.8027,  1.1920,  0.2030],\n",
      "        [-1.6471,  1.8788, -0.2164],\n",
      "        [ 0.2666, -0.1797, -0.6001],\n",
      "        [-0.8457,  0.8956, -0.5896],\n",
      "        [-0.1046,  0.1874, -0.6853],\n",
      "        [-1.7413,  1.3446,  0.5145],\n",
      "        [-1.9530,  1.7420, -0.1466],\n",
      "        [-1.4332,  0.2467,  1.2042],\n",
      "        [-1.1542,  0.8837, -0.1883],\n",
      "        [-1.6803,  1.7925, -0.0861],\n",
      "        [-1.5964,  1.5972, -0.0020]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5704,  0.3371,  0.9759],\n",
      "        [-1.1658,  1.0345, -0.3749],\n",
      "        [-1.6962,  1.7708, -0.2534],\n",
      "        [ 0.2535, -0.0678, -0.5904],\n",
      "        [-1.8942,  1.6128, -0.2138],\n",
      "        [-1.8027,  1.1920,  0.2030],\n",
      "        [-1.6471,  1.8788, -0.2164],\n",
      "        [ 0.2666, -0.1797, -0.6001],\n",
      "        [-0.8457,  0.8956, -0.5896],\n",
      "        [-0.1046,  0.1874, -0.6853],\n",
      "        [-1.7413,  1.3446,  0.5145],\n",
      "        [-1.9530,  1.7420, -0.1466],\n",
      "        [-1.4332,  0.2467,  1.2042],\n",
      "        [-1.1542,  0.8837, -0.1883],\n",
      "        [-1.6803,  1.7925, -0.0861],\n",
      "        [-1.5964,  1.5972, -0.0020]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6422,  0.9528,  0.5068],\n",
      "        [-1.4279,  0.2979,  0.9838],\n",
      "        [-1.3741,  0.4202,  1.0064],\n",
      "        [-1.5946,  1.6881, -0.1748],\n",
      "        [-1.3145,  0.1893,  1.0846],\n",
      "        [-1.3127,  0.0491,  0.9406],\n",
      "        [ 0.4041, -0.1813, -0.4825],\n",
      "        [-1.4796,  0.1934,  0.8865],\n",
      "        [-1.6990,  1.7079, -0.2266],\n",
      "        [ 0.1657, -0.0286, -0.6825],\n",
      "        [-1.6344,  0.2350,  0.8837],\n",
      "        [ 0.0700, -0.2761, -0.1786],\n",
      "        [-1.7842,  1.8159, -0.0613],\n",
      "        [-1.2957,  0.2378,  0.9400],\n",
      "        [-1.6808,  1.3390, -0.1858],\n",
      "        [ 0.3413, -0.1444, -0.4671]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6422,  0.9528,  0.5068],\n",
      "        [-1.4279,  0.2979,  0.9838],\n",
      "        [-1.3741,  0.4202,  1.0064],\n",
      "        [-1.5946,  1.6881, -0.1748],\n",
      "        [-1.3145,  0.1893,  1.0846],\n",
      "        [-1.3127,  0.0491,  0.9406],\n",
      "        [ 0.4041, -0.1813, -0.4825],\n",
      "        [-1.4796,  0.1934,  0.8865],\n",
      "        [-1.6990,  1.7079, -0.2266],\n",
      "        [ 0.1657, -0.0286, -0.6825],\n",
      "        [-1.6344,  0.2350,  0.8837],\n",
      "        [ 0.0700, -0.2761, -0.1786],\n",
      "        [-1.7842,  1.8159, -0.0613],\n",
      "        [-1.2957,  0.2378,  0.9400],\n",
      "        [-1.6808,  1.3390, -0.1858],\n",
      "        [ 0.3413, -0.1444, -0.4671]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4650,  0.1915,  0.9670],\n",
      "        [-1.6190,  1.5602, -0.4194],\n",
      "        [-1.5998,  1.5092, -0.0611],\n",
      "        [-1.7205,  1.4263,  0.1331],\n",
      "        [-1.4074,  1.6731, -0.3743],\n",
      "        [-1.4364,  1.3040,  0.0981],\n",
      "        [-1.7499,  1.8220, -0.1179],\n",
      "        [-1.2190,  0.1089,  0.7377],\n",
      "        [-1.3949,  0.0310,  0.9003],\n",
      "        [-1.2310,  0.2821,  0.7725],\n",
      "        [-1.1682,  1.1663, -0.3912],\n",
      "        [-1.4888,  0.0351,  1.0403],\n",
      "        [-1.3696,  0.1324,  1.0545],\n",
      "        [-1.5484,  1.6259, -0.1946],\n",
      "        [-1.6394,  0.6776,  0.6578],\n",
      "        [-1.2185,  1.4851, -0.5432]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4650,  0.1915,  0.9670],\n",
      "        [-1.6190,  1.5602, -0.4194],\n",
      "        [-1.5998,  1.5092, -0.0611],\n",
      "        [-1.7205,  1.4263,  0.1331],\n",
      "        [-1.4074,  1.6731, -0.3743],\n",
      "        [-1.4364,  1.3040,  0.0981],\n",
      "        [-1.7499,  1.8220, -0.1179],\n",
      "        [-1.2190,  0.1089,  0.7377],\n",
      "        [-1.3949,  0.0310,  0.9003],\n",
      "        [-1.2310,  0.2821,  0.7725],\n",
      "        [-1.1682,  1.1663, -0.3912],\n",
      "        [-1.4888,  0.0351,  1.0403],\n",
      "        [-1.3696,  0.1324,  1.0545],\n",
      "        [-1.5484,  1.6259, -0.1946],\n",
      "        [-1.6394,  0.6776,  0.6578],\n",
      "        [-1.2185,  1.4851, -0.5432]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4609,  0.3165,  0.9512],\n",
      "        [-1.4667,  1.5669, -0.0661],\n",
      "        [-1.5282,  1.5204, -0.1168],\n",
      "        [-1.6329,  1.7366,  0.0441],\n",
      "        [-1.4492,  1.5498, -0.2158],\n",
      "        [-1.6344,  1.6173, -0.0418],\n",
      "        [-1.5517,  1.0077,  0.3104],\n",
      "        [-1.7214,  1.1908,  0.2173],\n",
      "        [-1.7332,  1.4952,  0.2109],\n",
      "        [-1.6687,  0.4860,  0.9115],\n",
      "        [-1.6651,  1.3918,  0.0977],\n",
      "        [-1.6041,  1.6837, -0.2398],\n",
      "        [-1.7107,  1.5760, -0.0319],\n",
      "        [-1.3768,  0.1288,  1.0335],\n",
      "        [-1.7892,  1.4599, -0.0571],\n",
      "        [-1.7726,  1.7226, -0.1102]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4609,  0.3165,  0.9512],\n",
      "        [-1.4667,  1.5669, -0.0661],\n",
      "        [-1.5282,  1.5204, -0.1168],\n",
      "        [-1.6329,  1.7366,  0.0441],\n",
      "        [-1.4492,  1.5498, -0.2158],\n",
      "        [-1.6344,  1.6173, -0.0418],\n",
      "        [-1.5517,  1.0077,  0.3104],\n",
      "        [-1.7214,  1.1908,  0.2173],\n",
      "        [-1.7332,  1.4952,  0.2109],\n",
      "        [-1.6687,  0.4860,  0.9115],\n",
      "        [-1.6651,  1.3918,  0.0977],\n",
      "        [-1.6041,  1.6837, -0.2398],\n",
      "        [-1.7107,  1.5760, -0.0319],\n",
      "        [-1.3768,  0.1288,  1.0335],\n",
      "        [-1.7892,  1.4599, -0.0571],\n",
      "        [-1.7726,  1.7226, -0.1102]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7864,  1.6557,  0.0863],\n",
      "        [-1.7568,  0.7768,  0.7463],\n",
      "        [-1.7182,  0.9680,  0.4907],\n",
      "        [-0.7460, -0.0480,  0.5871],\n",
      "        [-1.3828,  0.2526,  0.8746],\n",
      "        [-1.5107,  1.4938, -0.3720],\n",
      "        [-1.7927,  0.9726,  0.6224],\n",
      "        [-1.7329,  1.3943, -0.0537],\n",
      "        [-1.6818,  1.1677,  0.4432],\n",
      "        [-1.8928,  1.7844, -0.1542],\n",
      "        [-1.5485,  1.2671,  0.0899],\n",
      "        [-1.5301,  1.3553, -0.0228],\n",
      "        [-1.3190,  0.2199,  0.9575],\n",
      "        [-1.3867,  0.0326,  0.9607],\n",
      "        [-1.5576,  1.1752, -0.2347],\n",
      "        [-1.9026,  1.5299, -0.1863]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7864,  1.6557,  0.0863],\n",
      "        [-1.7568,  0.7768,  0.7463],\n",
      "        [-1.7182,  0.9680,  0.4907],\n",
      "        [-0.7460, -0.0480,  0.5871],\n",
      "        [-1.3828,  0.2526,  0.8746],\n",
      "        [-1.5107,  1.4938, -0.3720],\n",
      "        [-1.7927,  0.9726,  0.6224],\n",
      "        [-1.7329,  1.3943, -0.0537],\n",
      "        [-1.6818,  1.1677,  0.4432],\n",
      "        [-1.8928,  1.7844, -0.1542],\n",
      "        [-1.5485,  1.2671,  0.0899],\n",
      "        [-1.5301,  1.3553, -0.0228],\n",
      "        [-1.3190,  0.2199,  0.9575],\n",
      "        [-1.3867,  0.0326,  0.9607],\n",
      "        [-1.5576,  1.1752, -0.2347],\n",
      "        [-1.9026,  1.5299, -0.1863]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4975,  0.1686,  0.9857],\n",
      "        [ 0.1310,  0.0320, -0.6754],\n",
      "        [-0.6506,  1.0332, -0.6708],\n",
      "        [-1.5171,  0.3241,  0.9961],\n",
      "        [-0.5193,  0.4641, -0.5470],\n",
      "        [-1.7587,  1.2763,  0.5701],\n",
      "        [-1.4980,  1.0621,  0.3984],\n",
      "        [-1.4677,  1.5097, -0.0758],\n",
      "        [-1.5482,  1.5155, -0.2330],\n",
      "        [-1.4586,  1.2848, -0.1900],\n",
      "        [-1.5755,  0.3846,  1.1401],\n",
      "        [-1.7287,  1.7924, -0.2507],\n",
      "        [-1.7082,  1.6859, -0.4087],\n",
      "        [-1.2324,  0.0582,  0.8575],\n",
      "        [-1.4702,  1.6997, -0.1872],\n",
      "        [ 0.3093, -0.0373, -0.6132]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4975,  0.1686,  0.9857],\n",
      "        [ 0.1310,  0.0320, -0.6754],\n",
      "        [-0.6506,  1.0332, -0.6708],\n",
      "        [-1.5171,  0.3241,  0.9961],\n",
      "        [-0.5193,  0.4641, -0.5470],\n",
      "        [-1.7587,  1.2763,  0.5701],\n",
      "        [-1.4980,  1.0621,  0.3984],\n",
      "        [-1.4677,  1.5097, -0.0758],\n",
      "        [-1.5482,  1.5155, -0.2330],\n",
      "        [-1.4586,  1.2848, -0.1900],\n",
      "        [-1.5755,  0.3846,  1.1401],\n",
      "        [-1.7287,  1.7924, -0.2507],\n",
      "        [-1.7082,  1.6859, -0.4087],\n",
      "        [-1.2324,  0.0582,  0.8575],\n",
      "        [-1.4702,  1.6997, -0.1872],\n",
      "        [ 0.3093, -0.0373, -0.6132]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6543,  1.4891, -0.0428],\n",
      "        [-1.4159,  1.5801, -0.3646],\n",
      "        [-1.7949,  1.1391,  0.4081],\n",
      "        [ 0.1906, -0.2524, -0.5046],\n",
      "        [-1.5091,  1.5863, -0.3592],\n",
      "        [-1.3681,  1.4828, -0.2573],\n",
      "        [-1.4921,  0.1741,  1.0944],\n",
      "        [-1.6923,  1.5777, -0.2087],\n",
      "        [-1.7114,  1.6439,  0.0164],\n",
      "        [-1.9285,  1.0184,  0.4399],\n",
      "        [-1.7130,  1.7467, -0.2373],\n",
      "        [-1.7148,  1.2243,  0.0452],\n",
      "        [-1.7316,  0.7566,  0.4301],\n",
      "        [-0.1116,  0.4428, -0.9655],\n",
      "        [-1.8263,  1.4342,  0.4208],\n",
      "        [-1.5416,  1.5907, -0.3416]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6543,  1.4891, -0.0428],\n",
      "        [-1.4159,  1.5801, -0.3646],\n",
      "        [-1.7949,  1.1391,  0.4081],\n",
      "        [ 0.1906, -0.2524, -0.5046],\n",
      "        [-1.5091,  1.5863, -0.3592],\n",
      "        [-1.3681,  1.4828, -0.2573],\n",
      "        [-1.4921,  0.1741,  1.0944],\n",
      "        [-1.6923,  1.5777, -0.2087],\n",
      "        [-1.7114,  1.6439,  0.0164],\n",
      "        [-1.9285,  1.0184,  0.4399],\n",
      "        [-1.7130,  1.7467, -0.2373],\n",
      "        [-1.7148,  1.2243,  0.0452],\n",
      "        [-1.7316,  0.7566,  0.4301],\n",
      "        [-0.1116,  0.4428, -0.9655],\n",
      "        [-1.8263,  1.4342,  0.4208],\n",
      "        [-1.5416,  1.5907, -0.3416]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6002,  1.6663, -0.3978],\n",
      "        [-1.8235,  1.4550,  0.2530],\n",
      "        [-1.2568,  1.5976, -0.6218],\n",
      "        [-1.3140,  0.0774,  1.0708],\n",
      "        [-0.3598, -0.1279,  0.2134],\n",
      "        [-1.7428,  0.7871,  0.9112],\n",
      "        [ 0.2631, -0.1912, -0.6935],\n",
      "        [-1.4893,  1.6905, -0.4444],\n",
      "        [-1.5367,  0.2719,  1.0114],\n",
      "        [-1.4823,  1.4998,  0.0071],\n",
      "        [-1.6921,  1.4909, -0.0954],\n",
      "        [-1.4211,  0.7149,  0.1728],\n",
      "        [-1.4312,  0.2046,  0.9603],\n",
      "        [-1.5502,  1.5807, -0.3131],\n",
      "        [-0.6693,  0.8298, -0.5521],\n",
      "        [-1.4561,  1.6516, -0.3538]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6002,  1.6663, -0.3978],\n",
      "        [-1.8235,  1.4550,  0.2530],\n",
      "        [-1.2568,  1.5976, -0.6218],\n",
      "        [-1.3140,  0.0774,  1.0708],\n",
      "        [-0.3598, -0.1279,  0.2134],\n",
      "        [-1.7428,  0.7871,  0.9112],\n",
      "        [ 0.2631, -0.1912, -0.6935],\n",
      "        [-1.4893,  1.6905, -0.4444],\n",
      "        [-1.5367,  0.2719,  1.0114],\n",
      "        [-1.4823,  1.4998,  0.0071],\n",
      "        [-1.6921,  1.4909, -0.0954],\n",
      "        [-1.4211,  0.7149,  0.1728],\n",
      "        [-1.4312,  0.2046,  0.9603],\n",
      "        [-1.5502,  1.5807, -0.3131],\n",
      "        [-0.6693,  0.8298, -0.5521],\n",
      "        [-1.4561,  1.6516, -0.3538]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5039,  1.5629, -0.1926],\n",
      "        [-1.5414,  1.6076, -0.2633],\n",
      "        [-1.6356,  1.4153, -0.2694],\n",
      "        [-1.3122,  0.1675,  0.9520],\n",
      "        [-1.8534,  1.6977, -0.2535],\n",
      "        [-1.5263,  1.6144,  0.0651],\n",
      "        [-1.4377,  1.7075, -0.1753],\n",
      "        [-1.3969,  1.5025, -0.3025],\n",
      "        [-1.6467,  0.3251,  1.0636],\n",
      "        [-0.8025,  1.1116, -0.6895],\n",
      "        [-1.3971,  0.3503,  0.7876],\n",
      "        [-1.5268,  1.4551, -0.4449],\n",
      "        [-1.5432,  0.4482,  0.8256],\n",
      "        [-1.5210,  1.6508, -0.1950],\n",
      "        [-1.7139,  1.4789, -0.0821],\n",
      "        [-0.0352,  0.2524, -0.8105]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5039,  1.5629, -0.1926],\n",
      "        [-1.5414,  1.6076, -0.2633],\n",
      "        [-1.6356,  1.4153, -0.2694],\n",
      "        [-1.3122,  0.1675,  0.9520],\n",
      "        [-1.8534,  1.6977, -0.2535],\n",
      "        [-1.5263,  1.6144,  0.0651],\n",
      "        [-1.4377,  1.7075, -0.1753],\n",
      "        [-1.3969,  1.5025, -0.3025],\n",
      "        [-1.6467,  0.3251,  1.0636],\n",
      "        [-0.8025,  1.1116, -0.6895],\n",
      "        [-1.3971,  0.3503,  0.7876],\n",
      "        [-1.5268,  1.4551, -0.4449],\n",
      "        [-1.5432,  0.4482,  0.8256],\n",
      "        [-1.5210,  1.6508, -0.1950],\n",
      "        [-1.7139,  1.4789, -0.0821],\n",
      "        [-0.0352,  0.2524, -0.8105]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5414,  1.5050, -0.3351],\n",
      "        [-1.6120,  1.5549, -0.3075],\n",
      "        [-1.5454,  1.4726, -0.2790],\n",
      "        [-1.7279,  1.7502, -0.2338],\n",
      "        [-1.2884,  0.2232,  0.7760],\n",
      "        [ 0.0899,  0.4070, -0.8992],\n",
      "        [-1.5728,  1.4206, -0.1493],\n",
      "        [ 0.2129, -0.1970, -0.4246],\n",
      "        [-1.5334,  1.6625, -0.3509],\n",
      "        [-1.5924,  0.3264,  0.9303],\n",
      "        [-1.7247,  1.2535,  0.2935],\n",
      "        [-1.4849,  1.5764, -0.1283],\n",
      "        [ 0.3366, -0.1747, -0.7518],\n",
      "        [-1.7312,  1.4895, -0.2393],\n",
      "        [-1.7657,  1.1369,  0.3551],\n",
      "        [-1.7401,  1.7110, -0.2861]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5414,  1.5050, -0.3351],\n",
      "        [-1.6120,  1.5549, -0.3075],\n",
      "        [-1.5454,  1.4726, -0.2790],\n",
      "        [-1.7279,  1.7502, -0.2338],\n",
      "        [-1.2884,  0.2232,  0.7760],\n",
      "        [ 0.0899,  0.4070, -0.8992],\n",
      "        [-1.5728,  1.4206, -0.1493],\n",
      "        [ 0.2129, -0.1970, -0.4246],\n",
      "        [-1.5334,  1.6625, -0.3509],\n",
      "        [-1.5924,  0.3264,  0.9303],\n",
      "        [-1.7247,  1.2535,  0.2935],\n",
      "        [-1.4849,  1.5764, -0.1283],\n",
      "        [ 0.3366, -0.1747, -0.7518],\n",
      "        [-1.7312,  1.4895, -0.2393],\n",
      "        [-1.7657,  1.1369,  0.3551],\n",
      "        [-1.7401,  1.7110, -0.2861]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4536,  1.6587, -0.2285],\n",
      "        [-1.5313,  1.4217, -0.4563],\n",
      "        [-1.5336,  1.7283, -0.3728],\n",
      "        [-1.4815,  1.7449, -0.3263],\n",
      "        [-1.5327,  0.7301,  0.7764],\n",
      "        [-1.7208,  1.5624, -0.2408],\n",
      "        [-1.7051,  0.4442,  0.8621],\n",
      "        [-1.2710,  0.1173,  1.0319],\n",
      "        [-1.3305,  1.5176, -0.4067],\n",
      "        [-1.4279,  0.2603,  0.9414],\n",
      "        [-1.7885,  1.8305, -0.2329],\n",
      "        [-1.3992,  1.4214, -0.2593],\n",
      "        [-1.4925,  0.1146,  1.0997],\n",
      "        [-1.5077,  0.0535,  1.0683],\n",
      "        [ 0.2663, -0.1274, -0.6499],\n",
      "        [-1.7952,  1.5778, -0.3339]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4536,  1.6587, -0.2285],\n",
      "        [-1.5313,  1.4217, -0.4563],\n",
      "        [-1.5336,  1.7283, -0.3728],\n",
      "        [-1.4815,  1.7449, -0.3263],\n",
      "        [-1.5327,  0.7301,  0.7764],\n",
      "        [-1.7208,  1.5624, -0.2408],\n",
      "        [-1.7051,  0.4442,  0.8621],\n",
      "        [-1.2710,  0.1173,  1.0319],\n",
      "        [-1.3305,  1.5176, -0.4067],\n",
      "        [-1.4279,  0.2603,  0.9414],\n",
      "        [-1.7885,  1.8305, -0.2329],\n",
      "        [-1.3992,  1.4214, -0.2593],\n",
      "        [-1.4925,  0.1146,  1.0997],\n",
      "        [-1.5077,  0.0535,  1.0683],\n",
      "        [ 0.2663, -0.1274, -0.6499],\n",
      "        [-1.7952,  1.5778, -0.3339]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8154,  1.6703,  0.0820],\n",
      "        [-1.6066,  1.7289, -0.4824],\n",
      "        [-1.4976,  1.6302, -0.3315],\n",
      "        [-1.5199,  1.7651, -0.5435],\n",
      "        [-1.3630,  1.5187, -0.5266],\n",
      "        [-1.6910,  1.8499, -0.3425],\n",
      "        [-1.6532,  1.1154,  0.0644],\n",
      "        [-1.7904,  1.0063,  0.6535],\n",
      "        [-1.5859,  0.9191,  0.4464],\n",
      "        [-1.5481,  0.1242,  0.9783],\n",
      "        [-0.2344,  0.5874, -0.9642],\n",
      "        [ 0.0529,  0.4737, -0.8250],\n",
      "        [-1.6430,  1.6572, -0.2237],\n",
      "        [-1.6335,  0.6375,  0.8389],\n",
      "        [-1.5544,  1.6371, -0.3808],\n",
      "        [-1.5982,  0.3635,  1.0461]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8154,  1.6703,  0.0820],\n",
      "        [-1.6066,  1.7289, -0.4824],\n",
      "        [-1.4976,  1.6302, -0.3315],\n",
      "        [-1.5199,  1.7651, -0.5435],\n",
      "        [-1.3630,  1.5187, -0.5266],\n",
      "        [-1.6910,  1.8499, -0.3425],\n",
      "        [-1.6532,  1.1154,  0.0644],\n",
      "        [-1.7904,  1.0063,  0.6535],\n",
      "        [-1.5859,  0.9191,  0.4464],\n",
      "        [-1.5481,  0.1242,  0.9783],\n",
      "        [-0.2344,  0.5874, -0.9642],\n",
      "        [ 0.0529,  0.4737, -0.8250],\n",
      "        [-1.6430,  1.6572, -0.2237],\n",
      "        [-1.6335,  0.6375,  0.8389],\n",
      "        [-1.5544,  1.6371, -0.3808],\n",
      "        [-1.5982,  0.3635,  1.0461]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5453, -0.1110, -0.6912],\n",
      "        [-1.5632,  1.5973, -0.2784],\n",
      "        [-1.4183,  0.1077,  0.9425],\n",
      "        [-1.9185,  1.4670,  0.0945],\n",
      "        [ 0.4428, -0.1250, -0.8002],\n",
      "        [-1.5137,  1.7585, -0.4959],\n",
      "        [-1.5331,  1.6442, -0.1584],\n",
      "        [-1.6178,  1.5347, -0.3230],\n",
      "        [-0.8402,  0.0596,  0.7645],\n",
      "        [ 0.3594, -0.2459, -0.8257],\n",
      "        [-1.5050,  1.8176, -0.3569],\n",
      "        [ 0.1338, -0.0588, -0.6479],\n",
      "        [-1.3832,  1.5950, -0.2169],\n",
      "        [-1.5981,  1.6249, -0.5120],\n",
      "        [-1.3342,  1.6384, -0.2775],\n",
      "        [-1.6784,  1.7087, -0.3743]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.5453, -0.1110, -0.6912],\n",
      "        [-1.5632,  1.5973, -0.2784],\n",
      "        [-1.4183,  0.1077,  0.9425],\n",
      "        [-1.9185,  1.4670,  0.0945],\n",
      "        [ 0.4428, -0.1250, -0.8002],\n",
      "        [-1.5137,  1.7585, -0.4959],\n",
      "        [-1.5331,  1.6442, -0.1584],\n",
      "        [-1.6178,  1.5347, -0.3230],\n",
      "        [-0.8402,  0.0596,  0.7645],\n",
      "        [ 0.3594, -0.2459, -0.8257],\n",
      "        [-1.5050,  1.8176, -0.3569],\n",
      "        [ 0.1338, -0.0588, -0.6479],\n",
      "        [-1.3832,  1.5950, -0.2169],\n",
      "        [-1.5981,  1.6249, -0.5120],\n",
      "        [-1.3342,  1.6384, -0.2775],\n",
      "        [-1.6784,  1.7087, -0.3743]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7270,  1.7740, -0.1209],\n",
      "        [-1.4360,  1.5887, -0.3289],\n",
      "        [ 0.5066, -0.2212, -0.4803],\n",
      "        [-0.9280,  0.6164, -0.1292],\n",
      "        [ 0.4495, -0.2640, -0.7062],\n",
      "        [-1.2175,  1.4758, -0.3570],\n",
      "        [-1.3077,  0.2404,  1.1476],\n",
      "        [-1.7011,  1.7013, -0.1686],\n",
      "        [ 0.2913, -0.0301, -0.6076],\n",
      "        [-1.7178,  0.1032,  1.1677],\n",
      "        [-1.4916,  0.3557,  0.7168],\n",
      "        [-1.6643,  0.9866,  0.1737],\n",
      "        [-1.7428,  0.5572,  1.1013],\n",
      "        [-1.5578,  1.6765, -0.2505],\n",
      "        [-1.4638,  1.5317, -0.3959],\n",
      "        [-1.5478,  1.7196, -0.3160]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7270,  1.7740, -0.1209],\n",
      "        [-1.4360,  1.5887, -0.3289],\n",
      "        [ 0.5066, -0.2212, -0.4803],\n",
      "        [-0.9280,  0.6164, -0.1292],\n",
      "        [ 0.4495, -0.2640, -0.7062],\n",
      "        [-1.2175,  1.4758, -0.3570],\n",
      "        [-1.3077,  0.2404,  1.1476],\n",
      "        [-1.7011,  1.7013, -0.1686],\n",
      "        [ 0.2913, -0.0301, -0.6076],\n",
      "        [-1.7178,  0.1032,  1.1677],\n",
      "        [-1.4916,  0.3557,  0.7168],\n",
      "        [-1.6643,  0.9866,  0.1737],\n",
      "        [-1.7428,  0.5572,  1.1013],\n",
      "        [-1.5578,  1.6765, -0.2505],\n",
      "        [-1.4638,  1.5317, -0.3959],\n",
      "        [-1.5478,  1.7196, -0.3160]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.1597, -0.2046, -0.8707],\n",
      "        [-1.5388,  0.8941,  0.7359],\n",
      "        [-1.6609,  1.7892, -0.4378],\n",
      "        [-1.6921,  0.4208,  1.0034],\n",
      "        [-1.5557,  1.5806, -0.2155],\n",
      "        [-1.7035,  1.7014, -0.2780],\n",
      "        [-1.4309,  1.7114, -0.3257],\n",
      "        [-1.7006,  0.8506,  0.8789],\n",
      "        [ 0.4416, -0.1885, -0.7912],\n",
      "        [-1.4197,  1.8219, -0.4129],\n",
      "        [-1.6051,  1.3002,  0.2605],\n",
      "        [-1.5101,  1.6050, -0.2718],\n",
      "        [-1.3445,  0.5514,  0.8461],\n",
      "        [-1.4615,  1.7027, -0.5706],\n",
      "        [-1.5897,  1.7076, -0.3357],\n",
      "        [-1.5390,  1.5479, -0.2771]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.1597, -0.2046, -0.8707],\n",
      "        [-1.5388,  0.8941,  0.7359],\n",
      "        [-1.6609,  1.7892, -0.4378],\n",
      "        [-1.6921,  0.4208,  1.0034],\n",
      "        [-1.5557,  1.5806, -0.2155],\n",
      "        [-1.7035,  1.7014, -0.2780],\n",
      "        [-1.4309,  1.7114, -0.3257],\n",
      "        [-1.7006,  0.8506,  0.8789],\n",
      "        [ 0.4416, -0.1885, -0.7912],\n",
      "        [-1.4197,  1.8219, -0.4129],\n",
      "        [-1.6051,  1.3002,  0.2605],\n",
      "        [-1.5101,  1.6050, -0.2718],\n",
      "        [-1.3445,  0.5514,  0.8461],\n",
      "        [-1.4615,  1.7027, -0.5706],\n",
      "        [-1.5897,  1.7076, -0.3357],\n",
      "        [-1.5390,  1.5479, -0.2771]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5777, -0.0043,  1.0596],\n",
      "        [-1.4689,  1.7226, -0.2867],\n",
      "        [-1.4926,  1.6097, -0.3549],\n",
      "        [ 0.5543, -0.1903, -0.6267],\n",
      "        [-1.5241,  1.5244, -0.3101],\n",
      "        [-1.5272,  0.5103,  1.0256],\n",
      "        [-1.6260,  1.6816, -0.2968],\n",
      "        [ 0.3817, -0.2366, -0.9315],\n",
      "        [-1.5350,  1.6425, -0.4569],\n",
      "        [ 0.3383, -0.1946, -0.6495],\n",
      "        [-1.5231,  1.6636, -0.2969],\n",
      "        [-1.4396,  1.5275, -0.2744],\n",
      "        [-1.5974,  1.7054, -0.4160],\n",
      "        [-1.5525,  1.7583, -0.4141],\n",
      "        [-1.7395,  1.1403,  0.1766],\n",
      "        [-1.7677,  1.4349, -0.0568]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5777, -0.0043,  1.0596],\n",
      "        [-1.4689,  1.7226, -0.2867],\n",
      "        [-1.4926,  1.6097, -0.3549],\n",
      "        [ 0.5543, -0.1903, -0.6267],\n",
      "        [-1.5241,  1.5244, -0.3101],\n",
      "        [-1.5272,  0.5103,  1.0256],\n",
      "        [-1.6260,  1.6816, -0.2968],\n",
      "        [ 0.3817, -0.2366, -0.9315],\n",
      "        [-1.5350,  1.6425, -0.4569],\n",
      "        [ 0.3383, -0.1946, -0.6495],\n",
      "        [-1.5231,  1.6636, -0.2969],\n",
      "        [-1.4396,  1.5275, -0.2744],\n",
      "        [-1.5974,  1.7054, -0.4160],\n",
      "        [-1.5525,  1.7583, -0.4141],\n",
      "        [-1.7395,  1.1403,  0.1766],\n",
      "        [-1.7677,  1.4349, -0.0568]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3007, -0.0228, -0.9128],\n",
      "        [-1.8394,  1.3511,  0.4665],\n",
      "        [-1.5969,  1.9031, -0.5017],\n",
      "        [-1.5115,  1.7227, -0.3342],\n",
      "        [ 0.4062, -0.0868, -0.7614],\n",
      "        [-1.5192,  1.5180, -0.1211],\n",
      "        [-1.6556,  1.6783, -0.4374],\n",
      "        [-1.2499,  1.5970, -0.5862],\n",
      "        [-1.4145,  1.8549, -0.4484],\n",
      "        [-1.5729,  1.8672, -0.4780],\n",
      "        [-1.5563,  1.7447, -0.2540],\n",
      "        [-1.5344,  1.7727, -0.2782],\n",
      "        [-1.6795,  1.8360, -0.2010],\n",
      "        [-1.6603,  1.6149, -0.0258],\n",
      "        [-1.7151,  1.5678, -0.3529],\n",
      "        [-1.4707,  1.6560, -0.3010]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.3007, -0.0228, -0.9128],\n",
      "        [-1.8394,  1.3511,  0.4665],\n",
      "        [-1.5969,  1.9031, -0.5017],\n",
      "        [-1.5115,  1.7227, -0.3342],\n",
      "        [ 0.4062, -0.0868, -0.7614],\n",
      "        [-1.5192,  1.5180, -0.1211],\n",
      "        [-1.6556,  1.6783, -0.4374],\n",
      "        [-1.2499,  1.5970, -0.5862],\n",
      "        [-1.4145,  1.8549, -0.4484],\n",
      "        [-1.5729,  1.8672, -0.4780],\n",
      "        [-1.5563,  1.7447, -0.2540],\n",
      "        [-1.5344,  1.7727, -0.2782],\n",
      "        [-1.6795,  1.8360, -0.2010],\n",
      "        [-1.6603,  1.6149, -0.0258],\n",
      "        [-1.7151,  1.5678, -0.3529],\n",
      "        [-1.4707,  1.6560, -0.3010]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5330, -0.0802, -0.8477],\n",
      "        [-1.4648,  1.6837, -0.1472],\n",
      "        [-1.5629,  1.5294, -0.2176],\n",
      "        [-1.4552,  1.5239, -0.4555],\n",
      "        [-1.4265,  0.0755,  0.9470],\n",
      "        [-1.4075,  1.6216, -0.3518],\n",
      "        [-1.8345,  0.4074,  1.1200],\n",
      "        [-1.4340,  1.5672, -0.4984],\n",
      "        [-1.3820,  1.6074, -0.2760],\n",
      "        [-1.6093,  1.7677, -0.3387],\n",
      "        [-1.4058,  0.3268,  0.8673],\n",
      "        [-1.7299,  1.7718, -0.4240],\n",
      "        [-1.5460,  1.4175, -0.2538],\n",
      "        [-1.5188,  1.5553, -0.4432],\n",
      "        [-0.4487,  0.5458, -0.8455],\n",
      "        [-1.5681,  0.1376,  1.0761]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.5330, -0.0802, -0.8477],\n",
      "        [-1.4648,  1.6837, -0.1472],\n",
      "        [-1.5629,  1.5294, -0.2176],\n",
      "        [-1.4552,  1.5239, -0.4555],\n",
      "        [-1.4265,  0.0755,  0.9470],\n",
      "        [-1.4075,  1.6216, -0.3518],\n",
      "        [-1.8345,  0.4074,  1.1200],\n",
      "        [-1.4340,  1.5672, -0.4984],\n",
      "        [-1.3820,  1.6074, -0.2760],\n",
      "        [-1.6093,  1.7677, -0.3387],\n",
      "        [-1.4058,  0.3268,  0.8673],\n",
      "        [-1.7299,  1.7718, -0.4240],\n",
      "        [-1.5460,  1.4175, -0.2538],\n",
      "        [-1.5188,  1.5553, -0.4432],\n",
      "        [-0.4487,  0.5458, -0.8455],\n",
      "        [-1.5681,  0.1376,  1.0761]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6987,  1.7169, -0.2103],\n",
      "        [-1.4001,  0.3033,  0.8526],\n",
      "        [-1.4795,  1.7069, -0.4616],\n",
      "        [-1.4715,  0.4400,  1.0297],\n",
      "        [ 0.5456, -0.1937, -0.8013],\n",
      "        [-1.6979,  1.6079, -0.3129],\n",
      "        [ 0.4484, -0.1561, -0.8019],\n",
      "        [-1.5193,  1.4950,  0.1652],\n",
      "        [-1.5545,  1.5080, -0.3590],\n",
      "        [-1.4228,  1.5620, -0.4921],\n",
      "        [-1.6360,  1.6978, -0.5527],\n",
      "        [-1.7256,  1.6806, -0.2319],\n",
      "        [-1.3894,  0.1836,  1.0874],\n",
      "        [-1.6517,  1.7059, -0.4969],\n",
      "        [-1.2329,  1.5898, -0.4990],\n",
      "        [-1.5816,  1.8471, -0.3177]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6987,  1.7169, -0.2103],\n",
      "        [-1.4001,  0.3033,  0.8526],\n",
      "        [-1.4795,  1.7069, -0.4616],\n",
      "        [-1.4715,  0.4400,  1.0297],\n",
      "        [ 0.5456, -0.1937, -0.8013],\n",
      "        [-1.6979,  1.6079, -0.3129],\n",
      "        [ 0.4484, -0.1561, -0.8019],\n",
      "        [-1.5193,  1.4950,  0.1652],\n",
      "        [-1.5545,  1.5080, -0.3590],\n",
      "        [-1.4228,  1.5620, -0.4921],\n",
      "        [-1.6360,  1.6978, -0.5527],\n",
      "        [-1.7256,  1.6806, -0.2319],\n",
      "        [-1.3894,  0.1836,  1.0874],\n",
      "        [-1.6517,  1.7059, -0.4969],\n",
      "        [-1.2329,  1.5898, -0.4990],\n",
      "        [-1.5816,  1.8471, -0.3177]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4388,  0.2965,  1.1343],\n",
      "        [-1.4772,  1.8869, -0.4161],\n",
      "        [-1.7282,  0.4212,  0.9332],\n",
      "        [ 0.4945, -0.1153, -0.9469],\n",
      "        [-1.2927,  0.7547,  0.0923],\n",
      "        [ 0.3977, -0.1402, -0.8195],\n",
      "        [ 0.5382, -0.0838, -0.7783],\n",
      "        [ 0.3501,  0.0469, -0.7768],\n",
      "        [-1.6901,  0.4419,  0.8301],\n",
      "        [-1.4952,  1.6884, -0.3299],\n",
      "        [-1.7139,  1.9503, -0.3204],\n",
      "        [-1.5440,  1.6790, -0.3538],\n",
      "        [-1.4098,  1.6198, -0.2838],\n",
      "        [-1.3730,  1.4134, -0.3671],\n",
      "        [-1.3277,  1.6492, -0.4805],\n",
      "        [-1.7548,  0.6299,  0.8507]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4388,  0.2965,  1.1343],\n",
      "        [-1.4772,  1.8869, -0.4161],\n",
      "        [-1.7282,  0.4212,  0.9332],\n",
      "        [ 0.4945, -0.1153, -0.9469],\n",
      "        [-1.2927,  0.7547,  0.0923],\n",
      "        [ 0.3977, -0.1402, -0.8195],\n",
      "        [ 0.5382, -0.0838, -0.7783],\n",
      "        [ 0.3501,  0.0469, -0.7768],\n",
      "        [-1.6901,  0.4419,  0.8301],\n",
      "        [-1.4952,  1.6884, -0.3299],\n",
      "        [-1.7139,  1.9503, -0.3204],\n",
      "        [-1.5440,  1.6790, -0.3538],\n",
      "        [-1.4098,  1.6198, -0.2838],\n",
      "        [-1.3730,  1.4134, -0.3671],\n",
      "        [-1.3277,  1.6492, -0.4805],\n",
      "        [-1.7548,  0.6299,  0.8507]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5663e+00,  2.7197e-01,  1.0268e+00],\n",
      "        [-1.4256e+00,  3.8039e-01,  1.0420e+00],\n",
      "        [-1.6211e+00,  1.8182e+00, -5.2521e-01],\n",
      "        [-1.4853e+00,  1.7010e+00, -6.6117e-02],\n",
      "        [-1.4776e+00,  1.3707e+00,  6.4830e-02],\n",
      "        [-1.8602e+00,  1.0316e+00,  4.5215e-01],\n",
      "        [ 4.5270e-01, -1.6652e-01, -8.3899e-01],\n",
      "        [-1.1678e-01,  6.8320e-01, -6.0803e-01],\n",
      "        [-1.8548e+00,  1.6722e+00, -1.5389e-01],\n",
      "        [-1.8470e+00,  1.1126e+00,  5.0678e-01],\n",
      "        [-1.5739e+00,  1.5585e+00, -3.4155e-01],\n",
      "        [ 1.2976e-01, -3.8634e-02, -5.0318e-01],\n",
      "        [-1.8726e+00,  1.2137e+00,  3.5865e-01],\n",
      "        [-1.2352e+00,  1.3681e-03,  8.8560e-01],\n",
      "        [-1.4610e+00,  1.8544e+00, -4.2263e-01],\n",
      "        [-1.4774e+00,  1.5992e+00, -2.6034e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5663e+00,  2.7197e-01,  1.0268e+00],\n",
      "        [-1.4256e+00,  3.8039e-01,  1.0420e+00],\n",
      "        [-1.6211e+00,  1.8182e+00, -5.2521e-01],\n",
      "        [-1.4853e+00,  1.7010e+00, -6.6117e-02],\n",
      "        [-1.4776e+00,  1.3707e+00,  6.4830e-02],\n",
      "        [-1.8602e+00,  1.0316e+00,  4.5215e-01],\n",
      "        [ 4.5270e-01, -1.6652e-01, -8.3899e-01],\n",
      "        [-1.1678e-01,  6.8320e-01, -6.0803e-01],\n",
      "        [-1.8548e+00,  1.6722e+00, -1.5389e-01],\n",
      "        [-1.8470e+00,  1.1126e+00,  5.0678e-01],\n",
      "        [-1.5739e+00,  1.5585e+00, -3.4155e-01],\n",
      "        [ 1.2976e-01, -3.8634e-02, -5.0318e-01],\n",
      "        [-1.8726e+00,  1.2137e+00,  3.5865e-01],\n",
      "        [-1.2352e+00,  1.3681e-03,  8.8560e-01],\n",
      "        [-1.4610e+00,  1.8544e+00, -4.2263e-01],\n",
      "        [-1.4774e+00,  1.5992e+00, -2.6034e-01]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5282,  1.4808, -0.5496],\n",
      "        [ 0.2756, -0.1297, -0.3936],\n",
      "        [-1.5467,  1.7357, -0.2684],\n",
      "        [-1.4915,  1.6058, -0.2988],\n",
      "        [-1.5390,  1.6932, -0.2095],\n",
      "        [-1.6999,  1.6882, -0.3205],\n",
      "        [ 0.2045,  0.0363, -0.9102],\n",
      "        [-1.2838,  1.4108, -0.3758],\n",
      "        [-1.5798,  1.5354, -0.2854],\n",
      "        [-1.5748,  1.3447, -0.2814],\n",
      "        [-1.4186,  1.5370, -0.1221],\n",
      "        [-1.5121,  1.6627, -0.2571],\n",
      "        [ 0.2676,  0.0243, -0.7772],\n",
      "        [-1.7395,  0.1855,  1.1395],\n",
      "        [-1.8658,  0.7914,  0.7610],\n",
      "        [-1.5582,  1.7532, -0.4279]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5282,  1.4808, -0.5496],\n",
      "        [ 0.2756, -0.1297, -0.3936],\n",
      "        [-1.5467,  1.7357, -0.2684],\n",
      "        [-1.4915,  1.6058, -0.2988],\n",
      "        [-1.5390,  1.6932, -0.2095],\n",
      "        [-1.6999,  1.6882, -0.3205],\n",
      "        [ 0.2045,  0.0363, -0.9102],\n",
      "        [-1.2838,  1.4108, -0.3758],\n",
      "        [-1.5798,  1.5354, -0.2854],\n",
      "        [-1.5748,  1.3447, -0.2814],\n",
      "        [-1.4186,  1.5370, -0.1221],\n",
      "        [-1.5121,  1.6627, -0.2571],\n",
      "        [ 0.2676,  0.0243, -0.7772],\n",
      "        [-1.7395,  0.1855,  1.1395],\n",
      "        [-1.8658,  0.7914,  0.7610],\n",
      "        [-1.5582,  1.7532, -0.4279]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8658e+00,  7.2888e-01,  9.5642e-01],\n",
      "        [-1.8702e+00,  8.2492e-01,  9.4928e-01],\n",
      "        [ 3.5974e-01, -6.2281e-04, -5.0509e-01],\n",
      "        [-1.5946e+00,  1.7099e+00, -4.2379e-01],\n",
      "        [-1.4914e+00,  1.7229e+00, -4.7052e-01],\n",
      "        [-1.5934e+00,  1.7427e+00, -4.4878e-01],\n",
      "        [-1.5755e+00,  1.8341e+00, -2.3678e-01],\n",
      "        [-1.6689e+00,  1.5859e+00, -4.2695e-01],\n",
      "        [-1.4788e+00,  1.7266e+00, -4.0582e-01],\n",
      "        [-1.6315e+00,  1.4851e+00, -3.8174e-01],\n",
      "        [-1.5016e+00,  1.6218e+00, -3.4059e-01],\n",
      "        [-1.4255e+00,  1.6768e+00, -5.1570e-01],\n",
      "        [-1.8396e+00,  3.8387e-01,  1.1448e+00],\n",
      "        [-1.7415e+00,  1.6755e+00, -1.9321e-01],\n",
      "        [ 5.4820e-01, -4.0627e-02, -8.8969e-01],\n",
      "        [-1.4588e+00,  1.4441e+00, -2.9387e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8658e+00,  7.2888e-01,  9.5642e-01],\n",
      "        [-1.8702e+00,  8.2492e-01,  9.4928e-01],\n",
      "        [ 3.5974e-01, -6.2281e-04, -5.0509e-01],\n",
      "        [-1.5946e+00,  1.7099e+00, -4.2379e-01],\n",
      "        [-1.4914e+00,  1.7229e+00, -4.7052e-01],\n",
      "        [-1.5934e+00,  1.7427e+00, -4.4878e-01],\n",
      "        [-1.5755e+00,  1.8341e+00, -2.3678e-01],\n",
      "        [-1.6689e+00,  1.5859e+00, -4.2695e-01],\n",
      "        [-1.4788e+00,  1.7266e+00, -4.0582e-01],\n",
      "        [-1.6315e+00,  1.4851e+00, -3.8174e-01],\n",
      "        [-1.5016e+00,  1.6218e+00, -3.4059e-01],\n",
      "        [-1.4255e+00,  1.6768e+00, -5.1570e-01],\n",
      "        [-1.8396e+00,  3.8387e-01,  1.1448e+00],\n",
      "        [-1.7415e+00,  1.6755e+00, -1.9321e-01],\n",
      "        [ 5.4820e-01, -4.0627e-02, -8.8969e-01],\n",
      "        [-1.4588e+00,  1.4441e+00, -2.9387e-01]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6953,  1.8920, -0.4259],\n",
      "        [-1.4533,  1.7722, -0.4142],\n",
      "        [-1.7499,  1.7883, -0.4980],\n",
      "        [-1.4835,  0.0660,  1.0829],\n",
      "        [ 0.5630, -0.1048, -0.7709],\n",
      "        [-1.5452,  1.7493, -0.4105],\n",
      "        [-1.6663,  1.7336, -0.4515],\n",
      "        [-1.5794,  1.8579, -0.3817],\n",
      "        [-1.3845,  1.7216, -0.4340],\n",
      "        [ 0.3099,  0.1681, -1.0443],\n",
      "        [-1.6469,  1.6218, -0.3514],\n",
      "        [-1.7606,  1.6124, -0.2806],\n",
      "        [-0.7799,  0.9443, -0.8486],\n",
      "        [-1.8120,  1.7828, -0.3449],\n",
      "        [-1.7133,  1.5876, -0.0810],\n",
      "        [-0.7493, -0.0677,  0.5938]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6953,  1.8920, -0.4259],\n",
      "        [-1.4533,  1.7722, -0.4142],\n",
      "        [-1.7499,  1.7883, -0.4980],\n",
      "        [-1.4835,  0.0660,  1.0829],\n",
      "        [ 0.5630, -0.1048, -0.7709],\n",
      "        [-1.5452,  1.7493, -0.4105],\n",
      "        [-1.6663,  1.7336, -0.4515],\n",
      "        [-1.5794,  1.8579, -0.3817],\n",
      "        [-1.3845,  1.7216, -0.4340],\n",
      "        [ 0.3099,  0.1681, -1.0443],\n",
      "        [-1.6469,  1.6218, -0.3514],\n",
      "        [-1.7606,  1.6124, -0.2806],\n",
      "        [-0.7799,  0.9443, -0.8486],\n",
      "        [-1.8120,  1.7828, -0.3449],\n",
      "        [-1.7133,  1.5876, -0.0810],\n",
      "        [-0.7493, -0.0677,  0.5938]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.4721,  0.1276, -0.8382],\n",
      "        [-1.4529,  1.6115, -0.1851],\n",
      "        [-1.5012,  1.7224, -0.5894],\n",
      "        [-1.2996,  1.8990, -0.3971],\n",
      "        [ 0.2181, -0.0068, -0.7127],\n",
      "        [ 0.0767,  0.2336, -0.8980],\n",
      "        [-1.5307,  1.5611, -0.3463],\n",
      "        [-2.1414,  0.7476,  0.8473],\n",
      "        [-1.6779,  1.6758, -0.3862],\n",
      "        [ 0.2622, -0.2009, -0.7386],\n",
      "        [-1.5756,  1.8671, -0.5914],\n",
      "        [-1.4145,  1.6379, -0.5124],\n",
      "        [-1.4690,  0.1497,  1.0522],\n",
      "        [-1.6420,  1.6490, -0.3904],\n",
      "        [-1.5974,  1.6113, -0.4980],\n",
      "        [-1.8561,  0.0576,  1.1985]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.4721,  0.1276, -0.8382],\n",
      "        [-1.4529,  1.6115, -0.1851],\n",
      "        [-1.5012,  1.7224, -0.5894],\n",
      "        [-1.2996,  1.8990, -0.3971],\n",
      "        [ 0.2181, -0.0068, -0.7127],\n",
      "        [ 0.0767,  0.2336, -0.8980],\n",
      "        [-1.5307,  1.5611, -0.3463],\n",
      "        [-2.1414,  0.7476,  0.8473],\n",
      "        [-1.6779,  1.6758, -0.3862],\n",
      "        [ 0.2622, -0.2009, -0.7386],\n",
      "        [-1.5756,  1.8671, -0.5914],\n",
      "        [-1.4145,  1.6379, -0.5124],\n",
      "        [-1.4690,  0.1497,  1.0522],\n",
      "        [-1.6420,  1.6490, -0.3904],\n",
      "        [-1.5974,  1.6113, -0.4980],\n",
      "        [-1.8561,  0.0576,  1.1985]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5794,  1.6810, -0.3233],\n",
      "        [ 0.3810, -0.1794, -0.6938],\n",
      "        [-1.4327,  1.5899, -0.3728],\n",
      "        [ 0.4582, -0.2325, -0.7279],\n",
      "        [-1.7327,  0.4541,  1.1682],\n",
      "        [-1.8983,  0.6069,  1.0741],\n",
      "        [-1.7980,  0.1362,  1.4413],\n",
      "        [-1.5994,  1.7452, -0.4484],\n",
      "        [-1.7316,  0.2580,  1.1256],\n",
      "        [-1.6609,  1.5144,  0.0909],\n",
      "        [-2.0141,  1.2434,  0.7509],\n",
      "        [-1.6300,  1.6804, -0.4324],\n",
      "        [-1.7052,  1.7042, -0.3360],\n",
      "        [-1.7668,  0.7568,  0.8010],\n",
      "        [-1.8151,  1.4513, -0.3588],\n",
      "        [-1.6510,  0.1665,  1.0742]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5794,  1.6810, -0.3233],\n",
      "        [ 0.3810, -0.1794, -0.6938],\n",
      "        [-1.4327,  1.5899, -0.3728],\n",
      "        [ 0.4582, -0.2325, -0.7279],\n",
      "        [-1.7327,  0.4541,  1.1682],\n",
      "        [-1.8983,  0.6069,  1.0741],\n",
      "        [-1.7980,  0.1362,  1.4413],\n",
      "        [-1.5994,  1.7452, -0.4484],\n",
      "        [-1.7316,  0.2580,  1.1256],\n",
      "        [-1.6609,  1.5144,  0.0909],\n",
      "        [-2.0141,  1.2434,  0.7509],\n",
      "        [-1.6300,  1.6804, -0.4324],\n",
      "        [-1.7052,  1.7042, -0.3360],\n",
      "        [-1.7668,  0.7568,  0.8010],\n",
      "        [-1.8151,  1.4513, -0.3588],\n",
      "        [-1.6510,  0.1665,  1.0742]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5381,  1.7228, -0.4822],\n",
      "        [-1.6873,  1.7568, -0.1877],\n",
      "        [-1.6621,  1.2593,  0.2037],\n",
      "        [-1.4852,  1.4199, -0.4267],\n",
      "        [-1.8975,  0.2334,  1.0418],\n",
      "        [-1.4643,  1.3040, -0.1408],\n",
      "        [-1.7027,  0.1869,  1.2871],\n",
      "        [-1.5427,  0.0513,  1.2705],\n",
      "        [-1.3145,  1.5057, -0.5235],\n",
      "        [-1.5429,  0.1111,  1.1660],\n",
      "        [ 0.0469,  0.3790, -1.0454],\n",
      "        [-1.7450,  0.9871,  0.7026],\n",
      "        [-1.3882,  1.7385, -0.2750],\n",
      "        [-1.2901,  1.5691, -0.5973],\n",
      "        [-1.5397,  1.4345, -0.4842],\n",
      "        [-1.5359,  1.3923, -0.0045]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5381,  1.7228, -0.4822],\n",
      "        [-1.6873,  1.7568, -0.1877],\n",
      "        [-1.6621,  1.2593,  0.2037],\n",
      "        [-1.4852,  1.4199, -0.4267],\n",
      "        [-1.8975,  0.2334,  1.0418],\n",
      "        [-1.4643,  1.3040, -0.1408],\n",
      "        [-1.7027,  0.1869,  1.2871],\n",
      "        [-1.5427,  0.0513,  1.2705],\n",
      "        [-1.3145,  1.5057, -0.5235],\n",
      "        [-1.5429,  0.1111,  1.1660],\n",
      "        [ 0.0469,  0.3790, -1.0454],\n",
      "        [-1.7450,  0.9871,  0.7026],\n",
      "        [-1.3882,  1.7385, -0.2750],\n",
      "        [-1.2901,  1.5691, -0.5973],\n",
      "        [-1.5397,  1.4345, -0.4842],\n",
      "        [-1.5359,  1.3923, -0.0045]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5312,  1.7170, -0.1548],\n",
      "        [-1.9396,  0.5305,  0.8623],\n",
      "        [ 0.3603, -0.1292, -0.7219],\n",
      "        [-1.2148,  1.4118, -0.5409],\n",
      "        [-1.5141,  1.6232, -0.5005],\n",
      "        [-1.7339,  0.1736,  1.2063],\n",
      "        [-1.4534,  1.7937, -0.4791],\n",
      "        [-1.6277,  0.1695,  1.2463],\n",
      "        [-1.3947,  1.5770, -0.1186],\n",
      "        [ 0.4226, -0.1449, -0.7634],\n",
      "        [-1.6067, -0.0422,  1.1601],\n",
      "        [-1.5756,  0.2184,  1.0112],\n",
      "        [ 0.4704, -0.0735, -0.7244],\n",
      "        [-1.3834,  1.7831, -0.7523],\n",
      "        [-1.7232,  0.1332,  1.0053],\n",
      "        [-0.7622,  1.3085, -0.8759]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5312,  1.7170, -0.1548],\n",
      "        [-1.9396,  0.5305,  0.8623],\n",
      "        [ 0.3603, -0.1292, -0.7219],\n",
      "        [-1.2148,  1.4118, -0.5409],\n",
      "        [-1.5141,  1.6232, -0.5005],\n",
      "        [-1.7339,  0.1736,  1.2063],\n",
      "        [-1.4534,  1.7937, -0.4791],\n",
      "        [-1.6277,  0.1695,  1.2463],\n",
      "        [-1.3947,  1.5770, -0.1186],\n",
      "        [ 0.4226, -0.1449, -0.7634],\n",
      "        [-1.6067, -0.0422,  1.1601],\n",
      "        [-1.5756,  0.2184,  1.0112],\n",
      "        [ 0.4704, -0.0735, -0.7244],\n",
      "        [-1.3834,  1.7831, -0.7523],\n",
      "        [-1.7232,  0.1332,  1.0053],\n",
      "        [-0.7622,  1.3085, -0.8759]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.4178, -0.1710, -1.0664],\n",
      "        [-1.3989,  1.6262, -0.3893],\n",
      "        [-1.5068,  1.7341, -0.2868],\n",
      "        [-1.3640,  1.7260, -0.5554],\n",
      "        [-1.2924,  1.6705, -0.3325],\n",
      "        [-1.3260,  1.5570, -0.6110],\n",
      "        [-1.6167,  0.1437,  1.2279],\n",
      "        [-1.4900,  1.8668, -0.5665],\n",
      "        [-1.8934,  0.6248,  1.0926],\n",
      "        [ 0.0142, -0.0102, -0.5331],\n",
      "        [-1.5189,  1.6871, -0.6186],\n",
      "        [-1.5946,  0.1982,  1.1882],\n",
      "        [-1.4334,  1.7369, -0.3976],\n",
      "        [-1.5294,  1.6007, -0.2180],\n",
      "        [-1.3360,  1.7872, -0.6026],\n",
      "        [-1.6888,  0.2153,  1.2308]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.4178, -0.1710, -1.0664],\n",
      "        [-1.3989,  1.6262, -0.3893],\n",
      "        [-1.5068,  1.7341, -0.2868],\n",
      "        [-1.3640,  1.7260, -0.5554],\n",
      "        [-1.2924,  1.6705, -0.3325],\n",
      "        [-1.3260,  1.5570, -0.6110],\n",
      "        [-1.6167,  0.1437,  1.2279],\n",
      "        [-1.4900,  1.8668, -0.5665],\n",
      "        [-1.8934,  0.6248,  1.0926],\n",
      "        [ 0.0142, -0.0102, -0.5331],\n",
      "        [-1.5189,  1.6871, -0.6186],\n",
      "        [-1.5946,  0.1982,  1.1882],\n",
      "        [-1.4334,  1.7369, -0.3976],\n",
      "        [-1.5294,  1.6007, -0.2180],\n",
      "        [-1.3360,  1.7872, -0.6026],\n",
      "        [-1.6888,  0.2153,  1.2308]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3298,  1.5978, -0.1921],\n",
      "        [-1.8261,  0.2846,  1.1475],\n",
      "        [-1.6514,  1.5635, -0.3438],\n",
      "        [-1.6408,  1.4882, -0.2020],\n",
      "        [-1.5008,  0.1774,  1.2155],\n",
      "        [-1.5774,  1.6462, -0.2548],\n",
      "        [-1.4171,  1.2803, -0.4437],\n",
      "        [-1.8228,  0.0830,  1.3317],\n",
      "        [-1.5905,  1.6761, -0.5068],\n",
      "        [-1.4499,  1.6910, -0.4277],\n",
      "        [-1.8984,  0.6588,  1.3080],\n",
      "        [-1.6151,  1.1575,  0.4371],\n",
      "        [-1.4914,  1.5968, -0.5819],\n",
      "        [-1.8494,  0.8672,  0.7874],\n",
      "        [-1.8742,  1.6990, -0.0262],\n",
      "        [-1.4641,  1.6538, -0.5240]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3298,  1.5978, -0.1921],\n",
      "        [-1.8261,  0.2846,  1.1475],\n",
      "        [-1.6514,  1.5635, -0.3438],\n",
      "        [-1.6408,  1.4882, -0.2020],\n",
      "        [-1.5008,  0.1774,  1.2155],\n",
      "        [-1.5774,  1.6462, -0.2548],\n",
      "        [-1.4171,  1.2803, -0.4437],\n",
      "        [-1.8228,  0.0830,  1.3317],\n",
      "        [-1.5905,  1.6761, -0.5068],\n",
      "        [-1.4499,  1.6910, -0.4277],\n",
      "        [-1.8984,  0.6588,  1.3080],\n",
      "        [-1.6151,  1.1575,  0.4371],\n",
      "        [-1.4914,  1.5968, -0.5819],\n",
      "        [-1.8494,  0.8672,  0.7874],\n",
      "        [-1.8742,  1.6990, -0.0262],\n",
      "        [-1.4641,  1.6538, -0.5240]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6738,  0.2392,  1.2251],\n",
      "        [-1.6771,  0.1029,  1.3065],\n",
      "        [-1.6804,  1.6331, -0.0503],\n",
      "        [-1.6038,  0.1920,  1.2252],\n",
      "        [-1.4835,  1.3764, -0.0554],\n",
      "        [-1.7759,  0.1181,  1.2266],\n",
      "        [-1.7414,  0.1494,  1.2517],\n",
      "        [-1.4158,  1.9068, -0.6375],\n",
      "        [-1.4175,  1.8077, -0.5498],\n",
      "        [-1.5089,  1.4605, -0.2153],\n",
      "        [-1.6409,  1.8381, -0.5597],\n",
      "        [-1.3526,  1.4434, -0.4782],\n",
      "        [-1.4337,  1.6182, -0.5561],\n",
      "        [-0.4311,  0.7247, -0.6739],\n",
      "        [-1.4387,  1.8337, -0.4639],\n",
      "        [-1.8037,  0.0960,  1.2812]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6738,  0.2392,  1.2251],\n",
      "        [-1.6771,  0.1029,  1.3065],\n",
      "        [-1.6804,  1.6331, -0.0503],\n",
      "        [-1.6038,  0.1920,  1.2252],\n",
      "        [-1.4835,  1.3764, -0.0554],\n",
      "        [-1.7759,  0.1181,  1.2266],\n",
      "        [-1.7414,  0.1494,  1.2517],\n",
      "        [-1.4158,  1.9068, -0.6375],\n",
      "        [-1.4175,  1.8077, -0.5498],\n",
      "        [-1.5089,  1.4605, -0.2153],\n",
      "        [-1.6409,  1.8381, -0.5597],\n",
      "        [-1.3526,  1.4434, -0.4782],\n",
      "        [-1.4337,  1.6182, -0.5561],\n",
      "        [-0.4311,  0.7247, -0.6739],\n",
      "        [-1.4387,  1.8337, -0.4639],\n",
      "        [-1.8037,  0.0960,  1.2812]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8400,  0.0769,  1.2547],\n",
      "        [ 0.0511, -0.0228, -0.6657],\n",
      "        [-1.6437,  0.0531,  1.2605],\n",
      "        [ 0.3705, -0.1048, -0.9349],\n",
      "        [-1.6096,  1.6589, -0.2488],\n",
      "        [ 0.6033, -0.1777, -0.6988],\n",
      "        [-1.5096,  1.4525, -0.6269],\n",
      "        [-1.4353,  1.4535, -0.7636],\n",
      "        [-1.9481,  0.6169,  0.8668],\n",
      "        [-1.6410,  1.8252, -0.2979],\n",
      "        [-1.1274,  1.5838, -0.5364],\n",
      "        [-1.8573,  0.0659,  1.2486],\n",
      "        [-1.6615,  0.2996,  1.1626],\n",
      "        [-1.3707,  1.5800, -0.4402],\n",
      "        [-1.5722,  1.6132, -0.6034],\n",
      "        [-1.6244,  0.7232,  0.8164]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8400,  0.0769,  1.2547],\n",
      "        [ 0.0511, -0.0228, -0.6657],\n",
      "        [-1.6437,  0.0531,  1.2605],\n",
      "        [ 0.3705, -0.1048, -0.9349],\n",
      "        [-1.6096,  1.6589, -0.2488],\n",
      "        [ 0.6033, -0.1777, -0.6988],\n",
      "        [-1.5096,  1.4525, -0.6269],\n",
      "        [-1.4353,  1.4535, -0.7636],\n",
      "        [-1.9481,  0.6169,  0.8668],\n",
      "        [-1.6410,  1.8252, -0.2979],\n",
      "        [-1.1274,  1.5838, -0.5364],\n",
      "        [-1.8573,  0.0659,  1.2486],\n",
      "        [-1.6615,  0.2996,  1.1626],\n",
      "        [-1.3707,  1.5800, -0.4402],\n",
      "        [-1.5722,  1.6132, -0.6034],\n",
      "        [-1.6244,  0.7232,  0.8164]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4191,  1.6609, -0.5062],\n",
      "        [-1.2536,  1.6262, -0.4874],\n",
      "        [-1.1999,  1.4573, -0.7451],\n",
      "        [-1.8088,  0.9374,  0.6546],\n",
      "        [ 0.6166, -0.3138, -0.8455],\n",
      "        [-1.5433,  1.2691, -0.1153],\n",
      "        [-1.1926,  1.6602, -0.6942],\n",
      "        [-1.4067,  1.6395, -0.3469],\n",
      "        [ 0.4601, -0.0308, -0.7116],\n",
      "        [-1.2651,  1.5365, -0.6004],\n",
      "        [-1.2973,  1.5399, -0.4974],\n",
      "        [-1.5855,  1.7331, -0.2400],\n",
      "        [-1.6876,  0.1725,  1.1123],\n",
      "        [-1.8462,  0.1967,  1.3906],\n",
      "        [-1.3921,  1.7028, -0.1323],\n",
      "        [-1.8851,  1.0887,  0.2849]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4191,  1.6609, -0.5062],\n",
      "        [-1.2536,  1.6262, -0.4874],\n",
      "        [-1.1999,  1.4573, -0.7451],\n",
      "        [-1.8088,  0.9374,  0.6546],\n",
      "        [ 0.6166, -0.3138, -0.8455],\n",
      "        [-1.5433,  1.2691, -0.1153],\n",
      "        [-1.1926,  1.6602, -0.6942],\n",
      "        [-1.4067,  1.6395, -0.3469],\n",
      "        [ 0.4601, -0.0308, -0.7116],\n",
      "        [-1.2651,  1.5365, -0.6004],\n",
      "        [-1.2973,  1.5399, -0.4974],\n",
      "        [-1.5855,  1.7331, -0.2400],\n",
      "        [-1.6876,  0.1725,  1.1123],\n",
      "        [-1.8462,  0.1967,  1.3906],\n",
      "        [-1.3921,  1.7028, -0.1323],\n",
      "        [-1.8851,  1.0887,  0.2849]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8371,  0.3359,  1.0338],\n",
      "        [-1.4796,  1.8816, -0.4293],\n",
      "        [-1.4242,  1.8201, -0.4117],\n",
      "        [-1.7142,  1.4126,  0.0363],\n",
      "        [-1.3444,  1.6355, -0.6277],\n",
      "        [-1.8075,  1.2582,  0.3924],\n",
      "        [-0.7791,  0.0202,  0.4171],\n",
      "        [-1.8671,  0.3574,  1.4555],\n",
      "        [-1.3594,  1.2501, -0.5473],\n",
      "        [-1.3784,  1.2572, -0.1191],\n",
      "        [-1.3758,  1.8471, -0.6770],\n",
      "        [ 0.0252,  0.5221, -0.9414],\n",
      "        [-1.5312,  1.7072, -0.5170],\n",
      "        [ 0.4011, -0.2162, -0.6183],\n",
      "        [-1.9207,  0.2000,  1.3643],\n",
      "        [-1.4355,  1.4992, -0.2371]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8371,  0.3359,  1.0338],\n",
      "        [-1.4796,  1.8816, -0.4293],\n",
      "        [-1.4242,  1.8201, -0.4117],\n",
      "        [-1.7142,  1.4126,  0.0363],\n",
      "        [-1.3444,  1.6355, -0.6277],\n",
      "        [-1.8075,  1.2582,  0.3924],\n",
      "        [-0.7791,  0.0202,  0.4171],\n",
      "        [-1.8671,  0.3574,  1.4555],\n",
      "        [-1.3594,  1.2501, -0.5473],\n",
      "        [-1.3784,  1.2572, -0.1191],\n",
      "        [-1.3758,  1.8471, -0.6770],\n",
      "        [ 0.0252,  0.5221, -0.9414],\n",
      "        [-1.5312,  1.7072, -0.5170],\n",
      "        [ 0.4011, -0.2162, -0.6183],\n",
      "        [-1.9207,  0.2000,  1.3643],\n",
      "        [-1.4355,  1.4992, -0.2371]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8404,  0.3204,  1.3645],\n",
      "        [-1.3059,  1.5057, -0.3883],\n",
      "        [-1.4457,  1.7223, -0.5413],\n",
      "        [-1.6829,  0.0573,  1.3040],\n",
      "        [-1.7112,  0.2797,  1.1320],\n",
      "        [-1.8404,  0.1541,  1.4735],\n",
      "        [-1.3918,  1.5009, -0.1126],\n",
      "        [-1.8615,  0.7055,  0.6772],\n",
      "        [-1.2977,  1.4530, -0.7110],\n",
      "        [-1.3680,  1.7558, -0.4445],\n",
      "        [-1.8647,  0.3482,  1.3808],\n",
      "        [-1.8317,  0.2588,  1.3462],\n",
      "        [-1.1226,  1.3740, -0.6960],\n",
      "        [-0.7805,  0.9506, -0.6109],\n",
      "        [-1.7630, -0.1149,  1.4570],\n",
      "        [-1.4114,  1.6287, -0.3364]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8404,  0.3204,  1.3645],\n",
      "        [-1.3059,  1.5057, -0.3883],\n",
      "        [-1.4457,  1.7223, -0.5413],\n",
      "        [-1.6829,  0.0573,  1.3040],\n",
      "        [-1.7112,  0.2797,  1.1320],\n",
      "        [-1.8404,  0.1541,  1.4735],\n",
      "        [-1.3918,  1.5009, -0.1126],\n",
      "        [-1.8615,  0.7055,  0.6772],\n",
      "        [-1.2977,  1.4530, -0.7110],\n",
      "        [-1.3680,  1.7558, -0.4445],\n",
      "        [-1.8647,  0.3482,  1.3808],\n",
      "        [-1.8317,  0.2588,  1.3462],\n",
      "        [-1.1226,  1.3740, -0.6960],\n",
      "        [-0.7805,  0.9506, -0.6109],\n",
      "        [-1.7630, -0.1149,  1.4570],\n",
      "        [-1.4114,  1.6287, -0.3364]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0052,  0.7741,  0.8835],\n",
      "        [-1.7759,  0.8081,  0.8445],\n",
      "        [-1.3123,  1.5222, -0.5733],\n",
      "        [-1.7149,  0.0201,  1.3711],\n",
      "        [-1.7918,  0.8067,  0.8659],\n",
      "        [-1.9732,  0.1674,  1.3942],\n",
      "        [-0.0300, -0.0954, -0.1516],\n",
      "        [-1.9674,  0.8308,  0.5673],\n",
      "        [-1.5720,  1.4257, -0.0532],\n",
      "        [-1.6120,  1.5640, -0.3980],\n",
      "        [ 0.6908, -0.1350, -0.8179],\n",
      "        [-1.9681,  0.4830,  1.3712],\n",
      "        [-1.9398,  0.1324,  1.3509],\n",
      "        [-1.2689,  1.6483, -0.4429],\n",
      "        [-0.2184,  0.6676, -0.9272],\n",
      "        [ 0.3528, -0.2344, -0.6018]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.0052,  0.7741,  0.8835],\n",
      "        [-1.7759,  0.8081,  0.8445],\n",
      "        [-1.3123,  1.5222, -0.5733],\n",
      "        [-1.7149,  0.0201,  1.3711],\n",
      "        [-1.7918,  0.8067,  0.8659],\n",
      "        [-1.9732,  0.1674,  1.3942],\n",
      "        [-0.0300, -0.0954, -0.1516],\n",
      "        [-1.9674,  0.8308,  0.5673],\n",
      "        [-1.5720,  1.4257, -0.0532],\n",
      "        [-1.6120,  1.5640, -0.3980],\n",
      "        [ 0.6908, -0.1350, -0.8179],\n",
      "        [-1.9681,  0.4830,  1.3712],\n",
      "        [-1.9398,  0.1324,  1.3509],\n",
      "        [-1.2689,  1.6483, -0.4429],\n",
      "        [-0.2184,  0.6676, -0.9272],\n",
      "        [ 0.3528, -0.2344, -0.6018]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2741,  1.8129, -0.3945],\n",
      "        [-1.1854,  1.5820, -0.3347],\n",
      "        [-2.0528,  0.1078,  1.5043],\n",
      "        [-1.1232,  1.6509, -0.7493],\n",
      "        [-1.9995,  0.0389,  1.4796],\n",
      "        [-1.6688,  0.5826,  0.9632],\n",
      "        [-1.4888,  1.8353, -0.5932],\n",
      "        [-1.3406,  1.6521, -0.6183],\n",
      "        [-1.1938,  1.4846, -0.5984],\n",
      "        [ 0.4815, -0.3056, -0.9037],\n",
      "        [-1.3246,  1.6454, -0.4175],\n",
      "        [-1.2725,  1.5154, -0.7270],\n",
      "        [-1.4786,  1.7952, -0.6567],\n",
      "        [-1.6580,  1.4434,  0.1524],\n",
      "        [-1.3315,  1.6882, -0.5829],\n",
      "        [-1.2108,  1.4866, -0.5945]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.2741,  1.8129, -0.3945],\n",
      "        [-1.1854,  1.5820, -0.3347],\n",
      "        [-2.0528,  0.1078,  1.5043],\n",
      "        [-1.1232,  1.6509, -0.7493],\n",
      "        [-1.9995,  0.0389,  1.4796],\n",
      "        [-1.6688,  0.5826,  0.9632],\n",
      "        [-1.4888,  1.8353, -0.5932],\n",
      "        [-1.3406,  1.6521, -0.6183],\n",
      "        [-1.1938,  1.4846, -0.5984],\n",
      "        [ 0.4815, -0.3056, -0.9037],\n",
      "        [-1.3246,  1.6454, -0.4175],\n",
      "        [-1.2725,  1.5154, -0.7270],\n",
      "        [-1.4786,  1.7952, -0.6567],\n",
      "        [-1.6580,  1.4434,  0.1524],\n",
      "        [-1.3315,  1.6882, -0.5829],\n",
      "        [-1.2108,  1.4866, -0.5945]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2363,  1.5890, -0.4830],\n",
      "        [-1.2594,  1.7776, -0.3476],\n",
      "        [ 0.3630, -0.0859, -0.8690],\n",
      "        [-1.3373,  1.6390, -0.4982],\n",
      "        [-1.7754,  0.2505,  1.3710],\n",
      "        [-0.7805,  0.8397, -0.6401],\n",
      "        [-1.6397,  0.6101,  0.8659],\n",
      "        [-1.5731,  1.6586, -0.3373],\n",
      "        [-1.9265,  0.1411,  1.5105],\n",
      "        [ 0.5677, -0.3094, -0.8294],\n",
      "        [ 0.4691, -0.2033, -0.8759],\n",
      "        [-1.7470,  1.0144,  0.4243],\n",
      "        [ 0.3404, -0.3407, -0.6136],\n",
      "        [-1.3279,  1.6272, -0.4702],\n",
      "        [-1.8867,  0.1956,  1.3348],\n",
      "        [-1.1293,  1.3342, -0.5047]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.2363,  1.5890, -0.4830],\n",
      "        [-1.2594,  1.7776, -0.3476],\n",
      "        [ 0.3630, -0.0859, -0.8690],\n",
      "        [-1.3373,  1.6390, -0.4982],\n",
      "        [-1.7754,  0.2505,  1.3710],\n",
      "        [-0.7805,  0.8397, -0.6401],\n",
      "        [-1.6397,  0.6101,  0.8659],\n",
      "        [-1.5731,  1.6586, -0.3373],\n",
      "        [-1.9265,  0.1411,  1.5105],\n",
      "        [ 0.5677, -0.3094, -0.8294],\n",
      "        [ 0.4691, -0.2033, -0.8759],\n",
      "        [-1.7470,  1.0144,  0.4243],\n",
      "        [ 0.3404, -0.3407, -0.6136],\n",
      "        [-1.3279,  1.6272, -0.4702],\n",
      "        [-1.8867,  0.1956,  1.3348],\n",
      "        [-1.1293,  1.3342, -0.5047]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3752,  1.9096, -0.6552],\n",
      "        [-1.2988,  1.7059, -0.6655],\n",
      "        [-2.0420,  0.1111,  1.4700],\n",
      "        [ 0.6601, -0.2273, -0.8923],\n",
      "        [-1.1410,  1.2030, -0.4821],\n",
      "        [-1.2423,  1.0611, -0.3329],\n",
      "        [-1.3204,  1.6454, -0.4420],\n",
      "        [-1.4738,  1.8673, -0.7113],\n",
      "        [-1.7641,  1.2907,  0.1833],\n",
      "        [-1.5202,  1.6689, -0.7497],\n",
      "        [ 0.2895, -0.2077, -0.7456],\n",
      "        [-1.2729,  1.7545, -0.7879],\n",
      "        [-1.9832,  0.8513,  1.0038],\n",
      "        [ 0.0261, -0.2102, -0.3151],\n",
      "        [-1.1886,  1.6218, -0.6958],\n",
      "        [-1.9754,  0.4544,  1.2801]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3752,  1.9096, -0.6552],\n",
      "        [-1.2988,  1.7059, -0.6655],\n",
      "        [-2.0420,  0.1111,  1.4700],\n",
      "        [ 0.6601, -0.2273, -0.8923],\n",
      "        [-1.1410,  1.2030, -0.4821],\n",
      "        [-1.2423,  1.0611, -0.3329],\n",
      "        [-1.3204,  1.6454, -0.4420],\n",
      "        [-1.4738,  1.8673, -0.7113],\n",
      "        [-1.7641,  1.2907,  0.1833],\n",
      "        [-1.5202,  1.6689, -0.7497],\n",
      "        [ 0.2895, -0.2077, -0.7456],\n",
      "        [-1.2729,  1.7545, -0.7879],\n",
      "        [-1.9832,  0.8513,  1.0038],\n",
      "        [ 0.0261, -0.2102, -0.3151],\n",
      "        [-1.1886,  1.6218, -0.6958],\n",
      "        [-1.9754,  0.4544,  1.2801]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8803,  0.8695,  0.8729],\n",
      "        [-2.0663,  0.1413,  1.6616],\n",
      "        [-1.1736,  1.7094, -0.7029],\n",
      "        [ 0.5438, -0.2780, -0.7520],\n",
      "        [-1.9700,  0.6045,  0.8962],\n",
      "        [-1.8412,  0.1438,  1.2979],\n",
      "        [-1.1802,  1.5904, -0.1980],\n",
      "        [-1.2830,  1.6283, -0.7419],\n",
      "        [-1.0725,  1.4442, -0.7880],\n",
      "        [-1.2947,  1.6099, -0.7612],\n",
      "        [-0.4886, -0.0711,  0.4730],\n",
      "        [-1.2174,  1.5789, -0.7488],\n",
      "        [-1.9055,  0.2009,  1.4346],\n",
      "        [ 0.0399,  0.4033, -1.0332],\n",
      "        [ 0.5689, -0.1632, -0.7281],\n",
      "        [-1.3239,  1.7698, -0.8400]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8803,  0.8695,  0.8729],\n",
      "        [-2.0663,  0.1413,  1.6616],\n",
      "        [-1.1736,  1.7094, -0.7029],\n",
      "        [ 0.5438, -0.2780, -0.7520],\n",
      "        [-1.9700,  0.6045,  0.8962],\n",
      "        [-1.8412,  0.1438,  1.2979],\n",
      "        [-1.1802,  1.5904, -0.1980],\n",
      "        [-1.2830,  1.6283, -0.7419],\n",
      "        [-1.0725,  1.4442, -0.7880],\n",
      "        [-1.2947,  1.6099, -0.7612],\n",
      "        [-0.4886, -0.0711,  0.4730],\n",
      "        [-1.2174,  1.5789, -0.7488],\n",
      "        [-1.9055,  0.2009,  1.4346],\n",
      "        [ 0.0399,  0.4033, -1.0332],\n",
      "        [ 0.5689, -0.1632, -0.7281],\n",
      "        [-1.3239,  1.7698, -0.8400]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.3042e+00,  3.8154e-02,  1.4723e+00],\n",
      "        [-1.3766e+00,  1.6980e+00, -5.0230e-01],\n",
      "        [-1.4006e+00,  1.4478e+00, -3.7470e-01],\n",
      "        [-1.5776e+00,  4.9251e-02,  1.2136e+00],\n",
      "        [-1.8201e+00,  1.9408e-01,  1.4369e+00],\n",
      "        [ 4.2648e-01,  1.9317e-01, -9.5834e-01],\n",
      "        [-1.2188e+00,  1.4496e+00, -6.1818e-01],\n",
      "        [-1.0883e+00,  1.8338e+00, -8.2992e-01],\n",
      "        [-1.0607e+00,  1.6011e+00, -8.5876e-01],\n",
      "        [-1.6975e+00,  1.5476e+00, -7.6429e-02],\n",
      "        [-1.1090e+00,  1.4891e+00, -4.5939e-01],\n",
      "        [-1.0054e+00,  1.3985e+00, -9.1941e-01],\n",
      "        [ 4.0699e-01,  2.5526e-03, -1.0234e+00],\n",
      "        [-1.0878e+00,  1.7974e+00, -7.2944e-01],\n",
      "        [-2.0271e+00, -1.8129e-03,  1.6829e+00],\n",
      "        [-1.7350e+00,  8.6226e-01,  8.4085e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.3042e+00,  3.8154e-02,  1.4723e+00],\n",
      "        [-1.3766e+00,  1.6980e+00, -5.0230e-01],\n",
      "        [-1.4006e+00,  1.4478e+00, -3.7470e-01],\n",
      "        [-1.5776e+00,  4.9251e-02,  1.2136e+00],\n",
      "        [-1.8201e+00,  1.9408e-01,  1.4369e+00],\n",
      "        [ 4.2648e-01,  1.9317e-01, -9.5834e-01],\n",
      "        [-1.2188e+00,  1.4496e+00, -6.1818e-01],\n",
      "        [-1.0883e+00,  1.8338e+00, -8.2992e-01],\n",
      "        [-1.0607e+00,  1.6011e+00, -8.5876e-01],\n",
      "        [-1.6975e+00,  1.5476e+00, -7.6429e-02],\n",
      "        [-1.1090e+00,  1.4891e+00, -4.5939e-01],\n",
      "        [-1.0054e+00,  1.3985e+00, -9.1941e-01],\n",
      "        [ 4.0699e-01,  2.5526e-03, -1.0234e+00],\n",
      "        [-1.0878e+00,  1.7974e+00, -7.2944e-01],\n",
      "        [-2.0271e+00, -1.8129e-03,  1.6829e+00],\n",
      "        [-1.7350e+00,  8.6226e-01,  8.4085e-01]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9671,  0.0831,  1.2752],\n",
      "        [-0.7182, -0.1161,  0.5457],\n",
      "        [-1.3961,  1.3861, -0.2833],\n",
      "        [ 0.6834, -0.1178, -0.7958],\n",
      "        [-1.2357,  1.6892, -0.5152],\n",
      "        [-1.8306,  0.1648,  1.4271],\n",
      "        [-1.9811,  0.0641,  1.4506],\n",
      "        [-1.1176,  1.6245, -0.5046],\n",
      "        [-2.1111,  0.5011,  1.4621],\n",
      "        [-1.1038,  1.3968, -0.6593],\n",
      "        [-1.8535,  0.9896,  0.2404],\n",
      "        [-1.2898,  1.8157, -0.7248],\n",
      "        [-1.9341,  0.0955,  1.4808],\n",
      "        [-1.3634,  1.8056, -0.6491],\n",
      "        [ 0.3751, -0.2073, -0.7555],\n",
      "        [-2.0060,  0.2108,  1.6685]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9671,  0.0831,  1.2752],\n",
      "        [-0.7182, -0.1161,  0.5457],\n",
      "        [-1.3961,  1.3861, -0.2833],\n",
      "        [ 0.6834, -0.1178, -0.7958],\n",
      "        [-1.2357,  1.6892, -0.5152],\n",
      "        [-1.8306,  0.1648,  1.4271],\n",
      "        [-1.9811,  0.0641,  1.4506],\n",
      "        [-1.1176,  1.6245, -0.5046],\n",
      "        [-2.1111,  0.5011,  1.4621],\n",
      "        [-1.1038,  1.3968, -0.6593],\n",
      "        [-1.8535,  0.9896,  0.2404],\n",
      "        [-1.2898,  1.8157, -0.7248],\n",
      "        [-1.9341,  0.0955,  1.4808],\n",
      "        [-1.3634,  1.8056, -0.6491],\n",
      "        [ 0.3751, -0.2073, -0.7555],\n",
      "        [-2.0060,  0.2108,  1.6685]], grad_fn=<AddmmBackward0>)\n",
      "Epoch 2/3, Loss: 0.6025\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4193,  1.7030, -0.6536],\n",
      "        [-2.1103,  0.2947,  1.4580],\n",
      "        [-1.4710,  1.7076, -0.6102],\n",
      "        [-1.2073,  1.7804, -0.8777],\n",
      "        [-1.5131,  1.7694, -0.4873],\n",
      "        [-0.9811,  0.0109,  0.3823],\n",
      "        [-1.3377,  1.6726, -0.5325],\n",
      "        [-1.3490,  1.4266, -0.5032],\n",
      "        [-1.5182,  1.6899, -0.6127],\n",
      "        [-1.1671,  1.6608, -0.9529],\n",
      "        [-0.9427,  1.4583, -0.8423],\n",
      "        [-2.0271,  0.2098,  1.5688],\n",
      "        [-1.1574,  1.5486, -0.5985],\n",
      "        [-1.7703,  0.3657,  1.3405],\n",
      "        [-1.9578,  0.7924,  1.1799],\n",
      "        [-1.2351,  1.7214, -0.6795]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4193,  1.7030, -0.6536],\n",
      "        [-2.1103,  0.2947,  1.4580],\n",
      "        [-1.4710,  1.7076, -0.6102],\n",
      "        [-1.2073,  1.7804, -0.8777],\n",
      "        [-1.5131,  1.7694, -0.4873],\n",
      "        [-0.9811,  0.0109,  0.3823],\n",
      "        [-1.3377,  1.6726, -0.5325],\n",
      "        [-1.3490,  1.4266, -0.5032],\n",
      "        [-1.5182,  1.6899, -0.6127],\n",
      "        [-1.1671,  1.6608, -0.9529],\n",
      "        [-0.9427,  1.4583, -0.8423],\n",
      "        [-2.0271,  0.2098,  1.5688],\n",
      "        [-1.1574,  1.5486, -0.5985],\n",
      "        [-1.7703,  0.3657,  1.3405],\n",
      "        [-1.9578,  0.7924,  1.1799],\n",
      "        [-1.2351,  1.7214, -0.6795]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3215, -0.1050, -0.7276],\n",
      "        [-1.5160,  1.6485, -0.4672],\n",
      "        [-0.9540,  1.8687, -0.9279],\n",
      "        [-1.3259,  1.7395, -0.6482],\n",
      "        [-1.8902,  0.3401,  1.1044],\n",
      "        [-1.9305,  0.3032,  1.1931],\n",
      "        [-2.1630,  0.1831,  1.3141],\n",
      "        [-1.2888,  1.9189, -1.0127],\n",
      "        [-1.6834,  1.2513,  0.0231],\n",
      "        [ 0.5552, -0.0612, -0.9427],\n",
      "        [-1.2663,  1.4467, -0.4704],\n",
      "        [-1.2656,  1.7309, -0.6110],\n",
      "        [-1.1962,  1.8669, -0.7640],\n",
      "        [-1.0402, -0.0901,  0.7562],\n",
      "        [-2.1294,  0.0579,  1.4900],\n",
      "        [-1.3212,  1.7280, -0.8597]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.3215, -0.1050, -0.7276],\n",
      "        [-1.5160,  1.6485, -0.4672],\n",
      "        [-0.9540,  1.8687, -0.9279],\n",
      "        [-1.3259,  1.7395, -0.6482],\n",
      "        [-1.8902,  0.3401,  1.1044],\n",
      "        [-1.9305,  0.3032,  1.1931],\n",
      "        [-2.1630,  0.1831,  1.3141],\n",
      "        [-1.2888,  1.9189, -1.0127],\n",
      "        [-1.6834,  1.2513,  0.0231],\n",
      "        [ 0.5552, -0.0612, -0.9427],\n",
      "        [-1.2663,  1.4467, -0.4704],\n",
      "        [-1.2656,  1.7309, -0.6110],\n",
      "        [-1.1962,  1.8669, -0.7640],\n",
      "        [-1.0402, -0.0901,  0.7562],\n",
      "        [-2.1294,  0.0579,  1.4900],\n",
      "        [-1.3212,  1.7280, -0.8597]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1420,  0.6529,  1.1286],\n",
      "        [-1.2963,  1.7953, -0.6443],\n",
      "        [-1.0458,  1.7629, -0.7777],\n",
      "        [-1.8383,  1.0094,  0.5796],\n",
      "        [-1.9792,  0.3698,  1.4376],\n",
      "        [-1.3293,  1.5248, -1.0041],\n",
      "        [-0.8927, -0.0396,  0.3517],\n",
      "        [-1.4158,  1.1723,  0.0664],\n",
      "        [ 0.5724, -0.2939, -0.8349],\n",
      "        [-2.0433,  0.5499,  1.4244],\n",
      "        [-1.0249,  1.6521, -0.7574],\n",
      "        [ 0.1162,  0.5346, -1.1294],\n",
      "        [-2.0568,  0.2867,  1.4502],\n",
      "        [-1.2270,  1.8765, -0.8393],\n",
      "        [-1.0278,  1.6500, -0.8996],\n",
      "        [-1.1958,  1.8031, -0.9843]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.1420,  0.6529,  1.1286],\n",
      "        [-1.2963,  1.7953, -0.6443],\n",
      "        [-1.0458,  1.7629, -0.7777],\n",
      "        [-1.8383,  1.0094,  0.5796],\n",
      "        [-1.9792,  0.3698,  1.4376],\n",
      "        [-1.3293,  1.5248, -1.0041],\n",
      "        [-0.8927, -0.0396,  0.3517],\n",
      "        [-1.4158,  1.1723,  0.0664],\n",
      "        [ 0.5724, -0.2939, -0.8349],\n",
      "        [-2.0433,  0.5499,  1.4244],\n",
      "        [-1.0249,  1.6521, -0.7574],\n",
      "        [ 0.1162,  0.5346, -1.1294],\n",
      "        [-2.0568,  0.2867,  1.4502],\n",
      "        [-1.2270,  1.8765, -0.8393],\n",
      "        [-1.0278,  1.6500, -0.8996],\n",
      "        [-1.1958,  1.8031, -0.9843]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2858,  1.6692, -0.7251],\n",
      "        [-1.1690,  1.7031, -0.6376],\n",
      "        [-2.0482,  0.2066,  1.4962],\n",
      "        [-1.1821,  1.8519, -0.7978],\n",
      "        [-1.3911,  1.7470, -0.4273],\n",
      "        [-1.5696,  0.0825,  0.9101],\n",
      "        [-1.8945,  0.8104,  0.7467],\n",
      "        [-1.4592,  1.6309, -0.4525],\n",
      "        [-1.3435,  1.7631, -0.5904],\n",
      "        [-1.4505,  1.6917, -0.5725],\n",
      "        [-1.9390,  0.3007,  1.4243],\n",
      "        [-1.2595,  1.5524, -0.6703],\n",
      "        [-1.1367,  1.7296, -0.7673],\n",
      "        [-2.1466,  0.2510,  1.4693],\n",
      "        [ 0.7237, -0.3840, -0.7992],\n",
      "        [-1.2346,  1.4716, -0.8086]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.2858,  1.6692, -0.7251],\n",
      "        [-1.1690,  1.7031, -0.6376],\n",
      "        [-2.0482,  0.2066,  1.4962],\n",
      "        [-1.1821,  1.8519, -0.7978],\n",
      "        [-1.3911,  1.7470, -0.4273],\n",
      "        [-1.5696,  0.0825,  0.9101],\n",
      "        [-1.8945,  0.8104,  0.7467],\n",
      "        [-1.4592,  1.6309, -0.4525],\n",
      "        [-1.3435,  1.7631, -0.5904],\n",
      "        [-1.4505,  1.6917, -0.5725],\n",
      "        [-1.9390,  0.3007,  1.4243],\n",
      "        [-1.2595,  1.5524, -0.6703],\n",
      "        [-1.1367,  1.7296, -0.7673],\n",
      "        [-2.1466,  0.2510,  1.4693],\n",
      "        [ 0.7237, -0.3840, -0.7992],\n",
      "        [-1.2346,  1.4716, -0.8086]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0333,  0.3777,  1.4873],\n",
      "        [-1.4523,  1.7751, -0.4240],\n",
      "        [-2.2066,  0.4378,  1.2802],\n",
      "        [-1.9870,  0.6007,  1.0013],\n",
      "        [-1.4423,  1.5531, -0.7264],\n",
      "        [-1.3140,  1.6514, -0.7911],\n",
      "        [-1.2970,  1.7902, -0.4408],\n",
      "        [-1.3006,  1.8157, -0.8323],\n",
      "        [-1.3864,  1.5924, -0.6956],\n",
      "        [-1.3294,  1.5297, -0.4421],\n",
      "        [-2.2106,  0.3760,  1.4325],\n",
      "        [-1.3282,  1.6083, -0.3460],\n",
      "        [-1.1282,  1.8306, -0.8594],\n",
      "        [-1.2310,  1.5429, -0.6563],\n",
      "        [-1.0923,  1.6308, -1.0819],\n",
      "        [-2.1352,  0.3980,  1.4441]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.0333,  0.3777,  1.4873],\n",
      "        [-1.4523,  1.7751, -0.4240],\n",
      "        [-2.2066,  0.4378,  1.2802],\n",
      "        [-1.9870,  0.6007,  1.0013],\n",
      "        [-1.4423,  1.5531, -0.7264],\n",
      "        [-1.3140,  1.6514, -0.7911],\n",
      "        [-1.2970,  1.7902, -0.4408],\n",
      "        [-1.3006,  1.8157, -0.8323],\n",
      "        [-1.3864,  1.5924, -0.6956],\n",
      "        [-1.3294,  1.5297, -0.4421],\n",
      "        [-2.2106,  0.3760,  1.4325],\n",
      "        [-1.3282,  1.6083, -0.3460],\n",
      "        [-1.1282,  1.8306, -0.8594],\n",
      "        [-1.2310,  1.5429, -0.6563],\n",
      "        [-1.0923,  1.6308, -1.0819],\n",
      "        [-2.1352,  0.3980,  1.4441]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.6262, -0.3082, -0.8915],\n",
      "        [-1.1986,  1.7466, -1.0105],\n",
      "        [-1.4192,  1.7318, -0.7946],\n",
      "        [-1.9039,  1.0298,  0.7750],\n",
      "        [-1.1259,  1.6442, -0.8734],\n",
      "        [-2.0452,  0.3767,  1.5661],\n",
      "        [-1.9245,  1.1106,  0.5016],\n",
      "        [-1.8586,  0.5137,  1.0473],\n",
      "        [-2.0207,  0.5112,  1.4096],\n",
      "        [-2.0695,  0.3015,  1.5073],\n",
      "        [-1.8694,  0.2872,  1.2784],\n",
      "        [ 0.5435, -0.3213, -0.8238],\n",
      "        [-1.3609,  1.7283, -0.7257],\n",
      "        [-1.0696,  1.5190, -0.5513],\n",
      "        [-1.2768,  1.6888, -0.7544],\n",
      "        [-1.0964,  1.5243, -0.7460]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.6262, -0.3082, -0.8915],\n",
      "        [-1.1986,  1.7466, -1.0105],\n",
      "        [-1.4192,  1.7318, -0.7946],\n",
      "        [-1.9039,  1.0298,  0.7750],\n",
      "        [-1.1259,  1.6442, -0.8734],\n",
      "        [-2.0452,  0.3767,  1.5661],\n",
      "        [-1.9245,  1.1106,  0.5016],\n",
      "        [-1.8586,  0.5137,  1.0473],\n",
      "        [-2.0207,  0.5112,  1.4096],\n",
      "        [-2.0695,  0.3015,  1.5073],\n",
      "        [-1.8694,  0.2872,  1.2784],\n",
      "        [ 0.5435, -0.3213, -0.8238],\n",
      "        [-1.3609,  1.7283, -0.7257],\n",
      "        [-1.0696,  1.5190, -0.5513],\n",
      "        [-1.2768,  1.6888, -0.7544],\n",
      "        [-1.0964,  1.5243, -0.7460]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1373,  0.4479,  1.5177],\n",
      "        [-1.1484,  1.8409, -0.8009],\n",
      "        [-1.9507,  0.3418,  1.2717],\n",
      "        [-1.3158,  1.8213, -0.7974],\n",
      "        [ 0.6009, -0.1810, -0.6746],\n",
      "        [-1.8285,  0.4584,  1.3962],\n",
      "        [-1.9139,  0.4501,  1.0555],\n",
      "        [-2.0569,  0.3693,  1.3207],\n",
      "        [ 0.4380, -0.1808, -0.6895],\n",
      "        [-1.2788,  1.7255, -0.9043],\n",
      "        [ 0.7008, -0.3931, -0.8887],\n",
      "        [-1.5224,  1.7598, -0.1498],\n",
      "        [-1.3301,  1.8159, -0.9121],\n",
      "        [ 0.6954, -0.0645, -0.7215],\n",
      "        [-1.3147,  1.7558, -0.6399],\n",
      "        [-1.4028,  1.9153, -0.7932]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.1373,  0.4479,  1.5177],\n",
      "        [-1.1484,  1.8409, -0.8009],\n",
      "        [-1.9507,  0.3418,  1.2717],\n",
      "        [-1.3158,  1.8213, -0.7974],\n",
      "        [ 0.6009, -0.1810, -0.6746],\n",
      "        [-1.8285,  0.4584,  1.3962],\n",
      "        [-1.9139,  0.4501,  1.0555],\n",
      "        [-2.0569,  0.3693,  1.3207],\n",
      "        [ 0.4380, -0.1808, -0.6895],\n",
      "        [-1.2788,  1.7255, -0.9043],\n",
      "        [ 0.7008, -0.3931, -0.8887],\n",
      "        [-1.5224,  1.7598, -0.1498],\n",
      "        [-1.3301,  1.8159, -0.9121],\n",
      "        [ 0.6954, -0.0645, -0.7215],\n",
      "        [-1.3147,  1.7558, -0.6399],\n",
      "        [-1.4028,  1.9153, -0.7932]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.7368, -0.2514, -0.7886],\n",
      "        [-1.4682,  1.8094, -0.7191],\n",
      "        [-1.9540,  0.4839,  1.4685],\n",
      "        [ 0.5518, -0.2844, -0.9409],\n",
      "        [ 0.6507, -0.2725, -0.8077],\n",
      "        [-1.8640,  0.2733,  1.3482],\n",
      "        [-1.3363,  1.7933, -0.7910],\n",
      "        [ 0.6194, -0.1045, -0.8543],\n",
      "        [-2.1211,  0.4676,  1.3724],\n",
      "        [-1.8771,  0.3977,  1.0392],\n",
      "        [-1.4508,  1.6778, -0.6758],\n",
      "        [-1.0436,  1.5639, -0.6116],\n",
      "        [-1.1399,  1.8085, -0.6934],\n",
      "        [-1.1501,  1.7785, -0.7104],\n",
      "        [-1.3214,  1.8671, -0.8247],\n",
      "        [ 0.6447, -0.2470, -0.9796]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.7368, -0.2514, -0.7886],\n",
      "        [-1.4682,  1.8094, -0.7191],\n",
      "        [-1.9540,  0.4839,  1.4685],\n",
      "        [ 0.5518, -0.2844, -0.9409],\n",
      "        [ 0.6507, -0.2725, -0.8077],\n",
      "        [-1.8640,  0.2733,  1.3482],\n",
      "        [-1.3363,  1.7933, -0.7910],\n",
      "        [ 0.6194, -0.1045, -0.8543],\n",
      "        [-2.1211,  0.4676,  1.3724],\n",
      "        [-1.8771,  0.3977,  1.0392],\n",
      "        [-1.4508,  1.6778, -0.6758],\n",
      "        [-1.0436,  1.5639, -0.6116],\n",
      "        [-1.1399,  1.8085, -0.6934],\n",
      "        [-1.1501,  1.7785, -0.7104],\n",
      "        [-1.3214,  1.8671, -0.8247],\n",
      "        [ 0.6447, -0.2470, -0.9796]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.1604,  1.5758, -0.4697],\n",
      "        [-1.4604,  1.4518, -0.2132],\n",
      "        [-1.9131,  0.4069,  1.2456],\n",
      "        [-1.5920,  1.3860, -0.0509],\n",
      "        [-1.7651,  0.4934,  1.1461],\n",
      "        [ 0.7854, -0.3526, -0.7726],\n",
      "        [ 0.5834, -0.4536, -0.7747],\n",
      "        [-2.1661,  0.2538,  1.5007],\n",
      "        [-1.1991,  1.7350, -0.7124],\n",
      "        [-2.0541,  0.5141,  1.2024],\n",
      "        [-1.2068,  1.5147, -0.6151],\n",
      "        [-1.9579,  0.7493,  1.1367],\n",
      "        [-1.2042,  2.0086, -0.8534],\n",
      "        [-1.2655,  1.7756, -0.7067],\n",
      "        [-1.2958,  1.7068, -0.9810],\n",
      "        [-2.0214,  0.4281,  1.4194]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.1604,  1.5758, -0.4697],\n",
      "        [-1.4604,  1.4518, -0.2132],\n",
      "        [-1.9131,  0.4069,  1.2456],\n",
      "        [-1.5920,  1.3860, -0.0509],\n",
      "        [-1.7651,  0.4934,  1.1461],\n",
      "        [ 0.7854, -0.3526, -0.7726],\n",
      "        [ 0.5834, -0.4536, -0.7747],\n",
      "        [-2.1661,  0.2538,  1.5007],\n",
      "        [-1.1991,  1.7350, -0.7124],\n",
      "        [-2.0541,  0.5141,  1.2024],\n",
      "        [-1.2068,  1.5147, -0.6151],\n",
      "        [-1.9579,  0.7493,  1.1367],\n",
      "        [-1.2042,  2.0086, -0.8534],\n",
      "        [-1.2655,  1.7756, -0.7067],\n",
      "        [-1.2958,  1.7068, -0.9810],\n",
      "        [-2.0214,  0.4281,  1.4194]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2149,  1.7957, -0.6428],\n",
      "        [-1.1115,  1.6936, -0.7613],\n",
      "        [-1.8736,  0.3318,  1.3068],\n",
      "        [-2.1986,  0.4255,  1.4362],\n",
      "        [ 0.7270, -0.4412, -0.7124],\n",
      "        [-2.0109,  0.9417,  1.0271],\n",
      "        [-0.6607,  1.3085, -0.8623],\n",
      "        [-2.1528,  0.4799,  1.3860],\n",
      "        [ 0.4379, -0.2807, -0.7665],\n",
      "        [-2.0073,  0.6369,  1.1659],\n",
      "        [-1.4302,  1.6993, -0.6555],\n",
      "        [-1.4681,  1.8133, -0.5912],\n",
      "        [-1.9337,  0.4074,  1.1424],\n",
      "        [-1.2658,  1.7630, -0.8068],\n",
      "        [-1.8273,  0.4274,  1.2402],\n",
      "        [-1.3074,  1.5893, -0.7164]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.2149,  1.7957, -0.6428],\n",
      "        [-1.1115,  1.6936, -0.7613],\n",
      "        [-1.8736,  0.3318,  1.3068],\n",
      "        [-2.1986,  0.4255,  1.4362],\n",
      "        [ 0.7270, -0.4412, -0.7124],\n",
      "        [-2.0109,  0.9417,  1.0271],\n",
      "        [-0.6607,  1.3085, -0.8623],\n",
      "        [-2.1528,  0.4799,  1.3860],\n",
      "        [ 0.4379, -0.2807, -0.7665],\n",
      "        [-2.0073,  0.6369,  1.1659],\n",
      "        [-1.4302,  1.6993, -0.6555],\n",
      "        [-1.4681,  1.8133, -0.5912],\n",
      "        [-1.9337,  0.4074,  1.1424],\n",
      "        [-1.2658,  1.7630, -0.8068],\n",
      "        [-1.8273,  0.4274,  1.2402],\n",
      "        [-1.3074,  1.5893, -0.7164]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5962,  1.7650, -0.3852],\n",
      "        [-1.2774,  1.8375, -0.5346],\n",
      "        [-1.5231,  1.6467, -0.3811],\n",
      "        [-1.3662,  1.6485, -0.6822],\n",
      "        [-2.0559,  0.5550,  1.3851],\n",
      "        [ 0.6828, -0.1133, -0.9840],\n",
      "        [-1.1888,  1.6961, -0.6406],\n",
      "        [-0.7322,  0.8383, -0.5616],\n",
      "        [-2.2230,  0.5302,  1.5322],\n",
      "        [-0.8669,  1.4624, -0.7470],\n",
      "        [-1.3801,  1.7099, -0.5405],\n",
      "        [-1.9118,  0.6050,  1.3296],\n",
      "        [ 0.7982, -0.3050, -0.8577],\n",
      "        [-2.1140,  0.5621,  1.5388],\n",
      "        [-1.2846,  1.7164, -0.5174],\n",
      "        [-1.5716,  1.5798, -0.3204]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5962,  1.7650, -0.3852],\n",
      "        [-1.2774,  1.8375, -0.5346],\n",
      "        [-1.5231,  1.6467, -0.3811],\n",
      "        [-1.3662,  1.6485, -0.6822],\n",
      "        [-2.0559,  0.5550,  1.3851],\n",
      "        [ 0.6828, -0.1133, -0.9840],\n",
      "        [-1.1888,  1.6961, -0.6406],\n",
      "        [-0.7322,  0.8383, -0.5616],\n",
      "        [-2.2230,  0.5302,  1.5322],\n",
      "        [-0.8669,  1.4624, -0.7470],\n",
      "        [-1.3801,  1.7099, -0.5405],\n",
      "        [-1.9118,  0.6050,  1.3296],\n",
      "        [ 0.7982, -0.3050, -0.8577],\n",
      "        [-2.1140,  0.5621,  1.5388],\n",
      "        [-1.2846,  1.7164, -0.5174],\n",
      "        [-1.5716,  1.5798, -0.3204]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4306,  1.5204, -0.4995],\n",
      "        [-1.4420,  1.7929, -0.4948],\n",
      "        [-0.6701,  0.8398, -0.8244],\n",
      "        [-1.1726,  1.7416, -0.6725],\n",
      "        [-1.4229,  1.9781, -0.7813],\n",
      "        [-1.1424,  1.4169, -0.6506],\n",
      "        [-1.4270,  1.7264, -0.7390],\n",
      "        [-1.8998,  1.3429, -0.0032],\n",
      "        [-2.1694,  0.6026,  1.1514],\n",
      "        [-1.9698,  0.5221,  1.2609],\n",
      "        [-1.2771,  1.6531, -0.7687],\n",
      "        [-1.4095,  1.9188, -0.6695],\n",
      "        [-2.1134,  0.5665,  1.2296],\n",
      "        [-1.9726,  1.0234,  0.9855],\n",
      "        [-0.9174,  1.3142, -0.7974],\n",
      "        [ 0.7683, -0.3470, -0.9094]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4306,  1.5204, -0.4995],\n",
      "        [-1.4420,  1.7929, -0.4948],\n",
      "        [-0.6701,  0.8398, -0.8244],\n",
      "        [-1.1726,  1.7416, -0.6725],\n",
      "        [-1.4229,  1.9781, -0.7813],\n",
      "        [-1.1424,  1.4169, -0.6506],\n",
      "        [-1.4270,  1.7264, -0.7390],\n",
      "        [-1.8998,  1.3429, -0.0032],\n",
      "        [-2.1694,  0.6026,  1.1514],\n",
      "        [-1.9698,  0.5221,  1.2609],\n",
      "        [-1.2771,  1.6531, -0.7687],\n",
      "        [-1.4095,  1.9188, -0.6695],\n",
      "        [-2.1134,  0.5665,  1.2296],\n",
      "        [-1.9726,  1.0234,  0.9855],\n",
      "        [-0.9174,  1.3142, -0.7974],\n",
      "        [ 0.7683, -0.3470, -0.9094]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2190,  1.6586, -0.4684],\n",
      "        [-1.8530,  0.8523,  0.8957],\n",
      "        [-1.4466,  1.9768, -0.5814],\n",
      "        [-1.7205,  1.3339,  0.6159],\n",
      "        [-1.4669,  1.8014, -0.7907],\n",
      "        [-1.4407,  1.6794, -0.6248],\n",
      "        [-2.0567,  0.3152,  1.3019],\n",
      "        [-1.9304,  0.7957,  0.7721],\n",
      "        [-1.5539,  1.9375, -0.6063],\n",
      "        [-1.3999,  1.8069, -0.5477],\n",
      "        [-1.6090,  1.6335, -0.2621],\n",
      "        [-1.9092,  1.7136,  0.0443],\n",
      "        [-2.0392,  0.5226,  1.1931],\n",
      "        [-1.4118,  1.7887, -0.6635],\n",
      "        [-1.6925,  1.5091,  0.1001],\n",
      "        [-1.6997,  1.1364,  0.3555]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.2190,  1.6586, -0.4684],\n",
      "        [-1.8530,  0.8523,  0.8957],\n",
      "        [-1.4466,  1.9768, -0.5814],\n",
      "        [-1.7205,  1.3339,  0.6159],\n",
      "        [-1.4669,  1.8014, -0.7907],\n",
      "        [-1.4407,  1.6794, -0.6248],\n",
      "        [-2.0567,  0.3152,  1.3019],\n",
      "        [-1.9304,  0.7957,  0.7721],\n",
      "        [-1.5539,  1.9375, -0.6063],\n",
      "        [-1.3999,  1.8069, -0.5477],\n",
      "        [-1.6090,  1.6335, -0.2621],\n",
      "        [-1.9092,  1.7136,  0.0443],\n",
      "        [-2.0392,  0.5226,  1.1931],\n",
      "        [-1.4118,  1.7887, -0.6635],\n",
      "        [-1.6925,  1.5091,  0.1001],\n",
      "        [-1.6997,  1.1364,  0.3555]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2599,  1.4752, -0.5720],\n",
      "        [-1.3456,  1.6753, -0.5531],\n",
      "        [-1.2688,  1.7588, -0.7398],\n",
      "        [-1.4809,  1.8623, -0.6566],\n",
      "        [-2.0323,  0.6233,  1.1499],\n",
      "        [-1.3625,  1.8436, -0.7152],\n",
      "        [-1.2607,  1.7442, -0.6945],\n",
      "        [-1.8149,  1.6112, -0.3281],\n",
      "        [-1.3670,  1.6033, -0.6387],\n",
      "        [-1.2732,  1.7337, -0.6394],\n",
      "        [-1.4566,  1.8678, -0.5779],\n",
      "        [-1.4924,  1.8932, -0.4952],\n",
      "        [-2.3039,  0.4315,  1.3017],\n",
      "        [-1.5370,  1.4493, -0.1903],\n",
      "        [-1.6345,  1.2518, -0.0335],\n",
      "        [-1.2555,  1.7938, -0.5573]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.2599,  1.4752, -0.5720],\n",
      "        [-1.3456,  1.6753, -0.5531],\n",
      "        [-1.2688,  1.7588, -0.7398],\n",
      "        [-1.4809,  1.8623, -0.6566],\n",
      "        [-2.0323,  0.6233,  1.1499],\n",
      "        [-1.3625,  1.8436, -0.7152],\n",
      "        [-1.2607,  1.7442, -0.6945],\n",
      "        [-1.8149,  1.6112, -0.3281],\n",
      "        [-1.3670,  1.6033, -0.6387],\n",
      "        [-1.2732,  1.7337, -0.6394],\n",
      "        [-1.4566,  1.8678, -0.5779],\n",
      "        [-1.4924,  1.8932, -0.4952],\n",
      "        [-2.3039,  0.4315,  1.3017],\n",
      "        [-1.5370,  1.4493, -0.1903],\n",
      "        [-1.6345,  1.2518, -0.0335],\n",
      "        [-1.2555,  1.7938, -0.5573]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3847,  1.7516, -0.5161],\n",
      "        [-2.0285,  0.5768,  1.1857],\n",
      "        [-2.1550,  0.5645,  1.1593],\n",
      "        [-1.5296,  1.9707, -0.5775],\n",
      "        [-1.3238,  1.6970, -0.4927],\n",
      "        [-1.6580,  0.3815,  1.0555],\n",
      "        [-2.0154,  0.6318,  1.2055],\n",
      "        [ 0.1850,  0.4126, -0.9949],\n",
      "        [-1.4644,  1.6642, -0.5766],\n",
      "        [ 0.7612, -0.3464, -0.7993],\n",
      "        [-1.4476,  1.4108, -0.4335],\n",
      "        [-1.4367,  1.8615, -0.4416],\n",
      "        [-2.0104,  0.6431,  1.2234],\n",
      "        [-1.7094,  1.4407, -0.0457],\n",
      "        [-1.4057,  1.7141, -0.3004],\n",
      "        [-2.1015,  0.5759,  1.4149]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3847,  1.7516, -0.5161],\n",
      "        [-2.0285,  0.5768,  1.1857],\n",
      "        [-2.1550,  0.5645,  1.1593],\n",
      "        [-1.5296,  1.9707, -0.5775],\n",
      "        [-1.3238,  1.6970, -0.4927],\n",
      "        [-1.6580,  0.3815,  1.0555],\n",
      "        [-2.0154,  0.6318,  1.2055],\n",
      "        [ 0.1850,  0.4126, -0.9949],\n",
      "        [-1.4644,  1.6642, -0.5766],\n",
      "        [ 0.7612, -0.3464, -0.7993],\n",
      "        [-1.4476,  1.4108, -0.4335],\n",
      "        [-1.4367,  1.8615, -0.4416],\n",
      "        [-2.0104,  0.6431,  1.2234],\n",
      "        [-1.7094,  1.4407, -0.0457],\n",
      "        [-1.4057,  1.7141, -0.3004],\n",
      "        [-2.1015,  0.5759,  1.4149]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0257,  0.5464,  1.1653],\n",
      "        [ 0.6244, -0.2142, -0.9198],\n",
      "        [-2.0470,  0.5035,  1.1766],\n",
      "        [-2.2781,  0.6355,  1.3383],\n",
      "        [ 0.6991, -0.1208, -0.9891],\n",
      "        [-2.0724,  0.6600,  1.1435],\n",
      "        [ 0.7679, -0.3123, -0.9527],\n",
      "        [-2.1178,  0.5060,  1.3095],\n",
      "        [-2.0189,  0.5533,  1.2639],\n",
      "        [-1.4787,  1.8234, -0.4852],\n",
      "        [-1.4984,  1.7165, -0.3856],\n",
      "        [-1.7601,  1.4960, -0.0806],\n",
      "        [-1.9809,  0.5152,  1.1877],\n",
      "        [-1.4722,  1.9971, -0.6124],\n",
      "        [-2.0814,  0.5980,  1.1023],\n",
      "        [-1.5510,  1.8658, -0.4876]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.0257,  0.5464,  1.1653],\n",
      "        [ 0.6244, -0.2142, -0.9198],\n",
      "        [-2.0470,  0.5035,  1.1766],\n",
      "        [-2.2781,  0.6355,  1.3383],\n",
      "        [ 0.6991, -0.1208, -0.9891],\n",
      "        [-2.0724,  0.6600,  1.1435],\n",
      "        [ 0.7679, -0.3123, -0.9527],\n",
      "        [-2.1178,  0.5060,  1.3095],\n",
      "        [-2.0189,  0.5533,  1.2639],\n",
      "        [-1.4787,  1.8234, -0.4852],\n",
      "        [-1.4984,  1.7165, -0.3856],\n",
      "        [-1.7601,  1.4960, -0.0806],\n",
      "        [-1.9809,  0.5152,  1.1877],\n",
      "        [-1.4722,  1.9971, -0.6124],\n",
      "        [-2.0814,  0.5980,  1.1023],\n",
      "        [-1.5510,  1.8658, -0.4876]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5232,  1.7964, -0.5475],\n",
      "        [-1.4949,  0.2801,  1.0300],\n",
      "        [-2.1501,  0.6201,  1.2047],\n",
      "        [-2.1760,  0.3323,  1.3087],\n",
      "        [-1.9375,  1.4197,  0.5801],\n",
      "        [-1.6275,  1.7997, -0.3442],\n",
      "        [-1.4634,  1.8682, -0.2891],\n",
      "        [-1.6892,  1.7677, -0.2338],\n",
      "        [ 0.7392, -0.3949, -0.7982],\n",
      "        [-2.0941,  0.4307,  1.1244],\n",
      "        [-1.5671,  1.8430, -0.4915],\n",
      "        [-1.5453,  1.8312, -0.4098],\n",
      "        [-1.3453,  0.1008,  0.7827],\n",
      "        [-1.4684,  1.7660, -0.6294],\n",
      "        [-2.0850,  0.4072,  1.0519],\n",
      "        [-1.5939,  1.5793, -0.2857]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5232,  1.7964, -0.5475],\n",
      "        [-1.4949,  0.2801,  1.0300],\n",
      "        [-2.1501,  0.6201,  1.2047],\n",
      "        [-2.1760,  0.3323,  1.3087],\n",
      "        [-1.9375,  1.4197,  0.5801],\n",
      "        [-1.6275,  1.7997, -0.3442],\n",
      "        [-1.4634,  1.8682, -0.2891],\n",
      "        [-1.6892,  1.7677, -0.2338],\n",
      "        [ 0.7392, -0.3949, -0.7982],\n",
      "        [-2.0941,  0.4307,  1.1244],\n",
      "        [-1.5671,  1.8430, -0.4915],\n",
      "        [-1.5453,  1.8312, -0.4098],\n",
      "        [-1.3453,  0.1008,  0.7827],\n",
      "        [-1.4684,  1.7660, -0.6294],\n",
      "        [-2.0850,  0.4072,  1.0519],\n",
      "        [-1.5939,  1.5793, -0.2857]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4035,  1.5301, -0.2320],\n",
      "        [-2.1661,  0.5599,  1.2322],\n",
      "        [-1.3928,  1.7301, -0.4441],\n",
      "        [-1.6141,  1.6234, -0.3378],\n",
      "        [-1.8504,  0.8374,  0.9522],\n",
      "        [-1.9887,  1.3744,  0.3391],\n",
      "        [-1.3821,  1.6411, -0.6345],\n",
      "        [ 0.6239, -0.1661, -0.9799],\n",
      "        [-1.7109,  1.7092, -0.3920],\n",
      "        [-1.9428,  0.5054,  1.1571],\n",
      "        [ 0.5860, -0.3144, -0.9235],\n",
      "        [-1.9376,  0.5451,  0.9950],\n",
      "        [-1.4217,  1.9934, -0.5309],\n",
      "        [-1.9890,  0.5165,  1.2696],\n",
      "        [-1.8036,  0.5414,  1.2330],\n",
      "        [-1.4370,  1.7664, -0.3086]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4035,  1.5301, -0.2320],\n",
      "        [-2.1661,  0.5599,  1.2322],\n",
      "        [-1.3928,  1.7301, -0.4441],\n",
      "        [-1.6141,  1.6234, -0.3378],\n",
      "        [-1.8504,  0.8374,  0.9522],\n",
      "        [-1.9887,  1.3744,  0.3391],\n",
      "        [-1.3821,  1.6411, -0.6345],\n",
      "        [ 0.6239, -0.1661, -0.9799],\n",
      "        [-1.7109,  1.7092, -0.3920],\n",
      "        [-1.9428,  0.5054,  1.1571],\n",
      "        [ 0.5860, -0.3144, -0.9235],\n",
      "        [-1.9376,  0.5451,  0.9950],\n",
      "        [-1.4217,  1.9934, -0.5309],\n",
      "        [-1.9890,  0.5165,  1.2696],\n",
      "        [-1.8036,  0.5414,  1.2330],\n",
      "        [-1.4370,  1.7664, -0.3086]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9982,  0.5510,  0.7982],\n",
      "        [-2.2990,  0.5463,  1.2648],\n",
      "        [-2.2305,  0.4542,  1.2249],\n",
      "        [-1.8780,  0.5347,  1.1411],\n",
      "        [-1.5535,  1.8575, -0.4452],\n",
      "        [-2.0370,  1.1147,  0.6937],\n",
      "        [ 0.4160, -0.2136, -0.8507],\n",
      "        [-1.6867,  1.8394, -0.5203],\n",
      "        [-1.3267,  1.8309, -0.6165],\n",
      "        [-1.9790,  0.7889,  1.1578],\n",
      "        [-1.4836,  1.7156, -0.6211],\n",
      "        [ 0.1337, -0.1444, -0.3757],\n",
      "        [-1.5070,  1.7467, -0.4373],\n",
      "        [-1.6711,  2.1178, -0.6429],\n",
      "        [-1.9841,  0.4371,  1.2121],\n",
      "        [-1.5093,  1.5866, -0.1736]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9982,  0.5510,  0.7982],\n",
      "        [-2.2990,  0.5463,  1.2648],\n",
      "        [-2.2305,  0.4542,  1.2249],\n",
      "        [-1.8780,  0.5347,  1.1411],\n",
      "        [-1.5535,  1.8575, -0.4452],\n",
      "        [-2.0370,  1.1147,  0.6937],\n",
      "        [ 0.4160, -0.2136, -0.8507],\n",
      "        [-1.6867,  1.8394, -0.5203],\n",
      "        [-1.3267,  1.8309, -0.6165],\n",
      "        [-1.9790,  0.7889,  1.1578],\n",
      "        [-1.4836,  1.7156, -0.6211],\n",
      "        [ 0.1337, -0.1444, -0.3757],\n",
      "        [-1.5070,  1.7467, -0.4373],\n",
      "        [-1.6711,  2.1178, -0.6429],\n",
      "        [-1.9841,  0.4371,  1.2121],\n",
      "        [-1.5093,  1.5866, -0.1736]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6353,  1.7665, -0.4401],\n",
      "        [-1.5507,  1.8226, -0.4199],\n",
      "        [ 0.7607, -0.2781, -0.8645],\n",
      "        [-1.6298,  1.6324, -0.4388],\n",
      "        [-2.2566,  0.4974,  1.2185],\n",
      "        [-1.3530,  1.6484, -0.6168],\n",
      "        [-1.5299,  1.7503, -0.4802],\n",
      "        [-2.1815,  0.4250,  1.1006],\n",
      "        [-1.7228,  1.9581, -0.4734],\n",
      "        [-1.6666,  1.5606, -0.2003],\n",
      "        [-1.4292,  1.7054, -0.4896],\n",
      "        [-1.6544,  1.5933, -0.0922],\n",
      "        [-1.9450,  1.3118,  0.2705],\n",
      "        [-1.5853,  1.6825, -0.5065],\n",
      "        [ 0.6100, -0.4265, -0.9473],\n",
      "        [-2.0992,  0.5941,  1.2276]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6353,  1.7665, -0.4401],\n",
      "        [-1.5507,  1.8226, -0.4199],\n",
      "        [ 0.7607, -0.2781, -0.8645],\n",
      "        [-1.6298,  1.6324, -0.4388],\n",
      "        [-2.2566,  0.4974,  1.2185],\n",
      "        [-1.3530,  1.6484, -0.6168],\n",
      "        [-1.5299,  1.7503, -0.4802],\n",
      "        [-2.1815,  0.4250,  1.1006],\n",
      "        [-1.7228,  1.9581, -0.4734],\n",
      "        [-1.6666,  1.5606, -0.2003],\n",
      "        [-1.4292,  1.7054, -0.4896],\n",
      "        [-1.6544,  1.5933, -0.0922],\n",
      "        [-1.9450,  1.3118,  0.2705],\n",
      "        [-1.5853,  1.6825, -0.5065],\n",
      "        [ 0.6100, -0.4265, -0.9473],\n",
      "        [-2.0992,  0.5941,  1.2276]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0049,  0.7963,  0.7651],\n",
      "        [-1.4467,  1.7358, -0.3487],\n",
      "        [-2.0577,  0.4840,  1.2611],\n",
      "        [-1.6002,  1.6620, -0.2515],\n",
      "        [-2.3116,  1.0965,  0.6646],\n",
      "        [ 0.5982, -0.3555, -0.7313],\n",
      "        [-1.6300,  1.8087, -0.3446],\n",
      "        [ 0.7403, -0.4303, -0.9283],\n",
      "        [-1.4539,  0.3564,  1.0511],\n",
      "        [-1.9217,  1.6717, -0.1172],\n",
      "        [-2.1990,  0.6378,  1.0827],\n",
      "        [-1.9363,  1.8361, -0.3283],\n",
      "        [-1.5200,  1.7375, -0.4727],\n",
      "        [-1.4374,  1.7443, -0.4234],\n",
      "        [-1.8286,  0.4906,  1.3655],\n",
      "        [ 0.7879, -0.2778, -0.7374]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.0049,  0.7963,  0.7651],\n",
      "        [-1.4467,  1.7358, -0.3487],\n",
      "        [-2.0577,  0.4840,  1.2611],\n",
      "        [-1.6002,  1.6620, -0.2515],\n",
      "        [-2.3116,  1.0965,  0.6646],\n",
      "        [ 0.5982, -0.3555, -0.7313],\n",
      "        [-1.6300,  1.8087, -0.3446],\n",
      "        [ 0.7403, -0.4303, -0.9283],\n",
      "        [-1.4539,  0.3564,  1.0511],\n",
      "        [-1.9217,  1.6717, -0.1172],\n",
      "        [-2.1990,  0.6378,  1.0827],\n",
      "        [-1.9363,  1.8361, -0.3283],\n",
      "        [-1.5200,  1.7375, -0.4727],\n",
      "        [-1.4374,  1.7443, -0.4234],\n",
      "        [-1.8286,  0.4906,  1.3655],\n",
      "        [ 0.7879, -0.2778, -0.7374]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3348,  1.6955, -0.6426],\n",
      "        [-2.1782,  0.4095,  1.4813],\n",
      "        [-1.7889,  1.9434, -0.7010],\n",
      "        [-2.1253,  0.5270,  1.3665],\n",
      "        [-2.0617,  0.5395,  1.3053],\n",
      "        [ 0.3641, -0.2552, -0.5883],\n",
      "        [-1.7538,  1.7783, -0.1395],\n",
      "        [-1.5308,  2.0882, -0.5548],\n",
      "        [-1.6563,  1.8628, -0.5103],\n",
      "        [-2.0063,  0.6174,  1.2254],\n",
      "        [-1.7141,  1.8444, -0.3877],\n",
      "        [-1.6235,  1.9526, -0.4746],\n",
      "        [-1.4377,  2.0413, -0.5292],\n",
      "        [-2.1157,  0.6476,  1.2421],\n",
      "        [-1.5914,  1.9072, -0.2272],\n",
      "        [ 0.7424, -0.4646, -0.7397]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3348,  1.6955, -0.6426],\n",
      "        [-2.1782,  0.4095,  1.4813],\n",
      "        [-1.7889,  1.9434, -0.7010],\n",
      "        [-2.1253,  0.5270,  1.3665],\n",
      "        [-2.0617,  0.5395,  1.3053],\n",
      "        [ 0.3641, -0.2552, -0.5883],\n",
      "        [-1.7538,  1.7783, -0.1395],\n",
      "        [-1.5308,  2.0882, -0.5548],\n",
      "        [-1.6563,  1.8628, -0.5103],\n",
      "        [-2.0063,  0.6174,  1.2254],\n",
      "        [-1.7141,  1.8444, -0.3877],\n",
      "        [-1.6235,  1.9526, -0.4746],\n",
      "        [-1.4377,  2.0413, -0.5292],\n",
      "        [-2.1157,  0.6476,  1.2421],\n",
      "        [-1.5914,  1.9072, -0.2272],\n",
      "        [ 0.7424, -0.4646, -0.7397]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9209,  0.3994,  1.0837],\n",
      "        [-1.8986,  0.5317,  1.3431],\n",
      "        [-2.0547,  0.5178,  1.2447],\n",
      "        [-1.9609,  0.4499,  1.3386],\n",
      "        [-2.0357,  0.3478,  1.4483],\n",
      "        [-1.3217,  1.5981, -0.3376],\n",
      "        [-1.5283,  2.0152, -0.5797],\n",
      "        [-1.4904,  1.8910, -0.4873],\n",
      "        [ 0.8139, -0.3678, -0.8598],\n",
      "        [-1.8085,  0.3773,  1.2065],\n",
      "        [ 0.4708, -0.2985, -0.8941],\n",
      "        [-1.3824,  1.8495, -0.5157],\n",
      "        [-1.4312,  1.7077, -0.6363],\n",
      "        [-1.4967,  2.0657, -0.7648],\n",
      "        [-1.6317,  1.8410, -0.4164],\n",
      "        [-1.6481,  1.6758, -0.6795]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9209,  0.3994,  1.0837],\n",
      "        [-1.8986,  0.5317,  1.3431],\n",
      "        [-2.0547,  0.5178,  1.2447],\n",
      "        [-1.9609,  0.4499,  1.3386],\n",
      "        [-2.0357,  0.3478,  1.4483],\n",
      "        [-1.3217,  1.5981, -0.3376],\n",
      "        [-1.5283,  2.0152, -0.5797],\n",
      "        [-1.4904,  1.8910, -0.4873],\n",
      "        [ 0.8139, -0.3678, -0.8598],\n",
      "        [-1.8085,  0.3773,  1.2065],\n",
      "        [ 0.4708, -0.2985, -0.8941],\n",
      "        [-1.3824,  1.8495, -0.5157],\n",
      "        [-1.4312,  1.7077, -0.6363],\n",
      "        [-1.4967,  2.0657, -0.7648],\n",
      "        [-1.6317,  1.8410, -0.4164],\n",
      "        [-1.6481,  1.6758, -0.6795]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6406,  1.8667, -0.5540],\n",
      "        [-1.7728,  1.6968, -0.0740],\n",
      "        [-1.5482,  1.8713, -0.5350],\n",
      "        [-1.7828,  1.7373, -0.4733],\n",
      "        [ 0.8248, -0.5385, -0.8313],\n",
      "        [ 0.8318, -0.4196, -0.7507],\n",
      "        [-1.4980,  1.7783, -0.4447],\n",
      "        [-2.0102,  1.0859,  0.3810],\n",
      "        [-1.6357,  1.8293, -0.4278],\n",
      "        [-2.0017,  0.5931,  1.2292],\n",
      "        [ 0.6716, -0.3941, -0.8717],\n",
      "        [-1.7008,  1.8401, -0.4959],\n",
      "        [-1.7226,  1.9423, -0.2800],\n",
      "        [-2.0415,  0.8369,  1.0613],\n",
      "        [-2.0033,  0.4951,  1.1829],\n",
      "        [ 0.9046, -0.4301, -0.8284]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6406,  1.8667, -0.5540],\n",
      "        [-1.7728,  1.6968, -0.0740],\n",
      "        [-1.5482,  1.8713, -0.5350],\n",
      "        [-1.7828,  1.7373, -0.4733],\n",
      "        [ 0.8248, -0.5385, -0.8313],\n",
      "        [ 0.8318, -0.4196, -0.7507],\n",
      "        [-1.4980,  1.7783, -0.4447],\n",
      "        [-2.0102,  1.0859,  0.3810],\n",
      "        [-1.6357,  1.8293, -0.4278],\n",
      "        [-2.0017,  0.5931,  1.2292],\n",
      "        [ 0.6716, -0.3941, -0.8717],\n",
      "        [-1.7008,  1.8401, -0.4959],\n",
      "        [-1.7226,  1.9423, -0.2800],\n",
      "        [-2.0415,  0.8369,  1.0613],\n",
      "        [-2.0033,  0.4951,  1.1829],\n",
      "        [ 0.9046, -0.4301, -0.8284]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1280,  0.5124,  1.3958],\n",
      "        [-1.7193,  0.5454,  1.1164],\n",
      "        [-1.3488,  1.8400, -0.5445],\n",
      "        [-1.6318,  1.9056, -0.6012],\n",
      "        [-2.0275,  0.3063,  1.4427],\n",
      "        [-1.6281,  1.8240, -0.5082],\n",
      "        [-1.6735,  2.0090, -0.5410],\n",
      "        [-1.7515,  1.8257, -0.1750],\n",
      "        [-1.3986,  1.7672, -0.3661],\n",
      "        [-1.8031,  0.6776,  1.1159],\n",
      "        [-1.6668,  1.7992, -0.4691],\n",
      "        [-1.2817,  1.4620, -0.6506],\n",
      "        [-1.9016,  0.4141,  1.3805],\n",
      "        [-1.8265,  2.0869, -0.4075],\n",
      "        [-1.9808,  0.8842,  0.7935],\n",
      "        [-1.8327,  2.0295, -0.4630]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.1280,  0.5124,  1.3958],\n",
      "        [-1.7193,  0.5454,  1.1164],\n",
      "        [-1.3488,  1.8400, -0.5445],\n",
      "        [-1.6318,  1.9056, -0.6012],\n",
      "        [-2.0275,  0.3063,  1.4427],\n",
      "        [-1.6281,  1.8240, -0.5082],\n",
      "        [-1.6735,  2.0090, -0.5410],\n",
      "        [-1.7515,  1.8257, -0.1750],\n",
      "        [-1.3986,  1.7672, -0.3661],\n",
      "        [-1.8031,  0.6776,  1.1159],\n",
      "        [-1.6668,  1.7992, -0.4691],\n",
      "        [-1.2817,  1.4620, -0.6506],\n",
      "        [-1.9016,  0.4141,  1.3805],\n",
      "        [-1.8265,  2.0869, -0.4075],\n",
      "        [-1.9808,  0.8842,  0.7935],\n",
      "        [-1.8327,  2.0295, -0.4630]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7874,  1.3830,  0.0498],\n",
      "        [ 0.4047, -0.2431, -0.9765],\n",
      "        [-1.7210,  1.9633, -0.2111],\n",
      "        [-1.6198,  1.6743, -0.3068],\n",
      "        [-1.9882,  1.5797,  0.1463],\n",
      "        [-2.1390,  0.4389,  1.2435],\n",
      "        [-1.7798,  1.9520, -0.4399],\n",
      "        [-1.9710,  0.4381,  1.5667],\n",
      "        [-1.5503,  1.6448, -0.2935],\n",
      "        [-1.8732,  1.4965, -0.2188],\n",
      "        [-1.4797,  1.8983, -0.5149],\n",
      "        [-2.1181,  0.2965,  1.5182],\n",
      "        [-2.1021,  0.5874,  0.9489],\n",
      "        [-1.8911,  1.6599,  0.0951],\n",
      "        [-2.2136,  0.5659,  1.1935],\n",
      "        [-1.7555,  0.3767,  1.2631]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7874,  1.3830,  0.0498],\n",
      "        [ 0.4047, -0.2431, -0.9765],\n",
      "        [-1.7210,  1.9633, -0.2111],\n",
      "        [-1.6198,  1.6743, -0.3068],\n",
      "        [-1.9882,  1.5797,  0.1463],\n",
      "        [-2.1390,  0.4389,  1.2435],\n",
      "        [-1.7798,  1.9520, -0.4399],\n",
      "        [-1.9710,  0.4381,  1.5667],\n",
      "        [-1.5503,  1.6448, -0.2935],\n",
      "        [-1.8732,  1.4965, -0.2188],\n",
      "        [-1.4797,  1.8983, -0.5149],\n",
      "        [-2.1181,  0.2965,  1.5182],\n",
      "        [-2.1021,  0.5874,  0.9489],\n",
      "        [-1.8911,  1.6599,  0.0951],\n",
      "        [-2.2136,  0.5659,  1.1935],\n",
      "        [-1.7555,  0.3767,  1.2631]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1914,  0.5084,  1.3677],\n",
      "        [-2.0625,  0.3950,  1.5146],\n",
      "        [-1.7109,  1.4093, -0.0833],\n",
      "        [ 0.3316,  0.1398, -0.9050],\n",
      "        [-1.8592,  0.4371,  1.3313],\n",
      "        [-1.8304,  0.2666,  1.4956],\n",
      "        [ 0.8445, -0.3513, -0.8785],\n",
      "        [-1.8035,  1.8589, -0.4486],\n",
      "        [-0.1687, -0.1283,  0.1283],\n",
      "        [ 0.6407, -0.2998, -0.8114],\n",
      "        [-2.0180,  0.3078,  1.2598],\n",
      "        [ 0.5512, -0.1733, -1.0634],\n",
      "        [-2.0638,  0.2603,  1.4454],\n",
      "        [-1.6051,  2.0727, -0.3716],\n",
      "        [-1.5851,  1.8884, -0.4867],\n",
      "        [-1.7221,  1.8726, -0.5154]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.1914,  0.5084,  1.3677],\n",
      "        [-2.0625,  0.3950,  1.5146],\n",
      "        [-1.7109,  1.4093, -0.0833],\n",
      "        [ 0.3316,  0.1398, -0.9050],\n",
      "        [-1.8592,  0.4371,  1.3313],\n",
      "        [-1.8304,  0.2666,  1.4956],\n",
      "        [ 0.8445, -0.3513, -0.8785],\n",
      "        [-1.8035,  1.8589, -0.4486],\n",
      "        [-0.1687, -0.1283,  0.1283],\n",
      "        [ 0.6407, -0.2998, -0.8114],\n",
      "        [-2.0180,  0.3078,  1.2598],\n",
      "        [ 0.5512, -0.1733, -1.0634],\n",
      "        [-2.0638,  0.2603,  1.4454],\n",
      "        [-1.6051,  2.0727, -0.3716],\n",
      "        [-1.5851,  1.8884, -0.4867],\n",
      "        [-1.7221,  1.8726, -0.5154]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7772,  2.0640, -0.5544],\n",
      "        [-1.7567,  1.9473, -0.5679],\n",
      "        [-1.5423,  1.9160, -0.3641],\n",
      "        [-1.9348,  0.5442,  1.3224],\n",
      "        [-1.6199,  2.0379, -0.3023],\n",
      "        [ 0.6684,  0.0254, -1.0011],\n",
      "        [-1.7635,  2.0837, -0.5067],\n",
      "        [-1.8426,  0.1808,  1.3160],\n",
      "        [-1.8242,  0.6990,  1.0519],\n",
      "        [-1.9006,  2.0865, -0.2842],\n",
      "        [-1.9321,  0.5630,  1.2927],\n",
      "        [-1.7311,  2.0127, -0.2915],\n",
      "        [-1.6225,  1.7671, -0.4068],\n",
      "        [-1.5777,  2.1289, -0.3603],\n",
      "        [-1.6882,  1.8044, -0.3337],\n",
      "        [ 0.4608, -0.3555, -0.6026]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7772,  2.0640, -0.5544],\n",
      "        [-1.7567,  1.9473, -0.5679],\n",
      "        [-1.5423,  1.9160, -0.3641],\n",
      "        [-1.9348,  0.5442,  1.3224],\n",
      "        [-1.6199,  2.0379, -0.3023],\n",
      "        [ 0.6684,  0.0254, -1.0011],\n",
      "        [-1.7635,  2.0837, -0.5067],\n",
      "        [-1.8426,  0.1808,  1.3160],\n",
      "        [-1.8242,  0.6990,  1.0519],\n",
      "        [-1.9006,  2.0865, -0.2842],\n",
      "        [-1.9321,  0.5630,  1.2927],\n",
      "        [-1.7311,  2.0127, -0.2915],\n",
      "        [-1.6225,  1.7671, -0.4068],\n",
      "        [-1.5777,  2.1289, -0.3603],\n",
      "        [-1.6882,  1.8044, -0.3337],\n",
      "        [ 0.4608, -0.3555, -0.6026]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.6244, -0.1774, -0.8937],\n",
      "        [-1.9826,  2.1356, -0.3225],\n",
      "        [-2.2187,  0.1773,  1.5474],\n",
      "        [-1.8816,  2.1149, -0.3247],\n",
      "        [-2.0344,  0.1676,  1.5429],\n",
      "        [-1.7091,  1.8208, -0.1792],\n",
      "        [-1.6824,  1.7704, -0.3983],\n",
      "        [-1.5655,  2.0067, -0.5756],\n",
      "        [-1.9351,  1.8454, -0.4566],\n",
      "        [-2.0385,  1.3831,  0.7049],\n",
      "        [ 0.6985, -0.4913, -0.8027],\n",
      "        [-1.5495,  1.9689, -0.2983],\n",
      "        [ 0.7599, -0.4211, -0.8321],\n",
      "        [-1.5788,  1.6670, -0.2578],\n",
      "        [-1.6949,  2.0380, -0.4498],\n",
      "        [-1.9654,  0.6517,  1.0845]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.6244, -0.1774, -0.8937],\n",
      "        [-1.9826,  2.1356, -0.3225],\n",
      "        [-2.2187,  0.1773,  1.5474],\n",
      "        [-1.8816,  2.1149, -0.3247],\n",
      "        [-2.0344,  0.1676,  1.5429],\n",
      "        [-1.7091,  1.8208, -0.1792],\n",
      "        [-1.6824,  1.7704, -0.3983],\n",
      "        [-1.5655,  2.0067, -0.5756],\n",
      "        [-1.9351,  1.8454, -0.4566],\n",
      "        [-2.0385,  1.3831,  0.7049],\n",
      "        [ 0.6985, -0.4913, -0.8027],\n",
      "        [-1.5495,  1.9689, -0.2983],\n",
      "        [ 0.7599, -0.4211, -0.8321],\n",
      "        [-1.5788,  1.6670, -0.2578],\n",
      "        [-1.6949,  2.0380, -0.4498],\n",
      "        [-1.9654,  0.6517,  1.0845]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7200,  2.1053, -0.2825],\n",
      "        [-1.8228,  1.7430, -0.5257],\n",
      "        [-1.4976,  1.9513, -0.5484],\n",
      "        [-1.7445,  2.0053, -0.4266],\n",
      "        [-1.6163,  1.8199, -0.3533],\n",
      "        [-1.5579,  1.8206, -0.5471],\n",
      "        [-2.0813,  0.3655,  1.5532],\n",
      "        [ 0.7516, -0.4143, -0.6572],\n",
      "        [-1.7220,  2.0153, -0.5127],\n",
      "        [-1.7071,  2.0916, -0.4352],\n",
      "        [-1.6354,  1.9024, -0.4700],\n",
      "        [-1.8972,  0.2745,  1.5167],\n",
      "        [-1.9756,  0.2248,  1.2911],\n",
      "        [-1.8730,  0.2625,  1.3161],\n",
      "        [-1.7216,  1.8327, -0.6388],\n",
      "        [ 0.3768, -0.2587, -0.8132]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7200,  2.1053, -0.2825],\n",
      "        [-1.8228,  1.7430, -0.5257],\n",
      "        [-1.4976,  1.9513, -0.5484],\n",
      "        [-1.7445,  2.0053, -0.4266],\n",
      "        [-1.6163,  1.8199, -0.3533],\n",
      "        [-1.5579,  1.8206, -0.5471],\n",
      "        [-2.0813,  0.3655,  1.5532],\n",
      "        [ 0.7516, -0.4143, -0.6572],\n",
      "        [-1.7220,  2.0153, -0.5127],\n",
      "        [-1.7071,  2.0916, -0.4352],\n",
      "        [-1.6354,  1.9024, -0.4700],\n",
      "        [-1.8972,  0.2745,  1.5167],\n",
      "        [-1.9756,  0.2248,  1.2911],\n",
      "        [-1.8730,  0.2625,  1.3161],\n",
      "        [-1.7216,  1.8327, -0.6388],\n",
      "        [ 0.3768, -0.2587, -0.8132]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8278,  2.0601, -0.5359],\n",
      "        [-1.8051,  1.7011, -0.1385],\n",
      "        [-1.7040,  1.8830, -0.4955],\n",
      "        [-2.1157,  0.4763,  1.3954],\n",
      "        [-1.5760,  1.9123, -0.4323],\n",
      "        [-1.7739,  1.9384, -0.4221],\n",
      "        [-1.7854,  1.9622, -0.2602],\n",
      "        [-1.5010,  1.9844, -0.6671],\n",
      "        [-1.9157,  2.0248, -0.5622],\n",
      "        [ 0.3934, -0.1047, -0.8455],\n",
      "        [-1.8002,  0.0874,  1.4221],\n",
      "        [-1.7056,  1.9484, -0.5149],\n",
      "        [ 0.3950, -0.2307, -0.7454],\n",
      "        [-1.9017,  1.8628, -0.4446],\n",
      "        [-1.7275,  1.9212, -0.2929],\n",
      "        [ 0.6993, -0.3744, -0.7534]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8278,  2.0601, -0.5359],\n",
      "        [-1.8051,  1.7011, -0.1385],\n",
      "        [-1.7040,  1.8830, -0.4955],\n",
      "        [-2.1157,  0.4763,  1.3954],\n",
      "        [-1.5760,  1.9123, -0.4323],\n",
      "        [-1.7739,  1.9384, -0.4221],\n",
      "        [-1.7854,  1.9622, -0.2602],\n",
      "        [-1.5010,  1.9844, -0.6671],\n",
      "        [-1.9157,  2.0248, -0.5622],\n",
      "        [ 0.3934, -0.1047, -0.8455],\n",
      "        [-1.8002,  0.0874,  1.4221],\n",
      "        [-1.7056,  1.9484, -0.5149],\n",
      "        [ 0.3950, -0.2307, -0.7454],\n",
      "        [-1.9017,  1.8628, -0.4446],\n",
      "        [-1.7275,  1.9212, -0.2929],\n",
      "        [ 0.6993, -0.3744, -0.7534]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5847,  1.7640, -0.4502],\n",
      "        [-1.9071,  0.3479,  1.3520],\n",
      "        [-1.8215,  2.0813, -0.2957],\n",
      "        [-1.5355,  2.0370, -0.5476],\n",
      "        [-1.7685,  1.9947, -0.3459],\n",
      "        [-1.8164,  1.8916, -0.3688],\n",
      "        [-2.0550,  0.0895,  1.3609],\n",
      "        [-1.8006,  1.3332,  0.2649],\n",
      "        [-1.8937,  2.1801, -0.3695],\n",
      "        [-1.2686,  1.3187, -0.2085],\n",
      "        [-1.7404,  2.0376, -0.3996],\n",
      "        [-1.7048,  1.9540, -0.4213],\n",
      "        [-2.1909,  0.3512,  1.7142],\n",
      "        [-1.8448,  2.0232, -0.3212],\n",
      "        [-1.7126,  2.1231, -0.4284],\n",
      "        [-1.7621,  1.9207, -0.4148]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5847,  1.7640, -0.4502],\n",
      "        [-1.9071,  0.3479,  1.3520],\n",
      "        [-1.8215,  2.0813, -0.2957],\n",
      "        [-1.5355,  2.0370, -0.5476],\n",
      "        [-1.7685,  1.9947, -0.3459],\n",
      "        [-1.8164,  1.8916, -0.3688],\n",
      "        [-2.0550,  0.0895,  1.3609],\n",
      "        [-1.8006,  1.3332,  0.2649],\n",
      "        [-1.8937,  2.1801, -0.3695],\n",
      "        [-1.2686,  1.3187, -0.2085],\n",
      "        [-1.7404,  2.0376, -0.3996],\n",
      "        [-1.7048,  1.9540, -0.4213],\n",
      "        [-2.1909,  0.3512,  1.7142],\n",
      "        [-1.8448,  2.0232, -0.3212],\n",
      "        [-1.7126,  2.1231, -0.4284],\n",
      "        [-1.7621,  1.9207, -0.4148]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9186,  0.2574,  1.4176],\n",
      "        [-1.8974,  0.1097,  1.5442],\n",
      "        [-1.5781,  1.7488, -0.4264],\n",
      "        [-1.8392,  2.0683, -0.5190],\n",
      "        [-1.7877,  2.0661, -0.6208],\n",
      "        [ 0.6743, -0.3073, -0.7801],\n",
      "        [-1.8219,  1.9188, -0.5094],\n",
      "        [-1.5631,  1.7787, -0.3773],\n",
      "        [-1.7562,  1.9828, -0.2961],\n",
      "        [-1.7402,  0.1082,  1.4247],\n",
      "        [-1.8195,  1.9928, -0.2140],\n",
      "        [-2.0146,  0.3431,  1.5188],\n",
      "        [-1.7388,  2.1065, -0.4431],\n",
      "        [-1.7144,  1.9813, -0.3261],\n",
      "        [-1.7174,  1.6245, -0.1371],\n",
      "        [-1.7476,  0.3184,  1.2421]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9186,  0.2574,  1.4176],\n",
      "        [-1.8974,  0.1097,  1.5442],\n",
      "        [-1.5781,  1.7488, -0.4264],\n",
      "        [-1.8392,  2.0683, -0.5190],\n",
      "        [-1.7877,  2.0661, -0.6208],\n",
      "        [ 0.6743, -0.3073, -0.7801],\n",
      "        [-1.8219,  1.9188, -0.5094],\n",
      "        [-1.5631,  1.7787, -0.3773],\n",
      "        [-1.7562,  1.9828, -0.2961],\n",
      "        [-1.7402,  0.1082,  1.4247],\n",
      "        [-1.8195,  1.9928, -0.2140],\n",
      "        [-2.0146,  0.3431,  1.5188],\n",
      "        [-1.7388,  2.1065, -0.4431],\n",
      "        [-1.7144,  1.9813, -0.3261],\n",
      "        [-1.7174,  1.6245, -0.1371],\n",
      "        [-1.7476,  0.3184,  1.2421]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5704, -0.3328, -0.6943],\n",
      "        [-1.9281,  0.3699,  1.3292],\n",
      "        [-1.7607,  0.1924,  1.1065],\n",
      "        [-0.5921,  1.1009, -1.0372],\n",
      "        [-1.9193,  0.2616,  1.5664],\n",
      "        [-1.9566,  0.2193,  1.3815],\n",
      "        [ 0.5289, -0.3962, -0.8371],\n",
      "        [-2.0668,  0.3114,  1.2892],\n",
      "        [-0.0749, -0.1925, -0.2281],\n",
      "        [-1.6824,  2.0281, -0.4394],\n",
      "        [-1.8515,  0.1497,  1.4560],\n",
      "        [-1.8262,  1.6851, -0.1404],\n",
      "        [-1.8116,  2.0586, -0.2431],\n",
      "        [-1.4792,  1.9161, -0.4992],\n",
      "        [-1.7867,  0.2142,  1.3349],\n",
      "        [-1.9693,  0.0687,  1.2284]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.5704, -0.3328, -0.6943],\n",
      "        [-1.9281,  0.3699,  1.3292],\n",
      "        [-1.7607,  0.1924,  1.1065],\n",
      "        [-0.5921,  1.1009, -1.0372],\n",
      "        [-1.9193,  0.2616,  1.5664],\n",
      "        [-1.9566,  0.2193,  1.3815],\n",
      "        [ 0.5289, -0.3962, -0.8371],\n",
      "        [-2.0668,  0.3114,  1.2892],\n",
      "        [-0.0749, -0.1925, -0.2281],\n",
      "        [-1.6824,  2.0281, -0.4394],\n",
      "        [-1.8515,  0.1497,  1.4560],\n",
      "        [-1.8262,  1.6851, -0.1404],\n",
      "        [-1.8116,  2.0586, -0.2431],\n",
      "        [-1.4792,  1.9161, -0.4992],\n",
      "        [-1.7867,  0.2142,  1.3349],\n",
      "        [-1.9693,  0.0687,  1.2284]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0860,  1.3141,  0.7167],\n",
      "        [-2.0381,  1.8258, -0.0391],\n",
      "        [-1.6240,  1.8675, -0.4273],\n",
      "        [-1.6539,  1.7705, -0.4562],\n",
      "        [-1.8660,  0.3671,  1.1213],\n",
      "        [-1.5852,  1.8608, -0.4807],\n",
      "        [-1.8636,  2.0071, -0.1424],\n",
      "        [-1.7810,  1.8698, -0.4626],\n",
      "        [-1.6223,  2.0465, -0.6581],\n",
      "        [-1.8972,  0.4639,  1.5095],\n",
      "        [ 0.7311, -0.4260, -0.7428],\n",
      "        [-1.6642,  1.9891, -0.6145],\n",
      "        [-1.7362,  0.2510,  1.2961],\n",
      "        [-1.7171,  1.9493, -0.4033],\n",
      "        [-1.5660,  1.7689, -0.4048],\n",
      "        [-1.7601,  1.6284, -0.2655]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.0860,  1.3141,  0.7167],\n",
      "        [-2.0381,  1.8258, -0.0391],\n",
      "        [-1.6240,  1.8675, -0.4273],\n",
      "        [-1.6539,  1.7705, -0.4562],\n",
      "        [-1.8660,  0.3671,  1.1213],\n",
      "        [-1.5852,  1.8608, -0.4807],\n",
      "        [-1.8636,  2.0071, -0.1424],\n",
      "        [-1.7810,  1.8698, -0.4626],\n",
      "        [-1.6223,  2.0465, -0.6581],\n",
      "        [-1.8972,  0.4639,  1.5095],\n",
      "        [ 0.7311, -0.4260, -0.7428],\n",
      "        [-1.6642,  1.9891, -0.6145],\n",
      "        [-1.7362,  0.2510,  1.2961],\n",
      "        [-1.7171,  1.9493, -0.4033],\n",
      "        [-1.5660,  1.7689, -0.4048],\n",
      "        [-1.7601,  1.6284, -0.2655]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8199,  0.3822,  1.2776],\n",
      "        [-1.5390,  1.7917, -0.5264],\n",
      "        [-1.9156,  0.3068,  1.3451],\n",
      "        [-1.8280,  1.9841, -0.5177],\n",
      "        [-1.8512,  0.4016,  1.2880],\n",
      "        [-1.5528,  2.0575, -0.5039],\n",
      "        [-1.6546,  2.0537, -0.7152],\n",
      "        [-1.9283,  0.4279,  1.3940],\n",
      "        [-1.7788,  1.8817, -0.3454],\n",
      "        [-1.7706,  1.8674, -0.4783],\n",
      "        [-2.1220,  0.5930,  1.1646],\n",
      "        [-1.8139,  1.9901, -0.2620],\n",
      "        [-1.7798,  0.3212,  1.3207],\n",
      "        [-1.9965,  0.5315,  1.4303],\n",
      "        [-1.5932,  1.9364, -0.4399],\n",
      "        [-1.6544,  1.8425, -0.4065]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8199,  0.3822,  1.2776],\n",
      "        [-1.5390,  1.7917, -0.5264],\n",
      "        [-1.9156,  0.3068,  1.3451],\n",
      "        [-1.8280,  1.9841, -0.5177],\n",
      "        [-1.8512,  0.4016,  1.2880],\n",
      "        [-1.5528,  2.0575, -0.5039],\n",
      "        [-1.6546,  2.0537, -0.7152],\n",
      "        [-1.9283,  0.4279,  1.3940],\n",
      "        [-1.7788,  1.8817, -0.3454],\n",
      "        [-1.7706,  1.8674, -0.4783],\n",
      "        [-2.1220,  0.5930,  1.1646],\n",
      "        [-1.8139,  1.9901, -0.2620],\n",
      "        [-1.7798,  0.3212,  1.3207],\n",
      "        [-1.9965,  0.5315,  1.4303],\n",
      "        [-1.5932,  1.9364, -0.4399],\n",
      "        [-1.6544,  1.8425, -0.4065]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5514,  1.7810, -0.3237],\n",
      "        [-1.6858,  1.9327, -0.4579],\n",
      "        [-1.6774,  2.0548, -0.4737],\n",
      "        [-1.7164,  1.8876, -0.5156],\n",
      "        [-1.8277,  0.3859,  1.3495],\n",
      "        [ 0.3942,  0.0201, -1.1379],\n",
      "        [-1.5835,  1.9065, -0.4923],\n",
      "        [-1.8262,  0.3353,  1.4903],\n",
      "        [-1.4625,  1.5044, -0.2503],\n",
      "        [-1.5234,  1.7533, -0.3024],\n",
      "        [-1.8506,  1.9012, -0.1037],\n",
      "        [-1.6675,  1.7196, -0.4873],\n",
      "        [-1.6990,  2.0454, -0.3579],\n",
      "        [-2.0034,  0.5382,  1.2115],\n",
      "        [-1.7657,  1.4260, -0.3912],\n",
      "        [-1.4803,  1.7424, -0.3896]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5514,  1.7810, -0.3237],\n",
      "        [-1.6858,  1.9327, -0.4579],\n",
      "        [-1.6774,  2.0548, -0.4737],\n",
      "        [-1.7164,  1.8876, -0.5156],\n",
      "        [-1.8277,  0.3859,  1.3495],\n",
      "        [ 0.3942,  0.0201, -1.1379],\n",
      "        [-1.5835,  1.9065, -0.4923],\n",
      "        [-1.8262,  0.3353,  1.4903],\n",
      "        [-1.4625,  1.5044, -0.2503],\n",
      "        [-1.5234,  1.7533, -0.3024],\n",
      "        [-1.8506,  1.9012, -0.1037],\n",
      "        [-1.6675,  1.7196, -0.4873],\n",
      "        [-1.6990,  2.0454, -0.3579],\n",
      "        [-2.0034,  0.5382,  1.2115],\n",
      "        [-1.7657,  1.4260, -0.3912],\n",
      "        [-1.4803,  1.7424, -0.3896]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6612,  1.8865, -0.4084],\n",
      "        [-1.6985,  1.8803, -0.2423],\n",
      "        [-2.1013,  1.0445,  0.7445],\n",
      "        [-1.7314,  2.0948, -0.5667],\n",
      "        [-1.7128,  0.4799,  1.3220],\n",
      "        [ 0.1025,  0.4923, -1.0277],\n",
      "        [-1.6155,  1.6099, -0.2899],\n",
      "        [-1.6524,  1.9676, -0.4198],\n",
      "        [-1.7581,  2.0037, -0.5390],\n",
      "        [-1.6403,  1.7646, -0.3182],\n",
      "        [-1.8065,  1.7631, -0.3548],\n",
      "        [-1.8500,  1.9595, -0.4595],\n",
      "        [-0.3361,  0.9178, -0.9599],\n",
      "        [-1.4714,  1.9567, -0.6257],\n",
      "        [-1.9631,  0.4512,  1.2557],\n",
      "        [-1.1757,  0.0823,  1.0122]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6612,  1.8865, -0.4084],\n",
      "        [-1.6985,  1.8803, -0.2423],\n",
      "        [-2.1013,  1.0445,  0.7445],\n",
      "        [-1.7314,  2.0948, -0.5667],\n",
      "        [-1.7128,  0.4799,  1.3220],\n",
      "        [ 0.1025,  0.4923, -1.0277],\n",
      "        [-1.6155,  1.6099, -0.2899],\n",
      "        [-1.6524,  1.9676, -0.4198],\n",
      "        [-1.7581,  2.0037, -0.5390],\n",
      "        [-1.6403,  1.7646, -0.3182],\n",
      "        [-1.8065,  1.7631, -0.3548],\n",
      "        [-1.8500,  1.9595, -0.4595],\n",
      "        [-0.3361,  0.9178, -0.9599],\n",
      "        [-1.4714,  1.9567, -0.6257],\n",
      "        [-1.9631,  0.4512,  1.2557],\n",
      "        [-1.1757,  0.0823,  1.0122]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4349e+00,  1.7506e+00, -2.7144e-01],\n",
      "        [-2.0397e+00,  5.9577e-01,  1.2960e+00],\n",
      "        [-1.7220e+00,  1.8245e+00, -2.6808e-01],\n",
      "        [-1.5946e+00,  1.8844e+00, -2.8326e-01],\n",
      "        [-1.6721e+00,  1.8843e+00, -4.1333e-01],\n",
      "        [ 6.2858e-01, -3.6403e-01, -8.3379e-01],\n",
      "        [-1.8233e+00,  3.8058e-01,  1.0640e+00],\n",
      "        [-1.6307e+00,  1.6612e+00, -4.5697e-01],\n",
      "        [ 6.4083e-01, -1.6829e-01, -8.5690e-01],\n",
      "        [-1.7498e+00,  1.6035e+00,  5.5818e-04],\n",
      "        [-1.7939e+00,  3.9197e-01,  1.1163e+00],\n",
      "        [-2.6458e-01, -2.3657e-01,  4.5358e-03],\n",
      "        [-2.1880e+00,  1.0367e+00,  6.0173e-01],\n",
      "        [-1.2593e+00,  1.0565e+00, -2.3042e-01],\n",
      "        [-1.8768e+00,  2.0021e+00, -5.0798e-01],\n",
      "        [-2.1312e+00,  5.7647e-01,  1.3473e+00]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4349e+00,  1.7506e+00, -2.7144e-01],\n",
      "        [-2.0397e+00,  5.9577e-01,  1.2960e+00],\n",
      "        [-1.7220e+00,  1.8245e+00, -2.6808e-01],\n",
      "        [-1.5946e+00,  1.8844e+00, -2.8326e-01],\n",
      "        [-1.6721e+00,  1.8843e+00, -4.1333e-01],\n",
      "        [ 6.2858e-01, -3.6403e-01, -8.3379e-01],\n",
      "        [-1.8233e+00,  3.8058e-01,  1.0640e+00],\n",
      "        [-1.6307e+00,  1.6612e+00, -4.5697e-01],\n",
      "        [ 6.4083e-01, -1.6829e-01, -8.5690e-01],\n",
      "        [-1.7498e+00,  1.6035e+00,  5.5818e-04],\n",
      "        [-1.7939e+00,  3.9197e-01,  1.1163e+00],\n",
      "        [-2.6458e-01, -2.3657e-01,  4.5358e-03],\n",
      "        [-2.1880e+00,  1.0367e+00,  6.0173e-01],\n",
      "        [-1.2593e+00,  1.0565e+00, -2.3042e-01],\n",
      "        [-1.8768e+00,  2.0021e+00, -5.0798e-01],\n",
      "        [-2.1312e+00,  5.7647e-01,  1.3473e+00]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9318,  0.4461,  1.5011],\n",
      "        [-1.5309,  1.8706, -0.2954],\n",
      "        [-1.9473,  0.3233,  0.9567],\n",
      "        [-1.6929,  1.5563, -0.2980],\n",
      "        [-1.7846,  0.8876,  0.6146],\n",
      "        [ 0.6336, -0.2969, -0.7195],\n",
      "        [-0.1847,  0.0909, -0.2780],\n",
      "        [-1.3790,  1.6249, -0.6997],\n",
      "        [-1.5929,  1.9102, -0.5617],\n",
      "        [-1.6567,  1.9890, -0.2723],\n",
      "        [-1.8597,  1.8970,  0.0468],\n",
      "        [ 0.7300, -0.4344, -0.8166],\n",
      "        [-1.5871,  1.6681, -0.4566],\n",
      "        [-1.9420,  1.9571, -0.2903],\n",
      "        [-1.4514,  1.7650, -0.4473],\n",
      "        [-1.7827,  1.9673, -0.5086]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9318,  0.4461,  1.5011],\n",
      "        [-1.5309,  1.8706, -0.2954],\n",
      "        [-1.9473,  0.3233,  0.9567],\n",
      "        [-1.6929,  1.5563, -0.2980],\n",
      "        [-1.7846,  0.8876,  0.6146],\n",
      "        [ 0.6336, -0.2969, -0.7195],\n",
      "        [-0.1847,  0.0909, -0.2780],\n",
      "        [-1.3790,  1.6249, -0.6997],\n",
      "        [-1.5929,  1.9102, -0.5617],\n",
      "        [-1.6567,  1.9890, -0.2723],\n",
      "        [-1.8597,  1.8970,  0.0468],\n",
      "        [ 0.7300, -0.4344, -0.8166],\n",
      "        [-1.5871,  1.6681, -0.4566],\n",
      "        [-1.9420,  1.9571, -0.2903],\n",
      "        [-1.4514,  1.7650, -0.4473],\n",
      "        [-1.7827,  1.9673, -0.5086]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6808,  1.8377, -0.2857],\n",
      "        [ 0.4948, -0.3155, -0.8937],\n",
      "        [-1.8199,  1.9609, -0.1825],\n",
      "        [ 0.1908,  0.4005, -1.1673],\n",
      "        [-1.8100,  0.4624,  1.1128],\n",
      "        [-1.5951,  1.8130, -0.4154],\n",
      "        [-1.3356,  1.9255, -0.4149],\n",
      "        [-1.8264,  1.2003,  0.4749],\n",
      "        [-1.8942,  0.5149,  1.2509],\n",
      "        [-1.7755,  1.7964, -0.1060],\n",
      "        [-1.9382,  0.5967,  1.2037],\n",
      "        [-1.5276,  1.9418, -0.4981],\n",
      "        [-1.6276,  1.5943, -0.4725],\n",
      "        [-1.8572,  1.9237, -0.1621],\n",
      "        [-1.9186,  0.3889,  1.2105],\n",
      "        [-1.1996,  1.5869, -0.6414]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6808,  1.8377, -0.2857],\n",
      "        [ 0.4948, -0.3155, -0.8937],\n",
      "        [-1.8199,  1.9609, -0.1825],\n",
      "        [ 0.1908,  0.4005, -1.1673],\n",
      "        [-1.8100,  0.4624,  1.1128],\n",
      "        [-1.5951,  1.8130, -0.4154],\n",
      "        [-1.3356,  1.9255, -0.4149],\n",
      "        [-1.8264,  1.2003,  0.4749],\n",
      "        [-1.8942,  0.5149,  1.2509],\n",
      "        [-1.7755,  1.7964, -0.1060],\n",
      "        [-1.9382,  0.5967,  1.2037],\n",
      "        [-1.5276,  1.9418, -0.4981],\n",
      "        [-1.6276,  1.5943, -0.4725],\n",
      "        [-1.8572,  1.9237, -0.1621],\n",
      "        [-1.9186,  0.3889,  1.2105],\n",
      "        [-1.1996,  1.5869, -0.6414]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9132,  0.5224,  1.1151],\n",
      "        [-1.6913,  1.7883, -0.3674],\n",
      "        [-1.6099,  1.9169, -0.4747],\n",
      "        [-1.7291,  0.4365,  1.1320],\n",
      "        [-1.6515,  1.9381, -0.2421],\n",
      "        [-1.5405,  1.8702, -0.3196],\n",
      "        [ 0.6404, -0.1465, -1.0495],\n",
      "        [-2.2375,  0.8080,  0.9239],\n",
      "        [ 0.0680,  0.3771, -1.0868],\n",
      "        [-1.6456,  1.8424, -0.3791],\n",
      "        [-1.8056,  0.6629,  1.1853],\n",
      "        [-1.5666,  1.7533, -0.4090],\n",
      "        [-1.6741,  1.9242, -0.1690],\n",
      "        [ 0.6957, -0.2122, -0.8684],\n",
      "        [-0.2868,  0.7828, -1.0843],\n",
      "        [-1.6127,  1.6573, -0.3695]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9132,  0.5224,  1.1151],\n",
      "        [-1.6913,  1.7883, -0.3674],\n",
      "        [-1.6099,  1.9169, -0.4747],\n",
      "        [-1.7291,  0.4365,  1.1320],\n",
      "        [-1.6515,  1.9381, -0.2421],\n",
      "        [-1.5405,  1.8702, -0.3196],\n",
      "        [ 0.6404, -0.1465, -1.0495],\n",
      "        [-2.2375,  0.8080,  0.9239],\n",
      "        [ 0.0680,  0.3771, -1.0868],\n",
      "        [-1.6456,  1.8424, -0.3791],\n",
      "        [-1.8056,  0.6629,  1.1853],\n",
      "        [-1.5666,  1.7533, -0.4090],\n",
      "        [-1.6741,  1.9242, -0.1690],\n",
      "        [ 0.6957, -0.2122, -0.8684],\n",
      "        [-0.2868,  0.7828, -1.0843],\n",
      "        [-1.6127,  1.6573, -0.3695]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8414,  1.9981, -0.5238],\n",
      "        [-2.0437,  0.5741,  1.1347],\n",
      "        [-1.7305,  1.5719, -0.2109],\n",
      "        [-1.8016,  1.8491, -0.2870],\n",
      "        [-1.9364,  0.5786,  1.2609],\n",
      "        [ 0.7014, -0.3250, -0.8755],\n",
      "        [-1.5959,  1.6687, -0.4181],\n",
      "        [-1.6542,  1.7587, -0.1969],\n",
      "        [ 0.2341,  0.4500, -1.0398],\n",
      "        [-1.5708,  1.7218, -0.3547],\n",
      "        [-1.5997,  0.4809,  0.9966],\n",
      "        [-0.5918,  1.1108, -0.8138],\n",
      "        [-1.3145,  1.7891, -0.9156],\n",
      "        [-1.8129,  1.6749, -0.1850],\n",
      "        [-1.9259,  1.8596, -0.3740],\n",
      "        [-1.7846,  1.7778, -0.4027]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8414,  1.9981, -0.5238],\n",
      "        [-2.0437,  0.5741,  1.1347],\n",
      "        [-1.7305,  1.5719, -0.2109],\n",
      "        [-1.8016,  1.8491, -0.2870],\n",
      "        [-1.9364,  0.5786,  1.2609],\n",
      "        [ 0.7014, -0.3250, -0.8755],\n",
      "        [-1.5959,  1.6687, -0.4181],\n",
      "        [-1.6542,  1.7587, -0.1969],\n",
      "        [ 0.2341,  0.4500, -1.0398],\n",
      "        [-1.5708,  1.7218, -0.3547],\n",
      "        [-1.5997,  0.4809,  0.9966],\n",
      "        [-0.5918,  1.1108, -0.8138],\n",
      "        [-1.3145,  1.7891, -0.9156],\n",
      "        [-1.8129,  1.6749, -0.1850],\n",
      "        [-1.9259,  1.8596, -0.3740],\n",
      "        [-1.7846,  1.7778, -0.4027]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6767,  1.6492, -0.1980],\n",
      "        [ 0.5093, -0.1468, -0.9827],\n",
      "        [-1.8809,  1.9651, -0.3052],\n",
      "        [-1.6596,  0.4154,  1.1613],\n",
      "        [-1.6018,  1.7797, -0.4107],\n",
      "        [-1.8258,  1.7629,  0.0566],\n",
      "        [-1.9989,  1.4731,  0.2596],\n",
      "        [-1.8166,  1.1891,  0.4711],\n",
      "        [-1.7727,  1.9004, -0.3694],\n",
      "        [-1.7367,  0.5287,  0.9877],\n",
      "        [ 0.5889, -0.0846, -0.7587],\n",
      "        [-1.6779,  0.4410,  1.3148],\n",
      "        [-1.6185,  1.8742, -0.2694],\n",
      "        [-1.7082,  1.6684, -0.1952],\n",
      "        [-1.5162,  2.0016, -0.4487],\n",
      "        [-1.5803,  1.6510, -0.4539]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6767,  1.6492, -0.1980],\n",
      "        [ 0.5093, -0.1468, -0.9827],\n",
      "        [-1.8809,  1.9651, -0.3052],\n",
      "        [-1.6596,  0.4154,  1.1613],\n",
      "        [-1.6018,  1.7797, -0.4107],\n",
      "        [-1.8258,  1.7629,  0.0566],\n",
      "        [-1.9989,  1.4731,  0.2596],\n",
      "        [-1.8166,  1.1891,  0.4711],\n",
      "        [-1.7727,  1.9004, -0.3694],\n",
      "        [-1.7367,  0.5287,  0.9877],\n",
      "        [ 0.5889, -0.0846, -0.7587],\n",
      "        [-1.6779,  0.4410,  1.3148],\n",
      "        [-1.6185,  1.8742, -0.2694],\n",
      "        [-1.7082,  1.6684, -0.1952],\n",
      "        [-1.5162,  2.0016, -0.4487],\n",
      "        [-1.5803,  1.6510, -0.4539]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.6198, -0.2798, -0.9268],\n",
      "        [-1.4860,  1.6372, -0.3152],\n",
      "        [-1.7033,  1.6936, -0.2214],\n",
      "        [-1.6870,  0.4535,  1.1260],\n",
      "        [-1.7873,  1.7778, -0.3314],\n",
      "        [-1.6655,  1.6955, -0.5334],\n",
      "        [ 0.8095, -0.1772, -0.9347],\n",
      "        [-1.2176,  1.7860, -0.4211],\n",
      "        [-1.6838,  0.5048,  1.1266],\n",
      "        [ 0.6952, -0.4254, -0.7693],\n",
      "        [-1.7272,  0.5229,  1.0783],\n",
      "        [-1.6462,  1.6843, -0.3449],\n",
      "        [-1.0441,  1.2587, -0.5530],\n",
      "        [ 0.5353, -0.1000, -0.9311],\n",
      "        [-1.9007,  1.6606,  0.1321],\n",
      "        [-1.5769,  1.5444, -0.2287]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.6198, -0.2798, -0.9268],\n",
      "        [-1.4860,  1.6372, -0.3152],\n",
      "        [-1.7033,  1.6936, -0.2214],\n",
      "        [-1.6870,  0.4535,  1.1260],\n",
      "        [-1.7873,  1.7778, -0.3314],\n",
      "        [-1.6655,  1.6955, -0.5334],\n",
      "        [ 0.8095, -0.1772, -0.9347],\n",
      "        [-1.2176,  1.7860, -0.4211],\n",
      "        [-1.6838,  0.5048,  1.1266],\n",
      "        [ 0.6952, -0.4254, -0.7693],\n",
      "        [-1.7272,  0.5229,  1.0783],\n",
      "        [-1.6462,  1.6843, -0.3449],\n",
      "        [-1.0441,  1.2587, -0.5530],\n",
      "        [ 0.5353, -0.1000, -0.9311],\n",
      "        [-1.9007,  1.6606,  0.1321],\n",
      "        [-1.5769,  1.5444, -0.2287]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0720,  0.8250,  0.9116],\n",
      "        [-1.8440,  1.8419, -0.3867],\n",
      "        [-1.7144,  1.8183, -0.5590],\n",
      "        [-1.8009,  1.7881, -0.2946],\n",
      "        [-1.7953,  1.5042, -0.0489],\n",
      "        [-1.7321,  1.9809, -0.3528],\n",
      "        [-1.7212,  1.9055, -0.1863],\n",
      "        [-1.7379,  1.7611, -0.2437],\n",
      "        [-1.8300,  0.5146,  1.0621],\n",
      "        [-1.7424,  1.7703,  0.1453],\n",
      "        [-1.8370,  0.2897,  1.2636],\n",
      "        [-1.9216,  0.6810,  0.9194],\n",
      "        [-1.7865,  1.8500, -0.4751],\n",
      "        [-1.8571,  0.7625,  1.1031],\n",
      "        [-1.8632,  0.7188,  0.7906],\n",
      "        [-1.8619,  2.0693, -0.4092]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.0720,  0.8250,  0.9116],\n",
      "        [-1.8440,  1.8419, -0.3867],\n",
      "        [-1.7144,  1.8183, -0.5590],\n",
      "        [-1.8009,  1.7881, -0.2946],\n",
      "        [-1.7953,  1.5042, -0.0489],\n",
      "        [-1.7321,  1.9809, -0.3528],\n",
      "        [-1.7212,  1.9055, -0.1863],\n",
      "        [-1.7379,  1.7611, -0.2437],\n",
      "        [-1.8300,  0.5146,  1.0621],\n",
      "        [-1.7424,  1.7703,  0.1453],\n",
      "        [-1.8370,  0.2897,  1.2636],\n",
      "        [-1.9216,  0.6810,  0.9194],\n",
      "        [-1.7865,  1.8500, -0.4751],\n",
      "        [-1.8571,  0.7625,  1.1031],\n",
      "        [-1.8632,  0.7188,  0.7906],\n",
      "        [-1.8619,  2.0693, -0.4092]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5818,  1.7307, -0.0100],\n",
      "        [-1.5188,  1.8058, -0.2931],\n",
      "        [-1.8103,  0.7057,  0.8654],\n",
      "        [-1.7951,  1.9965, -0.1571],\n",
      "        [-1.7970,  0.5691,  1.1387],\n",
      "        [ 0.6320, -0.3138, -0.9932],\n",
      "        [-1.7005,  0.6328,  1.0155],\n",
      "        [-1.8171,  2.2183, -0.1769],\n",
      "        [-1.9537,  0.7035,  1.1944],\n",
      "        [-1.5601,  1.7115, -0.3407],\n",
      "        [ 0.6182, -0.2395, -0.7269],\n",
      "        [-1.6750,  1.6891, -0.3279],\n",
      "        [-1.6717,  1.5079, -0.1605],\n",
      "        [-2.0380,  1.1643,  0.5203],\n",
      "        [-1.6337,  1.8013, -0.3706],\n",
      "        [-1.7594,  1.8112, -0.3949]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5818,  1.7307, -0.0100],\n",
      "        [-1.5188,  1.8058, -0.2931],\n",
      "        [-1.8103,  0.7057,  0.8654],\n",
      "        [-1.7951,  1.9965, -0.1571],\n",
      "        [-1.7970,  0.5691,  1.1387],\n",
      "        [ 0.6320, -0.3138, -0.9932],\n",
      "        [-1.7005,  0.6328,  1.0155],\n",
      "        [-1.8171,  2.2183, -0.1769],\n",
      "        [-1.9537,  0.7035,  1.1944],\n",
      "        [-1.5601,  1.7115, -0.3407],\n",
      "        [ 0.6182, -0.2395, -0.7269],\n",
      "        [-1.6750,  1.6891, -0.3279],\n",
      "        [-1.6717,  1.5079, -0.1605],\n",
      "        [-2.0380,  1.1643,  0.5203],\n",
      "        [-1.6337,  1.8013, -0.3706],\n",
      "        [-1.7594,  1.8112, -0.3949]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8532,  0.6356,  1.0969],\n",
      "        [-1.6807,  0.4110,  1.0215],\n",
      "        [-1.4171,  1.6790, -0.4349],\n",
      "        [-1.5586,  1.8224, -0.1758],\n",
      "        [-1.8866,  1.0202,  0.7121],\n",
      "        [ 0.6805, -0.0520, -0.9430],\n",
      "        [-1.9756,  0.6376,  1.1185],\n",
      "        [-1.8111,  1.6867, -0.3451],\n",
      "        [-1.4822,  1.6758, -0.2560],\n",
      "        [-1.4308,  1.7800, -0.1697],\n",
      "        [-1.9471,  0.6508,  1.0770],\n",
      "        [-1.6767,  0.6382,  0.8834],\n",
      "        [-1.8228,  1.6268,  0.1539],\n",
      "        [-1.8647,  0.2842,  1.0481],\n",
      "        [-1.6240,  1.9044, -0.2203],\n",
      "        [-1.8761,  1.8542, -0.3398]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8532,  0.6356,  1.0969],\n",
      "        [-1.6807,  0.4110,  1.0215],\n",
      "        [-1.4171,  1.6790, -0.4349],\n",
      "        [-1.5586,  1.8224, -0.1758],\n",
      "        [-1.8866,  1.0202,  0.7121],\n",
      "        [ 0.6805, -0.0520, -0.9430],\n",
      "        [-1.9756,  0.6376,  1.1185],\n",
      "        [-1.8111,  1.6867, -0.3451],\n",
      "        [-1.4822,  1.6758, -0.2560],\n",
      "        [-1.4308,  1.7800, -0.1697],\n",
      "        [-1.9471,  0.6508,  1.0770],\n",
      "        [-1.6767,  0.6382,  0.8834],\n",
      "        [-1.8228,  1.6268,  0.1539],\n",
      "        [-1.8647,  0.2842,  1.0481],\n",
      "        [-1.6240,  1.9044, -0.2203],\n",
      "        [-1.8761,  1.8542, -0.3398]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8810,  1.9750, -0.3237],\n",
      "        [-1.4676,  1.5046, -0.1602],\n",
      "        [ 0.7168, -0.3869, -0.7781],\n",
      "        [ 0.7472, -0.1534, -1.1688],\n",
      "        [-1.5628,  1.6055, -0.2072],\n",
      "        [ 0.5185, -0.0114, -1.0760],\n",
      "        [-1.9196,  2.0299, -0.3580],\n",
      "        [-1.6262,  1.9538, -0.2008],\n",
      "        [-1.2698,  1.5683, -0.5064],\n",
      "        [-2.0569,  1.8267, -0.2379],\n",
      "        [-1.8383,  1.8866, -0.0169],\n",
      "        [ 0.5167, -0.0026, -1.0254],\n",
      "        [ 0.7509, -0.3103, -0.7018],\n",
      "        [-1.5739,  1.5021, -0.3466],\n",
      "        [-1.6032,  1.8305, -0.2602],\n",
      "        [-1.9017,  0.5542,  1.0930]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8810,  1.9750, -0.3237],\n",
      "        [-1.4676,  1.5046, -0.1602],\n",
      "        [ 0.7168, -0.3869, -0.7781],\n",
      "        [ 0.7472, -0.1534, -1.1688],\n",
      "        [-1.5628,  1.6055, -0.2072],\n",
      "        [ 0.5185, -0.0114, -1.0760],\n",
      "        [-1.9196,  2.0299, -0.3580],\n",
      "        [-1.6262,  1.9538, -0.2008],\n",
      "        [-1.2698,  1.5683, -0.5064],\n",
      "        [-2.0569,  1.8267, -0.2379],\n",
      "        [-1.8383,  1.8866, -0.0169],\n",
      "        [ 0.5167, -0.0026, -1.0254],\n",
      "        [ 0.7509, -0.3103, -0.7018],\n",
      "        [-1.5739,  1.5021, -0.3466],\n",
      "        [-1.6032,  1.8305, -0.2602],\n",
      "        [-1.9017,  0.5542,  1.0930]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9621,  1.6353, -0.1883],\n",
      "        [-2.1103,  0.7259,  1.0725],\n",
      "        [-1.9194,  1.8513, -0.1834],\n",
      "        [-1.8333,  0.8279,  0.6127],\n",
      "        [-1.9936,  1.9200, -0.1437],\n",
      "        [-1.8456,  0.6315,  1.1247],\n",
      "        [-1.7952,  0.7233,  0.8319],\n",
      "        [-1.7978,  1.4449,  0.0321],\n",
      "        [ 0.5661, -0.2404, -1.0037],\n",
      "        [-1.8980,  1.6257, -0.1360],\n",
      "        [-1.7854,  1.7362, -0.1798],\n",
      "        [-1.9499,  1.8857, -0.1898],\n",
      "        [-1.6396,  1.7487, -0.2008],\n",
      "        [ 0.8867, -0.2198, -0.9794],\n",
      "        [-1.6825,  1.7851, -0.2686],\n",
      "        [-1.6297,  1.6531, -0.3434]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9621,  1.6353, -0.1883],\n",
      "        [-2.1103,  0.7259,  1.0725],\n",
      "        [-1.9194,  1.8513, -0.1834],\n",
      "        [-1.8333,  0.8279,  0.6127],\n",
      "        [-1.9936,  1.9200, -0.1437],\n",
      "        [-1.8456,  0.6315,  1.1247],\n",
      "        [-1.7952,  0.7233,  0.8319],\n",
      "        [-1.7978,  1.4449,  0.0321],\n",
      "        [ 0.5661, -0.2404, -1.0037],\n",
      "        [-1.8980,  1.6257, -0.1360],\n",
      "        [-1.7854,  1.7362, -0.1798],\n",
      "        [-1.9499,  1.8857, -0.1898],\n",
      "        [-1.6396,  1.7487, -0.2008],\n",
      "        [ 0.8867, -0.2198, -0.9794],\n",
      "        [-1.6825,  1.7851, -0.2686],\n",
      "        [-1.6297,  1.6531, -0.3434]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5235, -0.1596, -1.0515],\n",
      "        [-2.0008,  0.9451,  0.8715],\n",
      "        [-1.7539,  0.6929,  1.1001],\n",
      "        [ 0.8715, -0.1971, -0.9206],\n",
      "        [-1.6089,  0.5519,  1.0736],\n",
      "        [-1.8643,  1.6061,  0.2204],\n",
      "        [-1.8333,  0.7118,  0.8698],\n",
      "        [-1.9142,  0.5792,  0.9814],\n",
      "        [ 0.6513, -0.2879, -1.0481],\n",
      "        [-1.9182,  1.8745, -0.1743],\n",
      "        [-1.7487,  1.8204, -0.1222],\n",
      "        [-1.9172,  0.6942,  1.0129],\n",
      "        [-1.4045,  1.6950, -0.2625],\n",
      "        [-1.8222,  0.7161,  1.0663],\n",
      "        [-1.9684,  1.9730, -0.0756],\n",
      "        [-1.9074,  1.0379,  0.8543]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.5235, -0.1596, -1.0515],\n",
      "        [-2.0008,  0.9451,  0.8715],\n",
      "        [-1.7539,  0.6929,  1.1001],\n",
      "        [ 0.8715, -0.1971, -0.9206],\n",
      "        [-1.6089,  0.5519,  1.0736],\n",
      "        [-1.8643,  1.6061,  0.2204],\n",
      "        [-1.8333,  0.7118,  0.8698],\n",
      "        [-1.9142,  0.5792,  0.9814],\n",
      "        [ 0.6513, -0.2879, -1.0481],\n",
      "        [-1.9182,  1.8745, -0.1743],\n",
      "        [-1.7487,  1.8204, -0.1222],\n",
      "        [-1.9172,  0.6942,  1.0129],\n",
      "        [-1.4045,  1.6950, -0.2625],\n",
      "        [-1.8222,  0.7161,  1.0663],\n",
      "        [-1.9684,  1.9730, -0.0756],\n",
      "        [-1.9074,  1.0379,  0.8543]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8043,  1.4222,  0.4072],\n",
      "        [-1.8394,  1.8430, -0.0921],\n",
      "        [-1.7488,  1.9878, -0.2635],\n",
      "        [-1.7205,  1.8745, -0.1225],\n",
      "        [ 0.6453, -0.2644, -0.9667],\n",
      "        [-1.8903,  1.8710, -0.1345],\n",
      "        [-1.6879,  1.6957, -0.4292],\n",
      "        [ 0.7391, -0.2162, -0.9965],\n",
      "        [-1.9949,  1.3117,  0.6322],\n",
      "        [-1.8026,  0.6047,  1.0032],\n",
      "        [-1.7605,  1.6384, -0.1381],\n",
      "        [-1.8710,  1.9479, -0.3150],\n",
      "        [-1.7161,  1.8010, -0.1628],\n",
      "        [ 0.7365, -0.3129, -1.0305],\n",
      "        [-1.8163,  0.8797,  0.9460],\n",
      "        [-1.7379,  2.0187, -0.2285]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8043,  1.4222,  0.4072],\n",
      "        [-1.8394,  1.8430, -0.0921],\n",
      "        [-1.7488,  1.9878, -0.2635],\n",
      "        [-1.7205,  1.8745, -0.1225],\n",
      "        [ 0.6453, -0.2644, -0.9667],\n",
      "        [-1.8903,  1.8710, -0.1345],\n",
      "        [-1.6879,  1.6957, -0.4292],\n",
      "        [ 0.7391, -0.2162, -0.9965],\n",
      "        [-1.9949,  1.3117,  0.6322],\n",
      "        [-1.8026,  0.6047,  1.0032],\n",
      "        [-1.7605,  1.6384, -0.1381],\n",
      "        [-1.8710,  1.9479, -0.3150],\n",
      "        [-1.7161,  1.8010, -0.1628],\n",
      "        [ 0.7365, -0.3129, -1.0305],\n",
      "        [-1.8163,  0.8797,  0.9460],\n",
      "        [-1.7379,  2.0187, -0.2285]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5363,  0.8037,  1.0379],\n",
      "        [-1.5958,  1.7429, -0.2484],\n",
      "        [ 0.1019,  0.3186, -0.9829],\n",
      "        [-1.2041,  1.3891, -0.6259],\n",
      "        [-2.0258,  1.7231,  0.1567],\n",
      "        [-1.7819,  2.1006, -0.0451],\n",
      "        [-1.7087,  0.6986,  1.1054],\n",
      "        [-1.9102,  1.9796, -0.3440],\n",
      "        [ 0.6092, -0.3236, -1.0250],\n",
      "        [-2.0549,  2.1289, -0.2932],\n",
      "        [-1.8667,  1.9664, -0.1882],\n",
      "        [-1.7628,  1.8203, -0.3026],\n",
      "        [ 0.6873, -0.2342, -1.0121],\n",
      "        [ 0.5485,  0.0840, -1.1087],\n",
      "        [-1.6487,  0.5817,  1.0979],\n",
      "        [-1.7331,  0.3608,  1.0780]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5363,  0.8037,  1.0379],\n",
      "        [-1.5958,  1.7429, -0.2484],\n",
      "        [ 0.1019,  0.3186, -0.9829],\n",
      "        [-1.2041,  1.3891, -0.6259],\n",
      "        [-2.0258,  1.7231,  0.1567],\n",
      "        [-1.7819,  2.1006, -0.0451],\n",
      "        [-1.7087,  0.6986,  1.1054],\n",
      "        [-1.9102,  1.9796, -0.3440],\n",
      "        [ 0.6092, -0.3236, -1.0250],\n",
      "        [-2.0549,  2.1289, -0.2932],\n",
      "        [-1.8667,  1.9664, -0.1882],\n",
      "        [-1.7628,  1.8203, -0.3026],\n",
      "        [ 0.6873, -0.2342, -1.0121],\n",
      "        [ 0.5485,  0.0840, -1.1087],\n",
      "        [-1.6487,  0.5817,  1.0979],\n",
      "        [-1.7331,  0.3608,  1.0780]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9948,  1.9368, -0.2455],\n",
      "        [-1.7885,  0.6167,  1.0646],\n",
      "        [-1.9992,  1.0577,  0.6305],\n",
      "        [-1.5985,  0.5400,  0.9923],\n",
      "        [-1.7078,  1.6505, -0.2339],\n",
      "        [-1.8000,  0.6082,  1.1183],\n",
      "        [-1.9069,  1.9383, -0.3338],\n",
      "        [-1.7136,  0.3185,  1.1017],\n",
      "        [-1.9949,  0.7659,  0.9898],\n",
      "        [-1.7494,  1.8751, -0.1034],\n",
      "        [-1.7357,  1.2080,  0.4848],\n",
      "        [-1.8502,  2.0241, -0.1058],\n",
      "        [-2.0025,  1.7446, -0.0969],\n",
      "        [-1.7503,  1.5864, -0.3508],\n",
      "        [-1.7135,  0.5060,  0.8229],\n",
      "        [-1.5174,  1.5608, -0.4459]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9948,  1.9368, -0.2455],\n",
      "        [-1.7885,  0.6167,  1.0646],\n",
      "        [-1.9992,  1.0577,  0.6305],\n",
      "        [-1.5985,  0.5400,  0.9923],\n",
      "        [-1.7078,  1.6505, -0.2339],\n",
      "        [-1.8000,  0.6082,  1.1183],\n",
      "        [-1.9069,  1.9383, -0.3338],\n",
      "        [-1.7136,  0.3185,  1.1017],\n",
      "        [-1.9949,  0.7659,  0.9898],\n",
      "        [-1.7494,  1.8751, -0.1034],\n",
      "        [-1.7357,  1.2080,  0.4848],\n",
      "        [-1.8502,  2.0241, -0.1058],\n",
      "        [-2.0025,  1.7446, -0.0969],\n",
      "        [-1.7503,  1.5864, -0.3508],\n",
      "        [-1.7135,  0.5060,  0.8229],\n",
      "        [-1.5174,  1.5608, -0.4459]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9985,  1.9334, -0.1613],\n",
      "        [ 0.6449, -0.1787, -1.0367],\n",
      "        [-1.9675,  1.9810, -0.3310],\n",
      "        [-2.1625,  1.9933,  0.0290],\n",
      "        [ 0.6959, -0.2525, -1.0309],\n",
      "        [-1.7788,  1.8224, -0.2060],\n",
      "        [-2.0087,  0.7627,  0.8727],\n",
      "        [-1.8200,  0.5623,  1.1437],\n",
      "        [-1.8746,  0.8377,  0.8682],\n",
      "        [ 0.6982, -0.2185, -0.9387],\n",
      "        [-1.8776,  0.6312,  1.0859],\n",
      "        [-1.6574,  0.6797,  1.2508],\n",
      "        [-0.8303,  0.9112, -0.6370],\n",
      "        [-2.0029,  2.1142, -0.2049],\n",
      "        [-1.2445,  1.4564, -0.6350],\n",
      "        [-1.9025,  1.8428, -0.2660]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9985,  1.9334, -0.1613],\n",
      "        [ 0.6449, -0.1787, -1.0367],\n",
      "        [-1.9675,  1.9810, -0.3310],\n",
      "        [-2.1625,  1.9933,  0.0290],\n",
      "        [ 0.6959, -0.2525, -1.0309],\n",
      "        [-1.7788,  1.8224, -0.2060],\n",
      "        [-2.0087,  0.7627,  0.8727],\n",
      "        [-1.8200,  0.5623,  1.1437],\n",
      "        [-1.8746,  0.8377,  0.8682],\n",
      "        [ 0.6982, -0.2185, -0.9387],\n",
      "        [-1.8776,  0.6312,  1.0859],\n",
      "        [-1.6574,  0.6797,  1.2508],\n",
      "        [-0.8303,  0.9112, -0.6370],\n",
      "        [-2.0029,  2.1142, -0.2049],\n",
      "        [-1.2445,  1.4564, -0.6350],\n",
      "        [-1.9025,  1.8428, -0.2660]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9331,  1.8951,  0.0260],\n",
      "        [-1.9143,  0.5682,  1.1036],\n",
      "        [-2.2658,  0.7452,  0.9485],\n",
      "        [-1.9132,  1.7708,  0.2336],\n",
      "        [ 0.8540, -0.3027, -0.8771],\n",
      "        [ 0.6811, -0.2801, -0.9377],\n",
      "        [-1.7594,  1.6779, -0.2618],\n",
      "        [-2.0207,  2.0585, -0.1383],\n",
      "        [-1.8358,  1.8685, -0.1637],\n",
      "        [-1.8149,  1.7743, -0.5307],\n",
      "        [-1.9150,  1.9905, -0.1883],\n",
      "        [-2.0198,  0.7238,  1.3172],\n",
      "        [ 0.7078, -0.0976, -0.9179],\n",
      "        [ 0.5613, -0.1360, -1.0317],\n",
      "        [-1.7236,  0.8144,  0.4899],\n",
      "        [-2.0421,  1.9673, -0.0661]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9331,  1.8951,  0.0260],\n",
      "        [-1.9143,  0.5682,  1.1036],\n",
      "        [-2.2658,  0.7452,  0.9485],\n",
      "        [-1.9132,  1.7708,  0.2336],\n",
      "        [ 0.8540, -0.3027, -0.8771],\n",
      "        [ 0.6811, -0.2801, -0.9377],\n",
      "        [-1.7594,  1.6779, -0.2618],\n",
      "        [-2.0207,  2.0585, -0.1383],\n",
      "        [-1.8358,  1.8685, -0.1637],\n",
      "        [-1.8149,  1.7743, -0.5307],\n",
      "        [-1.9150,  1.9905, -0.1883],\n",
      "        [-2.0198,  0.7238,  1.3172],\n",
      "        [ 0.7078, -0.0976, -0.9179],\n",
      "        [ 0.5613, -0.1360, -1.0317],\n",
      "        [-1.7236,  0.8144,  0.4899],\n",
      "        [-2.0421,  1.9673, -0.0661]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2643,  1.4606,  0.4810],\n",
      "        [-1.9675,  2.0419, -0.1965],\n",
      "        [-1.8861,  1.8589, -0.0607],\n",
      "        [-1.7365,  1.7852,  0.0699],\n",
      "        [-1.8199,  1.9517, -0.1840],\n",
      "        [-1.7506,  1.8294, -0.0604],\n",
      "        [-1.7295,  1.9404, -0.3671],\n",
      "        [-2.1371,  0.8673,  1.0982],\n",
      "        [-1.8983,  1.8786, -0.1018],\n",
      "        [ 0.5924, -0.0099, -0.9913],\n",
      "        [-2.0409,  1.5201,  0.0183],\n",
      "        [-1.9488,  0.8327,  0.9463],\n",
      "        [-1.8726,  1.6503, -0.0172],\n",
      "        [ 0.7219, -0.3011, -1.1746],\n",
      "        [-2.0859,  1.8900, -0.2327],\n",
      "        [-2.0462,  0.7094,  1.2329]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.2643,  1.4606,  0.4810],\n",
      "        [-1.9675,  2.0419, -0.1965],\n",
      "        [-1.8861,  1.8589, -0.0607],\n",
      "        [-1.7365,  1.7852,  0.0699],\n",
      "        [-1.8199,  1.9517, -0.1840],\n",
      "        [-1.7506,  1.8294, -0.0604],\n",
      "        [-1.7295,  1.9404, -0.3671],\n",
      "        [-2.1371,  0.8673,  1.0982],\n",
      "        [-1.8983,  1.8786, -0.1018],\n",
      "        [ 0.5924, -0.0099, -0.9913],\n",
      "        [-2.0409,  1.5201,  0.0183],\n",
      "        [-1.9488,  0.8327,  0.9463],\n",
      "        [-1.8726,  1.6503, -0.0172],\n",
      "        [ 0.7219, -0.3011, -1.1746],\n",
      "        [-2.0859,  1.8900, -0.2327],\n",
      "        [-2.0462,  0.7094,  1.2329]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0745,  1.6300,  0.0409],\n",
      "        [-1.8321,  1.9685, -0.1503],\n",
      "        [-2.2917,  1.6920,  0.1762],\n",
      "        [-2.1372,  1.4006,  0.6379],\n",
      "        [-1.9552,  1.6589, -0.2100],\n",
      "        [-1.9018,  0.6654,  1.1176],\n",
      "        [-1.8733,  1.9566, -0.3496],\n",
      "        [-1.9156,  0.4847,  1.1790],\n",
      "        [-1.7856,  1.3906,  0.4417],\n",
      "        [-2.1159,  1.9394, -0.2985],\n",
      "        [-2.0539,  0.5065,  1.0964],\n",
      "        [-1.6600,  0.5867,  1.1171],\n",
      "        [-1.9864,  1.8989, -0.1980],\n",
      "        [-1.8204,  0.6293,  0.9826],\n",
      "        [-1.6265,  1.8513, -0.4270],\n",
      "        [-1.9827,  1.8952,  0.1371]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.0745,  1.6300,  0.0409],\n",
      "        [-1.8321,  1.9685, -0.1503],\n",
      "        [-2.2917,  1.6920,  0.1762],\n",
      "        [-2.1372,  1.4006,  0.6379],\n",
      "        [-1.9552,  1.6589, -0.2100],\n",
      "        [-1.9018,  0.6654,  1.1176],\n",
      "        [-1.8733,  1.9566, -0.3496],\n",
      "        [-1.9156,  0.4847,  1.1790],\n",
      "        [-1.7856,  1.3906,  0.4417],\n",
      "        [-2.1159,  1.9394, -0.2985],\n",
      "        [-2.0539,  0.5065,  1.0964],\n",
      "        [-1.6600,  0.5867,  1.1171],\n",
      "        [-1.9864,  1.8989, -0.1980],\n",
      "        [-1.8204,  0.6293,  0.9826],\n",
      "        [-1.6265,  1.8513, -0.4270],\n",
      "        [-1.9827,  1.8952,  0.1371]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0796,  1.5926, -0.0224],\n",
      "        [-2.0651,  1.2403,  0.7167],\n",
      "        [-2.0058,  1.5066, -0.1117],\n",
      "        [ 0.5904, -0.0757, -1.0497],\n",
      "        [-0.0826,  0.1991, -0.4146],\n",
      "        [ 0.6160, -0.0050, -0.9756],\n",
      "        [-1.6827,  1.7573, -0.4025],\n",
      "        [-1.9482,  0.7943,  0.9419],\n",
      "        [-1.8733,  0.5555,  1.0271],\n",
      "        [-1.4186,  0.6514,  0.4980],\n",
      "        [-1.8092,  1.7874, -0.3140],\n",
      "        [-1.6623,  0.4181,  0.9154],\n",
      "        [ 0.7885,  0.1250, -1.1220],\n",
      "        [-1.9577,  2.0901, -0.1548],\n",
      "        [-2.0241,  1.3183,  0.4962],\n",
      "        [ 0.5153,  0.1428, -1.1269]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.0796,  1.5926, -0.0224],\n",
      "        [-2.0651,  1.2403,  0.7167],\n",
      "        [-2.0058,  1.5066, -0.1117],\n",
      "        [ 0.5904, -0.0757, -1.0497],\n",
      "        [-0.0826,  0.1991, -0.4146],\n",
      "        [ 0.6160, -0.0050, -0.9756],\n",
      "        [-1.6827,  1.7573, -0.4025],\n",
      "        [-1.9482,  0.7943,  0.9419],\n",
      "        [-1.8733,  0.5555,  1.0271],\n",
      "        [-1.4186,  0.6514,  0.4980],\n",
      "        [-1.8092,  1.7874, -0.3140],\n",
      "        [-1.6623,  0.4181,  0.9154],\n",
      "        [ 0.7885,  0.1250, -1.1220],\n",
      "        [-1.9577,  2.0901, -0.1548],\n",
      "        [-2.0241,  1.3183,  0.4962],\n",
      "        [ 0.5153,  0.1428, -1.1269]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.4671,  0.1615, -1.1710],\n",
      "        [-1.8458,  1.7932, -0.0938],\n",
      "        [ 0.5809, -0.1655, -1.1646],\n",
      "        [-1.8108,  0.5825,  1.0544],\n",
      "        [-1.8130,  1.8553, -0.4272],\n",
      "        [-1.9795,  1.9620, -0.3285],\n",
      "        [-2.1029,  1.9010, -0.0279],\n",
      "        [-1.9275,  0.7389,  1.0629],\n",
      "        [-1.7310,  1.6210, -0.1779],\n",
      "        [-1.6383,  1.9046, -0.1799],\n",
      "        [-1.8310,  1.7271, -0.1535],\n",
      "        [-2.1325,  1.7497,  0.1559],\n",
      "        [-2.0302,  0.5922,  1.1526],\n",
      "        [-1.8355,  1.9919, -0.2384],\n",
      "        [-1.8093,  0.6669,  1.0102],\n",
      "        [-2.0828,  0.6715,  1.3356]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.4671,  0.1615, -1.1710],\n",
      "        [-1.8458,  1.7932, -0.0938],\n",
      "        [ 0.5809, -0.1655, -1.1646],\n",
      "        [-1.8108,  0.5825,  1.0544],\n",
      "        [-1.8130,  1.8553, -0.4272],\n",
      "        [-1.9795,  1.9620, -0.3285],\n",
      "        [-2.1029,  1.9010, -0.0279],\n",
      "        [-1.9275,  0.7389,  1.0629],\n",
      "        [-1.7310,  1.6210, -0.1779],\n",
      "        [-1.6383,  1.9046, -0.1799],\n",
      "        [-1.8310,  1.7271, -0.1535],\n",
      "        [-2.1325,  1.7497,  0.1559],\n",
      "        [-2.0302,  0.5922,  1.1526],\n",
      "        [-1.8355,  1.9919, -0.2384],\n",
      "        [-1.8093,  0.6669,  1.0102],\n",
      "        [-2.0828,  0.6715,  1.3356]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5557, -0.0187, -1.1778],\n",
      "        [-1.8838,  0.7025,  1.0661],\n",
      "        [-1.6457,  2.0632, -0.4261],\n",
      "        [-0.6431,  0.8249, -0.7859],\n",
      "        [-1.9919,  2.0959, -0.1615],\n",
      "        [-2.2344,  1.8686,  0.2798],\n",
      "        [-1.8062,  0.5149,  1.1510],\n",
      "        [-2.1029,  1.8168, -0.0596],\n",
      "        [-1.9927,  2.0921, -0.2968],\n",
      "        [-1.8950,  1.8977, -0.2199],\n",
      "        [-2.0400,  1.7720,  0.2715],\n",
      "        [-2.0345,  0.8644,  0.9179],\n",
      "        [-1.6732,  0.4669,  0.9177],\n",
      "        [-2.0127,  1.8628, -0.0531],\n",
      "        [-1.9482,  1.8997, -0.2681],\n",
      "        [-1.6088,  2.0251, -0.2223]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.5557, -0.0187, -1.1778],\n",
      "        [-1.8838,  0.7025,  1.0661],\n",
      "        [-1.6457,  2.0632, -0.4261],\n",
      "        [-0.6431,  0.8249, -0.7859],\n",
      "        [-1.9919,  2.0959, -0.1615],\n",
      "        [-2.2344,  1.8686,  0.2798],\n",
      "        [-1.8062,  0.5149,  1.1510],\n",
      "        [-2.1029,  1.8168, -0.0596],\n",
      "        [-1.9927,  2.0921, -0.2968],\n",
      "        [-1.8950,  1.8977, -0.2199],\n",
      "        [-2.0400,  1.7720,  0.2715],\n",
      "        [-2.0345,  0.8644,  0.9179],\n",
      "        [-1.6732,  0.4669,  0.9177],\n",
      "        [-2.0127,  1.8628, -0.0531],\n",
      "        [-1.9482,  1.8997, -0.2681],\n",
      "        [-1.6088,  2.0251, -0.2223]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9254,  2.0005,  0.1956],\n",
      "        [-1.5915,  0.8454,  0.3890],\n",
      "        [-1.9672,  0.7178,  1.1267],\n",
      "        [-1.8844,  0.6469,  1.2281],\n",
      "        [-1.8604,  0.6910,  1.1672],\n",
      "        [-2.1329,  1.5915,  0.4905],\n",
      "        [-1.7216,  1.8991, -0.1237],\n",
      "        [-2.2119,  2.0331, -0.1073],\n",
      "        [-1.8929,  1.8185, -0.2363],\n",
      "        [-2.1119,  0.7799,  1.0951],\n",
      "        [-1.9394,  0.6678,  1.0131],\n",
      "        [-1.7652,  0.6905,  1.0078],\n",
      "        [-1.2849,  1.4521, -0.5854],\n",
      "        [-2.0793,  0.6894,  1.0519],\n",
      "        [-1.7161,  0.5865,  1.0966],\n",
      "        [-1.9144,  2.0329, -0.1774]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9254,  2.0005,  0.1956],\n",
      "        [-1.5915,  0.8454,  0.3890],\n",
      "        [-1.9672,  0.7178,  1.1267],\n",
      "        [-1.8844,  0.6469,  1.2281],\n",
      "        [-1.8604,  0.6910,  1.1672],\n",
      "        [-2.1329,  1.5915,  0.4905],\n",
      "        [-1.7216,  1.8991, -0.1237],\n",
      "        [-2.2119,  2.0331, -0.1073],\n",
      "        [-1.8929,  1.8185, -0.2363],\n",
      "        [-2.1119,  0.7799,  1.0951],\n",
      "        [-1.9394,  0.6678,  1.0131],\n",
      "        [-1.7652,  0.6905,  1.0078],\n",
      "        [-1.2849,  1.4521, -0.5854],\n",
      "        [-2.0793,  0.6894,  1.0519],\n",
      "        [-1.7161,  0.5865,  1.0966],\n",
      "        [-1.9144,  2.0329, -0.1774]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.0826,  0.2981, -0.5399],\n",
      "        [-1.7736,  2.1029, -0.2673],\n",
      "        [-2.1360,  1.9807, -0.0778],\n",
      "        [-1.8733,  1.8113, -0.1610],\n",
      "        [-1.7613,  0.5925,  0.8507],\n",
      "        [-1.8264,  1.8617, -0.2723],\n",
      "        [-1.7184,  1.7886, -0.3101],\n",
      "        [-2.2206,  2.1406, -0.0368],\n",
      "        [-0.4308,  0.4344, -0.3153],\n",
      "        [ 0.1238,  0.4892, -1.0032],\n",
      "        [-1.9525,  1.7108, -0.1503],\n",
      "        [-2.0103,  0.6943,  1.3172],\n",
      "        [ 0.5033, -0.0724, -1.0117],\n",
      "        [-1.9083,  0.7005,  1.0049],\n",
      "        [-1.7502,  2.0679, -0.2151],\n",
      "        [-1.8999,  0.4548,  0.9918]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-0.0826,  0.2981, -0.5399],\n",
      "        [-1.7736,  2.1029, -0.2673],\n",
      "        [-2.1360,  1.9807, -0.0778],\n",
      "        [-1.8733,  1.8113, -0.1610],\n",
      "        [-1.7613,  0.5925,  0.8507],\n",
      "        [-1.8264,  1.8617, -0.2723],\n",
      "        [-1.7184,  1.7886, -0.3101],\n",
      "        [-2.2206,  2.1406, -0.0368],\n",
      "        [-0.4308,  0.4344, -0.3153],\n",
      "        [ 0.1238,  0.4892, -1.0032],\n",
      "        [-1.9525,  1.7108, -0.1503],\n",
      "        [-2.0103,  0.6943,  1.3172],\n",
      "        [ 0.5033, -0.0724, -1.0117],\n",
      "        [-1.9083,  0.7005,  1.0049],\n",
      "        [-1.7502,  2.0679, -0.2151],\n",
      "        [-1.8999,  0.4548,  0.9918]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7566,  1.7137, -0.2125],\n",
      "        [-1.8541,  1.8175, -0.1628],\n",
      "        [-1.8411,  0.6855,  1.1414],\n",
      "        [-1.9004,  0.7318,  1.1909],\n",
      "        [-1.8060,  2.0779, -0.3169],\n",
      "        [-1.9212,  0.6279,  1.0897],\n",
      "        [ 0.5602,  0.1293, -1.3113],\n",
      "        [ 0.4189,  0.1106, -1.1237],\n",
      "        [ 0.4553,  0.0985, -1.2317],\n",
      "        [-2.0991,  1.0728,  0.7912],\n",
      "        [-1.7595,  0.5375,  1.1672],\n",
      "        [-2.0394,  1.8781, -0.1712],\n",
      "        [-2.0655,  1.7609, -0.0274],\n",
      "        [-1.8906,  2.1423, -0.1881],\n",
      "        [-1.7241,  1.8925, -0.2282],\n",
      "        [-1.9553,  1.9291, -0.3007]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7566,  1.7137, -0.2125],\n",
      "        [-1.8541,  1.8175, -0.1628],\n",
      "        [-1.8411,  0.6855,  1.1414],\n",
      "        [-1.9004,  0.7318,  1.1909],\n",
      "        [-1.8060,  2.0779, -0.3169],\n",
      "        [-1.9212,  0.6279,  1.0897],\n",
      "        [ 0.5602,  0.1293, -1.3113],\n",
      "        [ 0.4189,  0.1106, -1.1237],\n",
      "        [ 0.4553,  0.0985, -1.2317],\n",
      "        [-2.0991,  1.0728,  0.7912],\n",
      "        [-1.7595,  0.5375,  1.1672],\n",
      "        [-2.0394,  1.8781, -0.1712],\n",
      "        [-2.0655,  1.7609, -0.0274],\n",
      "        [-1.8906,  2.1423, -0.1881],\n",
      "        [-1.7241,  1.8925, -0.2282],\n",
      "        [-1.9553,  1.9291, -0.3007]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3327,  0.0657, -0.9827],\n",
      "        [ 0.2524,  0.2450, -0.8644],\n",
      "        [-1.9344,  1.9978, -0.2653],\n",
      "        [-1.9360,  0.5674,  1.2548],\n",
      "        [-1.7411,  1.4147, -0.0644],\n",
      "        [-1.8682,  1.7943, -0.0561],\n",
      "        [-1.8127,  1.8459, -0.2706],\n",
      "        [-2.0632,  0.6067,  1.2717],\n",
      "        [-2.0395,  1.6848, -0.0637],\n",
      "        [-1.9588,  1.6591,  0.3793],\n",
      "        [-2.1086,  0.8823,  0.9152],\n",
      "        [-0.7738,  0.8656, -0.6944],\n",
      "        [-1.9307,  2.1609, -0.1027],\n",
      "        [-1.9600,  0.6210,  1.1101],\n",
      "        [-1.7854,  1.8595, -0.0262],\n",
      "        [-2.2108,  0.6524,  1.3167]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.3327,  0.0657, -0.9827],\n",
      "        [ 0.2524,  0.2450, -0.8644],\n",
      "        [-1.9344,  1.9978, -0.2653],\n",
      "        [-1.9360,  0.5674,  1.2548],\n",
      "        [-1.7411,  1.4147, -0.0644],\n",
      "        [-1.8682,  1.7943, -0.0561],\n",
      "        [-1.8127,  1.8459, -0.2706],\n",
      "        [-2.0632,  0.6067,  1.2717],\n",
      "        [-2.0395,  1.6848, -0.0637],\n",
      "        [-1.9588,  1.6591,  0.3793],\n",
      "        [-2.1086,  0.8823,  0.9152],\n",
      "        [-0.7738,  0.8656, -0.6944],\n",
      "        [-1.9307,  2.1609, -0.1027],\n",
      "        [-1.9600,  0.6210,  1.1101],\n",
      "        [-1.7854,  1.8595, -0.0262],\n",
      "        [-2.2108,  0.6524,  1.3167]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8503,  2.1632, -0.3697],\n",
      "        [-1.9619,  2.0018, -0.3459],\n",
      "        [-1.9023,  0.5524,  1.0958],\n",
      "        [-1.8129,  1.9542, -0.0871],\n",
      "        [-2.0479,  1.9939, -0.0397],\n",
      "        [-1.9168,  0.5434,  1.1867],\n",
      "        [-2.1185,  0.7769,  1.2364],\n",
      "        [-2.1852,  1.3933,  0.4958],\n",
      "        [-1.8299,  0.9155,  1.1833],\n",
      "        [ 0.3837,  0.1428, -1.0104],\n",
      "        [-1.9828,  1.8744, -0.0676],\n",
      "        [-1.7872,  0.4926,  1.1663],\n",
      "        [-2.1824,  1.4461,  0.7026],\n",
      "        [-1.8039,  2.0001, -0.4501],\n",
      "        [-2.1301,  1.0021,  0.9937],\n",
      "        [-2.1378,  1.0090,  0.9102]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8503,  2.1632, -0.3697],\n",
      "        [-1.9619,  2.0018, -0.3459],\n",
      "        [-1.9023,  0.5524,  1.0958],\n",
      "        [-1.8129,  1.9542, -0.0871],\n",
      "        [-2.0479,  1.9939, -0.0397],\n",
      "        [-1.9168,  0.5434,  1.1867],\n",
      "        [-2.1185,  0.7769,  1.2364],\n",
      "        [-2.1852,  1.3933,  0.4958],\n",
      "        [-1.8299,  0.9155,  1.1833],\n",
      "        [ 0.3837,  0.1428, -1.0104],\n",
      "        [-1.9828,  1.8744, -0.0676],\n",
      "        [-1.7872,  0.4926,  1.1663],\n",
      "        [-2.1824,  1.4461,  0.7026],\n",
      "        [-1.8039,  2.0001, -0.4501],\n",
      "        [-2.1301,  1.0021,  0.9937],\n",
      "        [-2.1378,  1.0090,  0.9102]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7275,  1.7313, -0.0949],\n",
      "        [-1.8180,  1.9753, -0.1340],\n",
      "        [ 0.6250, -0.0320, -1.2301],\n",
      "        [ 0.4423,  0.0029, -1.0949],\n",
      "        [-1.6944,  1.7442, -0.0854],\n",
      "        [-2.0687,  1.9239, -0.0324],\n",
      "        [-2.1088,  0.6882,  1.0593],\n",
      "        [ 0.4419,  0.1162, -1.2379],\n",
      "        [-1.8308,  1.9377, -0.2260],\n",
      "        [-2.2489,  1.8917,  0.0177],\n",
      "        [-1.9923,  0.4695,  1.1762],\n",
      "        [-1.9127,  0.4606,  1.1979],\n",
      "        [-1.8810,  1.9025, -0.0628],\n",
      "        [-1.8478,  1.8017, -0.1080],\n",
      "        [-2.0642,  0.6261,  1.4164],\n",
      "        [-1.9741,  1.9668, -0.2414]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7275,  1.7313, -0.0949],\n",
      "        [-1.8180,  1.9753, -0.1340],\n",
      "        [ 0.6250, -0.0320, -1.2301],\n",
      "        [ 0.4423,  0.0029, -1.0949],\n",
      "        [-1.6944,  1.7442, -0.0854],\n",
      "        [-2.0687,  1.9239, -0.0324],\n",
      "        [-2.1088,  0.6882,  1.0593],\n",
      "        [ 0.4419,  0.1162, -1.2379],\n",
      "        [-1.8308,  1.9377, -0.2260],\n",
      "        [-2.2489,  1.8917,  0.0177],\n",
      "        [-1.9923,  0.4695,  1.1762],\n",
      "        [-1.9127,  0.4606,  1.1979],\n",
      "        [-1.8810,  1.9025, -0.0628],\n",
      "        [-1.8478,  1.8017, -0.1080],\n",
      "        [-2.0642,  0.6261,  1.4164],\n",
      "        [-1.9741,  1.9668, -0.2414]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7809,  2.0295, -0.1052],\n",
      "        [ 0.4364, -0.0335, -1.2444],\n",
      "        [-1.5566,  1.7285, -0.3304],\n",
      "        [-1.7899,  1.9207,  0.0244],\n",
      "        [-2.0351,  0.5662,  1.1117],\n",
      "        [-1.9323,  1.9571, -0.0746],\n",
      "        [-2.0376,  0.5108,  1.1411],\n",
      "        [ 0.2392,  0.1162, -0.9641],\n",
      "        [-1.7159,  1.7684, -0.3854],\n",
      "        [-1.6134,  1.7514,  0.0132],\n",
      "        [-1.8666,  1.9191, -0.2525],\n",
      "        [ 0.4375,  0.1347, -0.9495],\n",
      "        [-2.1186,  0.4415,  1.2985],\n",
      "        [-2.1430,  1.7494, -0.1386],\n",
      "        [-1.8504,  1.7735,  0.0040],\n",
      "        [-1.5533,  1.6128, -0.2640]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7809,  2.0295, -0.1052],\n",
      "        [ 0.4364, -0.0335, -1.2444],\n",
      "        [-1.5566,  1.7285, -0.3304],\n",
      "        [-1.7899,  1.9207,  0.0244],\n",
      "        [-2.0351,  0.5662,  1.1117],\n",
      "        [-1.9323,  1.9571, -0.0746],\n",
      "        [-2.0376,  0.5108,  1.1411],\n",
      "        [ 0.2392,  0.1162, -0.9641],\n",
      "        [-1.7159,  1.7684, -0.3854],\n",
      "        [-1.6134,  1.7514,  0.0132],\n",
      "        [-1.8666,  1.9191, -0.2525],\n",
      "        [ 0.4375,  0.1347, -0.9495],\n",
      "        [-2.1186,  0.4415,  1.2985],\n",
      "        [-2.1430,  1.7494, -0.1386],\n",
      "        [-1.8504,  1.7735,  0.0040],\n",
      "        [-1.5533,  1.6128, -0.2640]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8215,  1.7513, -0.1947],\n",
      "        [ 0.1932,  0.0130, -1.0550],\n",
      "        [-2.0594,  2.1237, -0.0990],\n",
      "        [-1.7716,  1.9001, -0.2644],\n",
      "        [-1.8631,  1.7267, -0.2309],\n",
      "        [-1.8023,  1.7048,  0.0990],\n",
      "        [-2.1135,  0.6028,  1.3238],\n",
      "        [-2.1086,  1.7615, -0.1856],\n",
      "        [-1.7989,  1.8151, -0.1777],\n",
      "        [-1.9772,  1.5553, -0.0837],\n",
      "        [-1.9153,  2.0506, -0.2425],\n",
      "        [-2.0310,  0.7364,  1.2464],\n",
      "        [-2.2202,  1.5177,  0.4931],\n",
      "        [-1.9266,  1.7495, -0.3333],\n",
      "        [-1.9102,  1.8009, -0.2471],\n",
      "        [ 0.6017,  0.0135, -1.2259]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8215,  1.7513, -0.1947],\n",
      "        [ 0.1932,  0.0130, -1.0550],\n",
      "        [-2.0594,  2.1237, -0.0990],\n",
      "        [-1.7716,  1.9001, -0.2644],\n",
      "        [-1.8631,  1.7267, -0.2309],\n",
      "        [-1.8023,  1.7048,  0.0990],\n",
      "        [-2.1135,  0.6028,  1.3238],\n",
      "        [-2.1086,  1.7615, -0.1856],\n",
      "        [-1.7989,  1.8151, -0.1777],\n",
      "        [-1.9772,  1.5553, -0.0837],\n",
      "        [-1.9153,  2.0506, -0.2425],\n",
      "        [-2.0310,  0.7364,  1.2464],\n",
      "        [-2.2202,  1.5177,  0.4931],\n",
      "        [-1.9266,  1.7495, -0.3333],\n",
      "        [-1.9102,  1.8009, -0.2471],\n",
      "        [ 0.6017,  0.0135, -1.2259]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6975,  0.4335,  1.2119],\n",
      "        [-1.9290,  0.5222,  1.2472],\n",
      "        [-1.9679,  1.9639, -0.3437],\n",
      "        [-1.6730,  1.6978, -0.1892],\n",
      "        [-1.8076,  1.7964, -0.3868],\n",
      "        [ 0.2066,  0.5087, -0.9622],\n",
      "        [-1.8121,  0.3997,  1.1456],\n",
      "        [-2.0202,  0.5095,  1.2686],\n",
      "        [-1.5328,  1.6806, -0.3851],\n",
      "        [-2.1234,  0.4300,  1.1480],\n",
      "        [-1.9365,  1.2286,  0.3637],\n",
      "        [-1.8164,  1.9562, -0.2235],\n",
      "        [-2.0357,  1.0766,  0.7682],\n",
      "        [-1.9753,  1.9451, -0.1288],\n",
      "        [-2.1667,  2.2285, -0.0254],\n",
      "        [-1.8376,  1.7090,  0.0773]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6975,  0.4335,  1.2119],\n",
      "        [-1.9290,  0.5222,  1.2472],\n",
      "        [-1.9679,  1.9639, -0.3437],\n",
      "        [-1.6730,  1.6978, -0.1892],\n",
      "        [-1.8076,  1.7964, -0.3868],\n",
      "        [ 0.2066,  0.5087, -0.9622],\n",
      "        [-1.8121,  0.3997,  1.1456],\n",
      "        [-2.0202,  0.5095,  1.2686],\n",
      "        [-1.5328,  1.6806, -0.3851],\n",
      "        [-2.1234,  0.4300,  1.1480],\n",
      "        [-1.9365,  1.2286,  0.3637],\n",
      "        [-1.8164,  1.9562, -0.2235],\n",
      "        [-2.0357,  1.0766,  0.7682],\n",
      "        [-1.9753,  1.9451, -0.1288],\n",
      "        [-2.1667,  2.2285, -0.0254],\n",
      "        [-1.8376,  1.7090,  0.0773]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.4715, -0.0064, -1.1706],\n",
      "        [-2.2563,  1.6240,  0.2857],\n",
      "        [-1.9192,  1.8391, -0.2681],\n",
      "        [-1.9211,  1.6706, -0.3614],\n",
      "        [-2.2233,  1.8817, -0.2774],\n",
      "        [-1.8016,  1.8822, -0.2646],\n",
      "        [ 0.5047,  0.1388, -1.1576],\n",
      "        [-2.0590,  0.4797,  1.2465],\n",
      "        [-1.9451,  2.0281, -0.1788],\n",
      "        [-2.0478,  0.7807,  1.0560],\n",
      "        [-1.8245,  1.4814, -0.0385],\n",
      "        [-1.7613,  1.8244, -0.3424],\n",
      "        [ 0.2713,  0.1487, -1.0883],\n",
      "        [-1.7263,  1.3389,  0.5039],\n",
      "        [-1.8256,  1.8975, -0.2311],\n",
      "        [-1.4520,  1.7376, -0.4782]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.4715, -0.0064, -1.1706],\n",
      "        [-2.2563,  1.6240,  0.2857],\n",
      "        [-1.9192,  1.8391, -0.2681],\n",
      "        [-1.9211,  1.6706, -0.3614],\n",
      "        [-2.2233,  1.8817, -0.2774],\n",
      "        [-1.8016,  1.8822, -0.2646],\n",
      "        [ 0.5047,  0.1388, -1.1576],\n",
      "        [-2.0590,  0.4797,  1.2465],\n",
      "        [-1.9451,  2.0281, -0.1788],\n",
      "        [-2.0478,  0.7807,  1.0560],\n",
      "        [-1.8245,  1.4814, -0.0385],\n",
      "        [-1.7613,  1.8244, -0.3424],\n",
      "        [ 0.2713,  0.1487, -1.0883],\n",
      "        [-1.7263,  1.3389,  0.5039],\n",
      "        [-1.8256,  1.8975, -0.2311],\n",
      "        [-1.4520,  1.7376, -0.4782]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9942,  2.0902, -0.1385],\n",
      "        [-1.8151,  1.8665, -0.3283],\n",
      "        [-1.9723,  0.7737,  1.1359],\n",
      "        [-2.0030,  1.0159,  1.0065],\n",
      "        [-1.9815,  1.9627, -0.2953],\n",
      "        [-2.3292,  1.3103,  0.9692],\n",
      "        [-1.9389,  1.0161,  0.9921],\n",
      "        [-1.7675,  0.6732,  1.3080],\n",
      "        [ 0.6022,  0.1074, -1.1962],\n",
      "        [-1.9939,  0.8230,  1.1158],\n",
      "        [-1.7097,  1.8474, -0.5112],\n",
      "        [-2.0390,  1.8111, -0.1452],\n",
      "        [-2.0634,  0.5636,  1.2759],\n",
      "        [-2.0481,  0.5969,  1.2108],\n",
      "        [-1.8675,  0.4968,  1.3224],\n",
      "        [-1.9135,  2.0842, -0.3527]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9942,  2.0902, -0.1385],\n",
      "        [-1.8151,  1.8665, -0.3283],\n",
      "        [-1.9723,  0.7737,  1.1359],\n",
      "        [-2.0030,  1.0159,  1.0065],\n",
      "        [-1.9815,  1.9627, -0.2953],\n",
      "        [-2.3292,  1.3103,  0.9692],\n",
      "        [-1.9389,  1.0161,  0.9921],\n",
      "        [-1.7675,  0.6732,  1.3080],\n",
      "        [ 0.6022,  0.1074, -1.1962],\n",
      "        [-1.9939,  0.8230,  1.1158],\n",
      "        [-1.7097,  1.8474, -0.5112],\n",
      "        [-2.0390,  1.8111, -0.1452],\n",
      "        [-2.0634,  0.5636,  1.2759],\n",
      "        [-2.0481,  0.5969,  1.2108],\n",
      "        [-1.8675,  0.4968,  1.3224],\n",
      "        [-1.9135,  2.0842, -0.3527]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7980,  1.8182, -0.1999],\n",
      "        [ 0.5378, -0.1084, -1.1419],\n",
      "        [-1.5799,  1.6470, -0.1904],\n",
      "        [ 0.3984,  0.1839, -1.0960],\n",
      "        [-1.9080,  1.8313, -0.3037],\n",
      "        [-1.7530,  1.9266, -0.2786],\n",
      "        [-1.7286,  1.6291, -0.3510],\n",
      "        [-1.9607,  0.6654,  1.2436],\n",
      "        [-2.0890,  2.0549, -0.0959],\n",
      "        [-2.0596,  0.4082,  1.2142],\n",
      "        [-1.8706,  1.6287, -0.3982],\n",
      "        [-1.7543,  0.3972,  1.5293],\n",
      "        [-1.3795,  1.6849, -0.4770],\n",
      "        [-1.9658,  0.6488,  1.1112],\n",
      "        [ 0.3569,  0.2318, -1.1292],\n",
      "        [-1.8302,  0.5873,  1.1921]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7980,  1.8182, -0.1999],\n",
      "        [ 0.5378, -0.1084, -1.1419],\n",
      "        [-1.5799,  1.6470, -0.1904],\n",
      "        [ 0.3984,  0.1839, -1.0960],\n",
      "        [-1.9080,  1.8313, -0.3037],\n",
      "        [-1.7530,  1.9266, -0.2786],\n",
      "        [-1.7286,  1.6291, -0.3510],\n",
      "        [-1.9607,  0.6654,  1.2436],\n",
      "        [-2.0890,  2.0549, -0.0959],\n",
      "        [-2.0596,  0.4082,  1.2142],\n",
      "        [-1.8706,  1.6287, -0.3982],\n",
      "        [-1.7543,  0.3972,  1.5293],\n",
      "        [-1.3795,  1.6849, -0.4770],\n",
      "        [-1.9658,  0.6488,  1.1112],\n",
      "        [ 0.3569,  0.2318, -1.1292],\n",
      "        [-1.8302,  0.5873,  1.1921]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8479,  2.0584, -0.0996],\n",
      "        [ 0.3623,  0.1438, -1.2882],\n",
      "        [-1.9347,  0.6443,  1.1041],\n",
      "        [-1.9370,  0.6789,  1.1821],\n",
      "        [-1.7790,  1.9675, -0.4425],\n",
      "        [-1.7972,  1.9402, -0.1043],\n",
      "        [-1.8331,  1.7018, -0.3202],\n",
      "        [-1.9154,  1.8921, -0.3182],\n",
      "        [-1.9189,  0.6953,  0.9784],\n",
      "        [-1.7494,  0.8724,  0.9901],\n",
      "        [-1.8227,  2.0763, -0.3115],\n",
      "        [-1.9983,  2.0407, -0.3671],\n",
      "        [-1.6868,  0.5475,  1.1710],\n",
      "        [-1.7702,  1.8537, -0.2858],\n",
      "        [-1.9552,  0.4888,  1.2935],\n",
      "        [-1.7566,  1.6489, -0.4958]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8479,  2.0584, -0.0996],\n",
      "        [ 0.3623,  0.1438, -1.2882],\n",
      "        [-1.9347,  0.6443,  1.1041],\n",
      "        [-1.9370,  0.6789,  1.1821],\n",
      "        [-1.7790,  1.9675, -0.4425],\n",
      "        [-1.7972,  1.9402, -0.1043],\n",
      "        [-1.8331,  1.7018, -0.3202],\n",
      "        [-1.9154,  1.8921, -0.3182],\n",
      "        [-1.9189,  0.6953,  0.9784],\n",
      "        [-1.7494,  0.8724,  0.9901],\n",
      "        [-1.8227,  2.0763, -0.3115],\n",
      "        [-1.9983,  2.0407, -0.3671],\n",
      "        [-1.6868,  0.5475,  1.1710],\n",
      "        [-1.7702,  1.8537, -0.2858],\n",
      "        [-1.9552,  0.4888,  1.2935],\n",
      "        [-1.7566,  1.6489, -0.4958]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9307,  2.0363, -0.3245],\n",
      "        [-1.6219,  1.8414, -0.0714],\n",
      "        [-1.9649,  2.1018, -0.2763],\n",
      "        [-1.6731,  1.9228, -0.3601],\n",
      "        [-1.7037,  1.5106,  0.0371],\n",
      "        [ 0.2599,  0.0743, -0.9675],\n",
      "        [ 0.2748,  0.0330, -1.0775],\n",
      "        [-1.7224,  2.1108, -0.2542],\n",
      "        [-1.8804,  0.8747,  0.9933],\n",
      "        [-1.6732,  2.0709, -0.2981],\n",
      "        [-1.6539,  1.8554, -0.4258],\n",
      "        [-1.8355,  0.5844,  0.6613],\n",
      "        [-2.0574,  0.7337,  1.2831],\n",
      "        [-1.4836,  1.8052, -0.6323],\n",
      "        [-1.7690,  1.9873, -0.4126],\n",
      "        [-1.6033,  0.4178,  1.0673]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9307,  2.0363, -0.3245],\n",
      "        [-1.6219,  1.8414, -0.0714],\n",
      "        [-1.9649,  2.1018, -0.2763],\n",
      "        [-1.6731,  1.9228, -0.3601],\n",
      "        [-1.7037,  1.5106,  0.0371],\n",
      "        [ 0.2599,  0.0743, -0.9675],\n",
      "        [ 0.2748,  0.0330, -1.0775],\n",
      "        [-1.7224,  2.1108, -0.2542],\n",
      "        [-1.8804,  0.8747,  0.9933],\n",
      "        [-1.6732,  2.0709, -0.2981],\n",
      "        [-1.6539,  1.8554, -0.4258],\n",
      "        [-1.8355,  0.5844,  0.6613],\n",
      "        [-2.0574,  0.7337,  1.2831],\n",
      "        [-1.4836,  1.8052, -0.6323],\n",
      "        [-1.7690,  1.9873, -0.4126],\n",
      "        [-1.6033,  0.4178,  1.0673]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8083,  1.7724, -0.5149],\n",
      "        [-1.9951,  1.8223, -0.4616],\n",
      "        [-1.7856,  2.1509, -0.2868],\n",
      "        [-1.7153,  1.9446, -0.3100],\n",
      "        [-1.5731,  1.9493, -0.2597],\n",
      "        [-1.5344,  0.4096,  1.0032],\n",
      "        [-1.7836,  0.3695,  1.1569],\n",
      "        [-1.9661,  2.0626, -0.3652],\n",
      "        [ 0.3497,  0.1991, -1.0877],\n",
      "        [-1.8292,  0.3440,  1.0992],\n",
      "        [-1.8191,  2.1167, -0.2409],\n",
      "        [-1.9803,  2.1936, -0.2413],\n",
      "        [-1.6985,  1.7885, -0.1567],\n",
      "        [-2.0966,  0.6443,  1.3144],\n",
      "        [-1.2531,  1.6932, -0.4243],\n",
      "        [-1.7668,  1.6846, -0.3559]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8083,  1.7724, -0.5149],\n",
      "        [-1.9951,  1.8223, -0.4616],\n",
      "        [-1.7856,  2.1509, -0.2868],\n",
      "        [-1.7153,  1.9446, -0.3100],\n",
      "        [-1.5731,  1.9493, -0.2597],\n",
      "        [-1.5344,  0.4096,  1.0032],\n",
      "        [-1.7836,  0.3695,  1.1569],\n",
      "        [-1.9661,  2.0626, -0.3652],\n",
      "        [ 0.3497,  0.1991, -1.0877],\n",
      "        [-1.8292,  0.3440,  1.0992],\n",
      "        [-1.8191,  2.1167, -0.2409],\n",
      "        [-1.9803,  2.1936, -0.2413],\n",
      "        [-1.6985,  1.7885, -0.1567],\n",
      "        [-2.0966,  0.6443,  1.3144],\n",
      "        [-1.2531,  1.6932, -0.4243],\n",
      "        [-1.7668,  1.6846, -0.3559]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7525,  1.9652, -0.3241],\n",
      "        [-1.8975,  0.4272,  1.1395],\n",
      "        [ 0.2629,  0.3665, -1.1191],\n",
      "        [-1.7567,  2.0205, -0.2698],\n",
      "        [-1.7571,  1.9874, -0.3876],\n",
      "        [ 0.1211,  0.1156, -0.8422],\n",
      "        [-1.8915,  1.9172, -0.3969],\n",
      "        [-1.6747,  1.6847, -0.4213],\n",
      "        [-1.6744,  0.3784,  1.1378],\n",
      "        [-1.6920,  1.7475, -0.2400],\n",
      "        [-1.8550,  2.1188, -0.3315],\n",
      "        [-1.9267,  0.5915,  1.1201],\n",
      "        [-1.8264,  1.8960, -0.3748],\n",
      "        [-1.7115,  1.9335, -0.5082],\n",
      "        [-1.7704,  1.8712, -0.0452],\n",
      "        [-1.9056,  0.5679,  0.9822]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7525,  1.9652, -0.3241],\n",
      "        [-1.8975,  0.4272,  1.1395],\n",
      "        [ 0.2629,  0.3665, -1.1191],\n",
      "        [-1.7567,  2.0205, -0.2698],\n",
      "        [-1.7571,  1.9874, -0.3876],\n",
      "        [ 0.1211,  0.1156, -0.8422],\n",
      "        [-1.8915,  1.9172, -0.3969],\n",
      "        [-1.6747,  1.6847, -0.4213],\n",
      "        [-1.6744,  0.3784,  1.1378],\n",
      "        [-1.6920,  1.7475, -0.2400],\n",
      "        [-1.8550,  2.1188, -0.3315],\n",
      "        [-1.9267,  0.5915,  1.1201],\n",
      "        [-1.8264,  1.8960, -0.3748],\n",
      "        [-1.7115,  1.9335, -0.5082],\n",
      "        [-1.7704,  1.8712, -0.0452],\n",
      "        [-1.9056,  0.5679,  0.9822]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8660,  1.8749, -0.5445],\n",
      "        [-1.8426,  0.5804,  1.2778],\n",
      "        [-1.8822,  1.9538, -0.2412],\n",
      "        [-1.8126,  1.9790, -0.4160],\n",
      "        [-1.7901,  2.0532, -0.2859],\n",
      "        [-1.8853,  1.8744, -0.1772],\n",
      "        [ 0.5135,  0.0567, -1.1155],\n",
      "        [-1.3910,  1.5509, -0.4953],\n",
      "        [-1.5115,  1.9066, -0.6829],\n",
      "        [-1.9470,  0.6888,  1.1584],\n",
      "        [-1.7721,  2.0210, -0.4484],\n",
      "        [-1.6924,  1.7740, -0.3983],\n",
      "        [ 0.4272,  0.0373, -1.0885],\n",
      "        [-1.7705,  0.3702,  1.2029],\n",
      "        [-1.7932,  1.7822, -0.4328],\n",
      "        [-1.5846,  1.8354, -0.3797]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8660,  1.8749, -0.5445],\n",
      "        [-1.8426,  0.5804,  1.2778],\n",
      "        [-1.8822,  1.9538, -0.2412],\n",
      "        [-1.8126,  1.9790, -0.4160],\n",
      "        [-1.7901,  2.0532, -0.2859],\n",
      "        [-1.8853,  1.8744, -0.1772],\n",
      "        [ 0.5135,  0.0567, -1.1155],\n",
      "        [-1.3910,  1.5509, -0.4953],\n",
      "        [-1.5115,  1.9066, -0.6829],\n",
      "        [-1.9470,  0.6888,  1.1584],\n",
      "        [-1.7721,  2.0210, -0.4484],\n",
      "        [-1.6924,  1.7740, -0.3983],\n",
      "        [ 0.4272,  0.0373, -1.0885],\n",
      "        [-1.7705,  0.3702,  1.2029],\n",
      "        [-1.7932,  1.7822, -0.4328],\n",
      "        [-1.5846,  1.8354, -0.3797]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6748,  1.9600, -0.4428],\n",
      "        [-1.6248,  0.4356,  1.0657],\n",
      "        [-2.0002,  1.1919,  0.7020],\n",
      "        [-1.6277,  1.8079, -0.4701],\n",
      "        [-1.8650,  1.7775, -0.3249],\n",
      "        [-1.9540,  2.0137, -0.1804],\n",
      "        [-1.7163,  1.8050, -0.1945],\n",
      "        [-2.0278,  1.9535, -0.4901],\n",
      "        [-1.0150,  1.5149, -0.6359],\n",
      "        [-1.8702,  1.8903, -0.2577],\n",
      "        [-1.7972,  1.9464, -0.3362],\n",
      "        [-1.7838,  0.3794,  1.1399],\n",
      "        [-2.0173,  1.7785, -0.3003],\n",
      "        [ 0.2677,  0.1241, -1.2268],\n",
      "        [-1.5758,  1.9435, -0.4023],\n",
      "        [-1.8451,  1.2023,  0.6505]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6748,  1.9600, -0.4428],\n",
      "        [-1.6248,  0.4356,  1.0657],\n",
      "        [-2.0002,  1.1919,  0.7020],\n",
      "        [-1.6277,  1.8079, -0.4701],\n",
      "        [-1.8650,  1.7775, -0.3249],\n",
      "        [-1.9540,  2.0137, -0.1804],\n",
      "        [-1.7163,  1.8050, -0.1945],\n",
      "        [-2.0278,  1.9535, -0.4901],\n",
      "        [-1.0150,  1.5149, -0.6359],\n",
      "        [-1.8702,  1.8903, -0.2577],\n",
      "        [-1.7972,  1.9464, -0.3362],\n",
      "        [-1.7838,  0.3794,  1.1399],\n",
      "        [-2.0173,  1.7785, -0.3003],\n",
      "        [ 0.2677,  0.1241, -1.2268],\n",
      "        [-1.5758,  1.9435, -0.4023],\n",
      "        [-1.8451,  1.2023,  0.6505]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9606,  2.1562, -0.3095],\n",
      "        [-1.6698,  0.5230,  1.1168],\n",
      "        [-2.0048,  1.9029, -0.3187],\n",
      "        [-0.6298,  0.8456, -0.6928],\n",
      "        [-1.9193,  0.6646,  1.1171],\n",
      "        [-1.8636,  1.7973, -0.5010],\n",
      "        [-0.9564,  0.5730,  0.1302],\n",
      "        [-1.6832,  1.7630, -0.1887],\n",
      "        [-1.9827,  2.0621, -0.3679],\n",
      "        [-1.8827,  1.9858, -0.3370],\n",
      "        [-1.7297,  1.8601, -0.5081],\n",
      "        [-2.0898,  1.5150,  0.6650],\n",
      "        [-1.6904,  1.9821, -0.6824],\n",
      "        [-1.7981,  0.7138,  0.9162],\n",
      "        [-2.0074,  2.1407, -0.4088],\n",
      "        [-1.9032,  0.5762,  1.3409]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9606,  2.1562, -0.3095],\n",
      "        [-1.6698,  0.5230,  1.1168],\n",
      "        [-2.0048,  1.9029, -0.3187],\n",
      "        [-0.6298,  0.8456, -0.6928],\n",
      "        [-1.9193,  0.6646,  1.1171],\n",
      "        [-1.8636,  1.7973, -0.5010],\n",
      "        [-0.9564,  0.5730,  0.1302],\n",
      "        [-1.6832,  1.7630, -0.1887],\n",
      "        [-1.9827,  2.0621, -0.3679],\n",
      "        [-1.8827,  1.9858, -0.3370],\n",
      "        [-1.7297,  1.8601, -0.5081],\n",
      "        [-2.0898,  1.5150,  0.6650],\n",
      "        [-1.6904,  1.9821, -0.6824],\n",
      "        [-1.7981,  0.7138,  0.9162],\n",
      "        [-2.0074,  2.1407, -0.4088],\n",
      "        [-1.9032,  0.5762,  1.3409]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.2036,  0.9262,  0.7218],\n",
      "        [-1.7497,  0.4749,  1.1178],\n",
      "        [-1.9861,  1.5614,  0.6529],\n",
      "        [-1.9982,  0.3998,  1.0781],\n",
      "        [-1.9056,  1.9130, -0.3591],\n",
      "        [-1.0480,  1.7295, -0.8152],\n",
      "        [ 0.2646,  0.3166, -1.0304],\n",
      "        [-1.9406,  0.4069,  1.3602],\n",
      "        [ 0.4075,  0.2348, -1.1179],\n",
      "        [-1.7512,  0.4268,  0.9516],\n",
      "        [-2.0296,  1.6191,  0.3028],\n",
      "        [-2.0461,  2.1408, -0.3807],\n",
      "        [-1.7303,  1.9916, -0.3444],\n",
      "        [-1.7037,  1.8755, -0.4344],\n",
      "        [ 0.3611,  0.2053, -1.2159],\n",
      "        [-1.9134,  1.7118, -0.4952]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.2036,  0.9262,  0.7218],\n",
      "        [-1.7497,  0.4749,  1.1178],\n",
      "        [-1.9861,  1.5614,  0.6529],\n",
      "        [-1.9982,  0.3998,  1.0781],\n",
      "        [-1.9056,  1.9130, -0.3591],\n",
      "        [-1.0480,  1.7295, -0.8152],\n",
      "        [ 0.2646,  0.3166, -1.0304],\n",
      "        [-1.9406,  0.4069,  1.3602],\n",
      "        [ 0.4075,  0.2348, -1.1179],\n",
      "        [-1.7512,  0.4268,  0.9516],\n",
      "        [-2.0296,  1.6191,  0.3028],\n",
      "        [-2.0461,  2.1408, -0.3807],\n",
      "        [-1.7303,  1.9916, -0.3444],\n",
      "        [-1.7037,  1.8755, -0.4344],\n",
      "        [ 0.3611,  0.2053, -1.2159],\n",
      "        [-1.9134,  1.7118, -0.4952]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8400,  1.9085, -0.4476],\n",
      "        [ 0.3590,  0.1874, -1.3033],\n",
      "        [-1.7842,  1.9746, -0.2446],\n",
      "        [-1.8644,  2.0313, -0.2448],\n",
      "        [-1.6365,  1.8469, -0.2758],\n",
      "        [-1.8771,  2.0469, -0.0540],\n",
      "        [-1.8565,  0.2294,  1.2499],\n",
      "        [-1.5799,  1.8119, -0.6076],\n",
      "        [-1.9380,  0.4329,  1.0873],\n",
      "        [-2.0572,  0.3752,  1.3735],\n",
      "        [-1.5742,  2.1793, -0.3366],\n",
      "        [-1.7516,  1.7845, -0.4661],\n",
      "        [-1.8871,  2.1306, -0.3173],\n",
      "        [-1.9003,  1.9443, -0.4837],\n",
      "        [-2.0384,  0.4263,  1.2963],\n",
      "        [-1.7777,  2.0657, -0.5315]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8400,  1.9085, -0.4476],\n",
      "        [ 0.3590,  0.1874, -1.3033],\n",
      "        [-1.7842,  1.9746, -0.2446],\n",
      "        [-1.8644,  2.0313, -0.2448],\n",
      "        [-1.6365,  1.8469, -0.2758],\n",
      "        [-1.8771,  2.0469, -0.0540],\n",
      "        [-1.8565,  0.2294,  1.2499],\n",
      "        [-1.5799,  1.8119, -0.6076],\n",
      "        [-1.9380,  0.4329,  1.0873],\n",
      "        [-2.0572,  0.3752,  1.3735],\n",
      "        [-1.5742,  2.1793, -0.3366],\n",
      "        [-1.7516,  1.7845, -0.4661],\n",
      "        [-1.8871,  2.1306, -0.3173],\n",
      "        [-1.9003,  1.9443, -0.4837],\n",
      "        [-2.0384,  0.4263,  1.2963],\n",
      "        [-1.7777,  2.0657, -0.5315]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6279,  0.3681,  0.7816],\n",
      "        [-1.7392,  0.2851,  1.4885],\n",
      "        [-1.7766,  1.9113, -0.3439],\n",
      "        [-1.8943,  2.1135, -0.4690],\n",
      "        [-1.8135,  0.4560,  1.1208],\n",
      "        [ 0.1411,  0.0766, -0.6246],\n",
      "        [-1.9609,  2.0792, -0.5031],\n",
      "        [-1.6989,  1.8595, -0.5281],\n",
      "        [-2.0025,  2.0317, -0.4098],\n",
      "        [-1.7915,  0.8376,  0.5425],\n",
      "        [-1.7606,  2.1153, -0.3894],\n",
      "        [-1.7181,  1.7677, -0.4273],\n",
      "        [ 0.4513,  0.2618, -1.3077],\n",
      "        [-1.8550,  2.1785, -0.5276],\n",
      "        [-1.0710,  1.5008, -0.8776],\n",
      "        [-1.8953,  0.4994,  1.3044]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6279,  0.3681,  0.7816],\n",
      "        [-1.7392,  0.2851,  1.4885],\n",
      "        [-1.7766,  1.9113, -0.3439],\n",
      "        [-1.8943,  2.1135, -0.4690],\n",
      "        [-1.8135,  0.4560,  1.1208],\n",
      "        [ 0.1411,  0.0766, -0.6246],\n",
      "        [-1.9609,  2.0792, -0.5031],\n",
      "        [-1.6989,  1.8595, -0.5281],\n",
      "        [-2.0025,  2.0317, -0.4098],\n",
      "        [-1.7915,  0.8376,  0.5425],\n",
      "        [-1.7606,  2.1153, -0.3894],\n",
      "        [-1.7181,  1.7677, -0.4273],\n",
      "        [ 0.4513,  0.2618, -1.3077],\n",
      "        [-1.8550,  2.1785, -0.5276],\n",
      "        [-1.0710,  1.5008, -0.8776],\n",
      "        [-1.8953,  0.4994,  1.3044]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7692,  2.0139, -0.5853],\n",
      "        [-2.2589,  0.8491,  1.0181],\n",
      "        [-1.6896,  1.8707, -0.5687],\n",
      "        [ 0.1733,  0.4885, -1.2557],\n",
      "        [-1.9978,  1.8205, -0.4790],\n",
      "        [ 0.2456,  0.2832, -1.2197],\n",
      "        [-1.9085,  2.3048, -0.5203],\n",
      "        [-1.5187,  1.8405, -0.3895],\n",
      "        [-1.6126,  1.9507, -0.5983],\n",
      "        [-1.8174,  1.9137, -0.3143],\n",
      "        [-1.6296,  2.1305, -0.3006],\n",
      "        [-1.0601,  0.2419,  0.7057],\n",
      "        [-1.7427,  2.0598, -0.4237],\n",
      "        [ 0.0922,  0.3264, -1.1137],\n",
      "        [ 0.5191,  0.2044, -1.1542],\n",
      "        [ 0.4931,  0.1730, -1.2406]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7692,  2.0139, -0.5853],\n",
      "        [-2.2589,  0.8491,  1.0181],\n",
      "        [-1.6896,  1.8707, -0.5687],\n",
      "        [ 0.1733,  0.4885, -1.2557],\n",
      "        [-1.9978,  1.8205, -0.4790],\n",
      "        [ 0.2456,  0.2832, -1.2197],\n",
      "        [-1.9085,  2.3048, -0.5203],\n",
      "        [-1.5187,  1.8405, -0.3895],\n",
      "        [-1.6126,  1.9507, -0.5983],\n",
      "        [-1.8174,  1.9137, -0.3143],\n",
      "        [-1.6296,  2.1305, -0.3006],\n",
      "        [-1.0601,  0.2419,  0.7057],\n",
      "        [-1.7427,  2.0598, -0.4237],\n",
      "        [ 0.0922,  0.3264, -1.1137],\n",
      "        [ 0.5191,  0.2044, -1.1542],\n",
      "        [ 0.4931,  0.1730, -1.2406]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5252,  1.9213, -0.4386],\n",
      "        [-1.7096,  0.3284,  1.0872],\n",
      "        [-1.8320,  0.3441,  1.2749],\n",
      "        [-1.7152,  2.1213, -0.6461],\n",
      "        [-1.9038,  1.1141,  0.2633],\n",
      "        [-1.8664,  0.2175,  1.2378],\n",
      "        [-1.8154,  0.3972,  1.2893],\n",
      "        [-1.8493,  1.7756, -0.2249],\n",
      "        [-1.6412,  0.4445,  1.0318],\n",
      "        [-1.8875,  1.7912, -0.4217],\n",
      "        [-1.6430,  1.8705, -0.2933],\n",
      "        [-1.8030,  1.8756, -0.5596],\n",
      "        [-1.5716,  0.0380,  1.2243],\n",
      "        [-1.3696,  1.8191, -0.6861],\n",
      "        [-1.7434,  1.8284, -0.5765],\n",
      "        [-1.6973,  2.0750, -0.5175]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5252,  1.9213, -0.4386],\n",
      "        [-1.7096,  0.3284,  1.0872],\n",
      "        [-1.8320,  0.3441,  1.2749],\n",
      "        [-1.7152,  2.1213, -0.6461],\n",
      "        [-1.9038,  1.1141,  0.2633],\n",
      "        [-1.8664,  0.2175,  1.2378],\n",
      "        [-1.8154,  0.3972,  1.2893],\n",
      "        [-1.8493,  1.7756, -0.2249],\n",
      "        [-1.6412,  0.4445,  1.0318],\n",
      "        [-1.8875,  1.7912, -0.4217],\n",
      "        [-1.6430,  1.8705, -0.2933],\n",
      "        [-1.8030,  1.8756, -0.5596],\n",
      "        [-1.5716,  0.0380,  1.2243],\n",
      "        [-1.3696,  1.8191, -0.6861],\n",
      "        [-1.7434,  1.8284, -0.5765],\n",
      "        [-1.6973,  2.0750, -0.5175]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7745,  1.9660, -0.4560],\n",
      "        [-1.7890,  0.5788,  0.9748],\n",
      "        [-1.6745,  1.9331, -0.3726],\n",
      "        [-1.7952,  0.6676,  1.0400],\n",
      "        [-1.8383,  2.2814, -0.1828],\n",
      "        [-1.6925,  1.9567, -0.4894],\n",
      "        [-1.7349,  1.9645, -0.6530],\n",
      "        [ 0.5281,  0.0752, -1.1620],\n",
      "        [-1.5582,  1.8518, -0.6458],\n",
      "        [-1.9488,  2.0139, -0.3065],\n",
      "        [-1.8632,  1.9149, -0.5723],\n",
      "        [-1.6943,  1.9115, -0.4038],\n",
      "        [-1.7650,  2.0306, -0.4803],\n",
      "        [-1.6937,  1.9408, -0.5429],\n",
      "        [ 0.4106,  0.1429, -1.0923],\n",
      "        [-1.5688,  0.4863,  1.2578]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7745,  1.9660, -0.4560],\n",
      "        [-1.7890,  0.5788,  0.9748],\n",
      "        [-1.6745,  1.9331, -0.3726],\n",
      "        [-1.7952,  0.6676,  1.0400],\n",
      "        [-1.8383,  2.2814, -0.1828],\n",
      "        [-1.6925,  1.9567, -0.4894],\n",
      "        [-1.7349,  1.9645, -0.6530],\n",
      "        [ 0.5281,  0.0752, -1.1620],\n",
      "        [-1.5582,  1.8518, -0.6458],\n",
      "        [-1.9488,  2.0139, -0.3065],\n",
      "        [-1.8632,  1.9149, -0.5723],\n",
      "        [-1.6943,  1.9115, -0.4038],\n",
      "        [-1.7650,  2.0306, -0.4803],\n",
      "        [-1.6937,  1.9408, -0.5429],\n",
      "        [ 0.4106,  0.1429, -1.0923],\n",
      "        [-1.5688,  0.4863,  1.2578]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7736,  2.0627, -0.6058],\n",
      "        [-1.8352,  0.2005,  1.3048],\n",
      "        [-1.6112,  2.0560, -0.5609],\n",
      "        [ 0.3491,  0.4007, -1.2989],\n",
      "        [-1.7068,  0.2969,  1.3284],\n",
      "        [-1.7138,  2.1404, -0.8328],\n",
      "        [-1.6378,  0.4053,  1.2730],\n",
      "        [-1.6290,  1.8353, -0.4253],\n",
      "        [-1.7594,  1.8212, -0.4312],\n",
      "        [-1.5416,  1.8649, -0.3969],\n",
      "        [-2.0323,  0.2427,  1.3426],\n",
      "        [-1.8022,  0.4753,  1.0479],\n",
      "        [-1.8517,  1.9885, -0.3742],\n",
      "        [-1.8189,  1.0586,  0.6515],\n",
      "        [-1.5893,  1.7368, -0.5048],\n",
      "        [ 0.4434,  0.1376, -1.1964]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7736,  2.0627, -0.6058],\n",
      "        [-1.8352,  0.2005,  1.3048],\n",
      "        [-1.6112,  2.0560, -0.5609],\n",
      "        [ 0.3491,  0.4007, -1.2989],\n",
      "        [-1.7068,  0.2969,  1.3284],\n",
      "        [-1.7138,  2.1404, -0.8328],\n",
      "        [-1.6378,  0.4053,  1.2730],\n",
      "        [-1.6290,  1.8353, -0.4253],\n",
      "        [-1.7594,  1.8212, -0.4312],\n",
      "        [-1.5416,  1.8649, -0.3969],\n",
      "        [-2.0323,  0.2427,  1.3426],\n",
      "        [-1.8022,  0.4753,  1.0479],\n",
      "        [-1.8517,  1.9885, -0.3742],\n",
      "        [-1.8189,  1.0586,  0.6515],\n",
      "        [-1.5893,  1.7368, -0.5048],\n",
      "        [ 0.4434,  0.1376, -1.1964]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7739,  1.9923, -0.4330],\n",
      "        [-1.6601,  1.8789, -0.6610],\n",
      "        [-1.4216,  1.6801, -0.6932],\n",
      "        [-1.6464,  1.7489, -0.4276],\n",
      "        [-1.7079,  0.2054,  1.2793],\n",
      "        [-1.3162,  1.9006, -0.8569],\n",
      "        [-1.6132,  1.4584,  0.0099],\n",
      "        [-1.5550,  1.8305, -0.8419],\n",
      "        [-1.7375,  0.1700,  1.3359],\n",
      "        [-1.0377,  1.3860, -0.7167],\n",
      "        [ 0.0174,  0.5501, -1.1787],\n",
      "        [-1.7928,  1.6526, -0.1569],\n",
      "        [-1.7193,  0.3138,  1.2413],\n",
      "        [-1.4750,  1.9862, -0.4033],\n",
      "        [-1.6392,  0.3088,  1.1460],\n",
      "        [-1.3113,  1.8278, -0.4939]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7739,  1.9923, -0.4330],\n",
      "        [-1.6601,  1.8789, -0.6610],\n",
      "        [-1.4216,  1.6801, -0.6932],\n",
      "        [-1.6464,  1.7489, -0.4276],\n",
      "        [-1.7079,  0.2054,  1.2793],\n",
      "        [-1.3162,  1.9006, -0.8569],\n",
      "        [-1.6132,  1.4584,  0.0099],\n",
      "        [-1.5550,  1.8305, -0.8419],\n",
      "        [-1.7375,  0.1700,  1.3359],\n",
      "        [-1.0377,  1.3860, -0.7167],\n",
      "        [ 0.0174,  0.5501, -1.1787],\n",
      "        [-1.7928,  1.6526, -0.1569],\n",
      "        [-1.7193,  0.3138,  1.2413],\n",
      "        [-1.4750,  1.9862, -0.4033],\n",
      "        [-1.6392,  0.3088,  1.1460],\n",
      "        [-1.3113,  1.8278, -0.4939]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5794e+00,  1.8629e+00, -6.4519e-01],\n",
      "        [-1.9590e+00,  8.6451e-01,  8.5850e-01],\n",
      "        [-1.6082e+00,  9.3913e-01,  7.6599e-01],\n",
      "        [-1.7271e+00,  1.5440e+00, -3.8058e-02],\n",
      "        [-1.5898e+00,  5.1686e-01,  9.0137e-01],\n",
      "        [-1.2308e+00,  1.6780e+00, -8.7869e-01],\n",
      "        [ 2.0115e-01,  2.4193e-01, -1.3580e+00],\n",
      "        [-5.9021e-01,  1.3048e-03,  1.8510e-01],\n",
      "        [-1.6009e+00,  4.0568e-01,  1.1234e+00],\n",
      "        [-1.8636e-01,  2.1929e-01, -3.8122e-01],\n",
      "        [ 3.4342e-01,  3.2392e-01, -1.1749e+00],\n",
      "        [-1.4418e+00,  2.1783e+00, -7.1542e-01],\n",
      "        [-1.5751e+00,  2.0010e+00, -6.6718e-01],\n",
      "        [-1.7376e+00,  4.2319e-01,  1.1537e+00],\n",
      "        [-1.7375e+00,  2.0880e+00, -3.6358e-01],\n",
      "        [-1.7941e+00,  3.4722e-01,  1.3819e+00]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5794e+00,  1.8629e+00, -6.4519e-01],\n",
      "        [-1.9590e+00,  8.6451e-01,  8.5850e-01],\n",
      "        [-1.6082e+00,  9.3913e-01,  7.6599e-01],\n",
      "        [-1.7271e+00,  1.5440e+00, -3.8058e-02],\n",
      "        [-1.5898e+00,  5.1686e-01,  9.0137e-01],\n",
      "        [-1.2308e+00,  1.6780e+00, -8.7869e-01],\n",
      "        [ 2.0115e-01,  2.4193e-01, -1.3580e+00],\n",
      "        [-5.9021e-01,  1.3048e-03,  1.8510e-01],\n",
      "        [-1.6009e+00,  4.0568e-01,  1.1234e+00],\n",
      "        [-1.8636e-01,  2.1929e-01, -3.8122e-01],\n",
      "        [ 3.4342e-01,  3.2392e-01, -1.1749e+00],\n",
      "        [-1.4418e+00,  2.1783e+00, -7.1542e-01],\n",
      "        [-1.5751e+00,  2.0010e+00, -6.6718e-01],\n",
      "        [-1.7376e+00,  4.2319e-01,  1.1537e+00],\n",
      "        [-1.7375e+00,  2.0880e+00, -3.6358e-01],\n",
      "        [-1.7941e+00,  3.4722e-01,  1.3819e+00]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6248,  2.0606, -0.6565],\n",
      "        [-1.9503,  0.7815,  0.8621],\n",
      "        [-1.6487,  0.4016,  1.0643],\n",
      "        [-1.7697,  1.8451, -0.8832],\n",
      "        [-1.6866,  0.3014,  1.1326],\n",
      "        [-1.5357,  1.7199, -0.5801],\n",
      "        [-1.7184,  0.2217,  1.2624],\n",
      "        [-1.7445,  0.2814,  1.1862],\n",
      "        [-1.7794,  1.9634, -0.4928],\n",
      "        [-1.5544,  0.3562,  1.2622],\n",
      "        [-0.9092,  0.1428,  0.5464],\n",
      "        [-1.6405,  1.1909,  0.2435],\n",
      "        [-1.5503,  2.0247, -0.7061],\n",
      "        [ 0.3406,  0.2806, -1.4682],\n",
      "        [-1.4167,  1.3452,  0.0232],\n",
      "        [-1.6396,  1.7918, -0.4996]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6248,  2.0606, -0.6565],\n",
      "        [-1.9503,  0.7815,  0.8621],\n",
      "        [-1.6487,  0.4016,  1.0643],\n",
      "        [-1.7697,  1.8451, -0.8832],\n",
      "        [-1.6866,  0.3014,  1.1326],\n",
      "        [-1.5357,  1.7199, -0.5801],\n",
      "        [-1.7184,  0.2217,  1.2624],\n",
      "        [-1.7445,  0.2814,  1.1862],\n",
      "        [-1.7794,  1.9634, -0.4928],\n",
      "        [-1.5544,  0.3562,  1.2622],\n",
      "        [-0.9092,  0.1428,  0.5464],\n",
      "        [-1.6405,  1.1909,  0.2435],\n",
      "        [-1.5503,  2.0247, -0.7061],\n",
      "        [ 0.3406,  0.2806, -1.4682],\n",
      "        [-1.4167,  1.3452,  0.0232],\n",
      "        [-1.6396,  1.7918, -0.4996]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3056,  0.2184, -1.1431],\n",
      "        [-1.8521,  0.5970,  1.1491],\n",
      "        [-0.9147,  1.4155, -0.8999],\n",
      "        [-1.5910,  1.7953, -0.4507],\n",
      "        [-1.6338,  0.3119,  0.8881],\n",
      "        [-1.5992,  2.0259, -0.4318],\n",
      "        [-1.8064,  1.5130,  0.1901],\n",
      "        [-1.5522,  1.3344,  0.0151],\n",
      "        [-1.5733, -0.0253,  1.1056],\n",
      "        [-1.5026,  1.8396, -0.5730],\n",
      "        [-1.6040,  0.9658,  0.5994],\n",
      "        [-1.7762,  0.3203,  1.3648],\n",
      "        [-1.6016,  2.2204, -0.8538],\n",
      "        [-1.5378,  1.9459, -0.5111],\n",
      "        [-1.6948,  2.0717, -0.6386],\n",
      "        [-1.4851,  0.0417,  1.2058]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.3056,  0.2184, -1.1431],\n",
      "        [-1.8521,  0.5970,  1.1491],\n",
      "        [-0.9147,  1.4155, -0.8999],\n",
      "        [-1.5910,  1.7953, -0.4507],\n",
      "        [-1.6338,  0.3119,  0.8881],\n",
      "        [-1.5992,  2.0259, -0.4318],\n",
      "        [-1.8064,  1.5130,  0.1901],\n",
      "        [-1.5522,  1.3344,  0.0151],\n",
      "        [-1.5733, -0.0253,  1.1056],\n",
      "        [-1.5026,  1.8396, -0.5730],\n",
      "        [-1.6040,  0.9658,  0.5994],\n",
      "        [-1.7762,  0.3203,  1.3648],\n",
      "        [-1.6016,  2.2204, -0.8538],\n",
      "        [-1.5378,  1.9459, -0.5111],\n",
      "        [-1.6948,  2.0717, -0.6386],\n",
      "        [-1.4851,  0.0417,  1.2058]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2615,  1.7893, -0.6798],\n",
      "        [-1.2038,  0.3943,  0.9898],\n",
      "        [ 0.3647,  0.2040, -1.2812],\n",
      "        [-1.3794,  1.8432, -0.7378],\n",
      "        [-1.4748,  2.0703, -0.4477],\n",
      "        [ 0.4292,  0.2698, -1.1390],\n",
      "        [-1.4523,  1.7731, -0.7638],\n",
      "        [-1.2680,  1.6996, -0.9897],\n",
      "        [-1.6568,  0.9851,  0.9644],\n",
      "        [-0.0494,  0.8286, -1.1555],\n",
      "        [-1.3237,  1.7759, -0.7526],\n",
      "        [-1.6277,  1.7708, -0.3252],\n",
      "        [-1.3630,  1.7443, -0.7142],\n",
      "        [-1.6425,  2.1538, -0.7228],\n",
      "        [-1.4518,  1.7022, -0.5117],\n",
      "        [-1.7142,  0.5255,  1.0116]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.2615,  1.7893, -0.6798],\n",
      "        [-1.2038,  0.3943,  0.9898],\n",
      "        [ 0.3647,  0.2040, -1.2812],\n",
      "        [-1.3794,  1.8432, -0.7378],\n",
      "        [-1.4748,  2.0703, -0.4477],\n",
      "        [ 0.4292,  0.2698, -1.1390],\n",
      "        [-1.4523,  1.7731, -0.7638],\n",
      "        [-1.2680,  1.6996, -0.9897],\n",
      "        [-1.6568,  0.9851,  0.9644],\n",
      "        [-0.0494,  0.8286, -1.1555],\n",
      "        [-1.3237,  1.7759, -0.7526],\n",
      "        [-1.6277,  1.7708, -0.3252],\n",
      "        [-1.3630,  1.7443, -0.7142],\n",
      "        [-1.6425,  2.1538, -0.7228],\n",
      "        [-1.4518,  1.7022, -0.5117],\n",
      "        [-1.7142,  0.5255,  1.0116]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6267,  1.8620, -0.7135],\n",
      "        [-1.7319,  1.9165, -0.8047],\n",
      "        [-1.6068,  1.8157, -0.8278],\n",
      "        [-1.3443,  1.8232, -0.5394],\n",
      "        [ 0.4261,  0.3012, -1.2540],\n",
      "        [-1.6045,  1.8891, -0.5859],\n",
      "        [-1.4978,  0.4510,  0.7023],\n",
      "        [-1.5168,  1.8771, -0.5920],\n",
      "        [-1.3977,  0.5728,  0.8956],\n",
      "        [-1.6626,  1.8852, -0.4590],\n",
      "        [-1.5667,  0.3138,  1.2589],\n",
      "        [-1.5358,  1.7222, -0.6250],\n",
      "        [-0.4269,  0.0951, -0.0748],\n",
      "        [-1.6538,  1.9351, -0.9336],\n",
      "        [ 0.3320,  0.0877, -1.1219],\n",
      "        [-1.7280,  0.5643,  0.8074]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6267,  1.8620, -0.7135],\n",
      "        [-1.7319,  1.9165, -0.8047],\n",
      "        [-1.6068,  1.8157, -0.8278],\n",
      "        [-1.3443,  1.8232, -0.5394],\n",
      "        [ 0.4261,  0.3012, -1.2540],\n",
      "        [-1.6045,  1.8891, -0.5859],\n",
      "        [-1.4978,  0.4510,  0.7023],\n",
      "        [-1.5168,  1.8771, -0.5920],\n",
      "        [-1.3977,  0.5728,  0.8956],\n",
      "        [-1.6626,  1.8852, -0.4590],\n",
      "        [-1.5667,  0.3138,  1.2589],\n",
      "        [-1.5358,  1.7222, -0.6250],\n",
      "        [-0.4269,  0.0951, -0.0748],\n",
      "        [-1.6538,  1.9351, -0.9336],\n",
      "        [ 0.3320,  0.0877, -1.1219],\n",
      "        [-1.7280,  0.5643,  0.8074]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5949,  1.6930, -0.7674],\n",
      "        [-1.7462,  2.0470, -0.6234],\n",
      "        [-1.6251,  0.2798,  1.1876],\n",
      "        [-0.6523,  1.1605, -1.0752],\n",
      "        [-1.2129,  1.4906, -0.7974],\n",
      "        [-1.5819,  0.2393,  1.2834],\n",
      "        [-1.7473,  1.6802, -0.4893],\n",
      "        [-1.4404,  1.7460, -0.6432],\n",
      "        [-1.6423,  0.2522,  1.1973],\n",
      "        [-1.4397,  1.9393, -0.3364],\n",
      "        [-1.7097,  2.2586, -0.6995],\n",
      "        [ 0.4146,  0.2640, -1.1856],\n",
      "        [-1.5266,  1.7317, -0.8354],\n",
      "        [-1.5846,  1.8581, -0.4835],\n",
      "        [-1.4187,  0.2568,  1.1044],\n",
      "        [-1.6695,  1.9573, -0.7799]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5949,  1.6930, -0.7674],\n",
      "        [-1.7462,  2.0470, -0.6234],\n",
      "        [-1.6251,  0.2798,  1.1876],\n",
      "        [-0.6523,  1.1605, -1.0752],\n",
      "        [-1.2129,  1.4906, -0.7974],\n",
      "        [-1.5819,  0.2393,  1.2834],\n",
      "        [-1.7473,  1.6802, -0.4893],\n",
      "        [-1.4404,  1.7460, -0.6432],\n",
      "        [-1.6423,  0.2522,  1.1973],\n",
      "        [-1.4397,  1.9393, -0.3364],\n",
      "        [-1.7097,  2.2586, -0.6995],\n",
      "        [ 0.4146,  0.2640, -1.1856],\n",
      "        [-1.5266,  1.7317, -0.8354],\n",
      "        [-1.5846,  1.8581, -0.4835],\n",
      "        [-1.4187,  0.2568,  1.1044],\n",
      "        [-1.6695,  1.9573, -0.7799]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4103,  1.5968, -0.4879],\n",
      "        [-1.4696,  1.9246, -0.8021],\n",
      "        [-1.4646,  1.3495, -0.1813],\n",
      "        [ 0.4882,  0.1416, -1.2658],\n",
      "        [-1.5987,  2.0709, -0.7942],\n",
      "        [-1.4347,  1.8536, -0.7757],\n",
      "        [-1.3382,  1.7154, -0.8256],\n",
      "        [ 0.7612,  0.0726, -1.4210],\n",
      "        [-1.4080,  1.9100, -0.7227],\n",
      "        [-1.3468,  0.2724,  1.1778],\n",
      "        [ 0.1371, -0.0344, -0.7152],\n",
      "        [ 0.7288,  0.2870, -1.4738],\n",
      "        [-1.6139,  1.6255, -0.5193],\n",
      "        [-1.1176,  1.7535, -0.8651],\n",
      "        [-1.7235,  0.3208,  1.0815],\n",
      "        [-1.7297,  1.5854,  0.0543]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4103,  1.5968, -0.4879],\n",
      "        [-1.4696,  1.9246, -0.8021],\n",
      "        [-1.4646,  1.3495, -0.1813],\n",
      "        [ 0.4882,  0.1416, -1.2658],\n",
      "        [-1.5987,  2.0709, -0.7942],\n",
      "        [-1.4347,  1.8536, -0.7757],\n",
      "        [-1.3382,  1.7154, -0.8256],\n",
      "        [ 0.7612,  0.0726, -1.4210],\n",
      "        [-1.4080,  1.9100, -0.7227],\n",
      "        [-1.3468,  0.2724,  1.1778],\n",
      "        [ 0.1371, -0.0344, -0.7152],\n",
      "        [ 0.7288,  0.2870, -1.4738],\n",
      "        [-1.6139,  1.6255, -0.5193],\n",
      "        [-1.1176,  1.7535, -0.8651],\n",
      "        [-1.7235,  0.3208,  1.0815],\n",
      "        [-1.7297,  1.5854,  0.0543]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.7386,  0.2022, -1.4592],\n",
      "        [-1.3748,  1.6102, -0.4933],\n",
      "        [-1.4840,  0.2022,  0.9567],\n",
      "        [-1.4508,  0.1528,  1.0912],\n",
      "        [-1.5023,  1.9587, -0.7293],\n",
      "        [-1.7127,  2.0166, -0.6973],\n",
      "        [-1.5687,  0.2689,  1.2111],\n",
      "        [-1.6104,  0.0478,  1.2185],\n",
      "        [-1.6073,  2.0078, -0.5508],\n",
      "        [-1.4382,  0.2937,  1.1345],\n",
      "        [-1.6299,  0.2200,  1.1629],\n",
      "        [-1.4824,  1.8311, -0.8161],\n",
      "        [-1.3948,  1.7578, -0.7826],\n",
      "        [ 0.6491,  0.0335, -1.3558],\n",
      "        [-1.2489,  1.6290, -0.6191],\n",
      "        [-1.3132,  1.8084, -0.7679]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.7386,  0.2022, -1.4592],\n",
      "        [-1.3748,  1.6102, -0.4933],\n",
      "        [-1.4840,  0.2022,  0.9567],\n",
      "        [-1.4508,  0.1528,  1.0912],\n",
      "        [-1.5023,  1.9587, -0.7293],\n",
      "        [-1.7127,  2.0166, -0.6973],\n",
      "        [-1.5687,  0.2689,  1.2111],\n",
      "        [-1.6104,  0.0478,  1.2185],\n",
      "        [-1.6073,  2.0078, -0.5508],\n",
      "        [-1.4382,  0.2937,  1.1345],\n",
      "        [-1.6299,  0.2200,  1.1629],\n",
      "        [-1.4824,  1.8311, -0.8161],\n",
      "        [-1.3948,  1.7578, -0.7826],\n",
      "        [ 0.6491,  0.0335, -1.3558],\n",
      "        [-1.2489,  1.6290, -0.6191],\n",
      "        [-1.3132,  1.8084, -0.7679]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3799,  1.7977, -1.0113],\n",
      "        [-1.5380,  0.3352,  1.1703],\n",
      "        [-1.5539,  1.6315, -0.2549],\n",
      "        [ 0.5410,  0.1600, -1.4159],\n",
      "        [-1.2713,  1.8928, -1.0063],\n",
      "        [ 0.4859,  0.0517, -1.0312],\n",
      "        [-1.2688,  1.5800, -0.5714],\n",
      "        [-1.5044,  0.6172,  0.5374],\n",
      "        [-1.5221,  1.8660, -0.8490],\n",
      "        [-1.4664,  0.2288,  1.0059],\n",
      "        [-1.4556,  1.8418, -0.5898],\n",
      "        [-1.5388,  1.9072, -0.6873],\n",
      "        [-1.7716,  1.2250,  0.1851],\n",
      "        [-1.3570,  0.2108,  1.0871],\n",
      "        [-1.3364,  0.3857,  0.9022],\n",
      "        [-1.2440,  1.6420, -0.6525]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3799,  1.7977, -1.0113],\n",
      "        [-1.5380,  0.3352,  1.1703],\n",
      "        [-1.5539,  1.6315, -0.2549],\n",
      "        [ 0.5410,  0.1600, -1.4159],\n",
      "        [-1.2713,  1.8928, -1.0063],\n",
      "        [ 0.4859,  0.0517, -1.0312],\n",
      "        [-1.2688,  1.5800, -0.5714],\n",
      "        [-1.5044,  0.6172,  0.5374],\n",
      "        [-1.5221,  1.8660, -0.8490],\n",
      "        [-1.4664,  0.2288,  1.0059],\n",
      "        [-1.4556,  1.8418, -0.5898],\n",
      "        [-1.5388,  1.9072, -0.6873],\n",
      "        [-1.7716,  1.2250,  0.1851],\n",
      "        [-1.3570,  0.2108,  1.0871],\n",
      "        [-1.3364,  0.3857,  0.9022],\n",
      "        [-1.2440,  1.6420, -0.6525]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5203,  2.0591, -0.7262],\n",
      "        [-1.3530,  1.7454, -0.3023],\n",
      "        [-1.6462,  0.3273,  1.1934],\n",
      "        [ 0.4648,  0.0441, -0.8740],\n",
      "        [-1.3356,  1.7325, -0.5925],\n",
      "        [-1.5208,  0.1323,  1.0710],\n",
      "        [ 0.4730,  0.1952, -1.4075],\n",
      "        [ 0.3835,  0.2111, -1.1877],\n",
      "        [ 0.5203,  0.1691, -1.4886],\n",
      "        [-1.3490,  1.6457, -0.5763],\n",
      "        [-1.3452,  1.9406, -0.7232],\n",
      "        [-1.4545,  0.3666,  1.0590],\n",
      "        [-1.6455,  0.3589,  1.2902],\n",
      "        [-1.5157,  0.4307,  1.0527],\n",
      "        [-1.1476,  1.7973, -0.4372],\n",
      "        [-0.5398,  0.9738, -0.7616]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5203,  2.0591, -0.7262],\n",
      "        [-1.3530,  1.7454, -0.3023],\n",
      "        [-1.6462,  0.3273,  1.1934],\n",
      "        [ 0.4648,  0.0441, -0.8740],\n",
      "        [-1.3356,  1.7325, -0.5925],\n",
      "        [-1.5208,  0.1323,  1.0710],\n",
      "        [ 0.4730,  0.1952, -1.4075],\n",
      "        [ 0.3835,  0.2111, -1.1877],\n",
      "        [ 0.5203,  0.1691, -1.4886],\n",
      "        [-1.3490,  1.6457, -0.5763],\n",
      "        [-1.3452,  1.9406, -0.7232],\n",
      "        [-1.4545,  0.3666,  1.0590],\n",
      "        [-1.6455,  0.3589,  1.2902],\n",
      "        [-1.5157,  0.4307,  1.0527],\n",
      "        [-1.1476,  1.7973, -0.4372],\n",
      "        [-0.5398,  0.9738, -0.7616]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3825,  0.1172,  1.0562],\n",
      "        [-1.4655,  1.8026, -0.6624],\n",
      "        [-1.4372,  1.6030, -0.3759],\n",
      "        [-1.3615,  1.7861, -0.7011],\n",
      "        [-1.3567,  1.6605, -0.6606],\n",
      "        [-1.2777,  0.2590,  1.3349],\n",
      "        [-1.2351,  1.7134, -0.5503],\n",
      "        [-1.4489,  2.0403, -0.6365],\n",
      "        [ 0.5084,  0.2767, -1.4762],\n",
      "        [-1.4086,  0.1320,  1.1090],\n",
      "        [-1.5139,  0.0936,  1.2530],\n",
      "        [-1.4328,  2.0239, -0.6811],\n",
      "        [-1.2275,  1.8282, -0.4705],\n",
      "        [-1.3115,  1.6697, -0.4534],\n",
      "        [-1.6287,  1.2476, -0.0276],\n",
      "        [-1.6095,  1.9414, -0.7518]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3825,  0.1172,  1.0562],\n",
      "        [-1.4655,  1.8026, -0.6624],\n",
      "        [-1.4372,  1.6030, -0.3759],\n",
      "        [-1.3615,  1.7861, -0.7011],\n",
      "        [-1.3567,  1.6605, -0.6606],\n",
      "        [-1.2777,  0.2590,  1.3349],\n",
      "        [-1.2351,  1.7134, -0.5503],\n",
      "        [-1.4489,  2.0403, -0.6365],\n",
      "        [ 0.5084,  0.2767, -1.4762],\n",
      "        [-1.4086,  0.1320,  1.1090],\n",
      "        [-1.5139,  0.0936,  1.2530],\n",
      "        [-1.4328,  2.0239, -0.6811],\n",
      "        [-1.2275,  1.8282, -0.4705],\n",
      "        [-1.3115,  1.6697, -0.4534],\n",
      "        [-1.6287,  1.2476, -0.0276],\n",
      "        [-1.6095,  1.9414, -0.7518]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.3109,  0.0459, -0.1618],\n",
      "        [ 0.6676,  0.1048, -1.5207],\n",
      "        [-1.3157,  1.6943, -0.5320],\n",
      "        [-1.3887,  1.6967, -0.6819],\n",
      "        [ 0.6619,  0.1586, -1.3338],\n",
      "        [-1.1960,  1.5851, -1.0348],\n",
      "        [-1.4252,  1.8601, -0.6515],\n",
      "        [-0.9092,  0.8444, -0.2248],\n",
      "        [-1.3498,  1.5254, -0.4306],\n",
      "        [-1.1085,  1.6578, -0.5767],\n",
      "        [-1.6576,  0.1724,  1.1046],\n",
      "        [ 0.5225,  0.2775, -1.6163],\n",
      "        [-1.5592,  1.4310,  0.1022],\n",
      "        [ 0.5173,  0.0580, -1.1858],\n",
      "        [-1.2131,  1.5440, -0.6539],\n",
      "        [ 0.5941,  0.1345, -1.1727]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-0.3109,  0.0459, -0.1618],\n",
      "        [ 0.6676,  0.1048, -1.5207],\n",
      "        [-1.3157,  1.6943, -0.5320],\n",
      "        [-1.3887,  1.6967, -0.6819],\n",
      "        [ 0.6619,  0.1586, -1.3338],\n",
      "        [-1.1960,  1.5851, -1.0348],\n",
      "        [-1.4252,  1.8601, -0.6515],\n",
      "        [-0.9092,  0.8444, -0.2248],\n",
      "        [-1.3498,  1.5254, -0.4306],\n",
      "        [-1.1085,  1.6578, -0.5767],\n",
      "        [-1.6576,  0.1724,  1.1046],\n",
      "        [ 0.5225,  0.2775, -1.6163],\n",
      "        [-1.5592,  1.4310,  0.1022],\n",
      "        [ 0.5173,  0.0580, -1.1858],\n",
      "        [-1.2131,  1.5440, -0.6539],\n",
      "        [ 0.5941,  0.1345, -1.1727]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.1355,  1.6822, -0.5649],\n",
      "        [ 0.6089,  0.2918, -1.3596],\n",
      "        [-1.5807,  1.8587, -0.6396],\n",
      "        [ 0.6209,  0.0448, -1.4529],\n",
      "        [-1.2228,  0.2301,  0.8638],\n",
      "        [-1.2344,  1.8206, -0.8925],\n",
      "        [-1.6178,  0.1937,  1.0392],\n",
      "        [-1.6848,  0.2575,  1.5137],\n",
      "        [-1.5763,  0.1411,  1.3872],\n",
      "        [-1.3950,  1.7899, -0.4985],\n",
      "        [ 0.5028,  0.2712, -1.4927],\n",
      "        [-1.3119,  1.7029, -0.8379],\n",
      "        [-1.2231,  1.5961, -0.9040],\n",
      "        [-1.2467,  1.5311, -0.8807],\n",
      "        [-0.0410,  0.6381, -1.2448],\n",
      "        [-1.0969,  0.0939,  1.1210]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.1355,  1.6822, -0.5649],\n",
      "        [ 0.6089,  0.2918, -1.3596],\n",
      "        [-1.5807,  1.8587, -0.6396],\n",
      "        [ 0.6209,  0.0448, -1.4529],\n",
      "        [-1.2228,  0.2301,  0.8638],\n",
      "        [-1.2344,  1.8206, -0.8925],\n",
      "        [-1.6178,  0.1937,  1.0392],\n",
      "        [-1.6848,  0.2575,  1.5137],\n",
      "        [-1.5763,  0.1411,  1.3872],\n",
      "        [-1.3950,  1.7899, -0.4985],\n",
      "        [ 0.5028,  0.2712, -1.4927],\n",
      "        [-1.3119,  1.7029, -0.8379],\n",
      "        [-1.2231,  1.5961, -0.9040],\n",
      "        [-1.2467,  1.5311, -0.8807],\n",
      "        [-0.0410,  0.6381, -1.2448],\n",
      "        [-1.0969,  0.0939,  1.1210]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.1015, -0.0791, -0.5682],\n",
      "        [-1.4496,  1.2071,  0.2258],\n",
      "        [-1.2926,  1.7848, -0.6999],\n",
      "        [-1.3898,  2.0598, -0.6635],\n",
      "        [-1.0368,  1.4346, -0.6629],\n",
      "        [-1.4257,  1.9277, -0.6955],\n",
      "        [-1.4471,  0.1549,  1.0357],\n",
      "        [-1.6673, -0.0069,  1.1014],\n",
      "        [-1.3951,  1.8729, -0.9035],\n",
      "        [-1.4167,  1.4086, -0.0978],\n",
      "        [-0.9548,  1.5123, -0.9383],\n",
      "        [-1.4987,  0.2732,  1.2893],\n",
      "        [ 0.0832,  0.0072, -0.5108],\n",
      "        [-0.2035,  0.6087, -0.6282],\n",
      "        [-1.4877,  1.8677, -0.7819],\n",
      "        [ 0.4547,  0.0710, -1.1075]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.1015, -0.0791, -0.5682],\n",
      "        [-1.4496,  1.2071,  0.2258],\n",
      "        [-1.2926,  1.7848, -0.6999],\n",
      "        [-1.3898,  2.0598, -0.6635],\n",
      "        [-1.0368,  1.4346, -0.6629],\n",
      "        [-1.4257,  1.9277, -0.6955],\n",
      "        [-1.4471,  0.1549,  1.0357],\n",
      "        [-1.6673, -0.0069,  1.1014],\n",
      "        [-1.3951,  1.8729, -0.9035],\n",
      "        [-1.4167,  1.4086, -0.0978],\n",
      "        [-0.9548,  1.5123, -0.9383],\n",
      "        [-1.4987,  0.2732,  1.2893],\n",
      "        [ 0.0832,  0.0072, -0.5108],\n",
      "        [-0.2035,  0.6087, -0.6282],\n",
      "        [-1.4877,  1.8677, -0.7819],\n",
      "        [ 0.4547,  0.0710, -1.1075]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4335,  1.7635, -0.5781],\n",
      "        [-1.5403,  0.2028,  1.1485],\n",
      "        [-1.4440,  1.7070, -0.5265],\n",
      "        [-0.9745,  1.2578, -0.8592],\n",
      "        [ 0.5543,  0.2315, -1.5743],\n",
      "        [-1.3201,  0.0085,  0.9301],\n",
      "        [-1.4946,  0.2491,  1.3389],\n",
      "        [-1.4221,  1.7834, -0.5965],\n",
      "        [ 0.3228,  0.1199, -1.3126],\n",
      "        [-1.2369,  1.6792, -1.0019],\n",
      "        [-1.2454,  1.9459, -0.5557],\n",
      "        [-1.3725,  0.0991,  0.7948],\n",
      "        [-1.4357,  1.4610, -0.6780],\n",
      "        [-1.1522,  1.7738, -0.9735],\n",
      "        [-1.5170,  1.5769, -0.6222],\n",
      "        [-1.6086,  1.3311, -0.0306]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4335,  1.7635, -0.5781],\n",
      "        [-1.5403,  0.2028,  1.1485],\n",
      "        [-1.4440,  1.7070, -0.5265],\n",
      "        [-0.9745,  1.2578, -0.8592],\n",
      "        [ 0.5543,  0.2315, -1.5743],\n",
      "        [-1.3201,  0.0085,  0.9301],\n",
      "        [-1.4946,  0.2491,  1.3389],\n",
      "        [-1.4221,  1.7834, -0.5965],\n",
      "        [ 0.3228,  0.1199, -1.3126],\n",
      "        [-1.2369,  1.6792, -1.0019],\n",
      "        [-1.2454,  1.9459, -0.5557],\n",
      "        [-1.3725,  0.0991,  0.7948],\n",
      "        [-1.4357,  1.4610, -0.6780],\n",
      "        [-1.1522,  1.7738, -0.9735],\n",
      "        [-1.5170,  1.5769, -0.6222],\n",
      "        [-1.6086,  1.3311, -0.0306]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.1963,  1.6856, -0.9892],\n",
      "        [-1.0162,  1.6072, -0.7000],\n",
      "        [-1.5281,  0.4235,  1.1448],\n",
      "        [-1.4515,  1.2750, -0.0723],\n",
      "        [-1.5489,  0.1243,  1.2082],\n",
      "        [-1.4524,  1.8045, -0.6957],\n",
      "        [ 0.5931, -0.0659, -1.2501],\n",
      "        [-1.3880,  1.7025, -0.8101],\n",
      "        [-1.7663,  0.3079,  1.0794],\n",
      "        [-1.5552, -0.0114,  1.2546],\n",
      "        [-1.3326,  1.6581, -0.6018],\n",
      "        [ 0.6136,  0.0422, -1.3259],\n",
      "        [-1.4624,  0.3513,  1.0680],\n",
      "        [-1.6199,  1.5937, -0.3617],\n",
      "        [-1.2831,  1.7142, -0.5520],\n",
      "        [ 0.1179,  0.5671, -1.3170]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.1963,  1.6856, -0.9892],\n",
      "        [-1.0162,  1.6072, -0.7000],\n",
      "        [-1.5281,  0.4235,  1.1448],\n",
      "        [-1.4515,  1.2750, -0.0723],\n",
      "        [-1.5489,  0.1243,  1.2082],\n",
      "        [-1.4524,  1.8045, -0.6957],\n",
      "        [ 0.5931, -0.0659, -1.2501],\n",
      "        [-1.3880,  1.7025, -0.8101],\n",
      "        [-1.7663,  0.3079,  1.0794],\n",
      "        [-1.5552, -0.0114,  1.2546],\n",
      "        [-1.3326,  1.6581, -0.6018],\n",
      "        [ 0.6136,  0.0422, -1.3259],\n",
      "        [-1.4624,  0.3513,  1.0680],\n",
      "        [-1.6199,  1.5937, -0.3617],\n",
      "        [-1.2831,  1.7142, -0.5520],\n",
      "        [ 0.1179,  0.5671, -1.3170]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2922,  1.8358, -0.6134],\n",
      "        [-1.6285,  0.2551,  1.1264],\n",
      "        [-1.6143,  0.3443,  1.2313],\n",
      "        [-1.7885,  0.2591,  1.4378],\n",
      "        [ 0.5870,  0.2995, -1.4366],\n",
      "        [-1.3282,  1.7712, -0.4586],\n",
      "        [-1.4702,  0.6737,  0.8617],\n",
      "        [-1.6681,  0.0759,  1.0732],\n",
      "        [ 0.1928,  0.1152, -0.7015],\n",
      "        [-1.5291,  0.7131,  0.6849],\n",
      "        [-1.3426,  1.6842, -0.6255],\n",
      "        [-1.6015,  1.4460, -0.3200],\n",
      "        [ 0.5159, -0.0474, -0.8355],\n",
      "        [-1.2997,  1.9418, -0.7393],\n",
      "        [-1.3190,  1.6278, -0.7281],\n",
      "        [-1.4806,  1.8468, -0.9451]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.2922,  1.8358, -0.6134],\n",
      "        [-1.6285,  0.2551,  1.1264],\n",
      "        [-1.6143,  0.3443,  1.2313],\n",
      "        [-1.7885,  0.2591,  1.4378],\n",
      "        [ 0.5870,  0.2995, -1.4366],\n",
      "        [-1.3282,  1.7712, -0.4586],\n",
      "        [-1.4702,  0.6737,  0.8617],\n",
      "        [-1.6681,  0.0759,  1.0732],\n",
      "        [ 0.1928,  0.1152, -0.7015],\n",
      "        [-1.5291,  0.7131,  0.6849],\n",
      "        [-1.3426,  1.6842, -0.6255],\n",
      "        [-1.6015,  1.4460, -0.3200],\n",
      "        [ 0.5159, -0.0474, -0.8355],\n",
      "        [-1.2997,  1.9418, -0.7393],\n",
      "        [-1.3190,  1.6278, -0.7281],\n",
      "        [-1.4806,  1.8468, -0.9451]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2417,  1.5254, -0.9294],\n",
      "        [-1.2228,  1.5149, -0.9639],\n",
      "        [ 0.4531,  0.1601, -1.3969],\n",
      "        [-0.8141,  1.3136, -0.9984],\n",
      "        [-1.7057,  0.2720,  1.3606],\n",
      "        [-1.6049,  0.3677,  1.0359],\n",
      "        [-1.7258,  0.3267,  1.1487],\n",
      "        [-1.3552,  1.7970, -0.6789],\n",
      "        [-1.3838,  1.5128, -0.2224],\n",
      "        [ 0.6595,  0.0516, -1.2853],\n",
      "        [-1.5329,  0.1892,  1.1852],\n",
      "        [-1.2697,  1.4817, -0.7771],\n",
      "        [-1.2882,  1.9728, -0.7061],\n",
      "        [-1.4143,  1.8137, -0.3308],\n",
      "        [-1.7480,  0.7784,  0.6155],\n",
      "        [-1.1486,  1.5877, -0.9659]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.2417,  1.5254, -0.9294],\n",
      "        [-1.2228,  1.5149, -0.9639],\n",
      "        [ 0.4531,  0.1601, -1.3969],\n",
      "        [-0.8141,  1.3136, -0.9984],\n",
      "        [-1.7057,  0.2720,  1.3606],\n",
      "        [-1.6049,  0.3677,  1.0359],\n",
      "        [-1.7258,  0.3267,  1.1487],\n",
      "        [-1.3552,  1.7970, -0.6789],\n",
      "        [-1.3838,  1.5128, -0.2224],\n",
      "        [ 0.6595,  0.0516, -1.2853],\n",
      "        [-1.5329,  0.1892,  1.1852],\n",
      "        [-1.2697,  1.4817, -0.7771],\n",
      "        [-1.2882,  1.9728, -0.7061],\n",
      "        [-1.4143,  1.8137, -0.3308],\n",
      "        [-1.7480,  0.7784,  0.6155],\n",
      "        [-1.1486,  1.5877, -0.9659]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4576e+00,  1.6023e+00, -4.6419e-01],\n",
      "        [-1.4374e+00,  1.8897e+00, -8.0234e-01],\n",
      "        [-7.1400e-01,  1.3387e+00, -1.0870e+00],\n",
      "        [ 6.6748e-01, -4.6221e-04, -1.2090e+00],\n",
      "        [-1.4645e+00,  4.8635e-01,  8.4276e-01],\n",
      "        [-1.4161e+00,  1.0349e-01,  1.0789e+00],\n",
      "        [-1.6499e+00,  1.4696e+00, -2.0077e-01],\n",
      "        [ 7.4780e-01, -8.8378e-02, -1.2785e+00],\n",
      "        [-1.3939e+00,  3.6623e-01,  9.5069e-01],\n",
      "        [-1.5226e+00,  4.3630e-01,  1.0196e+00],\n",
      "        [-1.5382e+00,  1.9669e+00, -6.1502e-01],\n",
      "        [-1.4587e+00,  1.7122e+00, -5.5338e-01],\n",
      "        [-1.4192e+00,  1.5667e+00, -4.3115e-01],\n",
      "        [-1.4178e+00,  1.9538e+00, -7.9360e-01],\n",
      "        [ 3.7171e-01, -3.9997e-02, -1.0199e+00],\n",
      "        [-1.4638e+00,  1.8624e+00, -3.9297e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4576e+00,  1.6023e+00, -4.6419e-01],\n",
      "        [-1.4374e+00,  1.8897e+00, -8.0234e-01],\n",
      "        [-7.1400e-01,  1.3387e+00, -1.0870e+00],\n",
      "        [ 6.6748e-01, -4.6221e-04, -1.2090e+00],\n",
      "        [-1.4645e+00,  4.8635e-01,  8.4276e-01],\n",
      "        [-1.4161e+00,  1.0349e-01,  1.0789e+00],\n",
      "        [-1.6499e+00,  1.4696e+00, -2.0077e-01],\n",
      "        [ 7.4780e-01, -8.8378e-02, -1.2785e+00],\n",
      "        [-1.3939e+00,  3.6623e-01,  9.5069e-01],\n",
      "        [-1.5226e+00,  4.3630e-01,  1.0196e+00],\n",
      "        [-1.5382e+00,  1.9669e+00, -6.1502e-01],\n",
      "        [-1.4587e+00,  1.7122e+00, -5.5338e-01],\n",
      "        [-1.4192e+00,  1.5667e+00, -4.3115e-01],\n",
      "        [-1.4178e+00,  1.9538e+00, -7.9360e-01],\n",
      "        [ 3.7171e-01, -3.9997e-02, -1.0199e+00],\n",
      "        [-1.4638e+00,  1.8624e+00, -3.9297e-01]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3417,  1.5446, -0.7654],\n",
      "        [-1.0413,  0.6375,  0.0790],\n",
      "        [-1.2326,  0.9455,  0.4509],\n",
      "        [-1.4941,  1.5653, -0.3333],\n",
      "        [-1.1577,  1.4745, -0.6995],\n",
      "        [-0.4568, -0.0374,  0.1467],\n",
      "        [-1.3641,  1.8431, -0.8884],\n",
      "        [-0.8789,  1.6239, -0.8672],\n",
      "        [-1.1156,  1.4702, -0.8861],\n",
      "        [-1.4716,  0.3078,  1.0065],\n",
      "        [-1.7929,  1.5155, -0.0893],\n",
      "        [-1.4712,  0.3598,  1.0195],\n",
      "        [-1.4171,  0.8029,  0.4586],\n",
      "        [-1.4813,  0.3320,  1.1267],\n",
      "        [ 0.6059,  0.0780, -1.0289],\n",
      "        [-1.2983,  1.8623, -0.9578]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3417,  1.5446, -0.7654],\n",
      "        [-1.0413,  0.6375,  0.0790],\n",
      "        [-1.2326,  0.9455,  0.4509],\n",
      "        [-1.4941,  1.5653, -0.3333],\n",
      "        [-1.1577,  1.4745, -0.6995],\n",
      "        [-0.4568, -0.0374,  0.1467],\n",
      "        [-1.3641,  1.8431, -0.8884],\n",
      "        [-0.8789,  1.6239, -0.8672],\n",
      "        [-1.1156,  1.4702, -0.8861],\n",
      "        [-1.4716,  0.3078,  1.0065],\n",
      "        [-1.7929,  1.5155, -0.0893],\n",
      "        [-1.4712,  0.3598,  1.0195],\n",
      "        [-1.4171,  0.8029,  0.4586],\n",
      "        [-1.4813,  0.3320,  1.1267],\n",
      "        [ 0.6059,  0.0780, -1.0289],\n",
      "        [-1.2983,  1.8623, -0.9578]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.2119,  0.2462, -0.6488],\n",
      "        [-1.2307,  1.7435, -0.7185],\n",
      "        [-1.5547,  0.3314,  1.0488],\n",
      "        [-1.6391,  0.0851,  1.0881],\n",
      "        [ 0.5907,  0.2001, -1.5641],\n",
      "        [-1.2549,  2.0748, -0.7728],\n",
      "        [-1.1399,  0.3910,  0.4040],\n",
      "        [-1.8637,  0.4306,  1.2083],\n",
      "        [-1.3443,  1.8161, -0.6816],\n",
      "        [ 0.4937,  0.0664, -1.4163],\n",
      "        [-1.4613,  0.3224,  1.1623],\n",
      "        [-1.3855,  0.2755,  1.0289],\n",
      "        [-1.2958,  1.9038, -0.6679],\n",
      "        [ 0.2600,  0.1553, -0.9980],\n",
      "        [ 0.5854,  0.1408, -1.2969],\n",
      "        [-1.6955,  0.5448,  1.1167]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.2119,  0.2462, -0.6488],\n",
      "        [-1.2307,  1.7435, -0.7185],\n",
      "        [-1.5547,  0.3314,  1.0488],\n",
      "        [-1.6391,  0.0851,  1.0881],\n",
      "        [ 0.5907,  0.2001, -1.5641],\n",
      "        [-1.2549,  2.0748, -0.7728],\n",
      "        [-1.1399,  0.3910,  0.4040],\n",
      "        [-1.8637,  0.4306,  1.2083],\n",
      "        [-1.3443,  1.8161, -0.6816],\n",
      "        [ 0.4937,  0.0664, -1.4163],\n",
      "        [-1.4613,  0.3224,  1.1623],\n",
      "        [-1.3855,  0.2755,  1.0289],\n",
      "        [-1.2958,  1.9038, -0.6679],\n",
      "        [ 0.2600,  0.1553, -0.9980],\n",
      "        [ 0.5854,  0.1408, -1.2969],\n",
      "        [-1.6955,  0.5448,  1.1167]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3755,  2.1426, -0.8591],\n",
      "        [-1.7024,  0.1977,  1.0209],\n",
      "        [-1.0998,  1.6850, -0.9508],\n",
      "        [-1.3143,  1.9514, -0.8515],\n",
      "        [-1.4665,  1.9895, -0.8096],\n",
      "        [-1.6457,  1.0588,  0.3451],\n",
      "        [-1.5638,  0.3388,  1.0461],\n",
      "        [-1.3785,  1.0428, -0.4493],\n",
      "        [ 0.6410,  0.0329, -1.2636],\n",
      "        [-1.4141,  1.3365, -0.0209],\n",
      "        [-1.4173,  2.0378, -0.8283],\n",
      "        [-1.4215,  1.7516, -0.7433],\n",
      "        [-1.8719,  0.3129,  1.1311],\n",
      "        [-1.3583,  1.7656, -0.9557],\n",
      "        [-1.5827,  0.4618,  1.0369],\n",
      "        [-1.5609,  1.9494, -0.8546]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3755,  2.1426, -0.8591],\n",
      "        [-1.7024,  0.1977,  1.0209],\n",
      "        [-1.0998,  1.6850, -0.9508],\n",
      "        [-1.3143,  1.9514, -0.8515],\n",
      "        [-1.4665,  1.9895, -0.8096],\n",
      "        [-1.6457,  1.0588,  0.3451],\n",
      "        [-1.5638,  0.3388,  1.0461],\n",
      "        [-1.3785,  1.0428, -0.4493],\n",
      "        [ 0.6410,  0.0329, -1.2636],\n",
      "        [-1.4141,  1.3365, -0.0209],\n",
      "        [-1.4173,  2.0378, -0.8283],\n",
      "        [-1.4215,  1.7516, -0.7433],\n",
      "        [-1.8719,  0.3129,  1.1311],\n",
      "        [-1.3583,  1.7656, -0.9557],\n",
      "        [-1.5827,  0.4618,  1.0369],\n",
      "        [-1.5609,  1.9494, -0.8546]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4001,  0.8245,  0.2342],\n",
      "        [-0.9884,  1.0375, -0.1934],\n",
      "        [-1.1506,  1.7707, -0.7433],\n",
      "        [ 0.6634,  0.0987, -1.3583],\n",
      "        [ 0.6583,  0.0432, -1.5128],\n",
      "        [-1.7133,  0.4065,  1.1457],\n",
      "        [-1.4811,  0.5848,  1.0255],\n",
      "        [-1.5753,  0.4754,  0.9027],\n",
      "        [-1.5132,  0.4566,  1.1696],\n",
      "        [-1.5420,  1.5131, -0.0022],\n",
      "        [-1.7295,  0.6379,  0.8780],\n",
      "        [-1.7792,  1.8856, -0.3966],\n",
      "        [-1.4436,  2.0058, -0.8524],\n",
      "        [-1.3278,  1.8070, -0.9900],\n",
      "        [-1.5218,  1.8683, -0.6019],\n",
      "        [-1.6504,  0.1922,  1.0569]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4001,  0.8245,  0.2342],\n",
      "        [-0.9884,  1.0375, -0.1934],\n",
      "        [-1.1506,  1.7707, -0.7433],\n",
      "        [ 0.6634,  0.0987, -1.3583],\n",
      "        [ 0.6583,  0.0432, -1.5128],\n",
      "        [-1.7133,  0.4065,  1.1457],\n",
      "        [-1.4811,  0.5848,  1.0255],\n",
      "        [-1.5753,  0.4754,  0.9027],\n",
      "        [-1.5132,  0.4566,  1.1696],\n",
      "        [-1.5420,  1.5131, -0.0022],\n",
      "        [-1.7295,  0.6379,  0.8780],\n",
      "        [-1.7792,  1.8856, -0.3966],\n",
      "        [-1.4436,  2.0058, -0.8524],\n",
      "        [-1.3278,  1.8070, -0.9900],\n",
      "        [-1.5218,  1.8683, -0.6019],\n",
      "        [-1.6504,  0.1922,  1.0569]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2175,  1.9715, -0.7071],\n",
      "        [-1.2603,  1.9252, -0.7456],\n",
      "        [-1.6415,  1.7806, -0.4952],\n",
      "        [-1.3130,  1.9710, -0.8723],\n",
      "        [-0.8563,  1.1243, -0.5339],\n",
      "        [-1.4529,  1.7975, -0.7454],\n",
      "        [-1.3170,  0.4612,  0.7882],\n",
      "        [-1.4900,  2.1368, -0.7378],\n",
      "        [-1.3558,  2.2388, -0.7799],\n",
      "        [-1.2037,  0.3688,  0.6879],\n",
      "        [-1.2010,  1.9861, -0.7545],\n",
      "        [ 0.5371,  0.2026, -1.4832],\n",
      "        [-1.3543,  2.0418, -0.7401],\n",
      "        [-1.3245,  0.9768, -0.1486],\n",
      "        [-1.1121,  1.9512, -0.9604],\n",
      "        [-1.3170,  1.6960, -0.8716]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.2175,  1.9715, -0.7071],\n",
      "        [-1.2603,  1.9252, -0.7456],\n",
      "        [-1.6415,  1.7806, -0.4952],\n",
      "        [-1.3130,  1.9710, -0.8723],\n",
      "        [-0.8563,  1.1243, -0.5339],\n",
      "        [-1.4529,  1.7975, -0.7454],\n",
      "        [-1.3170,  0.4612,  0.7882],\n",
      "        [-1.4900,  2.1368, -0.7378],\n",
      "        [-1.3558,  2.2388, -0.7799],\n",
      "        [-1.2037,  0.3688,  0.6879],\n",
      "        [-1.2010,  1.9861, -0.7545],\n",
      "        [ 0.5371,  0.2026, -1.4832],\n",
      "        [-1.3543,  2.0418, -0.7401],\n",
      "        [-1.3245,  0.9768, -0.1486],\n",
      "        [-1.1121,  1.9512, -0.9604],\n",
      "        [-1.3170,  1.6960, -0.8716]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4029,  2.0622, -0.7082],\n",
      "        [-1.4638,  1.8643, -0.6801],\n",
      "        [ 0.4506,  0.2929, -1.3440],\n",
      "        [-1.5895,  2.0558, -0.8189],\n",
      "        [-1.4097,  1.9663, -0.8746],\n",
      "        [-1.7344,  0.3991,  1.2450],\n",
      "        [-0.9928,  1.4634, -0.9376],\n",
      "        [-1.3864,  1.7020, -0.8766],\n",
      "        [-1.4991,  1.7649, -0.7658],\n",
      "        [-1.4777,  2.0567, -0.7492],\n",
      "        [-1.5208,  0.4017,  0.9290],\n",
      "        [ 0.6013,  0.1306, -1.4710],\n",
      "        [-1.5833,  0.9449,  0.2840],\n",
      "        [ 0.7714,  0.2124, -1.2911],\n",
      "        [-1.0549,  1.5221, -0.8980],\n",
      "        [ 0.4637,  0.2415, -1.4090]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4029,  2.0622, -0.7082],\n",
      "        [-1.4638,  1.8643, -0.6801],\n",
      "        [ 0.4506,  0.2929, -1.3440],\n",
      "        [-1.5895,  2.0558, -0.8189],\n",
      "        [-1.4097,  1.9663, -0.8746],\n",
      "        [-1.7344,  0.3991,  1.2450],\n",
      "        [-0.9928,  1.4634, -0.9376],\n",
      "        [-1.3864,  1.7020, -0.8766],\n",
      "        [-1.4991,  1.7649, -0.7658],\n",
      "        [-1.4777,  2.0567, -0.7492],\n",
      "        [-1.5208,  0.4017,  0.9290],\n",
      "        [ 0.6013,  0.1306, -1.4710],\n",
      "        [-1.5833,  0.9449,  0.2840],\n",
      "        [ 0.7714,  0.2124, -1.2911],\n",
      "        [-1.0549,  1.5221, -0.8980],\n",
      "        [ 0.4637,  0.2415, -1.4090]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7139,  0.5166,  1.0853],\n",
      "        [-1.2861,  1.9427, -0.6889],\n",
      "        [ 0.5856,  0.4499, -1.3838],\n",
      "        [-1.3056,  1.7392, -0.8025],\n",
      "        [-1.6417,  0.4594,  1.1702],\n",
      "        [-1.0730,  0.9632, -0.4872],\n",
      "        [-1.2339,  1.6243, -0.6305],\n",
      "        [-1.3659,  0.2778,  0.7450],\n",
      "        [ 0.7571,  0.0525, -1.2198],\n",
      "        [ 0.5672,  0.0484, -1.1781],\n",
      "        [-1.3518,  2.0425, -0.7243],\n",
      "        [-1.0750,  1.5528, -0.8247],\n",
      "        [-1.7656,  0.5283,  0.9852],\n",
      "        [-1.2574,  1.7568, -0.9513],\n",
      "        [-1.1523,  1.9111, -0.7708],\n",
      "        [-1.4027,  1.9454, -0.5638]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7139,  0.5166,  1.0853],\n",
      "        [-1.2861,  1.9427, -0.6889],\n",
      "        [ 0.5856,  0.4499, -1.3838],\n",
      "        [-1.3056,  1.7392, -0.8025],\n",
      "        [-1.6417,  0.4594,  1.1702],\n",
      "        [-1.0730,  0.9632, -0.4872],\n",
      "        [-1.2339,  1.6243, -0.6305],\n",
      "        [-1.3659,  0.2778,  0.7450],\n",
      "        [ 0.7571,  0.0525, -1.2198],\n",
      "        [ 0.5672,  0.0484, -1.1781],\n",
      "        [-1.3518,  2.0425, -0.7243],\n",
      "        [-1.0750,  1.5528, -0.8247],\n",
      "        [-1.7656,  0.5283,  0.9852],\n",
      "        [-1.2574,  1.7568, -0.9513],\n",
      "        [-1.1523,  1.9111, -0.7708],\n",
      "        [-1.4027,  1.9454, -0.5638]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.8244, -0.0040, -1.3400],\n",
      "        [-1.2400,  1.5875, -0.7870],\n",
      "        [ 0.8260,  0.1809, -1.4925],\n",
      "        [-1.7588,  1.8035, -0.4421],\n",
      "        [-1.3788,  1.6144, -0.4999],\n",
      "        [-1.4165,  1.7036, -0.1525],\n",
      "        [ 0.4129,  0.4180, -1.4293],\n",
      "        [-0.9009,  1.1251, -0.8897],\n",
      "        [-1.8918,  0.5480,  1.0961],\n",
      "        [-1.3496,  1.8576, -0.3212],\n",
      "        [-1.0245,  1.3502, -0.8247],\n",
      "        [ 0.5883,  0.1295, -1.3056],\n",
      "        [-1.1755,  1.4173, -0.7386],\n",
      "        [-1.8115,  2.1519, -0.4278],\n",
      "        [-1.6237,  0.8524,  0.6325],\n",
      "        [-1.3300,  1.8894, -0.7827]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.8244, -0.0040, -1.3400],\n",
      "        [-1.2400,  1.5875, -0.7870],\n",
      "        [ 0.8260,  0.1809, -1.4925],\n",
      "        [-1.7588,  1.8035, -0.4421],\n",
      "        [-1.3788,  1.6144, -0.4999],\n",
      "        [-1.4165,  1.7036, -0.1525],\n",
      "        [ 0.4129,  0.4180, -1.4293],\n",
      "        [-0.9009,  1.1251, -0.8897],\n",
      "        [-1.8918,  0.5480,  1.0961],\n",
      "        [-1.3496,  1.8576, -0.3212],\n",
      "        [-1.0245,  1.3502, -0.8247],\n",
      "        [ 0.5883,  0.1295, -1.3056],\n",
      "        [-1.1755,  1.4173, -0.7386],\n",
      "        [-1.8115,  2.1519, -0.4278],\n",
      "        [-1.6237,  0.8524,  0.6325],\n",
      "        [-1.3300,  1.8894, -0.7827]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2891,  1.6215, -0.6026],\n",
      "        [-1.4693,  1.8870, -0.7311],\n",
      "        [-1.4997,  1.9819, -0.7713],\n",
      "        [-1.3635,  1.7370, -0.8080],\n",
      "        [-1.5954,  0.4717,  1.0776],\n",
      "        [ 0.7926,  0.0195, -1.2602],\n",
      "        [-1.7552,  1.4484, -0.0934],\n",
      "        [-1.6099,  2.1477, -0.6080],\n",
      "        [-1.6572,  0.4813,  1.0995],\n",
      "        [-1.3083,  1.7832, -0.7599],\n",
      "        [-1.2363,  0.6589,  0.6643],\n",
      "        [-1.5687,  2.1094, -0.5933],\n",
      "        [-1.6854,  1.9311, -0.6741],\n",
      "        [-1.5044,  0.9432,  0.5045],\n",
      "        [-1.4201,  1.4569, -0.4298],\n",
      "        [-1.3526,  1.9568, -0.6230]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.2891,  1.6215, -0.6026],\n",
      "        [-1.4693,  1.8870, -0.7311],\n",
      "        [-1.4997,  1.9819, -0.7713],\n",
      "        [-1.3635,  1.7370, -0.8080],\n",
      "        [-1.5954,  0.4717,  1.0776],\n",
      "        [ 0.7926,  0.0195, -1.2602],\n",
      "        [-1.7552,  1.4484, -0.0934],\n",
      "        [-1.6099,  2.1477, -0.6080],\n",
      "        [-1.6572,  0.4813,  1.0995],\n",
      "        [-1.3083,  1.7832, -0.7599],\n",
      "        [-1.2363,  0.6589,  0.6643],\n",
      "        [-1.5687,  2.1094, -0.5933],\n",
      "        [-1.6854,  1.9311, -0.6741],\n",
      "        [-1.5044,  0.9432,  0.5045],\n",
      "        [-1.4201,  1.4569, -0.4298],\n",
      "        [-1.3526,  1.9568, -0.6230]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7095,  0.4334,  0.9249],\n",
      "        [ 0.6885,  0.2463, -1.5198],\n",
      "        [-1.6300,  2.0085, -0.7299],\n",
      "        [-1.5544,  1.9036, -0.6925],\n",
      "        [-1.5291,  1.9167, -0.6296],\n",
      "        [-1.9399,  0.3681,  1.0831],\n",
      "        [-1.5308,  1.6939, -0.3995],\n",
      "        [-1.6676,  0.4751,  1.2548],\n",
      "        [-1.2068,  2.0238, -0.6176],\n",
      "        [-1.3593,  1.8026, -0.6377],\n",
      "        [-1.4652,  0.5336,  0.9022],\n",
      "        [-1.3420,  1.8630, -0.6212],\n",
      "        [-1.6077,  0.8356,  0.7451],\n",
      "        [-1.1318,  1.5482, -0.7127],\n",
      "        [-1.5538,  1.9178, -0.3412],\n",
      "        [-1.6497,  0.4507,  1.1263]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7095,  0.4334,  0.9249],\n",
      "        [ 0.6885,  0.2463, -1.5198],\n",
      "        [-1.6300,  2.0085, -0.7299],\n",
      "        [-1.5544,  1.9036, -0.6925],\n",
      "        [-1.5291,  1.9167, -0.6296],\n",
      "        [-1.9399,  0.3681,  1.0831],\n",
      "        [-1.5308,  1.6939, -0.3995],\n",
      "        [-1.6676,  0.4751,  1.2548],\n",
      "        [-1.2068,  2.0238, -0.6176],\n",
      "        [-1.3593,  1.8026, -0.6377],\n",
      "        [-1.4652,  0.5336,  0.9022],\n",
      "        [-1.3420,  1.8630, -0.6212],\n",
      "        [-1.6077,  0.8356,  0.7451],\n",
      "        [-1.1318,  1.5482, -0.7127],\n",
      "        [-1.5538,  1.9178, -0.3412],\n",
      "        [-1.6497,  0.4507,  1.1263]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6473,  0.4620,  1.2686],\n",
      "        [ 0.8450,  0.0983, -1.3506],\n",
      "        [-1.6728,  0.1528,  1.2231],\n",
      "        [-1.4401,  1.9492, -0.5027],\n",
      "        [-1.5525,  1.7651, -0.5591],\n",
      "        [-1.8010,  0.4792,  1.0024],\n",
      "        [-1.3711,  2.1025, -0.7178],\n",
      "        [ 0.7350,  0.1988, -1.6062],\n",
      "        [-1.2576,  1.9212, -0.6321],\n",
      "        [-1.4171,  1.4696, -0.2655],\n",
      "        [-1.1438,  1.7686, -0.6901],\n",
      "        [-1.4972,  1.8886, -0.5000],\n",
      "        [-1.5629,  1.5219, -0.4871],\n",
      "        [-1.4608,  1.6461, -0.4372],\n",
      "        [-2.0143,  0.7163,  0.9413],\n",
      "        [-1.4001,  1.9290, -0.6062]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6473,  0.4620,  1.2686],\n",
      "        [ 0.8450,  0.0983, -1.3506],\n",
      "        [-1.6728,  0.1528,  1.2231],\n",
      "        [-1.4401,  1.9492, -0.5027],\n",
      "        [-1.5525,  1.7651, -0.5591],\n",
      "        [-1.8010,  0.4792,  1.0024],\n",
      "        [-1.3711,  2.1025, -0.7178],\n",
      "        [ 0.7350,  0.1988, -1.6062],\n",
      "        [-1.2576,  1.9212, -0.6321],\n",
      "        [-1.4171,  1.4696, -0.2655],\n",
      "        [-1.1438,  1.7686, -0.6901],\n",
      "        [-1.4972,  1.8886, -0.5000],\n",
      "        [-1.5629,  1.5219, -0.4871],\n",
      "        [-1.4608,  1.6461, -0.4372],\n",
      "        [-2.0143,  0.7163,  0.9413],\n",
      "        [-1.4001,  1.9290, -0.6062]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.7027,  0.1738, -1.2151],\n",
      "        [-1.3655,  1.7956, -0.4924],\n",
      "        [-1.5089,  1.1715,  0.2042],\n",
      "        [-1.6320,  0.4241,  1.0641],\n",
      "        [-1.5793,  1.7394, -0.6562],\n",
      "        [-1.8198,  1.1233,  0.1745],\n",
      "        [-0.8322,  1.3384, -0.9552],\n",
      "        [-1.3792,  1.9466, -0.6534],\n",
      "        [-1.9490,  0.4166,  1.2242],\n",
      "        [ 0.9888,  0.1125, -1.3806],\n",
      "        [-1.7393,  0.2552,  1.0706],\n",
      "        [-1.6364,  0.3616,  1.2527],\n",
      "        [-1.5195,  1.7084, -0.7047],\n",
      "        [-1.7800,  0.3774,  1.1994],\n",
      "        [ 0.2113,  0.0318, -0.5539],\n",
      "        [-1.4287,  1.7224, -0.6043]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.7027,  0.1738, -1.2151],\n",
      "        [-1.3655,  1.7956, -0.4924],\n",
      "        [-1.5089,  1.1715,  0.2042],\n",
      "        [-1.6320,  0.4241,  1.0641],\n",
      "        [-1.5793,  1.7394, -0.6562],\n",
      "        [-1.8198,  1.1233,  0.1745],\n",
      "        [-0.8322,  1.3384, -0.9552],\n",
      "        [-1.3792,  1.9466, -0.6534],\n",
      "        [-1.9490,  0.4166,  1.2242],\n",
      "        [ 0.9888,  0.1125, -1.3806],\n",
      "        [-1.7393,  0.2552,  1.0706],\n",
      "        [-1.6364,  0.3616,  1.2527],\n",
      "        [-1.5195,  1.7084, -0.7047],\n",
      "        [-1.7800,  0.3774,  1.1994],\n",
      "        [ 0.2113,  0.0318, -0.5539],\n",
      "        [-1.4287,  1.7224, -0.6043]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5459,  1.6650, -0.4934],\n",
      "        [-1.7187,  0.1758,  1.1843],\n",
      "        [-1.4875,  1.8605, -0.5925],\n",
      "        [-1.5949,  1.7183, -0.3055],\n",
      "        [ 0.6792,  0.1213, -1.3478],\n",
      "        [-1.8636,  0.3727,  1.1609],\n",
      "        [-1.6305,  1.7894, -0.4831],\n",
      "        [-1.7897,  0.4873,  1.1632],\n",
      "        [-1.5504,  1.8542, -0.5438],\n",
      "        [-1.7510,  0.4013,  1.3636],\n",
      "        [-1.4110,  0.9130,  0.5523],\n",
      "        [-1.3371,  1.5955, -0.5680],\n",
      "        [-1.4083,  0.5924,  0.8303],\n",
      "        [-1.7175,  0.5844,  0.9764],\n",
      "        [-1.5571,  0.5173,  1.1168],\n",
      "        [-1.4275,  1.7007, -0.6844]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5459,  1.6650, -0.4934],\n",
      "        [-1.7187,  0.1758,  1.1843],\n",
      "        [-1.4875,  1.8605, -0.5925],\n",
      "        [-1.5949,  1.7183, -0.3055],\n",
      "        [ 0.6792,  0.1213, -1.3478],\n",
      "        [-1.8636,  0.3727,  1.1609],\n",
      "        [-1.6305,  1.7894, -0.4831],\n",
      "        [-1.7897,  0.4873,  1.1632],\n",
      "        [-1.5504,  1.8542, -0.5438],\n",
      "        [-1.7510,  0.4013,  1.3636],\n",
      "        [-1.4110,  0.9130,  0.5523],\n",
      "        [-1.3371,  1.5955, -0.5680],\n",
      "        [-1.4083,  0.5924,  0.8303],\n",
      "        [-1.7175,  0.5844,  0.9764],\n",
      "        [-1.5571,  0.5173,  1.1168],\n",
      "        [-1.4275,  1.7007, -0.6844]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8034,  0.2395,  1.3275],\n",
      "        [-1.8079,  1.5940,  0.0484],\n",
      "        [-1.5396,  1.3538, -0.1632],\n",
      "        [ 0.7580, -0.0599, -1.5609],\n",
      "        [-1.4607,  1.6629, -0.4104],\n",
      "        [-1.5727,  1.6355, -0.0752],\n",
      "        [ 0.5808, -0.0698, -1.2758],\n",
      "        [-1.8240,  1.6864, -0.2755],\n",
      "        [-0.9199,  0.0909,  0.5461],\n",
      "        [ 0.7999, -0.0422, -1.3758],\n",
      "        [ 0.7026,  0.2487, -1.3761],\n",
      "        [-1.4016,  1.9427, -0.6782],\n",
      "        [-1.0001,  1.2283, -0.6679],\n",
      "        [ 0.6146, -0.0242, -1.2572],\n",
      "        [-1.7645,  0.4519,  1.2560],\n",
      "        [-1.7405,  0.1380,  1.2996]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8034,  0.2395,  1.3275],\n",
      "        [-1.8079,  1.5940,  0.0484],\n",
      "        [-1.5396,  1.3538, -0.1632],\n",
      "        [ 0.7580, -0.0599, -1.5609],\n",
      "        [-1.4607,  1.6629, -0.4104],\n",
      "        [-1.5727,  1.6355, -0.0752],\n",
      "        [ 0.5808, -0.0698, -1.2758],\n",
      "        [-1.8240,  1.6864, -0.2755],\n",
      "        [-0.9199,  0.0909,  0.5461],\n",
      "        [ 0.7999, -0.0422, -1.3758],\n",
      "        [ 0.7026,  0.2487, -1.3761],\n",
      "        [-1.4016,  1.9427, -0.6782],\n",
      "        [-1.0001,  1.2283, -0.6679],\n",
      "        [ 0.6146, -0.0242, -1.2572],\n",
      "        [-1.7645,  0.4519,  1.2560],\n",
      "        [-1.7405,  0.1380,  1.2996]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6455,  0.1886,  1.0640],\n",
      "        [-1.5458,  1.8045, -0.2615],\n",
      "        [-1.6532,  0.2434,  1.3217],\n",
      "        [-1.6186,  1.9501, -0.4406],\n",
      "        [-1.6399,  0.4392,  1.1024],\n",
      "        [-1.4930,  1.9789, -0.6577],\n",
      "        [-1.6473,  1.5422, -0.2624],\n",
      "        [-1.8298,  0.2291,  1.2849],\n",
      "        [-1.9871,  0.3537,  1.5067],\n",
      "        [ 0.9793,  0.0645, -1.4696],\n",
      "        [-1.4897,  1.7856, -0.5882],\n",
      "        [-1.6052,  1.8514, -0.2483],\n",
      "        [-1.7691,  0.4550,  1.2486],\n",
      "        [-1.7933,  0.2627,  1.4026],\n",
      "        [-2.0153,  1.0213,  0.4209],\n",
      "        [-1.8164,  0.4155,  1.2177]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6455,  0.1886,  1.0640],\n",
      "        [-1.5458,  1.8045, -0.2615],\n",
      "        [-1.6532,  0.2434,  1.3217],\n",
      "        [-1.6186,  1.9501, -0.4406],\n",
      "        [-1.6399,  0.4392,  1.1024],\n",
      "        [-1.4930,  1.9789, -0.6577],\n",
      "        [-1.6473,  1.5422, -0.2624],\n",
      "        [-1.8298,  0.2291,  1.2849],\n",
      "        [-1.9871,  0.3537,  1.5067],\n",
      "        [ 0.9793,  0.0645, -1.4696],\n",
      "        [-1.4897,  1.7856, -0.5882],\n",
      "        [-1.6052,  1.8514, -0.2483],\n",
      "        [-1.7691,  0.4550,  1.2486],\n",
      "        [-1.7933,  0.2627,  1.4026],\n",
      "        [-2.0153,  1.0213,  0.4209],\n",
      "        [-1.8164,  0.4155,  1.2177]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.0919,  1.7538, -0.5675],\n",
      "        [-1.6216,  2.1356, -0.4738],\n",
      "        [-1.5571,  1.7949, -0.4672],\n",
      "        [-1.5770,  1.8049, -0.5080],\n",
      "        [ 0.6216, -0.0470, -1.2080],\n",
      "        [-1.3837,  1.6800, -0.5847],\n",
      "        [-1.7398,  0.4802,  1.0378],\n",
      "        [-1.6354,  1.3868,  0.0348],\n",
      "        [-1.7141,  1.9724, -0.4538],\n",
      "        [-1.6105,  1.8272, -0.4978],\n",
      "        [-1.6669,  0.1009,  1.3233],\n",
      "        [-1.7573,  0.2784,  1.2434],\n",
      "        [-1.5972,  1.9443, -0.5767],\n",
      "        [-1.6015,  1.7146, -0.4049],\n",
      "        [-1.6266,  0.5770,  1.0599],\n",
      "        [-2.0660,  0.5507,  1.1572]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.0919,  1.7538, -0.5675],\n",
      "        [-1.6216,  2.1356, -0.4738],\n",
      "        [-1.5571,  1.7949, -0.4672],\n",
      "        [-1.5770,  1.8049, -0.5080],\n",
      "        [ 0.6216, -0.0470, -1.2080],\n",
      "        [-1.3837,  1.6800, -0.5847],\n",
      "        [-1.7398,  0.4802,  1.0378],\n",
      "        [-1.6354,  1.3868,  0.0348],\n",
      "        [-1.7141,  1.9724, -0.4538],\n",
      "        [-1.6105,  1.8272, -0.4978],\n",
      "        [-1.6669,  0.1009,  1.3233],\n",
      "        [-1.7573,  0.2784,  1.2434],\n",
      "        [-1.5972,  1.9443, -0.5767],\n",
      "        [-1.6015,  1.7146, -0.4049],\n",
      "        [-1.6266,  0.5770,  1.0599],\n",
      "        [-2.0660,  0.5507,  1.1572]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5464,  1.8385, -0.4594],\n",
      "        [-1.3501,  1.5491, -0.5732],\n",
      "        [-1.3490,  1.7204, -0.7160],\n",
      "        [ 0.6794,  0.0073, -1.1780],\n",
      "        [-1.8336,  0.2308,  1.3461],\n",
      "        [-1.5248,  0.3249,  1.0236],\n",
      "        [-1.6908,  0.2290,  1.1632],\n",
      "        [-1.5703,  2.0337, -0.2422],\n",
      "        [-0.8586,  1.0797, -0.6997],\n",
      "        [ 0.6112, -0.0258, -1.4130],\n",
      "        [ 0.8219,  0.0567, -1.3081],\n",
      "        [-1.6577,  1.9785, -0.3628],\n",
      "        [-1.6415,  1.5055, -0.3960],\n",
      "        [-1.7240,  1.8019, -0.3301],\n",
      "        [-1.0213,  1.5120, -0.7697],\n",
      "        [-1.6562,  0.3776,  1.3218]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5464,  1.8385, -0.4594],\n",
      "        [-1.3501,  1.5491, -0.5732],\n",
      "        [-1.3490,  1.7204, -0.7160],\n",
      "        [ 0.6794,  0.0073, -1.1780],\n",
      "        [-1.8336,  0.2308,  1.3461],\n",
      "        [-1.5248,  0.3249,  1.0236],\n",
      "        [-1.6908,  0.2290,  1.1632],\n",
      "        [-1.5703,  2.0337, -0.2422],\n",
      "        [-0.8586,  1.0797, -0.6997],\n",
      "        [ 0.6112, -0.0258, -1.4130],\n",
      "        [ 0.8219,  0.0567, -1.3081],\n",
      "        [-1.6577,  1.9785, -0.3628],\n",
      "        [-1.6415,  1.5055, -0.3960],\n",
      "        [-1.7240,  1.8019, -0.3301],\n",
      "        [-1.0213,  1.5120, -0.7697],\n",
      "        [-1.6562,  0.3776,  1.3218]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7522,  0.4658,  1.2039],\n",
      "        [-1.5282,  1.8810, -0.4734],\n",
      "        [-1.6637,  0.3564,  1.1880],\n",
      "        [ 0.7965, -0.0178, -1.4016],\n",
      "        [-1.5581,  1.5529, -0.3182],\n",
      "        [ 0.2480,  0.5331, -1.2701],\n",
      "        [-1.4973,  1.7949, -0.4478],\n",
      "        [ 0.6830,  0.0677, -1.2549],\n",
      "        [-1.6149,  1.7741, -0.5555],\n",
      "        [-1.7031,  1.8922, -0.2977],\n",
      "        [-2.0023,  0.5494,  1.2646],\n",
      "        [-1.4397,  1.6573, -0.4108],\n",
      "        [-1.8357,  0.2906,  1.3492],\n",
      "        [-1.5441,  1.8804, -0.4184],\n",
      "        [ 0.6796,  0.0694, -1.4098],\n",
      "        [ 0.7784, -0.1055, -1.2022]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7522,  0.4658,  1.2039],\n",
      "        [-1.5282,  1.8810, -0.4734],\n",
      "        [-1.6637,  0.3564,  1.1880],\n",
      "        [ 0.7965, -0.0178, -1.4016],\n",
      "        [-1.5581,  1.5529, -0.3182],\n",
      "        [ 0.2480,  0.5331, -1.2701],\n",
      "        [-1.4973,  1.7949, -0.4478],\n",
      "        [ 0.6830,  0.0677, -1.2549],\n",
      "        [-1.6149,  1.7741, -0.5555],\n",
      "        [-1.7031,  1.8922, -0.2977],\n",
      "        [-2.0023,  0.5494,  1.2646],\n",
      "        [-1.4397,  1.6573, -0.4108],\n",
      "        [-1.8357,  0.2906,  1.3492],\n",
      "        [-1.5441,  1.8804, -0.4184],\n",
      "        [ 0.6796,  0.0694, -1.4098],\n",
      "        [ 0.7784, -0.1055, -1.2022]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7507,  1.6571,  0.0291],\n",
      "        [-2.0733,  0.1586,  1.3278],\n",
      "        [-1.8330,  0.7909,  0.8154],\n",
      "        [ 0.3982, -0.0283, -0.9428],\n",
      "        [-1.8733,  0.3891,  1.4908],\n",
      "        [-2.0145,  0.6037,  1.0451],\n",
      "        [-0.7829,  0.9784, -0.5348],\n",
      "        [-1.6619,  1.5335, -0.0339],\n",
      "        [ 0.6157,  0.0469, -1.4175],\n",
      "        [-1.6580,  1.8454, -0.2901],\n",
      "        [-1.5629,  1.6685, -0.6073],\n",
      "        [-1.6383,  1.7234, -0.4243],\n",
      "        [-2.0269,  0.2572,  1.1546],\n",
      "        [-1.5930,  1.5307, -0.0770],\n",
      "        [ 0.5570, -0.0698, -1.2617],\n",
      "        [ 0.8234,  0.0134, -1.3035]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7507,  1.6571,  0.0291],\n",
      "        [-2.0733,  0.1586,  1.3278],\n",
      "        [-1.8330,  0.7909,  0.8154],\n",
      "        [ 0.3982, -0.0283, -0.9428],\n",
      "        [-1.8733,  0.3891,  1.4908],\n",
      "        [-2.0145,  0.6037,  1.0451],\n",
      "        [-0.7829,  0.9784, -0.5348],\n",
      "        [-1.6619,  1.5335, -0.0339],\n",
      "        [ 0.6157,  0.0469, -1.4175],\n",
      "        [-1.6580,  1.8454, -0.2901],\n",
      "        [-1.5629,  1.6685, -0.6073],\n",
      "        [-1.6383,  1.7234, -0.4243],\n",
      "        [-2.0269,  0.2572,  1.1546],\n",
      "        [-1.5930,  1.5307, -0.0770],\n",
      "        [ 0.5570, -0.0698, -1.2617],\n",
      "        [ 0.8234,  0.0134, -1.3035]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7023,  1.8762, -0.4178],\n",
      "        [-1.8262,  0.4883,  1.1933],\n",
      "        [-1.6854,  0.9269,  0.5817],\n",
      "        [-1.3397,  0.1501,  1.1276],\n",
      "        [-1.4580,  1.6436, -0.3854],\n",
      "        [-1.4078,  1.6742, -0.4490],\n",
      "        [-1.7656,  0.5061,  1.1941],\n",
      "        [-1.8636,  0.4131,  1.4813],\n",
      "        [-1.6787,  1.5211, -0.5560],\n",
      "        [-1.9729,  0.3791,  1.3281],\n",
      "        [-1.4978,  1.6863, -0.3384],\n",
      "        [-1.6757,  1.8819, -0.3203],\n",
      "        [-1.5730,  1.7135, -0.3579],\n",
      "        [-1.5085,  1.9836, -0.5148],\n",
      "        [ 0.7745,  0.0888, -1.3172],\n",
      "        [-2.0499,  0.5274,  1.2990]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7023,  1.8762, -0.4178],\n",
      "        [-1.8262,  0.4883,  1.1933],\n",
      "        [-1.6854,  0.9269,  0.5817],\n",
      "        [-1.3397,  0.1501,  1.1276],\n",
      "        [-1.4580,  1.6436, -0.3854],\n",
      "        [-1.4078,  1.6742, -0.4490],\n",
      "        [-1.7656,  0.5061,  1.1941],\n",
      "        [-1.8636,  0.4131,  1.4813],\n",
      "        [-1.6787,  1.5211, -0.5560],\n",
      "        [-1.9729,  0.3791,  1.3281],\n",
      "        [-1.4978,  1.6863, -0.3384],\n",
      "        [-1.6757,  1.8819, -0.3203],\n",
      "        [-1.5730,  1.7135, -0.3579],\n",
      "        [-1.5085,  1.9836, -0.5148],\n",
      "        [ 0.7745,  0.0888, -1.3172],\n",
      "        [-2.0499,  0.5274,  1.2990]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4438,  1.5717, -0.2711],\n",
      "        [-1.6938,  1.7774, -0.8054],\n",
      "        [-1.6785,  1.6451, -0.3310],\n",
      "        [-1.9624,  0.4411,  1.3015],\n",
      "        [-1.4167,  1.6942, -0.7657],\n",
      "        [-0.3970,  0.5597, -0.4747],\n",
      "        [-1.9286,  0.5015,  1.0730],\n",
      "        [-1.4131,  1.6687, -0.3503],\n",
      "        [-1.9193,  0.4158,  1.4183],\n",
      "        [-1.6458,  1.9601, -0.6257],\n",
      "        [-1.5508,  2.0265, -0.4992],\n",
      "        [ 0.6662,  0.0779, -1.3082],\n",
      "        [-1.5208,  1.0605,  0.0285],\n",
      "        [-1.8825,  0.3795,  1.3196],\n",
      "        [-1.9240,  0.3686,  1.3401],\n",
      "        [-1.4243,  0.3740,  1.0102]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4438,  1.5717, -0.2711],\n",
      "        [-1.6938,  1.7774, -0.8054],\n",
      "        [-1.6785,  1.6451, -0.3310],\n",
      "        [-1.9624,  0.4411,  1.3015],\n",
      "        [-1.4167,  1.6942, -0.7657],\n",
      "        [-0.3970,  0.5597, -0.4747],\n",
      "        [-1.9286,  0.5015,  1.0730],\n",
      "        [-1.4131,  1.6687, -0.3503],\n",
      "        [-1.9193,  0.4158,  1.4183],\n",
      "        [-1.6458,  1.9601, -0.6257],\n",
      "        [-1.5508,  2.0265, -0.4992],\n",
      "        [ 0.6662,  0.0779, -1.3082],\n",
      "        [-1.5208,  1.0605,  0.0285],\n",
      "        [-1.8825,  0.3795,  1.3196],\n",
      "        [-1.9240,  0.3686,  1.3401],\n",
      "        [-1.4243,  0.3740,  1.0102]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6069,  0.3926,  1.0995],\n",
      "        [-1.4745,  1.7791, -0.3908],\n",
      "        [-1.3961,  1.9108, -0.3685],\n",
      "        [-1.9448,  0.5697,  0.7947],\n",
      "        [-1.6617,  1.8620, -0.4451],\n",
      "        [-1.9965,  0.3815,  1.3245],\n",
      "        [-1.7843,  1.7761, -0.4942],\n",
      "        [-1.7012,  1.8548, -0.2948],\n",
      "        [-1.6868,  1.8131, -0.4255],\n",
      "        [ 0.6640,  0.3154, -1.3067],\n",
      "        [-1.8786,  0.5361,  1.2429],\n",
      "        [ 0.8256,  0.1161, -1.1988],\n",
      "        [-1.9210,  0.2272,  1.2318],\n",
      "        [-1.6292,  0.4722,  1.0511],\n",
      "        [-1.6524,  1.7518, -0.5480],\n",
      "        [-1.9423,  0.2085,  1.0959]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6069,  0.3926,  1.0995],\n",
      "        [-1.4745,  1.7791, -0.3908],\n",
      "        [-1.3961,  1.9108, -0.3685],\n",
      "        [-1.9448,  0.5697,  0.7947],\n",
      "        [-1.6617,  1.8620, -0.4451],\n",
      "        [-1.9965,  0.3815,  1.3245],\n",
      "        [-1.7843,  1.7761, -0.4942],\n",
      "        [-1.7012,  1.8548, -0.2948],\n",
      "        [-1.6868,  1.8131, -0.4255],\n",
      "        [ 0.6640,  0.3154, -1.3067],\n",
      "        [-1.8786,  0.5361,  1.2429],\n",
      "        [ 0.8256,  0.1161, -1.1988],\n",
      "        [-1.9210,  0.2272,  1.2318],\n",
      "        [-1.6292,  0.4722,  1.0511],\n",
      "        [-1.6524,  1.7518, -0.5480],\n",
      "        [-1.9423,  0.2085,  1.0959]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5804,  1.7114, -0.5291],\n",
      "        [-1.7297,  0.4435,  1.2674],\n",
      "        [-1.7135,  1.8600, -0.2919],\n",
      "        [ 0.4671,  0.0904, -1.4157],\n",
      "        [-1.8131,  1.0950,  0.4617],\n",
      "        [-2.0207,  1.0031,  0.7179],\n",
      "        [-1.5826,  1.7008, -0.2709],\n",
      "        [-1.4558,  1.6556, -0.4091],\n",
      "        [-1.7128,  1.9352, -0.3810],\n",
      "        [-1.6940,  1.7948, -0.3865],\n",
      "        [-1.6078,  1.9552, -0.3185],\n",
      "        [-1.6114,  2.0067, -0.4547],\n",
      "        [-1.8916,  0.9744,  0.8120],\n",
      "        [-1.8574,  1.8731, -0.3732],\n",
      "        [-1.7258,  1.9779, -0.5259],\n",
      "        [-1.5270,  0.8065,  0.8539]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5804,  1.7114, -0.5291],\n",
      "        [-1.7297,  0.4435,  1.2674],\n",
      "        [-1.7135,  1.8600, -0.2919],\n",
      "        [ 0.4671,  0.0904, -1.4157],\n",
      "        [-1.8131,  1.0950,  0.4617],\n",
      "        [-2.0207,  1.0031,  0.7179],\n",
      "        [-1.5826,  1.7008, -0.2709],\n",
      "        [-1.4558,  1.6556, -0.4091],\n",
      "        [-1.7128,  1.9352, -0.3810],\n",
      "        [-1.6940,  1.7948, -0.3865],\n",
      "        [-1.6078,  1.9552, -0.3185],\n",
      "        [-1.6114,  2.0067, -0.4547],\n",
      "        [-1.8916,  0.9744,  0.8120],\n",
      "        [-1.8574,  1.8731, -0.3732],\n",
      "        [-1.7258,  1.9779, -0.5259],\n",
      "        [-1.5270,  0.8065,  0.8539]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3651,  1.5789, -0.4686],\n",
      "        [-1.7383,  1.9857, -0.6613],\n",
      "        [-1.7893,  0.5931,  1.2151],\n",
      "        [-1.6928,  0.5006,  1.2444],\n",
      "        [-1.9247,  1.4394, -0.2714],\n",
      "        [-1.5583,  1.8207, -0.5392],\n",
      "        [-1.7623,  1.7856, -0.5026],\n",
      "        [ 0.6991,  0.0085, -1.2759],\n",
      "        [-1.5495,  1.8663, -0.2933],\n",
      "        [-1.4705,  1.9420, -0.5475],\n",
      "        [ 0.6400,  0.2305, -1.2052],\n",
      "        [-1.9635,  0.5341,  1.2138],\n",
      "        [-1.7048,  0.5269,  1.2421],\n",
      "        [-1.5069,  1.5568, -0.4731],\n",
      "        [-1.6557,  1.5548, -0.3116],\n",
      "        [-1.7164,  0.2932,  1.1277]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3651,  1.5789, -0.4686],\n",
      "        [-1.7383,  1.9857, -0.6613],\n",
      "        [-1.7893,  0.5931,  1.2151],\n",
      "        [-1.6928,  0.5006,  1.2444],\n",
      "        [-1.9247,  1.4394, -0.2714],\n",
      "        [-1.5583,  1.8207, -0.5392],\n",
      "        [-1.7623,  1.7856, -0.5026],\n",
      "        [ 0.6991,  0.0085, -1.2759],\n",
      "        [-1.5495,  1.8663, -0.2933],\n",
      "        [-1.4705,  1.9420, -0.5475],\n",
      "        [ 0.6400,  0.2305, -1.2052],\n",
      "        [-1.9635,  0.5341,  1.2138],\n",
      "        [-1.7048,  0.5269,  1.2421],\n",
      "        [-1.5069,  1.5568, -0.4731],\n",
      "        [-1.6557,  1.5548, -0.3116],\n",
      "        [-1.7164,  0.2932,  1.1277]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5308,  1.7191, -0.4926],\n",
      "        [-1.7843,  0.4914,  1.2383],\n",
      "        [-1.5476,  1.8071, -0.5675],\n",
      "        [-1.6987,  1.8626, -0.1047],\n",
      "        [-1.7309,  1.5846, -0.0516],\n",
      "        [-1.7820,  0.4202,  1.2909],\n",
      "        [-1.6672,  1.5935, -0.3349],\n",
      "        [-1.7707,  1.7791, -0.2941],\n",
      "        [-1.6651,  0.6856,  0.9736],\n",
      "        [ 0.8488,  0.0603, -1.5295],\n",
      "        [-1.4901,  1.9290, -0.3152],\n",
      "        [-1.4345,  1.9456, -0.5165],\n",
      "        [-1.0372,  1.0187, -0.2431],\n",
      "        [-1.6460,  1.6608, -0.4080],\n",
      "        [-1.5725,  1.8314, -0.3613],\n",
      "        [-1.6476,  1.9416, -0.3492]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5308,  1.7191, -0.4926],\n",
      "        [-1.7843,  0.4914,  1.2383],\n",
      "        [-1.5476,  1.8071, -0.5675],\n",
      "        [-1.6987,  1.8626, -0.1047],\n",
      "        [-1.7309,  1.5846, -0.0516],\n",
      "        [-1.7820,  0.4202,  1.2909],\n",
      "        [-1.6672,  1.5935, -0.3349],\n",
      "        [-1.7707,  1.7791, -0.2941],\n",
      "        [-1.6651,  0.6856,  0.9736],\n",
      "        [ 0.8488,  0.0603, -1.5295],\n",
      "        [-1.4901,  1.9290, -0.3152],\n",
      "        [-1.4345,  1.9456, -0.5165],\n",
      "        [-1.0372,  1.0187, -0.2431],\n",
      "        [-1.6460,  1.6608, -0.4080],\n",
      "        [-1.5725,  1.8314, -0.3613],\n",
      "        [-1.6476,  1.9416, -0.3492]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5557,  1.8233, -0.5749],\n",
      "        [-1.7107,  0.5279,  1.1847],\n",
      "        [-1.7810,  1.6950, -0.3087],\n",
      "        [-1.8202,  2.0178, -0.4036],\n",
      "        [-1.6182,  1.6896, -0.4094],\n",
      "        [-1.1081,  0.6583,  0.2458],\n",
      "        [-1.7944,  2.0410, -0.5939],\n",
      "        [-1.6163,  1.6400, -0.6879],\n",
      "        [-1.6536,  0.2708,  1.1928],\n",
      "        [-1.7836,  0.7098,  1.1148],\n",
      "        [-1.6667,  2.1145, -0.5158],\n",
      "        [-1.8418,  1.9192, -0.2472],\n",
      "        [-1.4117,  1.3440, -0.6411],\n",
      "        [-1.8254,  0.4880,  1.1809],\n",
      "        [ 0.5255,  0.0505, -1.1031],\n",
      "        [ 0.8269,  0.1334, -1.2351]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5557,  1.8233, -0.5749],\n",
      "        [-1.7107,  0.5279,  1.1847],\n",
      "        [-1.7810,  1.6950, -0.3087],\n",
      "        [-1.8202,  2.0178, -0.4036],\n",
      "        [-1.6182,  1.6896, -0.4094],\n",
      "        [-1.1081,  0.6583,  0.2458],\n",
      "        [-1.7944,  2.0410, -0.5939],\n",
      "        [-1.6163,  1.6400, -0.6879],\n",
      "        [-1.6536,  0.2708,  1.1928],\n",
      "        [-1.7836,  0.7098,  1.1148],\n",
      "        [-1.6667,  2.1145, -0.5158],\n",
      "        [-1.8418,  1.9192, -0.2472],\n",
      "        [-1.4117,  1.3440, -0.6411],\n",
      "        [-1.8254,  0.4880,  1.1809],\n",
      "        [ 0.5255,  0.0505, -1.1031],\n",
      "        [ 0.8269,  0.1334, -1.2351]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0487,  0.9040,  0.8758],\n",
      "        [-1.3820,  1.8187, -0.6256],\n",
      "        [ 0.6354,  0.1135, -1.5327],\n",
      "        [-1.7750,  1.8456, -0.3785],\n",
      "        [-1.6498,  1.9944, -0.8008],\n",
      "        [-1.7756,  0.7491,  1.0773],\n",
      "        [-1.7728,  1.9088, -0.4357],\n",
      "        [ 0.7585,  0.0552, -1.1470],\n",
      "        [-1.5579,  1.9037, -0.3627],\n",
      "        [ 0.5625,  0.2470, -1.3716],\n",
      "        [-1.8735,  0.4256,  1.3263],\n",
      "        [-1.6555,  2.0711, -0.4466],\n",
      "        [-1.7173,  1.7544, -0.2349],\n",
      "        [-1.6711,  1.6774, -0.6403],\n",
      "        [-1.6809,  1.9038, -0.4187],\n",
      "        [-1.8792,  0.5876,  1.1580]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.0487,  0.9040,  0.8758],\n",
      "        [-1.3820,  1.8187, -0.6256],\n",
      "        [ 0.6354,  0.1135, -1.5327],\n",
      "        [-1.7750,  1.8456, -0.3785],\n",
      "        [-1.6498,  1.9944, -0.8008],\n",
      "        [-1.7756,  0.7491,  1.0773],\n",
      "        [-1.7728,  1.9088, -0.4357],\n",
      "        [ 0.7585,  0.0552, -1.1470],\n",
      "        [-1.5579,  1.9037, -0.3627],\n",
      "        [ 0.5625,  0.2470, -1.3716],\n",
      "        [-1.8735,  0.4256,  1.3263],\n",
      "        [-1.6555,  2.0711, -0.4466],\n",
      "        [-1.7173,  1.7544, -0.2349],\n",
      "        [-1.6711,  1.6774, -0.6403],\n",
      "        [-1.6809,  1.9038, -0.4187],\n",
      "        [-1.8792,  0.5876,  1.1580]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.7255,  0.0351, -1.2764],\n",
      "        [-1.4233,  2.0236, -0.5373],\n",
      "        [-1.9027,  0.4506,  1.1572],\n",
      "        [-1.6005,  0.4272,  0.9914],\n",
      "        [-1.4734,  1.5211, -0.6165],\n",
      "        [-1.4728,  1.9523, -0.7107],\n",
      "        [-1.7896,  0.4629,  1.0447],\n",
      "        [ 0.2421,  0.6067, -1.4026],\n",
      "        [-1.9012,  0.5591,  1.1467],\n",
      "        [-1.7729,  1.8836, -0.2634],\n",
      "        [-1.6756,  1.7764, -0.7233],\n",
      "        [-1.7547,  0.6113,  1.3260],\n",
      "        [-1.7030,  1.2714,  0.1243],\n",
      "        [-1.5258,  2.1638, -0.5965],\n",
      "        [-1.9062,  0.9288,  1.1712],\n",
      "        [-2.0912,  0.4640,  1.2654]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.7255,  0.0351, -1.2764],\n",
      "        [-1.4233,  2.0236, -0.5373],\n",
      "        [-1.9027,  0.4506,  1.1572],\n",
      "        [-1.6005,  0.4272,  0.9914],\n",
      "        [-1.4734,  1.5211, -0.6165],\n",
      "        [-1.4728,  1.9523, -0.7107],\n",
      "        [-1.7896,  0.4629,  1.0447],\n",
      "        [ 0.2421,  0.6067, -1.4026],\n",
      "        [-1.9012,  0.5591,  1.1467],\n",
      "        [-1.7729,  1.8836, -0.2634],\n",
      "        [-1.6756,  1.7764, -0.7233],\n",
      "        [-1.7547,  0.6113,  1.3260],\n",
      "        [-1.7030,  1.2714,  0.1243],\n",
      "        [-1.5258,  2.1638, -0.5965],\n",
      "        [-1.9062,  0.9288,  1.1712],\n",
      "        [-2.0912,  0.4640,  1.2654]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7757,  0.4997,  1.1070],\n",
      "        [-1.6288,  2.1040, -0.5774],\n",
      "        [-1.6203,  1.7760, -0.6475],\n",
      "        [-1.3899,  1.7301, -0.5897],\n",
      "        [-1.5370,  1.9209, -0.4287],\n",
      "        [-1.5396,  2.0377, -0.4774],\n",
      "        [ 0.8348, -0.0071, -1.2058],\n",
      "        [ 0.7002,  0.0962, -1.2460],\n",
      "        [-1.8794,  0.9296,  0.8306],\n",
      "        [-1.9543,  0.6519,  0.8297],\n",
      "        [-1.8749,  0.8058,  0.9750],\n",
      "        [-1.8380,  0.5955,  0.9830],\n",
      "        [-1.8974,  0.5918,  1.0499],\n",
      "        [-1.6044,  1.8876, -0.7318],\n",
      "        [-1.7459,  2.1360, -0.3120],\n",
      "        [-1.9435,  0.4867,  1.0979]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7757,  0.4997,  1.1070],\n",
      "        [-1.6288,  2.1040, -0.5774],\n",
      "        [-1.6203,  1.7760, -0.6475],\n",
      "        [-1.3899,  1.7301, -0.5897],\n",
      "        [-1.5370,  1.9209, -0.4287],\n",
      "        [-1.5396,  2.0377, -0.4774],\n",
      "        [ 0.8348, -0.0071, -1.2058],\n",
      "        [ 0.7002,  0.0962, -1.2460],\n",
      "        [-1.8794,  0.9296,  0.8306],\n",
      "        [-1.9543,  0.6519,  0.8297],\n",
      "        [-1.8749,  0.8058,  0.9750],\n",
      "        [-1.8380,  0.5955,  0.9830],\n",
      "        [-1.8974,  0.5918,  1.0499],\n",
      "        [-1.6044,  1.8876, -0.7318],\n",
      "        [-1.7459,  2.1360, -0.3120],\n",
      "        [-1.9435,  0.4867,  1.0979]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8195,  0.6451,  1.2097],\n",
      "        [-1.7459,  2.0565, -0.3606],\n",
      "        [-1.5837,  1.8518, -0.4282],\n",
      "        [-1.8994,  2.1622, -0.3904],\n",
      "        [-1.7270,  2.0542, -0.4965],\n",
      "        [ 0.7423, -0.0185, -1.5195],\n",
      "        [-0.9011,  1.2041, -0.8398],\n",
      "        [-1.4977,  1.9091, -0.7911],\n",
      "        [-1.5794,  1.6663, -0.3449],\n",
      "        [-1.7349,  0.4339,  1.1143],\n",
      "        [-2.1054,  0.7233,  1.3639],\n",
      "        [-1.7421,  1.8770, -0.4021],\n",
      "        [-1.5239,  1.9101, -0.5482],\n",
      "        [-1.6650,  1.8157, -0.5112],\n",
      "        [-1.6452,  0.5393,  1.2356],\n",
      "        [-2.0148,  0.5833,  1.1433]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8195,  0.6451,  1.2097],\n",
      "        [-1.7459,  2.0565, -0.3606],\n",
      "        [-1.5837,  1.8518, -0.4282],\n",
      "        [-1.8994,  2.1622, -0.3904],\n",
      "        [-1.7270,  2.0542, -0.4965],\n",
      "        [ 0.7423, -0.0185, -1.5195],\n",
      "        [-0.9011,  1.2041, -0.8398],\n",
      "        [-1.4977,  1.9091, -0.7911],\n",
      "        [-1.5794,  1.6663, -0.3449],\n",
      "        [-1.7349,  0.4339,  1.1143],\n",
      "        [-2.1054,  0.7233,  1.3639],\n",
      "        [-1.7421,  1.8770, -0.4021],\n",
      "        [-1.5239,  1.9101, -0.5482],\n",
      "        [-1.6650,  1.8157, -0.5112],\n",
      "        [-1.6452,  0.5393,  1.2356],\n",
      "        [-2.0148,  0.5833,  1.1433]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6722,  1.6329, -0.1019],\n",
      "        [-1.1722,  1.6289, -0.8291],\n",
      "        [-1.5704,  2.0294, -0.4810],\n",
      "        [-1.6921,  2.1359, -0.4240],\n",
      "        [-1.7222,  2.0737, -0.4935],\n",
      "        [-1.2903,  1.5775, -0.7419],\n",
      "        [-2.0015,  2.0769, -0.6380],\n",
      "        [-1.5814,  1.8795, -0.5686],\n",
      "        [-1.8165,  1.6895,  0.1609],\n",
      "        [-1.7340,  2.1343, -0.6416],\n",
      "        [-1.6342,  1.9105, -0.4708],\n",
      "        [-1.9080,  0.9602,  0.7480],\n",
      "        [ 0.5413,  0.0230, -1.2732],\n",
      "        [ 0.7139,  0.0612, -1.2678],\n",
      "        [-1.7700,  1.9891, -0.4539],\n",
      "        [-1.4841,  1.9893, -0.6597]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6722,  1.6329, -0.1019],\n",
      "        [-1.1722,  1.6289, -0.8291],\n",
      "        [-1.5704,  2.0294, -0.4810],\n",
      "        [-1.6921,  2.1359, -0.4240],\n",
      "        [-1.7222,  2.0737, -0.4935],\n",
      "        [-1.2903,  1.5775, -0.7419],\n",
      "        [-2.0015,  2.0769, -0.6380],\n",
      "        [-1.5814,  1.8795, -0.5686],\n",
      "        [-1.8165,  1.6895,  0.1609],\n",
      "        [-1.7340,  2.1343, -0.6416],\n",
      "        [-1.6342,  1.9105, -0.4708],\n",
      "        [-1.9080,  0.9602,  0.7480],\n",
      "        [ 0.5413,  0.0230, -1.2732],\n",
      "        [ 0.7139,  0.0612, -1.2678],\n",
      "        [-1.7700,  1.9891, -0.4539],\n",
      "        [-1.4841,  1.9893, -0.6597]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3327,  0.3477, -1.2694],\n",
      "        [-1.8374,  2.1619, -0.4732],\n",
      "        [-1.5847,  2.0719, -0.5046],\n",
      "        [-1.6509,  1.5730,  0.0268],\n",
      "        [ 0.5978,  0.2561, -1.3653],\n",
      "        [-1.8778,  0.5912,  1.1558],\n",
      "        [-1.9848,  1.1704,  0.4827],\n",
      "        [ 0.6287,  0.2408, -1.2477],\n",
      "        [-1.8415,  2.1878, -0.5018],\n",
      "        [-1.9651,  0.5807,  1.2498],\n",
      "        [-1.9099,  1.5624,  0.1294],\n",
      "        [-1.4666,  1.7566, -0.4499],\n",
      "        [-1.9854,  0.5858,  1.1785],\n",
      "        [-1.7184,  1.9137, -0.6124],\n",
      "        [-1.6487,  1.9429, -0.5838],\n",
      "        [-1.8107,  0.7469,  1.0624]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.3327,  0.3477, -1.2694],\n",
      "        [-1.8374,  2.1619, -0.4732],\n",
      "        [-1.5847,  2.0719, -0.5046],\n",
      "        [-1.6509,  1.5730,  0.0268],\n",
      "        [ 0.5978,  0.2561, -1.3653],\n",
      "        [-1.8778,  0.5912,  1.1558],\n",
      "        [-1.9848,  1.1704,  0.4827],\n",
      "        [ 0.6287,  0.2408, -1.2477],\n",
      "        [-1.8415,  2.1878, -0.5018],\n",
      "        [-1.9651,  0.5807,  1.2498],\n",
      "        [-1.9099,  1.5624,  0.1294],\n",
      "        [-1.4666,  1.7566, -0.4499],\n",
      "        [-1.9854,  0.5858,  1.1785],\n",
      "        [-1.7184,  1.9137, -0.6124],\n",
      "        [-1.6487,  1.9429, -0.5838],\n",
      "        [-1.8107,  0.7469,  1.0624]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7317,  1.9326, -0.6166],\n",
      "        [-1.7011,  1.8649, -0.5151],\n",
      "        [ 0.8450,  0.0702, -1.1610],\n",
      "        [-1.9406,  2.1253, -0.3229],\n",
      "        [-1.7551,  1.8700, -0.5173],\n",
      "        [ 0.1062,  0.4213, -1.2552],\n",
      "        [-1.5909,  1.8254, -0.4415],\n",
      "        [-1.7534,  1.7412, -0.5265],\n",
      "        [-1.9532,  1.2859,  0.3727],\n",
      "        [-1.7730,  2.1216, -0.4484],\n",
      "        [-1.6444,  0.6261,  0.9356],\n",
      "        [-1.4789,  1.8165, -0.6542],\n",
      "        [-1.6212,  1.8046, -0.5208],\n",
      "        [-1.7119,  1.9953, -0.4593],\n",
      "        [-1.7461,  1.0742,  0.9680],\n",
      "        [-1.8195,  0.7085,  0.9962]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7317,  1.9326, -0.6166],\n",
      "        [-1.7011,  1.8649, -0.5151],\n",
      "        [ 0.8450,  0.0702, -1.1610],\n",
      "        [-1.9406,  2.1253, -0.3229],\n",
      "        [-1.7551,  1.8700, -0.5173],\n",
      "        [ 0.1062,  0.4213, -1.2552],\n",
      "        [-1.5909,  1.8254, -0.4415],\n",
      "        [-1.7534,  1.7412, -0.5265],\n",
      "        [-1.9532,  1.2859,  0.3727],\n",
      "        [-1.7730,  2.1216, -0.4484],\n",
      "        [-1.6444,  0.6261,  0.9356],\n",
      "        [-1.4789,  1.8165, -0.6542],\n",
      "        [-1.6212,  1.8046, -0.5208],\n",
      "        [-1.7119,  1.9953, -0.4593],\n",
      "        [-1.7461,  1.0742,  0.9680],\n",
      "        [-1.8195,  0.7085,  0.9962]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4373,  1.6606, -0.7549],\n",
      "        [ 0.6991,  0.0736, -1.1811],\n",
      "        [-1.7792,  1.8096, -0.1912],\n",
      "        [-1.8895,  2.2303, -0.4581],\n",
      "        [-1.8693,  0.6112,  1.1991],\n",
      "        [-1.9049,  2.1651, -0.4425],\n",
      "        [-1.6498,  1.8441, -0.5276],\n",
      "        [-1.7251,  2.0355, -0.1765],\n",
      "        [-1.9068,  1.8308, -0.3284],\n",
      "        [-1.7140,  2.1919, -0.4827],\n",
      "        [-0.1964,  0.1380, -0.0551],\n",
      "        [-1.7337,  1.9972, -0.1616],\n",
      "        [-1.9977,  1.9026, -0.3689],\n",
      "        [-0.9150,  0.9832, -0.2595],\n",
      "        [ 0.4115,  0.3721, -1.2370],\n",
      "        [-1.7578,  2.1462, -0.2832]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4373,  1.6606, -0.7549],\n",
      "        [ 0.6991,  0.0736, -1.1811],\n",
      "        [-1.7792,  1.8096, -0.1912],\n",
      "        [-1.8895,  2.2303, -0.4581],\n",
      "        [-1.8693,  0.6112,  1.1991],\n",
      "        [-1.9049,  2.1651, -0.4425],\n",
      "        [-1.6498,  1.8441, -0.5276],\n",
      "        [-1.7251,  2.0355, -0.1765],\n",
      "        [-1.9068,  1.8308, -0.3284],\n",
      "        [-1.7140,  2.1919, -0.4827],\n",
      "        [-0.1964,  0.1380, -0.0551],\n",
      "        [-1.7337,  1.9972, -0.1616],\n",
      "        [-1.9977,  1.9026, -0.3689],\n",
      "        [-0.9150,  0.9832, -0.2595],\n",
      "        [ 0.4115,  0.3721, -1.2370],\n",
      "        [-1.7578,  2.1462, -0.2832]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6763,  1.8265, -0.1588],\n",
      "        [-1.6873,  1.8795, -0.2076],\n",
      "        [-1.9277,  2.0164, -0.2334],\n",
      "        [-1.9864,  0.6595,  1.2173],\n",
      "        [-1.9131,  2.0158, -0.3602],\n",
      "        [-1.8218,  2.2156, -0.4340],\n",
      "        [-1.9476,  0.3979,  1.3566],\n",
      "        [-1.6817,  0.6824,  0.8414],\n",
      "        [-0.8951,  0.2385,  0.4339],\n",
      "        [ 0.6820, -0.0258, -1.3029],\n",
      "        [-1.9108,  0.7492,  0.9018],\n",
      "        [ 0.3497,  0.3666, -1.2674],\n",
      "        [-1.6154,  0.6201,  1.0551],\n",
      "        [-1.7613,  1.9504, -0.5131],\n",
      "        [-1.8337,  1.9556, -0.4623],\n",
      "        [-1.7802,  0.5540,  1.0855]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6763,  1.8265, -0.1588],\n",
      "        [-1.6873,  1.8795, -0.2076],\n",
      "        [-1.9277,  2.0164, -0.2334],\n",
      "        [-1.9864,  0.6595,  1.2173],\n",
      "        [-1.9131,  2.0158, -0.3602],\n",
      "        [-1.8218,  2.2156, -0.4340],\n",
      "        [-1.9476,  0.3979,  1.3566],\n",
      "        [-1.6817,  0.6824,  0.8414],\n",
      "        [-0.8951,  0.2385,  0.4339],\n",
      "        [ 0.6820, -0.0258, -1.3029],\n",
      "        [-1.9108,  0.7492,  0.9018],\n",
      "        [ 0.3497,  0.3666, -1.2674],\n",
      "        [-1.6154,  0.6201,  1.0551],\n",
      "        [-1.7613,  1.9504, -0.5131],\n",
      "        [-1.8337,  1.9556, -0.4623],\n",
      "        [-1.7802,  0.5540,  1.0855]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8691,  0.4217,  1.2451],\n",
      "        [-1.6632,  1.8353, -0.5453],\n",
      "        [-1.7847,  1.7751, -0.6337],\n",
      "        [-1.8457,  1.9820, -0.3666],\n",
      "        [-1.8512,  1.2753, -0.1182],\n",
      "        [-1.9249,  2.0611, -0.4450],\n",
      "        [-2.0094,  2.0412, -0.2788],\n",
      "        [-1.9102,  2.0468, -0.4424],\n",
      "        [-2.0633,  1.9927,  0.0126],\n",
      "        [-1.9006,  1.9916, -0.2442],\n",
      "        [-2.0110,  0.3897,  1.3906],\n",
      "        [-1.7183,  1.9864, -0.3620],\n",
      "        [-1.7831,  0.4924,  0.9242],\n",
      "        [-1.9033,  0.2918,  1.2245],\n",
      "        [-1.8436,  2.0797, -0.2759],\n",
      "        [ 0.4174,  0.1364, -1.0915]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8691,  0.4217,  1.2451],\n",
      "        [-1.6632,  1.8353, -0.5453],\n",
      "        [-1.7847,  1.7751, -0.6337],\n",
      "        [-1.8457,  1.9820, -0.3666],\n",
      "        [-1.8512,  1.2753, -0.1182],\n",
      "        [-1.9249,  2.0611, -0.4450],\n",
      "        [-2.0094,  2.0412, -0.2788],\n",
      "        [-1.9102,  2.0468, -0.4424],\n",
      "        [-2.0633,  1.9927,  0.0126],\n",
      "        [-1.9006,  1.9916, -0.2442],\n",
      "        [-2.0110,  0.3897,  1.3906],\n",
      "        [-1.7183,  1.9864, -0.3620],\n",
      "        [-1.7831,  0.4924,  0.9242],\n",
      "        [-1.9033,  0.2918,  1.2245],\n",
      "        [-1.8436,  2.0797, -0.2759],\n",
      "        [ 0.4174,  0.1364, -1.0915]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9879,  0.5597,  0.9520],\n",
      "        [-1.9962,  0.4625,  1.2609],\n",
      "        [-1.5605,  1.9254, -0.6015],\n",
      "        [-1.6635,  1.7280, -0.1433],\n",
      "        [-0.4384,  0.8482, -0.6554],\n",
      "        [-1.9267,  1.8285, -0.0203],\n",
      "        [-1.9462,  1.8914, -0.0023],\n",
      "        [-1.8420,  1.7357, -0.2649],\n",
      "        [-1.7875,  1.7952, -0.1895],\n",
      "        [-1.8563,  1.8065, -0.4250],\n",
      "        [-1.5707,  1.9382, -0.4355],\n",
      "        [-1.7045,  0.4510,  1.1551],\n",
      "        [-1.7194,  2.0423, -0.3846],\n",
      "        [-1.9755,  1.8985, -0.1840],\n",
      "        [-1.9988,  0.9602,  1.0584],\n",
      "        [-1.9449,  1.6991, -0.5313]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9879,  0.5597,  0.9520],\n",
      "        [-1.9962,  0.4625,  1.2609],\n",
      "        [-1.5605,  1.9254, -0.6015],\n",
      "        [-1.6635,  1.7280, -0.1433],\n",
      "        [-0.4384,  0.8482, -0.6554],\n",
      "        [-1.9267,  1.8285, -0.0203],\n",
      "        [-1.9462,  1.8914, -0.0023],\n",
      "        [-1.8420,  1.7357, -0.2649],\n",
      "        [-1.7875,  1.7952, -0.1895],\n",
      "        [-1.8563,  1.8065, -0.4250],\n",
      "        [-1.5707,  1.9382, -0.4355],\n",
      "        [-1.7045,  0.4510,  1.1551],\n",
      "        [-1.7194,  2.0423, -0.3846],\n",
      "        [-1.9755,  1.8985, -0.1840],\n",
      "        [-1.9988,  0.9602,  1.0584],\n",
      "        [-1.9449,  1.6991, -0.5313]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.2057,  0.5244, -0.8543],\n",
      "        [-2.0731,  0.5210,  1.4388],\n",
      "        [-1.8307,  1.8782, -0.1721],\n",
      "        [-1.3436,  0.3562,  0.6869],\n",
      "        [-1.9384,  2.0155, -0.3020],\n",
      "        [-1.8360,  2.0503, -0.1851],\n",
      "        [-2.0014,  1.8715, -0.1787],\n",
      "        [-1.8083,  1.6268, -0.4879],\n",
      "        [-1.5901,  1.4484, -0.2410],\n",
      "        [-1.7518,  0.4883,  1.4504],\n",
      "        [ 0.3946,  0.2292, -1.0262],\n",
      "        [-1.7876,  1.9363, -0.3977],\n",
      "        [-1.3405,  1.4671, -0.6984],\n",
      "        [-1.8567,  0.4720,  1.3346],\n",
      "        [ 0.3807,  0.1170, -1.2145],\n",
      "        [-1.5327,  1.5159, -0.5358]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-0.2057,  0.5244, -0.8543],\n",
      "        [-2.0731,  0.5210,  1.4388],\n",
      "        [-1.8307,  1.8782, -0.1721],\n",
      "        [-1.3436,  0.3562,  0.6869],\n",
      "        [-1.9384,  2.0155, -0.3020],\n",
      "        [-1.8360,  2.0503, -0.1851],\n",
      "        [-2.0014,  1.8715, -0.1787],\n",
      "        [-1.8083,  1.6268, -0.4879],\n",
      "        [-1.5901,  1.4484, -0.2410],\n",
      "        [-1.7518,  0.4883,  1.4504],\n",
      "        [ 0.3946,  0.2292, -1.0262],\n",
      "        [-1.7876,  1.9363, -0.3977],\n",
      "        [-1.3405,  1.4671, -0.6984],\n",
      "        [-1.8567,  0.4720,  1.3346],\n",
      "        [ 0.3807,  0.1170, -1.2145],\n",
      "        [-1.5327,  1.5159, -0.5358]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8740,  0.8700,  0.8148],\n",
      "        [-1.8562,  1.8292, -0.0321],\n",
      "        [-2.1010,  0.5203,  1.3121],\n",
      "        [-1.8823,  0.4829,  1.3651],\n",
      "        [-2.1102,  2.0130, -0.0768],\n",
      "        [-1.9537,  1.8670, -0.0439],\n",
      "        [-1.7489,  1.8758, -0.1677],\n",
      "        [-1.8115,  0.3728,  1.3072],\n",
      "        [-2.0284,  2.0139, -0.0646],\n",
      "        [-2.0507,  2.0190, -0.1588],\n",
      "        [-1.9507,  0.4631,  1.3114],\n",
      "        [-1.4185,  1.4056, -0.4911],\n",
      "        [-1.6939,  2.1446, -0.3872],\n",
      "        [-1.8209,  0.5939,  1.4228],\n",
      "        [ 0.3290,  0.1209, -0.9416],\n",
      "        [-1.8865,  1.8532, -0.3453]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8740,  0.8700,  0.8148],\n",
      "        [-1.8562,  1.8292, -0.0321],\n",
      "        [-2.1010,  0.5203,  1.3121],\n",
      "        [-1.8823,  0.4829,  1.3651],\n",
      "        [-2.1102,  2.0130, -0.0768],\n",
      "        [-1.9537,  1.8670, -0.0439],\n",
      "        [-1.7489,  1.8758, -0.1677],\n",
      "        [-1.8115,  0.3728,  1.3072],\n",
      "        [-2.0284,  2.0139, -0.0646],\n",
      "        [-2.0507,  2.0190, -0.1588],\n",
      "        [-1.9507,  0.4631,  1.3114],\n",
      "        [-1.4185,  1.4056, -0.4911],\n",
      "        [-1.6939,  2.1446, -0.3872],\n",
      "        [-1.8209,  0.5939,  1.4228],\n",
      "        [ 0.3290,  0.1209, -0.9416],\n",
      "        [-1.8865,  1.8532, -0.3453]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7383,  2.0587, -0.3185],\n",
      "        [ 0.4710,  0.0754, -1.1852],\n",
      "        [ 0.3884,  0.0420, -1.0366],\n",
      "        [-1.7863,  1.9678, -0.4613],\n",
      "        [-1.6527,  0.1995,  1.2141],\n",
      "        [-1.8422,  1.9382, -0.2011],\n",
      "        [-1.8949,  0.5160,  1.3732],\n",
      "        [-1.9924,  0.3475,  1.3819],\n",
      "        [-1.8420,  1.6634,  0.1326],\n",
      "        [-2.2595,  0.6571,  1.2025],\n",
      "        [-1.8006,  2.0131, -0.1350],\n",
      "        [-1.8221,  0.5256,  1.4274],\n",
      "        [-1.8541,  1.9623, -0.4101],\n",
      "        [-1.9208,  0.4464,  1.3851],\n",
      "        [-1.7281,  0.4506,  1.2819],\n",
      "        [-1.6267,  0.3400,  1.2386]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7383,  2.0587, -0.3185],\n",
      "        [ 0.4710,  0.0754, -1.1852],\n",
      "        [ 0.3884,  0.0420, -1.0366],\n",
      "        [-1.7863,  1.9678, -0.4613],\n",
      "        [-1.6527,  0.1995,  1.2141],\n",
      "        [-1.8422,  1.9382, -0.2011],\n",
      "        [-1.8949,  0.5160,  1.3732],\n",
      "        [-1.9924,  0.3475,  1.3819],\n",
      "        [-1.8420,  1.6634,  0.1326],\n",
      "        [-2.2595,  0.6571,  1.2025],\n",
      "        [-1.8006,  2.0131, -0.1350],\n",
      "        [-1.8221,  0.5256,  1.4274],\n",
      "        [-1.8541,  1.9623, -0.4101],\n",
      "        [-1.9208,  0.4464,  1.3851],\n",
      "        [-1.7281,  0.4506,  1.2819],\n",
      "        [-1.6267,  0.3400,  1.2386]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9923,  0.4221,  1.5908],\n",
      "        [-1.9327,  0.3432,  1.3778],\n",
      "        [-1.4619,  1.2780, -0.3722],\n",
      "        [-1.7509,  1.8744, -0.1978],\n",
      "        [-2.0400,  1.9242, -0.3459],\n",
      "        [ 0.3989,  0.2295, -1.1242],\n",
      "        [-1.7030,  2.0477, -0.3796],\n",
      "        [-1.8179,  1.5111, -0.2884],\n",
      "        [-2.0468,  1.7242, -0.2359],\n",
      "        [-1.9433,  1.8416, -0.2432],\n",
      "        [ 0.4092,  0.2770, -1.0528],\n",
      "        [-1.7491,  1.8192, -0.4979],\n",
      "        [-1.8987,  1.7093, -0.2601],\n",
      "        [-1.6674,  1.8643, -0.4544],\n",
      "        [-1.7656,  1.8057, -0.3400],\n",
      "        [-1.7728,  2.1707, -0.4045]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9923,  0.4221,  1.5908],\n",
      "        [-1.9327,  0.3432,  1.3778],\n",
      "        [-1.4619,  1.2780, -0.3722],\n",
      "        [-1.7509,  1.8744, -0.1978],\n",
      "        [-2.0400,  1.9242, -0.3459],\n",
      "        [ 0.3989,  0.2295, -1.1242],\n",
      "        [-1.7030,  2.0477, -0.3796],\n",
      "        [-1.8179,  1.5111, -0.2884],\n",
      "        [-2.0468,  1.7242, -0.2359],\n",
      "        [-1.9433,  1.8416, -0.2432],\n",
      "        [ 0.4092,  0.2770, -1.0528],\n",
      "        [-1.7491,  1.8192, -0.4979],\n",
      "        [-1.8987,  1.7093, -0.2601],\n",
      "        [-1.6674,  1.8643, -0.4544],\n",
      "        [-1.7656,  1.8057, -0.3400],\n",
      "        [-1.7728,  2.1707, -0.4045]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9141,  1.8931, -0.3712],\n",
      "        [-1.8635,  1.8140, -0.2104],\n",
      "        [-2.0377,  0.4276,  1.4773],\n",
      "        [-1.7822,  1.7588, -0.1738],\n",
      "        [-2.1666,  1.4898,  0.3832],\n",
      "        [-1.4473,  1.4518, -0.3012],\n",
      "        [-1.7606,  0.2567,  1.4162],\n",
      "        [-1.8178,  1.8971, -0.2399],\n",
      "        [-1.9810,  1.7994, -0.2907],\n",
      "        [-0.5045,  0.1949, -0.0131],\n",
      "        [-2.1901,  0.5085,  1.3893],\n",
      "        [-1.9178,  1.8767, -0.3194],\n",
      "        [ 0.3325,  0.0888, -1.0134],\n",
      "        [-2.0899,  2.0702, -0.3145],\n",
      "        [-1.9362,  1.7713, -0.2886],\n",
      "        [-2.0289,  2.0896, -0.1923]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9141,  1.8931, -0.3712],\n",
      "        [-1.8635,  1.8140, -0.2104],\n",
      "        [-2.0377,  0.4276,  1.4773],\n",
      "        [-1.7822,  1.7588, -0.1738],\n",
      "        [-2.1666,  1.4898,  0.3832],\n",
      "        [-1.4473,  1.4518, -0.3012],\n",
      "        [-1.7606,  0.2567,  1.4162],\n",
      "        [-1.8178,  1.8971, -0.2399],\n",
      "        [-1.9810,  1.7994, -0.2907],\n",
      "        [-0.5045,  0.1949, -0.0131],\n",
      "        [-2.1901,  0.5085,  1.3893],\n",
      "        [-1.9178,  1.8767, -0.3194],\n",
      "        [ 0.3325,  0.0888, -1.0134],\n",
      "        [-2.0899,  2.0702, -0.3145],\n",
      "        [-1.9362,  1.7713, -0.2886],\n",
      "        [-2.0289,  2.0896, -0.1923]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9805,  1.8570, -0.4737],\n",
      "        [-1.9727,  1.5154,  0.1020],\n",
      "        [-1.8098,  1.8231, -0.3744],\n",
      "        [-1.9216,  0.4555,  1.4634],\n",
      "        [-0.5851,  0.8404, -0.7767],\n",
      "        [-0.8561,  1.0293, -0.5875],\n",
      "        [-0.3291,  0.6837, -0.7065],\n",
      "        [ 0.4691,  0.1638, -1.0170],\n",
      "        [-0.1806,  0.6156, -1.0056],\n",
      "        [-1.7026,  1.8552, -0.2929],\n",
      "        [-1.5901,  2.0216, -0.5086],\n",
      "        [-1.8864,  2.1256, -0.4050],\n",
      "        [-2.1121,  0.3714,  1.4189],\n",
      "        [ 0.2073, -0.0924, -0.6375],\n",
      "        [-1.7921,  0.2760,  1.3852],\n",
      "        [-1.9544,  0.3481,  1.4150]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9805,  1.8570, -0.4737],\n",
      "        [-1.9727,  1.5154,  0.1020],\n",
      "        [-1.8098,  1.8231, -0.3744],\n",
      "        [-1.9216,  0.4555,  1.4634],\n",
      "        [-0.5851,  0.8404, -0.7767],\n",
      "        [-0.8561,  1.0293, -0.5875],\n",
      "        [-0.3291,  0.6837, -0.7065],\n",
      "        [ 0.4691,  0.1638, -1.0170],\n",
      "        [-0.1806,  0.6156, -1.0056],\n",
      "        [-1.7026,  1.8552, -0.2929],\n",
      "        [-1.5901,  2.0216, -0.5086],\n",
      "        [-1.8864,  2.1256, -0.4050],\n",
      "        [-2.1121,  0.3714,  1.4189],\n",
      "        [ 0.2073, -0.0924, -0.6375],\n",
      "        [-1.7921,  0.2760,  1.3852],\n",
      "        [-1.9544,  0.3481,  1.4150]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9241,  0.4027,  1.5263],\n",
      "        [-1.8742,  1.9079, -0.1939],\n",
      "        [-1.7426,  1.7714, -0.3346],\n",
      "        [-1.7801,  0.5130,  1.3330],\n",
      "        [ 0.2786,  0.2294, -0.9422],\n",
      "        [-1.8964,  1.9165, -0.2669],\n",
      "        [-1.7824,  0.2587,  1.2647],\n",
      "        [-2.0393,  1.9211, -0.5050],\n",
      "        [-1.9107,  1.8595, -0.2695],\n",
      "        [-1.8851,  1.8378, -0.3746],\n",
      "        [-1.8386,  1.8103, -0.5183],\n",
      "        [-1.9675,  0.5749,  1.2974],\n",
      "        [-1.9410,  0.4312,  1.1316],\n",
      "        [-2.0653,  1.5586,  0.2462],\n",
      "        [-2.0699,  2.0555, -0.2966],\n",
      "        [-1.9651,  1.7558, -0.2267]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9241,  0.4027,  1.5263],\n",
      "        [-1.8742,  1.9079, -0.1939],\n",
      "        [-1.7426,  1.7714, -0.3346],\n",
      "        [-1.7801,  0.5130,  1.3330],\n",
      "        [ 0.2786,  0.2294, -0.9422],\n",
      "        [-1.8964,  1.9165, -0.2669],\n",
      "        [-1.7824,  0.2587,  1.2647],\n",
      "        [-2.0393,  1.9211, -0.5050],\n",
      "        [-1.9107,  1.8595, -0.2695],\n",
      "        [-1.8851,  1.8378, -0.3746],\n",
      "        [-1.8386,  1.8103, -0.5183],\n",
      "        [-1.9675,  0.5749,  1.2974],\n",
      "        [-1.9410,  0.4312,  1.1316],\n",
      "        [-2.0653,  1.5586,  0.2462],\n",
      "        [-2.0699,  2.0555, -0.2966],\n",
      "        [-1.9651,  1.7558, -0.2267]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9243e+00,  2.0201e+00, -2.7529e-04],\n",
      "        [ 4.0648e-01, -5.0526e-02, -1.0596e+00],\n",
      "        [-1.8586e+00,  2.0384e+00, -2.6743e-01],\n",
      "        [-1.9800e+00,  1.8505e+00, -2.5116e-01],\n",
      "        [-2.0362e+00,  1.7284e+00, -5.0376e-02],\n",
      "        [-1.8175e+00,  3.5106e-01,  1.2551e+00],\n",
      "        [-2.1393e+00,  1.4056e+00,  4.2152e-01],\n",
      "        [-1.8125e+00,  1.9345e+00, -1.4473e-01],\n",
      "        [-2.0293e+00,  1.9887e+00, -1.8726e-01],\n",
      "        [-1.8354e+00,  1.8500e+00, -4.7082e-01],\n",
      "        [-1.8494e+00,  6.7606e-01,  9.4084e-01],\n",
      "        [-1.6984e+00,  1.9940e-01,  1.5212e+00],\n",
      "        [-1.9689e+00,  1.7836e+00, -1.1533e-01],\n",
      "        [-1.9915e+00,  1.9471e+00, -2.1317e-01],\n",
      "        [ 4.6435e-01,  1.4673e-01, -9.4451e-01],\n",
      "        [-1.9004e+00,  1.8552e+00, -1.8060e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9243e+00,  2.0201e+00, -2.7529e-04],\n",
      "        [ 4.0648e-01, -5.0526e-02, -1.0596e+00],\n",
      "        [-1.8586e+00,  2.0384e+00, -2.6743e-01],\n",
      "        [-1.9800e+00,  1.8505e+00, -2.5116e-01],\n",
      "        [-2.0362e+00,  1.7284e+00, -5.0376e-02],\n",
      "        [-1.8175e+00,  3.5106e-01,  1.2551e+00],\n",
      "        [-2.1393e+00,  1.4056e+00,  4.2152e-01],\n",
      "        [-1.8125e+00,  1.9345e+00, -1.4473e-01],\n",
      "        [-2.0293e+00,  1.9887e+00, -1.8726e-01],\n",
      "        [-1.8354e+00,  1.8500e+00, -4.7082e-01],\n",
      "        [-1.8494e+00,  6.7606e-01,  9.4084e-01],\n",
      "        [-1.6984e+00,  1.9940e-01,  1.5212e+00],\n",
      "        [-1.9689e+00,  1.7836e+00, -1.1533e-01],\n",
      "        [-1.9915e+00,  1.9471e+00, -2.1317e-01],\n",
      "        [ 4.6435e-01,  1.4673e-01, -9.4451e-01],\n",
      "        [-1.9004e+00,  1.8552e+00, -1.8060e-01]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.1257,  0.1098,  0.8949],\n",
      "        [ 0.5837, -0.0302, -0.9735],\n",
      "        [-1.8824,  1.7903, -0.0869],\n",
      "        [-1.8434,  1.9029, -0.3108],\n",
      "        [-1.8122,  1.8639, -0.4094],\n",
      "        [-2.0626,  2.0204, -0.0123],\n",
      "        [-1.7932,  1.9576, -0.1914],\n",
      "        [-0.5929,  0.6735, -0.6719],\n",
      "        [-1.6748,  1.9334, -0.3212],\n",
      "        [-1.9617,  0.1623,  1.4695],\n",
      "        [ 0.3704,  0.1782, -0.9683],\n",
      "        [-1.8042,  0.3497,  1.2515],\n",
      "        [-2.0689,  1.5474,  0.0419],\n",
      "        [-1.9449,  2.0767, -0.3605],\n",
      "        [-1.9201,  1.9172, -0.4271],\n",
      "        [-1.7930,  0.3201,  1.3503]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.1257,  0.1098,  0.8949],\n",
      "        [ 0.5837, -0.0302, -0.9735],\n",
      "        [-1.8824,  1.7903, -0.0869],\n",
      "        [-1.8434,  1.9029, -0.3108],\n",
      "        [-1.8122,  1.8639, -0.4094],\n",
      "        [-2.0626,  2.0204, -0.0123],\n",
      "        [-1.7932,  1.9576, -0.1914],\n",
      "        [-0.5929,  0.6735, -0.6719],\n",
      "        [-1.6748,  1.9334, -0.3212],\n",
      "        [-1.9617,  0.1623,  1.4695],\n",
      "        [ 0.3704,  0.1782, -0.9683],\n",
      "        [-1.8042,  0.3497,  1.2515],\n",
      "        [-2.0689,  1.5474,  0.0419],\n",
      "        [-1.9449,  2.0767, -0.3605],\n",
      "        [-1.9201,  1.9172, -0.4271],\n",
      "        [-1.7930,  0.3201,  1.3503]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5448,  0.0398, -1.0448],\n",
      "        [-1.8408,  1.6728, -0.1624],\n",
      "        [-1.8978,  1.7510, -0.2684],\n",
      "        [-1.9146,  1.9266, -0.4000],\n",
      "        [ 0.1302,  0.2405, -0.9285],\n",
      "        [ 0.4086,  0.1507, -0.8838],\n",
      "        [-1.8856,  1.9209, -0.1492],\n",
      "        [-1.8886,  0.5613,  1.2272],\n",
      "        [-1.9127,  1.9610, -0.0852],\n",
      "        [-2.0772,  1.8242,  0.0405],\n",
      "        [-1.9955,  1.1712,  0.6832],\n",
      "        [-1.8982,  0.4868,  1.4455],\n",
      "        [-1.8274,  1.6199, -0.2403],\n",
      "        [-2.2332,  1.2862,  0.7597],\n",
      "        [-2.1439,  1.9219,  0.0255],\n",
      "        [-1.9576,  1.9356, -0.3643]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.5448,  0.0398, -1.0448],\n",
      "        [-1.8408,  1.6728, -0.1624],\n",
      "        [-1.8978,  1.7510, -0.2684],\n",
      "        [-1.9146,  1.9266, -0.4000],\n",
      "        [ 0.1302,  0.2405, -0.9285],\n",
      "        [ 0.4086,  0.1507, -0.8838],\n",
      "        [-1.8856,  1.9209, -0.1492],\n",
      "        [-1.8886,  0.5613,  1.2272],\n",
      "        [-1.9127,  1.9610, -0.0852],\n",
      "        [-2.0772,  1.8242,  0.0405],\n",
      "        [-1.9955,  1.1712,  0.6832],\n",
      "        [-1.8982,  0.4868,  1.4455],\n",
      "        [-1.8274,  1.6199, -0.2403],\n",
      "        [-2.2332,  1.2862,  0.7597],\n",
      "        [-2.1439,  1.9219,  0.0255],\n",
      "        [-1.9576,  1.9356, -0.3643]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8640,  1.2299,  0.3200],\n",
      "        [-1.8810,  0.3233,  1.2943],\n",
      "        [-1.8304,  1.7377, -0.1373],\n",
      "        [-1.7617,  0.3743,  1.4807],\n",
      "        [-1.2315,  1.3688, -0.3494],\n",
      "        [-1.9624,  2.1003, -0.2370],\n",
      "        [-1.8036,  1.7458, -0.4931],\n",
      "        [-1.7048,  0.2904,  1.4768],\n",
      "        [-1.7456,  0.5240,  1.2298],\n",
      "        [-2.0045,  0.4477,  1.4150],\n",
      "        [ 0.5596, -0.0950, -1.0451],\n",
      "        [-1.8300,  2.1026, -0.1087],\n",
      "        [-1.8981,  1.6425, -0.2123],\n",
      "        [ 0.4997, -0.0036, -0.9776],\n",
      "        [-1.7197,  0.5221,  0.9168],\n",
      "        [-1.7409,  1.7883, -0.2240]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8640,  1.2299,  0.3200],\n",
      "        [-1.8810,  0.3233,  1.2943],\n",
      "        [-1.8304,  1.7377, -0.1373],\n",
      "        [-1.7617,  0.3743,  1.4807],\n",
      "        [-1.2315,  1.3688, -0.3494],\n",
      "        [-1.9624,  2.1003, -0.2370],\n",
      "        [-1.8036,  1.7458, -0.4931],\n",
      "        [-1.7048,  0.2904,  1.4768],\n",
      "        [-1.7456,  0.5240,  1.2298],\n",
      "        [-2.0045,  0.4477,  1.4150],\n",
      "        [ 0.5596, -0.0950, -1.0451],\n",
      "        [-1.8300,  2.1026, -0.1087],\n",
      "        [-1.8981,  1.6425, -0.2123],\n",
      "        [ 0.4997, -0.0036, -0.9776],\n",
      "        [-1.7197,  0.5221,  0.9168],\n",
      "        [-1.7409,  1.7883, -0.2240]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8518,  1.3228,  0.1262],\n",
      "        [-1.6766,  1.5529, -0.3146],\n",
      "        [-1.9349,  1.9016, -0.1118],\n",
      "        [-1.7460,  1.6945, -0.2453],\n",
      "        [-1.7687,  2.0455, -0.3749],\n",
      "        [-1.8829,  1.9734, -0.2627],\n",
      "        [-1.8540,  0.0973,  1.5106],\n",
      "        [-2.0682,  1.4571,  0.3379],\n",
      "        [-1.8894,  1.4579,  0.1122],\n",
      "        [-1.7971,  1.8817, -0.2816],\n",
      "        [ 0.5028, -0.0645, -1.0324],\n",
      "        [-1.5756,  1.8807, -0.3775],\n",
      "        [-1.7317,  1.9557, -0.1770],\n",
      "        [-1.8254,  1.7926, -0.1031],\n",
      "        [-1.7801,  1.8193, -0.2530],\n",
      "        [ 0.5585,  0.0309, -0.9428]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8518,  1.3228,  0.1262],\n",
      "        [-1.6766,  1.5529, -0.3146],\n",
      "        [-1.9349,  1.9016, -0.1118],\n",
      "        [-1.7460,  1.6945, -0.2453],\n",
      "        [-1.7687,  2.0455, -0.3749],\n",
      "        [-1.8829,  1.9734, -0.2627],\n",
      "        [-1.8540,  0.0973,  1.5106],\n",
      "        [-2.0682,  1.4571,  0.3379],\n",
      "        [-1.8894,  1.4579,  0.1122],\n",
      "        [-1.7971,  1.8817, -0.2816],\n",
      "        [ 0.5028, -0.0645, -1.0324],\n",
      "        [-1.5756,  1.8807, -0.3775],\n",
      "        [-1.7317,  1.9557, -0.1770],\n",
      "        [-1.8254,  1.7926, -0.1031],\n",
      "        [-1.7801,  1.8193, -0.2530],\n",
      "        [ 0.5585,  0.0309, -0.9428]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.4165, -0.0663, -0.8988],\n",
      "        [-1.7113,  1.6931,  0.0357],\n",
      "        [-1.9683,  0.4164,  1.2978],\n",
      "        [-1.7403,  1.9792, -0.1809],\n",
      "        [-1.6791,  1.6203, -0.4058],\n",
      "        [-1.6609,  1.9044, -0.2626],\n",
      "        [-2.0157,  1.9090, -0.2034],\n",
      "        [-1.5206,  1.9431, -0.3505],\n",
      "        [ 0.5468, -0.2714, -0.8770],\n",
      "        [-1.8908,  1.7013, -0.2138],\n",
      "        [-1.9510,  1.8867, -0.2171],\n",
      "        [-1.9417,  0.3516,  1.5124],\n",
      "        [-1.6584,  1.6847, -0.2954],\n",
      "        [-1.9930,  1.9943, -0.3060],\n",
      "        [-1.6656,  1.8658, -0.1221],\n",
      "        [-1.8835,  0.2353,  1.5162]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.4165, -0.0663, -0.8988],\n",
      "        [-1.7113,  1.6931,  0.0357],\n",
      "        [-1.9683,  0.4164,  1.2978],\n",
      "        [-1.7403,  1.9792, -0.1809],\n",
      "        [-1.6791,  1.6203, -0.4058],\n",
      "        [-1.6609,  1.9044, -0.2626],\n",
      "        [-2.0157,  1.9090, -0.2034],\n",
      "        [-1.5206,  1.9431, -0.3505],\n",
      "        [ 0.5468, -0.2714, -0.8770],\n",
      "        [-1.8908,  1.7013, -0.2138],\n",
      "        [-1.9510,  1.8867, -0.2171],\n",
      "        [-1.9417,  0.3516,  1.5124],\n",
      "        [-1.6584,  1.6847, -0.2954],\n",
      "        [-1.9930,  1.9943, -0.3060],\n",
      "        [-1.6656,  1.8658, -0.1221],\n",
      "        [-1.8835,  0.2353,  1.5162]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.0054,  1.8951, -0.4050],\n",
      "        [-1.5630,  1.6334, -0.2437],\n",
      "        [-1.8749,  1.8470, -0.2128],\n",
      "        [ 0.5250, -0.1564, -0.9510],\n",
      "        [-1.8374,  1.4756,  0.0801],\n",
      "        [-1.6833,  1.7356, -0.2341],\n",
      "        [-1.4137,  1.4736, -0.0405],\n",
      "        [-1.8965,  0.7879,  0.6743],\n",
      "        [-1.8199,  0.2572,  1.5067],\n",
      "        [-1.7111,  1.9917, -0.3263],\n",
      "        [-1.7870,  0.6871,  1.0470],\n",
      "        [-1.8504,  2.1161, -0.4138],\n",
      "        [-2.0856,  1.2355,  0.4115],\n",
      "        [-2.1256,  2.1089, -0.2169],\n",
      "        [-1.5461,  1.7565, -0.3036],\n",
      "        [ 0.0480,  0.0840, -0.4070]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.0054,  1.8951, -0.4050],\n",
      "        [-1.5630,  1.6334, -0.2437],\n",
      "        [-1.8749,  1.8470, -0.2128],\n",
      "        [ 0.5250, -0.1564, -0.9510],\n",
      "        [-1.8374,  1.4756,  0.0801],\n",
      "        [-1.6833,  1.7356, -0.2341],\n",
      "        [-1.4137,  1.4736, -0.0405],\n",
      "        [-1.8965,  0.7879,  0.6743],\n",
      "        [-1.8199,  0.2572,  1.5067],\n",
      "        [-1.7111,  1.9917, -0.3263],\n",
      "        [-1.7870,  0.6871,  1.0470],\n",
      "        [-1.8504,  2.1161, -0.4138],\n",
      "        [-2.0856,  1.2355,  0.4115],\n",
      "        [-2.1256,  2.1089, -0.2169],\n",
      "        [-1.5461,  1.7565, -0.3036],\n",
      "        [ 0.0480,  0.0840, -0.4070]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8777,  2.0038, -0.3692],\n",
      "        [-1.6344,  1.7876, -0.2548],\n",
      "        [-1.9122,  2.0029, -0.1439],\n",
      "        [-1.8236,  1.8698, -0.4406],\n",
      "        [-1.8161,  2.0304, -0.2420],\n",
      "        [-0.2041,  0.8572, -0.9469],\n",
      "        [-1.9374,  1.8808, -0.0437],\n",
      "        [-1.8660,  0.5609,  1.1173],\n",
      "        [-1.9835,  0.3973,  1.5065],\n",
      "        [ 0.2318, -0.1448, -0.6571],\n",
      "        [-1.5929,  1.8712,  0.0383],\n",
      "        [ 0.0950,  0.1611, -0.6625],\n",
      "        [-1.7173,  1.9023, -0.3754],\n",
      "        [-1.7379,  1.8014, -0.1776],\n",
      "        [-1.5227,  1.7978, -0.2974],\n",
      "        [-1.6687,  1.9548, -0.2660]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8777,  2.0038, -0.3692],\n",
      "        [-1.6344,  1.7876, -0.2548],\n",
      "        [-1.9122,  2.0029, -0.1439],\n",
      "        [-1.8236,  1.8698, -0.4406],\n",
      "        [-1.8161,  2.0304, -0.2420],\n",
      "        [-0.2041,  0.8572, -0.9469],\n",
      "        [-1.9374,  1.8808, -0.0437],\n",
      "        [-1.8660,  0.5609,  1.1173],\n",
      "        [-1.9835,  0.3973,  1.5065],\n",
      "        [ 0.2318, -0.1448, -0.6571],\n",
      "        [-1.5929,  1.8712,  0.0383],\n",
      "        [ 0.0950,  0.1611, -0.6625],\n",
      "        [-1.7173,  1.9023, -0.3754],\n",
      "        [-1.7379,  1.8014, -0.1776],\n",
      "        [-1.5227,  1.7978, -0.2974],\n",
      "        [-1.6687,  1.9548, -0.2660]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5635,  1.6368, -0.0535],\n",
      "        [-1.7626,  1.5450,  0.0491],\n",
      "        [-1.7770,  1.7240, -0.2160],\n",
      "        [-1.8965,  0.2247,  1.4817],\n",
      "        [ 0.2327,  0.1050, -0.7355],\n",
      "        [-1.6629,  1.8595, -0.3507],\n",
      "        [-1.7000,  0.4515,  1.2495],\n",
      "        [-1.6927,  0.0903,  1.3636],\n",
      "        [-2.0845,  0.3059,  1.5897],\n",
      "        [-1.9191,  1.8945, -0.2594],\n",
      "        [-1.9521,  1.3825,  0.2099],\n",
      "        [-2.0381,  0.5539,  1.2530],\n",
      "        [-1.8148,  1.8843,  0.0716],\n",
      "        [-1.7066,  1.7892, -0.3691],\n",
      "        [-1.9414,  2.2226, -0.3286],\n",
      "        [-1.8089,  0.4224,  1.4032]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5635,  1.6368, -0.0535],\n",
      "        [-1.7626,  1.5450,  0.0491],\n",
      "        [-1.7770,  1.7240, -0.2160],\n",
      "        [-1.8965,  0.2247,  1.4817],\n",
      "        [ 0.2327,  0.1050, -0.7355],\n",
      "        [-1.6629,  1.8595, -0.3507],\n",
      "        [-1.7000,  0.4515,  1.2495],\n",
      "        [-1.6927,  0.0903,  1.3636],\n",
      "        [-2.0845,  0.3059,  1.5897],\n",
      "        [-1.9191,  1.8945, -0.2594],\n",
      "        [-1.9521,  1.3825,  0.2099],\n",
      "        [-2.0381,  0.5539,  1.2530],\n",
      "        [-1.8148,  1.8843,  0.0716],\n",
      "        [-1.7066,  1.7892, -0.3691],\n",
      "        [-1.9414,  2.2226, -0.3286],\n",
      "        [-1.8089,  0.4224,  1.4032]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8081,  1.6825, -0.4677],\n",
      "        [-1.7754,  1.9143, -0.1710],\n",
      "        [-1.6164,  1.7248, -0.5588],\n",
      "        [-0.9869,  1.0634, -0.5330],\n",
      "        [-0.0692, -0.1453, -0.1931],\n",
      "        [-1.3699,  1.3482, -0.5587],\n",
      "        [-1.7993,  1.7925, -0.2658],\n",
      "        [-1.6448,  1.7564, -0.2158],\n",
      "        [-1.2564,  1.8014, -0.3753],\n",
      "        [-0.2458, -0.0686, -0.2005],\n",
      "        [ 0.0464,  0.2695, -0.9868],\n",
      "        [-1.4481,  1.7860, -0.2710],\n",
      "        [-1.8140,  1.7876, -0.1818],\n",
      "        [-1.7617,  1.9273, -0.2327],\n",
      "        [-1.8116,  0.3227,  1.4608],\n",
      "        [-0.5238,  0.5357, -0.5402]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8081,  1.6825, -0.4677],\n",
      "        [-1.7754,  1.9143, -0.1710],\n",
      "        [-1.6164,  1.7248, -0.5588],\n",
      "        [-0.9869,  1.0634, -0.5330],\n",
      "        [-0.0692, -0.1453, -0.1931],\n",
      "        [-1.3699,  1.3482, -0.5587],\n",
      "        [-1.7993,  1.7925, -0.2658],\n",
      "        [-1.6448,  1.7564, -0.2158],\n",
      "        [-1.2564,  1.8014, -0.3753],\n",
      "        [-0.2458, -0.0686, -0.2005],\n",
      "        [ 0.0464,  0.2695, -0.9868],\n",
      "        [-1.4481,  1.7860, -0.2710],\n",
      "        [-1.8140,  1.7876, -0.1818],\n",
      "        [-1.7617,  1.9273, -0.2327],\n",
      "        [-1.8116,  0.3227,  1.4608],\n",
      "        [-0.5238,  0.5357, -0.5402]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5765,  1.8257, -0.2812],\n",
      "        [-1.7000,  0.9791,  0.7323],\n",
      "        [ 0.3478, -0.0053, -0.8325],\n",
      "        [ 0.2581,  0.0240, -0.7967],\n",
      "        [-1.8627,  1.5502, -0.1767],\n",
      "        [-1.8549,  0.4450,  1.2964],\n",
      "        [-1.5620,  1.9172, -0.3785],\n",
      "        [-1.6410,  0.2102,  1.1755],\n",
      "        [-1.5910,  0.2007,  1.2438],\n",
      "        [-1.6445,  1.8768, -0.3851],\n",
      "        [-0.6337,  0.7073, -0.5349],\n",
      "        [-2.0221,  1.0691,  0.9594],\n",
      "        [-1.7770,  1.9053, -0.2010],\n",
      "        [-1.8042,  1.7516, -0.2204],\n",
      "        [-1.7916,  1.7003, -0.1132],\n",
      "        [-1.7869,  1.9354, -0.1854]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5765,  1.8257, -0.2812],\n",
      "        [-1.7000,  0.9791,  0.7323],\n",
      "        [ 0.3478, -0.0053, -0.8325],\n",
      "        [ 0.2581,  0.0240, -0.7967],\n",
      "        [-1.8627,  1.5502, -0.1767],\n",
      "        [-1.8549,  0.4450,  1.2964],\n",
      "        [-1.5620,  1.9172, -0.3785],\n",
      "        [-1.6410,  0.2102,  1.1755],\n",
      "        [-1.5910,  0.2007,  1.2438],\n",
      "        [-1.6445,  1.8768, -0.3851],\n",
      "        [-0.6337,  0.7073, -0.5349],\n",
      "        [-2.0221,  1.0691,  0.9594],\n",
      "        [-1.7770,  1.9053, -0.2010],\n",
      "        [-1.8042,  1.7516, -0.2204],\n",
      "        [-1.7916,  1.7003, -0.1132],\n",
      "        [-1.7869,  1.9354, -0.1854]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9113,  0.8653,  0.8500],\n",
      "        [-1.6522,  1.9270, -0.2064],\n",
      "        [ 0.2280, -0.1352, -0.7509],\n",
      "        [-1.8885,  0.1862,  1.6399],\n",
      "        [-1.8280,  1.7995, -0.2533],\n",
      "        [-1.6264,  1.7702, -0.1850],\n",
      "        [-1.6838,  1.8982, -0.3620],\n",
      "        [ 0.5057, -0.0807, -0.9469],\n",
      "        [-1.6749,  0.2578,  1.3248],\n",
      "        [-1.6872,  2.0467, -0.4152],\n",
      "        [ 0.1351,  0.1251, -0.7983],\n",
      "        [-1.5435,  1.8246, -0.5342],\n",
      "        [-1.5603,  0.2137,  1.5283],\n",
      "        [-0.0807, -0.0175, -0.2453],\n",
      "        [-2.0480,  0.2550,  1.5550],\n",
      "        [-0.8634,  0.8532, -0.4634]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9113,  0.8653,  0.8500],\n",
      "        [-1.6522,  1.9270, -0.2064],\n",
      "        [ 0.2280, -0.1352, -0.7509],\n",
      "        [-1.8885,  0.1862,  1.6399],\n",
      "        [-1.8280,  1.7995, -0.2533],\n",
      "        [-1.6264,  1.7702, -0.1850],\n",
      "        [-1.6838,  1.8982, -0.3620],\n",
      "        [ 0.5057, -0.0807, -0.9469],\n",
      "        [-1.6749,  0.2578,  1.3248],\n",
      "        [-1.6872,  2.0467, -0.4152],\n",
      "        [ 0.1351,  0.1251, -0.7983],\n",
      "        [-1.5435,  1.8246, -0.5342],\n",
      "        [-1.5603,  0.2137,  1.5283],\n",
      "        [-0.0807, -0.0175, -0.2453],\n",
      "        [-2.0480,  0.2550,  1.5550],\n",
      "        [-0.8634,  0.8532, -0.4634]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9986,  1.8901, -0.2439],\n",
      "        [ 0.4474,  0.0083, -0.9990],\n",
      "        [-1.7054,  1.9615, -0.0752],\n",
      "        [-1.5785,  1.7429, -0.3943],\n",
      "        [-1.7895,  0.5200,  1.1424],\n",
      "        [-1.8384,  0.5740,  1.1498],\n",
      "        [-1.9059,  0.3417,  1.5416],\n",
      "        [ 0.3843, -0.1603, -0.8261],\n",
      "        [-1.4177,  1.6929, -0.4598],\n",
      "        [-1.7478,  0.1479,  1.5194],\n",
      "        [-1.9804,  1.7378,  0.0889],\n",
      "        [-1.8510,  0.2773,  1.4960],\n",
      "        [-1.8036,  1.7226, -0.3566],\n",
      "        [-1.8003,  1.8233, -0.4454],\n",
      "        [-1.3177,  1.2995, -0.3749],\n",
      "        [-0.6449,  0.3396,  0.0827]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9986,  1.8901, -0.2439],\n",
      "        [ 0.4474,  0.0083, -0.9990],\n",
      "        [-1.7054,  1.9615, -0.0752],\n",
      "        [-1.5785,  1.7429, -0.3943],\n",
      "        [-1.7895,  0.5200,  1.1424],\n",
      "        [-1.8384,  0.5740,  1.1498],\n",
      "        [-1.9059,  0.3417,  1.5416],\n",
      "        [ 0.3843, -0.1603, -0.8261],\n",
      "        [-1.4177,  1.6929, -0.4598],\n",
      "        [-1.7478,  0.1479,  1.5194],\n",
      "        [-1.9804,  1.7378,  0.0889],\n",
      "        [-1.8510,  0.2773,  1.4960],\n",
      "        [-1.8036,  1.7226, -0.3566],\n",
      "        [-1.8003,  1.8233, -0.4454],\n",
      "        [-1.3177,  1.2995, -0.3749],\n",
      "        [-0.6449,  0.3396,  0.0827]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6908,  0.2476,  1.4550],\n",
      "        [ 0.3098,  0.0437, -0.7120],\n",
      "        [-1.7697,  2.1408, -0.4486],\n",
      "        [-1.5123,  1.6572, -0.2119],\n",
      "        [-1.7888,  0.2376,  1.4349],\n",
      "        [ 0.6351, -0.1173, -0.8078],\n",
      "        [-1.9401,  1.9095, -0.2201],\n",
      "        [ 0.6017, -0.0946, -0.9212],\n",
      "        [-1.5365,  1.7988, -0.3663],\n",
      "        [-1.7551,  1.6908, -0.1747],\n",
      "        [ 0.2796, -0.1451, -0.6615],\n",
      "        [ 0.5248, -0.2091, -0.9052],\n",
      "        [-1.6538,  1.8013, -0.2508],\n",
      "        [-1.2451,  1.4365, -0.4796],\n",
      "        [-1.8377,  0.2458,  1.3187],\n",
      "        [ 0.0188,  0.5292, -0.9993]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6908,  0.2476,  1.4550],\n",
      "        [ 0.3098,  0.0437, -0.7120],\n",
      "        [-1.7697,  2.1408, -0.4486],\n",
      "        [-1.5123,  1.6572, -0.2119],\n",
      "        [-1.7888,  0.2376,  1.4349],\n",
      "        [ 0.6351, -0.1173, -0.8078],\n",
      "        [-1.9401,  1.9095, -0.2201],\n",
      "        [ 0.6017, -0.0946, -0.9212],\n",
      "        [-1.5365,  1.7988, -0.3663],\n",
      "        [-1.7551,  1.6908, -0.1747],\n",
      "        [ 0.2796, -0.1451, -0.6615],\n",
      "        [ 0.5248, -0.2091, -0.9052],\n",
      "        [-1.6538,  1.8013, -0.2508],\n",
      "        [-1.2451,  1.4365, -0.4796],\n",
      "        [-1.8377,  0.2458,  1.3187],\n",
      "        [ 0.0188,  0.5292, -0.9993]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.9176,  0.4157,  1.3244],\n",
      "        [-1.6961,  1.9250, -0.3460],\n",
      "        [-1.9261,  1.2330,  0.3473],\n",
      "        [ 0.6255, -0.0943, -0.8555],\n",
      "        [-1.8558,  0.1309,  1.3447],\n",
      "        [-1.7706,  0.2386,  1.4970],\n",
      "        [-1.9559,  0.4360,  1.4775],\n",
      "        [-1.6340,  0.2624,  1.1994],\n",
      "        [ 0.6791, -0.0944, -0.9856],\n",
      "        [-1.6055,  0.2586,  1.2666],\n",
      "        [-1.7663,  1.4022,  0.3640],\n",
      "        [-1.7906,  0.9032,  0.5223],\n",
      "        [-1.7950,  1.6553, -0.2443],\n",
      "        [-1.6749,  1.7167, -0.4042],\n",
      "        [-1.7289,  1.8866, -0.3532],\n",
      "        [-1.8979,  0.5415,  1.4347]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.9176,  0.4157,  1.3244],\n",
      "        [-1.6961,  1.9250, -0.3460],\n",
      "        [-1.9261,  1.2330,  0.3473],\n",
      "        [ 0.6255, -0.0943, -0.8555],\n",
      "        [-1.8558,  0.1309,  1.3447],\n",
      "        [-1.7706,  0.2386,  1.4970],\n",
      "        [-1.9559,  0.4360,  1.4775],\n",
      "        [-1.6340,  0.2624,  1.1994],\n",
      "        [ 0.6791, -0.0944, -0.9856],\n",
      "        [-1.6055,  0.2586,  1.2666],\n",
      "        [-1.7663,  1.4022,  0.3640],\n",
      "        [-1.7906,  0.9032,  0.5223],\n",
      "        [-1.7950,  1.6553, -0.2443],\n",
      "        [-1.6749,  1.7167, -0.4042],\n",
      "        [-1.7289,  1.8866, -0.3532],\n",
      "        [-1.8979,  0.5415,  1.4347]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-9.0192e-02, -1.8864e-01,  3.9097e-02],\n",
      "        [-1.8467e+00,  1.9717e+00, -3.6350e-01],\n",
      "        [ 4.9121e-01, -1.3774e-03, -8.9525e-01],\n",
      "        [-1.8257e+00,  3.7567e-01,  1.3213e+00],\n",
      "        [-2.0085e+00,  2.3903e-01,  1.5630e+00],\n",
      "        [ 4.5604e-01, -1.2460e-01, -9.1459e-01],\n",
      "        [-1.8392e+00,  1.0454e-01,  1.2805e+00],\n",
      "        [-1.8275e+00,  3.6443e-01,  1.5158e+00],\n",
      "        [-1.5396e+00,  1.6662e+00, -3.1371e-01],\n",
      "        [-1.6718e+00,  1.9670e+00, -2.2817e-01],\n",
      "        [-1.5411e+00,  1.6409e+00, -3.6564e-01],\n",
      "        [-2.0775e+00,  1.1086e+00,  7.6816e-01],\n",
      "        [-1.8350e+00,  3.6225e-01,  1.3617e+00],\n",
      "        [-1.7721e+00,  7.2044e-01,  1.2944e+00],\n",
      "        [-1.6895e+00,  1.8508e+00, -4.4230e-01],\n",
      "        [-1.6656e+00,  1.8983e+00, -5.1346e-01]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-9.0192e-02, -1.8864e-01,  3.9097e-02],\n",
      "        [-1.8467e+00,  1.9717e+00, -3.6350e-01],\n",
      "        [ 4.9121e-01, -1.3774e-03, -8.9525e-01],\n",
      "        [-1.8257e+00,  3.7567e-01,  1.3213e+00],\n",
      "        [-2.0085e+00,  2.3903e-01,  1.5630e+00],\n",
      "        [ 4.5604e-01, -1.2460e-01, -9.1459e-01],\n",
      "        [-1.8392e+00,  1.0454e-01,  1.2805e+00],\n",
      "        [-1.8275e+00,  3.6443e-01,  1.5158e+00],\n",
      "        [-1.5396e+00,  1.6662e+00, -3.1371e-01],\n",
      "        [-1.6718e+00,  1.9670e+00, -2.2817e-01],\n",
      "        [-1.5411e+00,  1.6409e+00, -3.6564e-01],\n",
      "        [-2.0775e+00,  1.1086e+00,  7.6816e-01],\n",
      "        [-1.8350e+00,  3.6225e-01,  1.3617e+00],\n",
      "        [-1.7721e+00,  7.2044e-01,  1.2944e+00],\n",
      "        [-1.6895e+00,  1.8508e+00, -4.4230e-01],\n",
      "        [-1.6656e+00,  1.8983e+00, -5.1346e-01]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6553,  1.8761, -0.4093],\n",
      "        [-1.5961,  1.9471, -0.4401],\n",
      "        [-1.9486,  0.4220,  1.3454],\n",
      "        [-1.7603,  1.9892, -0.5095],\n",
      "        [-1.5238,  1.8894, -0.4471],\n",
      "        [-1.8555,  0.9604,  0.4033],\n",
      "        [-1.5553,  1.7212, -0.4351],\n",
      "        [-1.6172,  1.8027, -0.5336],\n",
      "        [-1.6166,  0.3960,  1.4168],\n",
      "        [-1.5616,  1.8339, -0.4058],\n",
      "        [ 0.3414, -0.0161, -1.0107],\n",
      "        [-1.6652,  1.8368, -0.6011],\n",
      "        [-1.5833,  1.7595, -0.3358],\n",
      "        [-1.4749,  1.6805, -0.2851],\n",
      "        [-1.9707,  1.6377, -0.1873],\n",
      "        [-1.5992,  1.8843, -0.3625]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6553,  1.8761, -0.4093],\n",
      "        [-1.5961,  1.9471, -0.4401],\n",
      "        [-1.9486,  0.4220,  1.3454],\n",
      "        [-1.7603,  1.9892, -0.5095],\n",
      "        [-1.5238,  1.8894, -0.4471],\n",
      "        [-1.8555,  0.9604,  0.4033],\n",
      "        [-1.5553,  1.7212, -0.4351],\n",
      "        [-1.6172,  1.8027, -0.5336],\n",
      "        [-1.6166,  0.3960,  1.4168],\n",
      "        [-1.5616,  1.8339, -0.4058],\n",
      "        [ 0.3414, -0.0161, -1.0107],\n",
      "        [-1.6652,  1.8368, -0.6011],\n",
      "        [-1.5833,  1.7595, -0.3358],\n",
      "        [-1.4749,  1.6805, -0.2851],\n",
      "        [-1.9707,  1.6377, -0.1873],\n",
      "        [-1.5992,  1.8843, -0.3625]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7829,  0.3453,  1.3632],\n",
      "        [-1.6124,  1.7628, -0.3869],\n",
      "        [-1.7431,  1.9179, -0.3997],\n",
      "        [-1.3706,  2.0909, -0.4809],\n",
      "        [-1.7700,  0.6874,  1.2249],\n",
      "        [-1.5808,  2.0584, -0.7261],\n",
      "        [-1.5576,  2.0662, -0.4316],\n",
      "        [-1.9599,  0.5795,  1.2953],\n",
      "        [ 0.5884, -0.1724, -0.9025],\n",
      "        [-1.9261,  0.3291,  1.4519],\n",
      "        [ 0.6929, -0.1672, -0.9888],\n",
      "        [ 0.4310, -0.0362, -1.0855],\n",
      "        [-1.5043,  1.8061, -0.5258],\n",
      "        [-2.0878,  0.4580,  1.3084],\n",
      "        [ 0.6782, -0.0523, -1.1670],\n",
      "        [-1.9611,  0.8349,  1.0047]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7829,  0.3453,  1.3632],\n",
      "        [-1.6124,  1.7628, -0.3869],\n",
      "        [-1.7431,  1.9179, -0.3997],\n",
      "        [-1.3706,  2.0909, -0.4809],\n",
      "        [-1.7700,  0.6874,  1.2249],\n",
      "        [-1.5808,  2.0584, -0.7261],\n",
      "        [-1.5576,  2.0662, -0.4316],\n",
      "        [-1.9599,  0.5795,  1.2953],\n",
      "        [ 0.5884, -0.1724, -0.9025],\n",
      "        [-1.9261,  0.3291,  1.4519],\n",
      "        [ 0.6929, -0.1672, -0.9888],\n",
      "        [ 0.4310, -0.0362, -1.0855],\n",
      "        [-1.5043,  1.8061, -0.5258],\n",
      "        [-2.0878,  0.4580,  1.3084],\n",
      "        [ 0.6782, -0.0523, -1.1670],\n",
      "        [-1.9611,  0.8349,  1.0047]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4828,  1.7958, -0.4858],\n",
      "        [-1.9804,  0.7324,  1.1154],\n",
      "        [-0.1015,  0.4377, -1.0351],\n",
      "        [-1.9543,  0.2148,  1.3795],\n",
      "        [ 0.1906,  0.1145, -0.7890],\n",
      "        [-1.7350,  0.2511,  1.2975],\n",
      "        [-1.6873,  0.2630,  1.2614],\n",
      "        [-1.6125,  0.5315,  1.3713],\n",
      "        [-1.6962,  0.1307,  1.4448],\n",
      "        [-1.8933,  0.6149,  1.0297],\n",
      "        [-1.8371,  1.8588, -0.4204],\n",
      "        [-1.9266,  0.6818,  1.1070],\n",
      "        [-1.6976,  1.8800, -0.5658],\n",
      "        [-1.5370,  1.6804, -0.3072],\n",
      "        [-1.7356,  1.7382, -0.4146],\n",
      "        [-1.4735,  2.1960, -0.4363]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4828,  1.7958, -0.4858],\n",
      "        [-1.9804,  0.7324,  1.1154],\n",
      "        [-0.1015,  0.4377, -1.0351],\n",
      "        [-1.9543,  0.2148,  1.3795],\n",
      "        [ 0.1906,  0.1145, -0.7890],\n",
      "        [-1.7350,  0.2511,  1.2975],\n",
      "        [-1.6873,  0.2630,  1.2614],\n",
      "        [-1.6125,  0.5315,  1.3713],\n",
      "        [-1.6962,  0.1307,  1.4448],\n",
      "        [-1.8933,  0.6149,  1.0297],\n",
      "        [-1.8371,  1.8588, -0.4204],\n",
      "        [-1.9266,  0.6818,  1.1070],\n",
      "        [-1.6976,  1.8800, -0.5658],\n",
      "        [-1.5370,  1.6804, -0.3072],\n",
      "        [-1.7356,  1.7382, -0.4146],\n",
      "        [-1.4735,  2.1960, -0.4363]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4781,  1.5416, -0.5765],\n",
      "        [-2.0512,  0.3748,  1.3397],\n",
      "        [-1.5235,  1.7714, -0.7433],\n",
      "        [-1.3267,  1.6331, -0.5894],\n",
      "        [-1.5142,  1.8837, -0.6773],\n",
      "        [-1.7607,  0.4831,  1.4365],\n",
      "        [-1.6342,  1.9061, -0.4290],\n",
      "        [-1.6445,  1.8376, -0.5774],\n",
      "        [-2.0364,  1.0147,  0.8008],\n",
      "        [-1.1159,  1.5718, -0.6881],\n",
      "        [-1.6908,  1.9197, -0.4856],\n",
      "        [ 0.5012,  0.1002, -1.1451],\n",
      "        [-1.1392,  1.7726, -0.7823],\n",
      "        [-1.5046,  1.8416, -0.5531],\n",
      "        [ 0.6975, -0.0660, -1.0283],\n",
      "        [ 0.5413, -0.0532, -1.0712]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4781,  1.5416, -0.5765],\n",
      "        [-2.0512,  0.3748,  1.3397],\n",
      "        [-1.5235,  1.7714, -0.7433],\n",
      "        [-1.3267,  1.6331, -0.5894],\n",
      "        [-1.5142,  1.8837, -0.6773],\n",
      "        [-1.7607,  0.4831,  1.4365],\n",
      "        [-1.6342,  1.9061, -0.4290],\n",
      "        [-1.6445,  1.8376, -0.5774],\n",
      "        [-2.0364,  1.0147,  0.8008],\n",
      "        [-1.1159,  1.5718, -0.6881],\n",
      "        [-1.6908,  1.9197, -0.4856],\n",
      "        [ 0.5012,  0.1002, -1.1451],\n",
      "        [-1.1392,  1.7726, -0.7823],\n",
      "        [-1.5046,  1.8416, -0.5531],\n",
      "        [ 0.6975, -0.0660, -1.0283],\n",
      "        [ 0.5413, -0.0532, -1.0712]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6964,  2.1559, -0.5362],\n",
      "        [-2.0269,  0.2502,  1.4536],\n",
      "        [-1.7119,  0.2654,  1.3533],\n",
      "        [-1.8283,  1.9092, -0.3885],\n",
      "        [-1.7925,  1.7350, -0.1231],\n",
      "        [-1.6540,  0.5832,  1.2898],\n",
      "        [-1.9305,  0.4167,  1.2988],\n",
      "        [-1.8283,  1.2928,  0.1757],\n",
      "        [-1.5962,  1.7162, -0.4312],\n",
      "        [ 0.1404,  0.2479, -0.9114],\n",
      "        [-1.5803,  1.7965, -0.5828],\n",
      "        [-1.1443,  0.0174,  1.0156],\n",
      "        [-2.0185,  0.4732,  1.4286],\n",
      "        [-1.0335, -0.0742,  0.9296],\n",
      "        [-1.7262,  1.9899, -0.6430],\n",
      "        [-1.6649,  1.9758, -0.3696]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6964,  2.1559, -0.5362],\n",
      "        [-2.0269,  0.2502,  1.4536],\n",
      "        [-1.7119,  0.2654,  1.3533],\n",
      "        [-1.8283,  1.9092, -0.3885],\n",
      "        [-1.7925,  1.7350, -0.1231],\n",
      "        [-1.6540,  0.5832,  1.2898],\n",
      "        [-1.9305,  0.4167,  1.2988],\n",
      "        [-1.8283,  1.2928,  0.1757],\n",
      "        [-1.5962,  1.7162, -0.4312],\n",
      "        [ 0.1404,  0.2479, -0.9114],\n",
      "        [-1.5803,  1.7965, -0.5828],\n",
      "        [-1.1443,  0.0174,  1.0156],\n",
      "        [-2.0185,  0.4732,  1.4286],\n",
      "        [-1.0335, -0.0742,  0.9296],\n",
      "        [-1.7262,  1.9899, -0.6430],\n",
      "        [-1.6649,  1.9758, -0.3696]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.1243,  0.2845, -0.9506],\n",
      "        [ 0.1603,  0.3390, -0.9878],\n",
      "        [-1.4425,  1.9317, -0.7428],\n",
      "        [ 0.6675, -0.1631, -1.0427],\n",
      "        [-1.5933,  1.8357, -0.3120],\n",
      "        [-1.9145,  0.2218,  1.6238],\n",
      "        [-2.0420,  0.1885,  1.3824],\n",
      "        [ 0.7380, -0.0959, -1.0379],\n",
      "        [-1.5096,  1.9890, -0.4044],\n",
      "        [-2.0117,  1.3146,  0.3765],\n",
      "        [-1.5487,  2.1263, -0.4547],\n",
      "        [-1.5890,  1.7981, -0.6710],\n",
      "        [-1.6280,  1.8128, -0.4526],\n",
      "        [-1.3729,  1.6309, -0.5848],\n",
      "        [-1.4001,  1.9410, -0.6137],\n",
      "        [-1.6151,  1.9406, -0.5164]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.1243,  0.2845, -0.9506],\n",
      "        [ 0.1603,  0.3390, -0.9878],\n",
      "        [-1.4425,  1.9317, -0.7428],\n",
      "        [ 0.6675, -0.1631, -1.0427],\n",
      "        [-1.5933,  1.8357, -0.3120],\n",
      "        [-1.9145,  0.2218,  1.6238],\n",
      "        [-2.0420,  0.1885,  1.3824],\n",
      "        [ 0.7380, -0.0959, -1.0379],\n",
      "        [-1.5096,  1.9890, -0.4044],\n",
      "        [-2.0117,  1.3146,  0.3765],\n",
      "        [-1.5487,  2.1263, -0.4547],\n",
      "        [-1.5890,  1.7981, -0.6710],\n",
      "        [-1.6280,  1.8128, -0.4526],\n",
      "        [-1.3729,  1.6309, -0.5848],\n",
      "        [-1.4001,  1.9410, -0.6137],\n",
      "        [-1.6151,  1.9406, -0.5164]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4871,  1.8067, -0.4771],\n",
      "        [ 0.6400, -0.0952, -0.9927],\n",
      "        [-1.1784,  1.6652, -0.5936],\n",
      "        [-1.7198,  1.8186, -0.5578],\n",
      "        [-1.9666,  0.9179,  0.5163],\n",
      "        [-1.6522,  2.2597, -0.4910],\n",
      "        [-1.5979,  2.0284, -0.6220],\n",
      "        [-1.7944,  0.2423,  1.2788],\n",
      "        [-1.5534,  1.9507, -0.5762],\n",
      "        [-1.5656,  1.7974, -0.5083],\n",
      "        [-1.5436,  1.9331, -0.5331],\n",
      "        [-1.4636,  1.5160, -0.3918],\n",
      "        [-1.7627,  0.4554,  1.0055],\n",
      "        [ 0.2888,  0.2379, -1.2570],\n",
      "        [-1.5113,  1.9860, -0.7450],\n",
      "        [ 0.0042,  0.4544, -0.8858]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4871,  1.8067, -0.4771],\n",
      "        [ 0.6400, -0.0952, -0.9927],\n",
      "        [-1.1784,  1.6652, -0.5936],\n",
      "        [-1.7198,  1.8186, -0.5578],\n",
      "        [-1.9666,  0.9179,  0.5163],\n",
      "        [-1.6522,  2.2597, -0.4910],\n",
      "        [-1.5979,  2.0284, -0.6220],\n",
      "        [-1.7944,  0.2423,  1.2788],\n",
      "        [-1.5534,  1.9507, -0.5762],\n",
      "        [-1.5656,  1.7974, -0.5083],\n",
      "        [-1.5436,  1.9331, -0.5331],\n",
      "        [-1.4636,  1.5160, -0.3918],\n",
      "        [-1.7627,  0.4554,  1.0055],\n",
      "        [ 0.2888,  0.2379, -1.2570],\n",
      "        [-1.5113,  1.9860, -0.7450],\n",
      "        [ 0.0042,  0.4544, -0.8858]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4602,  2.0343, -0.5661],\n",
      "        [-1.5394,  1.9852, -0.4787],\n",
      "        [-1.7189,  1.8133, -0.6063],\n",
      "        [-1.6122,  1.9488, -0.5634],\n",
      "        [-1.8595,  0.4398,  1.1182],\n",
      "        [-1.6601,  1.9522, -0.4564],\n",
      "        [ 0.7043, -0.1336, -1.0651],\n",
      "        [-1.4555,  1.7703, -0.9262],\n",
      "        [-1.5211,  2.0829, -0.4495],\n",
      "        [-1.4670,  1.7205, -0.6459],\n",
      "        [-1.9944,  0.1889,  1.5283],\n",
      "        [-1.6616,  1.9839, -0.3790],\n",
      "        [-1.0410,  1.3509, -0.8393],\n",
      "        [-1.3425,  1.8525, -0.6707],\n",
      "        [-1.9598,  0.3372,  1.4370],\n",
      "        [-1.5520,  1.9015, -0.6225]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4602,  2.0343, -0.5661],\n",
      "        [-1.5394,  1.9852, -0.4787],\n",
      "        [-1.7189,  1.8133, -0.6063],\n",
      "        [-1.6122,  1.9488, -0.5634],\n",
      "        [-1.8595,  0.4398,  1.1182],\n",
      "        [-1.6601,  1.9522, -0.4564],\n",
      "        [ 0.7043, -0.1336, -1.0651],\n",
      "        [-1.4555,  1.7703, -0.9262],\n",
      "        [-1.5211,  2.0829, -0.4495],\n",
      "        [-1.4670,  1.7205, -0.6459],\n",
      "        [-1.9944,  0.1889,  1.5283],\n",
      "        [-1.6616,  1.9839, -0.3790],\n",
      "        [-1.0410,  1.3509, -0.8393],\n",
      "        [-1.3425,  1.8525, -0.6707],\n",
      "        [-1.9598,  0.3372,  1.4370],\n",
      "        [-1.5520,  1.9015, -0.6225]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5316,  1.9995, -0.5348],\n",
      "        [-1.8606,  0.4009,  1.2354],\n",
      "        [-1.3704,  1.9425, -0.4774],\n",
      "        [-1.7963,  0.1884,  1.4166],\n",
      "        [-1.4975,  1.9718, -0.5033],\n",
      "        [-1.3554,  1.8975, -0.6647],\n",
      "        [-0.5774,  0.0285,  0.2801],\n",
      "        [-1.5251,  2.0347, -0.5148],\n",
      "        [-1.8619,  0.7364,  1.2584],\n",
      "        [-1.3689,  1.7333, -0.8782],\n",
      "        [-1.6154,  1.7507, -0.5872],\n",
      "        [-1.4411,  1.9082, -0.5157],\n",
      "        [-1.6538,  1.9698, -0.3498],\n",
      "        [-1.6071,  1.7585, -0.3484],\n",
      "        [-1.3669,  1.8464, -0.5818],\n",
      "        [-1.6725,  1.7900, -0.6453]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5316,  1.9995, -0.5348],\n",
      "        [-1.8606,  0.4009,  1.2354],\n",
      "        [-1.3704,  1.9425, -0.4774],\n",
      "        [-1.7963,  0.1884,  1.4166],\n",
      "        [-1.4975,  1.9718, -0.5033],\n",
      "        [-1.3554,  1.8975, -0.6647],\n",
      "        [-0.5774,  0.0285,  0.2801],\n",
      "        [-1.5251,  2.0347, -0.5148],\n",
      "        [-1.8619,  0.7364,  1.2584],\n",
      "        [-1.3689,  1.7333, -0.8782],\n",
      "        [-1.6154,  1.7507, -0.5872],\n",
      "        [-1.4411,  1.9082, -0.5157],\n",
      "        [-1.6538,  1.9698, -0.3498],\n",
      "        [-1.6071,  1.7585, -0.3484],\n",
      "        [-1.3669,  1.8464, -0.5818],\n",
      "        [-1.6725,  1.7900, -0.6453]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5504,  1.9559, -0.6604],\n",
      "        [-1.2806,  1.8095, -0.7027],\n",
      "        [-1.7515,  0.2140,  1.5019],\n",
      "        [-1.8201,  0.1742,  1.2969],\n",
      "        [-2.2380,  0.3346,  1.6523],\n",
      "        [-1.3969,  1.6827, -0.5620],\n",
      "        [-2.0351,  0.6621,  1.2414],\n",
      "        [-1.4968,  1.7139, -0.6330],\n",
      "        [-1.2904,  1.7889, -0.7413],\n",
      "        [-1.6709,  0.3247,  1.1757],\n",
      "        [-1.2996,  1.7338, -0.6664],\n",
      "        [-1.5700,  1.8662, -0.5001],\n",
      "        [-1.2744,  1.6015, -0.5503],\n",
      "        [-1.5073,  1.9557, -0.5257],\n",
      "        [-1.4321,  1.8895, -0.5517],\n",
      "        [-1.5701,  1.9670, -0.4707]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5504,  1.9559, -0.6604],\n",
      "        [-1.2806,  1.8095, -0.7027],\n",
      "        [-1.7515,  0.2140,  1.5019],\n",
      "        [-1.8201,  0.1742,  1.2969],\n",
      "        [-2.2380,  0.3346,  1.6523],\n",
      "        [-1.3969,  1.6827, -0.5620],\n",
      "        [-2.0351,  0.6621,  1.2414],\n",
      "        [-1.4968,  1.7139, -0.6330],\n",
      "        [-1.2904,  1.7889, -0.7413],\n",
      "        [-1.6709,  0.3247,  1.1757],\n",
      "        [-1.2996,  1.7338, -0.6664],\n",
      "        [-1.5700,  1.8662, -0.5001],\n",
      "        [-1.2744,  1.6015, -0.5503],\n",
      "        [-1.5073,  1.9557, -0.5257],\n",
      "        [-1.4321,  1.8895, -0.5517],\n",
      "        [-1.5701,  1.9670, -0.4707]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-2.1107,  0.7541,  0.9032],\n",
      "        [-1.5725,  1.7693, -0.3009],\n",
      "        [-1.2456,  1.7466, -0.2587],\n",
      "        [-1.3986,  1.8542, -0.6781],\n",
      "        [ 0.5896, -0.2421, -1.0433],\n",
      "        [-1.9607,  0.6040,  1.1283],\n",
      "        [-1.3977,  1.8123, -0.3277],\n",
      "        [-1.4611,  1.9896, -0.4640],\n",
      "        [-1.5515,  1.8097, -0.5666],\n",
      "        [-0.9426,  1.2910, -0.7472],\n",
      "        [-1.5396,  2.2202, -0.6763],\n",
      "        [-1.6943,  0.2186,  1.3435],\n",
      "        [-1.6034,  1.8496, -0.5071],\n",
      "        [-1.4922,  1.7107, -0.4702],\n",
      "        [-0.9955,  1.3244, -0.6015],\n",
      "        [ 0.5762, -0.0064, -0.9862]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-2.1107,  0.7541,  0.9032],\n",
      "        [-1.5725,  1.7693, -0.3009],\n",
      "        [-1.2456,  1.7466, -0.2587],\n",
      "        [-1.3986,  1.8542, -0.6781],\n",
      "        [ 0.5896, -0.2421, -1.0433],\n",
      "        [-1.9607,  0.6040,  1.1283],\n",
      "        [-1.3977,  1.8123, -0.3277],\n",
      "        [-1.4611,  1.9896, -0.4640],\n",
      "        [-1.5515,  1.8097, -0.5666],\n",
      "        [-0.9426,  1.2910, -0.7472],\n",
      "        [-1.5396,  2.2202, -0.6763],\n",
      "        [-1.6943,  0.2186,  1.3435],\n",
      "        [-1.6034,  1.8496, -0.5071],\n",
      "        [-1.4922,  1.7107, -0.4702],\n",
      "        [-0.9955,  1.3244, -0.6015],\n",
      "        [ 0.5762, -0.0064, -0.9862]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4277,  1.6955, -0.5228],\n",
      "        [-1.5331,  1.8843, -0.3861],\n",
      "        [-1.9618,  0.5620,  1.2497],\n",
      "        [ 0.7276, -0.2360, -0.9927],\n",
      "        [-1.4198,  1.5218, -0.7435],\n",
      "        [-1.8211,  0.6153,  1.1392],\n",
      "        [-1.5430,  1.5612, -0.5177],\n",
      "        [-1.6793,  0.3901,  1.3988],\n",
      "        [ 0.5870, -0.2320, -1.1228],\n",
      "        [-1.2182,  1.5348, -0.3866],\n",
      "        [ 0.7051, -0.1133, -0.7675],\n",
      "        [-1.2342,  1.4084, -0.5264],\n",
      "        [-1.5681,  1.9724, -0.3387],\n",
      "        [-1.9018,  1.1384,  0.6627],\n",
      "        [-1.5666,  1.5453, -0.2164],\n",
      "        [-1.1865,  1.6887, -0.7650]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4277,  1.6955, -0.5228],\n",
      "        [-1.5331,  1.8843, -0.3861],\n",
      "        [-1.9618,  0.5620,  1.2497],\n",
      "        [ 0.7276, -0.2360, -0.9927],\n",
      "        [-1.4198,  1.5218, -0.7435],\n",
      "        [-1.8211,  0.6153,  1.1392],\n",
      "        [-1.5430,  1.5612, -0.5177],\n",
      "        [-1.6793,  0.3901,  1.3988],\n",
      "        [ 0.5870, -0.2320, -1.1228],\n",
      "        [-1.2182,  1.5348, -0.3866],\n",
      "        [ 0.7051, -0.1133, -0.7675],\n",
      "        [-1.2342,  1.4084, -0.5264],\n",
      "        [-1.5681,  1.9724, -0.3387],\n",
      "        [-1.9018,  1.1384,  0.6627],\n",
      "        [-1.5666,  1.5453, -0.2164],\n",
      "        [-1.1865,  1.6887, -0.7650]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.6836, -0.0335, -0.9997],\n",
      "        [-0.5459,  0.0864,  0.5291],\n",
      "        [-2.0522,  0.1867,  1.4373],\n",
      "        [-1.7678,  1.5657, -0.2154],\n",
      "        [-1.6855,  1.7425, -0.1267],\n",
      "        [-1.5123,  0.5061,  0.9716],\n",
      "        [-1.5642,  0.8790,  0.7507],\n",
      "        [-1.6581,  1.6855, -0.3167],\n",
      "        [-1.2908,  1.5837, -0.4276],\n",
      "        [-1.5972,  1.7026, -0.3393],\n",
      "        [ 0.6264, -0.0840, -0.8906],\n",
      "        [-2.0370,  0.2391,  1.6274],\n",
      "        [-1.1253,  1.6467, -0.6276],\n",
      "        [-1.5205,  1.9339, -0.7797],\n",
      "        [-1.6727,  1.7969, -0.4651],\n",
      "        [-1.3978,  1.5596, -0.3458]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.6836, -0.0335, -0.9997],\n",
      "        [-0.5459,  0.0864,  0.5291],\n",
      "        [-2.0522,  0.1867,  1.4373],\n",
      "        [-1.7678,  1.5657, -0.2154],\n",
      "        [-1.6855,  1.7425, -0.1267],\n",
      "        [-1.5123,  0.5061,  0.9716],\n",
      "        [-1.5642,  0.8790,  0.7507],\n",
      "        [-1.6581,  1.6855, -0.3167],\n",
      "        [-1.2908,  1.5837, -0.4276],\n",
      "        [-1.5972,  1.7026, -0.3393],\n",
      "        [ 0.6264, -0.0840, -0.8906],\n",
      "        [-2.0370,  0.2391,  1.6274],\n",
      "        [-1.1253,  1.6467, -0.6276],\n",
      "        [-1.5205,  1.9339, -0.7797],\n",
      "        [-1.6727,  1.7969, -0.4651],\n",
      "        [-1.3978,  1.5596, -0.3458]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.8460,  0.2698,  1.4141],\n",
      "        [-1.3409,  1.6266, -0.6336],\n",
      "        [-1.7197,  1.2110,  0.3036],\n",
      "        [ 0.5367, -0.1700, -0.6313],\n",
      "        [-1.9630,  0.2902,  1.5499],\n",
      "        [-1.4621,  1.5395, -0.5295],\n",
      "        [-1.5067,  1.7500, -0.3390],\n",
      "        [-1.5406,  1.5841, -0.2806],\n",
      "        [-1.2605,  1.6773, -0.5092],\n",
      "        [-1.3035,  1.6245, -0.5641],\n",
      "        [-1.5280,  1.6336, -0.4062],\n",
      "        [-1.5767,  1.5025, -0.3611],\n",
      "        [-2.0935,  0.5304,  1.0619],\n",
      "        [-1.2439,  1.6771, -0.6385],\n",
      "        [-1.4383,  1.7111, -0.4163],\n",
      "        [-1.5622,  0.9784,  0.4099]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.8460,  0.2698,  1.4141],\n",
      "        [-1.3409,  1.6266, -0.6336],\n",
      "        [-1.7197,  1.2110,  0.3036],\n",
      "        [ 0.5367, -0.1700, -0.6313],\n",
      "        [-1.9630,  0.2902,  1.5499],\n",
      "        [-1.4621,  1.5395, -0.5295],\n",
      "        [-1.5067,  1.7500, -0.3390],\n",
      "        [-1.5406,  1.5841, -0.2806],\n",
      "        [-1.2605,  1.6773, -0.5092],\n",
      "        [-1.3035,  1.6245, -0.5641],\n",
      "        [-1.5280,  1.6336, -0.4062],\n",
      "        [-1.5767,  1.5025, -0.3611],\n",
      "        [-2.0935,  0.5304,  1.0619],\n",
      "        [-1.2439,  1.6771, -0.6385],\n",
      "        [-1.4383,  1.7111, -0.4163],\n",
      "        [-1.5622,  0.9784,  0.4099]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7938,  0.5203,  1.0582],\n",
      "        [-1.4707,  1.5231, -0.3321],\n",
      "        [-1.3508,  1.7176, -0.4472],\n",
      "        [ 0.6184, -0.1347, -0.9303],\n",
      "        [-1.5010,  1.4899, -0.3346],\n",
      "        [-1.7599, -0.0168,  1.5377],\n",
      "        [-1.9505,  0.0324,  1.5617],\n",
      "        [-1.3421,  1.5764, -0.4654],\n",
      "        [-1.5057,  1.6440, -0.6031],\n",
      "        [-1.5520,  1.6862, -0.3517],\n",
      "        [-1.4091,  1.7201, -0.3736],\n",
      "        [-1.8819,  0.1395,  1.5575],\n",
      "        [-1.8992,  0.8251,  0.6545],\n",
      "        [-0.8972,  1.2695, -0.4538],\n",
      "        [-1.2789,  1.3435, -0.3662],\n",
      "        [-1.5769,  1.6996, -0.3163]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7938,  0.5203,  1.0582],\n",
      "        [-1.4707,  1.5231, -0.3321],\n",
      "        [-1.3508,  1.7176, -0.4472],\n",
      "        [ 0.6184, -0.1347, -0.9303],\n",
      "        [-1.5010,  1.4899, -0.3346],\n",
      "        [-1.7599, -0.0168,  1.5377],\n",
      "        [-1.9505,  0.0324,  1.5617],\n",
      "        [-1.3421,  1.5764, -0.4654],\n",
      "        [-1.5057,  1.6440, -0.6031],\n",
      "        [-1.5520,  1.6862, -0.3517],\n",
      "        [-1.4091,  1.7201, -0.3736],\n",
      "        [-1.8819,  0.1395,  1.5575],\n",
      "        [-1.8992,  0.8251,  0.6545],\n",
      "        [-0.8972,  1.2695, -0.4538],\n",
      "        [-1.2789,  1.3435, -0.3662],\n",
      "        [-1.5769,  1.6996, -0.3163]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4631,  0.3698,  0.7497],\n",
      "        [-1.2596,  0.8889, -0.2507],\n",
      "        [-1.6230,  1.7153, -0.4997],\n",
      "        [-1.2876,  1.6176, -0.3535],\n",
      "        [-1.7417,  0.3541,  1.1434],\n",
      "        [-1.5828,  1.7548, -0.4249],\n",
      "        [-1.3276,  1.3376, -0.6841],\n",
      "        [-1.4152,  1.4735, -0.3687],\n",
      "        [-1.7391,  0.0995,  1.5912],\n",
      "        [ 0.3726, -0.0978, -0.7852],\n",
      "        [-1.6536,  0.0602,  1.5493],\n",
      "        [-1.9765,  0.0790,  1.5668],\n",
      "        [-1.6214,  1.6637, -0.2430],\n",
      "        [-1.5382,  1.2180, -0.2516],\n",
      "        [-1.4350,  1.0619,  0.0723],\n",
      "        [-1.5040,  1.6532, -0.4395]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4631,  0.3698,  0.7497],\n",
      "        [-1.2596,  0.8889, -0.2507],\n",
      "        [-1.6230,  1.7153, -0.4997],\n",
      "        [-1.2876,  1.6176, -0.3535],\n",
      "        [-1.7417,  0.3541,  1.1434],\n",
      "        [-1.5828,  1.7548, -0.4249],\n",
      "        [-1.3276,  1.3376, -0.6841],\n",
      "        [-1.4152,  1.4735, -0.3687],\n",
      "        [-1.7391,  0.0995,  1.5912],\n",
      "        [ 0.3726, -0.0978, -0.7852],\n",
      "        [-1.6536,  0.0602,  1.5493],\n",
      "        [-1.9765,  0.0790,  1.5668],\n",
      "        [-1.6214,  1.6637, -0.2430],\n",
      "        [-1.5382,  1.2180, -0.2516],\n",
      "        [-1.4350,  1.0619,  0.0723],\n",
      "        [-1.5040,  1.6532, -0.4395]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.2027,  0.0922, -1.0046],\n",
      "        [-1.3861,  1.7909, -0.4858],\n",
      "        [-1.3352,  1.7089, -0.2611],\n",
      "        [-1.4123,  1.5336, -0.4730],\n",
      "        [-1.0647,  1.4455, -0.5111],\n",
      "        [-1.3803,  1.6191, -0.1057],\n",
      "        [-1.7958,  0.4110,  1.2085],\n",
      "        [-1.7018,  1.7287, -0.3204],\n",
      "        [-1.3208,  1.3386, -0.6313],\n",
      "        [-1.8668,  1.0357,  0.6939],\n",
      "        [-1.5077,  1.5127, -0.5303],\n",
      "        [-1.4895,  1.9115, -0.3114],\n",
      "        [-1.3675,  1.7271, -0.4222],\n",
      "        [-1.4343,  1.5498, -0.4200],\n",
      "        [-1.4427,  1.6278, -0.3950],\n",
      "        [-1.5802,  1.4427, -0.3539]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.2027,  0.0922, -1.0046],\n",
      "        [-1.3861,  1.7909, -0.4858],\n",
      "        [-1.3352,  1.7089, -0.2611],\n",
      "        [-1.4123,  1.5336, -0.4730],\n",
      "        [-1.0647,  1.4455, -0.5111],\n",
      "        [-1.3803,  1.6191, -0.1057],\n",
      "        [-1.7958,  0.4110,  1.2085],\n",
      "        [-1.7018,  1.7287, -0.3204],\n",
      "        [-1.3208,  1.3386, -0.6313],\n",
      "        [-1.8668,  1.0357,  0.6939],\n",
      "        [-1.5077,  1.5127, -0.5303],\n",
      "        [-1.4895,  1.9115, -0.3114],\n",
      "        [-1.3675,  1.7271, -0.4222],\n",
      "        [-1.4343,  1.5498, -0.4200],\n",
      "        [-1.4427,  1.6278, -0.3950],\n",
      "        [-1.5802,  1.4427, -0.3539]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5011,  1.7644, -0.4681],\n",
      "        [-1.4366,  1.6425, -0.4171],\n",
      "        [-1.6107,  1.5914, -0.2049],\n",
      "        [-1.3660,  1.5885, -0.3565],\n",
      "        [-1.2221,  1.3517, -0.4149],\n",
      "        [ 0.6198, -0.1453, -1.0200],\n",
      "        [-1.7958,  0.1628,  1.5523],\n",
      "        [-1.0352,  1.2981, -0.5388],\n",
      "        [ 0.5695, -0.2342, -0.9824],\n",
      "        [-1.3867,  1.7647, -0.4827],\n",
      "        [-1.3859,  1.5541, -0.4123],\n",
      "        [-1.4833,  1.7728, -0.4953],\n",
      "        [-1.7991,  1.5650, -0.3153],\n",
      "        [-1.7404,  0.1453,  1.4043],\n",
      "        [-1.6624,  1.3810, -0.3594],\n",
      "        [-1.9378,  0.1614,  1.4533]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5011,  1.7644, -0.4681],\n",
      "        [-1.4366,  1.6425, -0.4171],\n",
      "        [-1.6107,  1.5914, -0.2049],\n",
      "        [-1.3660,  1.5885, -0.3565],\n",
      "        [-1.2221,  1.3517, -0.4149],\n",
      "        [ 0.6198, -0.1453, -1.0200],\n",
      "        [-1.7958,  0.1628,  1.5523],\n",
      "        [-1.0352,  1.2981, -0.5388],\n",
      "        [ 0.5695, -0.2342, -0.9824],\n",
      "        [-1.3867,  1.7647, -0.4827],\n",
      "        [-1.3859,  1.5541, -0.4123],\n",
      "        [-1.4833,  1.7728, -0.4953],\n",
      "        [-1.7991,  1.5650, -0.3153],\n",
      "        [-1.7404,  0.1453,  1.4043],\n",
      "        [-1.6624,  1.3810, -0.3594],\n",
      "        [-1.9378,  0.1614,  1.4533]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.0266,  1.2278, -0.5685],\n",
      "        [-1.2289,  1.2303, -0.2410],\n",
      "        [-1.9696,  0.7536,  0.5961],\n",
      "        [-1.7633,  0.0288,  1.3696],\n",
      "        [-1.6604,  1.4936,  0.1741],\n",
      "        [ 0.5983, -0.0927, -0.8577],\n",
      "        [ 0.6687, -0.3180, -1.0288],\n",
      "        [-1.6461,  1.5647, -0.3293],\n",
      "        [-1.4266,  1.5834, -0.3965],\n",
      "        [-1.6118,  1.5512, -0.4619],\n",
      "        [-1.6664, -0.0600,  1.5299],\n",
      "        [ 0.3889, -0.0400, -0.9475],\n",
      "        [-1.2325,  1.5985, -0.4364],\n",
      "        [-1.6023,  1.2629,  0.0970],\n",
      "        [-1.8984,  0.1106,  1.3693],\n",
      "        [-1.6511,  1.5696, -0.1433]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.0266,  1.2278, -0.5685],\n",
      "        [-1.2289,  1.2303, -0.2410],\n",
      "        [-1.9696,  0.7536,  0.5961],\n",
      "        [-1.7633,  0.0288,  1.3696],\n",
      "        [-1.6604,  1.4936,  0.1741],\n",
      "        [ 0.5983, -0.0927, -0.8577],\n",
      "        [ 0.6687, -0.3180, -1.0288],\n",
      "        [-1.6461,  1.5647, -0.3293],\n",
      "        [-1.4266,  1.5834, -0.3965],\n",
      "        [-1.6118,  1.5512, -0.4619],\n",
      "        [-1.6664, -0.0600,  1.5299],\n",
      "        [ 0.3889, -0.0400, -0.9475],\n",
      "        [-1.2325,  1.5985, -0.4364],\n",
      "        [-1.6023,  1.2629,  0.0970],\n",
      "        [-1.8984,  0.1106,  1.3693],\n",
      "        [-1.6511,  1.5696, -0.1433]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5359,  1.4930, -0.2885],\n",
      "        [-1.7452,  1.2754, -0.0896],\n",
      "        [ 0.4857, -0.0256, -1.0623],\n",
      "        [-1.8966,  0.0337,  1.6270],\n",
      "        [-1.5174,  1.5216, -0.2373],\n",
      "        [-1.6931,  1.4604, -0.1243],\n",
      "        [-1.4577,  1.6078, -0.0807],\n",
      "        [-1.2655,  1.2049, -0.4688],\n",
      "        [-1.5377,  1.0889,  0.1840],\n",
      "        [-1.5028,  1.6695, -0.3068],\n",
      "        [-2.0396,  0.1633,  1.8461],\n",
      "        [-1.8389,  0.1442,  1.4587],\n",
      "        [-1.1731,  1.5212, -0.4052],\n",
      "        [-1.7428,  0.0661,  1.5917],\n",
      "        [-1.6029,  1.7827, -0.3283],\n",
      "        [-1.6521,  1.5976, -0.3155]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5359,  1.4930, -0.2885],\n",
      "        [-1.7452,  1.2754, -0.0896],\n",
      "        [ 0.4857, -0.0256, -1.0623],\n",
      "        [-1.8966,  0.0337,  1.6270],\n",
      "        [-1.5174,  1.5216, -0.2373],\n",
      "        [-1.6931,  1.4604, -0.1243],\n",
      "        [-1.4577,  1.6078, -0.0807],\n",
      "        [-1.2655,  1.2049, -0.4688],\n",
      "        [-1.5377,  1.0889,  0.1840],\n",
      "        [-1.5028,  1.6695, -0.3068],\n",
      "        [-2.0396,  0.1633,  1.8461],\n",
      "        [-1.8389,  0.1442,  1.4587],\n",
      "        [-1.1731,  1.5212, -0.4052],\n",
      "        [-1.7428,  0.0661,  1.5917],\n",
      "        [-1.6029,  1.7827, -0.3283],\n",
      "        [-1.6521,  1.5976, -0.3155]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.9774,  1.1985, -0.3307],\n",
      "        [-1.9082, -0.0305,  1.5502],\n",
      "        [-1.9258,  0.1996,  1.5931],\n",
      "        [-1.6509,  0.8745,  0.7009],\n",
      "        [-1.8073,  1.6377, -0.0614],\n",
      "        [-1.3432,  1.6849, -0.3895],\n",
      "        [-1.3780,  1.2580, -0.2515],\n",
      "        [-1.4896,  1.7920, -0.4362],\n",
      "        [-1.4005,  1.5798, -0.2223],\n",
      "        [-1.8642,  0.0202,  1.5417],\n",
      "        [-1.1802,  1.6094, -0.5512],\n",
      "        [-1.2839,  1.3985, -0.8567],\n",
      "        [-1.4117,  1.6224, -0.3257],\n",
      "        [-1.5844,  1.8185, -0.4506],\n",
      "        [-1.2371,  0.9872, -0.1560],\n",
      "        [-1.6566,  1.3506,  0.1629]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-0.9774,  1.1985, -0.3307],\n",
      "        [-1.9082, -0.0305,  1.5502],\n",
      "        [-1.9258,  0.1996,  1.5931],\n",
      "        [-1.6509,  0.8745,  0.7009],\n",
      "        [-1.8073,  1.6377, -0.0614],\n",
      "        [-1.3432,  1.6849, -0.3895],\n",
      "        [-1.3780,  1.2580, -0.2515],\n",
      "        [-1.4896,  1.7920, -0.4362],\n",
      "        [-1.4005,  1.5798, -0.2223],\n",
      "        [-1.8642,  0.0202,  1.5417],\n",
      "        [-1.1802,  1.6094, -0.5512],\n",
      "        [-1.2839,  1.3985, -0.8567],\n",
      "        [-1.4117,  1.6224, -0.3257],\n",
      "        [-1.5844,  1.8185, -0.4506],\n",
      "        [-1.2371,  0.9872, -0.1560],\n",
      "        [-1.6566,  1.3506,  0.1629]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5984, -0.2042, -0.9114],\n",
      "        [-1.9704, -0.0744,  1.5916],\n",
      "        [-1.6587,  0.1854,  1.5456],\n",
      "        [-2.3908,  0.3783,  1.4024],\n",
      "        [-1.8944,  0.2217,  1.6885],\n",
      "        [-1.2998,  1.6704, -0.6875],\n",
      "        [-1.7855,  1.6289, -0.3826],\n",
      "        [-1.3735,  1.6330, -0.4435],\n",
      "        [-1.7542,  0.3450,  1.4565],\n",
      "        [ 0.5670, -0.1573, -0.8802],\n",
      "        [-1.9298,  0.3248,  1.4286],\n",
      "        [-1.6652,  1.5455,  0.0402],\n",
      "        [-1.5259,  0.3482,  0.8457],\n",
      "        [-1.5956,  1.5147, -0.5915],\n",
      "        [-1.8300,  0.4984,  1.0924],\n",
      "        [-1.7097,  0.2654,  1.3818]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.5984, -0.2042, -0.9114],\n",
      "        [-1.9704, -0.0744,  1.5916],\n",
      "        [-1.6587,  0.1854,  1.5456],\n",
      "        [-2.3908,  0.3783,  1.4024],\n",
      "        [-1.8944,  0.2217,  1.6885],\n",
      "        [-1.2998,  1.6704, -0.6875],\n",
      "        [-1.7855,  1.6289, -0.3826],\n",
      "        [-1.3735,  1.6330, -0.4435],\n",
      "        [-1.7542,  0.3450,  1.4565],\n",
      "        [ 0.5670, -0.1573, -0.8802],\n",
      "        [-1.9298,  0.3248,  1.4286],\n",
      "        [-1.6652,  1.5455,  0.0402],\n",
      "        [-1.5259,  0.3482,  0.8457],\n",
      "        [-1.5956,  1.5147, -0.5915],\n",
      "        [-1.8300,  0.4984,  1.0924],\n",
      "        [-1.7097,  0.2654,  1.3818]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-0.2718, -0.0917,  0.0131],\n",
      "        [-2.0866,  0.3825,  1.3793],\n",
      "        [-1.6381,  1.5498,  0.2192],\n",
      "        [-1.4212,  1.4908, -0.3300],\n",
      "        [-1.5640,  1.6591, -0.4896],\n",
      "        [-1.6968,  1.6984, -0.2670],\n",
      "        [-1.5070,  1.6089, -0.4354],\n",
      "        [-2.1066,  0.1439,  1.3011],\n",
      "        [-1.5824,  1.4989, -0.1865],\n",
      "        [-1.4263,  1.4758, -0.1077],\n",
      "        [ 0.2541,  0.1852, -0.9216],\n",
      "        [-1.7732,  1.7051, -0.0126],\n",
      "        [-0.1251,  0.6436, -0.8905],\n",
      "        [-1.6186,  0.4789,  1.0381],\n",
      "        [-1.6639,  1.7927, -0.3864],\n",
      "        [-1.8207,  0.1310,  1.3350]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-0.2718, -0.0917,  0.0131],\n",
      "        [-2.0866,  0.3825,  1.3793],\n",
      "        [-1.6381,  1.5498,  0.2192],\n",
      "        [-1.4212,  1.4908, -0.3300],\n",
      "        [-1.5640,  1.6591, -0.4896],\n",
      "        [-1.6968,  1.6984, -0.2670],\n",
      "        [-1.5070,  1.6089, -0.4354],\n",
      "        [-2.1066,  0.1439,  1.3011],\n",
      "        [-1.5824,  1.4989, -0.1865],\n",
      "        [-1.4263,  1.4758, -0.1077],\n",
      "        [ 0.2541,  0.1852, -0.9216],\n",
      "        [-1.7732,  1.7051, -0.0126],\n",
      "        [-0.1251,  0.6436, -0.8905],\n",
      "        [-1.6186,  0.4789,  1.0381],\n",
      "        [-1.6639,  1.7927, -0.3864],\n",
      "        [-1.8207,  0.1310,  1.3350]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6527,  1.8988, -0.3722],\n",
      "        [-1.6108,  1.6965, -0.3344],\n",
      "        [-1.7274,  1.0561,  0.7153],\n",
      "        [-2.1973,  0.7409,  1.2353],\n",
      "        [-1.5991,  1.8405, -0.4064],\n",
      "        [-1.3063,  1.7953, -0.5863],\n",
      "        [-1.5627,  1.6342, -0.2224],\n",
      "        [-1.7027,  0.3472,  1.1719],\n",
      "        [ 0.6142, -0.1686, -1.0016],\n",
      "        [-1.4692,  1.6791, -0.5717],\n",
      "        [-1.9029,  0.4243,  1.2380],\n",
      "        [-1.6661,  1.6761, -0.1058],\n",
      "        [-1.6256,  1.7435, -0.2348],\n",
      "        [-1.9685,  0.2749,  1.5566],\n",
      "        [-0.0995,  0.5842, -0.7112],\n",
      "        [-1.9515,  0.5789,  1.2155]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6527,  1.8988, -0.3722],\n",
      "        [-1.6108,  1.6965, -0.3344],\n",
      "        [-1.7274,  1.0561,  0.7153],\n",
      "        [-2.1973,  0.7409,  1.2353],\n",
      "        [-1.5991,  1.8405, -0.4064],\n",
      "        [-1.3063,  1.7953, -0.5863],\n",
      "        [-1.5627,  1.6342, -0.2224],\n",
      "        [-1.7027,  0.3472,  1.1719],\n",
      "        [ 0.6142, -0.1686, -1.0016],\n",
      "        [-1.4692,  1.6791, -0.5717],\n",
      "        [-1.9029,  0.4243,  1.2380],\n",
      "        [-1.6661,  1.6761, -0.1058],\n",
      "        [-1.6256,  1.7435, -0.2348],\n",
      "        [-1.9685,  0.2749,  1.5566],\n",
      "        [-0.0995,  0.5842, -0.7112],\n",
      "        [-1.9515,  0.5789,  1.2155]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5753,  1.5919, -0.3470],\n",
      "        [-1.9287,  0.2991,  1.5794],\n",
      "        [ 0.7051, -0.0620, -0.9708],\n",
      "        [-1.8993,  0.6992,  1.3054],\n",
      "        [ 0.5905, -0.2382, -1.1695],\n",
      "        [ 0.5321, -0.0342, -1.0210],\n",
      "        [-1.7508,  1.8046, -0.3695],\n",
      "        [-1.8073,  0.3664,  1.5389],\n",
      "        [-1.6107,  0.0889,  1.4752],\n",
      "        [-1.7366,  1.8709, -0.4153],\n",
      "        [-1.6324,  1.6228, -0.2278],\n",
      "        [-1.8421,  0.2941,  1.4548],\n",
      "        [ 0.4606, -0.0716, -1.0681],\n",
      "        [-1.5917,  1.6135, -0.3281],\n",
      "        [-1.3715,  1.6926, -0.1184],\n",
      "        [-1.6574,  1.7950, -0.1488]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5753,  1.5919, -0.3470],\n",
      "        [-1.9287,  0.2991,  1.5794],\n",
      "        [ 0.7051, -0.0620, -0.9708],\n",
      "        [-1.8993,  0.6992,  1.3054],\n",
      "        [ 0.5905, -0.2382, -1.1695],\n",
      "        [ 0.5321, -0.0342, -1.0210],\n",
      "        [-1.7508,  1.8046, -0.3695],\n",
      "        [-1.8073,  0.3664,  1.5389],\n",
      "        [-1.6107,  0.0889,  1.4752],\n",
      "        [-1.7366,  1.8709, -0.4153],\n",
      "        [-1.6324,  1.6228, -0.2278],\n",
      "        [-1.8421,  0.2941,  1.4548],\n",
      "        [ 0.4606, -0.0716, -1.0681],\n",
      "        [-1.5917,  1.6135, -0.3281],\n",
      "        [-1.3715,  1.6926, -0.1184],\n",
      "        [-1.6574,  1.7950, -0.1488]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5904,  1.6026, -0.3453],\n",
      "        [-1.6720,  0.2103,  1.3394],\n",
      "        [-1.5424,  1.7124, -0.4197],\n",
      "        [-1.4412,  1.4953, -0.2314],\n",
      "        [-1.5529,  1.6576, -0.2414],\n",
      "        [-1.9824,  0.4372,  1.4038],\n",
      "        [-1.7128,  1.6640, -0.3327],\n",
      "        [-1.5315,  1.5956,  0.0156],\n",
      "        [-1.7267,  1.6995, -0.3062],\n",
      "        [-1.7847,  1.7900, -0.0903],\n",
      "        [-1.8678,  1.6795, -0.2344],\n",
      "        [ 0.6316, -0.0664, -0.9992],\n",
      "        [-1.7248,  1.8216, -0.4188],\n",
      "        [ 0.4941,  0.1548, -0.9808],\n",
      "        [-1.8783,  1.9020, -0.5593],\n",
      "        [-1.7526,  1.7582, -0.3414]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5904,  1.6026, -0.3453],\n",
      "        [-1.6720,  0.2103,  1.3394],\n",
      "        [-1.5424,  1.7124, -0.4197],\n",
      "        [-1.4412,  1.4953, -0.2314],\n",
      "        [-1.5529,  1.6576, -0.2414],\n",
      "        [-1.9824,  0.4372,  1.4038],\n",
      "        [-1.7128,  1.6640, -0.3327],\n",
      "        [-1.5315,  1.5956,  0.0156],\n",
      "        [-1.7267,  1.6995, -0.3062],\n",
      "        [-1.7847,  1.7900, -0.0903],\n",
      "        [-1.8678,  1.6795, -0.2344],\n",
      "        [ 0.6316, -0.0664, -0.9992],\n",
      "        [-1.7248,  1.8216, -0.4188],\n",
      "        [ 0.4941,  0.1548, -0.9808],\n",
      "        [-1.8783,  1.9020, -0.5593],\n",
      "        [-1.7526,  1.7582, -0.3414]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4705,  1.8632, -0.3427],\n",
      "        [-1.5807,  1.6545, -0.4404],\n",
      "        [-1.7260,  1.7518, -0.3072],\n",
      "        [-0.0900,  0.4747, -0.7164],\n",
      "        [-1.8752,  1.8228, -0.2371],\n",
      "        [-1.7877,  0.3039,  1.3044],\n",
      "        [-1.6640,  0.3890,  1.2999],\n",
      "        [-2.0168,  0.7112,  0.7501],\n",
      "        [-1.5551,  1.5331, -0.4438],\n",
      "        [-1.5536,  1.8043, -0.5052],\n",
      "        [-1.5446,  1.5750, -0.2240],\n",
      "        [-1.9769,  0.1804,  1.5225],\n",
      "        [-1.7943,  0.4715,  1.4298],\n",
      "        [-2.0415,  0.2763,  1.2905],\n",
      "        [ 0.4799, -0.0289, -0.9092],\n",
      "        [-1.5379,  1.6719, -0.3580]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4705,  1.8632, -0.3427],\n",
      "        [-1.5807,  1.6545, -0.4404],\n",
      "        [-1.7260,  1.7518, -0.3072],\n",
      "        [-0.0900,  0.4747, -0.7164],\n",
      "        [-1.8752,  1.8228, -0.2371],\n",
      "        [-1.7877,  0.3039,  1.3044],\n",
      "        [-1.6640,  0.3890,  1.2999],\n",
      "        [-2.0168,  0.7112,  0.7501],\n",
      "        [-1.5551,  1.5331, -0.4438],\n",
      "        [-1.5536,  1.8043, -0.5052],\n",
      "        [-1.5446,  1.5750, -0.2240],\n",
      "        [-1.9769,  0.1804,  1.5225],\n",
      "        [-1.7943,  0.4715,  1.4298],\n",
      "        [-2.0415,  0.2763,  1.2905],\n",
      "        [ 0.4799, -0.0289, -0.9092],\n",
      "        [-1.5379,  1.6719, -0.3580]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5908,  1.8622, -0.3754],\n",
      "        [-1.5765,  1.9586, -0.1905],\n",
      "        [-1.6290,  1.7030, -0.5104],\n",
      "        [-1.2783,  1.2663, -0.1975],\n",
      "        [-1.8536,  0.3330,  1.1624],\n",
      "        [ 0.6610, -0.1702, -1.0067],\n",
      "        [-1.8001,  1.8834, -0.2607],\n",
      "        [-1.6258,  0.0779,  1.0620],\n",
      "        [-1.5284,  1.3909, -0.0609],\n",
      "        [ 0.2122,  0.1825, -0.9090],\n",
      "        [-1.5827,  1.7312, -0.5191],\n",
      "        [-1.8353,  0.5358,  1.2073],\n",
      "        [-1.5530,  1.6898, -0.2679],\n",
      "        [ 0.6225, -0.0670, -0.9569],\n",
      "        [-1.8203,  0.4291,  1.3837],\n",
      "        [-1.9496,  1.2752,  0.0108]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5908,  1.8622, -0.3754],\n",
      "        [-1.5765,  1.9586, -0.1905],\n",
      "        [-1.6290,  1.7030, -0.5104],\n",
      "        [-1.2783,  1.2663, -0.1975],\n",
      "        [-1.8536,  0.3330,  1.1624],\n",
      "        [ 0.6610, -0.1702, -1.0067],\n",
      "        [-1.8001,  1.8834, -0.2607],\n",
      "        [-1.6258,  0.0779,  1.0620],\n",
      "        [-1.5284,  1.3909, -0.0609],\n",
      "        [ 0.2122,  0.1825, -0.9090],\n",
      "        [-1.5827,  1.7312, -0.5191],\n",
      "        [-1.8353,  0.5358,  1.2073],\n",
      "        [-1.5530,  1.6898, -0.2679],\n",
      "        [ 0.6225, -0.0670, -0.9569],\n",
      "        [-1.8203,  0.4291,  1.3837],\n",
      "        [-1.9496,  1.2752,  0.0108]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7652,  1.6823, -0.3007],\n",
      "        [ 0.7295, -0.0304, -0.9476],\n",
      "        [ 0.5511, -0.0242, -0.8950],\n",
      "        [-1.8886,  0.2856,  1.4000],\n",
      "        [-1.7292,  0.2434,  1.4292],\n",
      "        [-1.5560,  1.7354, -0.3468],\n",
      "        [-1.3621,  0.4228,  0.7244],\n",
      "        [-0.3478,  0.6715, -0.8331],\n",
      "        [-1.5982,  1.6701, -0.3963],\n",
      "        [ 0.5913, -0.0551, -0.9789],\n",
      "        [-1.7132,  1.9469, -0.3190],\n",
      "        [-1.4194,  0.9642,  0.0160],\n",
      "        [-1.8236,  0.5445,  1.0881],\n",
      "        [ 0.3002,  0.0724, -1.1330],\n",
      "        [-1.7939,  1.8332, -0.4893],\n",
      "        [-1.7143,  1.8388, -0.2548]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7652,  1.6823, -0.3007],\n",
      "        [ 0.7295, -0.0304, -0.9476],\n",
      "        [ 0.5511, -0.0242, -0.8950],\n",
      "        [-1.8886,  0.2856,  1.4000],\n",
      "        [-1.7292,  0.2434,  1.4292],\n",
      "        [-1.5560,  1.7354, -0.3468],\n",
      "        [-1.3621,  0.4228,  0.7244],\n",
      "        [-0.3478,  0.6715, -0.8331],\n",
      "        [-1.5982,  1.6701, -0.3963],\n",
      "        [ 0.5913, -0.0551, -0.9789],\n",
      "        [-1.7132,  1.9469, -0.3190],\n",
      "        [-1.4194,  0.9642,  0.0160],\n",
      "        [-1.8236,  0.5445,  1.0881],\n",
      "        [ 0.3002,  0.0724, -1.1330],\n",
      "        [-1.7939,  1.8332, -0.4893],\n",
      "        [-1.7143,  1.8388, -0.2548]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.6688, -0.0458, -1.1081],\n",
      "        [-1.4815,  1.7775, -0.3050],\n",
      "        [-1.6768,  1.5791, -0.1425],\n",
      "        [-1.7525,  1.7342, -0.2913],\n",
      "        [ 0.6500, -0.1521, -0.8573],\n",
      "        [-1.8324,  0.4200,  1.1154],\n",
      "        [-1.7712,  1.9482, -0.3266],\n",
      "        [-1.7463,  1.6192, -0.0486],\n",
      "        [-1.6389,  1.8073, -0.4070],\n",
      "        [-1.6331,  0.5900,  0.8006],\n",
      "        [ 0.6017, -0.0661, -0.9134],\n",
      "        [-1.7764,  1.7649, -0.4721],\n",
      "        [-1.6125,  1.8302, -0.4661],\n",
      "        [-1.5867,  1.9661, -0.3646],\n",
      "        [-1.7637,  1.7083, -0.0241],\n",
      "        [-1.8084,  0.6933,  0.9213]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.6688, -0.0458, -1.1081],\n",
      "        [-1.4815,  1.7775, -0.3050],\n",
      "        [-1.6768,  1.5791, -0.1425],\n",
      "        [-1.7525,  1.7342, -0.2913],\n",
      "        [ 0.6500, -0.1521, -0.8573],\n",
      "        [-1.8324,  0.4200,  1.1154],\n",
      "        [-1.7712,  1.9482, -0.3266],\n",
      "        [-1.7463,  1.6192, -0.0486],\n",
      "        [-1.6389,  1.8073, -0.4070],\n",
      "        [-1.6331,  0.5900,  0.8006],\n",
      "        [ 0.6017, -0.0661, -0.9134],\n",
      "        [-1.7764,  1.7649, -0.4721],\n",
      "        [-1.6125,  1.8302, -0.4661],\n",
      "        [-1.5867,  1.9661, -0.3646],\n",
      "        [-1.7637,  1.7083, -0.0241],\n",
      "        [-1.8084,  0.6933,  0.9213]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7269,  1.8875, -0.4091],\n",
      "        [-0.3605,  0.8021, -0.8920],\n",
      "        [ 0.2353,  0.2919, -0.7564],\n",
      "        [-1.9105,  1.9644, -0.3887],\n",
      "        [-1.6476,  1.6330, -0.1919],\n",
      "        [-1.5179,  1.6656, -0.4188],\n",
      "        [-1.6743,  1.8838, -0.2536],\n",
      "        [-1.6183,  1.9832, -0.4043],\n",
      "        [-1.7295,  1.6691, -0.7331],\n",
      "        [-1.7967,  1.9753, -0.5295],\n",
      "        [-1.6461,  0.2220,  1.2743],\n",
      "        [-1.6213,  1.6441, -0.0469],\n",
      "        [-1.5461,  1.6746, -0.3810],\n",
      "        [-1.5851,  0.0422,  1.3658],\n",
      "        [-1.8474,  1.8932, -0.4008],\n",
      "        [-1.4667,  1.7897, -0.2977]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7269,  1.8875, -0.4091],\n",
      "        [-0.3605,  0.8021, -0.8920],\n",
      "        [ 0.2353,  0.2919, -0.7564],\n",
      "        [-1.9105,  1.9644, -0.3887],\n",
      "        [-1.6476,  1.6330, -0.1919],\n",
      "        [-1.5179,  1.6656, -0.4188],\n",
      "        [-1.6743,  1.8838, -0.2536],\n",
      "        [-1.6183,  1.9832, -0.4043],\n",
      "        [-1.7295,  1.6691, -0.7331],\n",
      "        [-1.7967,  1.9753, -0.5295],\n",
      "        [-1.6461,  0.2220,  1.2743],\n",
      "        [-1.6213,  1.6441, -0.0469],\n",
      "        [-1.5461,  1.6746, -0.3810],\n",
      "        [-1.5851,  0.0422,  1.3658],\n",
      "        [-1.8474,  1.8932, -0.4008],\n",
      "        [-1.4667,  1.7897, -0.2977]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7694,  0.3766,  1.3129],\n",
      "        [-1.8961,  1.3396,  0.3743],\n",
      "        [-1.5768,  1.9346, -0.3470],\n",
      "        [-0.4516,  0.4301, -0.1245],\n",
      "        [-1.5034,  1.7692, -0.2533],\n",
      "        [ 0.5266,  0.1466, -0.9684],\n",
      "        [-1.5140,  1.8981, -0.5870],\n",
      "        [-1.5791,  0.1971,  1.0522],\n",
      "        [-1.5455,  0.7659,  0.5889],\n",
      "        [-1.8019,  0.6635,  1.0309],\n",
      "        [-1.6662,  1.6283, -0.3776],\n",
      "        [-1.8076,  1.5971,  0.1623],\n",
      "        [-1.6898,  1.5734, -0.3694],\n",
      "        [-1.5584,  0.1542,  0.9975],\n",
      "        [-1.8541,  1.9661, -0.2706],\n",
      "        [-1.6183,  0.2288,  1.1784]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7694,  0.3766,  1.3129],\n",
      "        [-1.8961,  1.3396,  0.3743],\n",
      "        [-1.5768,  1.9346, -0.3470],\n",
      "        [-0.4516,  0.4301, -0.1245],\n",
      "        [-1.5034,  1.7692, -0.2533],\n",
      "        [ 0.5266,  0.1466, -0.9684],\n",
      "        [-1.5140,  1.8981, -0.5870],\n",
      "        [-1.5791,  0.1971,  1.0522],\n",
      "        [-1.5455,  0.7659,  0.5889],\n",
      "        [-1.8019,  0.6635,  1.0309],\n",
      "        [-1.6662,  1.6283, -0.3776],\n",
      "        [-1.8076,  1.5971,  0.1623],\n",
      "        [-1.6898,  1.5734, -0.3694],\n",
      "        [-1.5584,  0.1542,  0.9975],\n",
      "        [-1.8541,  1.9661, -0.2706],\n",
      "        [-1.6183,  0.2288,  1.1784]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6900,  0.3371,  1.2815],\n",
      "        [-1.9261,  0.8159,  0.7435],\n",
      "        [-1.6045,  0.7663,  0.5138],\n",
      "        [-1.5067,  0.2615,  1.0794],\n",
      "        [-1.5304,  0.3808,  1.2986],\n",
      "        [-1.7000,  1.7639, -0.0310],\n",
      "        [-1.8483,  1.3212,  0.1753],\n",
      "        [-1.6315,  1.5986, -0.1736],\n",
      "        [-1.8157,  1.7521, -0.1005],\n",
      "        [-1.7193,  1.6844, -0.4083],\n",
      "        [-1.5445,  0.1870,  1.3575],\n",
      "        [-2.0432,  1.4816,  0.1328],\n",
      "        [-1.6614,  1.9138, -0.5506],\n",
      "        [-1.5042,  1.6607, -0.3198],\n",
      "        [-1.6838,  1.8228, -0.2694],\n",
      "        [-1.8405,  0.6152,  1.1892]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6900,  0.3371,  1.2815],\n",
      "        [-1.9261,  0.8159,  0.7435],\n",
      "        [-1.6045,  0.7663,  0.5138],\n",
      "        [-1.5067,  0.2615,  1.0794],\n",
      "        [-1.5304,  0.3808,  1.2986],\n",
      "        [-1.7000,  1.7639, -0.0310],\n",
      "        [-1.8483,  1.3212,  0.1753],\n",
      "        [-1.6315,  1.5986, -0.1736],\n",
      "        [-1.8157,  1.7521, -0.1005],\n",
      "        [-1.7193,  1.6844, -0.4083],\n",
      "        [-1.5445,  0.1870,  1.3575],\n",
      "        [-2.0432,  1.4816,  0.1328],\n",
      "        [-1.6614,  1.9138, -0.5506],\n",
      "        [-1.5042,  1.6607, -0.3198],\n",
      "        [-1.6838,  1.8228, -0.2694],\n",
      "        [-1.8405,  0.6152,  1.1892]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5960,  1.8744, -0.2667],\n",
      "        [-1.2183,  1.4037, -0.2962],\n",
      "        [-1.8017,  1.7048, -0.1935],\n",
      "        [-1.4963,  0.2456,  1.0822],\n",
      "        [-1.7256,  1.7706, -0.4663],\n",
      "        [-1.6970,  1.8942, -0.3300],\n",
      "        [-1.6192,  0.1870,  1.1355],\n",
      "        [-1.6949,  1.6736, -0.3787],\n",
      "        [-1.7211,  1.7254, -0.3436],\n",
      "        [-1.7626,  1.7002, -0.1029],\n",
      "        [-1.5900,  1.0375,  0.6037],\n",
      "        [-1.2332,  0.1896,  0.9287],\n",
      "        [-1.6258,  1.5614, -0.5203],\n",
      "        [-1.6720,  1.6674, -0.4245],\n",
      "        [-0.6651,  1.0302, -0.7870],\n",
      "        [ 0.3961,  0.2232, -0.9419]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5960,  1.8744, -0.2667],\n",
      "        [-1.2183,  1.4037, -0.2962],\n",
      "        [-1.8017,  1.7048, -0.1935],\n",
      "        [-1.4963,  0.2456,  1.0822],\n",
      "        [-1.7256,  1.7706, -0.4663],\n",
      "        [-1.6970,  1.8942, -0.3300],\n",
      "        [-1.6192,  0.1870,  1.1355],\n",
      "        [-1.6949,  1.6736, -0.3787],\n",
      "        [-1.7211,  1.7254, -0.3436],\n",
      "        [-1.7626,  1.7002, -0.1029],\n",
      "        [-1.5900,  1.0375,  0.6037],\n",
      "        [-1.2332,  0.1896,  0.9287],\n",
      "        [-1.6258,  1.5614, -0.5203],\n",
      "        [-1.6720,  1.6674, -0.4245],\n",
      "        [-0.6651,  1.0302, -0.7870],\n",
      "        [ 0.3961,  0.2232, -0.9419]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.6348,  1.7146, -0.0274],\n",
      "        [-0.6267,  0.3351, -0.0459],\n",
      "        [ 0.4604,  0.2440, -1.1488],\n",
      "        [-1.3685,  0.2006,  1.2154],\n",
      "        [-1.7159,  1.6796, -0.4582],\n",
      "        [-1.8361,  1.8602, -0.1213],\n",
      "        [-1.5057,  1.5421, -0.0298],\n",
      "        [-1.6648,  1.6957, -0.1017],\n",
      "        [-1.7859,  0.5795,  1.0017],\n",
      "        [-1.4215,  1.5844, -0.3613],\n",
      "        [-1.8659,  1.3192,  0.5305],\n",
      "        [-1.6569,  1.6563, -0.3999],\n",
      "        [ 0.6247, -0.0773, -1.1961],\n",
      "        [ 0.5174,  0.0394, -0.8637],\n",
      "        [-1.6941,  0.5058,  1.0828],\n",
      "        [-1.6233,  1.1237,  0.5099]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.6348,  1.7146, -0.0274],\n",
      "        [-0.6267,  0.3351, -0.0459],\n",
      "        [ 0.4604,  0.2440, -1.1488],\n",
      "        [-1.3685,  0.2006,  1.2154],\n",
      "        [-1.7159,  1.6796, -0.4582],\n",
      "        [-1.8361,  1.8602, -0.1213],\n",
      "        [-1.5057,  1.5421, -0.0298],\n",
      "        [-1.6648,  1.6957, -0.1017],\n",
      "        [-1.7859,  0.5795,  1.0017],\n",
      "        [-1.4215,  1.5844, -0.3613],\n",
      "        [-1.8659,  1.3192,  0.5305],\n",
      "        [-1.6569,  1.6563, -0.3999],\n",
      "        [ 0.6247, -0.0773, -1.1961],\n",
      "        [ 0.5174,  0.0394, -0.8637],\n",
      "        [-1.6941,  0.5058,  1.0828],\n",
      "        [-1.6233,  1.1237,  0.5099]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4448,  0.1487,  1.1634],\n",
      "        [-1.6787,  0.3040,  0.9905],\n",
      "        [-1.5594,  0.3308,  0.8515],\n",
      "        [-1.6461,  1.5714, -0.3130],\n",
      "        [-1.4789,  1.6253, -0.4473],\n",
      "        [-1.4878,  1.6445, -0.4260],\n",
      "        [-1.5000,  0.9964,  0.2860],\n",
      "        [ 0.5937,  0.0130, -1.0076],\n",
      "        [-1.7316,  1.6905, -0.2864],\n",
      "        [-1.5370,  1.4628,  0.1152],\n",
      "        [ 0.4922, -0.0418, -0.9172],\n",
      "        [-1.4844,  0.3627,  0.9908],\n",
      "        [-1.4602,  1.7543, -0.3979],\n",
      "        [-1.4721,  0.4359,  1.0118],\n",
      "        [-1.6573,  1.5585, -0.1363],\n",
      "        [-1.7792,  1.7464, -0.3287]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4448,  0.1487,  1.1634],\n",
      "        [-1.6787,  0.3040,  0.9905],\n",
      "        [-1.5594,  0.3308,  0.8515],\n",
      "        [-1.6461,  1.5714, -0.3130],\n",
      "        [-1.4789,  1.6253, -0.4473],\n",
      "        [-1.4878,  1.6445, -0.4260],\n",
      "        [-1.5000,  0.9964,  0.2860],\n",
      "        [ 0.5937,  0.0130, -1.0076],\n",
      "        [-1.7316,  1.6905, -0.2864],\n",
      "        [-1.5370,  1.4628,  0.1152],\n",
      "        [ 0.4922, -0.0418, -0.9172],\n",
      "        [-1.4844,  0.3627,  0.9908],\n",
      "        [-1.4602,  1.7543, -0.3979],\n",
      "        [-1.4721,  0.4359,  1.0118],\n",
      "        [-1.6573,  1.5585, -0.1363],\n",
      "        [-1.7792,  1.7464, -0.3287]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3471,  0.1170, -0.9647],\n",
      "        [-1.6264,  0.3735,  1.1964],\n",
      "        [-1.4290,  0.4286,  1.0558],\n",
      "        [ 0.5000,  0.1439, -1.1011],\n",
      "        [-1.6438,  1.8665, -0.3086],\n",
      "        [ 0.1827,  0.3169, -0.8351],\n",
      "        [-1.8890,  0.7749,  0.6123],\n",
      "        [-1.6767,  1.5628, -0.2041],\n",
      "        [-1.4672,  1.7445, -0.3222],\n",
      "        [-1.4328,  1.5076, -0.3981],\n",
      "        [-1.6713,  1.5354, -0.2951],\n",
      "        [-1.5674,  0.4086,  1.0326],\n",
      "        [-1.6388,  0.2560,  1.0937],\n",
      "        [-1.9343,  1.3217,  0.3733],\n",
      "        [-1.6573,  1.9229, -0.3677],\n",
      "        [-1.8724,  1.7934, -0.0407]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[ 0.3471,  0.1170, -0.9647],\n",
      "        [-1.6264,  0.3735,  1.1964],\n",
      "        [-1.4290,  0.4286,  1.0558],\n",
      "        [ 0.5000,  0.1439, -1.1011],\n",
      "        [-1.6438,  1.8665, -0.3086],\n",
      "        [ 0.1827,  0.3169, -0.8351],\n",
      "        [-1.8890,  0.7749,  0.6123],\n",
      "        [-1.6767,  1.5628, -0.2041],\n",
      "        [-1.4672,  1.7445, -0.3222],\n",
      "        [-1.4328,  1.5076, -0.3981],\n",
      "        [-1.6713,  1.5354, -0.2951],\n",
      "        [-1.5674,  0.4086,  1.0326],\n",
      "        [-1.6388,  0.2560,  1.0937],\n",
      "        [-1.9343,  1.3217,  0.3733],\n",
      "        [-1.6573,  1.9229, -0.3677],\n",
      "        [-1.8724,  1.7934, -0.0407]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7263,  1.8643, -0.2403],\n",
      "        [-1.7341,  1.6876, -0.3402],\n",
      "        [-1.5843,  1.5029, -0.3794],\n",
      "        [-1.4383,  1.7001, -0.2300],\n",
      "        [-1.4460,  1.6466, -0.3005],\n",
      "        [-1.6582,  1.7930, -0.1590],\n",
      "        [-1.3220,  1.6586, -0.3956],\n",
      "        [-1.5860,  1.9300, -0.2967],\n",
      "        [-1.5526,  1.4357, -0.1229],\n",
      "        [-1.5931,  1.5511, -0.1470],\n",
      "        [-1.4632,  1.8600, -0.4679],\n",
      "        [-1.5536,  1.5602, -0.3404],\n",
      "        [-1.6923,  1.6959, -0.1784],\n",
      "        [-1.5898,  1.4057, -0.2376],\n",
      "        [-1.7930,  1.1820,  0.3083],\n",
      "        [-1.7853,  1.6991,  0.0072]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7263,  1.8643, -0.2403],\n",
      "        [-1.7341,  1.6876, -0.3402],\n",
      "        [-1.5843,  1.5029, -0.3794],\n",
      "        [-1.4383,  1.7001, -0.2300],\n",
      "        [-1.4460,  1.6466, -0.3005],\n",
      "        [-1.6582,  1.7930, -0.1590],\n",
      "        [-1.3220,  1.6586, -0.3956],\n",
      "        [-1.5860,  1.9300, -0.2967],\n",
      "        [-1.5526,  1.4357, -0.1229],\n",
      "        [-1.5931,  1.5511, -0.1470],\n",
      "        [-1.4632,  1.8600, -0.4679],\n",
      "        [-1.5536,  1.5602, -0.3404],\n",
      "        [-1.6923,  1.6959, -0.1784],\n",
      "        [-1.5898,  1.4057, -0.2376],\n",
      "        [-1.7930,  1.1820,  0.3083],\n",
      "        [-1.7853,  1.6991,  0.0072]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.7781,  1.6776, -0.3891],\n",
      "        [-1.6848,  0.9007,  0.5949],\n",
      "        [-1.6612,  1.7163, -0.1788],\n",
      "        [-1.6617,  1.7431, -0.2806],\n",
      "        [-1.5978,  1.6266, -0.0033],\n",
      "        [-1.7084,  1.8098, -0.2892],\n",
      "        [ 0.5929,  0.0727, -1.0570],\n",
      "        [-1.6752,  0.4400,  1.2325],\n",
      "        [-1.6331,  1.7308, -0.3018],\n",
      "        [-1.4294,  0.2760,  0.9524],\n",
      "        [-1.5105,  0.4527,  1.0807],\n",
      "        [ 0.8050,  0.0723, -1.0144],\n",
      "        [-1.6712,  0.4501,  0.8262],\n",
      "        [-1.7644,  1.5457, -0.2476],\n",
      "        [-1.5884,  1.2573, -0.3231],\n",
      "        [-1.5774,  1.7106, -0.3524]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.7781,  1.6776, -0.3891],\n",
      "        [-1.6848,  0.9007,  0.5949],\n",
      "        [-1.6612,  1.7163, -0.1788],\n",
      "        [-1.6617,  1.7431, -0.2806],\n",
      "        [-1.5978,  1.6266, -0.0033],\n",
      "        [-1.7084,  1.8098, -0.2892],\n",
      "        [ 0.5929,  0.0727, -1.0570],\n",
      "        [-1.6752,  0.4400,  1.2325],\n",
      "        [-1.6331,  1.7308, -0.3018],\n",
      "        [-1.4294,  0.2760,  0.9524],\n",
      "        [-1.5105,  0.4527,  1.0807],\n",
      "        [ 0.8050,  0.0723, -1.0144],\n",
      "        [-1.6712,  0.4501,  0.8262],\n",
      "        [-1.7644,  1.5457, -0.2476],\n",
      "        [-1.5884,  1.2573, -0.3231],\n",
      "        [-1.5774,  1.7106, -0.3524]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3340,  0.2475,  1.0498],\n",
      "        [-1.5015,  1.8946, -0.4029],\n",
      "        [-1.4378,  1.5722, -0.2757],\n",
      "        [-1.7209,  0.2763,  1.2484],\n",
      "        [-1.6681,  1.6548, -0.1526],\n",
      "        [-1.6009,  0.3508,  1.2056],\n",
      "        [-1.5544,  0.4218,  1.0207],\n",
      "        [-1.3410,  0.3680,  1.0890],\n",
      "        [-1.6400,  1.8856, -0.1719],\n",
      "        [-1.5782,  1.6095, -0.5622],\n",
      "        [-1.3865,  1.3211, -0.0649],\n",
      "        [-1.5642,  0.4749,  0.7556],\n",
      "        [-1.3643,  1.5086, -0.3650],\n",
      "        [-1.4130,  1.5314, -0.4230],\n",
      "        [-1.3336,  1.7197, -0.3795],\n",
      "        [ 0.5488,  0.1200, -1.1779]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3340,  0.2475,  1.0498],\n",
      "        [-1.5015,  1.8946, -0.4029],\n",
      "        [-1.4378,  1.5722, -0.2757],\n",
      "        [-1.7209,  0.2763,  1.2484],\n",
      "        [-1.6681,  1.6548, -0.1526],\n",
      "        [-1.6009,  0.3508,  1.2056],\n",
      "        [-1.5544,  0.4218,  1.0207],\n",
      "        [-1.3410,  0.3680,  1.0890],\n",
      "        [-1.6400,  1.8856, -0.1719],\n",
      "        [-1.5782,  1.6095, -0.5622],\n",
      "        [-1.3865,  1.3211, -0.0649],\n",
      "        [-1.5642,  0.4749,  0.7556],\n",
      "        [-1.3643,  1.5086, -0.3650],\n",
      "        [-1.4130,  1.5314, -0.4230],\n",
      "        [-1.3336,  1.7197, -0.3795],\n",
      "        [ 0.5488,  0.1200, -1.1779]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5170,  1.4860, -0.1381],\n",
      "        [-1.5138,  0.4933,  1.0186],\n",
      "        [-1.5544,  1.7353, -0.2917],\n",
      "        [-1.5279,  1.5616, -0.1058],\n",
      "        [ 0.5185,  0.0446, -1.0836],\n",
      "        [-1.4472,  1.7223, -0.2911],\n",
      "        [-1.5247,  1.8692, -0.3429],\n",
      "        [-1.4944,  0.2515,  1.2327],\n",
      "        [-1.5445,  1.5678, -0.0997],\n",
      "        [-1.7331,  0.3365,  1.1597],\n",
      "        [-1.4496,  1.4994, -0.0485],\n",
      "        [-1.6820,  0.3528,  0.8254],\n",
      "        [-1.3130,  1.3185, -0.4286],\n",
      "        [ 0.2018,  0.3863, -0.8537],\n",
      "        [-1.3808,  1.6151, -0.3824],\n",
      "        [-1.5000,  1.7891, -0.3363]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5170,  1.4860, -0.1381],\n",
      "        [-1.5138,  0.4933,  1.0186],\n",
      "        [-1.5544,  1.7353, -0.2917],\n",
      "        [-1.5279,  1.5616, -0.1058],\n",
      "        [ 0.5185,  0.0446, -1.0836],\n",
      "        [-1.4472,  1.7223, -0.2911],\n",
      "        [-1.5247,  1.8692, -0.3429],\n",
      "        [-1.4944,  0.2515,  1.2327],\n",
      "        [-1.5445,  1.5678, -0.0997],\n",
      "        [-1.7331,  0.3365,  1.1597],\n",
      "        [-1.4496,  1.4994, -0.0485],\n",
      "        [-1.6820,  0.3528,  0.8254],\n",
      "        [-1.3130,  1.3185, -0.4286],\n",
      "        [ 0.2018,  0.3863, -0.8537],\n",
      "        [-1.3808,  1.6151, -0.3824],\n",
      "        [-1.5000,  1.7891, -0.3363]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5013,  1.6873, -0.4179],\n",
      "        [ 0.5317, -0.0429, -1.0068],\n",
      "        [-1.4257,  1.4159, -0.4107],\n",
      "        [-1.6991,  0.4957,  0.8584],\n",
      "        [-1.4957,  1.4673, -0.3208],\n",
      "        [-1.5311,  1.7125, -0.5634],\n",
      "        [-1.4768,  0.3422,  1.0785],\n",
      "        [-1.3431,  1.6234, -0.1267],\n",
      "        [-0.0154,  0.0352, -0.3170],\n",
      "        [-1.4979,  1.5009, -0.1536],\n",
      "        [-1.6371,  0.3258,  1.0804],\n",
      "        [-1.6734,  0.8548,  0.7584],\n",
      "        [-1.4166,  1.4332, -0.1956],\n",
      "        [-0.4346,  0.5480, -0.4018],\n",
      "        [-1.6873,  1.7211, -0.2654],\n",
      "        [-1.2692,  1.4011, -0.2785]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5013,  1.6873, -0.4179],\n",
      "        [ 0.5317, -0.0429, -1.0068],\n",
      "        [-1.4257,  1.4159, -0.4107],\n",
      "        [-1.6991,  0.4957,  0.8584],\n",
      "        [-1.4957,  1.4673, -0.3208],\n",
      "        [-1.5311,  1.7125, -0.5634],\n",
      "        [-1.4768,  0.3422,  1.0785],\n",
      "        [-1.3431,  1.6234, -0.1267],\n",
      "        [-0.0154,  0.0352, -0.3170],\n",
      "        [-1.4979,  1.5009, -0.1536],\n",
      "        [-1.6371,  0.3258,  1.0804],\n",
      "        [-1.6734,  0.8548,  0.7584],\n",
      "        [-1.4166,  1.4332, -0.1956],\n",
      "        [-0.4346,  0.5480, -0.4018],\n",
      "        [-1.6873,  1.7211, -0.2654],\n",
      "        [-1.2692,  1.4011, -0.2785]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.4040,  1.5268, -0.5456],\n",
      "        [-1.4222,  1.6385, -0.1872],\n",
      "        [-1.4597,  1.6597, -0.2795],\n",
      "        [-1.4870,  0.2310,  1.0737],\n",
      "        [-1.3280,  1.6431, -0.2444],\n",
      "        [-1.6424,  0.2541,  1.0804],\n",
      "        [ 0.1065,  0.3598, -0.9507],\n",
      "        [-1.3947,  0.9821,  0.2667],\n",
      "        [-1.4973,  1.5287, -0.4676],\n",
      "        [-1.6321,  1.5310, -0.2922],\n",
      "        [-1.6678,  1.4418, -0.1084],\n",
      "        [-1.3002,  0.4042,  1.0101],\n",
      "        [-1.4168,  1.5392, -0.1181],\n",
      "        [-1.6414,  1.6850, -0.0916],\n",
      "        [ 0.5678,  0.0065, -0.9925],\n",
      "        [-1.5730,  0.3551,  0.8914]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.4040,  1.5268, -0.5456],\n",
      "        [-1.4222,  1.6385, -0.1872],\n",
      "        [-1.4597,  1.6597, -0.2795],\n",
      "        [-1.4870,  0.2310,  1.0737],\n",
      "        [-1.3280,  1.6431, -0.2444],\n",
      "        [-1.6424,  0.2541,  1.0804],\n",
      "        [ 0.1065,  0.3598, -0.9507],\n",
      "        [-1.3947,  0.9821,  0.2667],\n",
      "        [-1.4973,  1.5287, -0.4676],\n",
      "        [-1.6321,  1.5310, -0.2922],\n",
      "        [-1.6678,  1.4418, -0.1084],\n",
      "        [-1.3002,  0.4042,  1.0101],\n",
      "        [-1.4168,  1.5392, -0.1181],\n",
      "        [-1.6414,  1.6850, -0.0916],\n",
      "        [ 0.5678,  0.0065, -0.9925],\n",
      "        [-1.5730,  0.3551,  0.8914]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3492,  0.3854,  1.0430],\n",
      "        [-1.2769,  1.1808, -0.2621],\n",
      "        [-1.5569,  1.4124, -0.1578],\n",
      "        [-1.4628,  0.2512,  1.0403],\n",
      "        [-1.4587,  1.2687, -0.2983],\n",
      "        [-1.5177,  0.3102,  0.9383],\n",
      "        [-1.4066,  0.2493,  0.7468],\n",
      "        [-1.4343,  1.4563, -0.4108],\n",
      "        [-1.3917,  1.4297, -0.2719],\n",
      "        [-1.3603,  0.5734,  0.8681],\n",
      "        [-1.3011,  0.2968,  0.8114],\n",
      "        [-1.6817,  0.3457,  1.0138],\n",
      "        [-1.3601,  1.5290, -0.4923],\n",
      "        [ 0.4808, -0.0446, -0.9527],\n",
      "        [ 0.3850,  0.0056, -1.0371],\n",
      "        [-1.2284,  1.1715, -0.0551]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3492,  0.3854,  1.0430],\n",
      "        [-1.2769,  1.1808, -0.2621],\n",
      "        [-1.5569,  1.4124, -0.1578],\n",
      "        [-1.4628,  0.2512,  1.0403],\n",
      "        [-1.4587,  1.2687, -0.2983],\n",
      "        [-1.5177,  0.3102,  0.9383],\n",
      "        [-1.4066,  0.2493,  0.7468],\n",
      "        [-1.4343,  1.4563, -0.4108],\n",
      "        [-1.3917,  1.4297, -0.2719],\n",
      "        [-1.3603,  0.5734,  0.8681],\n",
      "        [-1.3011,  0.2968,  0.8114],\n",
      "        [-1.6817,  0.3457,  1.0138],\n",
      "        [-1.3601,  1.5290, -0.4923],\n",
      "        [ 0.4808, -0.0446, -0.9527],\n",
      "        [ 0.3850,  0.0056, -1.0371],\n",
      "        [-1.2284,  1.1715, -0.0551]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5685,  0.3051,  1.0314],\n",
      "        [ 0.5795,  0.0766, -0.9267],\n",
      "        [-1.3333,  1.8146, -0.4403],\n",
      "        [-1.2514,  1.0615, -0.0609],\n",
      "        [-1.3476,  1.2567, -0.0174],\n",
      "        [-1.5160,  1.5341, -0.2548],\n",
      "        [-1.3930,  1.2445, -0.2616],\n",
      "        [-1.4860,  0.2568,  0.9675],\n",
      "        [-1.4447,  1.2879, -0.1665],\n",
      "        [-1.3972,  0.3875,  1.0630],\n",
      "        [-1.4406,  0.5085,  0.8037],\n",
      "        [-1.5890,  0.3457,  0.8699],\n",
      "        [-1.1562,  1.4347, -0.4919],\n",
      "        [-1.3505,  1.4066, -0.2282],\n",
      "        [-1.4619,  0.2109,  1.1091],\n",
      "        [-1.9056,  0.5437,  0.9625]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5685,  0.3051,  1.0314],\n",
      "        [ 0.5795,  0.0766, -0.9267],\n",
      "        [-1.3333,  1.8146, -0.4403],\n",
      "        [-1.2514,  1.0615, -0.0609],\n",
      "        [-1.3476,  1.2567, -0.0174],\n",
      "        [-1.5160,  1.5341, -0.2548],\n",
      "        [-1.3930,  1.2445, -0.2616],\n",
      "        [-1.4860,  0.2568,  0.9675],\n",
      "        [-1.4447,  1.2879, -0.1665],\n",
      "        [-1.3972,  0.3875,  1.0630],\n",
      "        [-1.4406,  0.5085,  0.8037],\n",
      "        [-1.5890,  0.3457,  0.8699],\n",
      "        [-1.1562,  1.4347, -0.4919],\n",
      "        [-1.3505,  1.4066, -0.2282],\n",
      "        [-1.4619,  0.2109,  1.1091],\n",
      "        [-1.9056,  0.5437,  0.9625]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3957,  0.3404,  0.9754],\n",
      "        [-1.2289,  1.3999, -0.2691],\n",
      "        [-1.3235,  1.2462, -0.3382],\n",
      "        [-1.5394,  1.5512, -0.1080],\n",
      "        [-1.3764,  1.4105, -0.1028],\n",
      "        [ 0.2267,  0.1374, -1.0262],\n",
      "        [-0.4290,  0.9049, -0.8689],\n",
      "        [-1.6070,  0.8167,  0.5263],\n",
      "        [-1.3826,  1.2735, -0.1764],\n",
      "        [-1.3788,  0.1284,  1.0581],\n",
      "        [-1.4710,  0.2328,  0.9580],\n",
      "        [ 0.1666,  0.2828, -0.9136],\n",
      "        [-1.3440,  1.3285, -0.0941],\n",
      "        [-0.9266,  0.4953,  0.3197],\n",
      "        [-1.1933,  1.3228, -0.2218],\n",
      "        [-1.2973,  1.2484, -0.0901]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3957,  0.3404,  0.9754],\n",
      "        [-1.2289,  1.3999, -0.2691],\n",
      "        [-1.3235,  1.2462, -0.3382],\n",
      "        [-1.5394,  1.5512, -0.1080],\n",
      "        [-1.3764,  1.4105, -0.1028],\n",
      "        [ 0.2267,  0.1374, -1.0262],\n",
      "        [-0.4290,  0.9049, -0.8689],\n",
      "        [-1.6070,  0.8167,  0.5263],\n",
      "        [-1.3826,  1.2735, -0.1764],\n",
      "        [-1.3788,  0.1284,  1.0581],\n",
      "        [-1.4710,  0.2328,  0.9580],\n",
      "        [ 0.1666,  0.2828, -0.9136],\n",
      "        [-1.3440,  1.3285, -0.0941],\n",
      "        [-0.9266,  0.4953,  0.3197],\n",
      "        [-1.1933,  1.3228, -0.2218],\n",
      "        [-1.2973,  1.2484, -0.0901]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3466,  1.4175, -0.3357],\n",
      "        [-1.2287,  1.3166, -0.1256],\n",
      "        [-1.3960,  1.4081, -0.3106],\n",
      "        [-1.3770,  0.1579,  0.9522],\n",
      "        [ 0.2824,  0.0866, -0.8626],\n",
      "        [-1.7690,  1.5137, -0.1101],\n",
      "        [-1.3629,  1.1939, -0.2811],\n",
      "        [-1.3734,  1.3678, -0.1126],\n",
      "        [-1.4241,  1.3607, -0.0994],\n",
      "        [-1.2695,  1.3516, -0.4101],\n",
      "        [-1.6401,  0.3225,  1.0145],\n",
      "        [-1.2180,  1.1245, -0.3592],\n",
      "        [-1.3309,  0.2053,  0.9533],\n",
      "        [-1.3378,  1.1508, -0.1783],\n",
      "        [-1.2947,  1.3188, -0.2506],\n",
      "        [-1.5695,  0.3038,  1.0871]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3466,  1.4175, -0.3357],\n",
      "        [-1.2287,  1.3166, -0.1256],\n",
      "        [-1.3960,  1.4081, -0.3106],\n",
      "        [-1.3770,  0.1579,  0.9522],\n",
      "        [ 0.2824,  0.0866, -0.8626],\n",
      "        [-1.7690,  1.5137, -0.1101],\n",
      "        [-1.3629,  1.1939, -0.2811],\n",
      "        [-1.3734,  1.3678, -0.1126],\n",
      "        [-1.4241,  1.3607, -0.0994],\n",
      "        [-1.2695,  1.3516, -0.4101],\n",
      "        [-1.6401,  0.3225,  1.0145],\n",
      "        [-1.2180,  1.1245, -0.3592],\n",
      "        [-1.3309,  0.2053,  0.9533],\n",
      "        [-1.3378,  1.1508, -0.1783],\n",
      "        [-1.2947,  1.3188, -0.2506],\n",
      "        [-1.5695,  0.3038,  1.0871]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3795,  1.3732,  0.0242],\n",
      "        [-0.9787,  1.1819, -0.4855],\n",
      "        [-1.1587,  1.3849, -0.5612],\n",
      "        [-1.4169,  0.3960,  0.8290],\n",
      "        [-1.5296,  1.3925,  0.1022],\n",
      "        [-1.4573,  1.1148,  0.2004],\n",
      "        [ 0.4709,  0.1489, -1.1488],\n",
      "        [-1.5392,  0.9715,  0.3721],\n",
      "        [-1.3822,  0.4325,  0.7672],\n",
      "        [-1.4373,  1.3130, -0.1127],\n",
      "        [-1.7889,  0.6452,  0.7279],\n",
      "        [-1.4171,  0.4085,  0.9705],\n",
      "        [-1.4233,  0.1478,  0.9794],\n",
      "        [-1.4506,  1.3461, -0.4794],\n",
      "        [-1.3911,  1.3756, -0.2130],\n",
      "        [-1.4667,  0.6717,  0.7668]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3795,  1.3732,  0.0242],\n",
      "        [-0.9787,  1.1819, -0.4855],\n",
      "        [-1.1587,  1.3849, -0.5612],\n",
      "        [-1.4169,  0.3960,  0.8290],\n",
      "        [-1.5296,  1.3925,  0.1022],\n",
      "        [-1.4573,  1.1148,  0.2004],\n",
      "        [ 0.4709,  0.1489, -1.1488],\n",
      "        [-1.5392,  0.9715,  0.3721],\n",
      "        [-1.3822,  0.4325,  0.7672],\n",
      "        [-1.4373,  1.3130, -0.1127],\n",
      "        [-1.7889,  0.6452,  0.7279],\n",
      "        [-1.4171,  0.4085,  0.9705],\n",
      "        [-1.4233,  0.1478,  0.9794],\n",
      "        [-1.4506,  1.3461, -0.4794],\n",
      "        [-1.3911,  1.3756, -0.2130],\n",
      "        [-1.4667,  0.6717,  0.7668]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.2650,  1.3903, -0.1470],\n",
      "        [-1.2733,  1.3943, -0.0205],\n",
      "        [-1.6884,  0.1709,  1.1976],\n",
      "        [ 0.5233,  0.1151, -1.0862],\n",
      "        [-1.4755,  1.5673, -0.1216],\n",
      "        [-1.4003,  1.4200, -0.0830],\n",
      "        [ 0.1920,  0.4006, -1.0904],\n",
      "        [-1.3175,  1.4323, -0.2620],\n",
      "        [-1.3598,  1.3721, -0.1932],\n",
      "        [-1.3147,  1.3153, -0.0608],\n",
      "        [-1.4254,  1.5412, -0.2912],\n",
      "        [-1.2796,  1.2944, -0.4216],\n",
      "        [-1.5130,  1.2695, -0.1459],\n",
      "        [-1.4358,  1.1635, -0.1306],\n",
      "        [-1.4238,  1.2684, -0.2205],\n",
      "        [ 0.6317,  0.0194, -1.2710]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.2650,  1.3903, -0.1470],\n",
      "        [-1.2733,  1.3943, -0.0205],\n",
      "        [-1.6884,  0.1709,  1.1976],\n",
      "        [ 0.5233,  0.1151, -1.0862],\n",
      "        [-1.4755,  1.5673, -0.1216],\n",
      "        [-1.4003,  1.4200, -0.0830],\n",
      "        [ 0.1920,  0.4006, -1.0904],\n",
      "        [-1.3175,  1.4323, -0.2620],\n",
      "        [-1.3598,  1.3721, -0.1932],\n",
      "        [-1.3147,  1.3153, -0.0608],\n",
      "        [-1.4254,  1.5412, -0.2912],\n",
      "        [-1.2796,  1.2944, -0.4216],\n",
      "        [-1.5130,  1.2695, -0.1459],\n",
      "        [-1.4358,  1.1635, -0.1306],\n",
      "        [-1.4238,  1.2684, -0.2205],\n",
      "        [ 0.6317,  0.0194, -1.2710]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.5855,  0.1628,  1.2013],\n",
      "        [-1.1385,  1.5414, -0.2419],\n",
      "        [-1.4008,  1.4636, -0.4019],\n",
      "        [-1.2866,  1.4169, -0.2155],\n",
      "        [-1.2277,  1.4692, -0.4315],\n",
      "        [-1.1951,  1.1825, -0.2904],\n",
      "        [-1.7073,  0.6953,  0.5601],\n",
      "        [ 0.3515,  0.2281, -1.0343],\n",
      "        [-1.3647,  0.4809,  0.9393],\n",
      "        [-1.6215,  0.3888,  0.9679],\n",
      "        [-1.2823,  1.1843, -0.0806],\n",
      "        [-1.2827,  1.3214, -0.3155],\n",
      "        [-0.9298,  0.8576, -0.2620],\n",
      "        [-1.5876,  0.3846,  1.0366],\n",
      "        [ 0.4738,  0.1127, -1.2489],\n",
      "        [-1.3593,  1.3880, -0.3450]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.5855,  0.1628,  1.2013],\n",
      "        [-1.1385,  1.5414, -0.2419],\n",
      "        [-1.4008,  1.4636, -0.4019],\n",
      "        [-1.2866,  1.4169, -0.2155],\n",
      "        [-1.2277,  1.4692, -0.4315],\n",
      "        [-1.1951,  1.1825, -0.2904],\n",
      "        [-1.7073,  0.6953,  0.5601],\n",
      "        [ 0.3515,  0.2281, -1.0343],\n",
      "        [-1.3647,  0.4809,  0.9393],\n",
      "        [-1.6215,  0.3888,  0.9679],\n",
      "        [-1.2823,  1.1843, -0.0806],\n",
      "        [-1.2827,  1.3214, -0.3155],\n",
      "        [-0.9298,  0.8576, -0.2620],\n",
      "        [-1.5876,  0.3846,  1.0366],\n",
      "        [ 0.4738,  0.1127, -1.2489],\n",
      "        [-1.3593,  1.3880, -0.3450]], grad_fn=<AddmmBackward0>)\n",
      "Student outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-1.3280,  0.2643,  1.0397],\n",
      "        [-1.3828,  1.3660, -0.2644],\n",
      "        [-1.4650,  1.2303, -0.3299],\n",
      "        [-1.4290,  0.9939,  0.1496],\n",
      "        [-1.4727,  1.0039,  0.3342],\n",
      "        [-1.4573,  0.3789,  0.9871],\n",
      "        [-1.6132,  0.2944,  1.2294],\n",
      "        [-1.3493,  1.3592, -0.1101],\n",
      "        [-1.3368,  1.4265, -0.2145],\n",
      "        [-1.4603,  1.4539, -0.3017],\n",
      "        [-1.4661,  0.3666,  0.9550],\n",
      "        [-1.5135,  0.3873,  0.9126],\n",
      "        [-1.5073,  1.4797, -0.2143],\n",
      "        [-1.5975,  0.3499,  0.9059],\n",
      "        [-1.5099,  1.4472,  0.0490],\n",
      "        [-1.4847,  1.5136, -0.1943]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Student logits: tensor([[-1.3280,  0.2643,  1.0397],\n",
      "        [-1.3828,  1.3660, -0.2644],\n",
      "        [-1.4650,  1.2303, -0.3299],\n",
      "        [-1.4290,  0.9939,  0.1496],\n",
      "        [-1.4727,  1.0039,  0.3342],\n",
      "        [-1.4573,  0.3789,  0.9871],\n",
      "        [-1.6132,  0.2944,  1.2294],\n",
      "        [-1.3493,  1.3592, -0.1101],\n",
      "        [-1.3368,  1.4265, -0.2145],\n",
      "        [-1.4603,  1.4539, -0.3017],\n",
      "        [-1.4661,  0.3666,  0.9550],\n",
      "        [-1.5135,  0.3873,  0.9126],\n",
      "        [-1.5073,  1.4797, -0.2143],\n",
      "        [-1.5975,  0.3499,  0.9059],\n",
      "        [-1.5099,  1.4472,  0.0490],\n",
      "        [-1.4847,  1.5136, -0.1943]], grad_fn=<AddmmBackward0>)\n",
      "Epoch 3/3, Loss: 0.5899\n"
     ]
    }
   ],
   "source": [
    "# Now, distill the knowledge into the student model\n",
    "student_model = distillation_train_loop(student_model, teacher_model, train_dataset, val_dataset, tokenizer, epochs=3, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After the student model is trained, HuggingFace Trainer is used for evaluation. evaluate() method in Trainer does not perform training again, it only uses the student model in evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kv/563b5k8n4xg24_t9kd2d72c40000gn/T/ipykernel_56174/4119820128.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_student = Trainer(\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:07<00:00,  7.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 0.5431520938873291, 'eval_model_preparation_time': 0.0042, 'eval_runtime': 8.9747, 'eval_samples_per_second': 108.081, 'eval_steps_per_second': 6.797}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer_student = Trainer(\n",
    "    model=student_model,\n",
    "    args=training_args,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Evaluate the student model\n",
    "results = trainer_student.evaluate()\n",
    "print(f\"Evaluation Results: {results}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:07<00:00,  8.04it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer_student.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(predictions.predictions, axis=-1)\n",
    "\n",
    "true_labels = predictions.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8062\n",
      "Precision: 0.8145\n",
      "Recall: 0.8062\n",
      "F1 Score: 0.7975\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLprojectenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
